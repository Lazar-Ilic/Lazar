	~9999 Tasks In Competitive Programming
	Lazar Ilic

The target of this document is to record many little tricks and insights from the broader competitive programming corpus in a highly legible terse little review document to assist in preparation for big important rounds. Notes and key ideas, as well as tasks and editorials. Perhaps I will aspire to trawling through ~9999 tasks and editorials, and write up relevant new-to-me cruxes. Many thanks to fellow web loggers.

	Number Theory
	Trees
	Tree Heaps
	More Esoteric Data Structures
	Web Logs
	Maxwell Zhang

	Number Theory

AtCoder. Project Leonhard Euler.

Maxwell Zhang:
https://github.com/mzhang2021/cp-blog/blob/master/_posts/2021-09-04-burnside.md

"
Yet Another Competitive Programming Blog
Studies say your rating will increase exponentially after reading.

Burnside's Lemma
Disclaimer: I typed this up a few months prior to making this website as personal notes for myself, so it's possible that the article may be unclear in certain sections. If you have any tips on making certain sections clearer, feel free to comment below.

Burnside's lemma is a topic that's often explained in a group theory context and in a very abstract manner. Here I will attempt to document a more intuitive explanation of the lemma.

Main Idea
Consider the following simple problem: Given a cube, if we color each face one of three colors, how many rotationally distinct colorings are there?

The condition of being rotationally distinct means we have to account for an intractable amount of cases. For example, what if the opposite sides are the same color? Or what if this subset of sides are the same color? The casework gets tedious very quickly, so Burnside's Lemma helps us simplify that casework.

The statement of Burnside's Lemma:

|Classes|=1|G|∑π∈GI(π)

That's a very dense definition! In simple terms, we say the number of rotationally distinct colorings is equal to the average over all ways of transforming the object.

Wait what?
We use the example of a cube.

First, let's say our cube is locked in place, we cannot rotate it in any way. The number of colorings is then 36: we have 3 choices of colors for each of the 6 faces.

Now, let's consider the next method of transformation: the cube rotates 90∘ counterclockwise along the axis through the top and bottom face:

(It's difficult to draw 3D on a 2D plane, so I've shaded the two faces the axis goes through in green)

Essentially, we want to count the number of colorings of this cube, where each coloring maps to itself via a single 90∘ counterclockwise rotation about the red axis. I think these are called “fixed points.” Let's say we color the front face blue. Note that this means in all colorings of this group, the right face must also be blue. Why? Because all colorings must be able to “reach” one another with the power of a single 90∘ counterclockwise rotation. Applying this same argument repeatedly, we note that therefore all four lateral faces must be blue. So in total, there are 33 distinct colorings for this group: one color for the top face, one color for the bottom face, and one color for all four lateral faces.

Let's consider another transformation: a 90∘ clockwise rotation about the red axis. This, as you might guess, is the exact same as the previous case, so we get 33 colorings from this group.

Here's a more interesting transformation: a 180∘ rotation about the red axis (note I didn't specify clockwise or counterclockwise since they're the same). In this case, the front face must match the back face, but the front face need not match the right face, because there is no way to apply a 180∘ rotation to map the front face onto where the right face would be. Thus, we have 34 colorings for this group: top, bottom, left/right, and front/back.

We will continue these calculations with all transformative methods, with others such as rotating about the axis through the left and right face, or rotating about the axis through opposite corners. You can see all the calculations enumerated in this video. In total, there are 24 different groups. The number of rotationally distinct colorings ends up being 57.

Atcoder ABC 198F: Cube
Same problem as our cube coloring problem, but instead of colorings, we write numbers on each face such that they sum to a constant S≤1018.

Applying Burnside's Lemma will give us equations for which we have to count the number of solutions to. For example, a+b+4c=S. Many methods of counting solutions to such an equation become intractable when S is large or when we have many variables. A simple way is using matrix exponentiation: let dpS be the number of solutions to a+b+4c=S. Using the inclusion-exclusion principle, we get the recurrence dpS=dpS−1+dpS−1+dpS−4−dpS−2−dpS−5−dpS−5+dpS−6. Essentially, we add all ways based on choosing a,b, or c as our next variable to increase by 1. However, increasing a by 1, then b, versus increasing b by 1, then a, are equivalent, so we subtract out one occurrence of counting both a and b increasing by 1. Then, we over-subtracted out increasing a,b,c all by 1, so we add that back. The complexity of our solution is thus (logS), ignoring constant factors.

Colored Beads on Necklace
Say we have a necklace with N pearls, each which can be colored one of M different colors. How many rotationally distinct colorings are there? This problem is the example used in the Competitive Programmer's Handbook.

Our transformation possibilities are rotate 0, rotate 1, rotate 2, ..., rotate n−1 beads clockwise. With no rotation, the number of ways is MN. With one rotation, we reduce it down to just M ways, since each bead must share the same color as the next. With rotating by 2, we have M2 ways because all beads at even positions must share a color, and all beads at odd positions must share a color, but there is no relation between beads of different parity positions. In general, if we rotate by k
, we have Mgcd(k,N) ways.

To prove this, we essentially want to count the number of unique values of (i+kp)mod N for all positions 0≤i<N and p≥0. Let's find the minimum p until the position maps back to itself (i.e. kp = 0mod N ), which happens when p=N/gcd(k,N). One way of thinking about this is that k already contains some part of the prime factorization of N, namely gcd(k,N), and we need the other part of the factorization present in p. So if each component is of size N/gcd(k,N), then we have N/(N/gcd(k,N))=gcd(k,N) components.

Thus, our answer is

1N∑k=0N−1Mgcd(k,N)

Colored Beads on Necklace with Reflection
Same problem as previous, but now two necklaces are also identical if we allow reflections alongside rotations.

To make sure we're not accidentally counting the same transformation twice, we always reflect over the horizontal axis first, then rotate. So we have 2N different transformations. And when I reflect, that means positions i and N−i map onto each other, assuming zero-based indexing. There isn't an easy closed-form way of expressing this, but we don't have to use a closed form. If we use DSU to merge together indices that map onto each other after the transformation, we can just count the number of components at the end. So this actually gives an algorithmic way of counting the fixed points, which is easily generalized to other problems!

By the way, there is a closed form of expressing this. First, we add up ∑N−1k=0Mgcd(k,N) to account for rotation without reflection. Now for reflection, instead of reflecting and then rotating, we can just rotate the reflection axis itself. For odd N, we have N choices of a reflection axis, where each goes through exactly one bead and the center of the circle, giving us MN/2+1 ways to color (N/2 pairs formed over the reflection axis, plus 1 for the single bead that we initially chose). For even N, we have N/2 reflection axes that go through two beads, and N/2 reflection axes that go through no beads but are instead in between beads, giving us N/2⋅MN/2+1+N/2⋅MN/2 ways. Finally, we divide our total by 2N to get our answer.

References
https://www.youtube.com/watch?v=6kfbotHL0fs

https://cp-algorithms.com/combinatorics/burnside.html
"

	Trees

Breadth First Search


Depth First Search


Meta Hacker Cup 2023 Round 2 Task C
Interesting. Firstly, it ought to be noted that one may compress up any path so that afterwards without loss of generality each node has >1 child. Now it follows from the usual natural bottoms up Breadth First Search Tree Dynamic Program strategy of generating hitting paths upwards towards the root that each relevant string must have multiplicity at least L, the number of leafs on the tree. So we may go through and filter down to those strings and then execute quite simply upon them.

	Tree Heaps

	More Esoteric Data Structures

	Web Logs

	Maxwell Zhang
	https://github.com/mzhang2021/cp-blog/tree/master/_posts

"
---
layout: post
title: "First Post"
tags: [intro]
featured: true
---

Welcome to my blog! I go by [smax](https://codeforces.com/profile/smax) on Codeforces and most other competitive programming sites, and this is a fun personal project for me that I've always wanted to do. On this blog, I'll post articles about techniques, tricks, opinions, or pretty much anything remotely related to CP. Do check it out if you're interested. This site is powered by <a href="https://jekyllrb.com/">Jekyll</a> and the <a href="https://github.com/wowthemesnet/mediumish-theme-jekyll">"Mediumish"</a> theme, so if you like how the site looks be sure to check those out.

<!-- For starters, here's a link to my first tutorial article on [Burnside's Lemma]({{ site.baseurl }}/burnside/). I typed this up a few months prior to making this website as personal notes for myself, so it's possible that the article may be unclear in certain sections. If you have any tips on making certain sections clearer, feel free to comment below.

If you're instead interested in something more opinionated, you can check out [this article]({{ site.baseurl }}/difficulty/) on what makes a CP problem hard. If you find you like the stuff I post, feel free to sign up for the mailing list by scrolling down and clicking on the alert, so that you get instantly notified whenever I post. -->

## FAQ
### I found your blog but have no idea what competitive programming is. What is it?
Competitive programming (or CP for short) refers to programming competitions where contestants try to solve challenging algorithm problems as quickly as possible. The problems often utilize ingenious applications of traditional algorithms and data structures or deploy slick math/logic tricks, making them very enjoyable to try to come up with solutions for. If you're thinking of trying it out, just make an account on [codeforces.com](https://codeforces.com) and try your hand at some problems at this [link](https://codeforces.com/problemset?order=BY_RATING_ASC). The column with numbers (such as 800) refers to the difficulty of the problem, so you can skip forward a few pages any time you're ready to move to the next difficulty level.

### Why not just post blogs on Codeforces? Why make a separate blog?
1. I'm trying to learn web development anyways, so I figured I'd make my first personal web dev project this blog.
2. Not everything I post here will be useful for the general public, and I don't want to spam on Codeforces forums. Occasionally, if I write some really useful tutorial or something, I might consider making a redirect post on Codeforces.

### How often will you post?
Whenever I have a good idea, I'll try to make a post. In practice it'll probably be once a month. You can subscribe to the mailing list by scrolling down and filling in the form in the alert so that you get notified whenever I post.

### How long will this blog run for?
I plan on keeping this blog alive for as long as I feel motivated, minimum one year after release so that this doesn't become yet another CP initiative advertised on Codeforces that dies after a few weeks.

### What's your setup?
I use [VS Code](https://code.visualstudio.com/) with some [scripts](https://github.com/mzhang2021/cp-library/tree/master/scripts/parse) for scraping test cases from online judges and running them.

### Do you have an implementation library?
[Yes.](https://github.com/mzhang2021/cp-library)

### I have a question that's not on here.
Ask in the comments, and I might update this post with it.

---
layout: post
title: "Burnside's Lemma"
tags: [tutorial, math]
usemathjax: true
---

**Disclaimer:** I typed this up a few months prior to making this website as personal notes for myself, so it's possible that the article may be unclear in certain sections. If you have any tips on making certain sections clearer, feel free to comment below.

---

Burnside's lemma is a topic that's often explained in a group theory context and in a very abstract manner. Here I will attempt to document a more intuitive explanation of the lemma.

## Main Idea

Consider the following simple problem: Given a cube, if we color each face one of three colors, how many **rotationally distinct** colorings are there?

The condition of being rotationally distinct means we have to account for an intractable amount of cases. For example, what if the opposite sides are the same color? Or what if this subset of sides are the same color? The casework gets tedious very quickly, so Burnside's Lemma helps us simplify that casework.

The statement of Burnside's Lemma:

$$
|\text{Classes}| = \frac{1}{|G|} \sum_{\pi \in G} I(\pi)
$$

That's a very dense definition! In simple terms, we say the number of rotationally distinct colorings is equal to the average over all ways of transforming the object.

## Wait what?

We use the example of a cube.

First, let's say our cube is locked in place, we cannot rotate it in any way. The number of colorings is then $3^6$: we have $3$ choices of colors for each of the $6$ faces.

Now, let's consider the next method of transformation: the cube rotates $90^\circ$ counterclockwise along the axis through the top and bottom face:

![image 1]({{ site.baseurl }}/assets/images/burnside-1.png)

(It's difficult to draw 3D on a 2D plane, so I've shaded the two faces the axis goes through in green)

Essentially, we want to count the number of colorings of this cube, where **each coloring maps to itself via a single $90^\circ$ counterclockwise rotation about the red axis.** I think these are called "fixed points." Let's say we color the front face blue. Note that this means in all colorings of this group, the right face must also be blue. Why? Because all colorings must be able to "reach" one another with the power of a single $90^\circ$ counterclockwise rotation. Applying this same argument repeatedly, we note that therefore all four lateral faces must be blue. So in total, there are $3^3$ distinct colorings for this group: one color for the top face, one color for the bottom face, and one color for all four lateral faces.

Let's consider another transformation: a $90^\circ$ clockwise rotation about the red axis. This, as you might guess, is the exact same as the previous case, so we get $3^3$ colorings from this group.

Here's a more interesting transformation: a $180^\circ$ rotation about the red axis (note I didn't specify clockwise or counterclockwise since they're the same). In this case, the front face must match the back face, but the front face need not match the right face, because there is no way to apply a $180^\circ$ rotation to map the front face onto where the right face would be. Thus, we have $3^4$ colorings for this group: top, bottom, left/right, and front/back.

We will continue these calculations with all transformative methods, with others such as rotating about the axis through the left and right face, or rotating about the axis through opposite corners. You can see all the calculations enumerated in [this video](https://youtu.be/6kfbotHL0fs?t=744). In total, there are $24$ different groups. The number of rotationally distinct colorings ends up being $57$.

## [Atcoder ABC 198F: Cube](https://atcoder.jp/contests/abc198/tasks/abc198_f)

Same problem as our cube coloring problem, but instead of colorings, we write numbers on each face such that they sum to a constant $S \leq 10^{18}$.

Applying Burnside's Lemma will give us equations for which we have to count the number of solutions to. For example, $a + b + 4c = S$. Many methods of counting solutions to such an equation become intractable when $S$ is large or when we have many variables. A simple way is using matrix exponentiation: let $dp_S$ be the number of solutions to $a + b + 4c = S$. Using the inclusion-exclusion principle, we get the recurrence $dp_S = dp_{S-1} + dp_{S-1} + dp_{S-4} - dp_{S-2} - dp_{S-5} - dp_{S-5} + dp_{S-6}$. Essentially, we add all ways based on choosing $a, b, $ or $c$ as our next variable to increase by $1$. However, increasing $a$ by $1$, then $b$, versus increasing $b$ by $1$, then $a$, are equivalent, so we subtract out one occurrence of counting both $a$ and $b$ increasing by $1$. Then, we over-subtracted out increasing $a, b, c$ all by $1$, so we add that back. The complexity of our solution is thus $\mathcal O(\log S)$, ignoring constant factors.

## Colored Beads on Necklace

Say we have a necklace with $N$ pearls, each which can be colored one of $M$ different colors. How many rotationally distinct colorings are there? This problem is the example used in the Competitive Programmer's Handbook.

Our transformation possibilities are rotate $0$, rotate $1$, rotate $2$, $\dots$, rotate $n - 1$ beads clockwise. With no rotation, the number of ways is $M^N$. With one rotation, we reduce it down to just $M$ ways, since each bead must share the same color as the next. With rotating by $2$, we have $M^2$ ways because all beads at even positions must share a color, and all beads at odd positions must share a color, but there is no relation between beads of different parity positions. In general, if we rotate by $k$, we have $M^{\gcd(k, N)}$ ways.

To prove this, we essentially want to count the number of unique values of $(i + kp) \mod N$ for all positions $0 \leq i < N$ and $p \geq 0$. Let's find the minimum $p$ until the position maps back to itself (i.e. $kp = 0 \mod N$), which happens when $p = N / \gcd(k, N)$. One way of thinking about this is that $k$ already contains some part of the prime factorization of $N$, namely $\gcd(k, N)$, and we need the other part of the factorization present in $p$. So if each component is of size $N / \gcd(k, N)$, then we have $N / (N / \gcd(k, N)) = \gcd(k, N)$ components.

Thus, our answer is

$$
\frac{1}{N} \sum_{k=0}^{N-1} M^{\gcd(k, N)}
$$

## Colored Beads on Necklace with Reflection

Same problem as previous, but now two necklaces are also identical if we allow reflections alongside rotations.

To make sure we're not accidentally counting the same transformation twice, we always reflect over the horizontal axis first, then rotate. So we have $2N$ different transformations. And when I reflect, that means positions $i$ and $N - i$ map onto each other, assuming zero-based indexing. There isn't an easy closed-form way of expressing this, but we don't have to use a closed form. If we use DSU to merge together indices that map onto each other after the transformation, we can just count the number of components at the end. So this actually gives an algorithmic way of counting the fixed points, which is easily generalized to other problems!

By the way, there is a closed form of expressing this. First, we add up $\sum_{k=0}^{N-1} M^{\gcd(k, N)}$ to account for rotation without reflection. Now for reflection, instead of reflecting and then rotating, we can just rotate the reflection axis itself. For odd $N$, we have $N$ choices of a reflection axis, where each goes through exactly one bead and the center of the circle, giving us $M^{N/2 + 1}$ ways to color ($N / 2$ pairs formed over the reflection axis, plus $1$ for the single bead that we initially chose). For even $N$, we have $N / 2$ reflection axes that go through two beads, and $N / 2$ reflection axes that go through no beads but are instead in between beads, giving us $N / 2 \cdot M^{N / 2 + 1} + N / 2 \cdot M^{N / 2}$ ways. Finally, we divide our total by $2N$ to get our answer.

## References

[https://www.youtube.com/watch?v=6kfbotHL0fs](https://www.youtube.com/watch?v=6kfbotHL0fs)

[https://cp-algorithms.com/combinatorics/burnside.html](https://cp-algorithms.com/combinatorics/burnside.html)

[Competitive Programmer's Handbook](https://github.com/pllk/cphb/)

---
layout: post
title: "What Makes a Problem Hard?"
tags: [opinion]
usemathjax: true
---

Just go to the comment section of any announcement blog for a contest, and you'll likely see a comment like "A < C < B" or "E was much easier than D." Or look at any leaderboard, and there's always at least a few contestants who solve the problems out of order or skip some problem. Problem difficulty is a very subjective thing, and it's always near impossible to create a set of problems such that A is strictly easier than B, which is strictly easier than C, and so on. Why is that the case, and what makes a problem difficult?

## Knowledge
The difficulty of the algorithms and concepts used for a problem definitely contribute to problem difficulty. For instance, greedy is a very fundamental concept, and applying the "greedy" tag in Codeforces problemset yields problems of all difficulties from 800 to 3500. On the other hand, applying the "flows" tag quickly brings problems up to the 1800-2000+ range, and applying the "fft" tag almost guarantees the problem is at least 2000+ in rating, because of the complexity of these algorithms (at the time of writing this, there is an 800 problem marked with "flows", but I am almost certain that is a troll).

## Search Space
This aspect is one that I think gets overlooked the most when people claim a problem is too easy for its spot in a contest. When you approach a problem, there are a lot of ways you can go about it, and a lot of potential approaches to try. Not all approaches will lead to the solution. Take [this problem](https://codeforces.com/contest/1491/problem/F) for example. It's a 2700 rated interactive problem. And if you've read the editorial or know the solution, you might conclude that the problem should be rated way lower because the solution is so elementary. But the difficulty of this problem doesn't come the complexity of the concepts used, but the sheer size of its search space. I did this contest live, and I remember trying all sorts of different ways to take advantage of the $\lfloor \log_2{n} \rfloor$ bound in queries, some very close to the editorial idea.

## Number of Observations/Steps
Partly related to search space is the number of layers of observation you have to get through to solve the problem. Div 2 As and Bs typically only have one key observation that cracks the entire problem, which is why they can be solved in mere minutes by high rated contestants and have low ratings (as an aside, an unfortunate consequence of these problems is that sometimes solving them can be dumb luck because of how unmotivated the observations can be, and even a high rated contestant could get "stuck" on one if they just happen to miss the observation). On the other hand, a more difficult problem often contains multiple layers of reduction to get to the final solution.

The example I'll use is [Falling Sand](https://codeforces.com/contest/1534/problem/F2), which is a problem with several steps. In my opinion, each individual step is not difficult, but it can be difficult to assemble all of the necessary steps during a live contest. The solution breaks down as follows:

<div class="spoiler">
<ol>
<li>Recognize that the relation between the blocks of sand can be modeled as a directed graph, where block A can reach block B if perturbing block A will cause it to perturb block B when falling.</li>
<li>The directed graph actually only contains $\mathcal O(nm)$ edges, as it is sufficient to draw an edge from a block to the closest block below it in its adjacent columns.</li>
<ol>
<li>The above two observations are sufficient to solve F1. In F1, we just need to make all the sand blocks fall, so after compressing the graph into a DAG of SCCs, we can count the number of nodes with an indegree of 0 as our answer.</li>
</ol>
<li>In F2, we don't need to make all the sand blocks fall, just $a_i$ in each column. It is always optimal to prioritize making the bottommost $a_i$ blocks fall in each column $i$, as those blocks will always fall anyways in any optimal solution.</li>
<li>Let's consider the set of nodes with indegree 0 in the DAG after condensing into SCCs, denoted as $S$. Obviously it is optimal to only perturb nodes in $S$ directly, because if we perturb some lower node, we could have perturbed one of its ancestors instead and achieved the same effect (yeah I know I'm using the words "node" and "block" interchangeably). Now let's consider the nodes that need to be perturbed. Notice that the subset of $S$ which can reach that node, directly or indirectly, are always contiguous if $S$ is sorted by column. If a node in column $i$ can reach our target node, and a node in column $j > i$ can also reach our target node, some node in $S$ in column $k$ such that $i < k < j$ would also be able to reach our target node.</li>
<ol>
<li>To understand why that is true, notice that the structure of how blocks get perturbed is always "hit all blocks in this and adjacent columns," so there's a "path" of contiguous nodes from column $i$ to column $j$ for some node in column $i$ to be able to reach column $j$. Since the nodes in $S$ are always the highest nodes in their column, there's no way they would not be able to reach the "path" if they were in some column $k$ such that $i < k < j$. To understand what I'm talking about, refer to the diagram below (red blocks are in $S$, green is our target block):</li>
</ol>
<img src="{{ site.baseurl }}/assets/images/difficulty-1.png" alt="image 1">
<li>Therefore, the problem reduces down to picking the minimum number of nodes in $S$ to cover all intervals. This is a well known problem with a greedy solution: sort the intervals by right endpoint, and whenever an interval is not covered, increase the answer by 1 and pick the node on the interval's right endpoint.</li>
</ol>
</div>

## Combining Search Space and Number of Observations
Let's say the search space of a problem is a graph. You start at the beginning, and you want to reach the solution by traversing through a path of nodes by making a series of observations. Then a larger search space refers to larger degree nodes, and more observations means the path to the solution is longer. So an easy problem might look something like this:

![image 2]({{ site.baseurl }}/assets/images/difficulty-2.png)

or this:

![image 3]({{ site.baseurl }}/assets/images/difficulty-3.png)

The first diagram is what a Div 2 A might look like: there's one observation, and if you find it you solve the problem. The second diagram is what an easy DS problem might look like: there might be multiple steps, but each step is very obvious to get to. Naturally, a hard problem both has high degree nodes and a long path:

![image 4]({{ site.baseurl }}/assets/images/difficulty-4.png)

If you're a strong competitive programmer with lots of problem solving expertise, the problem search space might look more like this to you:

![image 5]({{ site.baseurl }}/assets/images/difficulty-5.png)

The red Xs are a result of experience: you know which ideas tend to work better, and you know how to approach certain types of problems.

And to complete this analogy, if you're missing knowledge or experience, the problem might look like this to you:

![image 6]({{ site.baseurl }}/assets/images/difficulty-6.png)

You're missing edges altogether, so you might not even be able to solve the problem, but those edges will appear with practice and time.

## Implementation
There's one aspect of problem solving I have not mentioned yet: after coming up with the idea, you still need to write the code! So what makes implementation difficult?
1. Lines of Code - When I say lines of code, I exclude templated code. Take [Good Graph](https://codeforces.com/contest/1555/problem/F) as an example. Most submissions have lines of code in 3 digits, but a large portion of this problem is just copy pasting heavy light decomposition or segment tree, so the actual difficulty of implementation is low. On the flip side, [Binary Table](https://codeforces.com/contest/1439/problem/A2) was a problem with a notoriously long and difficult implementation for its spot in the contest. It's not too bad for experienced contestants, but it's definitely way more implementation heavy than a Div 1 A should be.
2. Finnicky Details - I've encountered plenty of problems where working out the indexing was a pain in the ass, or the problem had many cases to consider. In recent memory, [Minimax](https://codeforces.com/contest/1530/problem/E) had an obnoxious amount of cases, and my [implementation](https://codeforces.com/contest/1530/submission/122824719) in contest ended up being extremely messy. It's honestly a miracle that I could even get it to work at all. [Funny Substrings](https://codeforces.com/contest/1538/problem/E) was another problem where I had a disgusting [implementation](https://codeforces.com/contest/1538/submission/119011583) in contest that demanded a high attention to detail, although this one was more my fault for overlooking a simpler solution.
3. Constant Factor Optimization - It's always frustrating when you have the correct complexity, but your solution is too slow because of unnecessarily tight limits set by the authors. There are ways to minimize this happening by adopting certain strategies. For example, I always pass non-primitives by const reference to functions, and I avoid STL data structures when not needed because C++ STL data structures like `std::set` and `std::map` consume a non-trivial amount of overhead.

## So back to the original question...
Different people have different opinions on problem difficulty because they've practiced and become more experienced in different skills. Each person's graph for the search space will look different. And the problemsetter's opinion of difficulty often differs drastically from competitors because they sometimes come up with the solution before the problem, or craft the problem with a specific solution in mind already.

## The Takeaway
Is there a takeaway from this article? I don't know. I'm moreso just expressing an opinion on a subject that I've given some thought about. That being said, I do think the way I think about problem solving provides some insight into how I think improving at CP works: as you practice, you expand the number of edges you can access, and you also get better at pruning bad edges. Maybe in the future I'll write an article on how to practice. Thanks for reading, and feel free to leave your thoughts on this subject in the comments below.

---
layout: post
title: "Applications of Divide and Conquer"
tags: [tutorial, algo]
usemathjax: true
---

Divide and conquer (D&Q for short) is a common and powerful problem solving paradigm in the world of algorithms. There are numerous well-known examples such as merge sort and fast Fourier transform, and in this article I will cover some (maybe less common) applications of D&Q that are more specific to competitive programming. The sections progress from simple to complex, so more experienced competitors can skip to a later section of the article.

## Core Concept
The core concept of D&Q is to divide our problem into subproblems, then combine them together in some way. Consider the classic example of merge sort, a D&Q algorithm to sort an array. Let's write a recursive function `sort(a)` which will sort the array $a$. First, we can split our array into two halves and sort each of those halves recursively with `sort(left)` and `sort(right)`:

```c++
void sort(vector<int> &a) {
    int n = (int) a.size();
    if (n == 1)
        return;
    int m = n / 2;
    // two halves denoted "left" and "right"
    vector<int> left, right;
    for (int i=0; i<m; i++)
        left.push_back(a[i]);
    for (int i=m; i<n; i++)
        right.push_back(a[i]);
    sort(left);
    sort(right);
    // now we need to combine the result of the two halves in some way
}
```

Then, after we've sorted the two individual halves, we can merge them together in linear time with the following algorithm:

```c++
// merges two sorted arrays into one sorted array
int n = (int) left.size(), m = (int) right.size(), i = 0, j = 0;
vector<int> comb;
while (i < n || j < m) {
    if (i < n && (j == m || left[i] < right[j]))
        comb.push_back(left[i++]);
    else
        comb.push_back(right[j++]);
}
```

<details markdown="1" style="margin-bottom: 5%"><summary>Complete Mergesort Code</summary>

```c++
vector<int> merge(const vector<int> &left, const vector<int> &right) {
    int n = (int) left.size(), m = (int) right.size(), i = 0, j = 0;
    vector<int> comb;
    while (i < n || j < m) {
        if (i < n && (j == m || left[i] < right[j]))
            comb.push_back(left[i++]);
        else
            comb.push_back(right[j++]);
    }
    return comb;
}

void sort(vector<int> &a) {
    int n = (int) a.size();
    if (n == 1)
        return;
    int m = n / 2;
    vector<int> left, right;
    for (int i=0; i<m; i++)
        left.push_back(a[i]);
    for (int i=m; i<n; i++)
        right.push_back(a[i]);
    sort(left);
    sort(right);
    a = merge(left, right);
}
```
</details>

In general, the code for any divide and conquer algorithm might look something like this:

```
solve(whole part) {
    solve(left part)
    solve(right part)
    combine(result of solve(left part), result of solve(right part))
}
```

Analyzing the time complexity of a D&Q algorithm isn't always obvious, and the most common way it's done in literature is using the [master theorem](https://en.wikipedia.org/wiki/Master_theorem_(analysis_of_algorithms)). However, I personally don't find the master theorem very intuitive, so I prefer to just analyze the complexity by looking at the recursive tree of states. To explain what I mean, take a look at the following diagram for merge sort:

![image 1]({{ site.baseurl }}/assets/images/divide-and-conquer-1.png)
<div style="text-align: center; margin-bottom: 5%"><em>Image courtesy of <a href="https://www.interviewbit.com/tutorial/merge-sort-algorithm/">InterviewBit</a></em></div>

To understand the complexity of merge sort, we note that the height of the recursive tree is at most $\mathcal O(\log n)$, because on each layer the size of the subarrays we are working with get halved, and we can only half an array of size $n$ at most $\log_2 n$ times. On each layer, we are merging together two subarrays from the next layer, and the sum of all subarray sizes is the size of the original array, or $n$. Since we do $\mathcal O(n)$ work on each of $\mathcal O(\log n)$ layers, the complexity of merge sort is $\mathcal O(n \log n)$.

This was a traditional simple example, so now let's jump into some harder problems!

## [Codeforces Edu 94E: Clear the Multiset](https://codeforces.com/problemset/problem/1400/E)

The problem essentially translates to the following: given an array, we can perform two types of operations:
1. Subtract 1 from some subarray of non-zero values.
2. Subtract any positive $x$ from any one value.

What is the minimum number of operations to reduce the array to all 0s?

There is an approach to this problem using dynamic programming, but let's consider a D&Q approach. Let's denote `solve(l, r)` as the minimum number of operations to reduce the subarray $a[l, r]$ to 0. For now, assume $a_i > 0$. An upper bound on our answer is `r - l + 1` by applying the type 2 operation to reduce each array element to 0. Now what if we want to perform type 1 operations? Note that it's always optimal to apply type 1 operations to the entire subarray, because that gets us closer to reducing all of them to 0. It is never optimal to use type 1 operations on some subset of the subarray, then type 2 operations in between, because we can achieve the same effect by applying type 1 operations to the entire array when possible and use less operations. We can apply type 1 operations until some element gets reduced to 0, which will first be the minimum element. After some index $a_m$ gets reduced to 0, we can compute and add `solve(l, m - 1)` and `solve(m + 1, r)` as subproblems. The code looks as follows:

```c++
int solve(int l, int r) {
    if (l > r)
        return 0;
    // we will apply type 1 operation (min a_i) times
    int mn = *min_element(a.begin() + l, a.begin() + r + 1), idx = -1;
    for (int i=l; i<=r; i++) {
        a[i] -= mn;
        if (a[i] == 0)
            idx = i;    // split at the index that drops to 0 (notice that ties don't matter)
    }
    assert(idx != -1);
    // return minimum of our two options: solve recursively, or just apply type 2 operations to each element
    return min(solve(l, idx - 1) + solve(idx + 1, r) + mn, r - l + 1);
}
```
<details markdown="1" style="margin-bottom: 5%"><summary>An Aside</summary>
Notice that this code allows applying type 2 operations on some $a_i = 0$, which is technically not allowed. Luckily, we will never do that in the optimal solution anyways, so it's ok that our code permits this possibility. This is actually a very common trick in CP: relaxing the conditions of the problem to ease the implementation because we know the optimal solution will follow a stricter set of conditions. [This problem](https://codeforces.com/contest/1473/problem/E) is another example of that trick (though it's not a D&Q problem).
</details>

One question left: what's the time complexity? One way of bounding the time complexity is doing the same thing we did in our merge sort example: bound the height of the recursive tree and the amount of work we perform on each height. The worst case would be doing uneven splits every time (i.e. always having the minimum element be $l$): $[1, n] \implies [2, n] \implies [3, n] \implies \dots$, giving us $\mathcal O(n)$ height. On each layer, we iterate over all the elements in the array at most once in one of the states on that layer, giving us $\mathcal O(n)$ work per layer, so our complexity is $\mathcal O(n^2)$, which is fast enough for the constraints of this problem.

Another approach is simply counting the number of total states. A naive bound would be $\mathcal O(n^2)$ states, since there are $\frac{n(n+1)}{2}$ possible subarrays, but we can prove a better bound. Consider this crudely drawn recursive tree:

![image 2]({{ site.baseurl }}/assets/images/divide-and-conquer-2.png)
<div markdown="1" style="text-align: center; margin-bottom: 5%">A circle with some $[l, r]$ written on it represents the recursive state `solve(l, r)`.
</div>

In this diagram, I actually include the minimum index still, so instead of splitting $[l, r]$ into $[l, m - 1]$ and $[m + 1, r]$, I split it into $[l, m]$ and $[m + 1, r]$. I do this because this is a general proof that extends to other problems, and including $m$ in one of the intervals can only make the complexity worse, so the proof still applies to this problem.

Now here's the intuition: let's pretend indices $1, 2, \dots, n$ actually refer to nodes in a graph. The state $[l, r]$ refers to a connected component of vertices $l, l + 1, \dots, r$. And initially, we have $[1, n]$ representing a line graph with edges connecting $(i, i + 1)$ for all $1 \leq i < n$, or $n - 1$ total edges. What does a split of a state into two other states represent in this analogy? It represents deleting some edge $(m, m + 1)$ and splitting the component into two separate ones. And since we can only delete at most $n - 1$ edges, we only have at most $2(n - 1) + 1$ states, or $\mathcal O(n)$ states! A naive bound on the amount of work we do at each state is $\mathcal O(n)$, so the complexity is $\mathcal O(n^2)$.

Notice that our second way of analyzing the complexity more easily lends itself to a subquadratic solution. Instead of naively iterating to find the minimum index, we can use a [RMQ sparse table](https://cp-algorithms.com/data_structures/sparse-table.html#toc-tgt-3) to instantly find it in $\mathcal O(1)$. And instead of subtracting `mn` from each index like in the code above, we notice that we're simply subtracting `mn` from every array element, so we can instead maintain some extra parameter `delta` in our recursive method to keep track of how much we've subtracted from all elements in our current range. So we've now reduced the amount of work done at each state to $\mathcal O(1)$, giving us an $\mathcal O(n)$ or $\mathcal O(n \log n)$, depending on how we precompute our sparse table.

<details markdown="1"><summary>$\mathcal O(n)$ Code</summary>

```c++
int solve(int l, int r, int delta) {
    if (l > r)
        return 0;
    // we will apply type 1 operation (min a_i) times
    int idx = sparse_table.query(l, r), mn = a[idx] - delta;
    // return minimum of our two options: solve recursively, or just apply type 2 operations to each element
    return min(solve(l, idx - 1, delta + mn) + solve(idx + 1, r, delta + mn) + mn, r - l + 1);
}
```
</details>

<details style="margin-bottom: 5%"><summary>An Aside</summary>
If you're familiar with top-down dynamic programming, you may recognize the similarities in code. You could think of this D&Q strategy as a special case of dynamic programming, except we don't need to memoize because our recursive structure is a tree, so each state is visited exactly once. If we were to draw a "recursive tree of states" for a typical dynamic programming problem, it would likely not be a tree, but be a DAG instead, so we would need memoization.
</details>

## [binarysearch.com: Every Sublist Containing Unique Element](https://binarysearch.com/problems/Every-Sublist-Containing-Unique-Element)

*I find this problem unusually hard for a coding interview question, especially one of "medium" difficulty, but I digress.*

We'll deploy a similar approach to the previous problem. Let `solve(l, r)` return `true` if every subarray contains a unique element, and `false` otherwise. Right off the bat, if $a[l, r]$ contains no unique element, then we are done and can return `false`. Otherwise, let's say $a_m$ is a unique element. Any subarray of $a[l, r]$ containing $a_m$ will for sure contain a unique element, which would be $a_m$, so a subarray of $a[l, r]$ containing no unique elements must not contain $a_m$. Thus, to search for the existence of such a subarray, we split into two subproblems `solve(l, m - 1)` and `solve(m + 1, r)`, and if any of those return `false`, we also return `false` from `solve(l, r)`. To check if there is a unique element, we can iterate over all elements and store them in a hashmap. The worst case complexity of this algorithm is $\mathcal O(n^2)$, since we visit $\mathcal O(n)$ states and perform $\mathcal O(n)$ work at each state.

We can apply a simple optimization: instead of splitting just at one index, we can split at every unique index. That is, if $a_{m_1}, a_{m_2}, \dots, a_{m_k}$ are all unique elements, then we can split `solve(l, r)` into `solve(l, a[m_1] - 1)`, `solve(a[m_1] + 1, a[m_2] - 1)`, ..., `solve(a[m_k] + 1, r)`. While the worst case complexity is still $\mathcal O(n^2)$, this optimization is sufficient to get AC on this problem. Weak test cases I guess.

<details markdown="1" style="margin-bottom: 5%"><summary>Optimized $\mathcal O(n^2)$</summary>

```c++
bool recur(int l, int r, const vector<int> &nums) {
    if (l >= r)
        return true;
    unordered_map<int, int> mp;
    for (int i=l; i<=r; i++)
        mp[nums[i]]++;
    int last = l;
    bool uniq = false;
    for (int i=l; i<=r; i++)
        if (mp[nums[i]] == 1) {
            uniq = true;
            if (!recur(last, i - 1, nums))
                return false;
            last = i + 1;
        }
    return uniq && recur(last, r, nums);
}

bool solve(vector<int>& nums) {
    return recur(0, (int) nums.size() - 1, nums);
}
```
The above code ACs in 235 ms.
</details>

But we can do better. We can achieve worst case $\mathcal O(n \log n)$. To do that, we apply the following optimization: instead of always iterating our for loop from the left to right, we iterate from both sides. So for the subarray $a[l, r]$, we first check $a_l$, then $a_r$, then $a_{l+1}$, then $a_{r-1}$, then $a_{l+2}$, and so on. We can check if some $a_m$ is unique in $a[l, r]$ in $\mathcal O(1)$ by precomputing `left[m]` and `right[m]`, arrays storing the index of the next occurrence of $a_m$ to the left or right of $a_m$. So if a state splits into two states of size $a$ and $b$, the amount of work done at that state is $\mathcal O(\min(a, b))$.

It turns out this single optimization is sufficient to achieve $\mathcal O(n \log n)$. To understand why, let's once again consult the recursive tree of states.

![image 2]({{ site.baseurl }}/assets/images/divide-and-conquer-2.png)

Once again, we use the analogy of nodes and components that we used in the previous problem (treating each state representing the range $[l, r]$ as a component of nodes $l, l + 1, \dots, r$). Instead of thinking of it as splitting a graph into individual nodes, let's think in reverse: we have $n$ nodes, and want to merge them into one component. Two child states merge to become one state. If we merge two components of size $a$ and $b$, we do $\min(a, b)$ work. Does this sound familiar? That's right, this is just [small-to-large](https://usaco.guide/plat/merging?lang=cpp) merging! In small-to-large merging, when we merge two components of size $a$ and $b$, we only iterate over the nodes in the smaller of the two components, so we do $\mathcal O(\min(a, b))$ work. That's essentially the same thing we're doing here: we only do $\mathcal O(\min(a, b))$ work since we only iterate as much as twice the size of the smaller subproblem in our divide and conquer (twice since we iterate on both ends). And so by the same analysis as small-to-large merging, our runtime is $\mathcal O(n \log n)$.

<details markdown="1" style="margin-bottom: 5%"><summary>Small-to-Large Complexity Proof</summary>
Consider merging two components $A$ and $B$, with sizes $|A|$ and $|B|$. WLOG, assume $|A| \leq |B|$. Small-to-large merging will iterate over each node in $A$ and add it to $B$, doing $\mathcal O(|A|)$ work. Let's track how many times we iterate over a node. If a node gets iterated over, it means it was in the smaller of two components being merged together. So after the merging, it will be in a component that is at least twice the size of its original component. The size of a component can only be doubled $\mathcal O(\log n)$ times before it reachs size $n$. So a node can only be iterated over at most $\mathcal O(\log n)$ times. Thus, when we sum up the work done on each of $n$ nodes, we get $\mathcal O(n \log n)$ complexity.
</details>

## [HackerRank: Find the Path](https://www.hackerrank.com/challenges/shortest-path/problem)

A naive solution is to run Dijkstra for each query, giving us a $\mathcal O(nmq \log (nm))$ approach. It's difficult to improve upon this online algorithm with some sort of precomputation, because the optimal path could go "backwards" or wrap around in any arbitrary snake-like path. So as you might have guessed, we'll solve this problem offline with D&Q on the queries.

<!-- Let's consider some recursive function `recur(l, r)` that will process queries with both endpoints lying in columns $[l, r]$. Consider column $m = \lfloor \frac{l + r}{2} \rfloor$. Any query with one endpoint to the left of this column and one endpoint to the right of this column must pass through this column at some point in its path. Another way of phrasing this is that any path between the two endpoints is a concatenation of two paths originating from column $m$. Since $n$ is small, we can brute force each cell in column $m$ and run Dijkstra from that cell, and update our answer for all queries accordingly. Afterwards, we call `recur(l, m)` and `recur(m + 1, r)`. We have a $\mathcal O(\log m)$ height recursive tree with $\mathcal O(n(nm \log (nm) + q))$ work on each layer, giving us $\mathcal O(n \log m (nm \log (nm) + q))$ as our final complexity. -->

Let's consider some recursive function `solve(l, r)` that will process queries for which the path between its endpoints lies in columns $[l, r]$. Consider column $m = \lfloor \frac{l + r}{2} \rfloor$. Any path in columns $[l, r]$ falls into one of three cases:
1. The path lies solely in columns $[l, m]$.
2. The path lies solely in columns $[m + 1, r]$.
3. The path exists in both halves and crosses over column $m$ (note that both endpoints can still be in the same half for this case).

Cases 1 and 2 will be handled in our recursive subproblems, `solve(l, m)` and `solve(m + 1, r)`. For case 3, notice that since our path crosses column $m$, it can be expressed as the concatenation of two paths originating from a single cell in column $m$. Since $n$ is small, we can brute force each cell in column $m$ and run Dijkstra from that cell, and update our answer for all queries with endpoints in columns $[l, r]$. We have a $\mathcal O(\log m)$ height recursive tree with $\mathcal O(n(nm \log (nm) + q))$ work on each layer, giving us $\mathcal O(n \log m (nm \log (nm) + q))$ as our final complexity.

<details markdown="1" style="margin-bottom: 5%"><summary>Old Messy Code Written 4 Months Ago</summary>

```c++
#include <bits/stdc++.h>
using namespace std;

const int INF = 1e9;

const int dx[] = {-1, 0, 1, 0};
const int dy[] = {0, 1, 0, -1};

typedef tuple<int, int, int> node;

int main() {
    ios_base::sync_with_stdio(false);
    cin.tie(NULL);

    int n, m;
    cin >> n >> m;
    vector<vector<int>> a(n, vector<int>(m));
    for (int i=0; i<n; i++)
        for (int j=0; j<m; j++)
            cin >> a[i][j];
    int q;
    cin >> q;
    vector<array<int, 5>> queries;
    for (int i=0; i<q; i++) {
        int r1, c1, r2, c2;
        cin >> r1 >> c1 >> r2 >> c2;
        queries.push_back({r1, c1, r2, c2, i});
    }

    vector<vector<vector<int>>> dist(n, vector<vector<int>>(n, vector<int>(m)));

    auto dijkstra = [&] (int s, int t, int l, int r) -> void {
        for (int i=0; i<n; i++)
            for (int j=l; j<=r; j++)
                dist[s][i][j] = INF;
        priority_queue<node, vector<node>, greater<node>> pq;
        pq.emplace(dist[s][s][t] = a[s][t], s, t);
        while (!pq.empty()) {
            auto [d, x, y] = pq.top();
            pq.pop();
            if (d > dist[s][x][y])
                continue;
            for (int i=0; i<4; i++) {
                int nx = x + dx[i], ny = y + dy[i];
                if (0 <= nx && nx < n && l <= ny && ny <= r && d + a[nx][ny] < dist[s][nx][ny])
                    pq.emplace(dist[s][nx][ny] = d + a[nx][ny], nx, ny);
            }
        }
    };

    vector<int> ret(q, INF);

    auto solve = [&] (auto &self, int l, int r, const vector<array<int, 5>> &queries) -> void {
        if (l > r)
            return;
        int x = (l + r) / 2;
        for (int i=0; i<n; i++)
            dijkstra(i, x, l, r);
        vector<array<int, 5>> left, right;
        for (auto [r1, c1, r2, c2, i] : queries) {
            for (int j=0; j<n; j++)
                ret[i] = min(ret[i], dist[j][r1][c1] + dist[j][r2][c2] - a[j][x]);
            if (c1 < x && c2 < x)
                left.push_back({r1, c1, r2, c2, i});
            else if (c1 > x && c2 > x)
                right.push_back({r1, c1, r2, c2, i});
        }
        self(self, l, x - 1, left);
        self(self, x + 1, r, right);
    };

    solve(solve, 0, m - 1, queries);
    for (int x : ret)
        cout << x << "\n";

    return 0;
}
```
</details>

## [CodeChef SEGPROD: Product on the Segment by Modulo](https://www.codechef.com/problems/SEGPROD)

This problem is very peculiar because of its abnormally large bounds and weird input method to facilitate that. Let's use the same approach as the previous problem, which is to D&Q on the queries. If our recursive method is currently processing the range $[l, r]$, then we can process all queries with the left endpoint $\leq m = \lfloor \frac{l + r}{2} \rfloor$ and right endpoint $> m$. To do this, we precompute $product[i, m]$ for all $l \leq i \leq m$ and $product[m + 1, i]$ for all $m < i \leq r$, and then each query is just the product of two precomputed values. Unfortunately, there are two issues with this approach:
1. The problem forces us to solve it online, and this is an offline algorithm.
2. The complexity is $\mathcal O((n + q) \log n)$, which is actually too much because $q \leq 2 \cdot 10^7$.

First, we can easily make our above algorithm online by storing all the prefix and suffix products precomputed at each layer, consuming $\mathcal O(n \log n)$ memory. Then, for each query, we can traverse recursively until we reach the correct layer, giving us $\mathcal O(\log n)$ per query.

Next, to improve our query complexity, we'll use the following trick. Let's round $n$ up to the nearest power of 2. Now take a look at the ranges we get in our recursive tree:

![image 3]({{ site.baseurl }}/assets/images/divide-and-conquer-3.png)

Notice anything peculiar? That's right, each state splits into two deeper states based on whether a bit is on or off. So to find the correct layer where the left and right endpoint of our query lie on different sides of $m$, we simply need to find the most significant bit where they differ. Or in other words, we need to find the most significant bit in the xor of the endpoints, which can be computed in $\mathcal O(1)$ using builtin functions like `__lg` or precomputing a lookup table. So we've reduced our complexity to $\mathcal O(n \log n + q)$, which is fast enough to get AC.

<details markdown="1" style="margin-bottom: 5%"><summary>Code</summary>

```c++
#include <bits/stdc++.h>
using namespace std;

int main() {
    ios_base::sync_with_stdio(false);
    cin.tie(NULL);

    int t;
    cin >> t;
    while (t--) {
        int n, p, q;
        cin >> n >> p >> q;
        int k = n == 1 ? 0 : __lg(n - 1) + 1;
        vector<int> a(1 << k);
        for (int i=0; i<n; i++)
            cin >> a[i];
        vector<int> b(q / 64 + 2);
        for (int &x : b)
            cin >> x;

        vector<vector<long long>> prod(k, vector<long long>(1 << k));

        auto recur = [&] (auto &self, int lg, int l, int r) -> void {
            if (lg < 0)
                return;
            int m = (l + r) / 2;
            for (int i=m-1; i>=l; i--)
                prod[lg][i] = a[i] * (i == m - 1 ? 1 : prod[lg][i+1]) % p;
            for (int i=m; i<r; i++)
                prod[lg][i] = a[i] * (i == m ? 1 : prod[lg][i-1]) % p;
            self(self, lg - 1, l, m);
            self(self, lg - 1, m, r);
        };

        auto query = [&] (int l, int r) -> int {
            if (l == r)
                return a[l];
            int lg = __lg(l ^ r);
            return prod[lg][l] * prod[lg][r] % p;
        };

        recur(recur, k - 1, 0, 1 << k);

        int x = 0, l, r;
        for (int i=0; i<q; i++) {
            if (i % 64 == 0) {
                l = (b[i / 64] + x) % n;
                r = (b[i / 64 + 1] + x) % n;
            } else {
                l = (l + x) % n;
                r = (r + x) % n;
            }
            if (l > r)
                swap(l, r);
            x = (query(l, r) + 1) % p;
        }
        cout << x << "\n";
    }

    return 0;
}
```
</details>

## CDQ Divide and Conquer
This final section refers to a specific application of D&Q: CDQ D&Q, which I first read about in [this Codeforces comment](https://codeforces.com/blog/entry/68263#comment-525816) and in the [linked PDF](https://assets.hkoi.org/training2018/dc.pdf). The general gist of the technique is as follows: say we have a data structure and two types of operations:
1. Update the data structure.
2. Query for some aggregate in the data structure.

Additionally, say this problem is much easier to solve offline than online. That is, if all the update operations came before all the query operations, then there exists some offline algorithm to solve it. CDQ D&Q allows us to solve the online version with an extra $\mathcal O(\log n)$ factor.

For our example problem, we'll use the one mentioned in [this blog](https://codeforces.com/blog/entry/68263). There is an online solution using 2D segment tree that solves this in $\mathcal O(q \log^2 q)$, but 2D segment tree has a non-trivial time and memory constant factor and is often difficult to squeeze into the problem bounds if not intended.

How do we solve this problem offline? This is a well-known problem: we perform a linesweep. Every time we encounter the right endpoint of an interval, we insert the length of that interval at the left endpoint of that interval in a segment tree. Every time we encounter the right endpoint of some query, we query for the maximum value in $[l, r]$ in the segment tree.

Now for the CDQ D&Q step: we will perform divide and conquer on the time of each operation (first operation is at time 1, second operation at time 2, etc.). When we are considering all operations with time in the range $[l, r]$, we will do the following: consider $m = \lfloor \frac{l + r}{2} \rfloor$. For all update operations with time $\leq m$, we insert them. For all query operations with time $> m$, we apply the offline algorithm to update their answers. In this case, we are considering the contribution of all update operations in $[l, m]$ to the query operations in $[m + 1, r]$. Any update contributions in $[1, l - 1]$ would have been considered on an earlier layer, and any update contributions in $[m + 1, r]$ will be considered in a later layer, when we recurse to $[m + 1, r]$. The code would look something like the following:

```c++
void solve(int l, int r) {
    if (l == r)
        return;
    int m = (l + r) / 2;
    solve(l, m);
    vector<Op> updates, queries;
    for (int i=l; i<=m; i++)
        updates.push_back(op[i]);
    for (int i=m+1; i<=r; i++)
        queries.push_back(op[i]);
    offlineAlgorithm(updates, queries);
    solve(m + 1, r);
}
```

You might be wondering, why am I calling `solve(l, m)` before computing the contribution of $[l, m]$ on $[m + 1, r]$, and not after? In this problem, it doesn't matter, but CDQ D&Q can also be applied to some dynamic programming problems where the order does matter. We would first call `solve(l, m)` to fully compute the final values of $dp[l, m]$. Once those DP values are final, we can rely on them to update the values $dp[m + 1, r]$. An example of this is in [this Atcoder problem](https://atcoder.jp/contests/abc213/tasks/abc213_h).

## Finale
Hopefully you gleaned something from this tutorial! I tried to order the article from simplest to most complicated techniques, and tried to explain stuff unambiguously but also concisely. If you have any feedback or questions, don't hesitate to drop a comment.

## Problems (Roughly Ordered Based on Techniques Used in Article)
[Codeforces Round 689D: Divide and Summarize](https://codeforces.com/contest/1461/problem/D)

[Codeforces Edu 105D: Dogeforces](https://codeforces.com/problemset/problem/1494/D)

[Codeforces Round 429D: Destiny](https://codeforces.com/problemset/problem/840/D)

[SPOJ ADACABAA: Ada and Species](https://www.spoj.com/problems/ADACABAA/)

[Atcoder ABC 213H: Stroll](https://atcoder.jp/contests/abc213/tasks/abc213_h)

This is a very short list, so comment any other problems you know.

## References (For CDQ D&Q)
[https://codeforces.com/blog/entry/68263?#comment-525816](https://codeforces.com/blog/entry/68263?#comment-525816)

[https://assets.hkoi.org/training2018/dc.pdf](https://assets.hkoi.org/training2018/dc.pdf)

---
layout: post
title: "Long Challenges are Awesome"
tags: [opinion]
usemathjax: true
---

Short contests are fun, although not without its fair share of frustrating moments. Have you ever come so close to solving a problem, but ran out of time? If only you had 10 extra minutes! Or have you ever "bricked" on a problem? That is, you come across a problem that should be within your rating range and easily solved, but you just can't think of the trick needed to solve it? This has happened to me many times, with the most recent example being [Global Round 15](https://codeforces.com/contest/1552/standings/participant/117714327#p117714327). I could not think of how to get past the naive $\mathcal O(n^2)$ solution for problem B for the longest time, and I had to skip that problem to do the other ones first in order to save my performance.

Now don't get me wrong. Codeforces contests are great, and the adrenaline rush they provide, from the last minute clutch solves to the anticipation of system tests, is unmatched. But sometimes, I just want to take it chill and casually solve problems. That's where the long challenge comes in.

The long challenge format is where contestants are given a long period of time, usually a week or several days, to work on a set of problems. Some notable examples include CodeChef Long Challenges, HackerEarth Circuits, and the Qualification Round of Google Code Jam. In this article, I'll talk about why I have a great appreciation for this contest format, and why this can be the most gratifying format to compete in.

## First, the elephant in the room.

Unfortunately, we can't talk about long challenges without acknowledging cheating. People cheat on programming contests. Programming contests are usually online and participated in from the comfort of your home, so no one can monitor your behavior. Couple that with the strong emphasis that certain software engineer employers place on competitive programming for hiring, and there's a tremendous incentive to cheat. The long challenge format is by far the easiest to cheat on, because solve times don't matter and there's a longer time frame to obtain answers from other people.

If I'm being honest, there's really not much one can do about cheating in programming contests. The fundamental nature of it being virtual means you can't spy on other contestants to prevent this type of behavior. There are countermeasures like MOSS (which doesn't really work and can't stop sharing of just ideas) and reporting by contestants, but the amount of cheating that happens each contest is likely intractable for contest admins to effectively shut down. What I can say is that cheating becomes far less prevalent as you move up in rating, so you could cheating as motivation to get out of lower divisions as quickly as possible. Also, since I usually don't do long contests for any form of rating (CodeChef long challenges are unrated for Div 1, and I don't really care about HackerEarth rating), I focus more on just trying my best to solve all the problems in the problemset. Cheating sucks, but it doesn't significantly impact my ability to enjoy long challenges.

Now with that out of the way, allow me to list some of the aspects I enjoy about this format.

## 1. Schedule Convenience
Where I live, the most popular contest platforms like Codeforces, Atcoder, and Codechef always host their short contests in the morning and end at noon. Especially now that school classes are returning to in-person, it's difficult to compete in these contests during the weekdays without them cutting into a significant part of my day, and it's annoying to wake up early on weekends to do them. Long challenges grant more flexibility in the timing, so I can work on them in the afternoon or nighttime instead.

## 2. Focus on Problem Solving
With long challenges, I feel like it's just me and the problems. I don't necessarily have to be sitting at my desk to think about problems. I can read them first, then keep them in the back of my head as I'm going through the rest of my day. If I'm tired or am getting repeatedly stuck on the same ideas, I can wait until tomorrow to try and get a fresh perspective. I remember in my first ever CodeChef long challenge, I was stuck on the problem [Blackjack](https://www.codechef.com/JAN21C/problems/BLKJK) after thinking about it for a few hours. For the next few days, I just kept it in the back of my head, working on the problem every once in a while and resetting my ideas constantly. Then one night, while I was brushing my teeth, I had an epiphany. A different way of thinking about the problem. And so I immediately rushed to my computer, coded up the solution, and claimed my AC.

I've also had plenty of moments where I've come up with a solution while on a walk. And because I'm walking outside instead of being at my computer, I can take the time to think about the implementation details and achieve mental clarity before I begin implementing. Long challenges give me the time to truly appreciate problem solving as an art.

## 3. Approximation Problems
Most long challenges will also have an approximation problem as a tiebreaker. In these problems, it is impossible to compute the optimal answer in the given limits, and contestants compete to use heuristics and approximation algorithms to get as close to the optimal answer as possible. I'm really bad at these because I'm used to approaching problems by thinking about the worst case and the optimal solution instead of thinking about heuristics, but these types of problems can be interesting to think about nonetheless.

Now, I'll talk more specifically about two platforms that host long challenges regularly: CodeChef and HackerEarth.

## CodeChef Long Challenges
![image 1]({{ site.baseurl }}/assets/images/long-challenge-1.png)
<div style="text-align: center; margin-bottom: 5%"><em>Despite finishing earlier than some of the contestants above me, I still appear below them on the leaderboard, so I have no clue what algorithm CodeChef uses for tiebreakers.</em></div>

CodeChef is where I first encountered the long challenge format. Long challenges usually happen once a month and have 8-10 problems. Scores are determined solely based on points from problems (time is disregarded), so multiple contestants can get the same place. They used to be rated for all divisions, but recently they were downgraded to just being rated for Div 3, presumably to prevent cheaters from reaching 7 stars with only long challenges. They also no longer have approximation problems, which is a bit of a shame, but it also means it's now possible for me to get a perfect score :D.

In terms of problem quality, CodeChef problems do not shy away from heavy implementation, although that is often not the bottleneck in the difficulty of their problems. I'd say the early problems are usually random fluff, where you just do one print statement, while the later problems contain some interesting ideas. For example, the August long challenge had a problem called [Alternating LG Queries](https://www.codechef.com/AUG21A/problems/ALTLG), which I thought required a neat observation.

<details markdown="1" style="margin-bottom: 5%"><summary>The Observation</summary>
GCD and LCM behave like a clamp function, so it is sufficient to compress a series of composed GCD and LCM functions into one GCD and one LCM function. The rough proof of this is to consider each prime factor separately, then notice that the exponent of the prime factor is either min'd or max'd, which is exactly what a clamp function does.
</details>

In terms of difficulty, I would say that older long challenges were harder since they were rated for Div 1 and often contained problems requiring research of esoteric algorithms to solve. Nowadays, the long challenges rated for Div 3 can usually be AK'd (means to solve all the problems) by a competitor that is Master+ on Codeforces (at least, that's the rating I was when I did them). All in all, I'd say the quality of these contests are pretty good.

## HackerEarth Circuits
![image 2]({{ site.baseurl }}/assets/images/long-challenge-2.png)

HackerEarth Circuits usually happen once a month as well, and tend to have 7 algorithm problems and 1 approximation problem. Scores are determined first based on total points, then sum of solve times as tiebreaker. Personally, I don't understand why they even incorporate solve times into the score calculation, since the whole point of long challenges is to be friendly to different time zones and disregard the time aspect of programming competitions. Luckily, the times don't really matter in practice since the approximation problem provides a tiebreaker anyways.

Problem quality for HackerEarth contests is definitely sketchier than the popular platforms. The problems tend to gather their difficulty from the algorithms and concepts used instead of the level of logical thinking required to make the observations. Also, some of the problems definitely push the boundary of what it means to be a **programming** problem. Take for example the problem [A Trigonometry Function](https://www.hackerearth.com/problem/algorithm/trignometry-function-4c614376/) (and people say Codeforces is Mathforces!).

<details markdown="1" style="margin-bottom: 5%"><summary>How I solved this in contest</summary>
Let $S(n) = \sum_{k=0}^n f(k)$. We want to compute $S(q) - S(p - 1)$.

We can split $f(n)$ into the sum of two functions, $f_1(n) = 2 \cdot 7^{n/2} \cdot \cos(n \theta)$ and $f_2(n) = n \cdot 4^n$.

Let's first tackle $f_1(n)$. It's not even immediately obvious that for integer inputs this function outputs an integer, let alone how this function behaves. Let's use WolframAlpha to compute the first few terms of the sequence.

$$
f_1(0) = 2 \\
f_1(1) = 4 \\
f_1(2) = 2 \\
f_1(3) = -20 \\
f_1(4) = -94 \\
f_1(5) = -236
$$

Ok, I'm not seeing any pattern at all. But maybe OEIS does. While there isn't an entry on OEIS for this exact sequence, there is an entry on OEIS for $a(n) = f_1(n) / 2$: [A213421](https://oeis.org/search?q=1%2C+2%2C+1%2C+-10%2C+-47%2C+-118&sort=&language=english&go=Search). Most of the formulas aren't too useful, except for the last one: $a(n) = 4 a(n - 1) - 7 a(n - 2)$.

Now remember, we don't need $a(n)$, but rather $S(n)$. Let's redefine $S(n) = \sum_{k=0}^n a(k)$ and just multiply our final answer by 2 at the end. A quick substitution will help us derive a recurrence relation for $S(n)$:

$$
\begin{align*}
S(n) &= a(0) + a(1) + \dots + a(n - 1) + a(n) \\
&= S(n - 1) + a(n) \\
&= S(n - 1) + 4 a(n - 1) - 7 a(n - 2)
\end{align*}
$$

Now we can calculate $S(n)$ in $\mathcal O(\log n)$ time using [matrix exponentiation](https://usaco.guide/plat/matrix-expo?lang=cpp). In our matrix, we maintain the values $a(n), a(n - 1), S(n)$.

For $f_2(n)$, there's a simple closed form from [WolframAlpha](https://www.wolframalpha.com/input/?i=sum+n*4%5En) (WolframAlpha is OP): $\sum_{k=0}^n f_2(k) = \frac{4}{9}(3 \cdot 4^n n - 4^n + 1)$.

</details>

<details markdown="1" style="margin-bottom: 5%"><summary>Rant about HackerEarth Contest Preparation</summary>
Aside from problem quality itself, the quality of the preparation and contest design is questionable. I questioned earlier why solve times were included in the scoring, but I think the real reason is simply that the devs recycled the contest system used for their short contests and couldn't be bothered to adapt it to sensible rules for a long contest. Furthermore, there's almost always some issue with at least one of the problems in each contest. [One problem](https://www.hackerearth.com/practice/algorithms/dynamic-programming/introduction-to-dynamic-programming-1/practice-problems/algorithm/matrix-and-xor-operation-a2e19185/) from December Circuits incorrectly handled certain inputs. The checker for the [approximation problem](https://www.hackerearth.com/practice/basic-programming/bit-manipulation/basics-of-bit-manipulation/practice-problems/approximate/longest-grid-path-a28ff86f/) in July Circuits was wrong and allowed paths going through blocked cells. The checker for the [approximation problem](https://www.hackerearth.com/practice/algorithms/string-algorithm/basics-of-string-manipulation/practice-problems/approximate/kolmogorov-78780f09/) in January Circuits contradicted the output format in the problem statement, and participants literally had to figure out that information from repeated submissions during the contest. Finally, most recently HackerEarth contests banned participants from copy pasting into the submission box for no reason, meaning they somehow expect you to retype complex algorithms from scratch into their submission box instead of importing it from your library. It's possible that they've fixed that issue, but I haven't competed on HackerEarth recently, because why would I?

The worst offense is that these mistakes are never corrected because nobody on the contest team ever replies. I even personally emailed the contest team for one of their contests once and only got a reply several days after the contest ended. Needless to say, I've stopped competing on this platform for the time being. It's really a shame that one of the only sources for long challenge contests was butchered so badly by poor preparation.
</details>

So that concludes my thoughts about long challenges. They're an underappreciated format that I wish there were more of, and they can be a lot of fun to compete in. Let me know your thoughts in the comments below.

---
layout: post
title: "Solutions to SPOJ GSS Series"
tags: [tutorial, algo]
usemathjax: true
---

SPOJ has a series of problems with problem codes [GSS1](https://www.spoj.com/problems/GSS1/), [GSS2](https://www.spoj.com/problems/GSS2/), ..., [GSS8](https://www.spoj.com/problems/GSS8). The problems are intended as educational range query problems, and while they are a bit outdated, they can still be interesting to work through and think about. I highly recommend thinking about each problem on your own before looking at the editorial. Also, don't feel the need to go in order, because they are definitely not ordered by difficulty. Finally, while I might include snippets of code for clarity of explanation, writing the full code for each problem will be left as an exercise to the reader :)

**Prerequisite: Segment Tree, General Understanding of Combinative Data Structures** \\
Note that the way I explain these problems will be framed by how I implement segment trees, which you can find [here (without lazy propagation)](https://github.com/mzhang2021/cp-library/blob/master/implementations/data-structures/SegmentTreeNode.h) and [here (with lazy propagation)](https://github.com/mzhang2021/cp-library/blob/master/implementations/data-structures/SegmentTreeNodeLazy.h). Essentially, I store aggregate information in segment tree nodes, and each query range can be decomposed into a combination of multiple segment tree nodes.

## [GSS1](https://www.spoj.com/problems/GSS1/)

<details markdown="1" style="margin-bottom: 5%"><summary>Problem</summary>

Given an array $\|a_i\| \leq 15007$ of size $n \leq 5 \cdot 10^4$, answer $m$ queries of the following form: given $(x, y)$, find

$$
\max_{x \leq i \leq j \leq y} (a_i + \dots + a_j)
$$

In other words, find the maximum subarray sum of the subarray $a[x, y]$.

*For some reason the problem provides no bounds on $m$.*

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>
The trick for any segment tree problem is the following:
1. Figure out what information we need to store in the nodes.
2. Figure out how to combine two nodes.

In this case, it might help to start with thinking about how combining two nodes works, as that will guide us to know what info we need to maintain. Let's say we're considering the node representing range $[l, r]$ which is merged from two child nodes $[l, m]$ and $[m + 1, r]$, where $m = \lfloor \frac{l + r}{2} \rfloor$. The maximum subarray sum in $a[l, r]$ could fall into one of three cases:
1. It lies solely in the range $[l, m]$.
2. It lies solely in the range $[m + 1, r]$
3. It exists in both halves.

In the first and second case, we just take the maximum subarray sum computed in the child nodes. In the third case, the optimal subarray would consist of some suffix of the range $[l, m]$ and some prefix of the range $[m + 1, r]$. We can also compute the maximum prefix and suffix sum for each node, so that case 3 is simply reduced to the maximum suffix in the left child plus the maximum prefix in the right child. So this tells us what info we need to store in each node: the maximum subarray sum, the maximum prefix sum, the maximum suffix sum, and the total sum. We get the following method for updating:
```c++
// in my template the function signature is pull(a, b), but I'm using merge(left, right) here instead for clarity
void merge(Node left, Node right) {
    maxSum = max({left.maxSum, right.maxSum, left.maxSuffix + right.maxPrefix});
    maxPrefix = max(left.maxPrefix, left.sum + right.maxPrefix);
    maxSuffix = max(right.maxSuffix, right.sum + left.maxSuffix);
    sum = left.sum + right.sum;
}
```

Be careful that you handle ranges of all negative numbers correctly, because the problem does not allow for non-empty subarrays.
</details>
</details>

## [GSS2](https://www.spoj.com/problems/GSS2/)

<details markdown="1" style="margin-bottom: 5%"><summary>Problem</summary>

*The original problem statement is very obviously poorly translated, so I literally had to read the comments to understand the problem.*

Given an array $\|a_i\| \leq 10^5$ of size $n \leq 10^5$, answer $q \leq 10^5$ queries of the following form: given $(x, y)$, find

$$
\max_{x \leq i \leq j \leq y} (a_i + \dots + a_j)
$$

but with the extra condition that duplicate elements are ignored. So for example, if some subarray contains three copies of $2$, we only add $2$ once.

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>
The extra condition of ignoring duplicates makes a direct online approach with segment tree difficult, because we don't have a concise way of maintaining the set of all elements that have at least one occurrence in each node. So let's consider an offline approach.

There's a general sweepline approach for solving range query problems offline: sweep from left to right while updating some sort of data structure. When you encounter the right endpoint of some query, use the data structure to find the answer for that query.

In this case, our data structure will be an array $p$, where $p_i$ represents the maximum subarray sum excluding duplicates with left endpoint beginning at index $i$. We will also maintain an array $last_x$ storing the rightmost index with value $x$ in the array that we've encountered in our sweepline so far.

Let's see what happens when we encounter $a_i$ in our sweepline. $a_i$ could contribute to every subarray beginning at $last_{a_i} + 1, last_{a_i} + 2, \dots, i$. It cannot contribute to a subarray beginning at $last_{a_i}$ or earlier, since such a subarray would already contain a copy of $a_i$ at index $last_{a_i}$ if it were to also include $a_i$, and duplicate elements only get added once. So we perform the following update:
```c++
for (int index=last[a[i]]+1; index<=i; index++) {
    sum[index] += a[i];
    p[index] = max(p[index], sum[index]);
}
```
Then, when we encounter some query $(l, r)$, its answer is simply

$$
\max_{i=l}^r p_i
$$

This offline algorithm runs in $\mathcal O(n(n + q))$, so let's now boost the efficiency to $\mathcal O((n + q) \log n)$ by upgrading $p$ to a segment tree. We need a segment tree that can handle the following operations:
1. Add $x$ to all $a_i$ in some range.
2. Query for the maximum $p_i$ in some range.

After every operation, $p_i := \max(p_i, a_i)$, so $p_i$ is the maximum of all values $a_i$ ever changed into.

Believe it or not, this is possible with a segment tree, and is described in the "Historic Information" section of this [segment tree beats](https://codeforces.com/blog/entry/57319) tutorial.

<details markdown="1" style="margin-bottom: 5%"><summary>The Idea</summary>
We maintain four values in each segment tree node: `a, p, lazy, historic_lazy`. Whenever we propagate lazy values, we do `historic_lazy = max(historic_lazy, lazy + propagated_historic_lazy)` and `lazy += propagated_lazy`. Whenever we apply the pending lazy update, we do `p = max(p, a + historic_lazy)` and `a += lazy`. And finally, when we merge, we do `p = max(left.p, right.p)` and `a = max(left.a, right.a)`. Take a moment to think about why this works, and why an additional `historic_lazy` value is necessary (i.e. why can't we just use one lazy value?).
</details>

That's it! We've successfully solved this problem in $\mathcal O((n + q) \log n)$. Personally, I think this is the hardest GSS problem out of the entire series.

</details>
</details>

## [GSS3](https://www.spoj.com/problems/GSS3/)

<details markdown="1" style="margin-bottom: 5%"><summary>Problem</summary>

Given an array $\|a_i\| \leq 10^4$ of size $n \leq 5 \cdot 10^4$, process $m \leq 5 \cdot 10^4$ queries of two types:
1. Set $a_x := y$.
2. Given $(x, y)$, find

$$
\max_{x \leq i \leq j \leq y} (a_i + \dots + a_j)
$$

In other words, find the maximum subarray sum of the subarray $a[x, y]$.

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>
This is just GSS1 with updates. The update method doesn't change any of the above logic.
</details>
</details>

## [GSS4](https://www.spoj.com/problems/GSS4/)

<details markdown="1" style="margin-bottom: 5%"><summary>Problem</summary>

Given an array of $a_i$ of size $n \leq 10^5$, process $m \leq 10^5$ queries of two types:
1. Given $(x, y)$, perform $a_i := \lfloor \sqrt a_i \rfloor$ for $x \leq i \leq y$.
2. Given $(x, y)$, find $\sum_{i=x}^y a_i$.

Constraints on $a_i$: $a_i > 0, \sum_{i=1}^n a_i \leq 10^{18}$

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>
The first operation is difficult to handle with traditional lazy propagation, because it's not clear how applying the square root operation to a subarray affects the sum of that subarray. Let's consider the naive way of updating the segment tree: we traverse all the way down to each leaf node in the range and update them directly, giving us $\mathcal O(n)$ per query. While that's obviously too slow, it's actually not far off from the right idea.

We will use the same idea as [segment tree beats](https://codeforces.com/blog/entry/57319) (don't worry, this is easier than the proof for segment tree beats). Observe that for $a_i \leq 10^{18}$, we can only apply $a_i := \lfloor \sqrt a_i \rfloor$ 6 times before $a_i$ converges to 1. So let's say you're currently at some node, and you want to apply the square root operation to all elements in the range covered by that node. If all the elements are 1, applying the square root operation on them again is useless, so we can just stop traversing further.

Let's prove a bound of $\mathcal O((n + m) \log n)$ from that optimization. Consider the following diagram:

![image 1]({{ site.baseurl }}/assets/images/gss-1.png)

We will refer to the blue nodes as *ordinary nodes* and the green nodes as *extra nodes* (the same terminology used in the segment tree beats blog). Ordinary nodes are nodes we would visit in standard segment tree anyways. In the naive algorithm, we would also visit all the extra nodes, which could be $\mathcal O(n)$ per query. We will keep some counter on each leaf node representing how many more times we can apply the square root operation to that element before it reduces to 1 (the red numbers in the diagram). The counter can be at most 6 for each leaf node. Finally, we keep some counter on each non-leaf node that equals the sum of the counters of its children. Let $\Phi$ equal the sum of all counters written on all nodes in the tree. What is the initial value of $\Phi$? It is $\mathcal O(n \log n)$.

<details markdown="1" style="margin-bottom: 5%"><summary>Why?</summary>
Each leaf node contributes at most +6 to the counter of every ancestor. There are $\mathcal O(\log n)$ ancestors per leaf node, so each leaf node contributes $+6 \log n$ to $\Phi$. Thus, summing up the total contribution from all leaf nodes gives $\Phi = 6n \log n$, or $\mathcal O(n \log n)$.
</details>

The number of ordinary nodes we visit is $\mathcal O(m \log n)$, since that's just standard segment tree. Under what cases will we visit an extra node? We visit an extra node whenever there exists a non-one element in that subtree, aka if the counter on the extra node is positive. So after the operation, that counter and thus $\Phi$ will decrease by one, because we will have square rooted some leaf node in that subtree. Thus, every movement to an extra node is accounted for by 1 unit of $\Phi$, so the total amount of times we visit some extra node is bounded by the initial value of $\Phi$, or $\mathcal O(n \log n)$. The total complexity is therefore $\mathcal O((n + m) \log n)$.

</details>
</details>

## [GSS5](https://www.spoj.com/problems/GSS5/)

<details markdown="1" style="margin-bottom: 5%"><summary>Problem</summary>

Given an array of $\|a_i\| \leq 10^4$ of size $n \leq 10^4$, process $m \leq 10^4$ queries of the following form: given $(x_1, y_1, x_2, y_2)$, find

$$
\max_{x_1 \leq i \leq y_1, x_2 \leq j \leq y_2} (a_i + \dots + a_j)
$$

where $x_1 \leq x_2$ and $y_1 \leq y_2$.

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>
First, read the solution for GSS1, as this problem will compute the same information in each segment tree node.

We will split the problem into two separate cases:

1. $[x_1, y_1]$ and $[x_2, y_2]$ form two disjoint intervals.
2. $[x_1, y_1]$ and $[x_2, y_2]$ overlap.

In the first case, the optimal subarray consists of some suffix of $a[x_1, y_1]$, the total sum of $a[y_1 + 1, x_2 - 1]$, and some prefix of $a[x_2, y_2]$. We can query for all three of those parts with the same segment tree used in GSS1.

In the second case, we have a few more possible cases, all handled with our segment tree:
1. The subarray starts in $[x_1, x_2]$ and ends in $[x_2, y_1]$.
2. The subarray starts in $[x_1, x_2]$ and ends in $[y_1, y_2]$.
3. The subarray starts in $[x_2, y_1]$ and ends in $[x_2, y_1]$.
4. The subarray starts in $[x_2, y_1]$ and ends in $[y_1, y_2]$.

Putting both cases together, the logic of each query looks something like this:
```c++
if (y1 <= x2) {
    Node a = st.query(x1, y1), b = st.query(y1, x2), c = st.query(x2, y2);
    cout << a.maxSuffix + b.sum + c.maxPrefix - arr[y1] - arr[x2] << "\n";
} else {
    Node a = st.query(x1, x2), b = st.query(x2, y1), c = st.query(y1, y2);
    cout << max({a.maxSuffix + b.maxPrefix - arr[x2], a.maxSuffix + b.sum + c.maxPrefix - arr[x2] - arr[y1],
                b.maxSum, b.maxSuffix + c.maxPrefix - arr[y1]}) << "\n";
}
```

</details>
</details>

## [GSS6](https://www.spoj.com/problems/GSS6/)

<details markdown="1" style="margin-bottom: 5%"><summary>Problem</summary>

Given an array of $\|a_i\| \leq 10^4$ of size $n \leq 10^5$, process $q \leq 10^5$ queries of four types:
1. Insert $y$ before index $x$ in the array (so the array size increases).
2. Delete the element at index $x$ (so the array size decreases).
3. Set $a_x := y$.
4. Given $(x, y)$, find

$$
\max_{x \leq i \leq j \leq y} (a_i + \dots + a_j)
$$

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>
This is GSS3, but you can now insert or delete elements from the array and change its size. Segment tree struggles with inserts and deletes, but luckily there's another combinative data structure that handles this with ease: [tre](https://cp-algorithms.com/data_structures/treap.html)[aps](https://codeforces.com/blog/entry/84017)!

Once you know what a treap's capabilities are, it should be apparent how this problem is solved. We store the same info from GSS1 in each treap node with the same merge function. Insert and delete can both be implemented as a series of split and merge functions. So this problem is solved in $\mathcal O(q \log n)$.

</details>
</details>

## [GSS7](https://www.spoj.com/problems/GSS7/)

<details markdown="1" style="margin-bottom: 5%"><summary>Problem</summary>

Given a tree of $n \leq 10^5$ nodes, each with some associated value $\|x_i\| \leq 10^4$, process $q \leq 10^5$ queries of two types:
1. Find the maximum subarray sum of the array formed from values on the path from node $a$ to $b$.
2. Set all values on the path from node $a$ to $b$ to $c$.

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>
This is GSS3 but on a tree. Luckily, there's a well-known way of adapting a range query solution to a tree with only an extra $\mathcal O(\log n)$ factor: [heavy light](https://cp-algorithms.com/graph/hld.html) [decomposition](https://codeforces.com/blog/entry/81317)!

Once you know what HLD's capabilities are, it should be apparent how this problem is solved. Just be wary that depending on how you implement HLD, the orientation may make a difference. To explain what I mean, take a look at the following code snippet below:
```c++
template<class B>
void process(int u, int v, B op) {
    bool s = false;
    for (; root[u]!=root[v]; u=par[root[u]]) {
        if (depth[root[u]] < depth[root[v]]) {
            swap(u, v);
            s ^= true;
        }
        op(pos[root[u]], pos[u], s);
    }
    if (depth[u] > depth[v]) {
        swap(u, v);
        s ^= true;
    }
    op(pos[u], pos[v], !s);
}

int query(int u, int v) {
    Node ls, rs;
    process(u, v, [this, &ls, &rs] (int l, int r, bool s) {
        Node cur = st.query(l, r);
        if (s) rs.merge(cur, rs);
        else ls.merge(cur, ls);
    });
    swap(ls.maxPrefix, ls.maxSuffix);
    Node ret;
    ret.merge(ls, rs);
    return ret.maxSum;
}
```
My full HLD implementation can be found [here](https://github.com/mzhang2021/cp-library/blob/master/implementations/graphs/HLD.h) and uses the same style as [this implementation](https://codeforces.com/blog/entry/22072). Essentially, the orientation of the segment tree is from smaller DFS time to larger DFS time (top to bottom). Therefore, I maintain the merged results of the query in two separate halves for two separate branches of the path connected by the LCA, and I swap the prefix and suffix of the left branch at the end to make its orientation consistent with the right half. If this doesn't make sense to you, try drawing out the diagram or tracing the code to see what happens if you don't account for orientation when merging.

</details>
</details>

## [GSS8](https://www.spoj.com/problems/GSS8/)

<details markdown="1" style="margin-bottom: 5%"><summary>Problem</summary>

Given an array of $a_i < 2^{32}$ of size $n \leq 10^5$, process $q \leq 10^5$ queries of four types:
1. Insert $val$ before index $pos$ in the array (so the array size increases).
2. Delete the element at index $pos$ (so the array size decreases).
3. Set $a_{pos} := val$.
4. Given $(l, r, k)$, find

$$
\sum_{i=l}^r a_i \cdot (i - l + 1)^k \mod 2^{32}
$$

where $k \leq 10$.

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>
Finally a problem that isn't a variation of GSS1! First off, we can handle the insert and delete operations with a [tre](https://cp-algorithms.com/data_structures/treap.html)[aps](https://codeforces.com/blog/entry/84017). The tricky part is going to be figuring out how to calculate the fourth operation.

Since $k$ is small, we can compute $ans[0], ans[1], \dots, ans[10]$ in each treap node. This way, we just print $ans[k]$ from the correct node to answer each query.

Consider the following small example: we are merging two nodes. The left node represents the array $[a_1, a_2]$ and the right node represents the array $[a_3, a_4]$. Say we've already computed $ans[k]$ in both nodes, and we want to compute $ans[k]$ for the merging of both nodes. In other words, we want:

$$
ans_l[k] = a_1 \cdot 1^k + a_2 \cdot 2^k \\
ans_r[k] = a_3 \cdot 1^k + a_4 \cdot 2^k \\
merge(ans_l[k], ans_r[k]) = ans[k] = a_1 \cdot 1^k + a_2 \cdot 2^k + a_3 \cdot 3^k + a_4 \cdot 4^k
$$

The first half of what we want is just $ans_l[k]$. The second half is almost $ans_r[k]$, except the base of each power term gets shifted up ($1^k$ becomes $3^k$, $2^k$ becomes $4^k$). Notice that each base gets shifted up by `size_of_left_node` (which I will denote as $size_l$), so we can rewrite the terms as $a_3 \cdot (1 + size_l)^k + a_4 \cdot (2 + size_l)^k$. There's a well-known theorem for expanding terms of the form $(a + b)^k$: the [Binomial Theorem](https://en.wikipedia.org/wiki/Binomial_theorem). So expanding yields:

$$
\begin{align*}
a_i \cdot ((i - size_l) + size_l)^k &= a_i \cdot \sum_{j=0}^k \left(\binom{k}{j} \cdot (i - size_l)^j \cdot (size_l)^{k-j}\right) \\
&= \sum_{j=0}^k \left(\binom{k}{j} \cdot (a_i (i - size_l)^j) \cdot (size_l)^{k-j}\right)
\end{align*}
$$

And when we sum up all of these for all $a_i$ in the right node:

$$
\sum_{\forall i} \sum_{j=0}^k \left(\binom{k}{j} \cdot (a_i (i - size_l)^j) \cdot (size_l)^{k-j}\right) \\
= \sum_{j=0}^k \left(\binom{k}{j} \cdot ans_r[j] \cdot (size_l)^{k-j}\right)
$$

This can be shown with some rearrangement of the terms.

So now, we've successfully shown how to compute the contribution of the right node to $ans[k]$ from $ans_r[0], ans_r[1], \dots, ans_r[k]$. After precomputing $(size_l)^j$ and $\binom{k}{j}$ for $0 \leq j, k \leq 10$, we can compute each of $ans[j]$ in $\mathcal O(k^2)$. The code for the merge function looks as follows:

```c++
treap->size = getSize(treap->l) + getSize(treap->r) + 1;
power[0] = 1;
for (int i=1; i<=MAXK; i++)
    power[i] = power[i-1] * (getSize(treap->l) + 1);
for (int i=0; i<=MAXK; i++) {
    treap->ans[i] = (treap->l ? treap->l->ans[i] : 0) + power[i] * treap->val;
    if (treap->r)
        for (int j=0; j<=i; j++)
            treap->ans[i] += choose[i][j] * power[i-j] * treap->r->ans[j];
}
```
*The code above differs slightly from the explanation because the treap merge actually consists of three parts: the left child, the right child, and the middle value stored in the current node.*

Thus, our final complexity is $\mathcal O(k^2 \log n)$ per query.

</details>
</details>

Let me know if you have any ideas for what my next article topic should be. I might cover the SPOJ QTREE series, or write about something else.

---
layout: post
title: "How Fair are Facebook Hacker Cup's Rules?"
tags: [opinion]
usemathjax: true
---

Facebook Hacker Cup is different from many other competitive programming competitions due to its submission format: instead of automatically judging competitiors' submissions via an online judge, competitors are given the input file and six minutes to generate the answer for that input file locally. This difference in submission format is very peculiar and allows for unorthodox methods of solving problems. For example, you could use MATLAB or Wolfram Mathematica. You could use parallel processing across multiple devices (which isn't just theorycrafting, it's actually doable as shown in [this recent blog](https://codeforces.com/blog/entry/95295)). All of this can make the competition more interesting, but it also begs the question of fairness.

The thing is, when you have to produce the output locally, your hardware plays a significantly larger role in your running time. What made online judging fair was that everyone's submission ran in the same environment under the same conditions (or as close as possible, since some online judges use multiple machines for judging). And for anyone wondering, there certainly is a difference in hardware performance, even just between a laptop vs a PC. I can personally attest that when I used to use my laptop, I was experiencing almost 5 second compile times when using `#include <bits/stdc++.h>`, reduced slightly by precompiling headers. After getting a PC, my compile times even without precompiling headers was easily under 1 second, sometimes 2. Actual execution times also received similar boosts. And I can only imagine the difference if using a more powerful machine or multiple. When I interned at a machine learning lab last year, we used supercomputers with GTX Titan Blacks for faster training of the neural networks, and I can only imagine applying such computational power to FHC.

Most of the time, this difference in hardware won't matter if you come up with the intended solution. FHC problem bounds are small enough that if you code a solution with correct complexity, you can expect to finish running on the input under a minute even with the crappiest hardware. Where it starts matter is when you have less optimal complexities, like $\mathcal O(n^2)$ for $n \leq 10^5$. I feel like cheesing with high computational power is definitely a viable strategy, just that no one has opted to do so yet because FHC is primarily targeted towards competitive programmers who focus more on solving problems with thinking. And if this strategy ends up being viable, these contests can quickly devolve into being pay-to-win instead of being based on algorithm solving prowess.

Regardless, I don't think this is a serious threat to the competition at the moment. As I mentioned before, FHC is mainly targeted towards competitive programmers, not machine learning scientists with access to insane cloud computing from their lab. It's just a thought I had. In the worst case, imagine if FHC problems started adapting to account for increased computational power. Problems start having $\mathcal O(n^2)$ as the intended solution for $n \leq 10^5$. That would be funny.

---

Thanks for reading! I apologize for posting what is essentially a filler article. I'm currently working on a longer tutorial article, but between classes and other responsibilities it'll take more time to complete, so be on the look out for that.

---
layout: post
title: "How to Understand Hard Tutorials"
tags: [tutorial, opinion]
usemathjax: true
---

*Hooray, it's my first post of October, meaning I've kept this blog running for at least a month!*

Tell me if this sounds familiar: you see a new tutorial blog posted on Codeforces about some crazy advanced topic. You read through it, and you find it goes way over your head really quickly. Or you open an editorial for some problem, and you get lost after reading the first few lines. While I can't guarantee you'll be able to understand every tutorial after reading this article, I can provide some insight on how I approach reading and understanding tutorials.

## 1. Make sure you meet the prerequisites.
Every tutorial assumes some amount of previous knowledge before reading it. For example, most tutorials assume you know how to code and possess an understanding of mathematics up to a high school level. A tutorial that builds on an existing topic will also usually require knowledge of that previous topic (i.e. a tutorial on persistent segment trees likely requires you to know what a segment tree is). Authors usually don't outright tell you what prerequisites are required, but you can infer them by skimming through the tutorial and looking for keywords. If a tutorial suddenly states "and now this is just a trivial application of convex hull trick" without further elaboration, "convex hull trick" is probably a prerequisite assumed by this tutorial.

Let's give an example. Say you're reading [this article on subtree lazy propagation for link-cut trees](https://codeforces.com/blog/entry/80145). What are the prerequisites?
1. Know what a link-cut tree is. It's literally in the title.
    1. Digging into link-cut trees reveal that you'll need to know what a splay tree is, since those are used to implement a link-cut tree is. More fundamentally, knowledge of what trees are and common properties of trees can help.
2. How to maintain subtree aggregate data for a link-cut tree.
3. How lazy propagation works, which you can pick up from a tutorial about lazy propagation for segment trees, since that's usually the simplest context where lazy propagation is introduced.

Most of those were just deduced from the title/first paragraph, which is quite convenient.

Here's another example: [this action-packed blog about generating functions](https://codeforces.com/blog/entry/77468). What are the prerequisites?
1. Being very comfortable with manipulating algebraic expressions and summations, given the high volume of LaTeX I see.
2. Knowledge of common math functions like $\exp$, $\ln$, and $\binom{n}{k}$.
3. You don't actually need to understand how to perform operations on polynomials such as $P(x) Q(x)$, $\sqrt{P(x)}$, or $\ln P(x)$ in subquadratic time, just know that that's possible.

I'd say that this blog isn't intimidating because of the knowledge required, but because of its density and how quickly it escalates. I believe that if you meet the prerequisites (most of which is likely acquired in your high school or undergrad depending on where you live), you can understand this blog by slowly working through the blog line by line. Which leads me to my second point...

## 2. Don't skip sections!
This is the fastest way to get lost. Tutorials are often self-building, where each section feeds understanding of the next. If you don't understand a section, I would highly recommend not moving on to the next section until you understand it, because it is very unlikely that a later section will clarify what you don't understand, and more likely that you'll just get lost.

**There is one exception to this rule: proofs.** Proofs are slightly different, because they're sometimes offered as a supplement for completeness or satisfaction rather than understanding. I've often found that if I understand the general intuition behind the concept, I can skip the proofs with little consequence (though usually I read the proof anyways out of curiosity). I wouldn't recommend always skipping over proofs though. A good proof can sometimes make things more clear.

## 3. Actively think about what you're reading.
Sometimes, you followed steps 1 and 2, but you still get stuck on a section. This might be because the step that the author is taking is not intuitive, or because the author skipped a few steps in between. While the author could be to blame for not doing enough handholding, the reader can also try to think on their own about why a step is true. In fact, it can sometimes be more satisfying to figure out why a step holds true on your own rather than getting it all from the author. Coming up with your own explanation or intuition for some concept is a great way to improve your thinking abilities. This isn't an invitation to authors to be as terse as possible in their writing though: a tutorial that skips too much is simply not helpful to anyone.

## 4. You rarely read a good tutorial once.
There are some blogs that I frequently refer back to when I want to recall how to do something. I don't have the best memory, so if I read a blog about ["queue undo trick"](https://codeforces.com/blog/entry/83467) a year ago, the most I might remember when I see such a problem is "oh, this is possible, I read some blog about this." Then, I'll pull up the blog from my bookmarks and figure out the implementation from there. Or other times, I'll see a cool blog but conclude I don't meet the prerequisites for it yet, so I'll store the second half of the article for future use. In fact, one such example is the [generating functions blog](https://codeforces.com/blog/entry/77468) I mentioned earlier, which I still have yet to fully read through even part 1, mostly because I'm too lazy to read and actively think about the later sections at the moment. The point is, I recommend saving blogs you like so you can come back to it when you have a better understanding of the prerequisites, or when you just want to recall the information.

## 5. Finally, ask if stuck.
I put this as the final step because I feel people often skip to this step too often before considering the previous ones. But indeed, sometimes the author simply didn't explain a part as clearly as they could have. Or they skipped over a non-trivial step thinking it was trivial. **My biggest pet peeve is when someone asks to simply "explain it again."** Too often, people ask something to the effect of "can you explain it again in more detail?" The issue here is it's not targeted. I have no idea which section/line you're confused about. Asking something like "I don't get how X is true in section Y because Z" is way more useful because the author immediately knows which section was unclear and can tailor their response to that question.

## Extra: Taking Notes?
I leave this as an extra section because I personally don't do this, but I know other people do. I have heard that taking notes yourself can help you retain the information better and also lets you organize the information in a way that helps with recall (step 4). However, when I personally tried it once, I deemed note taking to be too much effort for marginal benefit in return. Ultimately, it depends on what type of person you are. We all learn differently, so do what works for you.

---

That's all I have. I know some of this might sound like common sense, but one of my favorite quotes is "common sense is not common practice," and I hope this article can encourage some more common practice in your learning. Let me know if you agree or disagree with any of my suggestions.

---
layout: post
title: "Self Reflection and What's Next?"
tags: [personal, opinion]
---

It's been a month since my last major milestone in CP, and high time for some self reflection. There are two major CP competitions I competed in this month: Facebook Hacker Cup, and Kotlin Heroes 8.

## FHC

![image 1]({{ site.baseurl }}/assets/images/reflection-1.png)

In last weekend's round 3, I got a frustrating 222nd place, narrowly missing the top 200 badge on the t-shirt. To think that if I just did A and D1 faster, I could have gotten it! Or if only they counted top 200 for round 2 as well T_T.

Saltiness aside, my downfall in this contest was unfortunately implementation. In both my implementations for A and D1, I had a critical bug that required stress testing against a brute force solution to find. Those types of bugs are the worst, because it's so time consuming to write another solution AND a generator, and that's just the time taken to find the test case. When you add on the time it takes to analyze the test case, print debug output, and think about what's wrong, it's easy to lose a significant amount of time debugging. Thus, I submitted A at the 40 min mark and D1 at the 1 hr 50 min mark, both very undesirably late and not leaving much time to work on the other problems. A similar situation happened with C2 in round 2, so implementation woes is definitely a common trend with my FHC experience.

Practicing implementation is a strange thing. For me, writing clean implementations in a contest environment vs practice are two very different things. In practice, I'm usually able to keep my implementation relatively clean. On the other hand, in contest I'm often worried about other variables like time left in the contest, and I approach code writing in more of an additive manner, where I'll keep adding in more code on top of the old code to fix issues instead of refactoring, resulting in nonsense like this:

<div markdown="1" style="text-align: center; margin-bottom: 5%">
![image 2]({{ site.baseurl }}/assets/images/reflection-2.png)

<em>TFW you run out of ideas for variable names so you go with "yyyy"</em>
</div>
Perhaps the strat is to just approach implementation the same way I do in practice. Don't worry too much about the time, because writing sloppy code will probably consume more time overall anyways.

## Kotlin Heroes

![image 3]({{ site.baseurl }}/assets/images/reflection-3.png)
Kotlin heroes went slightly better for me, cause at least I got the shirt. Aside from the slow start from figuring out the kinks of Kotlin, I was on a pretty good pace for A-F, snagging me within top 50 off of speedforces. That being said, G was an annoying problem to not get because I felt that type of problem (DP with data structures) is within my ballpark. I got the naive DP recurrence: `dp[i][j] = max(dp[i-1][j] + a[i][j], dp[i-1][j+1])`, where `dp[i][j]` is the maximum damage after the first `i` warriors made moves and there are `j` barricades left, and `a[i][j]` is equal to the amount of damage warrior `i` can do if there are `j` barricades left (usually equal to 0). But the way I went about optimizing it was wrong: I tried to think of each row of the DP table as an array of segments of equal values. Then, the transition can be modeled as having each segment extend one unit to the left if it's larger than the left segment and updating a single point (which potentially creates a new segment). So kind of like a slope trick-esque approach. See the diagram below:

![image 4]({{ site.baseurl }}/assets/images/reflection-4.png)

Unfortunately, I couldn't find any good properties of this function, which made it difficult to speed it up past quadratic complexity. A better intuition is to map `dp[i][j]` as 2D coordinate points, and mark the transitions as querying a triangle:

![image 5]({{ site.baseurl }}/assets/images/reflection-5.png)

Essentially, most DP transitions don't change the DP value. Only a linear number of states actually change value by adding `a[i][j]`, so we can consider the transitions more directly between value changing points. `dp[i][j]` can transition from any previous state `dp[k][l]` if `k + l < i + j`. So a state can transition from any previous state within a triangle. Once you apply that intuition, the way to speed up the DP recurrence with data structures is far more apparent.

Missing the necessary intuition is probably the most common reason I fail to solve a problem, and unfortunately it's also the most nebulous to try to improve on. It's hard to practice to just "become smarter." In my experience, "becoming smarter" usually happens from the result of just doing a lot of relatively difficult problems (so above your rating range). Once you've done enough, you start to notice patterns in trains of thought and get better intuition for which ideas are good and which aren't (I talked extensively about this in a [post from last month]({{ site.baseurl }}/difficulty)). So perhaps I'd have to start grinding hard problems again if I want to get over this plateau.

## What's Next?
I'm not entirely sure. To be honest, I don't practice or spend anywhere close to as much time on CP as I used to, mainly because I've now found interest in other hobbies and things. Reaching red was kind of a "final boss" for me in CP, and now that I've hit red, I don't know how much effort I'd want to commit to the next milestone. But at the very least, I can assure you this blog will still be updated. Writing this blog hasn't gotten boring yet :)

How about you? Where are you in your CP journey, what's your next goal, and what specific aspects of CP do you need to work on? Feel free to comment them below.

---
layout: post
title: "Trivialize Linear Recurrence Problems with Berlekamp-Massey!"
tags: [tutorial, math]
featured: true
usemathjax: true
---

Berlekamp-Massey is a powerful tool that can knock out almost all linear recurrence problems, but it's often explained in the context of BCH decoding in many online tutorials, making it difficult to understand in a more general sense. There's [TLE's Codeforces blog](https://codeforces.com/blog/entry/61306), which contains all the core concepts of the algorithm but is a bit terse in my opinion. There's also [Massey's paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1054260), which is more on the mathematically rigorous side, and I have incorporated some of Massey's proofs into the proof section of this article. The goal of this article is to explain Berlekamp-Massey using my intuition/understanding of it.

**I promise this article isn't hard, just dense.** You won't need an understanding of mathematics beyond high school, but it's very easy to get lost if you don't read line-by-line and just skim it. I tried my best to make it as clear as possible, but there's only so much I can convey with words.

## Table of Contents
1. [Definition of a Linear Recurrence](#definition)
2. [Finding the $k$th Term of a Linear Recurrence](#kth)
3. [What is the Berlekamp-Massey algorithm?](#berlekamp-massey)
4. [An Example](#example)
5. [How does our process for choosing $d$ work?](#d-process)
6. [Which $b$ do we choose?](#b-process)
7. [The First Step](#first-step)
8. [Putting it all together in code…](#code)
9. [Test for Understanding](#test)
10. [Proofs](#proofs)
11. [Applications in Problems](#applications)
12. [Problems](#problems)
13. [References](#references)

## Definition of a Linear Recurrence <a name="definition"></a>

Let's say we have some arbitrary sequence of numbers:

$$
\{1, 2, 4, 8, 13\}
$$

Now, let's say we use the following rule to generate an infinite sequence from this initial sequence:

$$
s_i = s_{i-1} + 2s_{i-2} + 5s_{i-3} - 3s_{i-4} - s_{i-5} \\
s_0 = 1 \\ s_1 = 2 \\ s_2 = 4 \\ s_3 = 8 \\ s_4 = 13
$$

Using this rule, what will the next element of this sequence be? What will $s_5$ be?

$$
\begin{align*}
s_5 &= s_4 + 2s_3 + 5s_2 - 3s_1 - s_0 \\
&= 13 + 2 \cdot 8 + 5 \cdot 4 - 3 \cdot 2 - 1 \\
&= 42
\end{align*}
$$

And what will $s_6$ be?

$$
\begin{align*}
s_6 &= s_5 + 2s_4 + 5s_3 - 3s_2 - s_1 \\
&= 42 + 2 \cdot 13 + 5 \cdot 8 - 3 \cdot 4 - 2 \\
&= 94
\end{align*}
$$

Following this rule, here are the first 10 elements of our sequence:

$$
\{1, 2, 4, 8, 13, 42, 94, 215, 566, 1327, \dots\}
$$

We say the following sequence is defined by the **linear recurrence** $s_i = s_{i-1} + 2s_{i-2} + 5s_{i-3} - 3s_{i-4} - s_{i-5}$. The first 5 terms, $s_0, s_1, \dots, s_4$, are the **base case** or **initial conditions** of the recurrence. In general, a linear recurrence is a recurrence relation of the form:

$$
s_i = \sum_{j=1}^n c_j s_{i-j}
$$

where $c_j$ are constants, and $n$ is the length of the linear recurrence. Technically, what we defined above is a **homogeneous** linear recurrence. A linear recurrence could also be non-homogeneous, such as if we tack on a constant:

$$
s_i = p + \sum_{j=1}^n c_j s_{i-j}
$$

However, we will only be dealing with homogeneous linear recurrences in this article. After all, we can transform a $n$-length linear recurrence with an added constant into a $(n+1)$-th length homogeneous linear recurrence anyways.

<details markdown="1" style="margin-bottom: 5%"><summary>How?</summary>

Shift the linear recurrence and subtract from itself:

$$
\begin{align*}
s_i &= p + c_1 s_{i-1} + c_2 s_{i-2} + c_3 s_{i-3} + \dots + c_n s_{i-n} \\
s_{i+1} &= p + c_1 s_{i} + c_2 s_{i-1} + c_3 s_{i-2} + \dots + c_n s_{i-n+1} \\
s_{i+1} - s_i &= c_1 s_{i} + (c_2 - c_1) s_{i-1} + (c_3 - c_2) s_{i-2} + \dots + (c_n - c_{n-1}) s_{i-n+1} - c_n s_{i-n} \\
s_{i+1} &= (c_1 + 1) s_{i} + (c_2 - c_1) s_{i-1} + (c_3 - c_2) s_{i-2} + \dots + (c_n - c_{n-1}) s_{i-n+1} - c_n s_{i-n}
\end{align*}
$$

---

</details>

Here are some more examples (and one non-example) of linear recurrences:

<details markdown="1" style="margin-bottom: 5%"><summary>Example 1</summary>

$$
F_i = F_{i-1} + F_{i-2} \\
F_0 = 0 \\
F_1 = 1
$$

This linear recurrence is the well-known Fibonacci sequence.

---

</details>

<details markdown="1" style="margin-bottom: 5%"><summary>Example 2</summary>

$$
s_i = 2s_{i-2} \\
s_0 = 1 \\
s_1 = 3
$$

Despite this linear recurrence appearing to only have 1 term, we will still refer to it as having length 2. There is an implicit $0 \cdot s_{i-1}$ term. Essentially, we define length as the number of base case terms necessary.

---

</details>

<details markdown="1" style="margin-bottom: 5%"><summary>Example 3</summary>

$$
s_i = 0
$$

This is technically a homogeneous linear recurrence, albeit a trivial example.

---

</details>

<details markdown="1" style="margin-bottom: 5%"><summary>Example 4</summary>

$$
s_i = s_{i-1} s_{i-2} + 2s_{i-3} \\
s_0 = 0 \\
s_1 = 1 \\
s_2 = 1
$$

The above recurrence is **not** a linear recurrence. This is because the $s_{i-1} s_{i-2}$ term violates the linear condition, as it's not a constant times a single previous term. This would be a [quadratic recurrence](https://mathworld.wolfram.com/QuadraticRecurrenceEquation.html).

---

</details>

Once we obtain the linear recurrence, we can compute the $k$th term of a $n$ length linear recurrence in $\mathcal O(nk)$ naively. Or, if $k$ is larger (say $k \leq 10^{18}$), we can instead compute it using [matrix exponentiation](https://usaco.guide/plat/matrix-expo?lang=cpp) in $\mathcal O(n^3 \log k)$ time. However, what might be less known is an even faster algorithm that works in $\mathcal O(n \log n \log k)$. Let's learn about it in the next section.

## Finding the $k$th Term of a Linear Recurrence <a name="kth"></a>

This isn't part of the Berlekamp-Massey algorithm, but it's still useful to know. [TLE's blog](https://codeforces.com/blog/entry/61306) covers this algorithm pretty well, but I'll include it here for the sake of completeness.

First, for a polynomial $f(x) = \sum_{i=0}^n c_i x^i$, we define $G(f) = \sum_{i=0}^n c_i s_i$, where $s_i$ are the terms of our infinite sequence generated by our recurrence. $G$ satisfies the properties $G(f + g) = G(f) + G(g)$ for polynomials $f$ and $g$ and $G(kf) = k G(f)$ for scalar $k$. The $k$th term of our sequence is just $G(x^k)$:

$$
\begin{align*}
G(x^k) &= G(1 \cdot x^k + 0 \cdot x^{k-1} + 0 \cdot x^{k-2} + \dots + 0 \cdot x + 0 \cdot 1) \\
&= 1 \cdot s_k + 0 \cdot s_{k-1} + 0 \cdot s_{k-2} + \dots + 0 \cdot s_1 + 0 \cdot s_0 \\
&= s_k
\end{align*}
$$

This alone is kind of silly, because $G(x^k)$ requires knowledge of $s_k$ to evaluate, which is what we're trying to find. However, let's consider a special polynomial. For a linear recurrence $\\{c_1, c_2, \dots, c_n\\}$, we define the **characteristic polynomial** of that recurrence as $f(x) = x^n - c_1 x^{n-1} - c_2 x^{n-2} - \dots - c_{n-1} x - c_n$.

The characteristic polynomial has interesting properties when applying $G$. What is $G(f)$?

<details markdown="1" style="margin-bottom: 5%"><summary>Answer</summary>

$$
\begin{align*}
G(f) &= G(x^n - \sum_{j=1}^n c_j x^{n-j}) \\
&= 1 \cdot s_n - c_1 \cdot s_{n-1} - c_2 \cdot s_{n-2} - \dots - c_{n-1} \cdot s_1 - c_n \cdot s_0 \\
&= 0
\end{align*}
$$

The last line is because $s_n$ satisfies the recurrence relation $s_i = \sum_{j=1}^n c_j s_{i-j}$.

---

</details>

And similarly, what is $G(x f(x))$? Or $G(x^2 f(x))$? Or $G(f(x) g(x))$ for any arbitrary polynomial $g(x)$?

<details markdown="1" style="margin-bottom: 5%"><summary>Answer</summary>

$$
\begin{align*}
G(x f(x)) &= G(x^{n+1} - \sum_{j=1}^n c_j x^{n+1-j}) \\
&= 1 \cdot s_{n+1} - c_1 \cdot s_n - c_2 \cdot s_{n-1} - \dots - c_{n-1} \cdot s_2 - c_n \cdot s_1 \\
&= 0 \\
G(x^2 f(x)) &= G(x^{n+2} - \sum_{j=1}^n c_j x^{n+2-j}) \\
&= 1 \cdot s_{n+2} - c_1 \cdot s_{n+1} - c_2 \cdot s_n - \dots - c_{n-1} \cdot s_3 - c_n \cdot s_2 \\
&= 0
\end{align*}
$$

A similar proof applies to $G(x^k f(x))$ for any arbitrary $k$. And thus, $G(f(x) g(x)) = 0$ as well because we can distribute over the terms of $g$, pull out the scalar, and apply our knowledge of $G(x^k f(x)) = 0$.

---

</details>

What is the implication of this? Consider $x^k / f(x)$. We can express any two polynomials $a(x)$ and $b(x)$ as $a(x) = b(x) q(x) + r(x)$, where $q(x)$ is the quotient after dividing $a(x)$ by $b(x)$ and $r(x)$ is the remainder. Applying this to $x^k / f(x)$, we get

$$
\begin{align*}
x^k &= f(x) q(x) + r(x) \\
G(x^k) &= G(f(x) q(x) + r(x)) \\
&= G(f(x) q(x)) + G(r(x)) \\
&= G(r(x))
\end{align*}
$$

We use the notation $r(x) = a(x) \bmod b(x)$. So it suffices to compute $G(x^k \bmod f(x))$! If we use binary exponentiation, we can compute this in $\mathcal O(n \log n \log k)$:

```c++
template<typename T>
T solve(const vector<T> &c, const vector<T> &s, long long k) {
    int n = (int) c.size();
    assert(c.size() <= s.size());

    vector<T> a = n == 1 ? vector<T>{c[0]} : vector<T>{0, 1}, x{1};
    for (; k>0; k/=2) {
        if (k % 2)
            x = mul(x, a);  // mul(a, b) computes a(x) * b(x) mod f(x)
        a = mul(a, a);
    }
    x.resize(n);

    T ret = 0;
    for (int i=0; i<n; i++)
        ret += x[i] * s[i];
    return ret;
}
```

If you want to know how to compute $a(x) \bmod b(x)$ in $\mathcal O(n \log n)$, you can refer to this [cp-algorithms article](https://cp-algorithms.com/algebra/polynomial.html#toc-tgt-5).

In practice, we usually perform `mul` naively in $\mathcal O(n^2)$, giving us an $\mathcal O(n^2 \log k)$ algorithm instead. This is for two reasons.
1. Berlekamp-Massey works in $\mathcal O(n^2)$ and is usually the bottleneck anyways, so the $\mathcal O(n \log n \log k)$ algorithm has limited usage.
2. The $\mathcal O(n \log n \log k)$ algorithm uses FFT, so we would have to implement FFT with arbitrary modulus if our modulus was not FFT-friendly (e.g. $10^9 + 7$).

<details markdown="1" style="margin-bottom: 5%"><summary>Naive Implementation of "mul"</summary>

```c++
vector<T> mul(const vector<T> &a, const vector<T> &b) {
    vector<T> ret(a.size() + b.size() - 1);
    // ret = a * b
    for (int i=0; i<(int)a.size(); i++)
        for (int j=0; j<(int)b.size(); j++)
            ret[i+j] += a[i] * b[j];
    // reducing ret mod f(x)
    for (int i=(int)ret.size()-1; i>=n; i--)
        for (int j=n-1; j>=0; j--)
            ret[i-j-1] += ret[i] * c[j];
    ret.resize(min((int) ret.size(), n));
    return ret;
}
```

---

</details>

Now it's time for the meat of the article: obtaining the linear recurrence with Berlekamp-Massey.

## What is the Berlekamp-Massey algorithm? <a name="berlekamp-massey"></a>

Given some finite sequence of numbers $s$, the Berlekamp-Massey algorithm can find the shortest linear recurrence that satisfies $s$. For example, if we plug in the sequence $\\{0, 1, 1, 3, 5, 11, 21\\}$, the algorithm will return the sequence $\\{1, 2\\}$, corresponding to the linear recurrence $s_i = s_{i-1} + 2s_{i-2}$.

Before I explain the algorithm, I will unfortunately have to do a quick definition/notation dump. This is mainly so that I can make the rest of the article less verbose. Don't worry, most of the notation is very natural in my opinion.

- Sequences will be denoted using curly brackets (e.g. $\\{1, 2, 3\\}$ or $\\{43, 123, 2, 10\\}$).
- 0-based indexing will be used for the sequence, and 1-based indexing will be used for the sequence of recurrence relation coefficients. The sequence will be $s$, and the sequence of recurrence relation coefficients will be $c$. So we will have $\\{s_0, s_1, s_2, \dots\\}$ and $\\{c_1, c_2, \dots, c_n\\}$ satisfying $s_i = \sum_{j=1}^n c_j s_{i-j}$ for $i \geq n$.
- The length of a sequence is denoted as $\|c\|$ or $n$.
- Say I have some recurrence relation sequence $c = \\{c_1, c_2, \dots, c_n\\}$. I will denote "evaluating the recurrence relation at index $i$" as $c(i) = \sum_{j=1}^n c_j s_{i-j}$. If the recurrence relation correctly evaluates $s_i$, then $c(i) = s_i$.
    - A recurrence relation is correct if it successfully evaluates $c(i) = s_i$ for all $i \geq n$.
    - To avoid negative indices for $c(i)$ when $i < n$, we will simply say $c(i) = s_i$ is always true for $i < n$. This is an acceptable definition since those $s_i$ form the base case anyways.
    - If $c$ is empty, $c(i) = 0$.
- Say we have two sequences $c$ and $d$. I define adding two sequences $c$ and $d$ as $c + d = \\{c_1 + d_1, c_2 + d_2, \dots, c_n + d_n\\}$.
    - If $c$ and $d$ are of different lengths, we pad with zeros. So say $\|c\| = n, \|d\| = m > n$. Then $c + d = \\{c_1 + d_1, c_2 + d_2, \dots, c_n + d_n, d_{n+1}, \dots, d_m\\}$.
    - From this definition, we have the identity $c(i) + d(i) = (c + d)(i)$. You can prove this by explicitly writing the terms out.
- I define scalar multiplication with a sequence $c$ as $kc = \\{kc_1, kc_2, \dots, kc_n\\}$.
    - From this definition, we have the identity $k \cdot c(i) = (kc)(i)$. You can prove this by explicitly writing the terms out.
- The general gist of Berlekamp-Massey is as follows: we have some initial $c$. Each time we process the next element $s_i$, we will check if $c$ correctly evaluates $s_i$. If it's correct, we keep $c$. If it's wrong, we know $c$ isn't the correct recurrence relation for our sequence. We will have $c(i) \neq s_i$. Then, we will adjust $c$ to some new $c'$ such that $c'(j) = s_j$ for all $j \leq i$.
    - We say a recurrence relation sequence $c$ **fails** at index $i$ if $i$ is the first index where $c(i) \neq 0$.

Phew! Ok, let's start.

## An Example <a name="example"></a>

It is much easier to explain with an example. So let's use the sequence $s = \\{1, 2, 4, 8, 13, 20, 28, 215, 757, 2186\\}$. We will begin with an empty recurrence relation sequence $c = \\{\\}$.

Let's start by processing $i = 0$. We have $c(0) = 0 \neq 1 = s_0$ (recall that if $c$ is empty, $c(i) = 0$). Hmm, that's not right. Since this is the first time we're initializing $c$, we will merely set $c = \\{1\\}$. It's very likely that we'll have to change $c$ in the next step anyways, so the main purpose of initializing $c$ like this is simply to ensure $s_0$ is the base case. For all we care, we could set $c = \\{0\\}$ or $c = \\{69\\}$ and it wouldn't matter.

Next, let's go to $i = 1$. We have $c(1) = c_1 \cdot s_{1-1} = 1 \cdot 1 = 1 \neq 2 = s_1$. Ok, unfortunately the recurrence relation was wrong. We'll have to adjust. Fortunately, there's a simple fix to this: change to $c = \\{2\\}$. Now, $c(1) = 2 \cdot 1 = 2$ like we wanted.

Next, we process $i = 2$. We have $c(2) = c_1 \cdot s_{2-1} = 2 \cdot 2 = 4 = s_2$. It appears our $c$ works, so there's no need to modify it.

Next, $i = 3$. $c(3) = c_1 \cdot s_{3-1} = 2 \cdot 4 = 8 = s_3$. This works, so we make no changes.

Next, $i = 4$. $c(4) = c_1 \cdot s_{4-1} = 2 \cdot 8 = 16 \neq 13 = s_3$. We need to adjust. What if we made $c = \\{13 / 8\\}$? The issue is, now $c(4) = 13$ like we wanted, but $c(3)$ is wrong! We can no longer assume the linear recurrence is just of length 1. We'll need something more sophisticated.

Let's be more specific about what we want. We want some sequence $c' = c + d$ such that $c'(i)$ evaluates correctly for all $i \leq 4$. So we want some $d$ such that $d(i) = 0$ for $i < 4$ and $d(4) = s_4 - c(4) = -3$. We denote our desired value for $d(4)$ as $\Delta$.

Here's the trick to generate such a $d$: let's keep track of each previous version of $c$ and which index it failed on. So for example, we have $\\{\\}$ which failed at index 0 and $\\{1\\}$ which failed at index 1. Let's consider the second version of $c$, the $\\{1\\}$ sequence that failed at index 1. Let's denote the failure index as $f$. Here's what we'll do:
1. Set $d$ equal to that sequence.
2. Multiply the sequence by $-1$.
3. Insert a 1 on the left.
4. Multiply the sequence by $\frac{\Delta}{d(f + 1)} = \frac{-3}{1} = -3$.
5. Insert $i - f - 1 = 4 - 1 - 1 = 2$ zeros on the left.

<details markdown="1" style="margin-bottom: 5%"><summary>$d$ after each step</summary>

After Step 1: $d = \\{1\\}$

After Step 2: $d = \\{-1\\}$

After Step 3: $d = \\{1, -1\\}$

After Step 4: $d = \\{-3, 3\\}$

After Step 5: $d = \\{0, 0, -3, 3\\}$

---

</details>

So we have $d = \\{0, 0, -3, 3\\}$. I know this seems super arbitrary, but let's evaluate $d$ and see what happens:

$$
d(4) = d_1 s_{4-1} + d_2 s_{4-2} + d_3 s_{4-3} + d_4 s_{4-4} = 0 \cdot 8 + 0 \cdot 4 - 3 \cdot 2 + 3 \cdot 1 = -3
$$

And $d$ isn't defined for $i < 4$, since it's a length 4 sequence. So I guess this $d$ works. Our new recurrence is thus $c + d = \\{2\\} + \\{0, 0, -3, 3\\} = \\{2, 0, -3, 3\\}$.

Let's keep going. Our new $c$ will work for $i = 5$ and $i = 6$, but fail for $i = 7$.

$$
c(7) = c_1 s_{7-1} + c_2 s_{7-2} + c_3 s_{7-3} + c_4 s_{7-4} = 2 \cdot 28 + 0 \cdot 20 - 3 \cdot 13 + 3 \cdot 8 = 41 \neq 215 = s_7
$$

We need some $d$ to add to $c$ such that $d(i) = 0$ for $i < 7$ and $d(7) = s_7 - c(7) = 174$.

Once again, let's look at the past versions of $c$:
- $\\{\\}$ which failed at index 0.
- $\\{1\\}$ which failed at index 1.
- $\\{2\\}$ which failed at index 4.

This time, we'll consider the third version of $c$, the $\\{2\\}$ sequence that failed at index 4 (I'll explain which version you pick in a moment). We will apply the following seemingly arbitrary steps:
1. Set $d$ equal to our chosen sequence.
2. Multiply the sequence by $-1$.
3. Insert a 1 on the left.
4. Multiply the sequence by $\frac{\Delta}{d(f + 1)} = \frac{174}{-3} = -58$.
5. Insert $i - f - 1 = 7 - 4 - 1 = 2$ zeros on the left.

<details markdown="1" style="margin-bottom: 5%"><summary>$d$ after each step</summary>

After Step 1: $d = \\{2\\}$

After Step 2: $d = \\{-2\\}$

After Step 3: $d = \\{1, -2\\}$

After Step 4: $d = \\{-58, 116\\}$

After Step 5: $d = \\{0, 0, -58, 116\\}$

---

</details>

Does our $d$ work? Let's find out.

$$
\begin{align*}
d(7) &= d_1 s_{7-1} + d_2 s_{7-2} + d_3 s_{7-3} + d_4 s_{7-4} = 0 \cdot 28 + 0 \cdot 20 - 58 \cdot 13 + 116 \cdot 8 = 174 \\
d(6) &= d_1 s_{6-1} + d_2 s_{6-2} + d_3 s_{6-3} + d_4 s_{6-4} = 0 \cdot 20 + 0 \cdot 13 - 58 \cdot 8 + 116 \cdot 4 = 0 \\
d(5) &= d_1 s_{5-1} + d_2 s_{5-2} + d_3 s_{5-3} + d_4 s_{5-4} = 0 \cdot 13 + 0 \cdot 8 - 58 \cdot 4 + 116 \cdot 2 = 0 \\
d(4) &= d_1 s_{4-1} + d_2 s_{4-2} + d_3 s_{4-3} + d_4 s_{4-4} = 0 \cdot 8 + 0 \cdot 4 - 58 \cdot 2 + 116 \cdot 1 = 0
\end{align*}
$$

Holy cow this actually works! So we add $d$ to our old $c$ to get our new $c$: $\\{2, 0, -3, 3\\} + \\{0, 0, -58, 116\\} = \\{2, 0, -61, 119\\}$.

Finally, we process $i = 8$ and $i = 9$, and find the recurrence is correct for both of them. So $c = \\{2, 0, -61, 119\\}$ is our final answer.

## How does our process for choosing $d$ work? <a name="d-process"></a>

Let's examine those "arbitrary" steps closely, shall we?
1. Set $d$ equal to our chosen sequence.
2. Multiply the sequence by $-1$.
3. Insert a 1 on the left.
4. Multiply the sequence by $\frac{\Delta}{d(f + 1)}$.
5. Insert $i - f - 1$ zeros on the left.

First, we choose some older version of $c$, which we will denote as $b$ and having failed at index $f$. Notice that $b(j) = s_j$ for $j < f$ and $b(f) \neq s_f$. That's true by the definition of a failed sequence. Let's instead consider it as $s_j - b(j) = 0$ for $j < f$ and $s_f - b(f) \neq 0$. That's essentially what steps 1-3 are doing: they set $d$ such that $d(j + 1) = s_j - b(j)$.

<details markdown="1" style="margin-bottom: 5%"><summary>Written out more obviously</summary>

After step 1: $d = b = \\{b_1, b_2, \dots, b_n\\}$

After step 2: $d = \\{-b_1, -b_2, \dots, -b_n\\}$

After step 3: $d = \\{1, -b_1, -b_2, \dots, -b_n\\}$

And evaluating $d(j + 1)$:

$$
\begin{align*}
d(j + 1) &= \sum_{k=1}^n d_k s_{j+1-k} \\
&= 1 \cdot s_j - b_1 s_{j-1} - b_2 s_{j-2} - \dots - b_n s_{j-n} \\
&= s_j - (b_1 s_{j-1} + b_2 s_{j-2} + \dots + b_n s_{j-n}) \\
&= s_j - b(j)
\end{align*}
$$

---

</details>

We know that $d(j) = 0$ for $j \leq f$ and $d(f + 1) \neq 0$. After multiplying the sequence by $\frac{\Delta}{d(f + 1)}$ per step 4, we get that $d(j) = 0$ for $j \leq f$ still holds true, but now $d(f + 1) = \Delta$.

<details markdown="1" style="margin-bottom: 5%"><summary>Why?</summary>

You didn't forget the identity $k \cdot c(i) = (kc)(i)$, did you?

---

</details>

Finally, step 5 makes us insert $i - f - 1$ zeros on the left. To understand the effect of that, let's start by inserting one zero. Let $d'$ be $d$ with an extra zero inserted on the left. We have that $d'(j) = d(j - 1)$. To prove this, just write out the terms explicitly. So inserting zeros on the left is just a shift! If we insert $k$ zeros, we get $d'(j) = d(j - k)$. If we insert $i - f - 1$ zeros, we get $d'(j) = d(j - (i - f - 1))$. Specifically, $d'(i) = d(i - (i - f - 1)) = d(f + 1) = \Delta$, and $d'(j) = 0$ for $j < i$. This is exactly the condition we wanted to impose on our $d$ sequence!

## Which $b$ do we choose? <a name="b-process"></a>

While choosing any $b$ will work, let's not forget that in addition to finding a linear recurrence that works, we want a linear recurrence of minimal length.

Take a look at the diagram below.

![image 1]({{ site.baseurl }}/assets/images/berlekamp-massey-1.png)

We are currently processing $i = 8$. The current linear recurrence sequence is the red one, is of length 4, and has just failed at index 8. We have three previous versions of $c$: a yellow sequence of length 1 that failed at index 1, a green sequence of length 2 that failed at index 4, and a blue sequence of length 3 that failed at index 6. You can also imagine there's one more sequence: an empty sequence that failed at index 0. I didn't draw it since it's of length 0.

Let's say we pick the blue sequence as our $b$. I have now drawn a purple segment on our diagram:

![image 2]({{ site.baseurl }}/assets/images/berlekamp-massey-2.png)

This purple segment represents the length of $d$. You can verify that one unit of increased length comes from the inserted 1, and one unit of increased length comes from the $i - f - 1 = 8 - 6 - 1 = 1$ zeros inserted. And the final updated $c'$ comes from overlaying the red and purple segments, representing us adding $c$ and $d$.

This tells us what the optimal $b$ is: the one whose segment has the rightmost left endpoint! So we only need to keep track of that best $c$ throughout the algorithm, not every previous version.

## The First Step <a name="first-step"></a>

Selecting a previous version of $c$ to use only works if you're not updating $c$ for the first time. So what do you do if you do update $c$ for the first time? Let's find out with the following example: $s = \\{0, 0, 0, 0, 1, 0, 0, 2\\}$. Once again, $c = \\{\\}$ initially.

Process $i = 0$. $c(0) = 0 = s_0$. So we keep going.

Process $i = 1$. $c(0) = 0 = s_1$. So we keep going.

This repeats until we reach $i = 4$. $c(0) = 0 \neq 1 = s_4$. Since we are updating $c$ for the first time, there are no previous versions of $c$ to rely on. So we will initialize $c$ to an arbitrary length 5 sequence. The reason why it must be at least length 5 is because that is the minimal length required to include $s_4$ in the base case. If $s_4$ was not part of the base case, then it must satisfy some recurrence $s_4 = \sum_{j=1}^n c_j s_{4-j}$. But since $s_0, s_1, s_2, s_3$ are all zero, such a recurrence would always evaluate to 0. So $s_4$ must be part of the base case. For simplicity, we will assign $c = \\{0, 0, 0, 0, 0\\}$, although like I stated in the previous example, the values could be arbitrary.

Now, when you update $c$ a second time when failing at index 7, you can rely on $b = \\{\\}$ with failure index 4. You can try by hand to confirm that this works.

<details markdown="1" style="margin-bottom: 5%"><summary>What $c$ becomes at index 7</summary>

$$
\{0, 0, 2, 0, 0\}
$$

Yes, the extra trailing 0s matter! Without them, $s_4$ would not be part of the base case!

---

</details>

Notice that if the sequence is all 0s, this algorithm will simply return $c = \\{\\}$, which is fine since we defined $c(i) = 0$ for an empty sequence.

## Putting it all together in code... <a name="code"></a>

```c++
template<typename T>
vector<T> berlekampMassey(const vector<T> &s) {
    vector<T> c;    // the linear recurrence sequence we are building
    vector<T> oldC; // the best previous version of c to use (the one with the rightmost left endpoint)
    int f = -1;     // the index at which the best previous version of c failed on
    for (int i=0; i<(int)s.size(); i++) {
        // evaluate c(i)
        // delta = s_i - \sum_{j=1}^n c_j s_{i-j}
        // if delta == 0, c(i) is correct
        T delta = s[i];
        for (int j=1; j<=(int)c.size(); j++)
            delta -= c[j-1] * s[i-j];   // c_j is one-indexed, so we actually need index j - 1 in the code
        if (delta == 0)
            continue;   // c(i) is correct, keep going
        // now at this point, delta != 0, so we need to adjust it
        if (f == -1) {
            // this is the first time we're updating c
            // s_i was the first non-zero element we encountered
            // we make c of length i + 1 so that s_i is part of the base case
            c.resize(i + 1);
            mt19937 rng(chrono::steady_clock::now().time_since_epoch().count());
            for (T &x : c)
                x = rng();  // just to prove that the initial values don't matter in the first step, I will set to random values
            f = i;
        } else {
            // we need to use a previous version of c to improve on this one
            // apply the 5 steps to build d
            // 1. set d equal to our chosen sequence
            vector<T> d = oldC;
            // 2. multiply the sequence by -1
            for (T &x : d)
                x = -x;
            // 3. insert a 1 on the left
            d.insert(d.begin(), 1);
            // 4. multiply the sequence by delta / d(f + 1)
            T df1 = 0;  // d(f + 1)
            for (int j=1; j<=(int)d.size(); j++)
                df1 += d[j-1] * s[f+1-j];
            assert(df1 != 0);
            T coef = delta / df1;   // storing this in outer variable so it's O(n^2) instead of O(n^2 log MOD)
            for (T &x : d)
                x *= coef;
            // 5. insert i - f - 1 zeros on the left
            vector<T> zeros(i - f - 1);
            zeros.insert(zeros.end(), d.begin(), d.end());
            d = zeros;
            // now we have our new recurrence: c + d
            vector<T> temp = c; // save the last version of c because it might have a better left endpoint
            c.resize(max(c.size(), d.size()));
            for (int j=0; j<(int)d.size(); j++)
                c[j] += d[j];
            // finally, let's consider updating oldC
            if (i - (int) temp.size() > f - (int) oldC.size()) {
                // better left endpoint, let's update!
                oldC = temp;
                f = i;
            }
        }
    }
    return c;
}
```

I tried to annotate the code as best as I can, using the same terminology as in the article. The method uses generic types, so you can plug in modint if you're computing something under mod, or double, if you're working with real numbers (warning that numerical stability is not guaranteed). If you need a working modint template, you can find mine [here](https://github.com/mzhang2021/cp-library/blob/master/implementations/math/Modular.h). The complexity of this algorithm is clearly $\mathcal O(n^2)$.

## Test for Understanding <a name="test"></a>

Do you really understand everything I just explained? If so, try your hand at some of these exercises! For the purpose of this exercise, assume the first step fills with $i + 1$ zeros instead of random values.

1. Find the intermediate sequences of $c$ after each step of the algorithm on $s = \\{0, 2, 3, 4, 5, 6, 7, 8\\}$.

    <details markdown="1" style="margin-bottom: 5%"><summary>Answer</summary>

    $c$ after each $i$ is processed:

    $$
    \begin{align*}
    i = 0&: c = \{\} \\
    i = 1&: c = \{0, 0\} \\
    i = 2&: c = \{3/2, 0\} \\
    i = 3&: c = \{3/2, -1/4\} \\
    i = 4&: c = \{3/2, -1/4, -1/8\} \\
    i = 5&: c = \{2, -1, 0\} \\
    i = 6&: c = \{2, -1, 0\} \\
    i = 7&: c = \{2, -1, 0\}
    \end{align*}
    $$

    ---

    </details>

2. Find the intermediate sequences of $c$ after each step of the algorithm on $s = \\{1, 8, 10, 26, 46\\}$.

    <details markdown="1" style="margin-bottom: 5%"><summary>Answer</summary>

    $c$ after each $i$ is processed:

    $$
    \begin{align*}
    i = 0&: c = \{0\} \\
    i = 1&: c = \{8\} \\
    i = 2&: c = \{8, -54\} \\
    i = 3&: c = \{1, 2\} \\
    i = 4&: c = \{1, 2\}
    \end{align*}
    $$

    ---

    </details>

3. Find the intermediate sequences of $c$ after each step of the algorithm on $s = \\{1, 3, 5, 11, 25, 59, 141, 339\\}$.

    <details markdown="1" style="margin-bottom: 5%"><summary>Answer</summary>

    $c$ after each $i$ is processed:

    $$
    \begin{align*}
    i = 0&: c = \{0\} \\
    i = 1&: c = \{3\} \\
    i = 2&: c = \{3, -4\} \\
    i = 3&: c = \{1, 2\} \\
    i = 4&: c = \{1, 1, 3\} \\
    i = 5&: c = \{3, -1, -1\} \\
    i = 6&: c = \{3, -1, -1\} \\
    i = 7&: c = \{3, -1, -1\}
    \end{align*}
    $$

    ---

    </details>

## Proofs <a name="proofs"></a>

I know not everyone will be interested in this section, so I'll put them under a spoiler.

<details markdown="1" style="margin-bottom: 5%"><summary>Click Me!</summary>

The proofs come from [Massey's paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1054260) and will actually allow us to prove an even stronger condition on the minimum length recurrence relation, which will let us implement a conciser solution.

**Definition:** Let $L_i$ denote the minimum length recurrence relation for the prefix of the first $i$ elements of $s$. Let $r_i$ denote that recurrence relation of length $L_i$.

**Theorem:** If $r_{i-1}$ works for all positions up to $i - 1$ but not for position $i$ (i.e. $r_{i-1} \neq r_i$), then $L_i \geq \max(L_{i-1}, i + 1 - L_{i-1})$.

To prove this, we will prove the two arguments inside the $\max$ function separately.

**Lemma 1:** $L_i \geq L_{i-1}$

This lemma is kind of self-evident. By definition, $r_{i-1}$ must work for all positions up to $i - 1$ and is of minimal length for position $i - 1$. And $r_i$ must work for all positions up to $i$ and is of minimal length for position $i$. Say $L_i < L_{i-1}$. Then that contradicts the definition of $r_{i-1}$, because there exists a recurrence of shorter length that works for all positions up to $i - 1$: $r_i$. **Notice that this lemma is true for all $i$, not just when $r_{i-1} \neq r_i$.**

**Lemma 2:** $L_i \geq i + 1 - L_{i-1}$

Case 1: $L_{i-1} \geq i$

This case is self-evident, because then we get $L_i \geq 1$. There's no way $L_i = 0$ because that would imply $r_i$ is the empty sequence. $L_{i-1}$ would also have to be 0 because $L_{i-1} \leq L_i$ and $L_{i-1}$ can't be negative since you can't have negative length. So $L_{i-1}$ would also have to be the empty sequence, and $r_{i-1} = r_i$, meaning the theorem no longer applies since the theorem assumes $r_{i-1}$ fails for position $i$.

Case 2: $L_{i-1} < i$

Let the coefficients of $r_{i-1}$ be $c_j$ and the coefficients of $r_i$ be $d_j$. By definition:

$$
\sum_{j=1}^{L_{i-1}} c_j s_{k-j} \begin{cases}
= s_k & L_{i-1} \leq k < i \\
\neq s_k & k = i
\end{cases}
$$

and

$$
\sum_{j=1}^{L_i} d_j s_{k-j} \begin{array}{cc} = s_k & L_i \leq k \leq i \end{array}
$$

We will do a proof by contradiction. Assume $L_i < i + 1 - L_{i-1}$. Thus,

$$
\begin{align*}
\sum_{j=1}^{L_{i-1}} c_j s_{i-j} &= \sum_{j=1}^{L_{i-1}} c_j \left( \sum_{k=1}^{L_i} d_k s_{i-j-k} \right) \\
&= \sum_{j=1}^{L_{i-1}} \sum_{k=1}^{L_i} c_j d_k s_{i-j-k} \\
&= \sum_{k=1}^{L_i} \sum_{j=1}^{L_{i-1}} d_k c_j s_{i-k-j} \\
&= \sum_{k=1}^{L_i} d_k \left( \sum_{j=1}^{L_{i-1}} c_j s_{i-k-j} \right) \\
&= \sum_{k=1}^{L_i} d_k s_{i-k} \\
&= s_i
\end{align*}
$$

But this is a contradiction, since we forced by definition that $\sum_{j=1}^{L_{i-1}} c_j s_{i-j} \neq s_i$. Thus, $L_i \geq i + 1 - L_{i-1}$. Notice that the index $i - j - k$ never dips negative thanks to us assuming $L_i < i + 1 - L_{i-1}$.

Combining the above two lemmas provides us with our theorem.

### Proving the Algorithm

We will initiate a proof by induction. Let the base case be the first position of a non-zero element in $s$ (if all the elements in $s$ are 0, the recurrence is just the empty sequence and we are done). As proven under ["The First Step"](#first-step) section of this article, the optimal length of a first non-zero element at index $i$ is $i + 1$.

Now for the induction step: assume for all $j < i$, if $r_{j-1} \neq r_j$, then $L_j = \max(L_{j-1}, j + 1 - L_{j-1})$, and otherwise when $r_{j-1} = r_j$, then $L_j = L_{j-1}$. Then that same condition holds true for $j = i$. There are two cases.

Case 1: $r_{i-1}$ works for index $i$. In this case, we keep the same recurrence for the next index, and this is optimal per lemma 1.

Case 2: $r_{i-1}$ does not work for index $i$. Since this is not the first step, our algorithm chooses a previous version and use it to construct $d$. Recall from the section ["Which $b$ do we choose?"](#b-process) that it is optimal to pick the version with the rightmost left endpoint. From here, we spawn two more cases:

Case 2a: The left endpoint of the old version is greater than or equal to the left endpoint of our current recurrence. In this case, the length of our new recurrence sequence does not change, which is optimal.

Case 2b: The left endpoint of the old version is less than the left endpoint of our current recurrence. In this case, the length of our new recurrence does change! Recall our theorem, which states that $L_i \geq \max(L_{i-1}, i + 1 - L_{i-1})$ when our recurrence changes. Since the length is getting longer, it must be that $L_i \geq i + 1 - L_{i-1}$. Let's prove that our algorithm always yields $L_i = i + 1 - L_{i-1}$.

Let the index where our previous version failed be $m$. Notice that every time we update the previous version, it's when the recurrence got longer. So $L_{m-1} < L_m = L_{m+1} = \dots = L_{i-1}$. By induction, $L_m = \max(L_{m-1}, m + 1 - L_{m-1})$. Since $L_m > L_{m-1}$, $L_m = m + 1 - L_{m-1}$, or $L_{m-1} = m + 1 - L_m = m + 1 - L_{i-1}$. Now, note that if the previous version failed at index $m$ and we are currently at index $i$, the length of the new recurrence will be $i - m + L_{m-1}$ (look at the diagram of segments above if you're unsure). Finally,

$$
\begin{align*}
L_i &= i - m + L_{m-1} \\
&= i - m + (m + 1 - L_{i-1}) \\
&= i + 1 - L_{i-1}
\end{align*}
$$

### A More Concise Implementation

Our theorem above provided a stronger condition on $L_i$, which lets us greatly shorten our implementation. Take a look at the code below (courtesy of [KACTL](https://github.com/kth-competitive-programming/kactl/blob/main/content/numerical/BerlekampMassey.h)):

```c++
template<typename T>
vector<T> berlekampMassey(const vector<T> &s) {
    int n = (int) s.size(), l = 0, m = 1;
    vector<T> b(n), c(n);
    T ld = b[0] = c[0] = 1;
    for (int i=0; i<n; i++, m++) {
        T d = s[i];
        for (int j=1; j<=l; j++)
            d += c[j] * s[i-j];
        if (d == 0)
            continue;
        vector<T> temp = c;
        T coef = d / ld;
        for (int j=m; j<n; j++)
            c[j] -= coef * b[j-m];
        if (2 * l <= i) {
            l = i + 1 - l;
            b = temp;
            ld = d;
            m = 0;
        }
    }
    c.resize(l + 1);
    c.erase(c.begin());
    for (T &x : c)
        x = -x;
    return c;
}
```

Some notes about this implementation:
- `n` is the length of the $s$ sequence, not the $c$ sequence
- `c` is our current recurrence relation
- `b` is our best previous version
- `l` is the length of our current recurrence relation
- `m` is the number of steps since the last time we increased the length of our recurrence relation
- `ld` is the last $\Delta$ computed with our previous version
- In this implementation, we instead define the recurrence as $s_i + \sum_{j=1}^n c_j s_{i-j} = 0$, so we negate all the coefficients at the end.
- We also append a 1 at the beginning of `c` and `b`. You can figure out why this works by tracing the code.
- This implementation also takes care of the first step, all with the same logic!

---

</details>

## Applications in Problems <a name="applications"></a>

Ok, this is what you probably came for. Aside from contrived problems asking us to explicitly find the minimum length linear recurrence satisfying a sequence, what can we do with Berlekamp-Massey? The answer is that we pretty much never have to figure out an explicit recurrence ever again!

Take this [Codeforces problem](https://codeforces.com/contest/1511/problem/F) for example. First, let's come up with a naive DP solution. Feel free to think for a while, then click the spoiler.

<details markdown="1" style="margin-bottom: 5%"><summary>Naive DP Solution</summary>

Let $dp[i][a][b][c][d]$ be the number of chainwords of length $i$, where the final character in the chainword is the $b$th character of the $a$th word and the $d$th character of the $c$th word. Essentially, we maintain what segment we are on for the top and bottom hints. Let $L \leq 5$ be the maximum length of a dictionary word. The complexity of this algorithm is something like $\mathcal O(n^4 L^2 m)$, depending on how you implement your transitions.

---

</details>

This is obviously way too slow. But we can make the following observation: the transitions are the same for all $i$. When this is the case, we can turn the $m$ into a $\log m$ factor with matrix exponentation or the polynomial method. The number of states we have per $i$ is $\mathcal O(n^2 L^2) \leq 1600$. Matrix exponentiation will be too slow, but our new method using polynomials can handle this just fine!

<details markdown="1" style="margin-bottom: 5%"><summary>Wait, this isn't a linear recurrence...</summary>

You're right, when we look at the transition $dp[i][a][b][c][d] \to dp[i+1][e][f][g][h]$, this doesn't look like a linear recurrence because the states have 5 dimensions instead of 1. I claim $\\{dp[0][a][b][c][d], dp[1][a][b][c][d], \dots, dp[m][a][b][c][d]\\}$ for any $a, b, c, d$ satisfies a linear recurrence of length $\mathcal O(n^2 L^2)$. I actually don't know how to prove this claim, but I'll include a train of thought I had below and maybe someone can let me know if that train leads anywhere. Who knows, maybe it's not even true, although it seems to be true from past experience and self-generated examples.

First, we will convert our recurrence down to a 2D recurrence by compressing the indices. The technique for reducing a dimension is as follows. Say you have some 2D table $dp[i][j]$ with dimensions $n \times m$. You can instead express this as a 1D table $dp[i \cdot m + j]$ with dimension $n \cdot m$. Essentially, we express our 2D pair as a base $m$ number. Refer to the diagram below to see how the conversion from 2D to 1D coordinates works.

![image 3]({{ site.baseurl }}/assets/images/berlekamp-massey-3.png)

This same idea generalizes to multiple dimensions. For our example, $dp[a][b][c][d] \to dp[a \cdot L \cdot n \cdot L + b \cdot n \cdot L + c \cdot L + d]$.

So using this idea, we can compress $dp[i][a][b][c][d]$ down to 2 dimensions, $dp[i][\dots]$. We can express $dp[0], dp[1], \dots, dp[m]$ each as vectors of length $n^2 L^2$. For transitions, we can treat it as multiplying $dp[i]$ by some transition matrix $A$ of size $n^2 L^2 \times n^2 L^2$ to get $dp[i+1]$. And our desired result is $dp[m] = A^m dp[0]$.

The [Cayley-Hamilton theorem](https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem) states that if $A$ is of dimension $n \times n$, then $A^i$ satisfies a linear recurrence of length $n$ with coefficients of the characteristic polynomial. Specifically, it states $A^n = \sum_{j=1}^n c_j A^{n-j}$, and then we can generalize that to a linear recurrence for $A^i$ by multiplying both sides by $A^{i-n}$.

~~Now, I'm stuck, because I don't think a linear recurrence for $A^m$ necessarily signifies a linear recurrence for a specific entry of $dp[m]$. If anyone knows something about this, I'd be dying to hear about it. As a bonus, it's worth noting that you don't have to rely on faith that a linear recurrence exists for a specific entry of $dp[m]$, and instead just compute $A^m dp[0]$ directly as explained in [this blog](https://codeforces.com/blog/entry/85969). The idea is to generate some $1 \times n$ vector $\vec w$ to left multiply with $A^m dp[0]$ to convert from vector to scalar. Then, we can plug these scalar values into Berlekamp-Massey.~~

From here, showing a linear recurrence exists for $dp[m]$ can be done with some algebra. User shioko on Codeforces has worked out the details [here](https://codeforces.com/blog/entry/96199?#comment-903177).

---

</details>

Ok, so we know a linear recurrence of size $\mathcal O(n^2 L^2)$ exists, but what exactly is it? Let's ask Berlekamp-Massey! Essentially, we will run the naive DP to generate the first few terms, then plug them into Berlekamp-Massey to get the full linear recurrence. It's magic! Here's a [submission](https://codeforces.com/contest/1511/submission/131888684).

By the way, how many terms do we need to plug into Berlekamp-Massey before we can be sure we got the right recurrence? For example, say we're working with the Fibonacci sequence $\\{1, 1, 2, 3, 5, \dots\\}$. If we just feed $\\{1, 1, 2\\}$ into Berlekamp-Massey, the algorithm could return $s_i = s_{i-1} + s_{i-2}$. But it could also return $s_i = 3s_{i-1} - s_{i-2}$. Or $s_i = 4s_{i-1} - 2s_{i-2}$. How do we ensure Berlekamp-Massey gives us the right recurrence?

It turns out, for a linear recurrence of length $n$, you need to feed at least $2n$ terms into Berlekamp-Massey to guarantee getting the same or equivalent recurrence.

<details markdown="1" style="margin-bottom: 5%"><summary>Proof</summary>

Let's say you only provide $2n - 1$ terms of the sequence. Say $n = 5$, the sequence is $\\{0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, \dots \\}$, and the recurrence is $s_i = s_{i-5}$ for $i \geq 5$ (this counterexample is generalizable for any $n$). Another possible recurrence of length $n$ is $s_i = 0$ for $i \geq 5$ and base case $s_0 = s_1 = s_2 = s_3 = 0, s_4 = 1$. And we wouldn't notice that this recurrence is wrong until we process $a_9$, or the $2n$th element.

On the other hand, if we have at least $2n$ elements, all $n$ length linear recurrences we could generate are equivalent. Say we have two recurrence sequences $c$ and $d$. We want to show if $s_i = \sum_{j=1}^n c_j s_{i-j} = \sum_{j=1}^n d_j s_{i-j}$ for $n \leq i < 2n$, then $s_i = \sum_{j=1}^n c_j s_{i-j} = \sum_{j=1}^n d_j s_{i-j}$ for all $i \geq 2n$ as well.

We initiate a proof by induction. The base case is $s_i = \sum_{j=1}^n c_j s_{i-j} = \sum_{j=1}^n d_j s_{i-j}$ for all $i < 2n$. Now for the induction step: if the condition is true for $i < k$, then the condition is true for $i = k$. Now we just crank out the math:

$$
\begin{align*}
s_k &= \sum_{j=1}^n c_j s_{k-j} \\
&= \sum_{j=1}^n c_j \left(\sum_{l=1}^n d_l s_{k-j-l} \right) \\
&= \sum_{j=1}^n \sum_{l=1}^n c_j d_l s_{k-j-l} \\
&= \sum_{l=1}^n \sum_{j=1}^n d_l c_j s_{k-l-j} \\
&= \sum_{l=1}^n d_l \left(\sum_{j=1}^n c_j s_{k-l-j} \right) \\
&= \sum_{l=1}^n d_l s_{k-l} \\
&= \sum_{j=1}^n d_j s_{k-j}
\end{align*}
$$

Notice that $k - j - l$ never becomes negative since $k \geq 2n$, which is why this proof doesn't work when we only provide $2n - 1$ or less elements for Berlekamp-Massey.

---

</details>

Now as an aside, it's worth noting that in this problem, you need way less than $\mathcal O(n^2 L^2)$ terms. According to the editorial, there are only at most 241 states that matter, because we never reach certain combinations of states. Furthermore, in practice we don't even need to calculate an exact bound. Since extra terms can't hurt, it's much easier to just generate as many terms as the problem's time limit will allow, then plug all of them into Berlekamp-Massey and hope it gets AC. How easy is that?

## Problems <a name="problems"></a>

While none of these problems require Berlekamp-Massey to solve, Berlekamp-Massey trivializes them significantly in my opinion.

[Codeforces Round 286, Div 1 E: Mr. Kitayuta's Gift](https://codeforces.com/contest/506/problem/E)

[Atcoder Beginner Contest 198F: Cube](https://atcoder.jp/contests/abc198/tasks/abc198_f)

[Codechef July Challenge 2021, PARTN01: Even Odd Partition](https://www.codechef.com/JULY21A/problems/PARTN01)

## References <a name="references"></a>

[https://codeforces.com/blog/entry/61306](https://codeforces.com/blog/entry/61306)

[https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1054260](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1054260)

---
layout: post
title: "Maintaining a CP Library"
tags: [opinion]
---

I love maintaining a competitive programming library. You get to implement things attuned to your own personal style, and it's super satisfying when you use something from your library to successfully pass a problem. There's also just something satisfying about working on a project over a long period of time, and having it grow and evolve alongside your CP journey. I started my library 3 years ago[^1] in high school, and it's come a long way since then. And so now, I write this article so that I can ~~[plug my library](https://github.com/mzhang2021/cp-library)~~ explain how I design my implementations and how they integrate into my setup.

[^1]: If you check the stats for my Github repo, it was created in February 2020, but that was only the date when I put my implementations on Github. Before then, I used to store them locally on my laptop like a bum.

## Coding Style

The main reason I maintain a library is to have templates that integrate with my coding style. In CP, my code usually follows these certain guidelines:

- I don't use global variables. Instead, everything is in the main method, and I use lambda functions to substitute normal functions. This way, I don't ever worry about not resetting global variables in between test cases.
- I use vectors over C-style arrays so that out-of-bounds errors are caught earlier in samples rather than later in large tests.

To abide by these guidelines, you'll notice that my templates are usually in self-contained structs [^2], so that I can declare a new instance of them per test case.

[^2]: Some of my implementations use an outdated style like global arrays with fixed sizes. Those are usually implementations leftover from a long time ago that I never bothered to revamp because I don't use them frequently enough.

## An Example

Here's an example of a template for strongly connected components:

<details markdown="1" style="margin-bottom: 5%"><summary>Click Me!</summary>

```c++
// https://github.com/mzhang2021/cp-library/blob/master/implementations/graphs/SCC.h
struct SCC {
    int n, ti;
    vector<int> num, id, stk;
    vector<vector<int>> adj, dag, comp;

    SCC(int _n) : n(_n), ti(0), num(n), id(n, -1), adj(n) {}

    void addEdge(int u, int v) {
        adj[u].push_back(v);
    }

    void init() {
        for (int u=0; u<n; u++)
            if (!num[u])
                dfs(u);
        dag.resize(comp.size());
        for (auto &c : comp)
            for (int u : c)
                for (int v : adj[u])
                    if (id[u] != id[v])
                        dag[id[u]].push_back(id[v]);
        for (auto &v : dag) {
            sort(v.begin(), v.end());
            v.erase(unique(v.begin(), v.end()), v.end());
        }
    }

    int dfs(int u) {
        int low = num[u] = ++ti;
        stk.push_back(u);
        for (int v : adj[u]) {
            if (!num[v])
                low = min(low, dfs(v));
            else if (id[v] == -1)
                low = min(low, num[v]);
        }
        if (low == num[u]) {
            comp.emplace_back();
            do {
                id[stk.back()] = (int) comp.size() - 1;
                comp.back().push_back(stk.back());
                stk.pop_back();
            } while (comp.back().back() != u);
        }
        return low;
    }
};
```

---

</details>

The way you use this template is quite straightforward: you declare an instance of `SCC` initialized with the number of nodes. You add each edge with the `addEdge()` method. When you're done adding edges, you call `init()`, and afterwards `comp` will be populated with the nodes partitioned based on strongly connected components, and `dag` will be an adjacency list for the condensation graph. Importantly, I don't have to remember how the SCC algorithm actually works. I can just paste it in my global scope, then use it as a black box for solving a problem.

More generally, packing templates into structs like this makes life easier if I have to use multiple templates. For instance, my source file for a implementation-heavy tree problem might look something like this:

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![image 1]({{ site.baseurl }}/assets/images/library-1.png)

</div>

Pretty clean if you ask me.

## How Generic Should Templates Be?

This is something that I've gone back and forth on. Should I have to modify the internals of my implementation, or should I be able to abstract away the details and use it like an external library? The philosophy I've gone by is to try to make it as generic as possible, without making it too clunky or unnatural. For example, the following is a template for sliding window minimum/maximum:

<details markdown="1" style="margin-bottom: 5%"><summary>Click Me!</summary>

```c++
// https://github.com/mzhang2021/cp-library/blob/master/implementations/data-structures/MinDeque.h
template<typename T>
struct MinDeque {
    int l = 0, r = 0;
    deque<pair<T, int>> dq;

    void push(T x) {
        while (!dq.empty() && x <= dq.back().first)
            dq.pop_back();
        dq.emplace_back(x, r++);
    }

    void pop() {
        assert(l < r);
        if (dq.front().second == l++)
            dq.pop_front();
    }

    T min() {
        assert(!dq.empty());
        return dq.front().first;
    }
};
```

---

</details>

This is an implementation that's easy to make generic. The following code will work for any data type with comparison defined. On the other hand, lazy segment tree is something that's notoriously difficult to make generic. Here's my variant of lazy segment tree:

<details markdown="1" style="margin-bottom: 5%"><summary>Click Me!</summary>

```c++
// https://github.com/mzhang2021/cp-library/blob/master/implementations/data-structures/SegmentTreeNodeLazy.h
struct SegmentTree {
    struct Node {
        int ans = 0, lazy = 0, l, r;

        void leaf(int val) {
            ans += val;
        }

        void pull(const Node &a, const Node &b) {
            ans = a.ans + b.ans;
        }

        void push(int val) {
            lazy += val;
        }

        void apply() {
            ans += (r - l + 1) * lazy;
            lazy = 0;
        }
    };

    int n;
    vector<int> a;
    vector<Node> st;

    SegmentTree(int _n) : n(_n), a(n), st(4*n) {
        build(1, 0, n-1);
    }

    SegmentTree(const vector<int> &_a) : n((int) _a.size()), a(_a), st(4*n) {
        build(1, 0, n-1);
    }

    void build(int p, int l, int r) {
        st[p].l = l;
        st[p].r = r;
        if (l == r) {
            st[p].leaf(a[l]);
            return;
        }
        int m = (l + r) / 2;
        build(2*p, l, m);
        build(2*p+1, m+1, r);
        st[p].pull(st[2*p], st[2*p+1]);
    }

    void push(int p) {
        if (st[p].lazy) {
            if (st[p].l != st[p].r) {
                st[2*p].push(st[p].lazy);
                st[2*p+1].push(st[p].lazy);
            }
            st[p].apply();
        }
    }

    Node query(int p, int i, int j) {
        push(p);
        if (st[p].l == i && st[p].r == j)
            return st[p];
        int m = (st[p].l + st[p].r) / 2;
        if (j <= m)
            return query(2*p, i, j);
        else if (i > m)
            return query(2*p+1, i, j);
        Node ret, ls = query(2*p, i, m), rs = query(2*p+1, m+1, j);
        ret.pull(ls, rs);
        return ret;
    }

    int query(int i, int j) {
        return query(1, i, j).ans;
    }

    void update(int p, int i, int j, int val) {
        if (st[p].l == i && st[p].r == j) {
            st[p].push(val);
            push(p);
            return;
        }
        push(p);
        int m = (st[p].l + st[p].r) / 2;
        if (j <= m) {
            update(2*p, i, j, val);
            push(2*p+1);
        } else if (i > m) {
            push(2*p);
            update(2*p+1, i, j, val);
        } else {
            update(2*p, i, m, val);
            update(2*p+1, m+1, j, val);
        }
        st[p].pull(st[2*p], st[2*p+1]);
    }

    void update(int i, int j, int val) {
        update(1, i, j, val);
    }
};
```

---

</details>

To use this for a general problem, I'd have to modify the `Node` class, the returned parameter of `query()`, and maybe the `push()` method if I modify the `lazy` parameter. So that's quite a bit of internals that I have to mess with, although I think I prefer this to fully generic attempts at lazy segment tree. For contrast, the Atcoder Library has a [fully generic variant](https://github.com/atcoder/ac-library/blob/master/atcoder/lazysegtree.hpp) of lazy segment tree, and it ends up being kind of clunky because you have to define a struct for the data and lazy values, and define functions for interactions between them. Ultimately, it's up to personal preference, and I just think it's easier to not bother trying to make a lazy segment tree fully generic.

## Does It Always Make Sense to Use Structs?

Consider something like combinatoric functions (factorial, choose function, etc.). Currently, I have the following template for it:

<details markdown="1" style="margin-bottom: 5%"><summary>Click Me!</summary>

```c++
// https://github.com/mzhang2021/cp-library/blob/master/implementations/math/Combo.h
#include "Modular.h"

using M = ModInt<998244353>;

const int MAX = 1e5 + 5;

M fact[MAX], inv[MAX];

M choose(int n, int k) {
    if (k < 0 || n < k) return 0;
    return fact[n] * inv[k] * inv[n-k];
}

void preprocess() {
    fact[0] = 1;
    for (int i=1; i<MAX; i++)
        fact[i] = fact[i-1] * i;
    inv[MAX-1] = inverse(fact[MAX-1]);
    for (int i=MAX-2; i>=0; i--)
        inv[i] = inv[i+1] * (i + 1);
}
```

---

</details>

In this case, it doesn't make much sense to wrap it in a struct, because these things values are usually precomputed once for the entire instance of execution, not once for each test case. And since it's not really a data structure, it would be strange to treat it as one by wrapping it around a struct. Right now, I just put this in the global scope, but this does violate my guidelines by creating global variables `fact` and `inv`. One alternative that I've considered, which I've seen others do, is use **namespaces**. While I could, I've decided namespaces aren't worth the effort, because in practice I'll do `using namespace template_name;` anyways, and then it'll effectively be global variables anyways. I guess it could provide an extra layer of organization, since I can minimize namespaces in my IDE, but that's not too big of a deal.

## Where to Test Templates?

In order of preference:

1. [Yosupo Library Checker](https://judge.yosupo.jp/) - This has a wide array of well-known problems, and test cases are added by community members, so you can be pretty confident in their strength and coverage.
2. [CSES](https://cses.fi/problemset/list/) - Similar to Yosupo Library Checker, has a lot of well-known problems and test cases are added by community members.
3. Problems from Various OJs (Codeforces, etc.) - Codeforces does have hacks, but there's no guarantee a contestant added such a hack back when the contest was live, and there have certainly been instances of Codeforces problems with weak test cases. Other online judges don't even support hacks. And it can be harder to find a problem that tests for a specific template.

## Is Building a Personal Library Worth It?

It's definitely not necessary. Plenty of people have gotten very far from copy pasting off KACTL. I just personally maintain a library because it's fun, and it's a tangible project I can point to and be proud of.

---

---
layout: post
title: "Historic Information on Segment Trees"
tags: [tutorial, algo]
usemathjax: true
---

It's been a while, but I'm back with some more estoric knowledge! Historic information is a concept I've only seen briefly mentioned in [this tutorial](https://codeforces.com/blog/entry/57319) on segment tree beats, and the section only covers one example of it, so I'll cover some more examples in this article.

## What is Historic Information?

Let's look at the following problem: You're given an array of $n$ integers $a_i$, and you have another array $b_i$ initially equal to $a_i$. You want to support the following operations.

1. For $l \leq i \leq r$, add $x$ to $a_i$ ($x$ may be negative).
2. Query for $\max_{i=l}^r a_i$.
3. Query for $\max_{i=l}^r b_i$.

After each operation, update $b_i$ to $\max(b_i, a_i)$ for all $1 \leq i \leq n$. $b_i$ is essentially the maximum $a_i$ over time, and is an example of historic information.

The first two operations are pretty standard lazy segment tree. We use a single lazy variable to store the sum of all updates applied to a node. What about the third operation? One option would be to add the lazy value to $b_i$ once you're pushing down at a node, but that isn't exactly right. Consider the following scenario:

1. You add $2$ to $a_i$.
2. You add $6$ to $a_i$.
3. You add $-15$ to $a_i$.

The total lazy value is adding $2 + 6 - 15 = -7$ to $a_i$, so $a_i \to a_i - 7$. But what about $b_i$? It's incorrect to say $b_i \to b_i - 7$, because actually $b_i \to b_i + 8$. This is because the value was changed three times: $b_i \to b_i + 2 \to b_i + 2 + 6 \to b_i + 2 + 6 - 15$. The maximum of all of those would be $b_i + 2 + 6 = b_i + 8$. And here lies the issue: just storing the sum of all updates as our lazy value is not sufficient to track the history of changes across multiple operations.

To remedy this, we introduce another lazy value, dubbed `hlazy` (short for "historic lazy"), which stores the maximum prefix of lazy updates applied. So say there were four updates applied to a node: $\\{+2, +3, -6, +9\\}$. Then `hlazy` would equal $\max(0, +2, +2 + 3, +2 + 3 - 6, +2 + 3 - 6 + 9) = 8$. When we push down node $u$ onto node $v$, we have `v.hlazy = max(v.hlazy, v.lazy + u.hlazy)`. And now, we update `b[i] = max(b[i], a[i] + hlazy)` which gives the correct new value of $b_i$.

<details markdown="1" style="margin-bottom: 5%"><summary>Code</summary>

```c++
// based on how I implement lazy segment tree
// https://github.com/mzhang2021/cp-library/blob/master/implementations/data-structures/SegmentTreeNodeLazy.h
struct Node {
    int maxA, maxB, lazy, hlazy, l, r;

    void leaf(int val) {
        maxA = maxB = val;
        lazy = hlazy = 0;
    }

    void pull(const Node &a, const Node &b) {
        maxA = max(a.maxA, b.maxA);
        maxB = max(a.maxB, b.maxB);
    }

    void push(const Node &other) {
        hlazy = max(hlazy, lazy + other.hlazy);
        lazy += other.lazy;
    }

    void apply() {
        maxB = max(maxB, maxA + hlazy);
        maxA += lazy;
        lazy = hlazy = 0;
    }
};
```

---

</details>

## A Harder Example

Now let's look at another problem: You're given an array of $n$ integers $a_i$, and you have another array $b_i$ initially equal to $a_i$. You want to support the following operations.

1. For $l \leq i \leq r$, add $x$ to $a_i$.
2. Query for $\sum_{i=l}^r a_i$.
3. Query for $\sum_{i=l}^r b_i$.

After each operation, add $a_i$ to $b_i$ for all $1 \leq i \leq n$. So this time our historic information is an accumulation of all $a_i$ over time.

Operation 3 is a bit trickier to deal with this time. To deal with it, we introduce a new concept: a timestamp. We number each of the operations as happening at times $1, 2, \dots, m$. For each node, we store a timestamp denoting the time of latest operation we've applied to this node (or $0$ if no operations have been applied to this node yet). Now, let's take a look at how $b_i$ changes as we apply updates to it. For sake of simplicity, say we're updating a leaf node. Let's say we apply $+x$ at time $t_x$, $+y$ at time $t_y$, and $+z$ at time $t_z$, where $t_x < t_y < t_z$. The initial timestamp before applying these updates is $t_i$.

- $b_i \to b_i + a_i \cdot (t_x - t_i) + (a_i + x) \cdot (t_y - t_x) + (a_i + x + y) \cdot (t_z - t_y)$
- $a_i \to a_i + x + y + z$
- $t_i \to t_z$

Let's simplify the update to $b_i$:

$$
b_i \to b_i + a_i \cdot (t_x - t_i) + (a_i + x) \cdot (t_y - t_x) + (a_i + x + y) \cdot (t_z - t_y) \\
= b_i + a_i \cdot t_x - a_i \cdot t_i + a_i \cdot t_y - a_i \cdot t_x + x \cdot (t_y - t_x) + a_i \cdot t_z - a_i \cdot t_y + (x + y) \cdot (t_z - t_y) \\
= b_i + a_i \cdot (t_z - t_i) + x \cdot (t_y - t_x) + (x + y) \cdot (t_z - t_y)
$$

Let's denote $x + y + z$ as `lazysum` and $x \cdot (t_y - t_x) + (x + y) \cdot (t_z - t_y)$ as another lazy value `cumsum` (short for "cummulative sum").

How does push down work? Say we have a node with updates $\\{+u, +v, +w\\}$ and we push down another node with updates $\\{+x, +y, +z\\}$. Then we get:

- Initial `cumsum`: $u \cdot (t_v - t_u) + (u + v) \cdot (t_w - t_v)$
- After push down:

$$
u \cdot (t_v - t_u) + (u + v) \cdot (t_w - t_v) + (u + v + w) \cdot (t_x - t_w) + (u + v + w + x) \cdot (t_y - t_x) + (u + v + w + x + y) \cdot (t_z - t_y) \\
= \text{cumsum} + (u + v + w) \cdot (t_x - t_w + t_y - t_x + t_z - t_y) + x \cdot (t_y - t_x) + (x + y) \cdot (t_z - t_y) \\
= \text{cumsum} + \text{lazysum} \cdot (t_z - t_w) + \text{other.cumsum}
$$

I will leave it as an exercise to figure out the update for a non-leaf node and how to merge two segment tree nodes. Once you've figured it out, you can check your answers with the code below:

<details markdown="1" style="margin-bottom: 5%"><summary>Code</summary>

```c++
// based on how I implement lazy segment tree
// https://github.com/mzhang2021/cp-library/blob/master/implementations/data-structures/SegmentTreeNodeLazy.h
struct Node {
    int sumA, sumB, timestamp, lazysum, cumsum, lazyTimestamp, l, r;
    bool lazy;

    void leaf(int val) {
        sumA = val;
        sumB = timestamp = lazysum = cumsum = lazyTimestamp = lazy = 0;
    }

    void pull(const Node &a, const Node &b) {
        sumA = a.sumA + b.sumA;
        timestamp = max(a.timestamp, b.timestamp);
        sumB = a.sumB + b.sumB + a.sumA * (timestamp - a.timestamp) + b.sumA * (timestamp - b.timestamp);
    }

    void push(const Node &other) {
        if (lazy) {
            cumsum += lazysum * (other.lazyTimestamp - lazyTimestamp) + other.cumsum;
            lazysum += other.lazysum;
        } else {
            cumsum = other.cumsum;
            lazysum = other.lazysum;
            lazy = true;
        }
        lazyTimestamp = other.lazyTimestamp;
    }

    void apply() {
        sumB += sumA * (lazyTimestamp - timestamp) + (r - l + 1) * cumsum;
        sumA += (r - l + 1) * lazysum;
        timestamp = lazyTimestamp;
        lazysum = cumsum = lazyTimestamp = lazy = 0;
    }
};
```

---

</details>

## Applications

Ok, when on earth would you ever need this? Aside from contrived problems designed to test this technique, I've found historic information most useful when doing some sort of "all pairs" problem via linesweep. Take [this problem](https://codeforces.com/gym/103069/problem/G) from the 2020 ICPC Asia East Continent Final for example.

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>

The algorithm I describe below is very similar to the offline algorithm for solving [SPOJ DQUERY](https://www.spoj.com/problems/DQUERY/), which you can see [here](https://codeforces.com/blog/entry/8962?#comment-146571). For sake of brevity, I will assume that you have read and understood that solution in the paragraphs below.

We will use an offline algorithm. As we sweep from left to right, we maintain an array $p$ where each index's value is 1 if a subarray starting at that index is valid, and 0 otherwise. So say $a = [3, 9, 4, 3, 2, 9, 9, 3, 2, 3, 2, 2, 2]$. Then $p = [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]$. Now say you process the next element in your linesweep. There are two cases:

1. You've never seen this element before. In our example, say the next element is a $6$, so $a = [3, 9, 4, 3, 2, 9, 9, 3, 2, 3, 2, 2, 2, 6]$. Then now $p = [1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1]$. Notice that we basically just did a range flip operation.
2. You've seen this element before. In our example, say the next element is a $9$, so $a = [3, 9, 4, 3, 2, 9, 9, 3, 2, 3, 2, 2, 2, 9]$. First, we delete the last occurrence of $9$ (we basically pretend it doesn't exist and set $p_i = p_{i+1}$ at that index). So $p = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]$. And now we add our new last occurrence of $9$ at the end, giving us $p = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1]$. So we've essentially done just two range flip operations.

If we make $p$ a segment tree, we can query for the number of valid subarrays for each right endpoint. But our original problem needs the number of valid subarrays with left endpoint $\geq l$ for each right endpoint for ALL right endpoints in $[l, r]$. So to remedy this, we instead query for the historic sum of $p_i$ for all $l \leq i \leq r$. So we need a segment tree that supports range flip and historic sum. I leave the details of what values to store in the segment tree node as an exercise for the reader, because I think being able to figure this out will serve as a good test of understanding. If you're stuck, you can refer to my implementation [here](https://ideone.com/aADK7p) (ideone link because Codeforces gym links aren't public).

---

</details>

## Problems

Here are some other problems where I've used historic information. I don't have many at the moment, so if you have any more feel free to let me know.

### [SPOJ GSS2: Can you answer these queries II](https://www.spoj.com/problems/GSS2/)

<details markdown="1" style="margin-bottom: 5%"><summary>Solution Sketch</summary>

Similar to the 2020 ICPC Asia East Continent Final problem explained above: linesweep, store only last occurrence, support range add and historic maximum. Explained in more detail [here]({{site.baseurl}}/gss/).

---

</details>

### [Codeforces Round 751, Div 1 C: Optimal Insertion](https://codeforces.com/contest/1601/problem/C)

<details markdown="1" style="margin-bottom: 5%"><summary>Solution Sketch</summary>

Compress the input to values in the range $1, 2, \dots, n + m$. It's optimal to sort $b$ and have them be in the same relative order in $c$ to minimize the number of inversions. Now for each $b_i$, we can insert them in at the beginning, at the end, or between any $(a_i, a_{i+1})$ pair. Let's sweep through each of $a_i$ from left to right, and update a segment tree maintaining the number of inversions each element would add if inserted in that gap. Finally, for each element in $b$, query for the historic minimum of $b_i$ in the segment tree. So we need to support range add and historic minimum.

[Submission for Reference](https://codeforces.com/contest/1601/submission/133199732)

---

</details>

### [UOJ 164](https://uoj.ac/problem/164)

Translation: Support the following operations:

1. For $l \leq i \leq r$, add $x$ to $a_i$.
2. For $l \leq i \leq r$, set $a_i$ to $\max(a_i - x, 0)$.
3. For $l \leq i \leq r$, set $a_i$ to $x$.
4. Query for $a_y$.
5. Query for $b_y$.

<details markdown="1" style="margin-bottom: 5%"><summary>Solution Sketch</summary>

This is the example problem for historic information described [here](https://codeforces.com/blog/entry/57319). The blog also contains the solution.

[Submission for Reference](https://uoj.ac/submission/519426)

---

</details>

### [XXII Open Cup, Grand Prix of Nanjing, Problem E: Paimon Segment Tree](https://codeforces.com/gym/103470/problem/E)

<details markdown="1" style="margin-bottom: 5%"><summary>Solution Sketch</summary>

It literally says "historical values" in the problem statement 🤔. Maintaining the historical squared sum is just adding some extra values on top of maintaining the historical sum, so I'll let you work out the details. If you're stuck, you can refer to my code [here](https://ideone.com/2zIHRs).

P.S. Don't actually use persistent segment trees as the problem suggests, just split the query into $\text{query}(1, r) - \text{query}(1, l - 1)$.

---

</details>

---

And that's a wrap! Thanks for reading!

My next article idea (which will probably be published in a month from now) is to make a tier list of online judges. But this isn't gonna be just a baby tier list. I've made an insane number of accounts on different online judges, so this list will be as comprehensive as possible. Currently, I have the following list, and if you have any others to add, let me know. The only requirement is that the online judge must be in English.

<details markdown="1" style="margin-bottom: 5%"><summary>The List</summary>

- [Codeforces](https://codeforces.com/)
- [Atcoder](https://atcoder.jp/)
- [Codechef](https://www.codechef.com/)
- [SPOJ](https://www.spoj.com/)
- [UVa](https://onlinejudge.org/)
- [ICPC Live Archive](https://icpcarchive.ecs.baylor.edu/)
- [USACO](http://www.usaco.org/)
- [USACO Training](https://train.usaco.org/)
- [HackerRank](https://www.hackerrank.com/)
- [HackerEarth](https://www.hackerearth.com/)
- [LeetCode](https://leetcode.com/)
- [binarysearch](https://binarysearch.com/)
- [DMOJ](https://dmoj.ca/)
- [Aizu Online Judge](https://judge.u-aizu.ac.jp/onlinejudge/index.jsp)
- [PKU Online Judge](http://poj.org/)
- [Timus](https://acm.timus.ru/)
- [LightOJ](https://lightoj.com/)
- [oj.uz](https://oj.uz/)
- [CSA Academy](https://csacademy.com/)
- [Kattis](https://open.kattis.com/)
- [CodeDrills](https://codedrills.io/)

I decided not to add sites like [CSES](https://cses.fi/problemset/list/) or [Yosupo Judge](https://judge.yosupo.jp/) because they serve a different purpose than traditional online judges (e.g. CSES is a database of classical problems). I also might exclude interview prep sites like [LeetCode](https://leetcode.com/) since they also serve a different purpose, though I'm not sure at the moment.

---

</details>

---
layout: post
title: "A Competitive Winter Break"
tags: [personal]
usemathjax: true
---

Happy new year! It's been a minute since I last posted, but here's my first post of 2022. I was trying to go for a title similar to [Petr's blog posts](https://petr-mitrichev.blogspot.com/) with the adjective + "week" format, but it doesn't really sound that good now that I've typed it out.

Firstly, I must apologize that the tier list I mentioned at the end of the [last post]({{site.baseurl}}/historic-segtree/) is not ready yet. I originally planned on working on that over winter break, but ended up putting it off and falling back on unproductive habits instead.

For the time being, I figured I'd write an update post about CP competitions I did over winter break, because I had some more time to participate in several of them.

## Rated Codeforces

Ever since I first hit red in September, I've taken a hiatus from competing in rated contests. But I have to say, playing out of competition just didn't hit the same. Aside from it out of competition contests being div 2 instead of div 1, competing unrated just feels more low stake and not as fun, so it was refreshing to compete in rated contests again over break.

I did three rated contests over break. The first was Global Round 18, where I paid an unexpected visit to master rating again 😬.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 1]({{site.baseurl}}/assets/images/winter-break-1.png)

</div>

My contest experience consisted of a lot of hopping around between problems and just not seeing simple observations (when I say simple, I mean that based on my average performances, I would typically be able to find observations of this difficulty). I'll include a retelling of my contest performance in a spoiler below:

<details markdown="1" style="margin-bottom: 5%"><summary>The Story</summary>

Problem A and B were quick solves. I got the right ideas and submitted them relatively quickly. Next is problem C. On first read, I misunderstood the problem as only flipping adjacent candles instead of all other candles, because problem C reminded me of a different problem I saw before involving flipping adjacent candles. After working through the samples and realizing I misunderstood the problem, I switch to thinking about flipping all candles. I play with the samples and other small cases for a while, but no obvious pattern emerges. A significant amount of time passes without me solving it, and I decide I need to skip C for now to salvage my performance.

I open problem D. I get the observation about the parity of the bit count also being xor'ed pretty quickly, which means I only need to assign the unassigned edges 0 or 1. But I'm stuck on how to recover the answer. Again, I think about different ways of assigning, including some weird greedies, but nothing concrete comes to mind.

At this point, my morale and self-confidence aren't exactly high, because I've just bricked on two early problems and am on track to getting specialist performance if another problem doesn't get solved soon. I could move onto E, but the solve counts weren't giving me any confidence that E was any easier than C or D. I also did a quick sweep through the entire problem set to see if there was some data structure problem I could knock out instead, but there didn't appear to be any (yes, I later found out that problem G was general matching and problem H was a well-known flow problem, but I'm not too familiar with flows and matchings).

So I return to problem C. I finally come up with the following idea: if I form pairs between the characters at the same indices in the two strings, then only the count of 00, 01, 10, and 11 pairs matter and not the exact positions they're at. So if I compress the string into a 2x2 frequency table, maybe I could do BFS on this state graph. But the number of states appeared huge, so I made another observation that would turn out to be wrong: I thought maybe we could cap the frequency table values at just 2 or 3 to reduce the number of states, because all of the pairs except for the one you're operating on will flip. However, a wrong answer on pretest 2 disproved that claim. I code up a generator for a stress test because there's not much else I can do, and I find that even when I increase the cap to 5 or 10, the solution is still wrong. However, I notice something strange as I increase the bounds: the naive BFS with no cap still runs fast even for $n = 10^5$. With no better options left, I submit the naive BFS, and to my surprise it passes pretests! At this stage, I was certain there might be some countertest that could fail my solution, and I was just hoping problemsetters would miss that case in the systests. I later found out that such a countertest doesn't exist, because you can [prove](https://codeforces.com/blog/entry/98253?#comment-870707) the BFS solution runs in $\mathcal O(n)$.

Finally, I return to problem D. After more thinking and still no concrete ideas on how to recover the answer, I attempt to cheese the problem with [hill climbing](https://en.wikipedia.org/wiki/Hill_climbing). Unfortunately for me, the performance of hill climbing on this problem is really bad, to the point where it doesn't even consistently get the samples right. I also read E in the middle of doing this, but at this point I have little motivation left to think properly about yet another greedy problem that I'll likely miss the key insight for. And so the contest ends, and I'm left with the largest rating drop I've ever received.

---

</details>

If I were to reflect on my performance, I'd say my biggest mistake was **getting tilted.** I actually thought I'd gotten over that since my div 2 days, as I've gotten good at skipping problems. For example, I've had two performances ([ex. 1](https://codeforces.com/contest/1503/standings/participant/111989857#p111989857) and [ex. 2](https://codeforces.com/contest/1552/standings/participant/117714327#p117714327)) in the past that could have been much worse but were somewhat salvaged by me skipping a problem I was bricking on. But bricking on not one, but two problems in a row was just too frustrating, and once I got annoyed it only went downhill from there.

Next was Goodbye 2021, which definitely went much better than Global Round 18.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 2]({{site.baseurl}}/assets/images/winter-break-2.png)

</div>

No funny business happened this time. I got the right observations on the early problems and rolled through them quickly enough to get IGM performance despite not solving any of the GM+ difficulty problems. I did get one wrong submission due to integer overflow on problem E, which cost me roughly 20 places. Just speedforces things 😩.

To explain the -10 penalty on problem F, that was because I tried to cheese the problem with hill climbing again after not being able to think of a proper solution. It looked more promising than problem D from last round as the bounds were much smaller and I got to pretest 7, but I could not get it to work before the contest ended. As a side note, I'm annoyed I didn't get the intended solution because the intended solution only had one observation: the "all colors pairwise different or equal" condition was equivalent to the colors summing to 0 mod 3. After that, you just turn each triangle in the graph into an equation and plug into Gaussian elimination. I also learned my Gaussian elimination library code was objectively worse than everyone else's as [my practice submission](https://codeforces.com/contest/1616/submission/141131180) got uphacked.

The last Codeforces contest I did was Hello 2022.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 3]({{site.baseurl}}/assets/images/winter-break-3.png)

</div>

Despite getting back to GM, this was an extremely frustrating performance for me because of one reason: **my submission to problem G was one typo away from AC.**

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 4]({{site.baseurl}}/assets/images/winter-break-4.png)

*Ahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh!!!*

</div>

To clarify what happened: I made my first submission to G at 2 hours and 5 minutes. I'm greeted with a wrong answer on pretest 2. At this point, there are less than 10 minutes left in the contest, and I panicked because there's like no time left to debug. I quickly rethink through my idea again and comb through my code, and I see no issues. At this point, I decide to stress test, which in hindsight was a fatal mistake. Stress testing takes too long. I would have to write a generator and a naive solution, and after finding the countercase I would have to add debug statements to my code and pinpoint where the countercase is tripping me up. Indeed, by the time I find the countercase via stress testing, there's like 1 minute left and I'm unable to debug in time. What I should have done is just try to find the bug by inspection. Meticulously read each line and try to spot the bug, because that was the only chance I'd be able to debug in time.

This mistake was frustrating because I missed out on what could have been one of my best performances, and I missed out on solving a 3000+ rated problem in contest for the first time. I realize these are completely arbitrary milestones I've set for myself, but it still feels bad. I attribute this mistake to making a poor decision under pressure. I think going for G instead of F was the right call, because I heard F was a tedious casework greedy while G was much cleaner, and my mistake was trying to stress test in under 10 minutes.

Also, I don't have much right to complain about this performance anyways, because I still went positive and it definitely could have gone much worse. For instance, I was lucky I got the hit-or-miss observation on D quickly, and on a different day it could have easily been another Global Round 18 situation.

## Advent of Code

Advent of Code was running last month, and I was curious why so many [good CP'ers](https://adventofcode.com/2021/leaderboard) were doing it. So I decided to give it a try. After following along for a few days, I concluded that I simply wasn't the intended audience for these problems. From a CP standpoint, there were no interesting problems; almost every problem was solved with some form of brute force or "translate the problem statement to code." I guess day 8's second star was a nice ad hoc task where you had to deduce the digits from the set of segments turned on. But for the most part, the problem statements were overly wordy and complex, and half the challenge was understanding what the freaking problem was.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 5]({{site.baseurl}}/assets/images/winter-break-5.png)

*I'm sorry, but after seeing day 19 was yet another brute force problem, I couldn't do these anymore.*

</div>

And just to make sure I wasn't missing out on elegant solutions, I checked the AoC [subreddit](https://www.reddit.com/r/adventofcode/), where I found out the average software developer loves brute force and finds it highly stimulating and engaging. Take day 16 for example, where the entire challenge was parsing the infinitely long problem statement and translating the procedure to code. Apparently that was one of the subreddit's [favorite](https://www.reddit.com/r/adventofcode/comments/rhot41/2021_day_16_just_a_thank_you_to_the_aoc_creator/) [problems](https://www.reddit.com/r/adventofcode/comments/rhsq96/2021_day_16_that_was_surprisingly_a_lot_of_fun/). To be clear, I'm not saying these people's opinions are wrong. I'm just amused at the difference in opinion. If you enjoyed the AoC tasks, more power to you, because having fun is the most important part of any programming competition.

From watching [Neal's](https://www.youtube.com/c/nealwuprogramming/videos) AoC videos, I'm guessing the fun part for top CP'ers is speedforcing these problems. But personally, these problems aren't even fun to speedforce, because they're so overly tedious and verbose with almost no slick observations needed, making it quite literally a reading comprehension and typing contest. I guess the one cool thing coming out of this was that I got slightly more proficient at Python. I decided since the format of this contest was "submit output only," I would use Python and try to write as clean code as possible. I must say, some tasks like day 18 are *much* easier to handle with Python due to their input format, and I felt badass whenever I successfully used list comprehension to write one liners in certain probelms. All in all, the concept of Advent of Code is neat, but the problems just aren't my type, and that's perfectly ok.

## A Practice Story

Since this post is already getting overly long and rambly, I'll wrap it up soon and conclude with a short story about a problem I recently solved in practice. I found the process of solving this problem amusing because it ended up being a lesson in debugging and hashing out the details.

<details markdown="1" style="margin-bottom: 5%"><summary>The Story</summary>

So I was solving [this Codeforces problem](https://codeforces.com/contest/843/problem/E) that I pulled from this [hard problem list](https://codeforces.com/blog/entry/98630). The problem didn't seem too bad on first read, and I got most of the details for the solution right off the bat.

1. Putting non-zero flow through each edge with $g_i = 1$ can be done by finding any arbitrary path of $g_i = 1$ edges from the source to the sink going through that edge and adding 1 to the flow of each edge on the path.
2. To minimize the number of saturated edges, it suffices to only saturate edges in the minimum cut. This ensures any path from the source to the sink contains at least one saturated edge and thus no more flow can be pushed. To avoid including $g_i = 0$ edges in the minimum cut, my first idea was to just remove them from the network, which is incorrect.

I code up this idea, submit it, and am greeted with a wrong answer on test 3. I realize that my initial idea of excluding $g_i = 0$ edges from the network was wrong, because then it's possible that there exists a path of mostly $g_i = 0$ edges and one unsaturated $g_i = 1$ edge from the source to the sink. Luckily, this issue is quickly remedied by adding the $g_i = 0$ edges to the flow network with capacity $\infty$ so that they won't be included in the minimum cut.

However, after fixing what I thought was the bug, I still got wrong answer on test 3. Now I'm slightly confused. After rehashing through my idea and looking at all the details, I can't see anything wrong with the idea. I figured it must be a bug with my DFS. I try reimplementing the same procedure with different variations and make multiple submissions, all succumbing to the same wrong answer on test 3. And after almost an hour, I finally cave and begrudging turn to external resources. I decided since I felt so close to the AC idea, I didn't want to look at the editorial yet and just wanted a hint, so I scrolled through the comment section of the announcements blog. And I found my answer in [this thread](https://codeforces.com/blog/entry/54008?#comment-380734).

Ah, the devil is in the details! The nuance I was missing was that I didn't properly consider reverse edges. I'd forgotten that part of what makes the flow algorithm work is that augmenting paths can travel through reverse edges and "cancel" out flow. If I include a $g_i = 1$ edge going backwards from the $T$-side to $S$-side, it's possible for me to still have an augmenting path by going through a bunch of unsaturated edges from the source, going through that backwards $g_i = 1$ edge in **reverse** and cancelling out the flow already in it, and then going through more unsaturated edges to reach the sink. Luckily, the fix for this is simple: for each $g_i = 1$ edge, set the reverse capacity to $\infty$ so that the edge is never included backwards in the minimum cut.

Now here's the kicker: my solution is still wrong! And still on wrong answer on test 3! I continue to make more tweaks and trying alternative ways of implementing the same thing. For example, I tried accounting for $g_i = 1$ edges in cycles by sending a unit of flow through the cycle it's contained in instead of through a path from source to sink. All submissions succumb to the same wrong answer. And then, it hits me. My clown ass was finding the minimum cut wrong! In my DFS method for finding the minimum cut, I wasn't considering reverse edges in the flow network. Heck, I wasn't even considering $g_i = 0$ edges in my DFS because it was the same DFS method that I never changed since my first submission! This is so spectacularly wrong that it's a miracle my solution even passed test 2. I fix my DFS method and finally claim my AC.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 6]({{site.baseurl}}/assets/images/winter-break-6.png)

*My submission history after this fiasco...*

</div>

Where was I going with this story? I'm not sure. I just felt like writing about it. I guess my biggest takeaways are:

1. Fully understand the nuances of the algorithm you're tweaking. I usually black box maximum flow, so this was a cool problem that had me better understand how flow worked.
2. When debugging, actually debug. Look at all parts of the code, even parts you're sure are right.

</details>

---

I'm not sure what the future of this blog will be. It'll probably be a while until I write another long tutorial because those take time. Maybe I'll get around to finishing that tier list. In any case, thanks for reading!

---
layout: post
title: "A Shift in Perspective"
tags: [tutorial]
usemathjax: true
---

I've seen numerous problems recently where the solution comes from a shift in perspective, and I've found them amusing enough to write a whole blog around this topic. I wouldn't consider this a technique but rather just an explanation of visual intuition for problem solving.

## [Codeforces Round 767, Div 1 D2: Game on Sum (Hard Version)](https://codeforces.com/contest/1628/problem/D2)

Firstly, I will assume familiarity with the $\mathcal O(nm)$ DP solution that solves the Easy Version, which you can read about in the [official editorial](https://codeforces.com/blog/entry/99276).

Let $dp[i][j]$ be the answer when there are $i$ turns left and Bob has to choose $j$ more add operations. The transitions are as follows:

$$
\begin{align*}
j = 0 &\implies dp[i][j] = 0 \\
j = i &\implies dp[i][j] = i \cdot k \\
0 < j < i &\implies dp[i][j] = \frac{dp[i-1][j-1] + dp[i-1][j]}{2}
\end{align*}
$$

<details markdown="1" style="margin-bottom: 5%"><summary>Intuition for the DP</summary>

It would be ironic for a blog post about intuition to not explain the intuition for this recurrence. The editorial already covers the intuition pretty well, but I'll include it here for sake of completeness.

Let's knock out the straightforward cases first. If $j = 0$, the answer is $0$ because Bob can just subtract every time, so it would be suboptimal for Alice to pick any positive number. If $j = i$, the answer is $i \cdot k$ because Bob is forced to add for all of his remaining operations, so Alice can cash in a maximum of $+k$ on each operation.

Now let's consider another small case like $i = 2, j = 1$. Say Alice picks $x$. If Bob subtracted $x$ now, he would have no subtract operations left and Alice would cash in $+k$ in the final operation, so the resulting score would be $k - x$. If Bob added $x$ now, he would be able to subtract on his final operation and Alice would optimally state $0$ as her final number, so the resulting score would be $x$. Since Bob wants to minimize the score, he would pick the choice resulting in $\min(x, k - x)$. Now Alice wants to pick the $x$ that maximizes this minimum. The function is maximized when $x = k - x$, or $x = \frac{k}{2}$, and the final score would be $\frac{k}{2}$.

There's no reason we can't extend this logic to the general case. Say we're at any arbitrary state of the game $(i, j)$. If Alice selects $x$, Bob makes the choice that attains $\min(dp[i-1][j] - x, dp[i-1][j-1] + x)$<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>. For Alice to maximize this minimum, she selects the $x$ such that $dp[i-1][j] - x = dp[i-1][j-1] + x$, or $x = \frac{dp[i-1][j] - dp[i-1][j-1]}{2}$. The final score would be $\frac{dp[i-1][j-1] + dp[i-1][j]}{2}$. You can prove that this is always a valid move (i.e. $0 \leq \frac{dp[i-1][j] - dp[i-1][j-1]}{2} \leq k$) with some induction and algebra (written out in detail in this [comment](https://codeforces.com/blog/entry/99276?#comment-880412)).

---

<div class="footnotes">
<ol>
<li id="fn:1">
I always find DP solutions for game theory problems humorous because it's funny to imagine Alice and Bob mentally computing DP tables in their head while playing a game with each other.
<a href="#fnref:1" class="reversefootnote">&#8617;</a>
</li>
</ol>
</div>

---

</details>

Ok, now we must solve the hard version with constraints $m \leq n \leq 10^6$. To me, it isn't immediately obvious how to optimize this DP to linear time just by staring at the formulas. So as the title suggests, it's time for a shift in perspective!

Let's draw out the DP table, because visualizing stuff is great.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 1]({{site.baseurl}}/assets/images/perspective-1.png)

*You know, I'm something of an artist myself.*

</div>

Yes, I realize I have $i$ as the columns and $j$ as the rows in this diagram, but just roll with it. Each cell $(i, j)$ contains the value of $dp[i][j]$. So for cells of the form $(i, 0)$, their values are $0$. For cells of the form $(i, i)$, their values are $i \cdot k$. And for the remaining cells, I've drawn two green arrows representing the transitions from $(i, j)$ to $(i - 1, j)$ and $(i - 1, j - 1)$. Now here's the cool part: since this looks like a grid, let's think about grid paths. Say we initially start at cell $(n, m)$. We have a $\frac{1}{2}$ probability of moving to the cell on the left or diagonally up and left. If we ever reach a cell of the form $(i, i)$, we gain value $i \cdot k$ and stop moving. Now this problem becomes calculating the expected value of any path we take starting from $(n, m)$. Pretty neat!

This new interpretation is much easier to come up with an $\mathcal O(n)$ solution to. We precompute factorials and powers of $2$, and we iterate over each of the ending cells. If we end at $(i, i)$, we will take $n - i$ steps and move up exactly $m - i$ times. There are $\binom{n - i}{m - i}$ such paths, and we multiply by $\left(\frac{1}{2}\right)^{n - i}$ for the probability of making the right decision at each step. But this isn't exactly correct, because we have to exclude the paths that go through cell $(i + 1, i + 1)$. So we subtract $\binom{n - i - 1}{m - i - 1}$ from our number of paths. The final answer is thus

$$
\sum_{i=0}^m \left(\binom{n - i}{m - i} - \binom{n - i - 1}{m - i - 1}\right) \cdot \left(\frac{1}{2}\right)^{n - i} \cdot i \cdot k \\
= \sum_{i=0}^m \binom{n - i - 1}{m - i} \cdot \left(\frac{1}{2}\right)^{n - i} \cdot i \cdot k
$$

In summary, we've optimized a DP solution by looking at it under a combinatorics lens!

## [Kotlin Heroes Episode 8 G: A Battle Against a Dragon](https://codeforces.com/contest/1571/problem/G)

I already wrote about this problem [4 months ago]({{site.baseurl}}/reflection/#kotlin-heroes), but I'm mentioning it again as another example of a shift in perspective. The naive $\mathcal O(nm)$ DP approach is $dp[i][j] = \max(dp[i-1][j] + a[i][j], dp[i-1][j+1])$, where $dp[i][j]$ is the maximum damage done by the first $i$ warriors with $j$ barricades left and $a[i][j]$ is the amount of damage the $i$th warrior can do if there are exactly $j$ barricades. Again, optimizing this DP is best understood if you draw out the DP states on a grid, because then you'll notice that the transitions can be expressed as 2D triangle queries and the problem becomes a data structures exercise. You can read more details in my [older post]({{site.baseurl}}/reflection/#kotlin-heroes) about this problem.

<details markdown="1" style="margin-bottom: 5%"><summary>Data Structures Note</summary>

I realized I never explained how to actually solve the "data structures exercise" at hand in my older post. So I'll briefly explain it here. Treat the inputs as 2D points $(i, b_{ij})$ and sort them based on the diagonal $i + b_{ij}$ they lie on. Now perform a linesweep from smaller to larger diagonals and for each point, perform the following steps:

1. Calculate its DP value by querying in a segment tree on the range $[b_{ij}, m]$.
2. Insert the point into the segment tree at index $b_{ij}$.

By considering points in diagonal order, only points below the diagonal of the current point we're considering will have already been inserted into the data structure, giving us the desired triangle query.

[Submission for Reference](https://codeforces.com/contest/1571/submission/131573499)

---

</details>

## [2019-2020 ICPC Southern and Volga Russian Regional Contest D: Conference Problem](https://codeforces.com/contest/1250/problem/D)

Bounds are small which usually signify a DP solution is worth thinking about. However, the intervals are kind of annoying and don't easily lend themselves to a recurrence in my opinion. We will eventually arrive at a recurrence that can be explained using the intervals, but here's another way of arriving at it with a shift in perspective:

Let's turn to the 2D plane (Noticing a theme here? I get all of my intuition from drawing stuff as geometric points or grids). Express an interval $[l, r]$ as a 2D point $(l, r)$. Another interval $[l', r']$ intersects $[l, r]$ if $l' \leq r$ and $r' \geq l$. In other words, the point $(l', r')$ lies to the upper left of the point $(r, l)$.

Now, let's treat the countries as colors. So we can reformulate this problem as the following:

*You are given $2n$ 2D points, some already colored. The points come in pairs of $(l, r)$ and $(r, l)$. We will refer to the $(l, r)$ points as "regular points" and $(r, l)$ points as "query points." Points in the same pair must be the same color. Denote a query point as "bad" if it contains no different colored regular points to its upper left. Assign colors in the range $1 \dots 200$ to the uncolored points to maximize the number of bad points.*

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 2]({{site.baseurl}}/assets/images/perspective-2.png)

*In this diagram, I've labeled the regular and query points with R and Q respectively. I used different colors to distinguish points with different c values. In this example, only the green point is bad, so our answer is 1.*

</div>

Finally, here's the observation that leads to our DP: Peform a linesweep to process the points from left to right. We only care about the y-coordinate of the highest two previously processed regular points of different colors. If we have a regular point with $c = 1$ at $y = 10$ and a regular point with $c = 2$ at $y = 9$, we couldn't care less if there's a regular point with $c = 3$ and $y = 7$, because any query point containing that third point in its upper left will also contain the first two points and thus already be guaranteed to have a point of different color in its upper left. Armed with that knowledge, we can formulate an $\mathcal O(n^3 C^2)$ solution: let $dp[i][j][k][l][m]$ be the maximum number of bad points if we've processed the first $i$ points, our highest regular point is at coordinate $j$ with color $k$, and our second highest regular point with a different color than the first is at coordinate $l$ with color $m$. Note that we've compressed our coordinates down to just $\mathcal O(n)$ distinct values instead of $10^6$.

We can do better. Storing the highest point is unnecessary, because we know that if our query point y-coordinate is below the y-coordinate of the second highest point of a different color, then we cover at least two distinct colors, and otherwise we only cover one color. So we can knock off two dimensions from our DP and get $\mathcal O(n^2 C)$ which fits under the constraints of this problem. One more note: we will instead store the lowest y-coordinate $j$ such that all regular points above $j$ are color $k$. In other words, we will store the lowest point of the highest color instead of the highest point of the second highest color. This is so we can determine if a query point is bad or not if its y-coordinate is greater than or equal to $j$.

To summarize, our $\mathcal O(n^2 C)$ DP is as follows: $dp[i][j][k]$ is the maximum number of bad points if we've processed the first $i$ points and all points with y-coordinate greater than or equal to $j$ are color $k$.

The transitions aren't exactly straightforward, but they're also not too hard and can be worked out with enough conviction and casework. I'll leave the transitions as an exercise to the reader 🙂.

<details markdown="1" style="margin-bottom: 5%"><summary>Boooo!</summary>

Ok fine. I really don't feel like typing out the transitions because it's just casework about if point $i$ is above or below $j$ and if it matches or doesn't match color $k$. I'll link a [submission for reference](https://ideone.com/lxZxoa) and if you're still confused you can leave a comment below. In my code I used a binary indexed tree for convenience, but it's unnecessary because bounds are small enough that you can do everything with for loops.

---

</details>

## Finale: Optimizing Bitmask DP with Graph Interpretation

I don't have an official problem link for this problem, but it's problem 6 on [this blog](https://codeforces.com/blog/entry/99649). I usually don't pay attention to blog posts about coding interview problems, but I read problem 6 and felt solving it for $n \leq 20$ was kind of non-trivial. Maybe I'm wrong and the solution is standard for others.

The problem is as follows:

*You're given two arrays $a$ and $b$, both of size $n$. In one operation, you can choose an integer $x$ and two indices $i$ and $j$, then add $x$ to $a_i$ and subtract $x$ from $a_j$. Find the minimum number of operations to transform array $a$ into $b$, or print $-1$ if it's not possible.*

**Constraints:** $n \leq 20, -10^9 \leq a_i, b_i \leq 10^9$

(The constraints on $a_i$ might be smaller, but I can't read the image in the blog post very clearly and the complexity won't depend on $a_i$ anyways.)

If the sum of $a_i$ and the sum of $b_i$ are not equal, then the answer is obviously $-1$ because the sum of $a_i$ remains constant after each operation. Otherwise, it's always possible. Select some index $i$, add $b_i - a_i$ to $a_i$ and subtract $b_i - a_i$ from some other arbitrary $a_j$, then delete $a_i$ and $b_i$ from their respective arrays and solve the problem recursively. This procedure also provides an upper bound of $n - 1$ on the number of operations we perform.

To reduce the number of operations, we can partition the set of indices $U = \\{1, 2, \dots, n\\}$ into disjoint subsets, where for each subset $S$ is **good**. We define a subset $S$ to be good if $\sum_{i \in S} a_i = \sum_{i \in S} b_i$. Now we can fix the entire array just by performing our above procedure on each individual subset of indices. A subset $S$ can be fixed in $\|S\| - 1$ operations using the above procedure. So the answer is just $n - k$ where $k$ is the maximum number of disjoint subsets we can partition into.

This problem can be solved with a standard $\mathcal O(3^n)$ bitmask DP: let $dp[S]$ denote the maximum number of disjoint good subsets $S$ can be partitioned into. Iterate over all submasks and transition from that submask. Specifically:

$$
dp[S] = \max_{S' \subset S, S' \text{ is good}} (dp[S \setminus S'] + 1)
$$

The answer is $n - dp[U]$. But $\mathcal O(3^n)$ is too slow for $n \leq 20$. Can we do better?

<div class="spoiler" style="margin-bottom: 5%">Of course we can, that's why I'm writing about this problem.</div>

Here's the key observation: if $S$ is good, and $S' \subset S$ is good, then $S \setminus S'$ is also good. So instead of finding a partition of $U$ into disjoint subsets, let's find a sequence of good subsets $S_1, S_2, \dots, S_k$ such that $S_1 \subset S_2 \subset \dots \subset S_k \subset U$. Now just take set differences between adjacent subsets in the sequence and we have our partition of disjoint good subsets!

It's more clear how to optimize finding a maximum length sequence $S_1 \subset S_2 \subset \dots \subset S_k \subset U$. Let's take a shift in perspective! Let's treat all the good subsets as nodes in a graph, and draw an edge from $S$ to $T$ if $S \subset T$. We want to find a maximum length path from $\emptyset$ to $U$. However, this graph still could have up to $\mathcal O(3^n)$ edges. Instead, let's also add in the non-good subsets as nodes so that now every subset of $U$ is a node and there are $2^n$ nodes. And instead of adding edges for all subset relations, just add an edge from a subset to every other subset with exactly one new bit turned on (i.e. we draw an edge from $S$ to $T$ if $S \subset T$ and $\|T \setminus S\| = 1$). This way, all subset relations are represented indirectly as nodes being reachable in this graph. Each node only has at most $n$ outgoing edges for each of its bits, so there are $\mathcal O(n \cdot 2^n)$ edges in this graph. And we can find the path with the maximum number of good nodes on it with DP, since it's a directed acyclic graph. So we've successfully solved the problem in just $\mathcal O(n \cdot 2^n)$!

---

This blog post could go on forever because there are an infinite number of problems that benefit from shifting perspectives. In fact, sometimes problemsetters even start with a clear perspective, but then intentionally present you with a different perspective to hide the solution (e.g. the trick of this [AtCoder problem](https://atcoder.jp/contests/agc040/tasks/agc040_c) is to flip A and B in the odd positions, which makes the operations much clearer). These perspective shifts aren't meant to be black magic; I'm a huge proponent of visuals, and I typically find intuition just by drawing stuff. For example, if I'm doing a problem about arrays and intervals, you might see this on my paper:

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 3]({{site.baseurl}}/assets/images/perspective-3.png)

*I can't believe I'm providing such high quality diagrams for free* 🙄

</div>

Thanks for reading. If you have any other cool problems, feel free to share!

---
layout: post
title: "My First Ever ICPC Regionals Experience!"
tags: [personal]
usemathjax: true
---

This past weekend, I attended my first ever ICPC regionals! It was an incredibly fun and enlightening experience for me, so I'd like to share with you some takeaways I had.

First, let me provide a bit of background, since I think I've only referred to myself by handle on my blog so far. My name is Max, and I'm a first year CS major at Georgia Tech. My teammates for this regional were [Arvind](https://codeforces.com/profile/arvindr9) and [Jeffrey](https://codeforces.com/profile/RandomKami). We were team "Acceptable" at the [2021 Southeast US Regional](https://seusa21-d1.kattis.com/standings).

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 1]({{site.baseurl}}/assets/images/first-ever-regionals-1.png)

*We ranked 3rd overall, or 2nd after removing duplicate schools, which qualifies us for the NAC.*

</div>

In the following spoiler, I've put a play-by-play of how our contest went by the hour, reconstructed with help of our submission history, scoreboard, and my personal memory. The exact times might be slightly off because it was extremely hectic to keep track of all these things during the actual contest. This play-by-play is also only from my perspective; I might not mention what my teammates were working on at a given time because I wasn't paying attention to what they're doing.

<details markdown="1" style="margin-bottom: 5%"><summary>Play-by-play</summary>

So as you can see on the scoreboard, the two teams that beat us were both from UCF. Going into this contest, our coach [chenjb](https://codeforces.com/profile/chenjb) had already warned us that UCF would be the major threat in this competition and they were extremely good at speedforces, so we knew we had our work cut out for us.

The contest begins. Arvind and Jeffrey start flipping through the problems while I type out our template and set up an alias command for compiling with warning flags. Our first impression of the problemset was that it didn't look hard enough to not be speedforces, so we knew we needed a strong pace to have a chance of winning.

About 5 or so minutes in, Jeffrey tells me [problem F](https://seusa21-d1.kattis.com/problems/na21.hopscotch500) looks like an easy DP. I quickly skim problem F and confirm that it indeed looks like an easy DP. I code the most naive shit possible and submit it at 8 minutes in:

```c++
for (int i=0; i<k-1; i++)
    for (auto [x, y] : spots[i])
        for (auto [a, b] : spots[i+1])
            dp[a][b] = min(dp[a][b], dp[x][y] + min((x - a) * (x - a), (y - b) * (y - b)));
```

We submit and eagerly await the verdict, hoping that we got first blood on this contest. And we're greeted with... time limit exceeded? I look over what I submitted and facepalm: our solution was $\mathcal O(n^4)$ when $n \leq 500$! Somehow, I had convinced myself our solution was amortized $\mathcal O(n^3)$ or something when I coded it, but no, it's $\mathcal O(n^4)$ when there are lots of points in two consecutive layers. I rethink the details and come up a horrible solution using linesweep and maintaining prefix/suffix minimums. If you know this problem, you'll know this is not the intended solution, and there's a **much, much, much** easier solution that can be coded in less than 10 lines. But anyways, for now the linesweep bash solution is the only one I have in mind, and I tell my teammates it'll take a while to implement, so we put problem F aside for now.

The next problem we attempt is [J](https://seusa21-d1.kattis.com/problems/na21.treehopping), which Arvind goes to code. He finishes the code extremely quickly and we submit at the 12 minute mark. We eagerly await our verdict and get... wrong answer? We reread the problem and facepalm again: we misread the problem! The problem isn't asking if adjacent vertices in the tree are more than distance 3 apart in the permutation. It's asking if adjacent vertices in the permutation are more than distance 3 apart in the tree!

At this point, we're down bad. It hasn't even been 30 minutes in and we're already losing on penalty to UCF with no ACs yet. We think for a bit longer, but we don't see how to take advantage of it being distance 3 or less. The only solution we can think of is brainless LCA bash that would work for any distance $k$ apart. I decide to just go ahead and implement it.

I hammer out a solution using binary lifting to find the LCA, run it on samples, and it... crashes. I'm so confused. I've literally never messed up binary lifting in practice before, but it appears there's a first time for everything. If only that first time wasn't at ICPC regionals :/ . After staring at my code and commenting out parts of the code to find the location of the crash, I still can't find the bug. Jeffrey is also ready to code [problem H](https://seusa21-d1.kattis.com/problems/na21.tetrisgeneration), so I print my code and pass the computer over to him.

Staring at my code on paper still doesn't help. Luckily, Arvind also takes a look at the code and points out my silly mistake: in my DFS method, I referenced the wrong variable, `p` instead of `u`, for a certain line. Ahhhhhhhh!!! I quickly make the edit on the computer and submit to claim our first AC 30 minutes into the contest. But this first mistake would be a sign. Because you can bet this was certainly not the last mistake I made on this contest, but just the first of many...

Shortly after our AC on J, Jeffrey completes his code for H and claims AC on first submit. Nice! The next problem he attempts to code is [I](https://seusa21-d1.kattis.com/problems/na21.tournamentseeding). After one wrong submit and a quick bug fix, we claim AC on problem I.

I should also note that sometime in the midst of all this chaos, we implemented [problem A](https://seusa21-d1.kattis.com/problems/na21.blackandwhite). I don't remember if this was before or after we got problem I (I think it was after). What I do remember is that we saw on the scoreboard that several teams had solved problem A, so we figured it couldn't be that hard. And indeed, upon reading we immediately thought of bitmask DP, which is the intended solution for this problem. I came up with some formulas and coded problem A. It worked on the first two samples, but to my dismay it failed on the third. Problem A will end up being an on and off thing that we think about whenever the computer was free, and it will serve as a bottleneck for the next 2 hours...

At this time, we also decide to code my linesweep bash idea for F, since the computer was available. Honestly, with my track record on this contest so far, I should have been banned from coding. I implement F, run it on samples, and what a surprise, I fail the second sample. LOL. I print the code and stare at it while contemplating life.

Jeffrey now codes [problem B](https://seusa21-d1.kattis.com/problems/na21.circlebounce). He asks me if we have a modint template we can use, and I attempt to code one for him to use. Unfortunately, my modint template doesn't compile because of weird C++ const lvalue/rvalue crap (seriously, why am I still coding in this contest?), so we give up and just manually mod after each intermediate calculation. He submits at almost 2 hours into the contest and gets... time limit exceeded? We reread the problem and realize $n \leq 10^{12}$, and Jeffrey was trying to code an unoptimized version of his idea that ran in $\mathcal O(n)$. I notice that the linear time part of his code:

```c++
for(int x=1;x<=n;x++) {
    cos[x] = (cos[x-1]*cos[0]-sin[x-1]*sin[0])%mod;
    sin[x] = (sin[x-1]*cos[0]+sin[0]*cos[x-1])%mod;
}
```

looks like a linear transformation. So it can be optimized with matrix exponentiation. I add matrix exponentiation to his code and resubmit, giving us AC on problem B 2 hours and 13 minutes into the contest (and first solve on B!). We're finally starting to bounce back a little, albeit we're still missing some easier problems (according to the scoreboard) such as problem A.

The next target is [problem E](https://seusa21-d1.kattis.com/problems/na21.failthemall). Arvind tries implementing a backtracking solution because he guesses there might be good properties of the problem that allows the backtracking to run faster. We also write a generator to create some large cases which seem to verify this claim. However, our claim turned out to be false, as we got time limit exceeded on submit.

A little after this, Arvind comes up with an alternative set of formulas for implementing the transitions in problem A. He goes ahead and implements it, and gets AC first try. Nice. Still don't know why my formulas are wrong, but I guess that works.

Shortly after that, I notice we can use 2-sat to solve problem E. Specifically, KACTL's version of [2-sat](https://github.com/kth-competitive-programming/kactl/blob/main/content/graph/2sat.h), which we have in our team reference document, has a convenient function `atMostOne` that does exactly what we want. And to find the lexicographically smallest solution, we can just try placing characters one at a time and repeatedly run the 2-sat algorithm after each character placed. I code this solution and thankfully get AC first try (given my ratio of correct to incorrect code written on this contest, I might have actually lost my mind if I wrote yet another buggy code). And shortly after that, Arvind codes his idea for [problem G](https://seusa21-d1.kattis.com/problems/na21.shortestmissingsubsequences) and also gets AC on first try! Now at 7 problems 3 hours and 30 minutes into the contest, we were finally catching up to the front of the leaderboard.

After all of this, we finally knock out problem F. I realize that my linesweep bash idea was wrong because I wrongly assumed I could use two-pointers in one section when I actually couldn't. And we also realize the much easier intended solution at this time: for each cell, just brute force over the $x$ or $y$ value that we transition from in the previous layer and take the minimum of all cells in the previous layer with that $x$ or $y$ value. This works because the cost function for moving is a minimum of $x$ and $y$, so any "wrong" transitions we considered won't be optimal anyways. The code is super concise and clearly runs in $\mathcal O(n^3)$. We code it up and claim AC 4 hours in. And shortly after this, Jeffrey codes and claims AC on [problem D](https://seusa21-d1.kattis.com/problems/na21.dormroomdivide).

Now, we enter the final 30 minutes of the contest. Our hopes are to get one more problem, because we were certainly losing on penalty among teams with 9 solves. After some pondering about [problem C](https://seusa21-d1.kattis.com/problems/na21.diagonals), we figure maybe backtracking will work because the problem guarantees there exists exactly one solution, so the search space is likely much smaller than the naive bound of $2^{n^2}$. I code up a recursive backtracking solution and it... doesn't work on samples. I was unable to debug it successfully during contest, likely because I was panicking due to there being little time left. The solution did pass when I recoded it again in upsolving, so my guess is I just made a typo during the onsite :/ .

With 10 minutes left, Jeffrey tells me he has the solution to [problem K](https://seusa21-d1.kattis.com/problems/na21.xorisland). But it was unfortunately too late, and we could not finish our code before the end of the contest. And even when we submitted immediately after the end of the contest, we got WA, so we would have needed way more time. The contest was over.

---

</details>

Hopefully that play-by-play wasn't too dry to read (or if you didn't read it, that's ok too). Anyways, here are some of the takeaways I have from this experience:

**1. I've forgotten how great in-person events are.**

I'm opening with this point because I want to make clear that despite my frustration expressed at some moments in the play-by-play, I genuinely had fun at regionals. I complain because this wouldn't be a smax post-contest reflection post without some form of complaining, and because I'm generally quite critical of myself, but I still want the main takeaway from this post to be how great my experience was.

The vast majority of CP competitions such as Codeforces, AtCoder, or even many team competitions I did in high school, are online. I sit in my room and log onto my computer to compete. In the case of a team competition, I join a Discord call to coordinate with my friends. But the atmosphere is very different when you're actually sitting in a room with other competitors and hearing different teams discuss amongst themselves. And on our site, the runners bring a balloon to your table whenever you get AC on a problem, which adds to the hype (though I will say I got super psyched out at the beginning because the div 2 teams in our room were accruing balloons at a super fast rate near the beginning of the contest). It's just that much more fun and satisfying when you see a physical reward for your ACs. I have no doubt it will be extremely hype to attend NAC in-person and sit in the same auditorium as the strongest CPers from across North America.

And while we're on the topic of positives, I'll say that while I didn't get the chance to properly appreciate it in contest, [problem K](https://seusa21-d1.kattis.com/problems/na21.xorisland) was a really fun problem to upsolve. If you want to solve it yourself, then as a hint,

<div class="spoiler" style="margin-bottom: 5%">
read about the "blue eye brown eye riddle" first, because that personally helped me motivate the solution to problem K.
</div>

**2. I didn't realize how reliant I was on my own setup.**

At regionals, our team used VSCode, but the setup was very different from the VSCode setup we used in practice. You can't access the internet to install extensions on VSCode at regionals, so VSCode simply operated as a glorified text editor for our use case. The lack of a linter meant I had no idea if my code would compile until I ran the compilation command, so the number of uncaught typos I made definitely increased. Also, the number of times I hit "ctrl + Q" out of habit and accidentally closed the VSCode window (because on my personal setup I have "ctrl + Q" mapped to something else) was stupidly high. Finally, the keyboard they gave us at regionals was a big keyboard with the arrow keys on the far right. So something like the image below:

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 2]({{site.baseurl}}/assets/images/first-ever-regionals-2.png)

</div>

You might wonder what difference this makes. Well, the keyboard I personally use on both my laptop and my PC is a more concise keyboard with the arrow keys directly underneath the "shift" key:

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 3]({{site.baseurl}}/assets/images/first-ever-regionals-3.png)

*In this keyboard, the arrow keys can be reached without moving my right hand, while I can't do that in the larger keyboard.*

</div>

Yes, that's right. I use the arrow keys when coding. Instead of closing the right parenthesis by actually typing it, I use the arrow keys and rely on the autocomplete in my code editor to fill in the right parenthesis. In my defense, it's unnatural for me to type the right parenthesis when I already see it autocompleted on the screen, but this difference definitely messed with me during regionals and made even typing a simple for loop a much slower procedure. Of course, I'm not saying that we would have been significantly faster if I typed faster, because the bottleneck for our slow performance was still buggy code. It's just a small difference on top of many mistakes I was already making.

**3. I need to be more consistent.**

It would be disingenuous for me to say "oh if I didn't make a typo on J and if I didn't code A wrong and if I didn't code F wrong and if I was basically a perfect human being, we would have won." Committing mistakes and debugging are all part of the game, and the team that's best able to adapt and mitigate the damage of these mistakes is the one that comes out on top. Looking at the scoreboard, UCF also made wrong submits, which means their best case performance would have smoked our best case performance regardless.

The issue is that I'm really bad at recovering from a rough start. I described a similar pitfall in [my reflection post in January]({{site.baseurl}}/winter-break), where I never recovered from a rough start on Global Round 15 and lost 139 rating points. I think in this regionals, I also suffered from a similar issue where previous mistakes snowballed and made me more prone to committing future mistakes. If you didn't know me and judged my behavior this round, you would have thought I was a candidate master.

One way to alleviate this is to be more consistent in the first place. Reach a point where even my worst case performance is somewhat acceptable. I think this is an attribute that people overlook when discussing how to get better. If you look at performances of the top 10 competitors on CF, you'll notice that they hit consist LGM performance not just every once in a while, but almost every single time. And even if they brick on an early problem, they can usually salvage their performance with a solve on a harder problem to compensate, so their losses are never that devastating. Personally, I've gotten IGM performances before, but an ideal state would be to be able to hit IGM performances consistently, which will be my next goal.

Another way is to just get better at keeping my cool. Don't let early mistakes affect the rest of the contest. This is of course easier said than done, but it's a skill that would benefit me not just in CP, but in life.

---

Congrats for making it this far! If you're still here, here are some pics taken at the event. Cheers, and hopefully we'll do better at the NAC!

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 4]({{site.baseurl}}/assets/images/first-ever-regionals-4.png)

*Clowning in 4K*

![Image 5]({{site.baseurl}}/assets/images/first-ever-regionals-5.png)

*Awards ceremony! I am second from the left, the one wearing the dark green hoodie.*

![Image 6]({{site.baseurl}}/assets/images/first-ever-regionals-6.png)

*School picture! Georgia Tech sent 6 teams in total.*

![Image 7]({{site.baseurl}}/assets/images/first-ever-regionals-7.png)

*Productive use of balloons :)*

</div>

---
layout: post
title: "2022 ICPC North American Championship"
tags: [personal]
usemathjax: true
---

*Yay the blog has been revived!*

Hey everyone! This past weekend, I attended the 2022 ICPC North American Championship, which might just be the most fun CP in person events I've attended so far. I represented Georgia Tech alongside fellow teammates [Arvind](https://codeforces.com/profile/arvindr9) and [Jeffrey](https://codeforces.com/profile/RandomKami). We got to fly down to Florida, meet CP people in person, and get all expenses paid for by our school! Literally the perfect formula for fun. In a similar spirit to my post about [ICPC regionals]({{site.baseurl}}/first-ever-regionals), I'd like to write about my first ever NAC experience.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 1]({{site.baseurl}}/assets/images/nac-1.png)

</div>

*The next few sections will be me talking about the competitive programming aspects of NAC. If you don't care for that, you can just scroll to the bottom where I talk about more social aspects and dumped some photos.*

## Expectations

If you take a look at the [NAC teams list](https://codeforces.com/blog/entry/101221) this year, you might notice that there are some really stacked teams this year. Over a dozen teams have at least one red person, some of which are IGMs, and many of them have done ICPC before and are therefore probably more consistent than us. Thus, our goal going in was simple: secure a spot in the world finals.

It's a little hard to predict how many world finals slots there will be, because there are only two data points to go off of (2020 and 2021). Last year they cleared 19 teams, but I've been told that isn't/won't be the norm. The year before, it seems [17 teams](https://codeforces.com/blog/entry/73791) were chosen, but it wasn't simply just the top 17 teams on the NAC leaderboard. I found a [list of the different criteria](https://codeforces.com/blog/entry/70439) used to select teams that year, and it seems there were regional considerations as well. In particular, the maximum length prefix of teams on the [leaderboard](https://web.archive.org/web/20200615000000*/http://nac.icpc.global/scoreboard/) that all qualled in 2020 was only 10. So to secure a world finals spot, one would guess you want to be in the top 10, maybe 10-12 range.

<!-- ## Initial Impressions from NAPC

NAC is actually a multi-day event where the teams engage in a brief [programming camp](https://www.cecs.ucf.edu/NAC-NAPC/) and socialize for the first few days, and compete in the real NAC competition on the last day. The NAPC was our opportunity to actually compare ourselves to the other teams and see how team performances mirror their team ratings. Unfortunately, you can't access the NAPC leaderboards anymore because they were all hosted on [nac22.kattis.com](https://nac22.kattis.com/) and have since been overwritten with the real competition, so this part is me going off of memory.

In total, we did 4 contests aside from the real one:
1. A standard contest (but shorter, 4 hrs)
2. A half-keyboard contest (you can only code in the second half of each hour, 3 hrs total)
3. NSA challenge
4. Dress rehearsal

The NSA challenge isn't a helpful data point for evaluating NAC because the type of problems is too different (just [take a look yourself](https://nsachallenge22.kattis.com/problems)). Dress rehearsal also wasn't the most reliable data point because some teams focused more on testing the environment instead of AK'ing first, but enough teams tried that it can still be partially considered. The main takeaways I got were:

1. We do not want a speedforces NAC. A lot of teams are good at speedforces. We are not one of them.
2. I definitely slept on some of the teams with lower team rating on the [list](https://codeforces.com/blog/entry/101221).
3. Half-keyboard contest proved I still struggle to implement stuff correctly in the last 30 minutes at times.
4. During the dress rehearsal, I found out that sitting in the giant ballroom with the timer on the big screen is a very different vibe. I won't lie, I felt a bit of adrenaline during the dress rehearsal already despite it not being the real thing. And you can bet I felt it on the final day.

None of these things are things we could change or account for before NAC anyways. They're just things I observed. A lot of teams have the same build (a standard Algo/DS build), as teams with the same number of solves generally solved the same subset of problems and there weren't many holes in the leaderboard (so basically, the opposite of a CF global round leaderboard). -->

## The Contest

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 2]({{site.baseurl}}/assets/images/nac-2.jpg)

![Image 3]({{site.baseurl}}/assets/images/nac-3.jpg)

</div>

I'll say right now, competing on site is a very different feeling from doing a team practice in a random room. At the start, you wait outside the ballroom anxiously as they filter teams into the room one by one. When you walk in, they announce your school through the speakers. You walk across the enormous ballroom to find your seat as Imagine Dragons' "Whatever It Takes" is blaring through the speakers. You sit down and immediately notice the countdown timer on the big screen, counting down mere minutes before the contest starts. Different speakers and sponsors come on stage to give words of inspiration or talk about career opportunities, but everything is a blur because you're only fixated on that timer.

When the timer hits zero, everyone scrambles for the keyboard and the problem set. I hastily configure VS Code and type out our template as my teammates start reading the set. The contest has begun.

In similar fashion to my regionals post, I'll put a play-by-play in spoilers reassembled from memory, the scoreboard, and the [livestream](https://www.youtube.com/watch?v=1iez5djXwE4). Don't worry, I assure you I'll be far less salty than last time.

<details markdown="1" style="margin-bottom: 5%"><summary>Play-by-play</summary>

A link to all problems can be found [here](https://nac22.kattis.com/problems).

The first few minutes are all devoted to setting up the environment and combing through the problems. The first AC from MIT comes in at 9 minutes for problem J. Upon reading this, we flip to problem J. It's literally just brute force, simulate tic-tac-toe. I go to code up a simple recursive brute force. Unfortunately, it gets wrong answer. Oops. Luckily, I realize the fix shortly after:

In problem J, you also have to detect when a state is unreachable and print $-1$ in those cases. I handled most of the cases correctly but missed one: if the board has $3$ X tokens and $3$ O tokens, and X has $3$ in a row while O does not, then this is actually impossible. This is because X goes first, and after X wins, the game immediately ends, so it would have been impossible for O to place a third token. After correctly accounting for those types of cases, we get our first AC at the 38 minute mark.

The next problem we get AC on is M. Jeffrey comes up with a construction based on breaking a length 10 string into 3 sections and cycling AAAA -> AAAB -> AABB -> ... That one fortunately gets AC first try at 56 minutes.

After that, Arvind attempts a solution for E. It unfortunately gets wrong answer. Arvind and I go to debug that solution while Jeffrey independently codes problem A. The next hour is pretty dry as both our A and E are wrong for the longest time. After a few bugs, we finally get AC on problem A 1 hr and 59 minutes in.

Unfortunately, the issue with problem E ran more deep than a simple implementation bug. Our initial idea was to let $dp[u][v]$ denote the minimum cost of making the subtree rooted at node $u$ valid and having its value be $v$. That formulation is fine. The problem was that we assumed $v$ would be bounded by some constant multiple of $100$, because the input values were bounded by $100$, and we used that assumption for a $\mathcal O(nv^2)$ solution. An upper bound on the total answer is of course $2n$ (by simply changing all node values to $2$), but maybe each individual value never needs to be that big in an optimal solution? Unfortunately, that's not the case. A counterexample would be a root with $n - 1$ children, around half of which are $89$ and half of which are $97$. Then an optimal solution is to change the root to $89 \cdot 97 = 8633$. It took us a while and three wrong submissions to come to this conclusion...

Eventually, after realizing this, Arvind reformulates the DP to work for $v \leq 2n$, and we get to a $\mathcal O(n^2 \log n)$ solution from iterating over the prime divisors for the transition. After another wrong submit from a typo, we finally get AC on problem E.

At this point, we're in a tricky spot. It's 2 hours and 40 minutes into the contest, and we only have 4 problems and dubious penalty. 2 hours and 40 minutes for the 4 easiest problems in the set does not bode well for our ability to get the harder problems in time... I won't lie, at this stage of the contest I was concerned we weren't going to make it.

The next problem we solve is problem G. At this point, we were just chasing the scoreboard, and several problems (F, G, L) seemed roughly tied at this point. Problem G effectively gives us a functional graph and asks us to find a path on this graph visiting the most number of distinct sightseeing spots. The issue with a straightforward DP is accounting for overcount of sightseeing spots, so the best you could do with that idea is $\mathcal O((rc)^2)$ with reduced constant from bitset.

Fortunately, you can just reverse the edges, which gives you a tree rooted at either a single node or a cycle. And once you convert the problem to a tree problem, the rest of the solution flows quite naturally: DFS from the root and collect the sightseeing spots in some hashmap/frequency array for a pure $\mathcal O(rc)$ solution. There is a bit of code to hammer out to handle the 6 different types of characters in the grid and the contraction of cycles into single nodes in the tree, but it's not too bad, and we're able to get it with minimal dirt at the 3 hour 24 minute mark.

While I was implementing G, Jeffrey also read and worked out the solution to problem F, and he explains the solution to me after we AC G. The solution ends up being a clean $\mathcal O(nt \cdot 2^n)$ bitmask DP. We get AC on that problem just after the 4 hour mark.

We're now in the final hour, and the scoreboard is frozen. We have 6 problems and still slightly dubious penalty. Maybe we'll be ok if we don't get one more, but it's hard to say. The final problem we go for is L. L was a problem I read earlier because we saw MIT solved it ridiculously early and quickly, but I dismissed it because at the time I didn't even know how to solve it in 1D, let alone 2D. But the trick to the problem actually turns out to be quite simple (courtesy of Arvind): if you have too many points in your rectangle, then the answer is always 1. There will always be some triplet $(a, b, c)$ such that $a \leq b \leq c, a + b > c$. Specifically, the worst case grows like the Fibonacci sequence $\{1, 1, 2, 3, 5, 8, \dots\}$. So if you just set a threshold of $45$ points, then you can always print 1 if there are more than that many points in the rectangle, and use brute force otherwise.

The cleanest way enumerate all the points in a rectangle is with a merge sort tree, where you descend on the segment tree for the first dimension and binary search in a sorted vector for the second. Unfortunately, I kind of forgot that existed during the contest, so I thought you needed something more complex like a raw 2D segment tree with pointers and whatnot. Raw 2D segment tree is notorious for using a ton of memory, and it has been forever since I last implemented one, so I wasn't confident in my ability to code one. Fortunately, I also realized you can do square root decomposition instead. Just partition the first dimension into blocks containing sorted vectors and binary search on the second dimension. Funny enough, this is just a strictly worse version of the optimal segtree + sorted vector approach, so I'm not sure how I didn't think of that after thinking of square root, but whatever.

I go to implement this solution, and after getting a RTE due to setting incorrect array bounds, I get a WA still. Uh oh. But we remain calm. There's still like 40 minutes left. As long as we debug like we always do, it's literally impossible for us to not get such a raw DS problem before the contest ends. Also, since this is the last problem we plan on ACing, Arvind and Jeffrey had already created small cases to try while I was implementing, so we had plenty to go off of.

And fortunately, we do get it. I manage to find my typo after combing through my printed code. And after fixing, submitting, and anxiously waiting, we get our AC verdict! This is it! We're at 7 problems! We should be clean!

As a bonus, we also thought we might have gotten the solution to problem I near the very end as well, but we did not finish implementing in time. We also decided to spam submits on every problem at the last minute for fun, since the scoreboard was frozen and it would show a million question marks, but we could only get submits in on problems B and I before we got rate limited lmao.

---

</details>

Ultimately, we ended up solving 7 problems, which we were almost certain coming out of the contest was enough to qualify for world finals! And after asking around and finding out that a lot of teams were actually at 6, we realized we might medal too!

## The Results

<div markdown="1" style="text-align: center; margin-bottom: 5%">

<iframe width="886" height="498" src="https://www.youtube.com/embed/EHtnn7WC8V0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

*Resolving the scoreboard one-by-one is genius.*

</div>

I must say, that was a very anxious closing ceremony to sit through. But after listening to some long speeches and going through the awards for the NSA challenge and first solves, we finally get to the real deal. They announce there will only be 6 medals. Oh dear. That's going to be tight then, because we've already identified that some teams who would have better penalty than us if they were on 7[^1]. How many teams will actually hit 7 though?

It turns out, few enough that we're perfectly 6th! I just remember being so ecstatic upon finding out. The commitment to ICPC at the start of this year and the practices we did were all worth it. The effort was worth it. There's no feeling more rewarding than that.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 4]({{site.baseurl}}/assets/images/nac-4.jpg)

*From left to right: Jingbang (coach), Arvind, Jeffrey, Me*

<img src="{{site.baseurl}}/assets/images/nac-5.jpg" alt="Image 5" width="50%"/>

</div>

## The Experience

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 6]({{site.baseurl}}/assets/images/nac-6.jpg)

*There's a bigger group pic out there that exists but I have yet to get my hands on it.*

<img src="{{site.baseurl}}/assets/images/nac-7.jpg" alt="Image 7" width="50%"/>

*Omg who dis*

</div>

Regardless of the results, this was already one of the best competitive programming experiences I've had so far. There's something surreal about meeting someone who you only knew by their handle previously, but now have a real name and face to match it to. There's something surreal about chatting with others about CP in real life. Like you'll mention a Codeforces round or blog, and others will actually know what you're talking about. Heck, there's something surreal about finding out there are people who actually read this blog!

I also found out I suck at Poker. And Secret Hitler. And lockout. Luckily (or unfortunately), I have like a year[^2] to get better at all of these before world finals 😅

But with that, I think I will end it here. I originally had a whole other section about NAPC, the programming camp that happens before NAC, but that section ended up being too rambly and not going anywhere. I want to keep this post shortened to just the highlights and my main thoughts.

Also, as a reward for making it this far, I have a sneak peak for my next educational blog that will be crossposted to Codeforces: [click me!](https://dmoj.ca/problem/ds5) So stay tuned for that.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 8]({{site.baseurl}}/assets/images/nac-8.jpg)

![Image 9]({{site.baseurl}}/assets/images/nac-9.jpg)

<!-- ![Image 10]({{site.baseurl}}/assets/images/nac-10.jpg) -->

<img src="{{site.baseurl}}/assets/images/nac-11.jpg" alt="Image 11" width="50%"/>

![Image 12]({{site.baseurl}}/assets/images/nac-12.jpg)

![Image 13]({{site.baseurl}}/assets/images/nac-13.jpg)

<img src="{{site.baseurl}}/assets/images/nac-14.jpg" alt="Image 14" width="50%"/>

</div>

[^1]: Specifically, Jeffrey spent like the entire time in between the contest and the closing ceremony asking around and figuring out which teams were on 6 or 7 solves, and ended up narrowing it down to confirmed 6th or 7th, depending on whether or not the University of Washington solved 7 problems.

[^2]: I heard rumors 2022 world finals will be in November 2023? I also heard it will be in Egypt? Or Budapest? Who knows.

---
layout: post
title: "Fully Dynamic Trees Supporting Path/Subtree Aggregates and Lazy Path/Subtree Updates"
tags: [tutorial, algo]
featured: true
usemathjax: true
---

## Motivation

We will solve [this problem](https://dmoj.ca/problem/ds5).

## Prologue

The original name of this problem is [SONE1](https://darkbzoj.cc/problem/3153), originating from the fiery depths of Chinese OI. Amazingly, the Chinese have figured out how to augment the link/cut tree to solve this problem (ref [1](https://www.cnblogs.com/clrs97/p/4403244.html), [2](https://blog.csdn.net/iamzky/article/details/43494481)). Maintaining subtree aggregates with a LCT isn't difficult, and there's a well-known [Codeforces article](https://codeforces.com/blog/entry/67637) by [ouuan](https://codeforces.com/profile/ouuan) about it, but supporting lazy subtree updates is much harder. There's [this](https://codeforces.com/blog/entry/80145), but it requires the updates to be invertible. I haven't found any English resources explaining how to augment LCT to solve this problem, so this article is my attempt at doing that. Most of the content is credited to this [article](https://www.cnblogs.com/clrs97/p/4403244.html), and the implementation is built upon a clean [ordinary LCT implementation](https://codeforces.com/blog/entry/75885) by [bicsi](https://codeforces.com/profile/bicsi).

**EDIT**: As an aside, some readers have pointed out that this is essentially what's referred to in English as a ["Top Tree"](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.9754&rep=rep1&type=pdf). The articles I referenced referred to it as an "AAA Tree". I initially assumed they were different, but after skimming the paper in question there indeed seem to be similarities, just differences in what stuff are called.

## Prerequisites

- Link/Cut Tree
    - [https://en.wikipedia.org/wiki/Link/cut_tree](https://en.wikipedia.org/wiki/Link/cut_tree)
    - [https://www.youtube.com/watch?v=XZLN6NxEQWo](https://www.youtube.com/watch?v=XZLN6NxEQWo)
- Supporting Subtree Aggregates (But Not Lazy) with LCT
    - [https://codeforces.com/blog/entry/67637](https://codeforces.com/blog/entry/67637)

## Terminology

I will use the same terminology used in the resources linked in the prerequisites section. Here is a complete list of them to ensure we are all on the same page before proceeding:

<details markdown="1" style="margin-bottom: 5%"><summary>Terminology</summary>

- Link/cut trees (LCT) maintains a **preferred path decomposition** of a tree.
- A preferred path decomposition of a tree is a decomposition of its nodes into node-disjoint paths, known as **preferred paths**.
- Nodes on the same preferred path are connected with **preferred edges**. All other edges are **virtual edges**.
- We also have **preferred children** vs **virtual children** depending on the type of edge.
- The **represented tree** refers to the real tree graph we are representing. This is not to be confused with the structure of the LCT data structure.
- The preferred paths will be stored as **splay trees** (referred to in some literature as "auxiliary trees", but I will not use that term in this article).
- The entire collection of splay trees concatenated with parent pointers is referred to as just the **LCT** (referred to in some literature as "tree of aux trees", but not a fan of that phrasing).
- All operations in the LCT (adding an edge, removing an edge, rerooting the tree, etc.) revolve around the **access** operation. `access(u)` makes the path from root to $u$ preferred and splays $u$ to the top of the LCT.
- Subtree aggregates are stored in **virtual subtrees**, which are all subtrees in the LCT except for within the splays.
- When doing lazy propagation, pushing down lazy tags to children is referred to as a **push** operation. Recalculating the aggregates in a node based on children is referred to as a **pull** operation.

---

</details>

## The Core Idea

I have a LCT, and I store the aggregates of each subtree in **virtual subtrees**. Any child of a node is either a **preferred child** or a **virtual child**. The issue with doing lazy propagation directly on this model is that a node could have several (up to $\mathcal O(n)$) virtual subtrees hanging from it, and we cannot push down the lazy tags to each of its virtual children each time. The fix is surprisingly simple: **binarize** the tree. This way, when we push down lazy tags, we only have at most two virtual children to push to, and the complexity is fixed. To understand what I mean by binarize, take a look at the diagram of LCTs below:

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 1]({{site.baseurl}}/assets/images/ds5-1.png)

*The solid lines represent preferred edges, and the dotted lines are unpreferred/virtual edges. The nodes 2, 7, 1, 3 form a preferred path in that order. Node 1 has both a left and right preferred child, and it has 3 virtual children.*

</div>

The LCT on the left is what an ordinary LCT might look like. Node 1 has 3 virtual children, which is more than 2. Therefore, we binarize its virtual children by introducing a new **fake** vertex to connect both 4 and 5. Now as seen in the LCT on the right, each node has at most 2 preferred children and 2 virtual children (up to 4 children in total). So simple!

If only... the devil is in the details...

If you were to go and start coding this idea right now, you might realize there are quite few pitfalls to keep in mind while coding. The next few sections will be dedicated to talking about some of the implementation details in depth.

## The Access Method

Since everything in LCTs revolve around access, let's first characterize the access method. Here's what a typical access method might look like:

```c++
// tr is a global array storing each of the LCT nodes
// p is the parent and ch is a size 4 array of its children
void attach(int u, int d, int v) {
    tr[u].ch[d] = v;
    tr[v].p = u;
    pull(u);
}

// adds v as a virtual child of u
void add(int u, int v) {
    tr[u].vir += tr[v].sum;
}

// removes v as a virtual child of u
void rem(int u, int v) {
    tr[u].vir -= tr[v].sum;
}

void access(int u) {
    splay(u);
    add(u, tr[u].ch[1]);        // the preferred path ends at u, so any node with greater depth should be disconnected and made virtual instead
    attach(u, 1, 0);            // sets the right preferred child of u to null (0)
    while (tr[u].p) {
        int v = tr[u].p;
        splay(v);
        add(v, tr[v].ch[1]);    // disconnect any node with greater depth than v, so result is a preferred path ending at v
        rem(v, u);              // u is no longer a virtual child of v
        attach(v, 1, u);        // u is now the right preferred child of v
        splay(u);
    }
}
```

You'll be glad to hear this isn't far from the final product. The fundamental process of accessing a node remains the same. The only difference is that the `add` and `rem` methods become more complex, because we may have to introduce more fake nodes for binarization.

## The Add Method

Firstly, let's take a look at `add`.

```c++
// attaches v as a virtual child of u
void add(int u, int v) {
    if (!v)
        return;
    for (int i=2; i<4; i++)
        if (!tr[u].ch[i]) {
            attach(u, i, v);
            return;
        }
    int w = newFakeNode();
    attach(w, 2, tr[u].ch[2]);
    attach(w, 3, v);
    attach(u, 2, w);
}
```

The first case is straightforward: if one of our 2 virtual children is null, simply set $v$ as that virtual child instead.

```c++
for (int i=2; i<4; i++)
    if (!tr[u].ch[i]) {
        attach(u, i, v);
        return;
    }
```

The second case is when $u$ already has 2 virtual children. In that case, we create a new fake node connecting both $v$ and one of our old virtual children, and substituting that as the new virtual child.

```c++
int w = newFakeNode();
attach(w, 2, tr[u].ch[2]);
attach(w, 3, v);
attach(u, 2, w);
```

The `rem` method is slightly more complex and requires the introduction of several other concepts first, so we'll come back to that in a minute.

## Bound on Fake Node Creation

Firstly, while we're on the subject of fake nodes, **how many fake nodes will we create?** If we only create fake nodes without destroying, we could create as many as the number of preferred child changes, which is $\mathcal O(n \log n)$ with significant constant. That's often an undesirable amount of memory to use. Fortunately, observe that at any point, we only need at most $n$ fake nodes to binarize the entire tree. Therefore, as long as we recycle memory and destroy fake nodes in the `rem` method when they become unnecessary, we will limit our memory usage to just $2n$ nodes.

## Fake Nodes in Our Preferred Paths?

If we just splay willy-nilly in our access method, we might connect fake nodes into our preferred paths. This is undesirable because it becomes messy to keep track of where fake nodes are and when we can destroy them for preserving memory. Thus, we'll need to make the following change to access.

<details markdown="1" style="margin-bottom: 5%"><summary>Old Access</summary>

```c++
void access(int u) {
    splay(u);
    add(u, tr[u].ch[1]);
    attach(u, 1, 0);
    while (tr[u].p) {
        int v = tr[u].p;
        splay(v);
        add(v, tr[v].ch[1]);
        rem(v, u);
        attach(v, 1, u);
        splay(u);
    }
}
```

---

</details>

Instead of `int v = tr[u].p`, we will do `int v = par(u)`, where `par` is a method giving us the lowest ancestor of $u$ that is **not** a fake node.

```c++
int par(int u) {
    int v = tr[u].p;
    while (tr[v].fake)
        v = tr[v].p;
    return v;
}
```

However, this is not good enough. There is no height guarantee on our binary tree formed from fake nodes, so we could be repeating $\mathcal O(n)$ work each time and break complexity. The solution? Make it a splay. So we have **two splays**: the usual one in ordinary LCT and one on the fake nodes. The new `par` method would thus look like the following:

```c++
int par(int u) {
    int v = tr[u].p;
    if (!tr[v].fake)
        return v;
    fakeSplay(v);
    return tr[v].p;
}
```

<details markdown="1" style="margin-bottom: 5%"><summary>Technically...</summary>

So I said the old `par` method wasn't ok because the height could be $\mathcal O(n)$, but when I copy pasted it into my code and submitted it, it still got AC. My guess is it's very difficult to construct a sequence of operations to lead to a degenerate fake node binary tree, so in practice it still runs fast for random data? Either way, just use the second version to be safe.

---

</details>

## Fake Splay

There's no need to remake a new set of splay functions for the fake splay cause that's wasteful. Instead, strive to write reusable splay code that works for both versions depending on a parameter passed in. I don't want to get too into the weeds of the splay implementation because that's more about splay trees and less about LCT, and because everyone implements splay differently, so I'll just copy paste my before and after showing how I adapted splay tree code to work for both versions:

<details markdown="1" style="margin-bottom: 5%"><summary>Before</summary>

```c++
void attach(int u, int d, int v) {
    tr[u].ch[d] = v;
    tr[v].p = u;
    pull(u);
}

int dir(int u) {
    int v = tr[u].p;
    return tr[v].ch[0] == u ? 0 : tr[v].ch[1] == u ? 1 : -1;
}

void rotate(int u) {
    int v = tr[u].p, w = tr[v].p, du = dir(u), dv = dir(v);
    attach(v, du, tr[u].ch[!du]);
    attach(u, !du, v);
    if (~dv)
        attach(w, dv, u);
    else
        tr[u].p = w;
}

void splay(int u) {
    push(u);
    while (~dir(u)) {
        int v = tr[u].p, w = tr[v].p;
        push(w);
        push(v);
        push(u);
        int du = dir(u), dv = dir(v);
        if (~dv)
            rotate(du == dv ? v : u);
        rotate(u);
    }
}
```

---

</details>

<details markdown="1" style="margin-bottom: 5%"><summary>After</summary>

```c++
void attach(int u, int d, int v) {
    tr[u].ch[d] = v;
    tr[v].p = u;
    pull(u);
}

int dir(int u, int o) {
    int v = tr[u].p;
    return tr[v].ch[o] == u ? o : tr[v].ch[o+1] == u ? o + 1 : -1;
}

void rotate(int u, int o) {
    int v = tr[u].p, w = tr[v].p, du = dir(u, o), dv = dir(v, o);
    if (dv == -1 && o == 0)
        dv = dir(v, 2);
    attach(v, du, tr[u].ch[du^1]);
    attach(u, du ^ 1, v);
    if (~dv)
        attach(w, dv, u);
    else
        tr[u].p = w;
}

// call splay(u, 0) for ordinary and splay(u, 2) for fake
void splay(int u, int o) {
    push(u);
    while (~dir(u, o) && (o == 0 || tr[tr[u].p].fake)) {
        int v = tr[u].p, w = tr[v].p;
        push(w);
        push(v);
        push(u);
        int du = dir(u, o), dv = dir(v, o);
        if (~dv && (o == 0 || tr[w].fake))
            rotate(du == dv ? v : u, o);
        rotate(u, o);
    }
}
```

---

</details>

## How to Do the Lazy Propagation

A first thought on doing lazy propagation is to simply maintain 2 lazy values: one for the path, and one for the subtree. However, it's important to ensure the two lazy values cover a disjoint partition of nodes, because otherwise there's no way to properly order the combination of lazy values affecting the intersection of the two partitions. To clarify what I mean, consider the range set operation applied to a simple array.

$$
[1, 2, 3, 4, 5]
$$

Say we range set all values in the interval $[1, 3]$ to $7$, range set the interval $[3, 5]$ to $9$, and then range set the interval $[1, 3]$ again to $10$. Say we maintain two lazy values, one for the interval $[1, 3]$ and one for the interval $[3, 5]$, which would be $9$ and $10$ respectively. The issue is that it isn't obvious what the lazy effect on index $3$ is. In this case, we could maintain the time stamp of both lazy values and use the later one to determine the effect, but you can see how if we use some other lazy operation where intermediate operations, not just the last one, have an effect (e.g. applying an affine function $x := ax + b$ to a range), then this breaks down.

The same applies for the LCT model. If a LCT node has two lazy values, one for the path and one for subtree (in the represented tree), then we need them to cover a disjoint partition of all nodes in the subtree (in the LCT, not in the represented tree). For brevity, let's denote the first lazy value as `plazy` (short for "path lazy") and the second value as `slazy` (short for "subtree lazy"). We will also define 3 aggregates in each node: `path`, `sub`, and `all`. `path` is the standard path aggregate used in ordinary LCT, so it is `tr[tr[u].ch[0]].path + tr[tr[u].ch[1]].path + tr[u].val`. `sub` will be everything else not covered in `path`, so `tr[tr[u].ch[0]].sub + tr[tr[u].ch[1]].sub + tr[tr[u].ch[2]].all + tr[tr[u].ch[3]].all`. And finally, `all` is just a combination of both to get everything in this LCT subtree, or `tr[u].all = tr[u].path + tr[u].sub`. Putting it all together, we get the following `pull` method for recalculating the aggregates in a node:

```c++
void pull(int u) {
    if (!tr[u].fake)
        tr[u].path = tr[tr[u].ch[0]].path + tr[tr[u].ch[1]].path + tr[u].val;
    tr[u].sub = tr[tr[u].ch[0]].sub + tr[tr[u].ch[1]].sub + tr[tr[u].ch[2]].all + tr[tr[u].ch[3]].all;
    tr[u].all = tr[u].path + tr[u].sub;
}
```

Now for pushing down the lazy tags! Pushing `plazy` is the same as ordinary LCT: push down to the 0th and 1st child. Pushing `slazy` is slightly less obvious. Specifically, we will only update `slazy` for the 0th and 1st child, and we will update **both** `plazy` and `slazy` for the 2nd and 3rd child. For the 2nd and 3rd child, we update both lazy values because all values in that LCT subtree represent nodes affected in the real subtree, so both `path` and `sub` must be updated. But why don't we update both lazy values in the 0th and 1st child? It's because if we were to receive an update for this entire subtree from the parent, then there are 2 cases:

1. The current node is a preferred child of its parent. In this case, recursively go up until we hit case 2.
2. The current node is a virtual child of its parent. In this case, when we push down from the parent, the current node would have gotten both its `plazy` and `slazy` values updated. So the `path` part of its LCT subtree is already fully updated. If we were to update `plazy` of its 0th and 1st children again when pushing down from the current node, then we would be applying the update twice to the path.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 2]({{site.baseurl}}/assets/images/ds5-2.png)

*Say node 1 is following case 2, meaning it is a virtual child of its parent. Node 1 just received a tag pushed down from its parent, so its plazy and slazy values are updated. The nodes highlighted in red are the ones already correctly accounted for by plazy. If we were to push down and update node 2's plazy with node 1's slazy as well, then node 2 would be receiving the update twice which is incorrect.*

</div>

So putting everything together gives us the following push method:

```c++
void pushPath(int u, const Lazy &lazy) {
    if (!u || tr[u].fake)
        return;
    tr[u].val += lazy;
    tr[u].path += lazy;
    tr[u].all = tr[u].path + tr[u].sub;
    tr[u].plazy += lazy;
}

void pushSub(int u, bool o, const Lazy &lazy) {
    if (!u)
        return;
    tr[u].sub += lazy;
    tr[u].slazy += lazy;
    if (!tr[u].fake && o)
        pushPath(u, lazy);
    else
        tr[u].all = tr[u].path + tr[u].sub;
}

void push(int u) {
    if (!u)
        return;
    if (tr[u].plazy.lazy()) {
        pushPath(tr[u].ch[0], tr[u].plazy);
        pushPath(tr[u].ch[1], tr[u].plazy);
        tr[u].plazy = Lazy();   // empty constructor for lazy resets it
    }
    if (tr[u].slazy.lazy()) {
        pushSub(tr[u].ch[0], false, tr[u].slazy);
        pushSub(tr[u].ch[1], false, tr[u].slazy);
        pushSub(tr[u].ch[2], true, tr[u].slazy);
        pushSub(tr[u].ch[3], true, tr[u].slazy);
        tr[u].slazy = Lazy();
    }
}
```

<details markdown="1" style="margin-bottom: 5%"><summary>Note</summary>

This code uses a style of lazy where the values are correctly updated at the same time that the node receives the tag. I usually implement lazy in a different style, where the values are correctly updated when the node pushes down its tag, but I found implementing lazy propagation the first way yields a much better constant factor.

---

</details>

## The Rem Method

I promised you we would come back to the `rem` method. Well, we're finally ready to tackle it!

```c++
int dir(int u, int o) {
    int v = tr[u].p;
    return tr[v].ch[o] == u ? o : tr[v].ch[o+1] == u ? o + 1 : -1;
}

void recPush(int u) {
    if (tr[u].fake)
        recPush(tr[u].p);
    push(u);
}

void rem(int u) {
    int v = tr[u].p;
    recPush(v);
    if (tr[v].fake) {
        int w = tr[v].p;
        attach(w, dir(v, 2), tr[v].ch[dir(u, 2) ^ 1]);
        if (tr[w].fake)
            splay(w, 2);    // fake splay
        free(v);
    } else {
        attach(v, dir(u, 2), 0);
    }
    tr[u].p = 0;
}
```

What's happening here? Let's break it down. $u$ is the node that we are disconnecting from its parent, $v$. First consider the easier of the two cases:

```c++
} else {
    attach(v, dir(u, 2), 0);
}
```

This clause triggers when $v$ is not a fake node. In this case, it's exactly the same as ordinary LCT. Remove $u$ as a virtual child of $v$.

We could handle the second case in the same way, but there's an extra consideration. If $v$ is fake, then after removing $u$, $v$ only has one virtual child and is therefore obsolete. We can destroy the node and attach $v$'s other child directly to $v$'s parent instead! This step is necessary to ensure our number of fake nodes remains under our bound of $n$.

There's one more consideration: correct application of pushes and pulls. Consider the following scenario:

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 3]({{site.baseurl}}/assets/images/ds5-3.png)

*We are calling rem on node 4 and attaching it as a preferred child of 1 instead. The red fake node has a pending lazy tag waiting to be pushed down. The left and right diagrams show before and after the procedure.*

</div>

See the issue? When we remove $u$ and reattach it above, it could "dodge" a lazy tag that it's supposed to receive. So to remedy this, we need to call push on all fake ancestors of $u$ up to the next non-fake node, which is what the method `recPush` does in my code. Finally, notice that after removing $u$, we would need to call `pull` again on all fake ancestors up to the next non-fake node to correctly set their values. We could create another method `recPull` with similar structure to `recPush`. Or, we could just call `splay` at the end to correctly set all the node values moving up. Calling `splay` would also fix any amortized complexity concerns from calling `recPush`.

And that's it! We've successfully implemented our new version of `access`!

## The Rest of the Methods

Once you have access, every other method is sincerely trivial. I'll include them here for sake of completeness.

Reroot, link, cut, lca, and path query/update are all completely identical to ordinary LCT.

<details markdown="1" style="margin-bottom: 5%"><summary>Recap of Those Methods</summary>

`reroot(u)`:
- Introduce a lazy flip tag that swaps the 0th and 1st child of a node
- Access $u$
- Apply lazy flip tag to $u$

`link(u, v)`:
- Reroot $u$
- Access $v$
- Call `add(v, u)`

`cut(u, v)`:
- Reroot $u$
- Access $v$
- Disconnect $v$'s 0th child
- Pull $v$

`lca(u, v)`:
- Modify the access method to return the last parent of $u$ in the while loop before it becomes the root
- Access $u$
- Return access $v$

`path(u, v)`:
- Reroot $u$
- Access $v$
- Return $v$'s `path`/update $v$'s `plazy`

---

</details>

Finally, for subtree queries/updates. Say we are querying for the subtree of $u$ given that $r$ is the root. First:

- Reroot $r$
- Access $u$

Now, $u$'s subtree in the represented tree consists of all the virtual subtrees hanging off of $u$, plus $u$ itself. So in other words, `tr[tr[u].ch[2]].all + tr[tr[u].ch[3]].all + tr[u].val`. For query, we just return that value. For update, we update `tr[u].val` directly, and then we update both the `plazy` and `slazy` values of its two virtual children. We do not touch the 0th or 1st child, since those are not part of $u$'s subtree.

## The Code

I've pasted snippets here and there, but if you're still fuzzy on some of the implementation details, you can see my complete code [here](https://github.com/mzhang2021/cp-library/blob/master/implementations/graphs/TopTree.h).

## Performance

<div markdown="1" style="text-align: center; margin-bottom: 5%">

<img src="{{site.baseurl}}/assets/images/ds5-4.png" alt="Image 4" width="25%"/>

</div>

Presumably, the complexity of this augmentation of LCT is still $\mathcal O(\log n)$, but with a significant constant factor ~~([this article](https://www.cnblogs.com/clrs97/p/4403244.html) estimates the constant factor to be $97$)~~. On DMOJ, it runs in around 0.6-0.7 seconds for $n, q \leq 10^5$. On Library Checker, it runs in a [little over 1 second](https://judge.yosupo.jp/submission/91913) for $n, q \leq 2 \cdot 10^5$. So its performance is closer to $\mathcal O(\log^2 n)$ in practice. Some of the implementations in the Chinese articles run faster than mine, but that seems to come at the cost of readability and some strange code, and my implementation is fast enough for almost all reasonable competitive programming purposes.

## Applications

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 5]({{site.baseurl}}/assets/images/ds5-5.png)

</div>

---
layout: post
title: "September 2022 Update"
tags: [personal, opinion]
---

Hey everyone, it's been too long since I last took the time to sit down and write a blog post. There's a multitude of reasons why I haven't written anything lately. Mainly, once college started, any time to devote to CP instantly evaporated thanks to classes, clubs, and socializing. But also, I just didn't have anything to write. Typically, when I write a blog post, I write with some topic or intent in mind, usually to educate or as an opinion piece. I've started a number of drafts for my next article but have tentatively scrapped all of them, simply because I realized midway that I either didn't have too much to say or I didn't feel qualified enough to write on the subject.

**So what is this post then?** To be honest, this is just a post for myself. To write down my thoughts on CP right now. My progress in my CP journey and where I want to go next. And also where I want to go with this blog.

# The Current State of CP

Should qualify this section with the obvious disclaimer that this is my opinion, of course. This is from the perspective of someone who first started actively doing competitive programming and Codeforces in mid 2019. I have seen the platform change significantly over the course of those 3 years.

Right now, it feels like CP is in a plateau. I'm not talking about problem quality; problem quality has always been fine. Rather, I'm referring to innovation in the sport.

To get my point across, let me compare to the state of CP during the inception of COVID. When COVID hit, people had no choice but to turn to indoor activities, such as competitive programming. Codeforces saw a huge influx of people, with the average number of registrants for Div. 2s skyrocketing from below 10k to 20k+. Quarantine also marked the start of many high rated users' YouTube channels and streaming careers. More community Discord servers and big events like [Lockouts](https://codeforces.com/blog/entry/81395) began cropping up. It might be nostalgia talking, but it really did feel like the CP community was more alive at the time.

CF rounds also felt more memorable back in the day, maybe a big part due to community engagement. I still vividly remember two CF rounds I took part in 2 years ago: [Global Round 9](https://codeforces.com/blog/entry/79620) and [Codeforces Round 659](https://codeforces.com/blog/entry/80422). When Global Round 9 dropped, that was an experience. Before the round even started, there was the peak moment of the ["as a tester" memes](https://codeforces.com/blog/entry/79620?#comment-654440), marking the last time that meme would be funny as it proceeded to get beaten into to the ground and buried six feet under in the following 2 years. As for the round itself, in my mind the round forever marked a shift in the tone of Codeforces problemsetting and paved the way towards the acceptance of troll problems and problems with a huge [solution search space]({{site.baseurl}}/difficulty/) but simple solution. My friends and I collectively lost our shit in our group chat and the comment section of the announcements blog was flooded by exasperated or amused competitors. CF Round 659 was somehow so unbalanced that it was hilarious. In Div. 1, just solving AB got you a red performance and C-F were all 2800+, while Div. 2 got a 2200 rated problem B. And D1A was also super submit bait as it was too easy to come up with [something wrong](https://codeforces.com/blog/entry/80422?#comment-667993) for that problem. Personally, I solved a whopping 0 problems as a wee Candidate Master that round. I think that was the first time I ever solved 0 problems in a round. They just don't make CF rounds the same anymore 😔.

In many ways, this golden time obviously could not last forever. Eventually, quarantine would end and people would go back to the real world. And don't get me wrong, that's for the better. Personally, despite the CP boon, I prefer and am much healthier physically and mentally post COVID. It's just that with most of my old CP friends no longer doing CP and me no longer recognizing most of the handles on the leaderboards these days, I can't help but look fondly upon CP in the past. Most YT channels don't upload anymore, streams aren't a thing anymore, and CP for me has lost a lot of the "magic" it used to have when I first started.

I'm also just growing old. I'm about to turn 20 in a few months. I find the majority of posts on CF nowadays cringe or unfunny. The average age on CF is probably around the high school range, 16-18. And I've also just probably been doing CP for too long and am starting to feel burn out.

# My Progress in CP

It has been one year since I first hit red, and I'm still around the same rating one year later 😅. But to be fair, I believe myself to be much stronger than a year ago. In my mind (even if the data and contest results don't always back me up), I am now stable GM and essentially on the cusp, if not already over, the IGM line. So I certainly won't be quitting until I reach IGM, because I do firmly believe I have the capability to do so.

At the same time, I no longer grind anywhere close to as much as in the past. During quarantine, I devoted an unhealthy amount of time to CP and would do every contest possible. My practice was also unfocused; I was just trying to solve as many problems as I can, majority of which were editorial assists, so I was still hardstuck purple for half a year despite the volume of problems I was solving. Fast forward to now, and all of my engagement with CP is now either doing the occasional CF contest if it fits in my schedule, running my university's CP club, or teaching classes on the side. I hardly ever practice now, mostly because it's hard to find time to, and also because a part of me feels I shouldn't. When all of my HS friends have moved on from CP and gone to enjoy other activites and hobbies, I can't help but feel a little foolish still clinging onto CP as a primary hobby of mine. To avoid getting rusty, I've switched my practice focus now to mainly thinking, something I can do passively while walking to class or doing other daily activities. I'm more likely now to read some problems but not bother implementing them, which I feel ok with doing because I'm reasonably confident in my implementation skills up to this point.

As a tangent, I am starting to find the "magic" in other things I do. For example, I recently started climbing (specifically bouldering), and it's so much fun because it integrates thinking and puzzle solving (figuring out the best approach to a course and which limbs to use where) with getting a good workout. Also, because I'm just starting out, I'm in the golden phase where I feel improvement every session, so I feel motivated to keep trying. The feeling of joy from trying out a tip from a YouTube video or from a friend during my next session can be compared to the feeling of unlocking a new set of problems you can now solve after learning a new algorithm in competitive programming. I think this will be great for my personal development but also for my relationship with CP. During quarantine, CP was the only thing on my mind. I would literally do every contest possible on every platform, whether it be Codeforces, AtCoder, CodeChef, or even HackerEarth and LeetCode. I did CP so much because it was my only hobby during quarantine, and without CP I would feel empty. But if I can shift my focus to other activities where I'm making more progress, then I can maintain a healthy relationship with CP where I don't do it all the time and therefore still find it fun whenever I occasionally pick up the keyboard. It's all about balance.

# What's Next for the Blog?

Frankly, I'm not sure. Now that I've had a blog for a while, I can see why people stop making YT videos or streaming after a while. When you first start out, you have all these great ideas, and you just make banger after banger to share on the internet. But after you've exhausted all your great ideas, you don't know where to go next, and keeping the blog updated starts to feel more like an obligation than a form of enjoyment.

That being said, I do have some ideas to post next. I just need to sit down some day and type them out. So hopefully you'll stick around for that! And of course, if you have any ideas on what you want to see, or any thoughts about anything I wrote, please leave a comment! I assure you, I read every comment on all of my blogs. Thanks for reading, and I'll see you next time (in hopefully less than a month).

---
layout: post
title: "Kruskal Reconstruction Tree"
tags: [tutorial, algo]
usemathjax: true
---

The Kruskal Reconstruction Tree (KRT) is something that is prevalent in folklore but scarcely documented, and most high rated users have probably either used this trick inadvertently or know of some other way of solving the problems that this DS solves. The most complete resource I know of is this [CF blog](https://codeforces.com/blog/entry/85714), and this blog is basically me adding a few more uses of this DS that I've seen since the other blog was published. There's also something similar called a [line tree](https://codeforces.com/blog/entry/71568?#comment-559304) which seems to solve the same class of problems, but has a slightly different construction (an array instead of a tree). The name "Kruskal Reconstruction Tree" is one that I've heard others refer to it as, and is mentioned [here](https://codeforces.com/blog/entry/88669).

## The Concept

Let's say we want to preprocess some tree in $\mathcal O(n \log n)$ and answer path max queries in $\mathcal O(1)$. Most people might answer queries in $\mathcal O(\log n)$ with binary lifting or even $\mathcal O(\log^2 n)$ with HLD. But how to do $\mathcal O(1)$? This [blog](https://codeforces.com/blog/entry/71568) contains a bunch of cool methods, one of which is the aforementioned line tree and one of which is [KRT](https://codeforces.com/blog/entry/71568?#comment-559341).

The KRT construction is as follows: start with a DSU containing $n$ isolated vertices and process the edges in increasing order of weight. When we insert a new edge $(u, v)$, we create a new vertex representing that edge and set it as the parent of $u$ and $v$'s components in the DSU. The initial sort of edges is $\mathcal O(n \log n)$ and we build the structure using a DSU with path compression (but **not** union by size/rank, as we care about parent-child relationships!), so the overall build time is $\mathcal O(n \log n)$. Our final KRT will have $2n - 1$ edges ($n$ vertices as leaves, and $n - 1$ vertices representing tree edges). Take a look at the diagrams below for a concrete example.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 1]({{site.baseurl}}/assets/images/kruskal-1.png) ![Image 2]({{site.baseurl}}/assets/images/kruskal-2.png)

*The original tree is on the left and its KRT is on the right. All newly created vertices representing edges are labelled with the pair of vertices they connect in the original tree.*

</div>

From the diagram, we can discern a key property of the KRT: the maximum edge between $u$ and $v$ is their LCA in the KRT! It's well-known how to compute LCA in $\mathcal O(1)$ using euler tour and RMQ, so we've successfully answered path max queries in $\mathcal O(1)$. The code is super simple:

<details markdown="1" style="margin-bottom: 5%"><summary>Code</summary>

```c++
// id is the next unused id to assign to any new node created
// par is the standard definition of dsu parent
// adj will store the KRT
int id, par[2 * MAXN];
vector<int> adj[2 * MAXN];

int find(int u) {
    return par[u] == u ? u : par[u] = find(par[u]);
}

void unite(int u, int v) {
    u = find(u), v = find(v);
    if (u == v)
        return;
    par[u] = par[v] = par[id] = id;
    adj[id] = {u, v};
    id++;
}
```

---

</details>

Let's now look at some real applications of this DS!

## [Codeforces Round 809, Div 2 E: Qpwoeirut and Vertices](https://codeforces.com/contest/1706/problem/E)

**Statement:** Given an undirected graph, answer queries of the form $(l, r)$ where we find the smallest $k$ such that edges $1, \dots, k$ are sufficient for all vertices $l, \dots, r$ to be connected.

If we build the KRT, then the answer is simply the LCA of all vertices $l, \dots, r$. Of course, finding the LCA of a group of nodes by iterating over each of them is too slow. However, it suffices to find the nodes with the smallest and largest DFS times and take the LCA of those two nodes to get the LCA of the entire group. So the full solution is to build an RMQ on indices to query for the smallest and largest DFS times (in the KRT, not the original tree) within some range $[l, r]$, and then query the KRT to find the LCA edge, giving us an $\mathcal O((n + m) \log n + q)$ solution.

## [Codeforces Round 767, Div 1 E: Groceries in Meteor Town](https://codeforces.com/contest/1628/problem/E)

**Statement:** Given a weighted tree with all nodes initially deactivated, answer queries of three types:
1. Activate all nodes in some range $[l, r]$.
2. Deactivate all nodes in some range $[l, r]$.
3. For some node $x$, find the maximum weight edge from $x$ to any activated node.

Build the KRT again. That third query is simply asking for the LCA of all activated nodes and $x$. We can use the same trick as the previous problem. It suffices to find the activated node with the smallest and largest DFS times, and take the LCA of those nodes and $x$, to get the LCA of $x$ and all activated nodes. So we simply need a data structure that can range activate, range deactivate, and query for the minimum and maximum DFS times among all activated indices, which sounds like a job for a segment tree. Bam, Div 1E has never been so clean!

## [Codechef TULIPS: Tiptoe Through the Tulips](https://www.codechef.com/problems/TULIPS)

**Statement:** Given a weighted tree with all nodes initially containing a tulip, answer queries of the form $(d, u, k)$ where on day $d$, we perturb all nodes reachable from $u$ via edges with weight $\leq k$ and collect tulips from all nodes with tulips, and we want to know how many tulips we collect on that day. After a node is perturbed, it grows a tulip if it remains unperturbed in the next $X$ days.

Here we discover the true potential of KRT: we can turn component queries into subtree queries. Once the KRT is built, the set of nodes reachable from $u$ via edges with weight $\leq k$ correspond to a subtree in the KRT. To find the root of that subtree, we need to find the highest ancestor of $u$ with edge weight $\leq k$, which can be done using binary lifting as the edge weights increase monotonically going up the KRT. And if some DFS times are assigned, then subtree queries become range queries!

Now that we're in the realm of range queries, we can explore our vast toolbox of range query structures. We need some data structure that can count indices in a range with time $\leq d - X$ and range set times to $d$. That's an annoying formulation, so let's consider a simpler one: count zeros in a range and range add. Whenever we process a query, we count zeros in that range, and then we add $1$ to that range and mark a future event to be processed at time $d + X$ to add $-1$ from that same range. This is much more tractable, as values are always non-negative so counting zeros is equivalent to [counting minimums](https://usaco.guide/adv/count-min?lang=cpp), so all necessary operations can be handled by segment tree.

## [IOI 2018: Werewolf](https://oj.uz/problem/view/IOI18_werewolf)

**Statement:** Given an undirected graph, process queries of the form $(S, E, L, R)$ where we want to know if it's possible to reach $E$ from $S$ by first going through vertices with indices $\geq L$, reaching some vertex with index in between $[L, R]$, and going through vertices with indices $\leq R$.

It would be sacrilegious to talk about KRT and not mention the problem that spurred the trick, IOI Werewolf. So let's look at this problem now. This time, our KRT is going to look a little different, since our edges are unweighted. For processing $\geq L$ ($\leq R$ is analogous), start with an empty DSU and process the vertices in decreasing order of index. When we process a vertex, find the components of all previously processed vertices and create a new vertex as the DSU parent of all of those components. Now for a query $S$, the set of vertices it can reach that are $\geq L$ correspond to some subtree in the KRT.

If we build two KRTs, one for $\geq L$ and the other for $\leq R$, then we can find the sets of vertices reachable from $S$ and $E$ that are $\geq L$ or $\leq R$ respectively, and then check if those sets intersect. Since these are subtree queries, we can again turn them into range queries with DFS times, and the problem reduces to the following: given two permutations $A$ and $B$, answer queries of checking if there exists a common element between $A[l_1, r_1]$ and $B[l_2, r_2]$.

This can be formulated as a sweepline problem. We can find something stronger, the count of common elements between $A[l_1, r_1]$ and $B[l_2, r_2]$. This equals the count of common elements between $A[l_1, r_1]$ and $B[1, r_2]$ minus the count of common elements between $A[l_1, r_1]$ and $B[1, l_2 - 1]$. So we sweep on $B$, and when we process an element, add $1$ to its corresponding position in $A$ in a binary indexed tree. Then, when we reach the right endpoint of a query in $B$, answer it by querying for the sum between $[l_1, r_1]$ in $A$ with the binary indexed tree. Voilà!

## Closing

The power of KRT is giving us a way to handle queries based on partitioning components by edge weights into tree queries, something we are more familiar with and have more tools for. Of course, often times these queries can also be processed offline and answered while merging in DSUs, but that method isn't always nice, and the KRT gives us a clean online method of answering them.

---
layout: post
title: "Transition Then State"
tags: [tutorial, algo]
featured: true
usemathjax: true
---

When we think about the classic model for dynamic programming, typically we think about first enumerating the state, and then enumerating the transitions from that state. But sometimes that perspective doesn't yield itself to a sufficiently fast solution. Let's look at some examples.

## Bellman-Ford

Let's begin with a classic example, the [Bellman-Ford algorithm](https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm). The code for that typically looks something like this:

```c++
for (int iter = 0; iter < n - 1; iter++)
    for (auto [u, v, w] : edges)
        dist[v] = min(dist[v], dist[u] + w);
```

One perspective of this algorithm is that it is dynamic programming. Suppose there are no negative cycles, so the shortest distance from the source node $s$ to every other vertex in the same component is well-defined. Then each shortest path is always simple (no repeated vertices).

<details markdown="1" style="margin-bottom: 5%"><summary>Why?</summary>

Suppose the shortest path from $s$ to some other vertex $v$ was not simple, meaning the shortest path contains repeated vertices. Suppose vertex $w$ appears twice on the path. Then the segment of the path from the first to second occurrence of $w$ is a cycle. Because there are no negative cycles, the cycle has non-negative weight, so we can remove the cycle from the path and get a path with less edges and at least as low of total weight. We repeat this until the path becomes simple.

---

</details>

A simple path can contain at most $n$ vertices and therefore at most $n - 1$ edges. Initially, the only distance correctly computed is $dist[s] = 0$. In each iteration, we iterate over our edge list and perform what is known as a "relaxation", where we update $dist[v]$ based on the shortest path to $u$, plus the edge from $u$ to $v$. The important thing is that after the first iteration, all shortest paths with one edge will be correctly computed. In general, after the $k$th iteration, all shortest paths with $k$ edges will be correctly computed, because prior to that iteration all shortest paths with $k-1$ edges were correctly computed, and every shortest path with $k$ edges consists of a $k-1$ length path plus an extra edge covered in the $k$th iteration. So after $n - 1$ iterations, all shortest paths with at most $n-1$ edges (all of them) will be correctly computed, so the algorithm is correct.

If we look at this through the lens of the classic dynamic programming model, what's really happening here is there is an implicit second dimension. The actual state is $dp[k][v]$ denoting the shortest distance from $s$ to $v$ with at most $k$ edges. And the transition would be

$$
dp[k][v] = \min(dp[k-1][v], \min_{uv \in E(G)} dp[k-1][u] + w(u, v))
$$

The first part of that transition happens implicitly by reusing the same table for each iteration, and the second part of that transition is covered by the relaxation in each iteration. Bellman-Ford is essentially a memory efficient implementation of this recurrence.

If we code the DP explicitly with a 2D table, we get $\mathcal O(n(n + m))$. Compared to $\mathcal O(nm)$ Bellman-Ford, this way is worse when $m \ll n$.

## DP to Maintain Convex Polygon

This is actually the problem that kickstarted this blog post. [Problem K](https://qoj.ac/contest/1096/problem/5443) from the first stage of the 2022-23 Universal Cup gives us a simple polygon with $n \leq 200$ vertices and asks us to count the number of subsets of vertices (of size at least 2) such that for every pair of vertices in the subset, the line segment between them lies inside (or on the boundary of) the polygon.

We can start by precomputing for every pair of vertices whether or not the line segment between them lie inside the polygon in $\mathcal O(n^3)$. This subproblem itself is actually an ICPC World Finals problem, namely [problem A](https://qoj.ac/contest/414/problem/2767) from the 2017-18 WF, so you can refer to the solution to that for more details.

We can also observe that the subset of vertices we choose should form a convex polygon. If there are three adjacent vertices $u, v, w$ that form a concave section of the subset polygon, then some part of the line segment from $u$ to $w$ would lie outside the original polygon.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

<img src="{{site.baseurl}}/assets/images/transition-1.png" alt="Image 1" width="50%"/>

</div>

On the other hand, if the subset polygon is convex, then it suffices to check that the edges of that polygon lie within the original polygon, and we don't have to check all pairs of vertices.

These observations alone bring us to an $\mathcal O(n^4)$ DP: $dp[s][u][v]$ denotes the number of subsets where the first vertex was $s$, the last 2 vertices taken were $u$ and $v$, and we have an $\mathcal O(n)$ transition for enumerating the next vertex to take. A transition to vertex $w$ is valid if $u \to v \to w$ is a counterclockwise turn. That's not fast enough. But let's consider what makes this DP redundant: storing both of the last 2 vertices in order to track whether or not the next turn is counterclockwise.

Instead, let's redefine our DP: let $dp[s][v]$ denote the number of subsets where the first vertex was $s$ and the last vertex was $v$. And instead of iterating first state, then transition, let's enumerate the transitions as the outer loop. Collect all vectors between all pairs of vertices (so an edge $uv$ is included twice, once as $u \to v$ and once as $v \to u$) and sort them based on polar angle. Now iterate over the vectors in that order, and when we encounter vector $u \to v$, iterate over all $s$ and perform a relaxation $dp[s][v] \mathrel{+}= dp[s][u]$. So the code would look something like this:

```c++
// vecs contains all vectors u -> v that lie within the original polygon
sort(vecs.begin(), vecs.end(), cmp);
for (auto [u, v] : vecs)
    for (int s = 0; s < n; s++)
        dp[s][v] += dp[s][u];
```

This is very clearly $\mathcal O(n^3)$. As for correctness, after processing the $i$th vector, all DP states will represent having built part of a polygon with the last edge at an angle no more than the angle of the $i$th vector. So the condition of enforcing counter-clockwise turns in our subset polygon is automatically satisfied by the order in which we process the vectors.

Now unfortunately, the code I wrote above wouldn't actually get AC on the problem I linked, because the original problem allows collinear points, so you have to do some extra work to avoid reusing the same edge twice, once in each direction. But that's an implementation detail and not the core idea behind the solution.

Again, if we were to look at this from the classic dynamic programming model perspective, there is an implicit extra dimension. Our actual state is $dp[i][s][v]$ denoting the number of subsets where we have processed up to the $i$th vector, the first vertex was $s$, and the last vertex was $v$. And simulating this DP directly would consume $\mathcal O(n^4)$ time. So by saving memory, we also saved complexity.

This particular DP for computing convex polygons has actually appeared in a number of other problems.
- [Problem H: Satanic Panic from Codeforces](https://codeforces.com/contest/1146/problem/H) (with explanation of the trick [here](https://codeforces.com/blog/entry/66639?#comment-506612))
- [Problem F: Integer Convex Hull from AtCoder](https://atcoder.jp/contests/abc202/tasks/abc202_f) in $\mathcal O(n^3)$ instead of $\mathcal O(n^4)$
- [Pegs from NENA 2013](https://open.kattis.com/problems/peggame) in $\mathcal O(n^6)$ instead of $\mathcal O(n^8)$

## Genius - A Codeforces Problem

Finally, [this problem](https://codeforces.com/contest/1497/problem/D) is probably the first time I truly saw this idea, and I remember reading the editorial at the time and thinking it looked very similar to Bellman-Ford.

IQ is always increasing, so one approach is $dp[i][j]$ denoting the maximum number of points if the last 2 problems you solved were $i$ and $j$. Your IQ would therefore be $\|c_i - c_j\|$. And you have $\mathcal O(n)$ transition by enumerating the next problem you solve with larger complexity gap and a different tag, giving an $\mathcal O(n^3)$ solution overall, which is too slow.

Similar to the geometry problem, we will change from storing the last 2 problems to just the last problem solved and instead enumerate the edges in a better order. Because $c_i = 2^i$, a gap $(i, j)$ is greater than gap $(k, l)$ for $i > j, k > l$ iff $i > k$ or $i = k, j > l$. So the correct order to enumerate these edges in to get increasing order gaps is increasing $i$ as the outer loop, then decreasing $j$ as the inner loop.

```c++
for (int i = 1; i < n; i++)
    for (int j = i - 1; j >= 0; j--)
        if (tag[i] != tag[j]) {
            long long di = dp[i], dj = dp[j];
            dp[i] = max(dp[i], dj + abs(s[i] - s[j]));
            dp[j] = max(dp[j], di + abs(s[i] - s[j]));
        }
```

The condition of enforcing increasing IQ is automatically taken care of by the order in which we enumerate these edges. Or alternatively, the dimension of current IQ has become an implicit dimension. So again, we cut memory to also cut complexity and get $\mathcal O(n^2)$.

## More Problems

- [Problem F: Brave CHAIN from AtCoder](https://atcoder.jp/contests/abc176/tasks/abc176_f)

---
layout: post
title: "Segment Tree Merging"
tags: [tutorial, algo, ds]
featured: true
usemathjax: true
---

Segment tree merging often serves as an alternative to small-to-large while also cutting an extra log factor, or can be used for "directed" merging (i.e. the merging is not symmetric w.r.t. both sets). The extent to which this technique can be applied is actually quite extensive, and a lot of it is not documented in English (the only English resource I've found is [this cf post](https://codeforces.com/blog/entry/49446)), so I hope to bridge the gap with this post.

## The Technique

Suppose you have several [dynamic segment trees](https://usaco.guide/plat/sparse-segtree?lang=cpp). For our example, our segment trees will support point update and range sum.

```c++
const int NODES = 1e7 + 5;

int id = 1, sum[NODES], pl[NODES], pr[NODES];

int query(int p, int l, int r, int i, int j) {
    if (i > r || j < l || !p)
        return 0;
    if (i <= l && r <= j)
        return sum[p];
    int m = (l + r) / 2;
    return query(pl[p], l, m, i, j) + query(pr[p], m + 1, r, i, j);
}

int update(int p, int l, int r, int i, int v) {
    if (!p)
        p = id++;
    if (l == r) {
        sum[p] = v;
        return p;
    }
    int m = (l + r) / 2;
    if (i <= m)
        pl[p] = update(pl[p], l, m, i, v);
    else
        pr[p] = update(pr[p], m + 1, r, i, v);
    sum[p] = sum[pl[p]] + sum[pr[p]];
    return p;
}
```

Some notes on this implementation:
- Instead of C++ pointers, I prefer to implement dynamic segment trees by allocating a giant pool of nodes and using `int` as "pointers" (really indices to nodes in the pool).
- In the function signatures, `p` is the pointer to the current segtree node, `l` and `r` are the node range, `i` and `j` are the query range, and `v` is the updated value at index `i` in the update method.
- In the global scope, `id` is the next unused node in our pool. `sum` is the sum of our segment tree node and `pl` and `pr` are pointers to the node's left and right child.
- One neat thing about this implementation (and the reason why I prefer it over a C++ pointer approach) is that "null" is represented by index 0 and has sum 0, so we do not need to worry about dereferencing null pointers.
- Both of these methods are clearly $\mathcal O(\log n)$ by the same logic as normal segment tree.

Ok, now suppose I want to support merging two segment trees into one. Here is what that method looks like:

```c++
int merge(int p1, int p2) {
    if (!p1)
        return p2;
    if (!p2)
        return p1;
    pl[p1] = merge(pl[p1], pl[p2]);
    pr[p1] = merge(pr[p1], pr[p2]);
    sum[p1] = sum[pl[p1]] + sum[pr[p1]];
    return p1;
}
```

Essentially, we traverse down both segtrees at the same time. If either segtree is empty, we return the other. If both exist, then we recursively merge both children and we return the node of the first segtree.

What is the complexity of this? While a single merge may do up to $\mathcal O(n)$ work, the total complexity is bounded by $\mathcal O(n \log n)$ assuming the total sizes of all our segtrees add up to $n$. This is because whenever we keep recursing down in the merge method, we destroy the node of the second segtree (`p2` is no longer needed). So the total amount of work done by the merge method is bounded by the number of segtree nodes we can destroy, and we can only create at most $\mathcal O(n \log n)$ segtree nodes.

## POI Tree Rotations

Links to [$n \leq 2 \cdot 10^5$](https://szkopul.edu.pl/problemset/problem/sUe3qzxBtasek-RAWmZaxY_p/site/?key=statement) and [$n \leq 10^6$](https://szkopul.edu.pl/problemset/problem/b0BM0al2crQBt6zovEtJfOc6/site/?key=statement)

In this problem, we are given a binary tree, we have the option of swapping the children of each internal node of the tree, and we want to minimize the number of inversions in the inorder traversal of this tree.

Firstly, we might observe that each internal node's decision is independent of other internal nodes. Specifically, for each internal node, if $y$ was the number of pairs of elements in the left and right subtrees where the one in the left is greater than the one in the right, then the number of inversions contributed is $\min(y, sz[left] \cdot sz[right] - y)$, as we can either swap or not swap the children. So it remains to calculate $y$ quickly for each internal node.

One approach is small-to-large merging. We start at the leaves and maintain some data structure that stores elements and can query for the number of elements less than $x$ in the data structure. This could be a [pbds ordered set](https://codeforces.com/blog/entry/11080) or some other binary search tree. We merge these data structures bottom up with small-to-large merging and count the number of inversions between two subtrees as we merge into their parent. The complexity will be $\mathcal O(n \log^2 n)$.

But that's not the best we could do for this problem. Consider choosing a dynamic segment tree as our data structure. And instead of merging small-to-large, we use the merge method outlined above. Then the complexity becomes $\mathcal O(n \log n)$.

But wait, how do we count the number of inversions as we merge? The small-to-large merging approach looked something like this:

```c++
const int MAXN = 2e5 + 5;

long long inv;
ordered_set st[MAXN];

int merge(int a, int b) {
    bool flip = false;
    if (st[a].size() < st[b].size()) {
        st[a].swap(st[b]);
        flip = true;
    }
    for (int x : st[b]) {
        int cnt = st[a].order_of_key(x);
        inv += flip ? cnt : st[a].size() - cnt;
    }
    for (int x : st[b])
        st[a].insert(x);
    return a;
}
```

The key thing is that we had to iterate over every element in the smaller of the two sets and query for the number of inversion pairs it forms with the other set, which already consumes $\mathcal O(n \log^2 n)$ time.

The fix is to embed the inversion counting logic into our segtree merge. The "indices" of our segtrees are the values of its elements, and the aggregate is sum. Suppose that `p1` and `p2` are the segtrees of our left and right subtrees respectively. When we are at a stage in the merge method where both `p1` and `p2` exist, the number of inversions increases by `sum[pl[p2]] * sum[pr[p1]]`. All other inversion pairs will be counted at a later stage in the recursion. You can refer to the code below for more clarity:

```c++
long long inv;

int merge(int p1, int p2) {
    if (!p1)
        return p2;
    if (!p2)
        return p1;
    inv += (long long) sum[pl[p2]] * sum[pr[p1]];
    pl[p1] = merge(pl[p1], pl[p2]);
    pr[p1] = merge(pr[p1], pr[p2]);
    sum[p1] = sum[pl[p1]] + sum[pr[p1]];
    return p1;
}
```

So with this, we can solve the problem in just $\mathcal O(n \log n)$!

*Note that even though the complexity is correct for the $n \leq 10^6$ version of this problem, the memory limit is too tight for $\mathcal O(n \log n)$ memory, so to pass that version you have to merge a less sparse data structure such as splay trees or treaps.*

Now let's check out some other problems solvable with this technique which are a little harder to solve with small-to-large.

## [PKUWC2018 Minimax](https://loj.ac/p/2537)

**Translation:** You are given a **binary tree** of $n$ nodes rooted at $1$. If a node is a leaf, it is assigned an input weight. Otherwise, it is assigned some probability $p_i$. It has a $p_i$ chance of getting set to the maximum of its children and $1 - p_i$ chance of getting set to the minimum of its children. **It is guaranteed that all leaf node weights are distinct.** Now, if the root could become $m$ different values, then let $V_i$ denote the $i$th smallest value and $D_i$ denote the probability of the root becoming it, compute

$$
\sum_{i=1}^m i \cdot V_i \cdot D_i^2 \mod 998244353
$$

**Input format:** First line is $n \leq 3 \cdot 10^5$. Second line contains $n$ integers, the $i$th integer is the parent of node $i$ or $0$ if $i = 1$. Third line contains $n$ integers, the $i$th integer equals its weight $w_i \leq 10^9$ if it is a leaf node or $p_i \cdot 10^4$ otherwise (guaranteed to be an integer).

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>

Let's maintain for each node $i$ the set of values that node $i$ could become. For transition, say you're iterating over all values in a child's list. Accumulate the probabilities of the values in the other list that are larger than it, then multiply $p_i$ with that as well as its current probability to get the probability it is chosen. Same for smaller than it. This is $\mathcal O(n^2)$ as we need to iterate over both children's lists, and finding the position in the other can be maintained with some two pointers.

One could hope to speed this up with some sort of small-to-large merging, but unfortunately there isn't an easy way to update the probabilities in the big list. Instead, consider using a merging segment tree. Each node maintains its set of values as a segment tree sorted by values. The leaf nodes store the probabilities of attaining each of those values. The segment tree also maintains a lazy multiply value.

The merge function is more nuanced. As we traverse down the merge, we maintain lazy values $v_1$ and $v_2$ denoting the contribution of segment tree $1$ and $2$ to the other segment tree respectively. When we reach a point in the merge function where one exists but not the other, we lazy multiply the segment tree leftover. When both exist, consider the effect they have on each other. If we descend left down the segment tree, then we add the sum of the right segment tree all multiplied by $1 - p_i$ as all of those values are larger, so you need their sum of probabilities times $1 - p_i$ to contribute to the probability of selecting the values on the left. Analogously, when we descend right, we add sum of left segment tree multiplied by $p_i$. The complexity is $\mathcal O(n \log n)$.

To get a better sense of what I'm talking about it, you can refer to [my submission](https://loj.ac/s/1387916).

---

</details>

## Range Sort

Given an array of $n \leq 10^5$ integers, process $q \leq 10^5$ queries where you sort some subarray $[l, r]$ either increasing or decreasing. Output the final sequence after all queries.

I'm not aware of any submission link to this problem at the moment ([http://www.lydsy.com:808/JudgeOnline/problem.php?id=4552](http://www.lydsy.com:808/JudgeOnline/problem.php?id=4552) used to exist but that online judge is offline now). You could also submit as an overkill solution to [https://atcoder.jp/contests/abc237/tasks/abc237_g](https://atcoder.jp/contests/abc237/tasks/abc237_g).

<details markdown="1" style="margin-bottom: 5%"><summary>Solution</summary>

The key is to represent the array as a set of contiguous intervals, each one sorted either increasing or decreasing. So initially the array can have up to $\mathcal O(n)$ segments. With each query, we cut up to two segments on the ends, erase all segments fully contained within our query segment, and insert the query segment into the set. So the number of new segments in our set is at most $3$.

As for representing the segments, we can represent them as dynamic segment trees. And we just need to be able to merge and split these segments trees. Merge is the same as above, split is not difficult either and only creates at most $\mathcal O(\log n)$ new segtree nodes. The code below shows how to split a segtree into two segtrees, one containing the $k$ smallest elements and the other containing the remaining.

```c++
pair<int, int> split(int p, int k) {
    if (!p)
        return {0, 0};
    int q = id++;
    if (sum[pl[p]] >= k) {
        tie(pl[q], pl[p]) = split(pl[p], k);
        sum[p] -= k;
        sum[q] = k;
        return {q, p};
    } else {
        tie(pr[p], pr[q]) = split(pr[p], k - sum[pl[p]]);
        sum[q] = sum[p] - k;
        sum[p] = k;
        return {p, q};
    }
}
```

---

</details>

## More problems

- [https://codeforces.com/contest/1515/problem/H](https://codeforces.com/contest/1515/problem/H)
- [https://loj.ac/p/2553](https://loj.ac/p/2553)
- [https://loj.ac/p/2722](https://loj.ac/p/2722)
- [https://loj.ac/p/3340](https://loj.ac/p/3340)
- [https://www.spoj.com/problems/COT3/](https://www.spoj.com/problems/COT3/)

---
layout: post
title: "Simulating Cost Flow"
tags: [tutorial, algo]
featured: true
usemathjax: true
---

This post assumes knowledge of [min/max cost flow](https://en.wikipedia.org/wiki/Minimum-cost_flow_problem) and a rough understanding of the high-level methods for solving (successive shortest path and cycle canceling). Knowledge of specific algorithms and implementation details are not expected. Also solutions to some problems will use [Aliens trick](https://web.archive.org/web/20210511092429/http://www.serbanology.com/).

---

The cost flow problem is a well-known problem in literature that a whole slew of competitive programming problems can be formulated as. Unfortunately, competitive programming problems typically have constraints set too high for directly running even the most state of the art cost flow algorithm. However, in certain problems the flow network will have a very specific setup that allows us to figure out greedily the optimal flow (i.e. proving greedy with flow) or "simulate" the flow algorithm faster with data structures. That is what this post will be about.

I will say that I do not claim novelty over these ideas. This idea is (unsurprisingly) well-known in China. This particular post and some of the example problems are taken from [this Chinese blog](https://www.luogu.com.cn/blog/command-block/mu-ni-fei-yong-liu-xiao-ji).

I will also describe everything below in terms of min cost flow, max cost is of course analogous. When describing flow network constructions, I will shorthand with $(cost, capacity)$ for describing edges.

## High-level Methods for Cost Flow

Most cost flow algorithms fall into one of these categories of high-level approaches. The two in particular that we will look at are:

1. **Successive Shortest Path**: Repeatedly find a min cost augmenting path (a path with minimum total cost where all edges can still contain more flow) from source to sink and send flow through that path.
2. **Cycle Cancelling**: Repeatedly find a negative cost cycle (a cycle with negative total cost where all edges can still contain more flow) and send flow through that cycle.

Note that in the cycle cancelling paradigm, there is no concept of source and sink, but you can solve for source and sink by adding an edge from sink to source with cost of $-\infty$ and capacity of $k$ for the min cost $k$-flow (or $\infty$ capacity if you want min cost max flow).

## Min Cost Flow is Convex

Min cost flow as a function of amount of flow is convex. This makes intuitive sense, as you can always rearrange the augmenting paths you choose to pick less steep ones (lower cost) before more steep ones (higher cost). This fact is useful as it allows us to use Aliens trick.

## [Codeforces 802O: April Fools' Problem](https://codeforces.com/contest/802/problem/O)

**Statement Summary:** You are preparing and printing $k$ problems for a contest over the course of $n$ days. On the $i$th day, you can prepare a problem for cost $a_i$ and print a problem for cost $b_i$. You must prepare a problem before printing it. In other words, if you prepare a problem on day $i$, you can only print it on some day $j \geq i$. You can prepare and print at most one problem per day. What is the minimum cost of preparing and printing $k$ problems?

**Constraints:** $1 \leq k \leq n \leq 5 \cdot 10^5, 1 \leq a_i, b_i \leq 10^9$

---

Let's first think about solving this with flows. One straightforward way is to create $2n + 2$ nodes: a source $s$ and sink $t$, plus nodes representing $a_i$ and $b_i$ for each $i$. We add the following edges:

- $s$ to each $a_i$ node with $(a_i, 1)$
- each $b_i$ node to $t$ with $(b_i, 1)$
- each $a_i$ node to $b_j$ node where $i \leq j$ with $(0, 1)$

The answer is the min cost $k$-flow of this network.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 1]({{site.baseurl}}/assets/images/simulating-cost-flow-1.png)

*Example for $n = 3$*

</div>

Now let's try to optimize using one of two methods. Both are possible and lead to different solutions for this problem.

### Successive Shortest Path

This is the method described in the official editorial.

First, let's simplify this network to not use $\Omega(n^2)$ edges. Consider a slightly different setup with $n + 2$ nodes: a source $s$ and sink $t$, plus nodes $1$ through $n$. We add the following edges:

- $s$ to each $i$ with $(a_i, 1)$
- each $i$ to $t$ with $(b_i, 1)$
- $i$ to $i + 1$ with $(0, \infty)$

I claim the answer is also the min cost $k$-flow of this network. Essentially, a matching consists of picking some $a_i$, waiting zero or more days (represent by taking some number of $i \to i + 1$ edges), and then pick some $b_j$ where $i \leq j$.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 1]({{site.baseurl}}/assets/images/simulating-cost-flow-2.png)

*Example for $n = 4$*

</div>

An augmenting path consists of sending flow from $s$ to some $i$, then from $i$ to $j$, and finally from $j$ to $t$.

- $s \to i$ and $j \to t$ must of course have no flow going through them.
- If $i \leq j$, this is ok. We add $+1$ flow to each edge on the path from $i$ to $j$.
- If $i > j$, then we are sending flow along a reverse edge and cancelling out existing flow, so every edge on the path from $i$ to $j$ must have at least $1$ flow, and the augmenting path adds $-1$ flow to each path edge.

And in the successive shortest path algorithm, we simply need to choose the augmenting path with minimum cost each time. So we need to choose a pair of indices $i, j$ with minimum $a_i + b_j$, and either $i \leq j$ or there exists flow on every edge on the path between $i$ and $j$.

So we need to be able to add $+1$ or $-1$ to a range and recompute the minimum cost valid $(i, j)$ pair. This sounds like a job for lazy segment tree! We just repeat $k$ times of querying the segtree for $(i, j)$ and either add $+1$ or $-1$ to all edges in between $i$ and $j$, giving us an $\mathcal O(k \log n)$ solution.

The details for determining the minimum cost valid $(i, j)$ pair are quite tedious, but the TLDR is that you have to store first and second minimums of the amount of flow through any edge in a subarray. I have an [old submission](https://www.luogu.com.cn/record/79319016) that implements this idea with a ton of variables in the segtree node. It can probably be reduced with more thought.

### Cycle Cancelling

To drastically simplify our analysis, we will apply Aliens trick. Binary search on some reward $c$, so now there is no requirement of at least $k$ problems anymore, but instead you get a reward of $c$ for completing one problem. So preparing a problem on day $i$ and printing on day $j$ costs $a_i + b_j - c$. So there is an edge from $t$ to $s$ with $(-c, \infty)$. We binary search for the minimum $c$ that we complete at least $k$ problems. This is valid because we know min cost flow is convex with respect to the amount of flow.

Now consider incrementally adding in nodes in decreasing order (from $n$ to $1$) and consider how the optimal flow changes after each additional node. When we add node $i$, we add edges $s \to a_i$, $b_i \to t$, and $a_i \to b_j$ for all $i \leq j$. Upon adding node $i$, we consider the possibilities for how a new negative cycle could form.

1. $s \to a_i \to b_j \to t \to s$ with cost $a_i + b_j - c$. This is essentially matching $a_i$ with some unmatched $b_j$.
2. $s \to a_i \to b_j \to a_k \to s$ with cost $a_i - a_k$. This is cancelling out some existing flow passing through $s \to a_k \to b_j$ and is equivalent to changing the matching to match $b_j$ with $a_i$ instead of $a_k$.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 3]({{site.baseurl}}/assets/images/simulating-cost-flow-3.png) ![Image 4]({{site.baseurl}}/assets/images/simulating-cost-flow-4.png)

*Examples of negative cycles of the first and second types*

</div>

Those are actually the only two cases we need to consider. For example, you might think we need to consider some cycle of the form $s \to a_i \to b_j \to t \to b_k \to a_l \to s$. This cycle would represent taking some matched pair $(a_i, b_j)$ instead of $(a_l, b_k)$. However, if $(a_l, b_k)$ was originally matched in the first place, that would imply $a_l + b_k \leq c$, as otherwise $t \to b_j \to a_i \to s \to t$ would be a negative cycle with weight $c - a_l - b_k$ and we would have had to handle that before adding node $i$. And if $s \to a_i \to b_j \to t \to b_k \to a_l \to s$ was a negative cycle, that would imply $a_i + b_j < a_l + b_k$ and therefore $a_i + b_j < c$, so we could instead take the negative cycle $s \to a_i \to b_j \to t \to s$. In fact, we would ultimately converge to that state regardless, because if we took $s \to a_i \to b_j \to t \to b_k \to a_l \to s$ first, then $s \to a_l \to b_k \to t \to s$ would form a negative cycle afterwards, so the end result after resolving all negative cycles is identical.

You can also confirm that after taking a negative cycle of one of the two types listed above (whichever one is more negative), we will not create any more additional negative cycles. So essentially, each time we add a node $i$ to the network, we take at most one additional negative cycle.

<details markdown="1" style="margin-bottom: 5%"><summary>Example: Can taking a type 2 cycle lead to creating a type 1 cycle?</summary>

If we break up some old pair $(a_k, b_j)$ and instead match $(a_i, b_j)$, is it then possible for $a_k$ to be paired with some other $b_l$?

If we are breaking up the pair, that implies $a_i < a_k$. Now suppose we pair $a_k$ with $b_l$, implying $a_k + b_l < c$. Substituting $a_i < a_k$ yields $a_i + b_l < c$. Furthermore, if we compare $a_i - a_k$ and $a_i + b_l - c$, because $-a_k > b_l - c$, $a_i + b_l - c < a_i - a_k$, so it is more optimal to match $a_i$ with $b_l$ in the first place.

---

</details>

Therefore, we can simply maintain a priority queue of potential negative cycles and iterate $i$ from $n$ to $1$. When we match $(a_i, b_j)$, we insert $-a_i$ into the priority queue to allow for breaking up that matching and pairing $b_j$ with something else in the future. When we leave $b_i$ unmatched, we insert $b_i - c$ into the priority queue to allow for matching with that $b_i$ in the future. And at each step, if $a_i$ plus the minimum value in the priority queue is less than $0$, then we take that option. The overall complexity is $\mathcal O(n \log n \log A)$ (but with much better constant than the successive shortest path solution).

<details markdown="1" style="margin-bottom: 5%"><summary>Code for Clarity</summary>

```c++
auto solve = [&] (int c) -> pair<int, long long> {
    int cnt = 0;
    long long cost = 0;
    priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq;
    for (int i=n-1; i>=0; i--) {
        pq.emplace(b[i] - c, 0);
        if (a[i] + pq.top().first <= 0) {
            cnt += pq.top().second == 0;
            cost += a[i] + pq.top().first;
            pq.pop();
            pq.emplace(-a[i], 1);
        }
    }
    return {cnt, cost + (long long) k * c};
};

int l = 0, r = 2e9 + 5;
while (l < r) {
    int m = midpoint(l, r);
    if (solve(m).first >= k)
        r = m;
    else
        l = m + 1;
}

cout << solve(l).second << "\n";
```

The priority queue stores negative cycles as a pair of cost and what type it is (swapping with existing matching or creating a new matching). Note that `solve` tries to maximize the number of matchings created for tiebreakers, which is necessary to avoid reconstruction issues with Aliens trick (touched on in more detail in the Aliens trick resource I linked at the top).

---

</details>

Notice that the final solution looks awfully similar to a greedy algorithm. And indeed, we can apply a greedy interpretation to this: each $a_i$ can be matched with some $b_j$ where $i \leq j$ for cost $a_i + b_j - c$, and we want cost as negative as possible. Then the two types of negative cycles can be interpreted as "options" when introducing a new index $i$: either match $a_i$ with some unmatched $b_j$ or swap it with some existing $(a_k, b_l)$ matching. In essence, the flow interpretation serves as a **proof** for the correctness of the greedy.

<details markdown="1" style="margin-bottom: 5%"><summary>Do we need Aliens trick?</summary>

Maybe not, but the solution certainly gets significantly messier without it. If we don't apply Aliens trick and instead analyze the network directly, we have an edge from $t$ to $s$ with $(-\infty, k)$.

For types of negative cycles introduced upon adding a new index $i$, the two types described above still apply, but now $s \to a_i \to b_j \to t \to b_k \to a_l \to s$ is also possible, because the $t \to s$ edge no longer has infinite capacity, so it may not be possible to choose $s \to a_i \to b_j \to t \to s$ instead.

Furthermore, not only is $s \to a_i \to b_j \to t \to b_k \to a_l \to s$ possible, but there are even more complicated types of cycles that could spawn now. Consider the following case:

```
5 3
9 1 10 10 4
6 7 8 2 9
```

After processing $i = 5, 4, 3$, our matchings will be $(10, 8), (10, 2), (4, 9)$ for total cost of $43$.

When we introduce $i = 2$, we can no longer take any more matchings as $k = 3$, so we will have to consider swapping with existing matchings instead. The most negative cycle available is swapping out $(1, 7)$ for $(10, 8)$ for cost $1 + 7 - 10 - 8 = -10$. This is a negative cycle of the third type that didn't exist with Aliens trick, namely $s \to a_2 \to b_2 \to t \to b_3 \to a_3 \to s$. And so now we have $(1, 7), (10, 2), (4, 9)$ with total cost $33$.

Now introduce $i = 1$. The most negative cycle is $s \to a_1 \to b_4 \to a_4 \to s$ with cost $9 - 10 = -1$. So after swapping, we have matchings $(9, 2), (1, 7), (4, 9)$. However, we are not done. There's still a long negative cycle that exists in this situation: $t \to b_2 \to a_2 \to b_4 \to a_1 \to b_1 \to t$ with cost $-7 + 6 = -1$. What this does is this matches the $9$ with the $6$ instead and then matches the $1$ with the $2$ instead of the $7$. So this converges to $(9, 6), (1, 2), (4, 9)$ with the minimum cost of $31$.

If we were to do this in one negative cycle after adding $i = 1$, it would be $s \to a_1 \to b_1 \to t \to b_2 \to a_2 \to b_4 \to a_4 \to s$ with cost $9 + 6 - 7 - 10 = -2$. That's absurd!

In short, when there is a capacity $k$ restriction, it is no longer the case that the optimal solution containing $i$ from $2$ to $n$ changes just a little bit when adding $i = 1$. It could completely morph.

---

</details>

So with this first example, we can see two different solutions that arise from thinking about flows. The first one is probably impossible to think of without flows. For the second one, it might be difficult to prove Aliens trick can be applied here without formulating it as flow. Once Aliens trick is applied, the greedy is relatively easier to come up without thinking about flows, but having the flow network still gives us confidence in its correctness.

## [Codeforces 866D: Buy Low Sell High](https://codeforces.com/contest/866/problem/D)

**Statement Summary:** You have knowledge of the price of a stock over the next $n$ days. On the $i$th day it will have price $p_i$. On each day you can either buy one share of the stock, sell one existing share you currently have, or do nothing. You cannot sell shares you do not have. What is the maximum possible profit you can earn?

**Constraints:** $2 \leq n \leq 3 \cdot 10^5, 1 \leq p_i \leq 10^6$

---

This problem has several interpretations that lead to the same code. You can think of it as slope trick. Or as greedy. Let's think about it as flows.

Firstly, we can loosen the restrictions by allowing for both buying and selling a stock on a given day. This won't change the answer since both buying and selling on the same day is equivalent to doing nothing.

Now we design the following flow network with $n + 2$ nodes: a source $s$ and sink $t$ and $n$ nodes representing days $1$ through $n$. We add the following edges:

- $s$ to $i$ for all $1 \leq i \leq n$ with $(-p_i, 1)$
- $i$ to $t$ for all $1 \leq i \leq n$ with $(p_i, 1)$
- $i$ to $i + 1$ for all $1 \leq i < n$ with $(0, \infty)$

The answer is thus the max cost flow of this network.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 5]({{site.baseurl}}/assets/images/simulating-cost-flow-5.png)

*Example for $n = 3$*

</div>

Now consider the cycle cancelling method. Add an edge from $t$ to $s$ with $(0, \infty)$. We are using a cost of $0$ instead of $\infty$ because we do not require the max amount of flow, and forcing the max flow is not always optimal.

This network is extremely similar to the previous problem. We add the nodes from $n$ to $1$. When we add node $i$, the possible positive (since we are doing max cost flow) cycles are:

- $s \to i \to \dots \to j \to t \to s$ for $i \leq j$ with cost $p_j - p_i$
- $s \to i \to \dots \to j \to s$ for $i \leq j$ also with cost $p_j - p_i$

So the code ends up being quite simple and may resemble some other greedy code you've seen.

<details markdown="1" style="margin-bottom: 5%"><summary>Code</summary>

```c++
long long ret = 0;
priority_queue<int> pq;
for (int i=n-1; i>=0; i--) {
    pq.push(p[i]);
    if (pq.top() > p[i]) {
        ret += pq.top() - p[i];
        pq.pop();
        pq.push(p[i]);
    }
}
```

---

</details>

## [CSES Programmers and Artists](https://cses.fi/problemset/task/2426)

**Statement Summary:** You have $n$ people, the $i$th person has $x_i$ amount of programming skill and $y_i$ amount of art skill. Each person can be assigned to be a programmer, artist, or neither. You need exactly $a$ programmers and $b$ artists. What is the maximum sum of skills attainable by some matching?

**Constraints:** $1 \leq n \leq 2 \cdot 10^5, a + b \leq n, 1 \leq x_i, y_i \leq 10^9$

---

You get the drill now. Let's model this problem as a flow network. Here is one possible construction using $n + 4$ nodes.

- $s$ to $i$ with $(0, 1)$
- $i$ to $prog$ with $(x_i, 1)$
- $i$ to $art$ with $(y_i, 1)$
- $prog$ to $t$ with $(0, a)$
- $art$ to $t$ with $(0, b)$

The answer is the max cost max flow of this network. Notice that in this case the maximum flow is also optimal as all augmenting paths will have positive weight.

<div markdown="1" style="text-align: center; margin-bottom: 5%">

![Image 6]({{site.baseurl}}/assets/images/simulating-cost-flow-6.png)

*Example for $n = 3$*

</div>

Let's try approaching this with successive shortest path! Essentially, we repeatedly find an augmenting path from $s$ to $t$ with maximum cost and send $1$ unit of flow through. After some pondering, we conclude we only have $4$ types of paths to consider.

- $s \to i \to prog \to t$ with cost $x_i$
- $s \to i \to art \to t$ with cost $y_i$
- $s \to i \to prog \to j \to art \to t$ with cost $x_i - x_j + y_j$
- $s \to i \to art \to j \to prog \to t$ with cost $y_i - y_j + x_j$

The first and fourth types of paths decrease the capacity of $prog \to t$ by $1$, and the second and third types of paths decrease the capacity of $art \to t$ by $1$.

Do we need to consider any more complicated paths? Such as $s \to i \to prog \to j \to art \to k \to prog \to t$? Turns out we don't. Suppose path $s \to i \to prog \to j \to art \to k \to prog \to t$ has the maximum cost. The cost is $x_i - x_j + y_j - y_k + x_k$. Now consider a different augmenting path that would also be valid, $s \to i \to prog \to t$ with cost $x_i$. The fact that the other path was chosen implies $x_i - x_j + y_j - y_k + x_k > x_i$, or $y_j - x_j + x_k - y_k > 0$. This implies that there exists a positive cycle $j \to art \to k \to prog \to j$ before introducing our new augmenting path, contradicting the property of successive shortest paths which ensures optimal cost flow with each new augmenting path added.

Therefore, we just need to maintain some heaps to repeatedly find the maximum cost path out of those $4$ options:

- pair unmatched $i$ to programmer
- pair unmatched $i$ to artist
- pair unmatched $i$ to programmer, and switch some existing programmer $j$ to artist
- pair unmatched $i$ to artist, and switch some existing artist $j$ to programmer

My code is a bit verbose but attempts to implement this idea as straightforwardly as possible:

<details markdown="1" style="margin-bottom: 5%"><summary>Code</summary>

```c++
#include <bits/stdc++.h>
using namespace std;

#ifdef LOCAL
#define DEBUG(...) debug(#__VA_ARGS__, __VA_ARGS__)
#else
#define DEBUG(...) 6
#endif

template<typename T, typename S> ostream& operator << (ostream &os, const pair<T, S> &p) {return os << "(" << p.first << ", " << p.second << ")";}
template<typename C, typename T = decay<decltype(*begin(declval<C>()))>, typename enable_if<!is_same<C, string>::value>::type* = nullptr>
ostream& operator << (ostream &os, const C &c) {bool f = true; os << "["; for (const auto &x : c) {if (!f) os << ", "; f = false; os << x;} return os << "]";}
template<typename T> void debug(string s, T x) {cerr << "\033[1;35m" << s << "\033[0;32m = \033[33m" << x << "\033[0m\n";}
template<typename T, typename... Args> void debug(string s, T x, Args... args) {for (int i=0, b=0; i<(int)s.size(); i++) if (s[i] == '(' || s[i] == '{') b++; else
if (s[i] == ')' || s[i] == '}') b--; else if (s[i] == ',' && b == 0) {cerr << "\033[1;35m" << s.substr(0, i) << "\033[0;32m = \033[33m" << x << "\033[31m | "; debug(s.substr(s.find_first_not_of(' ', i + 1)), args...); break;}}

template<typename T>
struct FastSet {
    priority_queue<T> pq, pending;

    void add(T x) {
        pq.push(x);
    }

    void rem(T x) {
        pending.push(x);
        while (!pq.empty() && !pending.empty() && pq.top() == pending.top()) {
            pq.pop();
            pending.pop();
        }
    }

    T max() {
        assert(!pq.empty());
        return pq.top();
    }
};

int main() {
    ios_base::sync_with_stdio(false);
    cin.tie(NULL);

    int a, b, n;
    cin >> a >> b >> n;
    vector<int> x(n), y(n);
    for (int i=0; i<n; i++)
        cin >> x[i] >> y[i];

    FastSet<pair<int, int>> pqA, pqB;
    priority_queue<pair<int, int>> pqA2, pqB2;
    for (int i=0; i<n; i++) {
        pqA.add({x[i], i});
        pqB.add({y[i], i});
    }

    long long ret = 0;
    while (a > 0 || b > 0) {
        int mx = 0;
        if (a > 0) {
            if (!pqA.pq.empty())
                mx = max(mx, pqA.max().first);
            if (!pqB.pq.empty() && !pqB2.empty())
                mx = max(mx, pqB.max().first + pqB2.top().first);
        }
        if (b > 0) {
            if (!pqB.pq.empty())
                mx = max(mx, pqB.max().first);
            if (!pqA.pq.empty() && !pqA2.empty())
                mx = max(mx, pqA.max().first + pqA2.top().first);
        }
        assert(mx > 0);

        ret += mx;
        if (a > 0) {
            if (!pqA.pq.empty() && mx == pqA.max().first) {
                int i = pqA.max().second;
                pqA.rem({x[i], i});
                pqB.rem({y[i], i});
                pqA2.emplace(y[i] - x[i], i);
                a--;
                continue;
            }
            if (!pqB.pq.empty() && !pqB2.empty() && mx == pqB.max().first + pqB2.top().first) {
                int i = pqB.max().second, j = pqB2.top().second;
                pqA.rem({x[i], i});
                pqB.rem({y[i], i});
                pqB2.pop();
                pqB2.emplace(x[i] - y[i], i);
                pqA2.emplace(y[j] - x[j], j);
                a--;
                continue;
            }
        }
        if (b > 0) {
            if (!pqB.pq.empty() && mx == pqB.max().first) {
                int i = pqB.max().second;
                pqA.rem({x[i], i});
                pqB.rem({y[i], i});
                pqB2.emplace(x[i] - y[i], i);
                b--;
                continue;
            }
            if (!pqA.pq.empty() && !pqA2.empty() && mx == pqA.max().first + pqA2.top().first) {
                int i = pqA.max().second, j = pqA2.top().second;
                pqA.rem({x[i], i});
                pqB.rem({y[i], i});
                pqA2.pop();
                pqA2.emplace(y[i] - x[i], i);
                pqB2.emplace(x[j] - y[j], j);
                b--;
                continue;
            }
        }
        assert(false);
    }

    cout << ret << "\n";

    return 0;
}
```

---

</details>

## More Problems

- [Codeforces 280D: k-Maximum Subsequence Sum](https://codeforces.com/contest/280/problem/D)
- [NOI 2019: Sequence](https://loj.ac/p/3158)
- [CCPC Finals 2021 Problem I: Reverse LIS](https://codeforces.com/gym/103860/problem/I)
- Any other example problem from [this blog](https://www.luogu.com.cn/blog/command-block/mu-ni-fei-yong-liu-xiao-ji)
"

The post on the Meta Facebook Hacker Cup Rules certainly made me realise that my Young Steak Cumshot Flex On X Freestyle was unfortunately False and I would benefit from borrowing the University Of Illinois Urbana-Champaign Giga Cluster or renting or outright purchasing one myself for that competition...

"
Everybody Lies
Everybody Dies
"No More Living For The Culture
Your Lips [Are] Very Soft"
Flex On X
Vanilla Sex
I Play
Project Leonhard Euler
With Mediocre Specifications
I Take W[in]s
Log On To GitHub
I Am Superior
Like The
King Of Hearts
9160
You Already Know
My Name Is:
Young Steak Cumshot
"
- Lazyr
Codeforces Round #300 Editorial (+challenges)

By Endagorion, 8 years ago, In English As usual, a challenge comes with every problem. I tried not to repeat the mistakes of my previous editorials and made sure that all challenges have a solution =) (except for the italics parts that are open questions, at least for me). Go ahead and discuss them in the comments! General questions about problems and clarification requests are welcomed too.

UPD: I added codes of my solutions for all the problems. I didn't try to make them readable, but I believe most part of them should be clear. Feel free to ask questions.

538A - Cutting Banner

Let me first clarify the statement (I really wish I didn't have to do that but it seems many participants had trouble with the correct understanding). You had to erase exactly one substring from the given string so that the rest part would form the word CODEFORCES. The (somewhat vague) wording some substring in the English translation may be the case many people thought that many substrings can be erased; still, it is beyond my understanding how to interpret that as 'more than one substring'. Anyway, I'm sorry for the inconvenience.

Right, back to the problem. The most straightforward approach is to try over all substrings (i.e. all starting and ending positions) to erase them and check if the rest is the wanted word. When doing this, you have to be careful not to forget any corner cases, such as: erase few first letters, erase few last letters, erase a single letter, and so on. A popular question was if an empty substring may be erased or not. While it is not clarified explicitly in the statement, the question is irrelevant to the solution, for it is guaranteed in the statement that the initial string is not CODEFORCES, so erasing nothing will not make us happy. From the technical point of view, you could erase a substring from the string using standard functions like substr in C++ or similar, or do some bare-hands work and perform conditional iterating over all symbols. Depending on the implementation, this would be either O(n2) or O(n3) solution; both of these fit nicely.

One way of solving this in linear time is to compute the longest common prefix and suffix for the given string and the string CODEFORCES. If their total length is at least 10 (the length of CODEFORCES), it is possible to leave only some parts of the common prefix and suffix, thus the rest part (being a substring, of course) may be removed for good. If the total length is less than 10, no such way exists. This is clearly O(n) solution (rather O(n) for reading the input, and O(|t|) for comparisons where t is CODEFORCES in our case).

Sample solution: 10973831

Challenge (easy). A somewhat traditional question: how many (modulo some prime number) large Latin letter strings of length n have the property that a (non-empty) substring may be cut out to leave a given string t? Can you solve it in O(n + |t|2) time? In O(n + |t|) time? Maybe even faster? =)

538B - Quasi Binary

n is up to 106. We may note that there are only 26 + 1 = 65 quasi-binary numbers not exceeding 106, so we could find them all and implement a DP solution that counts the optimal representation for all numbers up to n, or even a brute-force recursive solution (which is not guaranteed to pass, but has a good odds).

Are there more effective solutions? Sure enough. First of all, one can notice that the number of summands in a representation can not be less than d — the largest digit in decimal representation of n. That is true because upon adding a quasi-binary number to any number the largest digit may not increase by more than 1 (easy enough to prove using the standard algorithm for adding numbers). On the other hand, d quasi-binary numbers are always enough. To see that, construct a number m as follows: for every digit of n that is not 0, place 1 in the corresponding digit of m, and for all the other digits place 0. Clearly, m is quasi-binary. If we subtract m from n, all non-zero digits will decrease by 1 (clearly, no carrying will take place), thus the largest digit of n - m will be equal to d - 1. Proceeding this way, we end up with the representation of n as a sum of d quasi-binary numbers. This solution is good for every numeric base, and works in  where d is the base.

Sample solution: 10973842

Challenge (easy). Let us call a number pseudo-binary if its decimal representation contains at most two different digits (e.g., 1, 555, 23, 9099 are pseudo-binary, while 103, 908 and 12345 are not). Represent an integer n as a sum of pseudo-binary numbers; minimize the number of summands. n ≤ 1018.

538C - Tourist's Notes

We want to make the maximum height as large as possible. Consider the part of the chain that was travelled between di and di + 1; we can arrange it in any valid way independently of any other parts of the chain, thus we consider all these parts separately. There also parts before d1 and after dn, but it is fairly easy to analyze them: make them monotonously decreasing (respectively, increasing), as this maximizes the top point.

Without the loss of generality consider di = 0 and di + 1 = t (they may be increased of decreased simultaneously without changing the answer), and hdi = a, hdi + 1 = b. Clearly, in consistent data |a - b| ≤ t, so if this condition fails for a single pair of adjacent entries, we conclude the data is flawed.

If the condition holds, it is fairly easy to construct a valid way to move between the days under the |hi - hi + 1| ≤ 1 condition: increase or decrease the height while it differs from b, than stay on the same height. That does not make the optimal way, but at least we are sure that the data is not inconsistent.

How to construct the optimal arrangement? From the adjacent difference inequality if follows that for any i between 0 and t the inequalities hi ≤ a + i and hi ≤ b + (t - i) hold. Let hi = min(a + i, b + (t - i)) on the [0; t] segment; clearly, every hi accomodates the largest possible value, therefore the value of maximum is also the largest possible. It suffices to show that these hi satisfy the difference condition. Basically, two cases should be considered: if for hi = a + i and hi + 1 = a + i + 1, or hi = b + (t - i) and hi + 1 = b + (t - i - 1), the statement is obvious. Else, hi = a + i but hi < b + (t - i) = hi + 1 + 1, and hi + 1 = b - (t - i - 1) but hi + 1 < a + (i + 1) = hi + 1. Thus, |hi - hi + 1| < 1, and hi = hi + 1.

To find the maximum value of maximum height (I really struggle not to use 'maximum maximum') we may either use ternary search on the h function, or find the point where lines a + i and b + (t - i) intersect and try integer points besides the intersection. If we use this approach analytically, we arrive at the formula (t + a + b) / 2 (try to prove that yourself!).

Sample solution: 10973854

Challenge (medium). Given the same data (that is, a subsequence hdi for a sequence hi), determine how many (modulo a prime number) integer sequences of length n with the property |hi - hi + 1| ≤ 1 agree with the subsequence and have global maximum equal to H? Can you solve the problem in O(n2) time? In  time? Maybe even faster?

538D - Weird Chess

Instead of trying to find out where the piece may go, let's try to find out where it can not go. Initially mark all the moves as possible; if there is a field (x1, y1) containing a piece, and a field (x2, y2) not containing a piece and not being attacked, clearly a move (x2 - x1, y2 - y1) is not possible. Let us iterate over all pieces and over all non-attacked fields and mark the corresponding moves as impossible.

Suppose we let our piece make all the rest moves (that are not yet marked as impossible), and recreate the position with all the pieces in the same places. If a field was not attacked in the initial position, it will not be attacked in the newly-crafted position: indeed, we have carefully removed all the moves that could take a piece to this field. Thus, the only possible problem with the new position is that some field that was attacked before is not attacked now. But our set of moves is maximal in the sense that adding any other move to it will cause the position to be incorrect. Thus, if the new position doesn't coincide with the initial position, the reconstruction is impossible. Else, we have already obtained a correct set of moves. This solution has complexity of O(n4) for iterating over all pieces and non-attacked fields. No optimizations were needed to make solution this pass.

Sample solution: 10973859

Challenge (medium). Solve the same problem in  time.

538E - Demiurges Play Again

With such large constraints our only hope is the subtree dynamic programming. Let us analyze the situation and how the subtrees are involved.

Denote w(v) the number of leaves in the subtree of v. Suppose that a non-leaf vertex v has children u1, ..., uk, and the numbers to arrange in the leaves are 1, ..., w(v). We are not yet sure how to arrange the numbers but we assume for now that we know everything we need about the children's subtrees.

Okay, what is the maximal number we can achieve if the maximizing player moves first? Clearly, he will choose the subtree optimally for himself, and we are eager to help him. Thus, it makes sense to put all the maximal numbers in a single subtree; indeed, if any of the maximal numbers is not in the subtree where the first player will go, we swap it with some of the not-so-maximal numbers and make the situation even better. If we place w(ui) maximal numbers (that is, w(v) - w(ui) + 1, ..., w(v)) in the subtree of w(ui), we must also arrange them optimally; this task is basically the same as arranging the numbers from 1 to w(ui) in the subtree of w(ui), but now the minimizing player goes first. Introduce the notation  for the maximal possible result if the maximizing/minimizing (depending on the lower index) player starts. From the previous discussion we obtain . Thus, if we know  for all children, the value of  can be determined.

How does the situation change when the minimizing player goes first? Suppose that for each i we assign numbers n1, 1, ..., n1, w(ui) to the leaves of the subtree of ui in some order; the numbers in the subtree of ui will be arranged so that the result is maximal when the maximizing player starts in ui. Suppose that numbers ni, j are sorted by increasing of j for every i; the minimizing player will then choose the subtree ui in such a way that  is minimal. For every arrangement, the minimizing player can guarantee himself the result of at most . Indeed, if all the numbers  are greater than r, all the numbers ni, j for  should also be greater than r; but there are  numbers ni, j that should be greater than r, while there are only w(v) - r possible numbers from 1 to w(v) to place; a contradiction (pigeonhole principle). On the other hand, the value of r is easily reachable: place all the numbers less than r as ni, j with , and r as, say, n1, dpmax(u1); the first player will have to move to u1 to achieve r. Thus, .

The previous, rather formal argument can be intuitively restated as follows: suppose we put the numbers from 1 to w(v) in that order to different subtrees of v. Once a subtree of ui contains dpmax(ui) numbers, the minimizing player can go to ui and grab the current result. It follows that we may safely put dpmax(ui) - 1 numbers to the subtree of u(i) for each i, and the next number (exactly r) will be grabbed regardless of what we do (if we do not fail and let the minimizing player grab a smaller number).

That DP scheme makes for an O(n) solution, as processing the k children of each node is done in O(k) (provided their results are already there). As an easy exercise, think about how the optimal arrangement of number in the leaves can be constructed; try to make implementation as simple as possible.

Sample solution: 10973864

Challenge (medium). Suppose that we are given numbers n, a, b, and we want to construct a tree with n leaves such that dpmax(root) = a and dpmin(root) = b. For which numbers n, a, b is this possible? (I'm sure you will like the answer for this one. =)) Can you propose an algorithm that constructs such a tree?

538F - A Heap of Heaps

The first approach. For a given k and an element v, how do we count the number of children of v that violate the property? This is basically a range query 'how many numbers in the range are greater than v' (because, evidently, children of any element occupy a subsegment of the array); the answers for every k are exactly the sums of results for queries at all non-leaf vertices. Online data structures for this query type are rather involved; however, we may process the queries offline by decreasing v, with a structure that is able to support an array, change its elements and take sum over a range (e.g., Fenwick tree or segment tree). This can be done as follows: for every element of the initial array store 1 in the same place of the structure array if the element has already been processed, and 0 otherwise. Now, if we sum over the range for the element v, only processed elements will have impact on the sum, and the result of the query will be exactly the number of elements greater than v. After all the queries for v, we put 1 in the corresponding element so that queries for smaller elements would take it into account. That makes for an  solution. Estimate q: notice that for a given k there are only  non-leaf vertices, thus the total number of queries will be  (harmonic sum estimation). To sum up, this solution works in  time.

Sample solution (first approach): 10973867

The second approach. Let us index the elements of the array starting from 0. It is easy to check that for a given k the parent of the element av is the element . One can show that there are only  different elements that can be the parent of av for some k. Indeed, if , the index of the parent is less that , and all  produce no more than  different parents too. Moreover, each possible parent corresponds to a range of values of k. To show that, solve the equality  for k. Transform: , pk ≤ v - 1 < (p + 1)k, , . For every k in the range above the property is either violated or not (that depends only on av and ap); if it's violated we should add 1 to all the answers for k's in the range. That can be done in O(1) offline using delta-encoding (storing differences between adjacent elements in the process and prefix-summing them in the end). There will be only  queries to the delta array (as this is the number of different child-parent pairs for all k). This makes for a simple  solution which barely uses any heavy algorithmic knowledge at all.

Sample solution (second approach): 10973868

Challenge 1 (medium). Denote ck the minimal number of elements that should be changed (each to a value of your choice) so that the array becomes a valid k-ary heap. Can you find a single ck (for a given k) in  time? Can you find all ck (for 1 ≤ k ≤ n - 1) at once in O(n2) time? Can you do better than these estimates?

Challenge 2 (hard). Solve the problem from Challenge 1 if an arbitrary rooted tree with numbers in vertices is given (that is, change the minimal number of elements so that no element is greater than its parent). Can you do it in O(n2)? In ? In ? (I'm pretty certain my approach should work, but I would be glad if anyone could check me on this one. That being said, I'm eagerly waiting for your comments.) Not likely, but maybe you could do even better?

538G - Berserk Robot

First of all, we'll simplify the problem a bit. Note that after every command the values of x + y and x - y are altered by  ± 1 independently. Suppose we have a one-dimensional problem: given a sequence of x's and t's, provide a looped program of length l with commands  ± 1 which agrees with the data. If we are able to solve this problem for numbers xi + yi and xi - yi separately, we can combine the answers to obtain a correct program for the original problem; if one of the subproblems fails, no answer exists. (Most — if not all — participants who solved this problem during the contest did not use this trick and went straight ahead to the two-dimensional problem. While the idea is basically the same, I'm not going into details for their approach, but you can view the submitted codes of contestants for more info on this one.)

Ok, now to solve the one-dimensional problem. Let us change the command set from  ± 1 to  + 0 /  + 1: set . If the division fails to produce an integer for some entry, we must conclude that the data is inconsistent (because xi and ti should have the same parity). Now it is clear to see that the operation  - 1 becomes operation 0, and the operation  + 1 stays as it is.

A program now is a string of length l that consists of 0's and 1's. Denote si the number of 1's among the first i commands, and s = sl for simplicity. Evidently, an equation  holds, because the full cycle is executed ⌊ ti / l⌋ times, and after that  more first commands. From this, we deduce .

Suppose that we know what s is equal to. Using this, we can compute all ; they are fixed from now on. One more important fixed value is sl = s. In any correct program si ≤ si + 1 ≤ si + 1, but not all values of si are known to us. When is it possible to fill out the rest of si to match a correct program? If sa and sb are adjacent entries that are fixed (that is, every sc under a < c < b is not fixed), the inequality 0 ≤ sb - sa ≤ b - a must hold (a and b may coincide if for different i several values of  coincide). Furthermore, if the inequality holds for every pair of adjacent fixed entries, a correct program can be restored easily: move over the fixed values, and place sb - sa 1's between positions a and b in any possible way, fill with 0's all the other positions in between.

The trouble is that we don't know s in advance. However, we know the positions and the order in which fixed values of sa come! Sort them by non-decreasing of a. All fixed sa can be expressed as linear functions of s; if we substitute these expressions in the 0 ≤ sb - sa ≤ b - a, from each pair of adjacent fixed values we obtain an inequality of general form 0 ≤ p·s + q ≤ d, where p, q, d are known values. If the obtained system of inequalities has a solution, we can get ourselves a valid s and restore the program as discussed above.

It suffices to notice that every inequality of the system has a set of solutions of general form l ≤ s ≤ r (if the set is not empty), where l and r should be calculated carefully depending on the sign of p. All the intervals should be intersected, and the resulting interval provides a range of valid values of s.

Overall, the solution works in , or even in O(n + l) if we use bucketing instead of sorting. Note that the l summand in the complexity is only there for the actual program reconstruction; if we were only to check the existence of a program, an O(n) solution would be possible.

Sample solution: 10973870

Challenge (kinda hard). Under the same statement, how many (modulo a prime number) different programs agree with the given data? Assume that all elementary modulo operations (including division) take O(1) time. Can you solve this problem in O(nl)? In O(n + l)? Maybe even better (in , for example?)

538H - Summer Dichotomy

The problem has several possible approaches.

The first approach. More popular one. Forget about t and T for a moment; we have to separate teachers into two groups so that no conflicting teachers are in the same group, and the number of students in each group can be chosen to satisfy all the teachers.

Consider a connected component via the edges which correspong to conflicting pairs. If the component is not bipartite, there is clearly no valid distribution. Else, the teachers in the component can be separated into two sets such that each set should be in the same group, and the groups for the sets should be different. The teachers in the same set will always go together in the same group, so we may as well make them into a single teacher whose interval is the intersection of all the intervals for the teachers we just compressed. Now, the graph is the set of disjoint edges (for simplicity, if a teacher does not conflict with anyone, connect him with a 'fake' teacher whose interval is [0;∞]).

Consider all possible distributions of students; they are given by a pair (n1, n2). Provided this distribution, in what cases a pair of conflicting teachers can be arranged correctly? If the teachers' segments are [l1, r1] and [l2, r2], either l1 ≤ n1 ≤ r1 and l2 ≤ n2 ≤ r2, or l2 ≤ n1 ≤ r2 and l1 ≤ n2 ≤ r1 must hold. Consider a coordinate plane, where a point (x, y) corresponds to a possible distribution of students. For a pair of conflicting teachers the valid configurations lie in the union of two rectangles which are given by the inequalities above. Valid configurations that satisfy all pairs of teachers lie exactly in the intersection of all these figures. Thus, the problem transformed to a (kinda) geometrical one.

A classical approach to this kind of problems is to perform line-sweeping. Note that any 'union of two rectangles' figure (we'll shorten it to UOTR) is symmetrical with respect to the diagonal line x = y. It follows that for any x the intersection of the vertical line given by x with any UOTR is a subsegment of y's. When x sweeps from left to right, for any UOTR there are O(1) events when a subsegment changes. Sort the events altogether and perform the sweeping while updating the sets of subsegments' left and right ends and the subsegments intersection (which is easy to find, given the sets). Once the intersection becomes non-empty, we obtain a pair (x, y) that satisfies all the pairs of teachers; to restore the distribution is now fairly easy (don't forget that every teacher may actually be a compressed set of teachers!).

Didn't we forget something? Right, there are bounds t and T to consider! Consider an adjacent set of events which occurs when x = x1 and x = x2 respectively. The intersection of subsegments for UOTRs obtained after the first event will stay the same while x1 ≤ x < x2. Suppose the y's subsegmen intersection is equal to [l;r]. If we stay within x1 ≤ x < x2, for a satisfying pair of (x, y) the minimal value of x + y is equal to x1 + l, and the maximal value is x2 + r - 1. If this range does not intersect with [t;T], no answer is produced this turn. In the other case, choose x and y while satisfying all boundaries upon x, y and x + y (consider all cases the rectangle can intersect with a 45-angle diagonal strip). Thus, the requirement of t and T does not make our life much harder.

This solution can be implemented in  using an efficient data structure like std::set or any self-balancing BST for sets of subsegments' ends. The very same solution can be implemented in the flavour of rectangles union problem canonical solution: represent a query 'add 1 to all the points inside UORT' with queries 'add x to all the points inside a rectangle', and find a point with the value m.

Sample solution (first approach): 10973887

The second approach. Less popular, and probably much more surprising.

Imagine that the values of t and T are small. Introduce the set of boolean variables zi, j which correspond to the event 'ni does not exceed j' (i is either 1 or 2, j ranges from 0 to T). There are fairly obvious implication relations between them: . As t ≤ n1 + n2 ≤ T, we must also introduce implications  (here i' is 1 or 2 not equal to i) because if a + b ≥ t and a ≤ j, b must be at least t - j, and  for a similar reason. In this, zi, j for j < 0 clearly must be considered automatically false, and zi, j for j ≥ T must be considered automatically true (to avoid boundary fails).

The last thing to consider is the teachers. For every teacher introduce a binary variable wj which corresponds to the event 'teacher j tutors the first group'. The implications  and  are pretty much self-explanating. A conflicting pair of teachers j and k is resolved in a straightforward way: , .

If a set of values for all the boolean variables described satisfies all the restrictions, a valid distribution can be restored explicitly: n1 and n2 are maximal so that z1, n1 and z2, n2 hold, and the teachers are distributed unequivocally by values of wj. It suffices to notice that the boolean system is a 2-SAT instance, and can be solved in linear time. If we count carefully, we obtain that the whole solution has linear complexity as well: O(n + m + T).

Didn't we forget something? Right! The value of T may be too much to handle Ω(T) variables explicitly. To avoid that, one may notice that the set of possible values of n1 and n2 may be reduced to 0, t, li, t - li, ri, t - ri. We can prove that by starting from any valid values of n1 and n2 and trying to make them as small as possible; the listed values are the ones we may end up with. Thus, we can only use O(n) variables instead of Ω(T). The implications can be built similarily, but using lower/upper bound on the list of possible values instead of exact values (much care is advised!). Finally, this solution can be made to work in , with the logarithmic factor from all the sorting and lower/upperbounding.

Sample solution (second approach): 10973881

Challenge (easy, for a change) Don't you think it's wrong that a group may be without a teacher altogether? Come up with an algorithm that finds a distribution that places at least one teacher in each group. The complexity should not become worse. How about at least k teachers in each group?

Whew, wasn't it a long run! I tried to be verbose and elaborate where it was possible, hope it was worth the wait. Let me know what you think of this write-up!

Codeforces Round #299 Editorial

By PrinceOfPersia, 8 years ago, In English 535A - Tavas and Nafas First of all check if n is one of the values 0, 10, 11, …, 19. Then, let’s have array x[] = {"", "", "twenty", "thirty", …, "ninety"} and y[] = {"", "one", …, "nine"}.

 

Let  and b = n modulo 10.

If n is not one of the values above, then if a = 0, print y[b], else if b = 0 print x[a] otherwise print x[a]-y[b].

Time complexity: O(1)

Code by SoroushE

Another Code by PrinceOfPersia

Another Code by Haghani

Python Code by Zlobober

535B - Tavas and SaDDas Sol1: Consider n has x digits, f(i) =  decimal representation of binary string i, m is a binary string of size x and its i - th digit is 0 if and only if the i - th digit of n is 4. Finally, answer equals to 21 + 22 + … + 2x - 1 + f(m) + 1.

Time complexity: O(log(n))

 

Sol2: Count the number of lucky numbers less than or equal to n using bitmask (assign a binary string to each lucky number by replacing 4s with 0 and 7s with 1).

Time complexity: O(2log(n))

Code by PrinceOfPersia

Another Code by SoroushE

Another Code by Haghani

Python Code by Zlobober

536A - Tavas and Karafs Lemma: Sequence h1, h2, …, hn is (m, t) - Tavas-Eatable if and only if max(h1, h2, …, hn) ≤ t and h1 + h2 + … + hn ≤ m × t.

Proof: only if is obvious (if the sequence is Tavas-Eatable, then it fulfills the condition).

So we should prove that if the conditions are fulfilled, then the sequence is Tavas-Eatable.

Use induction on h1 + h2 + ... + hn. Induction definition: the lemma above is true for every sequence h with sum of elements at most k. So now we should prove it for h1 + h2 + ... + hn = k + 1. There are two cases:

1- There are at least m non-zero elements in the sequence. So, the number of elements equal to t is at most m (otherwise sum will exceed m × t). So, we decrease m maximum elements by 1. Maximum element will be at most t - 1 and sum will be at least m × t - m = m(t - 1). So according to the induction definition, the new sequence is (m, t - 1) -  Tavas-Eatable, so h is (m, t) -  Tavas-Eatable.

2- There are less than m non-zero elements in the sequence. We decrease them all by 1. Obviously, the new sequence has maximum element at most equal to t - 1 so its sum will be at most m(t - 1). So according to the induction definition, the new sequence is (m, t - 1) -  Tavas-Eatable, so h is (m, t) -  Tavas-Eatable.

 

For this problem, use binary search on r and use the fact that the sequence is non-decreasing and  .

Time complexity: O(qlog(mt))

Code by PrinceOfPersia

Another Code by Haghani

Java Code by Zlobober

536B - Tavas and Malekas First of all you need to find uncovered positions in s (because rest of them will determine uniquely). If there is no parados in covered positions (a position should have more than one value), then the answer will be 0, otherwise it’s 26uncovered. To check this, you just need to check that no two consecutive matches in s have parados. So, for this purpose, you need to check if a prefix of t is equal to one of its suffixes in O(1). You can easily check this with prefix function (or Z function).

 

Time complexity: O(n + m)

Code by PrinceOfPersia

Another Code by Haghani

Java Code by Zlobober

536C - Tavas and Pashmaks For each competitor put the point  in the Cartesian plane. So, the time a competitor finishes the match is .

Determine their convex hull(with maximum number of points. i.e it doesn’t matter to have π radians angle). Let L be the leftmost point on this convex hull (if there are more than one, choose the one with minimum y component). Similarly, let D be the point with minimum y component on this convex hull (if there are more than one, consider the leftmost).

Proof:  is the scalar product that is smaller if the point  is farther in the direction of (S, R). It's obvious that the farthest points in some direction among the given set lie on a convex hull. (S, R) can get any value that is vector in first quadrant. So we need the points on the convex hull that we actually calculate (also we know that the points on the right or top of the convex hull, are not in the answer, because they're always losers).

 

It’s easy to see that the answer is the points on the path from D to L on the convex hull (bottom-left arc). i.e the bottom-left part of the convex hull.

Time complexity: O(nlog(n))

In this problem, we recommend you to use integers. How ? Look at the code below

Code by PrinceOfPersia

In this code, function CROSS returns  (it's from order of 1016, so there won't be any overflows.)

In double version, you should have a very small epsilon.

Code of double version by PrinceOfPersia

Another Code With Lower Envelope of Lines by Haghani

Java Code by Zlobober

536D - Tavas in Kansas For each vertex v, put a point (dis(s, v), dis(v, t)) with its point (score) in the Cartesian plane. The first player in his/her turn chooses a vertical line and erases all the points on its left side. Second player in his/her turn chooses a horizontal line and erases all the point below it.

Each player tries to maximize his/her score.

Obviously, each time a player chooses a line on the right/upper side of his/her last choice. Imagine that there are A different x components x1 < x2 < … < xA and B different y components y1 < y2 < … < yB among all these lines. So, we can show each state before the game ends with a pair (a, b) (1 ≤ a ≤ A, 1 ≤ b ≤ B It means that in this state a point (X, Y) is not erased yet if and only if xa ≤ X and yb ≤ Y).

 

So, using dp, dp[a][b][i] (1 ≤ i ≤ 2) is the maximum score of i - th player in state (a, b) and it’s i - th player’s turn. So, consider s[a][b] is the sum of the scores of all valid points in state (a, b) and t[a][b] is the amount of them. So,

If i = 1 then, dp[a][b][i] = max(s[a][b] - dp[c][b][2]) (a ≤ c ≤ A, t[c][b] < t[a][b]).

Otherwise dp[a][b][i] = max(s[a][b] - dp[a][c][1]) (b ≤ c ≤ B, t[a][c] < t[a][b]).

So we need two backward fors for our dp and another for on i. So, now the only thing that matters is updating the dp. For this purpose, we need two more arrays QA and QB.

QA[b][1] =  the minimum value of pairs (dp[j][b][2], t[j][b]) and QA[b][2] =  minimum value of pairs (dp[j][b][2], t[j][b]) such that t[j][b] > QA[b][1].second in the states we’ve seen so far. Similarly, QB[a][1] =  the minimum value of pairs (dp[a][j][1], t[a][j]) and QB[a][2] =  minimum value of pairs (dp[a][j][1], t[a][j]) such that t[a][j] > QB[a][1].second in the states we’ve seen so far. Now updating dp is pretty easy :

dp[a][b][1] = s[a][b] - (t[a][b] ≤ QA[b][1].second?QA[b][2].first: QA[b][1].first).

dp[a][b][2] = s[a][b] - (t[a][b] ≤ QB[a][1].second?QB[a][2].first: QB[a][1].first).

And updating QA and QB is super easy.

Now, let f = dp[1][1][1] and S be the sum of scores of all points. So, the score of first player is f and the second one is S - f.

Time complexity: O(n2)

Code by sobhan.miryoosefi

Another Code by Haghani

Java Code by Zlobober

536E - Tavas on the Path Let's call the answer for vertices v and u with edges e1, e2, ..., ek on the path, score of sequence w(e1), w(e2), ..., w(ek).

Use heavy-light decomposition. Decompose the edges into chains. So, for each Query, decompose the path into subchains. After solving the problem for them, combine them. Problem for subchains is :

We have an array a1, a2, …, an and q queries. Each query gives numbers x, y, l (1 ≤ x ≤ y ≤ n) and we should print the goodness of subarray ax, ax + 1, …, ay.

 

For this problem, we have too choices: 1.Solve offline with a normal segment tree. 2.Solve online using persistent segment tree. Now, I prefer to use the first approach. Sort the array to have a permutation of 1, 2, …, n: p1, p2, …, pn and ap1 ≥ ap2 ≥ … ≥ apn. Also sort the queries in the decreasing order of l. No for i - th query (in the sorted order) we have information: x, y, l, index.

Then, use two pointers. Keep a pointer = n and Initially we have a binary string b, of length n with all indices set to 0. Then in each query:

for i = 1 to q 	while (pointer > 1 and l[i] >= a[pointer]) 		Set p[pointer]-th bit of b (from left) to 1 		pointer = pointer - 1 	answer to query number index[i] = T(bx…by) Now, we should fins T(bx…Ty). For this purpose, we need a segment tree. In each node of the segment tree, we need to keep a package named node.

struct node{ 	int p, s, cnt, tot; }; A package node is used for calculating T of a binary string c. p =  the number of leading 1s, s =  the number of trading 1s, cnt =  the total number of 1s, tot =  the T value of the binary string after deleting its leading and trading 1s.

Merging two nodes is really easy. Also after reversing c, we just need to swap p and s.

So, we can determine the node of this subarray in subchains.

After solving these offline for subchains it's time for combining.

Merge the node of subchains in the path from v to LCA(v, u) then merge the result with the reverse of the nodes of answers in the subchains in path from LCA(v, u) to u.

Time complexity: O((n + m)log2(n))

Code by PrinceOfPersia (This was one of the hardest codes I ever wrote in competitive programming :D)

Shorter Code by Haghani

Java Code by Zlobober

 

If there's any suggestion or error, just let me know.

Codeforces Round #298 (Div. 2) Editorial

By danilka.pro, 8 years ago, translation, In English 534A - Exam Is easy to see that k = n with n ≥ 4. There are many algorithms that can be used to build a correct sequence of length n with n ≥ 4. For example, students can be seated from left to right with the first to seat students with odd numbers in decreasing order starting with largest odd number. Then similary to seat students with even numbers. In this sequence the absolute difference between two adjacent odd (or even) numbers equal to 2. And the difference between odd and even numbers greater or equal 3 (because n ≥ 4).

Cases n = 1, n = 2, n = 3 are considered separately. Solution complexity — O(n).

Jury's solution: 10691992

534B - Covered Path It can be easily proved that every second i (0 ≤ i ≤ t - 1) the maximum possible speed is . You can iterate through i from 0 to t - 1 and the values of vi.

Solution complexity — O(t).

Also you can use next fact. If current speed equal to u and left t seconds then there is a way to get v2 speed at the end only if |u - v2| ≤ t·d. Consider this criteria, one can simply try to change speed to maximum possible (from u + d down to u - d), choosing first giving a way to reach the end of the path.

Jury's solutions: 10692136 и 10692160

534C - Polycarpus' Dice Solution uses next fact. With k dice d1, d2, ..., dk you can dial any sum from k to . This is easily explained by the fact that if there is a way to get the amount of s > k, then there is a way to dial the sum equal s - 1, which is obtained by decreasing the value of one die by one.

Let's denote sum of all n dice as . Fix the dice di (value on it denote as x (1 ≤ x ≤ di). Using the other dice we can select s (n - 1 ≤ s ≤ S - di). We know that average value s + x = A, and n - 1 ≤ A - x ≤ S - di, giving A - (n - 1) ≥ x ≥ A - (S - di).

Using facts described above, for every dice one can calculate a possible values segment, giving the answer for the count of impossible values of that dice. Solution asymptotic — O(n).

Jury's solution: 10692192

534D - Handshakes From here we will not consider resulting permutation but correct handshakes sequence (rearranged given sequence). Formally, the sequence of handshakes count ai is correct if and only if ai + 1 ≤ ai + 1 and ai + 1 ≡ ai + 1 ± od{m} and a1 = 0. To form correct sequence, we can use following greedy algorithm.

First, place 0 as the first number. Next, for every following number ai + 1 we will select maximum possible number from numbers left, matching above constraints (in simple case it will be ai + 1, otherwise we will check if ai - 2 left, e.t.c).

The solution may divide given sequence into three parts (depending on modulo by 30), and using, for example, data structure ''set'', quickly find the next number to place into resulting sequence. Such solution will work in . There is also possible to get O(n) asymptotics using path compression technique.

Jury's solution: 10692252

534E - Berland Local Positioning System Suppose that the bus started his way from the stop with number 1 and modulate its way during m stops. For every stop we will calculate how many times this stop was visited by the bus at that way. Check if that counts match counts in the input and update the answer if needed. Then we will try to move the start stop to stop with number 2. It's easy to see that the last visited stop (as long as bus must visit m stops) will move to the next stop. So we need to modulate bus way to another one stop from first stop and from last stop to change the starting stop to another (it makes maximum of four counts to be updated). It could be done in O(1) time.

This way we need to move starting stop to every variant (its count is equal to 2n - 2) and for every variant update the answer if needed. Average solution works in O(n) time.

Jury's solution: 10705354

534F - Simplified Nonogram This task has several solution algorithms.

One of them could be described next way. Let's divide n × m field into two parts with almost same number of columns (it will be n × k and n × (m - k)). Let's solve the puzzle for every part of the field with brute-force algorithm (considering column constraints on number of blocks) with memorization (we do not need same solutions with same number of blocks in rows). Then we will use meet-in-the-middle approach to match some left part with right part to match constraints on n × m field.

Another solution could be profile dynamic programming, where the profile is the number of blocks in the row.

Jury's solution uses both ideas: 10705343

Codeforces Round #297 (Div.2) Editorial

By fcspartakm, 8 years ago, translation, In English 525A — Vitaliy and Patty To solve this problem we need to use array cnt[]. In this array we will store number of keys of every type, which we already found in rooms, but didn't use. Answer will store in variable ans.

Now, we iterate on string. If current element of string si is lowercase letter (key), we make cnt[si]++. Else if current element of string si uppercase letter (door) and cnt[tolower(si)] > 0, we make cnt[tolower(si)]--, else we make ans++. It remains only to print ans.

Asymptotic behavior of this solution — O(|s|), where |s| — length of string s.

525B — Pasha and String At first we need to understand next fact — it doesn't matter in wich order make reverses, answer will be the same for all orders.

Let's numerate elements of string from one. To solve given problem we need to count how many reverses will begin in every position of string. Then we need to count array sum[]. In sum[i] we need to store count of reverses of substrings, which begin in positions which not exceeding i.

Now iterate for i from 1 to n / 2 and if sum[i] is odd swap si and sn - i + 1. After that it remains only to print string s.

Asymptotic behavior of this solution — O(n + m), where n — length of string s, m — count of reverses.

525C — Ilya and Sticks This problem can be solved with help of greedy. At first count array cnt[]. In cnt[i] will store how many sticks with length i we have.

Now iterate for len from maximal length of sticks to minimal. If cnt[len] is odd and we have sticks with length len - 1 (that is cnt[len - 1] > 0), make cnt[len]-- and cnt[len - 1]++. If cnt[len] is odd and we have no sticks with length len - 1 (that is cnt[len - 1] = 0), make cnt[len]--.

In this way we properly done all sawing which we need and guaranteed that all cnt[len] is even. After that iterate similary on length of sticks and greedily merge pairs from 2 sticks with the same length in fours. It will be length of sides of sought-for rectangles, left only summarize their squares in answer. In the end can left 2 sticks without pair, we must not consider them in answer.

For example, if cnt[5] = 6, cnt[4] = 4, cnt[2] = 4, we need to merge this sticks in following way — (5, 5, 5, 5), (5, 5, 4, 4), (4, 4, 2, 2). Two sticks with length 2 are left, we must not count them.

Asymptotic behavior of this solution — O(n + maxlen - minlen), where n — count of sticks, maxlen — maximal length of stick, minlen — minimal length of stick.

525D — Arthur and Walls To solve this problem we need to observe next fact. If in some square whith size 2 × 2 in given matrix there is exactly one asterisk, we must change it on dot. That is if in matrix from dots and asterisks is not square 2 × 2 in which exactly one asterisk and three dots, then all maximum size of the area from dots connected by sides represent rectangles.

Now solve the problem with help of bfs and this fact. Iterate on all asterisks in given matrix and if only this asterisk contains in some 2 × 2 square, change this asterisk on dot and put this position in queue. Than we need to write standart bfs, in which we will change asterisks on dots in all come out 2 × 2 squares with exactly one asterisk.

Asymptotic behavior of this solution — O(n * m), where n and m sizes of given matrix.

525E — Anya and Cubes To solve this problem we need to use meet-in-the-middle. At first sort given array in increasing order and divide it in two parts. In first part must be first n / 2 elements, in second part — other.

Iterate all submasks of all masks of elements from first part. That is iterate which cubes from first part we take and on which from them we paste exclamation marks. In this way we iterated all possible sums, which we can get with cubes from first part. Let for current submask we get sum sum_lf and use tlf exclamation marks. To store all such sums we use associative arrays map < long long > cnt[k + 1], where k — count of exclamation marks which we have in the beginning.

After that similary iterate all submasks of all masks of elements from second part. Let for current submask sum is sumrg and number of used exclamation marks is trg. Then from first part we need to get sum (s - sumrg) and we can use only (k - trg) exclamation marks, where s — sum which we must get by condition of the problem. Then iterate how many exclamation marks we will use in first part (let it be variable cur) and increase answer on cnt[cur][s - sumrg]. To accelerate our programm we may increase answer only if cnt[cur].count(s - sumrg) = true.

For submasks in iterate we can cut off iteration on current sum for submask (it must be less or equal to given s) and on current count of exclamation marks (it must be less or equal to given k). Also we should not paste exclamation marks on cubecs with numbers larger than 18, because 19! more than 1016 — maximal value of s.

Asymptotic behavior of this solution — O(3((n + 1) / 2) * log(maxcnt) * k), where n — count of cubes, maxcnt — maximal size of associative array, k — count of exclamation marks.

Codeforces Round #296 Editorial

By Zlobober, 8 years ago, translation, In English 527A - Playing with Paper It’s easy to see that described process is equivalent to the following loop:

while a > 0 and b > 0:     if a ⩾ b:          a = a - b     else:          b = b - a     ans = ans + 1 But such naive approach will obviously lead to verdict TLE, since it makes ~10, 2015 - 03 - 1912 operations even on the third sample test. The key idea is to replace repeating subtraction operations with integer division operations. This leads to the logarithmic-time solution that looks similar to the Euclid algorithm:

while a > 0 and b > 0:     if a ⩾ b:         ans = ans + a div b         a = a mod b     else:         ans = ans + b div a         b = b mod a 527B - Error Correct System The first observation is that the new Hamming distance may not be less than the old one minus two, since we change only two characters. So the task is to actually determine, if we can attain decrease by two, one or can’t attain decrease at all.

The decrease by two is possible if there are two positions with the same two letters in two strings but that appear in different order (like “double” <-> “bundle”).

If there are no such positions, then we just need to check that we may decrease the distance. This can be done by just “fixing” the character that stands on the wrong position, like in “permanent” <-> “pergament” (here n stands in wrong pair with m, and there is also unmatched m, so we may fix this position).

Otherwise, the answer is to keep everything as it is. Implementation can be done by keeping for each pair (x, y) of symbols position where such pair appears in S and T and then by carefully checking the conditions above.

528A - Glass Carving Obviously the largest glass piece at any moment is the one that is product of the largest horizontal segment by the largest vertical segment. One of the possible solutions is to carefully implement what described in the statement and keep all horizontal segments and all vertical segments in priority queue or std::set, or some logarithmic data structure. This solution works in .

But there is also a nice linear solution if we answer all queries in reverse order. Suppose segments are not cutting, but merging. In this case we may keep the horizontal and vertical cut lines in double-linked lists and track the current maximum (that can only increase and become equal to the newly-merged segment each time). This solution works in O(k + n + m).

528B - Clique Problem One may think that this task is about graph theory, but it after some investigation and several equivalent changes in task statement it can be reduced to the well-known greedy problem.

Initially you have that points may lie together in a set if they are not too close, i. e. |xi - xj| ≥ wi + wj. This is obviously equivalent to the following condition. Let’s consider interval of radius wi with center in point xi and call this interval to be the interval of point i. Then the statement actually says that no two such intervals should be intersecting.

This task is well-known and can be solved greedily after sorting segments in ascending order of right endpoint:

Sort segments S in ascending order of S.x + S.w

last = 0 ans = 1 for i = 1..n - 1:     if S[i].x - S[i].w ⩾ S[last].x + S[last].w:         last = i         ans = ans + 1 It’s easy to prove that this solution is correct. Among all ways to choose first k segments, the best way is the one that minimizes x-coordinate of the right endpoint of the last segment (since it restricts us in the least possible way).

528C - Data Center Drama Problem legend asks you to add minimum number of edges to the given connected undirected graph (possibly, with loops and duplicating edges) and choose direction for its edges so that both the incoming and outgoing degrees of all vertices are even.

First idea is that the resulting graph before we choose the direction (but after we added some edges) will contain Euler circuit, since all degrees are even. That’s almost what we need: if we have an Euler circuit that contains even number of edges, we may direct them like following: a <- b -> c <- d -> e … It’s easy to see that each vertex appearance in this cycle adds 2 to its ingoing or outgoing degree, so the resulting degrees will be even.

But if the Euler circuit is odd (meaning that there is odd number of edges in the graph), we must add some extra edge to the graph before we continue, the easiest way is to add a loop from vertex 0 to itself, since it doesn’t affect the Euler tour, but now tour length is even, so everything is ok.

Now we should think how to add edges optimally. It’s easy to see that the optimal way is to first fix all odd degrees of vertices (i. e. combine all odd vertices by pairs and put an edge in each pair), and then, possibly, add an extra loop as described above. The last part is to actually find an Euler circuit, and to print the answer.

528D - Fuzzy Search There were issues with this task. Intended constraints were actually n, m, k ≤ 500000, and the intended solution was using Fast Fourier Transformation, that leads to  running time. But unfortunately the statement contained wrong constraints, so we reduced input size during the tour. Nevertheless, we will add the harder version of this task and you will be able to submit it shortly.

Key idea is to reduce this task to a polynomial multiplication. Let’s solve the task in following manner. For each position i of the S for each character c from “ATGC” we will calculate match(c, i) that is equal to the number of c characters that have matching symbol in S if we put string T in position i. Then the criteria for us to have an occurrence at position i is that match(A, i) + match(T, i) + match(G, i) + match(C, i) == |T| (that means exactly that each character from T being put at position i has a corresponding character in S).

Now let’s find out how to calculate match(c, i). Let’s keep only c characters and “not c” characters in both strings and denote them by 1 and 0 respectively. Let’s also spread each 1 in string S by the distance k to the left and to the right. For example, k = 1 for the sample string AGCAATTCAT and the character A corresponding bit vector will be 111110111, and for the character C it will be 0111001110. This bitvector can be calculated in O(n) by putting two events “+1” and “-1” in string S in positions x - k and x + k for each 1 in original string S and then sweeping from left to right over the string S and processing those events.

Now our task is reduced to searching all positions where the bitvector T is the submask of the bitvector S. In constraints n, m, k ≤ 200000 this can be done by using bitsets in O(m(n - m) / 32). Nevertheless, this task can be seen as calculation of polynomials S and reversed(T) product. We will keep this as an exercise for those who decide to submit the harder version of this task.

528E - Triangles 3000 Let’s draw a bounding box that contains all intersection points. Let’s fix a triangle and consider three angles shown on the picture. Calculate area of intersection of those area with the bounding box and call this area to be the “area of an angle”. Then it’s easy to see, that those three angles are complement to the triangle itself in the bounding box, i. e. triangle area is bounding box area minus three angle areas.

 

This leads us to the idea how to solve this task by carefully calculating for each possible formed angle on the plane, how much times does it appear in total answer if we sum all values like (S - angle_area(a, b) - angle_area(b, c) - angle_area(c, a)) over all triples (a, b, c) of lines.

 

Actually, the angle is considered as many times, as many lines there are that intersect both sides of its right adjacent angle. So, our task is reduced to calculate for each angle on plane how much lines intersect its sides (i. e. its rays).

This can be done in  by fixing the first side of the angle and then adding lines in ascending order of polar angle, and then by keeping the number of lines that intersect the base line to the left and that intersect the base line to the right. Key idea is that the exact of four angles formed by the pair of lines (a, b) that is crossed by some third line c, can be determined by two numbers: its polar angle alpha and its crossing with a coordinate x. Further details are shown on the picture below.

 

There is also a nice short O(n2) solution from enot110 here.

Codeforces Round #295 Editorial (now with bonuses!)

By Endagorion, 8 years ago, In English We would like to thank the testers of this round's and Winter Computer Camp olympiad's problems: alger95, thefacetakt, adamant, -imc-, riskingh, ASverdlov.

Make sure to comment if you find any mistakes.

UPD: I've just remembered to put up the usual challenges for the problems. So, here they go.

520A - Pangram

Idea: Endagorion

Preparation: Endagorion

To check that every letter is present in the string we can just make a boolean array of size 26 and for every letter set the corresponding variable to TRUE. In the end check that there are 26 TRUEs. That is an O(n) solution. Also don't forget to change all letters to lowercase (or all to uppercase).

To make all the letters lowercase, one could use standard functions, like tolower in Python. Also, it is known that the letters from a to z have consecutive ASCII numbers, as well as A to Z; an ASCII number of symbol is ord(c) in most languages. So, to get the number of a lowercase letter in the alphabet one can use ord(c) - ord('a') in most languages, or simply c - 'a' in C++ or C (because a char in C/C++ can be treated as a number); to check if a letter is lowercase, the inequality ord('a') <= ord(c) && ord(c) <= ord('z') should be checked.

Challenge: how many pangrams of length n are there? Strings that differ only in capitalization of some letters are considered distinct. Can you find the answer modulo some prime p in linear time?

520B - Two Buttons

Idea: Endagorion

Preparation: Endagorion

The simplest solution is simply doing a breadth-first search. Construct a graph with numbers as vertices and edges leading from one number to another if an operation can be made to change one number to the other. We may note that it is never reasonable to make the number larger than 2m, so under provided limitations the graph will contain at most 2·104 vertices and 4·104 edges, and the BFS should work real fast.

There is, however, an even faster solution. The problem can be reversed as follows: we should get the number n starting from m using the operations "add 1 to the number" and "divide the number by 2 if it is even".

Suppose that at some point we perform two operations of type 1 and then one operation of type 2; but in this case one operation of type 2 and one operation of type 1 would lead to the same result, and the sequence would contain less operations then before. That reasoning implies that in an optimal answer more than one consecutive operation of type 1 is possible only if no operations of type 2 follow, that is, the only situation where it makes sense is when n is smaller than m and we just need to make it large enough. Under this constraint, there is the only correct sequence of moves: if n is smaller than m, we just add 1 until they become equal; else we divide n by 2 if it is even, or add 1 and then divide by 2 if it is odd. The length of this sequence can be found in .

Challenge: suppose we have a generalized problem: we want to get n starting from m using two operations "subtract a" and "multiply by b". Generalize the solution to find the minimal number of moves to get from n to m in  time if a and b are coprime. Can you do it if a and b may have common divisors greater than 1?

520C - DNA Alignment/521A - DNA Alignment

Idea: Endagorion

Preparation: Endagorion

What is ρ(s, t) equal to? For every character of s and every character of t there is a unique cyclic shift of t that superposes these characters (indeed, after 0, ..., n - 1 shifts the character in t occupies different positions, and one of them matches the one of the character of s); therefore, there exist n cyclic shifts of s and t that superpose these characters (the situation is symmetrical for every position of the character of s). It follows that the input in ρ from a single character ti is equal to n × (the number of characters in s equal to ti). Therefore, ρ(s, t) is maximal when every character of t occurs the maximal possible number of times in s. Simply count the number of occurences for every type of characters; the answer is Kn, where K is the number of character types that occur in s most frequently. This is an O(n) solution.

Challenge: we know that ρmax(s) = n2·C(s), where C(s) is the maximal number that any character occurs in s. How many strings s of length n with characters from an alphabet of size k have C(s) = m? Can you find an O(kn2) solution? An  solution? An  solution? Maybe even better? (Hint: the modulo should be an appropriately chosen prime number for a fast solution =)).

520D - Cubes/521B - Cubes

Idea: savinov

Preparation: savinov, sokian, zemen

Basically, the first player should maximize the lexicographical order of numbers, and the second player should minimize it. Thus, at every move the first player should choose the largest available number, and the second should choose the minimal one.

First of all, how do we check if the cube can be removed? It is impossible only if there is some cube "supported" by it (i.e., it has coordinates (x - 1, y + 1), (x, y + 1), (x + 1, y + 1)) such that our cube is the only one supporting it. This can be checked explicitly. The large coordinates' limitations do not allow us to store a simply array for that, so we should use an associative array, like a set in C++.

Now we should find the maximal/minimal number that can be removed. A simple linear search won't work fast enough, so we store another data structure containing all numbers available to remove; the structure should allow inserting, erasing and finding global minimum/maximum, so the set C++ structure fits again.

When we've made our move, some cubes may have become available or unavailable to remove. However, there is an O(1) amount of cubes we have to recheck and possibly insert/erase from our structure: the cubes (x ± 1, y) and (x ± 2, y) may have become unavailable because some higher cube has become dangerous (that is, there is a single cube supporting it), and some of the cubes (x - 1, y - 1), (x, y - 1) and (x + 1, y - 1) may have become available because our cube was the only dangerous cube that it has been supporting. Anyway, a simple recheck for these cubes will handle all the cases.

This solution is  if using the appropriate data structure.

Challenge (inspired by questions from jk_qq and RetiredAmrMahmoud): suppose that the players put the numbers from right to left, that is, from the least significant digit to the most significant. The first player still wants to maximize the resulting number, and the second wants to minimize it. If the original rules of taking cubes apply, finding the optimal strategy for the players seems intractable. Try to solve this problem in the case where all the cubes are stacked in several independent towers; that is, a cube may only be taken from the top of any tower.

520E - Pluses everywhere/521C - Pluses everywhere

Idea: Endagorion

Preparation: gchebanov, DPR-pavlin

Consider some way of placing all the pluses, and a single digit di (digits in the string are numbered starting from 0 from left to right). This digit gives input of di·10l to the total sum, where l is the distance to the nearest plus from the right, or to the end of string if there are no pluses there. If we sum up these quantities for all digits and all ways of placing the pluses, we will obtain the answer.

For a given digit di and some fixed l, how many ways are there to place the pluses? First of all, consider the case when the part containing the digit di is not last, that is, i + l < n - 1. There are n - 1 gaps to place pluses in total; the constraint about di and the distance l means that after digits di, ..., di + l - 1 there are no pluses, while after the digit di + l there should be a plus. That is, the string should look as follows:

 Here a dot means a gap without a plus, and a question mark means that it's not important whether there is a plus or not. So, out of n - 1 possible gaps there are l + 1 gaps which states are defined, and there is one plus used in these gaps. That means that the other (n - 1) - (l + 1) = n - l - 2 gaps may contain k - 1 pluses in any possible way; that is, the number of such placements is . A similar reasoning implies that if the digit di is in the last part, that is, i + l = n - 1, the number of placements is .

To sum up, the total answer is equal to

 Let us transform the sum:

 To compute these sums, we will need to know all powers of 10 up to n-th (modulo 109 + 7), along with the binomial coefficients. To compute the binomials, recall that , so it is enough to know all the numbers k! for k upto n, along with their modular inverses. Also we should use the prefix sums of di, that is, the array . The rest is simple evaluation of the above sums.

The total complexity is , because the common algorithms for modular inverses (that is, Ferma's little theorem exponentiation or solving a diophantine equation using the Euclid's algorithm) have theoritcal worst-case complexity of . However, one can utilize a neat trick for finding modular inverses for first n consecutive numbers in linear time for a total complexity of O(n); for the description of the method refer to this comment by Kaban-5 (not sure why it has a negative rating, I found this quite insightful; maybe anyone can give a proper source for this method?).

Challenge: now we want to find the sum of all expressions that are made by placing k pluses with a ≤ k ≤ b; that is, we want to find the sum of the answers for the original problem with k = a, ..., b; here a and b can be any integers with 0 ≤ a ≤ b ≤ n - 1. There is an obvious O(n2) solution: just find the answers for all k separately. Can you find a linear solution?

521D - Shop

Idea: Endagorion

Preparation: gchebanov

Suppose the only type of upgrades we have is multiplication. It doesn't even matter for the answer which particular skill we are going to multiply, so we just choose several upgrades with greatest values of bi.

Now we have additions as well; set multiplications aside for a moment. It is clear that for every skill we should choose several largest additions (maybe none). Let us sort the additions for every skill by non-increasing; now we should choose several first upgrades for each type. Now, for some skill the (non-increasing) sorted row of b's is b1, ..., bl, and the initial value of the skill is a. Now, as we have decided to take some prefix of b's, we know that if we take the upgrade bi, the value changes from a + b1 + ... + bi - 1 to a + b1 + ... + bi - 1 + bi. That is, the ratio by which the value (and the whole product of values) is going to be multiplied by is the fraction . Now, with that ratio determined unambigiously for each addition upgrade, every addition has actually become a multiplication. =) So we have to compute the ratios for all additions (that is, we sort b's for each skill separately and find the fractions), and then sort the multiplications and additions altogether by the ratio they affect the whole product with. Clearly, all multiplications should be used after all the additions are done; that is, to choose which upgrades we use we should do the ratio sorting, but the order of actual using of upgrades is: first do all the additions, then do all the multiplications.

Finally, let's deal with the assignment upgrades. Clearly, for each skill at most one assignment upgrade should be used, and if it used, it should the assignment upgrade with the largest b among all assignments for this skill. Also, if the assignment is used, it should be used before all the additions and multiplications for this skill. So, for each skill we should simply determine whether we use the largest assignment for this skill or not. However, if we use the assignment, the ratios for the additions of current skill become invalid as the starting value of a is altered.

To deal with this problem, imagine that we have first chosen some addition upgrades, and now we have to choose whether we use the assignment upgrade or not. If we do, the value of the skill changes from a + b1 + ... + bk to b + b1 + ... + bk. That is, the assignment here behaves pretty much the same way as the addition of b - a. The only difference is that once we have chosen to use the assignment, we should put it before all the additions.

That is, all largest assigments for each skill should be made into additions of b - a and processed along with all the other additions, which are, as we already know, going to become multiplications in the end. =)

Finally, the problem is reduced to sorting the ratios for all upgrades. Let us estimate the numbers in the fractions. The ratio for a multiplication is an integer up to 106; the ratio for an addition is a fraction of general form . As k can be up to 105, and bi is up to 106, the numerator and denominator of such fraction can go up to 1011. To compare fractions  and  we should compare the products ad and bc, which can go up to 1022 by our estimates. That, unfortunately, overflows built-in integer types in most languages. However, this problem can be solved by subtracting 1 from all ratios (which clearly does not change the order of ratios), so that the additions' ratios will look like . Now, the numerator is up to 106, the products in the comparison are up to 1017, which fits in 64-bit integer type in any language.

Challenge: suppose that you have to compare two fractions  and , where a, b, c, d may be up to 1018. What way would you use to do that? Can you find a simple solution that does not involve long arithmetics, floating-point number or magic built-in integer types tricks (but may perform a non-constant number of operations)?

521E - Cycling City

Idea: Endagorion

Preparation: Endagorion

We have to find two vertices in an undirected graph such that there exist three vertex- and edge-independent paths between them. This could easily be a flow problem if not for the large constraints.

First of all, we can notice that all the paths between vertices should lie in the same biconnected component of the graph. Indeed, for every simple cycle all of its edges should lie in the same biconnected component, and the three-paths system is a union of cycles. Thus, we can find all the biconnected components of the graph and try to solve the problem for each of them independently. The computing of biconnected components can be done in linear time; a neat algorithm for doing this is described in the Wikipedia article by the link above.

Now, we have a biconnected component and the same problem as before. First of all, find any cycle in this component (with a simple DFS); the only case of a biconnected component that does not contain a cycle is a single edge, which is of no interest. Suppose that no vertex of this cycle has an adjacent edge that doesn't lie in the cycle; this means the cycle is not connected to anything else in the component, so the component is this cycle itself, in which case there is clearly no solution.

Otherwise, find a vertex v with an adjacent edge e that doesn't lie in the cycle (denote it c). If we can find a path p starting with e that arrives at a cycle vertex u (different from v), then we can find three vertex-distinct paths between v and u: one path is p, and two others are halves of the initial cycle. To find p, start a DFS from the edge e that halts when it arrives to vertex of c (that is different from v) and recovers all the paths.

What if we find that no appropriate path p exists? Denote C the component traversed by the latter DFS. The DFS did not find any path between vertices of C\ {v} and c\ {v}, therefore every such path should pass through v. That means that upon deletion of v, the component C\ {v} becomes separated from all vertices of c\ {v}, which contradicts with the assumption that the component was biconnected. That reasoning proves that the DFS starting from e will always find the path p and find the answer if only a biconnected component was not a cycle nor a single edge.

Finally, we obtain that the only case when the answer is non-existent is when all the biconnected components are single edges or simple cycles, that is, the graph is a union of disconnected cactuses. Otherwise, a couple of DFS are sure to find three vertex-disjoint paths. This yields an O(n + m) solution; a few logarithmic factors for simplification here and there are also allowed.

Challenge: how many graphs G on n labeled vertices exist such that there exist two vertices of G connected by three disjoint paths? (Hint: we have already shown that it suffices to count the number of disjoint unions of cacti.) Find the answer modulo 109 + 7. Can you come up with any polynomial-time solution? An O(n3) solution? Maybe even better?

Codeforces Round #294 (Div. 2) Editorial

By BekzhanKassenov, 8 years ago, In English 519A - A and B and Chess Author: BekzhanKassenov

This problem asked to determine whose chess position is better.

Solution: Iterate over the board and count scores of both player. Then just output the answer.

Complexity: O(n2), where n is the length of the side of the board (8 here)

Code: 10083191

519B - A and B and Compilation Errors Author: ADJA

In this problem you were given three arrays. Second array is the same as the first array without one element, third array is the same as second array without first element. You were asked to find deleted elements.

Solution: I'll describe easiest solution for this problem: Let's denote a as sum of all elements of first array, b as sum of all elements of second array and c as sum of all elements of third array. Then answer is a - b and b - c

There are also some other solutions for this problem which use map, xor, etc.

Complexity: O(N)

Code: 10083248

519C - A and B and Team Training Author: ADJA

In this problem we should split n experienced participants and m newbies into teams.

Solution: Let's denote number teams with 2 experienced partisipants and 1 new participant as type1 and teams with 1 experienced participant and 2 new participants as type2. Let's fix number of teams of type1 and denote it as i. Their amount is not grater than m. Then number of teams of type2 is min(m - 2 * i, n - i). Check all possible i' and update answer.

Complexity: O(N)

Code: 10083265

519D - A and B and Interesting Substrings Author: ADJA

In this problem you were asked to find number of substrings of given string, such that each substring starts and finishes with one and the same letter and sum of weight of letters of that substring without first and last letter is zero.

Solution: Let's denote sum[i] as sum of weights of first i letters. Create 26 map < longlong, int > 's, 1 for each letter. Suppose we are on position number i and current character's map is m. Then add m[sum[i - 1]] to the answer and add sum[i] to the m.

Complexity: O(NlogN), where N — the length of input string.

Code: 10083293

519E - A and B and Lecture Rooms Author: BekzhanKassenov

In this problem we have to answer to the following queries on tree: for given pairs of vertices your program should output number of eqidistand vertices from them.

Let's denote:

dist(a, b) as distance between vertices a and b.

LCA(a, b) as lowest common ancestor of vertices a and b.

depth[a] as distance between root of the tree and vertex a.

size[a] as size of subtree of vertex a.

On each picture green nodes are equidistant nodes, blue nodes — nodes from query.

Preprocessing: Read edges of tree and build data structure for LCA (it is more convenient to use binary raise, becase we will use it further for other purposes).

Complexity: O(NlogN)

Queries:

We have to consider several cases for each query:

1) a = b. In that case answer is n.

2) dist(a, b) is odd. Then answer is 0.

3) dist(a, l) = dist(b, l), where l = LCA(a, b).

 

Find children of l, which are ancestors of a and b (let's denote them as aa and bb). Answer will be n - size[aa] - size[bb].

4) All other cases.

   

Assume that depth[a] > depth[b]. Then using binary raise find dist(a, b) / 2-th ancestor of a (let's denote it as p1), dist(a, b) / 2 - 1-th ancestor of vertex a (denote it as p2). Answer will be size[p1] - size[p2].

Complexity: O(logN) for each query, O(MlogN) for all queries.

Resulting complexity:: O(MlogN + NlogN)

Code: 10083310

Codeforces Round #293 (Div.2) Editorial

By fcspartakm, 8 years ago, translation, In English 517A — Vitaly and Strings To solve this problem we can, for example, find string next, which lexicographically next to string s and check that string next is lexicographically less than string t. If string next is lexicographically smaller than string t, print string next and finish algorithm. If string next is equal to string t print No such string.

To find string next, which lexicographically next to string s, at first we need to find maximal suffix of string s, consisting from letters 'z', change all letters 'z' in this suffix on letters 'a', and then letter before this suffix increase on one. I.e. if before suffix was letter, for example, 'd', we need to change it on letter 'e'.

Asymptotic behavior of this solution — O(|s|), where |s| — length of string s.

517B — Tanya and Postcard To solve this problem at first will count array cnt[], where cnt[c] — how many times letter c found in string t. We will count two numbers ans1 and ans2 — how many times Tanya will shouts joyfully YAY! and how many times Tanya will says WHOOPS.

Let's iterate on string s and if cnt[s[i]] > 0, then increase ans1 on one and decrease cnt[s[i]] on one.

Then let's again iterate on string s. Let c is letter which equal to s[i],but in the opposite case for it. I. e. if s[i] = 'w', then c = 'W'. Now, if cnt[c] > 0, then increase ans2 on one and decrease cnt[с] on one.

Now, print two numbers — ans1 and ans2.

Asymptotic behavior of this solution — O(|s| + |t|), where |s| — length of string s and |t| — length of string t.

517C — Anya and Smartphone To solve this problem we will store two arrays — a[] and pos[]. In array a[] will store current order of icons, i. e. in a[i] store number of application, icon which stay on position i. In array pos[] will store on which place in list stays icons, i. e. in pos[i] store in which position of array a[] stay icon of application number i. We will count answer in variable ans.

Let's iterate on applications which we need to open. Let current application has number num. Then to ans we need add (pos[num] / k + 1). Now, if icon of application number num doesn't stay on first position in list of applications, we make the following — swap a[pos[num]] and a[pos[num] - 1] and update values in array pos[] for indexes of two icons which numbers a[pos[num]] and a[pos[num] - 1] .

Asymptotic behavior of this solution — O(n + m), where n — number of applications, m — number of requests to start applications.

517D — Ilya and Escalator To solve this problem let's use dynamic programming. We will store two-dimensional array z[][] with type double. In z[i][j] will store the likelihood that after i seconds j people are on escalator.

In dynamic will be following transitions. If j = n, i. e. all n people already on escalator then we make transition z[i + 1][j] +  = z[i][j]. Else, or person number j go to escalator in i + 1 second, i. e. z[i + 1][j + 1] +  = z[i][j] * p, or person number j stays on his place, i. e. z[i + 1][j] +  = z[i][j] * (1 – p).

Now we need to count answer — it is sum on j from 0 to n inclusive z[t][j] * j.

Asymptotic behavior of this solution — O(t * n), where t — on which moment we must count answer, n — how many people stay before escalator in the beginning.

517E — Arthur and Questions At first let's take two sums a1 + a2 + ... + ak and a2 + a3 + ... + ak + 1. It is correct that a1 + a2 + ... + ak < a2 + a3 + ... + ak + 1. If move from right to left all elements apart from ak + 1, all of them will reduce and will left only a1 < ak + 1. If write further all sums we will obtain that sequence disintegrate on k disjoint chains: a1 < ak + 1 < a2k + 1 < a3k + 1..., a2 < ak + 2 < a2k + 2 < a3k + 2..., ..., ak < a2k < a3k....

We will solve the problem for every chain separately. Let's iterate on first chain and find all pair of indexes i, j (i < j), that a[i] and a[j] are numbers (not questions) in given sequence, and for all k from i + 1 to j - 1 in a[k] stay questions. All this questions we need to change on numbers so does not violate the terms of the increase and minimize sum of absolute values of this numbers.

Between indexes i and j stay j - i - 1 questions, we can change them on a[j] - a[i] - 1 numbers. If j - i - 1 > a[j] - a[i] - 1, then we need to print Incorrect sequence and finish algorithm. Else we need to change all this questions to numbers in greedy way.

Here we have several cases. Will review one case when a[i] >  = 0 and a[j] >  = 0. Let current chain (3, ?, ?, ?, 9), i = 1, j = 5. We need to change questions on numbers in the following way — (3, 4, 5, 6, 9). In other cases (when a[i] <  = 0, a[j] <  = 0 and when a[i] <  = 0, a[j] >  = 0) we need to use greedy similary to first so does not violate the terms of the increase and minimize sum of absolute values of this numbers.

Asymptotic behavior of this solution — O(n), where n — count of elements in given sequence.

517F — Pasha and Pipe At first let's count two two-dimensional arrays of prefix sums sumv[][] and sumg[][]. In sumv[i][j] store how many grids are in column j beginning from row 1 to row i. In sumg[i][j] store how many grid are in row i beginning from column 1 to column j.

Let's count ans0 — how many pipes without bending we can pave. Count how many vertical pipes — we can pave. Iterate on j from 2 to m — 1 and, if sumg[n][j] — sumg[n][0] = 0 (i. e. in this column zero grids), increase ans0 on one. Similary count number of horizontal pipes.

Let's count ans1 — how many pipes with 1 bending we can pave. We need to brute cell, in which will bending. There are four cases. Let's consider first case, others we can count similary. This case — pipe begin in left column, go to current cell in brute and then go to top row. If brute cell in row i and column j then to ans1 we need to add one, if (sumg[i][j] — sumg[i][0]) + (sumv[i][j] — sumv[0][j]) = 0.

Let's count ans2 — how many pipes with 2 bendings we can pave. Let's count how many tunes begin from top row and end in top or bottom row and add this number to ans2. Then rotate our matrix three times on 90 degrees and after every rotate add to ans2 count of pipes, which begin from top row and end in top or bottom row. Then we need divide ans2 to 2, because every pipe will count twice.

How we can count to current matrix how many pipes begin from top row and end in top or bottom row? Let's count four two-dimension arrays lf[][], rg[][], sumUp[][], sumDown[][]. If i — number of row, j — number of column of current cell, then in position (i, lf[i][j]) in matrix are nearest from left grid for cell (i, j), and in position (i, rg[i][j]) in matrix are nearest from right grid for cell (i, j). sumUp[i][j] — how many columns without grids are in submatrix from (1, 1) to (i, j) of given matrix. sumDown[i][j] — how many columns without grids are in submatrix from (i, 1) to (n, j) of given matrix. Then let's brute cell in which will be the first bending of pipe (pipe goes from top row and in this cell turned to left or to right), check, that in column j above this cell 0 grids, with help of arrays lf and rg find out as far as pipe can go to left or to right and with help of arrays sumUp and sumDown carefully update answer.

Now print number ans1 + ans2 + ans3.

Asymptotic behavior of this solution — O(n * m * const), where n — hoew many rows in given matrix, m — how many columns in given matrix, const takes different values depending on the implementation, in solution from editorial const = 10.

Codeforces Round #292 Editorial

By dreamoon_love_AA, 8 years ago, In English Thanks to johnathan79717 fo polish my words.

515-A Drazil and Date If Drazil chooses the shortest path from (0,0) to (a,b), it takes |a| + |b| steps.

So we know that all numbers less than |a| + |b| are impossible to be the number of steps that Drazil took.

Now consider when the number of steps is not less than |a| + |b|.

When Drazil arrives at (a, b), he can take two more steps such as (a, b) -> (a, b + 1) -> (a, b) to remain at the same position.

So we know that for all s such that s ≥ |a| + |b| and (s - (|a| + |b|))%2 = 0, there exists a way for Drazil to get to (a, b) in exactly s steps.

The last part we should prove is that it's impossible for Drazil to arrive at (a,b) in exactly s steps when (s - (|a| + |b|))%2 = 1.

We can color all positions (x, y) where (x + y)%2 = 0 as white and color other points as black.

After each step, the color of the position you're at always changes.

So we know that it's impossible for Drazil to get to (a, b) in odd/even steps if the color of (a, b) is white/black.

Conclusion: If s ≥ |a| + |b| and (s - (|a| + |b|))%2 = 0 print "Yes", Otherwise print "No".

Time Complexity: O(1).

author's code

515-B Drazil and His Happy Friends You may notice that Drazil invites his friends periodically, and the period of invitation patterns is at most n * m (because there are only n * m possible pairs of boys and girls).

So if no one changes from unhappy to happy in consecutive n * m days, there won't be any changes anymore since then.

We can simulate the process of having dinner until there are no status changes in consecutive n * m days.

Because there are only n+m people, it's easy to prove the simulation requires O((n + m) * n * m) days.

But in fact, the simulation takes only O(n * m) days.(More accurately, the bound is (min(n, m) + 1) * (max(n, m) - 1) )

What happens? You can do some experiments by yourself. =) (you can suppose that only one person is happy in the beginning.)

In fact, this problem can be solved in O(n + m).

Let g be the greatest common divisor of n and m. If the i-th person is happy, then all people with number x satisfying  will become happy some day because of this person.

So for each 0 ≤ i ≤ g - 1, we only need to check if there exists at least one person whose number mod g is i and is happy.

If it exists for all i, the answer is 'Yes', otherwise the answer is 'No'.

author's code

515-C Drazil and Factorial Conclusion first:

First, we transform each digit of the original number as follows:

0, 1 -> empty

2 -> 2

3 -> 3

4 -> 322

5 -> 5

6 -> 53

7 -> 7

8 -> 7222

9 -> 7332

Then, sort all digits in decreasing order as a new number, then it will be the answer.

Proof:

We can observe that our answer won't contain digits 4,6,8,9, because we can always transform digits 4,6,8,9 to more digits as in the conclusion, and it makes the number larger.

Then, how can we make sure that the result is the largest after this transformation?

We can prove the following lemma:

For any positive integer x, if it can be written as the form (2!)c2 * (3!)c3 * (5!)c5 * (7!)c7, there will be only one unique way.

Suppose that there exists two ways to write down x in this form, we can assume that the two ways are (2!)a2 * (3!)a3 * (5!)a5 * (7!)a7 and (2!)b2 * (3!)b3 * (5!)b5 * (7!)b7.

We find the largest i such that ai ≠ bi, Then we know there exists at least one prime number whose factor is different in the two ways.

But according to the Fundamental Theorem of Arithmetic, there is only one prime factorization of each integer. So we get a contradiction.

After getting the result, we don't need to worry about other numbers being larger than ours.

Time Complexity: O(n).

author's code

515-D Drazil and Tiles Again we give conclusion first:

First, view each cell as a vertex and connect two adjacent cells by an edge.

Then, build a queue and push all vertices of degree 1 in it.

Finally, in each iteration, we pop a vertex from the queue until the queue is empty. If the vertex is used, go to the next iteration. Otherwise, we put a tile on the vertex and its adjacent vertex, and erase these two vertices from the graph. If it yields a new vertex with degree 1, push it into the queue.

When the queue is empty, if there are still some cells not covered by any tiles, the answer will be "Not unique."

It's easy to understand that if we can put tiles on all cells by the above steps, the result is correct. But how about the remaining cases?

We will prove that when the degrees of all vertices are at least two, the solution is never unique.

Suppose there is at least one solution.

According to this solution, we can color those edges covered by tiles as black and color other edges as white.

We can always find a cycle without any adjacent edges having the same colors. (I'll leave it as an exercise. You should notice that the graph is a bipartite graph first.)

Then we can move the tiles from black edges to white edges.

So if there is at least one solution, there are in fact at least two solutions.

Time Complexity: O(nm)

author's code

515-E Drazil and Park There are many methods for this problem. I'll only explain the one that I used.

Let's split a circle at some point (for example between 1 and n) and draw a picture twice (i. e. 1 2 3 ... n 1 2 3 ... n), thus changing the problem from a circle to a line.

Remember that if two trees Drazil chooses are x and y, the energy he consumes is dx + dx + 1 + ... + dy - 1 + 2 * (hx + hy).

Now rewrite this formula to (d1 + d2 + ... + dy - 1 + 2 * hy) + (2 * hx - (d1 + d2 + ... + dx - 1))

Denote (d1 + d2 + ... + dk - 1 + 2 * hk) as Rk and denote (2 * hk - (d1 + d2 + ... + dk - 1)) as Lk

When a query about range [a, b] comes (The range [a, b] is where Drazil can choose, but not the range where the children are playing), it's equivalent to querying the maximum value of Lu + Rv, where u and v are in [a, b] and u < v.

Another important thing is that Lu + Rv always bigger than Lv + Ru when u < v.

So we can almost solve the problem just by finding the maximum value of Lu and Rv by RMQ separately and sum them up.

However, there is a special case: u = v, but we can handle it by making RMQ find the two maximum values.

Time Complexity: O(n + m).

author's code (implement with )

More information about RMQ: editorial from Topcoder

516-D Drazil and Morning Exercise We can use dfs twice to get the farthest distance from each node to any leaves (detail omitted here), and denote the longest distance from the i-th node to any leaves as di.

Then we choose a node with minimum value of di as the root. We will find that for any node x, dx isn't greater than dy for any node y in the subtree of node x.

Next, we solve the problem when there's only one query of L. In all valid groups of nodes, where node x is the nearest to the root, obviously we can choose all nodes with di ≤ dx + L into the group. Now we want to enumerate all nodes as the nearest node to the root. We denote the group of nodes generated from node i as Gi.

We can do it in  using dfs only once. (if the length of every edge is 1, we can do it in O(n))

Imagine that Gi will almost be as same as the union of all Gj where node j is a child of node i, but some nodes which are too far from node i are kicked out. Each node will be kicked out from the groups we considered at most once in the whole process. Now we want to know when it happens. We solve it as follows: When we do dfs, we reserve a stack to record which nodes we have visited and still need to come back to. Yes, it's just like the implementation of recursive functions. Then we can just use binary search to find the node in the stack that when we go back to it, the current node will be kicked out (the closest node with |dx - di| ≥ L).

So the time complexity of the above algorithm is 

Now we provide another algorithm with O(qnα(n) + nlog(n)) by union find. (Thanks Shik for providing this method.)

First, sort all nodes by di.

Then for each query, consider each node one by one from larger di's to smaller di's.

At the beginning, set each node as a group of its own. We also need to record how many nodes each group contains.

When handling a node x, union all groups of itself and its children. At the same time, for each node j with dj > dx + L, we minus 1 from the record of how many nodes j's group has.

By doing these, we can get the number of nodes j in x's subtree with dj <  = dx + L. That's exactly what we want to know in the last algorithm.

author's code (implement with O(qnα(n) + nlog(n))))

516-E Drazil and His Happy Friends Simplifying this question, suppose that n and m are coprime. If n and m are not coprime and the gcd of n and m is g, then we can divide all people into g groups by the values of their id mod g and find the maximum answer between them. Obviously, If there is at least one group of friends which are all unhappy in the beginning, the answer is -1.

Now we determine the last one becoming happy, for boys and girls separately.

In fact, there's an easy way to explain this problem — finding the shortest path! View all friends as points, and add another point as the source. For all friends, we will view the distance from the source as the time becoming happy. And define two types of edges.

(1)

There is a fact: If a girl x become happy in time t, then the girl (x + n)%m will become happy in time t + n. So we can build a directed edge from point x to (x + n)%m with length n. Similar for boys.

(2)

If the i-th boy/girlfriend is happy originally, we can connect it to the source with an edge of length i. At the same time, we also connect the source to i%n-th boy(i%m for girl) with an edge of length i. You can imagine that the same gender of friends form a cycle. (eg. the (i * m)%n-th boy is connected to the ((i + 1) * m)%n)-th boy for i from 0 to n - 1)

With these two types of edges, we can find that if a friend is unhappy originally, he/she will become happy at the time value which is the length of the shortest path from the source.

The only question is that there are too many points and edges!

We can solve this problem by considering only some "important" points.

Points connected by the second type of edges. Points connected to important points in 1., by the first type of edges. And we can combine some consecutive edges of the first type to a new edge. The group of edges is the maximal edges that contain deleted points.(These deleted points always form a line).

Finally we find the maximum value of the shortest path from the source to these friends which is unhappy originally in the reduced graph.

Time complexity: 

author's code

Codeforces Round #291 (Div. 2) Editorial

By Rebryk, 8 years ago, translation, In English 514A - Chewbaсca and Number Author: Rebryk

It is obvious that all the digits, which are greater than 4, need to be inverted. The only exception is 9, if it's the first digit.

Complexity: 

514B - Han Solo and Lazer Gun Author: Antoniuk

Let's run through every point, where the stormtroopers are situated. If in current point stormtroopers are still alive, let's make a shot and destroy every stormtrooper on the same line with gun and current point.

Points (x1, y1), (x2, y2), (x3, y3) are on the same line, if (x2 - x1)(y3 - y1) = (x3 - x1)(y2 - y1).

Complexity: 

514C - Watto and Mechanism Author: Rebryk

While adding a string to the set, let's count its polynomial hash and add it to an array. Then let's sort this array. Now, to know the query answer, let's try to change every symbol in the string and check with binary search if its hash can be found in the array (recounting hashes with  complexity). If the hash is found in the array, the answer is "YES", otherwise "NO".

Complexity: , where L is total length of all strings.

514D - R2D2 and Droid Army Author: Rebryk

To destroy all the droids on a segment of l to r, we need to make  shots, where cnt[i][j] — number of j-type details in i-th droid. Let's support two pointers — on the beginning and on the end of the segment, which we want to destroy all the droids on. If we can destroy droids on current segment, let's increase right border of the segment, otherwise increase left border, updating the answer after every segment change. Let's use a queue in order to find the segment maximum effectively.

Complexity: 

514E - Darth Vader and Tree Author: Antoniuk

It's easy to realize that , where dp[i] is number of vertices, which are situated on a distance i from the root, and cnt[j] is number of children, which are situated on a distance j. Answer .

Let the dynamics condition

 

Let's build a transformation matrix of 101 × 101 size

 

Now, to move to the next condition, we need to multiply A by B. So, if matrix C = A·Bx - 100, then the answer will be situated in the very right cell of this matrix. For x < 100 we'll find the answer using dynamics explained in the beginning.

In order to find Bk let's use binary power.

Complexity: 

Codeforces Round #290 Editorial

By cgy4ever, 8 years ago, In English Update 1 : here are the reference solutions for this contest:

Div2-A: http://ideone.com/JP1Ksj DIv2-B: http://ideone.com/udz3bN Div2-C / Div1-A: http://ideone.com/KVobNb Div2-D / Div1-B: http://ideone.com/7MQqOm Div2-E / Div1-C: http://ideone.com/z3FsU2 Div1-D: http://ideone.com/Y7j21a Div1-E: http://ideone.com/Orbacp Note that for Div2-E / Div1-C, it is for the harder version: we need to handle '1' in the cycle.

510A - Fox And Snake

There are 2 different ways to solve this kind of task:

First one is to simulate the movement of the snake head, and you draw '#'s on the board. The code will look like:

head = (1, 1) repeat: 	repeat m-1 times: head move to right 	repeat 2 times: head move down 	repeat 2 times: head move down 	repeat m-1 times: head move to left 	repeat 2 times: head move down 	repeat 2 times: head move down until head is out of the board Another way is to do some observation about the result, you can find this pattern:

(4k+1) / (4k+3) line: "#######" (4k+2) line: ".......#" (4k+0) line: "#......." 510B - Fox And Two Dots

This task is essentially ask if there is a cycle in an undirected graph: treat each cell as a node, and add an edge if two cells are neighborhood and have some color.

There are lots of ways to do this, for example:

Run dfs / bfs, if an edge lead you to a visited node, then there must be a cycle.

For each connected component, test if |#edges| = |#nodes| - 1, if not then there must be a cycle.

510C - Fox And Names / 512A - Fox And Names

Let's first think about what S < T can tell us: suppose S = abcxyz and T = abcuv. Then we know that S < T if and only if x < u by the definition.

So we can transform the conditions name1 < name2, name2 < name3 ... into the order of letters.

Then the question become: do we have a permutation that satisfy those conditions. It is actually the classic topological order question.

One trick in this task is that, if we have something like xy < x then there is no solution. This is not covered in pretests. :)

510D - Fox And Jumping / 512B - Fox And Jumping

This task equals to: what is the minimal sum of costs that we can select k cards, so their GCD is 1.

First observation is that: GCD(x1, x2, ..., xk) = 1 means that for any prime p, there exist i such that xi is not dividable by p. So we only care about what prime factors a number contain. (So for example, 12 -> {2, 3}, 6 -> {2, 3}, 9 -> {3]})

The second observation is: If x ≤ 109 then it has at most 9 prime factors.

So after we select one number, we only care about these 9 or less primes. Then this problem equals to set covering problem (SCP), it can be done by mask DP. It can run in about O(2^9 * n^2).

510E - Fox And Dinner / 512C - Fox And Dinner

First finding is: if a + b is a prime, then one of them is an odd number, another is an even number. (that's why we set 2 ≤ xi)

Then we could find: every odd number have exactly 2 even number as neighborhood, and every even number have exactly 2 odd number as neighborhood. And that means we need |#even| = |#odd| to have a solution.

So it looks like bipartite graph matching, but every element matched 2 elements. And in fact it can be handled by maxflow: For each odd number, we add a node on the left side and link it from source with capacity equals to 2, and for each even number, we add a node on the right side and link it to sink with capacity equals to 2. And if sum of two numbers is a prime number, we link them with capacity equals to 1.

Then we solve the max flow, it have solution if and only if maxflow = 2 * |#even|.

We can construct the answer(cycles) from the matches.

Note: Actually this task is still solvable if we allow ai = 1. But you need some clever way to deal with it. We think it is too hard so we removed this case. What do you think about this decision?

512D - Fox And Travelling

We could find that some nodes cannot be visited. And more specific, if one node is in a cycle then it cannot be visited. So what about the structure of nodes that we can visit?

Let's first find a way to get all nodes that could be visited. We can deal with this by something like biconnected decomposition, but that is not easy to implement. In fact we can use this simple method: each time we pick one node that have at most 1 neighborhood and delete it. Repeat this process until we can't do it anymore.

We could find these nodes are actually belonging to these 2 kinds: 1. A tree. 2. Rooted tree. (that means, the root is attached to a cycle)

The rooted tree case is simple: we can solve it by tree DP. The state will be dp[i][j] = the way to remove j nodes in the subtree rooted at i.

Then how to solve the unrooted tree case? The way to deal with that is to transform it into rooted case. We have 2 solution:

We select one unvisited node as the root by some rules: for example, we select one with minimal index. Then we just need to modify the DP a bit to adjust this additional condition.

We could find if the tree has n nodes and we visit k nodes in the end, then there will be max(1, n-k) ways to choose the root. That means if we choose every node as the root and sum up them, we will count this case exactly max(1, n-k) times. So we just do the rooted DP for from node n times, and divide max(1, n-k) for ans[k].

The overall complicity is O(n4), and it can be optimize into O(n3) if you like.

512E - Fox And Polygon

Triangulation of polygon is something hard to think about. So the first key observation is that, we can transform this task into operations on rooted trees!

 

One Triangulation of polygon can be mapping to one rooted tree. And the flip operation can be mapping to the rotation of trees. (It is the operation we used to balance our BST) You can find the mapping from above picture. The red lines indicate the edge that will be flipped and the nodes we rotated.

Then we should find a standard shape of the tree, and solve this task: how to rotate any tree into this standard shape?

My solution is to choose the balanced tree as standard shape. The way to do that is this: find the node that the index is the middle number, rotate it to the top(that what we did for splay tree), and do the same thing for each subtree.

It is easy to see it could work in O(nlogn) steps.

Tutorial CodeForces Round 289 (Div.2) (Second Winter Computer Camp Selection 2015)

By riadwaw, 8 years ago, translation, In English 509A - Maximum in Table

In this problem one needed to implement what was written in the statement: create matrix (two-dimensional array) using given rules and find maximal value in the table.

It is also possible to see that maximal element is always in bottom-right corner.

Easier solution with recursion also was enough to get AC:

def elem(row, col):     if row == 1 or col == 1:         return 1     return elem(row - 1, col) + elem(row, col - 1) One may see the Pascal's triangle in the given matrix and understand that answer is equal to 

Prepared by: riadwaw Author of editorial: riadwaw

509B - Painting Pebbles

Suppose there are two piles with number of pebbles differed by more than k, then there is no solution:



Now let M = max ai ≤ min ai + k = m + k. There's a way to construct correct coloring:

Chose m peebles from each pile and assign first color to them. In each pile assign different colors to all other pebbles (you may use first color once more) (It's possible bacause there are no more than k uncolored pebbles. Now there are m or m + 1 pebbles of first color and 0 or 1 pebbles of any other color in each pile.

Prepared by: Kostroma Author of editorial: riadwaw

509C - Sums of Digits

The algorithm is greedy: first, take the minimal number with sum of digits a1 — call it b1. Then, on the i-th step take bi as the minimal number with sum of digits ai, which is more than bi - 1.

It can be easily proven that this algorithm gives an optimal answer. But how to solve the subproblem: given x and y, find the minimal number with sum of digits x, which is more than y?

We use a standard approach: iterate through the digits of y from right to left, trying to increase the current digit and somehow change the digits to the right in order to reach the sum of digits equal to x. Note that if we are considering the (k + 1)-th digit from the right and increase it, we can make the sum of k least significant digits to be any number between 0 and 9k. When we find such position, that increasing a digit in it and changing the least significant digits gives us a number with sum of digits x, we stop the process and obtain the answer. Note that if k least significant digits should have sum m (where 0 ≤ m ≤ 9k), we should obtain the answer greedily, going from the right to the left and putting to the position the largest digit we can.

Let us bound the maximal length of the answer, i.e. of bn. If some bi has at least 40 digits, than we take the minimal k such that 10k ≥ bi. Than between 10k and 10k + 1 there exist numbers with any sum of digits between 1 and 9k. If k ≥ 40, than 9k ≥ 300, which is the upper bound of all bi. So, in the constraints of the problem, bi + 1 will be less than 10k + 1. Than, similarly, bi + 2 < 10k + 2 and so on. So, the length of the answer increases by no more than one after reaching the length of 40. Consequently, the maximal length of the answer can't be more than 340.

The complexity of solution is O(n·maxLen). Since n ≤ 300, maxLen ≤ 340, the solution runs much faster the time limit.

Prepared by: Endagorion Author of editorial: Kostroma

509D - Restoring Numbers

First we note that if the sequences ai and bi are a valid solution, then so are the sequences ai - P and bi + P for any integer P. This means that we can consider a1 to be equal to 0 which allows us to recover the sequence bi by simply taking the first row of the matrix. Knowing bi we can also recover ai (for example by subtracting b1 from the first column of the matrix) At this stage we allow ai and bi to contain negative numbers, which can be later fixed by adding K a sufficient amount of times. Now we consider the “error” matrix e: .

If e consists entirely of 0s, then we’ve found our solution by taking a sufficiently large K. That is: K > maxi, j(wi, j).

Otherwise, we note that ei, j = 0(modK) which implies that K is a divisor of g = gcdi, j(ei, j). The greatest such number is g itself, so all that remains is to check if g is strictly greater than all the elements of the matrix w. If that is the case, then we’ve found our solution by setting K = g. Otherwise, there’s no solution.

Prepared by: Kostroma, riadwaw Author of editorial: riadwaw

509E - Pretty Song

We first calculate the prefix sums of vowel(si) which allows to calculate the sum of vowel(si) on any substring in O(1) time.

For all m from 1 to , we will calculate the sum of simple pretinesses of all substrings of that length, let’s call it SPm. For that purpose, let’s calculate the number of times the i-th character of the string s is included in this sum.

For m = 1 and m = |s|, every character is included exactly 1 time. For m = 2 and m = |s| - 1, the first and the last character are included 1 time and all other characters are included 2 times. For m = 3 and m = |s| - 2 the first and the last character are included 1 time, the second and the pre-last character are included 2 times and all others are included 3 times, and so on.

In general, the i-th character is included min(m, |s| - m + 1, i, |s| — i + 1) times. Note that when moving from substrings of length m to substrings of length m + 1, there are 2 ways in which the sum SP can change:

If m > |s| - m + 1, then SP is decreased by the number of vowel occurrences in the substring from |s| - m + 1 to m. Otherwise, SP is increased by the number of vowel occurrences in the substring from m to |s| - m + 1. This way we can easily recalculate SPm + 1 using SPm by adding (subtracting) the number of vowel occurrences on a substring (which is done in O(1) time). The complexity of this solution is O(N).

Prepared by: zemen Author of editorial: zemen

509F - Progress Monitoring

Consider a tree with n vertices rooted at vertex 1 and let b be the pseudocode’s (DFS) resulting sequence. Then b[lv..lv + sizev - 1], represents vertex v’s subtree, where lv is the index of v in b and sizev is the size of $v$’s subtree.

Let’s solve the problem using this fact and Dynamic Programming. Let e[l, r] be the number of trees consisting of vertices a[l], a[l + 1], …, a[r] such that running DFS starting from a[l] will result in a sequence with vertices in the same order as their order in a.

The base case is when l = r and e[l, r] = 1. Otherwise,  where the sum is taken over all partitions of the segment [l + 1, r], that is, over all k;pos1, ..., posk + 1, such that l + 1 = pos1 < pos2 < ... < posk + 1 = r, 1 ≤ k ≤ r - l, a[pos1] < a[pos2] < ... < a[posk]. Each such partition represents a different way to distribute the vertices among a[l]’s children’s subtrees. A solution using this formula for calculating e[l, r] will have an exponential running time.

The final idea is to introduce d[l, r]:  = e[l - 1, r], 2 ≤ l ≤ r ≤ n. It follows that: d[l, r] =  ([statement] is equal to 1 if the statement is true, 0 otherwise) and e[l, r] = d[l + 1, r]. This way d[l, r] and e[l, r] can be calculated in linear time for any segment [l, r]. The answer to the problem is e[1, n]. Overall complexity is O(n3).

Prepared by: DPR-pavlin Author of editorial: DPR-pavlin

Codeforces Round #288 (Div.2) Editorial

By fcspartakm, 8 years ago, translation, In English 508A — Pasha and Pixels To solve this problem let's create matrix with type bool and dimensions n on m. Cell (x, y) of this matrix is true — if this cell painted in black color.

Let on move number k Pasha paints pixel in position (i, j). Then game ending on this move, if square 2 × 2 formed from black cells appears, and cell (i, j) will upper-left, upper-right, bottom-left or bottom-right of this squares. Only this squares we need to check on current move. If we haven't such squares after k moves, print 0. Asymptotic behavior of this solution — O(k), where k — number of moves.

508B — Anton and currency you all know Because of specified number is odd (that mean that last digit of this number is odd) we need to swap last digit with some even digit. How to maximize number after this swap?

If number consists only from odd digits print  - 1.

Else, we need to find first even digit, which less than last digit if we will iterate from most significant digit. If we find such digit — swap it with last digit and we have an answer.

Else, we need to find first even digit, which more than last digit if we will iterate from less significant digit. If we find such digit — swap it with last digit and we have an answer.

Asymptotic behavior of this solution — O(n), where n — count of digits in specified number.

508C — Anya and Ghosts This problem can be solved with help of greedy algorithm. Let's iterate on moments when ghosts will appears.

We need to use use array, in wich we will mark moments of time, in wich we lighted candles (for example, put in corresponding positions 1). Than for every new ghost will count how many candles lights in time of his visit from our array.

If ghost appears in moment of time wi, iterate on out array from wi - 1 to wi - t, where t — count of seconds, which candle burns, and count the number of ones. If this count is not less than r, continue iterating on ghosts. Else, iterate on our array from wi - 1 to wi - t, and, if in current second candle didn't lighted — make it, and put in this position in array 1. We need to do such operation, while count of ones in this section of our array will not be equals to r. If we can't do this fore some ghost, we can print  - 1.

Answer to this problem — count of ones in our array. Asymptotic behavior of this solution — O(mt), where m — count of ghosts, t — the duration of a candle's burning.

508D — Tanya and Password At first, let's convert data from input in directed graph. Vertexes in this graph will all strings with length equals to 2 and consisting of uppercase and lowercase letters of the latin alphabet. For all 3-letters strings from input — si's, let's add edge from vertex si[0]si[1] to si[1]si[2].

Now we need to find in this graph Euler path. For this we can use Fleury's algorithm. It is worth noting, that Euler path consists, if count of vertexes, in wich in-degree and out-degree differs by one, less then 3, and in-degree and out-degree of others vertexes — even. If we can't find Euler path — print NO. Asymptotic behavior of this solution — O(m), where m — count of different 3-letters strings from input. It equals to number of edges in graphs.

508E — Arthur and Brackets This problem can be solved with help of dynamic dynamic programming. Let's create squre matrix Z with sizes n × n, where n — count of open brackets in sequence. Main hint — if open bracket is in position l, and corresponding for her close bracket — in position r, than from position l + 1 to position r - 1 must stay a regular bracket sequence.

In array Z first parametr lf — number of open bracket, second parametr rg — number of last open bracket, which can be in a regular bracket sequence, which will exists between open bracket with number lf and corresponding for it close bracket.

Z[lf][rg] = true if it is possible to construct such sequence. Otherwise Z[lf][rg] = false.

For current lf and rg let's iterate on cnt — how many open brackets and corresponding them close brackets in a regular bracket sequence will stay between open bracket number lf and corresponding for it close bracket. If this count falls in the given interval for open bracket lf, recurcively run dynamic from two segments — (lf + 1, lf + cnt) and (lf + cnt + 1, rg).

If for both segments we can construct regular bracket sequences, appropriate to data-in from input, put in Z[lf][rg] value true. To restore answer, we must move from segment (lf, rg) in segments (lf + 1, lf + cnt) and (lf + cnt + 1, rg), if for both this segments we can construct regular bracket sequences and recursively restore asnwer. If Z[0][n - 1] equals to false, print IMPOSSIBLE. Asymptotic behavior of this solution — O(n3).

UPD This problem can be solved with help of griddy algorithm. Asymptotic behavior of this solution — O(n). Here is example of such solution, participant matrix.

Codeforces Round #287 (Div. 2) Editorial

By RetiredAmrMahmoud, 8 years ago, In English 507A - Amr and Music Problem: We have to split the number k into maximum number of elements of ai such that their sum is less than or equal to k.

Hint: To maximize the answer we have to split the number into the smallest numbers possible.

Solution: So and since the limits are small we can pick up the smallest element of the array and subtract it from k, and we keep doing this n times or until the smallest number is larger than k. Another solution is to sort the array in non-decreasing order and go on the same way.

Time complexity:  or 

Implementation: 9529124 .

507B - Amr and Pins Problem: We have a circle with radius R at position (x, y) and we want to move it to (x', y') with minimum moves possible. A move is to choose an arbitrary point on the border of the circle and rotate the circle around it with arbitrary angle.

Hint: What is the shortest path between two points? A direct line. So moving the center on that line with maximum move possible each time will guarantee minimal number of moves.

Solution: Let's draw a straight line between the two centers.

 

Clearly to move the center with maximum distance we need to rotate it around the intersection of the line and the circle with 180 degrees. So the maximum distance we can move the center each time is 2 * R. Let's continue moving the center with 2 * R distance each time until the two circles intersects. Now obviously we can make the center moves into its final position by rotating it around one of the intersection points of the two circles until it reaches the final destination.

 

Every time we make the circle moves 2 * R times except the last move it'll be  ≤ 2 * R. Assume that the initial distance between the two points is d So the solution to the problem will be .

Time complexity: 

You have to be careful of precision errors. Here is a code that used only integer arithmetic operations 9529147.

507C - Guess Your Way Out! Hint: Simulate the algorithm until we reach a leaf node assume that it's not the exit. Now the question is Are there some nodes that are guaranteed to be visited before trying to reach the exit again?

Solution: The first observation is that in order to return to a parent we will have to visit all nodes of the right or the left subtree of some node first. Now imagine we are in the situation below where E is the exit.

 

By applying the algorithm we'll reach node X. Both the E and X are in different subtrees of the root. Which means before going to the proper subtree in which the Exit exists we'll have to visit all the nodes of the left subtree (marked in red).

This means we have to get the node which the Exit and the current leaf node X are in different subtrees which will be the least common ancestor (LCA) of the two nodes. Assume the subtree height is h1. This means we visited  node. By adding the nodes above the subtree which we visited during executing the string for the first time the total number of visited nodes will be . Now let's go to the other subtree. Obviously we don't need any other nodes except this subtree. So let's do the same we did to the original tree to this subtree. Execute the algorithm until we reach a leaf node, get the LCA, add to the solution  where h2 is the height of the subtree of the LCA node where the leaf node exists. And so on we keep applying the rules until after executing the algorithm we will reach the exit.

Also we can do the same operations in O(h) by beginning to move from the root, if the exit is located to the left we go to the left and ans++ and then set the next command to 'R' else if it is located to the right we will visited the whole left subtree so we add the left subtree nodes to the answer  and then set the next command to 'L' and so on.

Time complexity:  or 

Challenge: What if the pattern is given as an input (e.g. "LRRLLRRRLRLRLRR..."), How can this problem be solved?

Implementation: 9529181

507D - The Maths Lecture Hint: Dynamic programming problem. To handle repetitions we have to construct the number from right to the left and calculate the answer when we reach a number equivalent to 0 modulo k.

Solution: Let's define  as a recursive functions calculates the number of numbers consisting of n digits satisfying the conditions of the problem and with a specific suffix of length i Si such that .

We want to avoid repetition so by constructing the number from the right to the left when we reach a state with j = 0 with suffix  ≠ 0 we return the answer immediately so any other suffix that contains this suffix won't b calculated.

So the base cases are , .

So state transitions will be  (We add a digit to the left).

And we can handle j = 0 case coming from a zero suffix easily with a boolean variable we set to true when we use a digit  ≠ 0 in constructing the number.

Time complexity: 

Implementation: 9529210

507E - Breaking Good Hint: Consider we've chosen a certain path with length d where d is the length of the shortest path from 1 to n and it has x edges that are working. Assume that y is the total number of edges that are working in the whole country. So we need to make d - x changes (to make the malfunctioning edges on the path work) and y - x changes (to blow up all other edges that don't lie on the path). So we will totally make d + y - 2 * x changes where d and y are constants. So the optimal solution will depend only on number of working edges along the path. So we'll have to maximize this number!

Solution: We will use dynamic programming on all nodes that lies on some shortest path. In other words, every node x that satisfies that the shortest path from 1 to x + the shortest path from x to n equals d where d is the length of the shortest path from 1 to n. Let's define Max[x] is the maximum number of working edges along some shortest path from 1 to x. We can calculate the value Max[x] for all nodes by dynamic programming by traversing the nodes in order of increasing shortest path from node 1. So at the end we'll make d + y - 2 * Max[n] changes. We can get them easily by retrieving the chosen optimal path.

Time complexity: 

Implementation: 9529272

Codeforces Round #286 Editorial (Complete)

By evima, 8 years ago, In English Edit (Jan 22, 2:45 AM UTC): Added Div1E and the editorial is now complete. I am sorry for the delay.

Edit (Jan 21, 9:45 AM UTC): Added the explanation for Div1C/2E, and the problem setters' codes. Div1E will need several more hours. Thank you again for your patience.

First, here are some statistics on this round:

Division	Registrants	Participants	A Accepted	B Accepted	C Accepted	D Accepted	E Accepted 1	1364	572 (*)	294	199	8	113	1 (Estimated number of AC by me)	800 (wrong)	500 (wrong)	70 (FAIL)	90 (ok)	5 (wrong) 2	4016	2028	1355	945	41	5	0 (*) Where did the remaining 792 people go? :)

We are sorry for terribly underestimating the difficulty of the problems (except Div1D), especially Div1A/2C and Div1C/2E.

 Div.2 A: 505A - Mr. Kitayuta's Gift [Problem] Given a string, turn it into a palindrome by inserting one letter or state that it is impossible.

(Problem by evima)

Since the string is short (at most 10 characters), you can simply try every possible way of inserting a letter ("where" and "what" to insert), and check if the resulting string is a palindrome.

The writer's code (C++): 9501249 Note: For some strange reason, we (contest managers) cannot submit solutions so that everyone can see them. PraveenDhinwa told us how to do so. Thank you!



Div.2 B: 505B - Mr. Kitayuta's Colorful Graph [Problem] Given an undirected graph whose edges are painted in colors, process the queries of the following form:

Given two vertices ui and vi, find the number of the colors that satisfies the following condition: the edges of that color connect ui and vi (possibly indirectly). (Problem by hogloid)

Since neither the graph nor the number of queries is too large, for each query you can simply count the number of the "good" colors (the colors that satisfies the condition) by checking if each color is "good". To do that, you can perform Depth First Search (or Breadth First Search) and verify whether you can reach vi from ui traversing only the edges of that color. If you prefer using Union-Find, it will also do the job.

The writer's code (DFS, C++) The writer's code (Union-Find, C++)



Div.2 C / Div.1 A: 505C - Mr. Kitayuta, the Treasure Hunter [Problem] Since it is hard to summarize this problem, please refer to the official statement.

(Problem by yosupo)

Below is the explanation from yosupo, translated by me.

[From here]

Let m be the number of the islands (that is, 30001). First, let us describe a solution with time and memory complexity of O(m2).

We will apply Dynamic Programming. let dp[i][j] be the number of the gems that Mr. Kitayuta can collect after he jumps to island i, when the length of his previous jump is j (let us assume that he have not collect the gems on island i). Then, you can calculate the values of the table dp by the following:

dp[i][j] = 0, if i ≥ m (actually these islands do not exist, but we can suppose that they exist and when Mr. Kitayuta jumps to these islands, he stops jumping) dp[i][j] =  (the number of the gems on island i)  + max(dp[i + j][j], dp[i + j + 1][j + 1]), if i < m, j = 1 (he cannot perform a jump of length 0) dp[i][j] =  (the number of the gems on island i)  + max(dp[i + j - 1][j - 1], dp[i + j][j], dp[i + j + 1][j + 1]), if i < m, j ≥ 2 This solution is unfeasible in terms of both time and memory. However, the following observation makes it an Accepted solution: there are only 491 values of j that we have to consider, which are d - 245, d - 244, d - 243, ..., d + 244 and d + 245.

Why? First, let us find the upper bound of j. Suppose Mr. Kitayuta always performs the "l + 1" jump (l: the length of the previous jump). Then, he will reach the end of the islands before he performs a jump of length d + 246, because d + (d + 1) + (d + 2) + ... + (d + 245) ≥ 1 + 2 + ... + 245 = 245·(245 + 1) / 2 = 30135 > 30000. Thus, he will never be able to perform a jump of length d + 246 or longer.

Next, let us consider the lower bound of j in a similar way. If d ≤ 246, then obviously he will not be able to perform a jump of length d - 246 or shorter, because the length of a jump must be positive. Suppose Mr. Kitayuta always performs the "l - 1" jump, where d ≥ 247. Then, again he will reach the end of the islands before he performs a jump of length d - 246, because d + (d - 1) + (d - 2) + ... + (d - 245) ≥ 245 + 244 + ... + 1 = 245·(245 + 1) / 2 = 30135 > 30000. Thus, he will never be able to perform a jump of length d - 246 or shorter.

Therefore, we have obtained a working solution: similar to the O(m2) one, but we will only consider the value of j between d - 245 and d + 245. The time and memory complexity of this solution will be O(m1.5), since the value "245" is slightly larger than .

This solution can be implemented by, for example, using a "normal" two dimensional array with a offset like this: dp[i][j - offset]. The time limit is set tight in order to fail most of naive solutions with search using std::map or something, so using hash maps (unordered_map) will be risky although the complexity will be the same as the described solution.

[End]

The writer's code (memoized recursion, C++)



Div.2 D / Div.1 B: 505D - Mr. Kitayuta's Technology [Problem] Given an integer n and m pairs of integers (ai, bi) (1 ≤ ai, bi ≤ n), find the minimum number of edges in a directed graph that satisfies the following condition:

For each i, there exists a path from vertex ai to vertex bi. (Problem from evima)

Let G1 be the directed graph built from the input, and G2 be a directed graph that satisfies the given conditions. What we seek is the minimum number of edges in G2. Also, we say that two vertices u and v in a directed graph are "weakly connected" if we can reach v from u by traversing edges, not considering their directions.

If a pair (u, v) is present in the input, then vertices u and v must be weakly connected in G2. Therefore, for each weakly connected component (abbreviated to wcc) in G1, the vertices in that component must also be in the same wcc in G2. We can "merge" multiple wccs in G1 and create a larger wcc in G2, but for now, let us find the minimum number of edges required in G2 for each wcc in G1 when we do not "merge" them. There are two cases to consider:

If a wcc in G1 does not have cycles, then we can perform topological sort on that wcc, and we can make a "chain" (see the image below) using the topological order to satisfy the conditions. We need (the number of the vertices in the wcc)  - 1 edges, which is the minimum required number since any connected graph with V vertices has at least V - 1 edges.   If a wcc in G1 has cycles, then topological sort cannot be applied. We need at least (the number of the vertices in the wcc) edges this time, since any connected graph with V vertices and V - 1 edges is a tree, which does not contain cycles. Actually, this number (the number of the vertices in the wcc) is always achievable by connecting the vertices into a "ring" (see the image below), thus it is the minimum required number that we seek.   We have found the minimum required number of edges for each wcc in G1 when we do not "merge" them. Let us show that "merging" wccs in G1 do not reduce the number of required edges. Suppose we combine k( > 1) wccs C1, C2, ..., Ck in G1 into one wcc C in G2. Again, there are two cases to consider:

If none of C1, C2, ..., Ck contains cycles, then C will need |C1| + |C2| + ... + |Ck| - 1 edges. However, if we do not combine them, we will only need (|C1| - 1) + (|C2| - 1) + ... + (|Ck| - 1) edges in total, which is fewer. If some of C1, C2, ..., Ck contain cycles, then C will need |C1| + |C2| + ... + |Ck| edges. However, if we do not combine them, we will need (|C1| - noCycles(C1)) + (|C2| - noCycles(C2)) + ... + (|Ck| - noCycles(Ck)  ≤ |C1| + |C2| + ... + |Ck| edges (here, noCycles(Ci) is 1 if Ci do not contain cycles, otherwise 0), thus combining them does not reduce the number of required edges. Thus, we do not need to combine multiple wccs into one wcc in G2 in order to obtain the optimal solution. That is, the final answer to the problem is the sum of the minimum required number of edges for each wcc in G1, when they are considered separately.

As for the implementation, detecting cycles in a directed graph with 105 vertices and edges might be a problem if this is your first encounter with it. One possible way is to paste a code that decomposes a graph into strongly connected components. If the size of a strongly connected component is more than one, then that means the component contains cycles.

The writer's code (strongly connected component decomposition, C++): 9501202



Div.2 E / Div.1 C: 505E - Mr. Kitayuta vs. Bamboos [Problem] Since it is hard to summarize this problem, please refer to the official statement.

(Problem from yosupo)

Below is the explanation from yosupo, translated by me.

[From here]

Let us begin by applying Binary Search. The problem becomes: "is it possible that all the bamboos are at most X meters after m days?" It is complicated by the fact that the height does not become negative; the excessive decrease will be wasted. We have found two approaches to this problem.

Solution 1 Mr. Kitayuta must beat the i-th bamboo at least max(0, ⌈(hi + m·ai - X) / P⌉) times (let this number ti). Actually, it is not necessary for him to beat it more than this number of times. Thus, let us assume that he beat the i-th bamboo exactly ti times. Also, for each j (1 ≤ j ≤ ti), find the day di, j such that, if the j-th beat on the i-th bamboo is performed before day di, it will be no longer possible to keep the i-th bamboo's height after m days at most X (it can be found by doing simple math). If Mr. Kitayuta can beat the bamboos under this constraint, all the bamboos' heights will become X meters or less after m days. Otherwise, some bamboos' heights will exceed X meters.

The time complexity of this solution will be , if we first calculate only ti, then if the sum of ti exceeds km, we skip finding di, j (the answer is "NO").

Solution 2 This problem becomes simpler if we simulate Mr. Kitayuta's fight backwards, that is, from day m to day 1. It looks like this:

[Problem'] There are n bamboos. At the moment, the height of the i-th bamboo is X meters, and it shrinks ai meters at the beginning of each day. Mr. Kitayuta will play a game. He can use Magic Hammer at most k times per day to increase the height of a bamboo by p meters. If some bamboo's height becomes negative at any moment, he will lose the game immediately. Also, in order for him to win the game, the i-th bamboo's height must be at least hi meters after m days. Is victory possible?

Below is an illustration of this "reverse simulation":

  This version is simpler because he is increasing the heights instead of decreasing, thus we do not need to take into account the "excessive decrease beyond 0 meters" which will be wasted. Let us consider an optimal strategy. If there exist bamboos whose heights would become negative after day m, he should beat the one that is the earliest to make him lose. Otherwise, he can choose any bamboo whose height would be less than hi meters after day m. Repeat beating the bamboos following this strategy, and see if he can actually claim victory.

The writer's implementation of this solution uses a priority queue, and its time complexity is .

[End]

The tester's code (Solution 1, C++): 9501229 The writer's code (Solution 2, C++)





Div.1 D: 506D - Mr. Kitayuta's Colorful Graph [Problem] Given an undirected graph whose edges are painted in colors, process the queries of the following form:

Given two vertices ui and vi, find the number of the colors that satisfies the following condition: the edges of that color connect ui and vi (possibly indirectly). Note: this is the exact same problem as Div.2 B except the constraints, which are 105 instead of 100.

(Problem from hogloid)

Below is the explanation from hogloid.

[From here]

For each color, make a new graph that consists of the edges of the color and vertices connected by the edges. Make UnionFind for each graph, and you can check whether a color connects vertex A and B , using it. For each query, find a vertex which has smaller degree(let this vertex A, and the other vertex B) For each colors such that a edge of the color connects to A, check whether A and B is connected by the color. After answering the query, memorize its tuple — (A, B, answer). If the same query is requested, answer using this information.

This will lead to  solution.

For each query, the complexity is  (For each color connects A, find a vertex of B of the color & check whether they are connected) The queries that require longest computing time are, to ask every pair among  vertices which have largest degrees. Let the indices of the  vertices be , and degrees of the  vertices be d1, d2, ...dk. Now, let's fix vertex B as i. The total computing time of the queries such that B is vertex i is  . Vertex B can vary from 2 to k. Hence, the total complexity is at most . This complexity is at most .

By the way, in C++, using unordered_map, total complexity would be .

[End]

There will be many other solutions. I will briefly explain one of them which I think is typical.

Let ci be the number of colors of the edges incident to vertex i. The sum of all ci does not exceed 2m since each edge increases this sum by at most 2. Thus, there will be at most 450 values of i such that ci ≥ 450 (let B = 450). We will call these vertices large, and the remaining ones small. Using O(m / B·m) = O(m2 / B) time and memory, we can precalculate and store the answer for all the possible queries where at least one of ui and vi is large, then we can immediately answer these queries. For the remaining queries, both ui and vi will be small, therefore it is enough to directly count the color that connects vertices ui and vi in O(B) time. The total time required will be O(m2 / B + Bq). If we choose , we can solve the problem in  time.

The writer's code (the first solution, C++) The tester's code (the second solution, C++): 9501240



Div.1 E: 506E - Mr. Kitayuta's Gift [Problem] Given a string s and an integer n, find the number of the palindromes that can be obtained by inserting exactly n letters into s.

Note: Div.2 A is a similar problem, where n is fixed to 1.

(Problem from evima)

First of all, let us note that we are asked to count the resulting palindromes, not the ways to obtain them. For example, if we are to insert "b" into "abba", there are 5 possible positions, but only 3 strings will be produced ("babba", "abbba" and "abbab"). Rather than trying to count the ways of inserting a letter n times and removing the duplicated results, we should directly count the resulting palindrome. To do that, let us reformulate the problem:

[Problem'] Given a string s and an integer n, find the number of the palindromes of length |s| + n (let this number be N) that contains s as a subsequence (not necessarily contiguous).

Consider constructing a palindrome from both ends, and matching it to s from both left and right. For example, let s = "abaac" and N = 11. Let us call the final resulting string t. We first decide what letter to use as t1 and t11 (they must be equal in order for t to be a palindrome). Let us say 'c' is chosen. Now, we have to construct the remaining part of t, that is, t2..t10, so that t2..t10 contains "abaa" as a substring (note that the 'c' at the end of s is discarded). Again, we decide what letter to use as t2 and t10. This time we choose 'a'. Then, we have to construct t3..t9, so that it contains "ba" as a substring (this time the two 'a's at the both ends of s are discarded). We choose t3 = t9 = 'c'. Next, we construct t4..t8, so that it contains "ba" as a substring (this time s remains unchanged). We choose t4 = t8 = 'b'. Then, we construct t5..t7, so that it contains "a" as a substring. We choose t5 = t7 = 'a' (it is becoming repetitive, isn't it?). The last part of t, that is, t6, has no restriction (this time we choose a letter for only one position of t, not two). We choose 'd', and we have obtained a palindrome "cacbadabcac" that contains s = "abaac" as a subsequence.

This problem is mostly about analyzing this process carefully.

The most naive solution other than literally enumerating all palindromes of length N would be the following Dynamic Programming: let dp[i][left][right] be the number of the palindromes t that can be obtained if you have already decided the leftmost and the rightmost i letters (2i in total), and the substring sleftsleft + 1..sright of s remains unmatched. Each value in this table can be computed in O(1) time. Of course, since i can be up to ⌊n / 2⌋ (n ≤ 109), this solution is far from our goal.

Notice that the transitions from dp[i] to dp[i + 1] are the same regardless of i, thus we can calculate the table by matrix exponentiation. However, since there are O(|s|2) possible pairs for (left, right), we will need  time, which is actually worse than the naive calculation considering that |s| can be up to 200.

This is where we need to observe the process which we have gone through at the beginning more carefully. Let us build a automaton corresponding to the process (the image below).

  (*) An self-loop with a number means that there are actually that number of edges. A process of producing a palindrome of length N that contains s as a subsequence corresponds to a path of length ⌈N / 2⌉ from the upper-right vertex to the lower-left vertex. Each red vertex has 24 self-loops since the letters at the both ends of the remaining part of s is different, which correspond to two non-self-loop transitions. Similarly, each green vertex has 25 self-loops since the first letter and the last letter of the remaining string is the same, and the blue vertex, the destination, has 26 self-loops, as there are no more non-self-loop transitions available.

Here is an important fact: there are not so many possible combination of (n24, n25), where n24 and n25 are the number of times a path from START to GOAL visits a red vertex (with 24 self-loops) and a green vertex (with 25 self-loops), respectively. Why? Each time we leave a red vertex, the length of the remaining unmatched part of s decreases by 1, since exactly one of the two letters at the ends of the remaining part is matched and discarded. Similarly, each time we leave a green vertex, the length of the remaining string decreases by 2, since both of the two letters at the ends are matched and discarded. There is a exception, however: if the length of the remaining string is 1, then it will be a green vertex, but in this case the length will decrease by 1. Thus, for any path from START to GOAL, n24 + 2·n25 will be equal to either |s| or |s| + 1. If we fix n24, then n25 will be uniquely determined by n25 = ⌈(|s| - n24) / 2⌉. Since n24 can only take the value between 0 and |s| - 1, there are at most |s| possible pairs of (n24, n25).

With this fact, we are ready to count the paths: let us classify them by the value of n24. For each possible pair of (n24, n25), let us count the number of corresponding paths. To do that, we divide each paths into two parts: first we count the number of paths from START to GOAL, using only non-self-loop transitions. Then, we count the ways of inserting self-loop transitions into each of these paths. The product of these two numbers will be the number that we seek.

The first part is straightforward to solve: let dp[left][right][n24] be the number of paths from the vertex that corresponds to the substring sleftsleft + 1..sright, visiting exactly n24 red vertices using only non-self-loop transitions. Each value of the table can be found in O(1) time, thus the whole table can be computed in O(|s|3) time, which is fast enough for the input size (|s| ≤ 200).

The main obstacle will be the second part. For example, let us consider the case where s = "abaac", N = 11, n24 = 2, which corresponds to the example at the beginning. From the fact we found earlier, n25 = ⌈(|s| - n24) / 2⌉ = ⌈(5 - 2) / 2⌉ = 2. Thus, we have to insert ⌈N / 2⌉ - n24 - n25 = 6 - 2 - 2 = 2 self-loop transitions into this path (the image):

  The order in which red, green and blue vertices appears in this path does not affect the number of ways of insertion, and can be arbitrary. The number of ways to insert 2 self-loop transitions will be equal to the number of the path of length ⌈N / 2⌉ = 6 from START to GOAL in this automaton (we have to take into account the non-self-loop transitions in it), which can be calculated by matrix exponentiation.

Are we done? No! Consider the case s = "abbb..(|s| - 1 times)..bb". There are |s| - 1 possible values of n24 (n24 = 1 corresponds to the case where you match and discard the 'a' first, and n24 = |s| - 1 corresponds to the case where you keep the 'a' until s becomes "ab"). Thus, you need to perform matrix exponentiation |s| - 1 times, which results in a total of  time, which will be too much under the given constraints.

There is still hope, though, and here is the climax. Notice that these automata are very similar to each other, and they differ only in the number of the red and green vertices. We can combine these automata into one larger automaton like this (the image):

  The combined automaton should have |s| - 1 red, ⌈|s| / 2⌉ green and ⌈|s| / 2⌉ blue vertices. By performing matrix exponentiation on this automaton instead of many small automata, we can find all the required value in  time, which should be enough. We recommend speeding up matrix multiplication by noticing that the matrix will be upper triangular (6 times faster on paper), since the time limit is not so generous (in order to reject  solutions).

The problem is almost solved, but there is one more challenge. When N is odd, the situation becomes a little complicated: as we have seen at the beginning, in the last (⌈N / 2⌉-th) step of producing a palindrome we choose a letter for only one position of the resulting string, that is, the center of that string. In other words, the last transition in the path in the automaton we have first built must not be one from a green vertex with a string of length 2 (for example, "aa") to GOAL.

Let us find the number of the paths that violates this condition and subtract it from the answer. As previously mentioned, for each path n24 + 2·n25 will be equal to either |s| or |s| + 1, and if we fix the value of n24, n25 will be uniquely determined by n25 = ⌈(|s| - n24) / 2⌉. If |s| - n24 is odd, then it means that the last non-self-loop transition is one from a green vertex with a string of length 1, therefore in this case no path will violate the condition. If |s| - n24 is even, then the last non-self-loop trantision is from a green vertex with a string of length 2, thus the paths that does not contain the self-loop from GOAL to itself violate the condition. It will be equal to the number of the paths of length ⌈N / 2⌉ - 1 from START to the vertex just before GOAL, which can be found in a similar way to the second part of the solution.

The journey has finally come to an end. Actually, it is also possible to solve this problem in  time without matrix exponentiation, but this margin is too small to explain it. I will just paste the link to the code.

The writer's code (matrix exponentiation, C++): 9501164 The writer's code (without matrix exponentiation, C++): 9501177

Congratulations again to Petr who was the only participant to solve this problem in 108 minutes. Also, I would like to give a special mention to rng_58, who was VERY close to solving it in only 63 minutes. He was just one byte away from getting AC (compare 9460984 and 9465440)!



If you find a possible error, or have a question, please feel free to ask here. Alternative solutions are also welcome.

Codeforces Round #285 Editorial

By savinov, 8 years ago, translation, In English 501A - Contest

In this problem one need to determine the number of points for both guys and find out who got more points.

Time complexity: O(1).

501B - Misha and Changing Handles

The problem can be formulated as follows: The directed graph is given, its vertices correspond to users' handles and edges — to requests. It consists of a number of chains, so every vertex ingoing and outgoing degree doesn't exceed one. One need to find number of chains and first and last vertices of every chain. The arcs of this graph can be stored in dictionary(one can use std::map\unoredered_map in C++ and TreeMap\HashMap in Java) with head of the arc as the key and the tail as the value.

Each zero ingoing degree vertex corresponds to unique user as well as first vertex of some chain. We should iterate from such vertices through the arcs while it's possible. Thus we find relation between first and last vertices in the chain as well as relation between the original and the new handle of some user.

You can see my solution for details.

Time complexity: .

504A - Misha and Forest

Note that every non-empty forest has a leaf(vertex of degree 1). Let's remove edges one by one and maintain actual values (degreev, sv) as long as graph is not empty. To do so, we can maintain the queue(or stack) of the leaves. On every iteration we dequeue vertex v and remove edge (v, sv) and update values for vertex sv: degreesv -= 1 and ssv ^= v. If degree of vertex sv becomes equal to 1, we enqueue it.

When dequeued vertex has zero degree, just ignore it because we have already removed all edges of corresponding tree.

You can see my solution for details.

Time complexity: O(n)

504B - Misha and Permutations Summation

To solve the problem, one need to be able to find the index of given permutation in lexicographical order and permutation by its index. We will store indices in factorial number system. Thus number x is represented as . You can find the rules of the transform here.

To make the transform, you may need to use data structures such as binary search tree or binary indexed tree (for maintaining queries of finding k-th number in the set and finding the amount of numbers less than given one).

So, one need to get indices of the permutations, to sum them modulo n! and make inverse transform. You can read any accepted solution for better understanding.

Time complexity:  or .

504C - Misha and Palindrome Degree

Note that if the amount of elements, which number of occurrences is odd, is greater than one, the answer is zero. On the other hand, if array is the palindrome, answer is .

Let's cut equal elements from the end and the beginning of array while it is possible. Let's call remaining array as b and its length as m. We are interested in segments [l, r] which cover some prefix or suffix of b.

We need to find the minimum length of such prefix and suffix. Prefix and suffix can overlap the middle of b and these cases are needed to maintain. To find minimum length you can use binary search or simply iterating over array and storing the amount of every element to the left and right from the current index. Let's call minimum length of prefix as pref and as suf of suffix. So .

Time complexity: O(n) or .

504D - Misha and XOR

Firstly, we convert each number into a binary system: it can be done in O(MAXBITS2), where MAXBITS ≤ 2000 with rather small constant(we store number in system with big radix).

To solve the problem we need to modify Gauss elimination algorithm. For each row we should store set of row's indices which we already XORed this row to get row echelon form (we can store it in bitset), also for each bit i we store index p[i] of row, which lowest set bit is i in row echelon form.

Maintaining the query we try to reset bits from lowest to highest using array p and save information, which rows were XORed with current number. If we can reset whole number, the answer is positive and we know indices of answer. We update array p, otherwise.

Time complexity: O(m × MAXBITS × (MAXBITS + m)) with small constant due to bit compression.

504E - Misha and LCP on Tree

Let's build heavy-light decomposition of given tree and write all strings corresponding to heavy paths one by one in one string T, every path should be written twice: in the direct and reverse order.

Maintaining query we can split paths (a, b) и (c, d) into parts, which completely belongs to some heavy paths. There can be at most  such parts. Note that every part corresponds to some substring of T.

Now we only need to find longest common prefix of two substrings in string T. It can be done building suffix array of string T and lcp array. So, we can find longest common prefix of two substring in O(1) constructing rmq sparse table on lcp array.

Time complexity: 

For the better understanding see my solution.

P.S. One can uses hashes instead of suffix array.

ADD: There is another approach to solve this problem in  but it's rather slow in practice. We can do binary search on answer and use hashes, but we do it for all queries at one time. The only problem is to find k-th vertex on the path, we can do it offline for all queries in O(n + m) time. We run dfs and maintain stack of vertices. See my solution for details.

Codeforces Round #284 Editorial

By danilka.pro, 8 years ago, In English 499A - Watching a movie One can solve the problem using greedy algorithm: if we can skip x minutes at current moment without skipping any good moment — we do that, otherwise — watch another minute of the film.

499B - Lecture In this task you must find for every string in the text the pair containing that string, and from two strings of that pair output the shortest one.

498A - Crazy Town / 499C - Crazy Town It can be easily proved that, if two points from statement are placed on different sides of some line, this line will be crossed anyway. So, all we need to do is to cross all these lines, so the answer is the number of these lines.

To check if two points lies on different sides of a line one can simply use its coordinates to place in line equation and check if these two values have different signs.

Solution complexity — O(n).

498B - Name That Tune / 499D - Name That Tune Let's numerate all the songs and seconds starting from 0.

Problem will be solved using DP approach. State will be described by two integers (i, j): dp[i][j] is probability of that we named exactly i songs, and the last named song was named exactly before j'th second (after j - 1 seconds). dp[0][0] = 1 obviously.

To make a move from state (i, j) to state (i + 1, j + k) (1 ≤ k < ti), we must name the song exactly after k seconds its playing — probability of that is (1 - pi)k - 1·pi.

To fixed state (i + 1, j) sum of that moves can be represented as . Simple calculation of this value for each state gives O(nT2) complexity, so one must notice, that this values can be calculated using two pointers for fixed i (in common case it represent a segment with ti length) for every j in time O(T). This way calculating this type of moves takes O(nT) time.

There is also a move to (i + 1, j + ti) and a move from (i, j) to (i, (j + k) = T), when we couldn't name current song in time T. This types of moves is calculated with O(nT) too.

Solution complexity — O(nT).

498C - Array and Operations / 499E - Array and Operations We will divide only by prime numbers.

First, let's build a graph, where each of n numbers have own vertex group:

Find all prime factors of current number. Every factor will have its own vertex in a group, furthermore, if some factor p has power of ai in current number, it will have exactly ai vertexes in group.

The number of vertexes in such graph is .

Now we will make edges in our graph: edge between two vertexes exists if and only if there is a good pair (given in statement) of vertexes group numbers and the prime values of a vertexes are the same. That means that we can divide that group numbers by that prime.

The number of edges is .

Good pairs are given the way that our graph is bipartite. After finding maximum matching in this graph we represent the way of doing operations as described in the statement.

As soon as solution is using Kuhn's algorithm, its complexity is . One could notice that some of the edges are useless and reduce it to .

498D - Traffic Jams in the Land The solution of a problem — 60 (LCM of a numbers from 2 to 6) segment trees.

In v'th segment tree we will hold for every segment [l, r] the next value: minimum time needed to get from l to r if we start in a moment of time equal to v modulo 60. Using these trees' values it is easy to quickly answer the questions, carefully changing the trees' values.

498E - Stairs and Lines The problem is solved using DP approach dp[i][mask] — the number of ways to paint first i blocks of a ladder the way that the last layer of vertical edges is painted as described in mask mask. This could be easily recalculated using matrix M[mask1][mask2] — the number of ways to paint horizontal edges between two neighbour vertical layers painted as represented by masks mask1 and mask2.

For fixed i we have wi layers, so this matrix must be multiplied by itself wi times, which can be quickly done by binary-pow algorithm. After that this matrix is simply used in dynamic described above.

Solution complexity — .

Codeforces Round #283: editorial (with bonuses!)

By Endagorion, 8 years ago, translation, In English Each problem comes with a challenge — a bonus task somehow related to the problem; you may tackle at the challenges for fun and practice, also feel free to discuss them at the comments. =)

496A - Minimum Difficulty

For every option of removing an element we run through the remaining elements and find the maximal difference between adjacent ones; print the smallest found answer. The solution has complexity O(n2). It can be noticed that after removing an element the difficulty either stays the same or becomes equal to the difference between the neighbours of the removed element (whatever is larger); thus, the difficulty for every option of removing an element can be found in O(1), for the total complexity of O(n). Any of these solutions (or even less efficient ones) could pass the tests.

Challenge: suppose we now have to remove exactly k arbitrary elements (but the first and the last elements have to stay in their places). How small the maximal difference between adjacent elements can become? Solve this problem assuming the limitations are as follows: 1 ≤ k ≤ n - 2, n ≤ 105, ai ≤ 109.

496B - Secret Combination

We observe that the order of operations is not important: we may first perform all the shifts, and after that all the additions. Note that after n shifts the sequence returns to its original state, therefore it is sufficient to consider only the options with less than n shifts. Also, after 10 times of adding 1 to all digits the sequence does not change; we may consider only options with less than 10 additions. Thus, there are overall 10n reasonable options for performing the operations; for every option perform the operations and find the smallest answer among all the options. As performing the operations for every option and comparing two answers to choose the best takes O(n) operations, this solution performs about 10n2 elementary operations. The multiple of 10 can be get rid of, if we note that after all shifts are made the best choice is to make the first digit equal to zero, and this leaves us but a single option for the number of additions. However, implementing this optimization is not necessary to get accepted.

Challenge: can you solve the problem in  time? in O(n) time?

496C - Removing Columns/497A - Removing Columns

Let's look at the first column of the table. If its letters are not sorted alphabetically, then in any valid choice of removing some columns it has to be removed. However, if its letters are sorted, then for every valid choice that has this column removed it can be restored back to the table; it is clear that the new choice is valid (that is, the rows of the new table are sorted lexicographically) and the answer (that is, the number of removed columns) has just became smaller.

Consider all columns from left to right. We have already chosen which columns to remove among all the columns to the left of the current one; if leaving the current column in place breaks the lexicographical order of rows, then we have to remove it; otherwise, we may leave it in place to no harm. Arguing in the way of the previous paragraph we can prove that this greedy method yields an optimal (moreover, the only optimal) solution. The complexity is O(n2).

Challenge: compute how many (say, modulo 109 + 7) n × m tables are there for which the answer for this problem is k? The more efficient solution you come up with, the better.

496D - Tennis Game/497B - Tennis Game

Choose some t; now emulate how the match will go, ensure that the record is valid for this t and by the way find the corresponding value of s. Print all valid options for s and t. This solution works in O(n2) time, which is not good enough, but we will try to optimize it.

Suppose the current set if finished and we have processed k serves by now. Let us process the next set as follows: find t-th 1 and t-th 2 after position k. If t-th 1 occurs earlier, then the first player wins the set, and the set concludes right after the t-th 1; the other case is handled symmetrically. If the match is not over yet, and in the rest of the record there are no t ones nor t twos, then the record is clearly invalid. This way, every single set in the record can be processed in  time using binary search, or O(1) time using precomputed arrays of positions for each player.

Now observe that for any t a match of n serves can not contain more than n / t sets, as each set contains at least t serves. If we sum up the upper limits for the number of sets for each t, we obtain the total upper limit for the number of sets we may need to process:  (which is the famous harmonic sum). Using one of the approaches discussed above, one obtains a solution with complexity of  or ; each of these solutions fits the limit nicely.

Obviously, for every t there is no more than one valid choice for s; however, maybe a bit unexpected, for a given s there may exist more than one valid choice of t. The first test where this takes place is pretest 12. The statement requires that the pairs are printed lexicographically ordered; it is possible to make a mistake here and print the pairs with equal s by descending t (if we fill the array by increasing t and then simply reverse the array).

Challenge: while preparing this problem I discovered that it's quite hard to find a test such that the number of pairs in the answer is large; in the actual tests the maximal number is 128, which is the number of divisors of the number 83160. Can you beat this record? If you have a test with n ≤ 105 that has larger number of pairs in the answer, feel free to brag in the comments; also don't hesitate to share any insights on how one could bound the maximal number analytically.

496E - Distributing Parts /497C - Distributing Parts

Sort all the parts and actors altogether by increasing lower bounds (if equal, actors precede parts); process all the enitities in this order. We maintain a set of actors which have already occured in the order; if we meet an entry for an actor, add it to the set. If we currently process a part, we have to assign it to an actor; from the current set of actors we have to choose one such that his di ≥ bj (the ci ≤ aj constraint is provided by the fact that the i-th actor has occured earlier than the j-th part); if there are no such actors in the set, no answer can be obtained; if there are several actors satisftying this requirement, we should choose one with minimal di (intuitively, he will be less useful in the future). Assign the chosen actor with the current part and decrement his ki; if ki is now zero, the actor can not be used anymore, thus we remove him from the set.

To fit the limits we should implement the set of current actors as some efficient data structure (e.g., an std::set or a treap). The resulting complexity is .

Challenge: suppose that now there are qj copies of the j-th part (1 ≤ qj ≤ 109), and each copy must be separately assigned with an actor in a valid way. Can you solve this new problem with all the old constraints (as the actual distribution now has too much entries, it is sufficient to check whether an answer exists)?

497D - Gears

When a collision happens, a vertex of one polygon lands on a side of the other polygon. Consider a reference system such that the polygon A is not moving. In this system the polygon B preserves its orientation (that is, does not rotate), and each of its vertices moves on some circle. Intersect all the circles for vertices of B with all the sides of A; if any of them intersect, then some vertex of B collides with a side of A. Symmetrically, take a reference system associated with B and check whether some vertex of A collides with a side of B. The constraints for the points' coordinates are small enough for a solution with absolute precision to be possible (using built-in integer types).

Another approach (which is, in fact, basically the same) is such: suppose there is a collision in a reference system associated with A. Then the following equality for vectors holds: x + y = z; here z is a vector that starts at P and ends somewhere on the bound of A, x is a vector that starts at Q and ends somewhere on the bound of B, y is a vector that starts at P and ends somewhere on the circle centered at P that passes through Q. Rewrite the equality as y = z - x; now observe that the set of all possible values of z - x forms the Minkowski sum of A and reflection of B (up to some shift), and the set of all possible values of y is a circle with known parameters. The Minkowski sum can be represented as a union of nm parallelograms, each of which is the Minkowski sum of a pair of sides of different polygons; finally, intersect all parallelograms with the circle.

Both solutions have complexity O(nm). As noted above, it is possible to solve the problem using integer arithemetics (that is, with absolute precision); however, the fact that the points' coordinates are small lets most of the solutions with floating point arithmetics pass. It was tempting to write an approximate numerical solution; we struggled hard not to let such solutions pass, and eventually none of them did. =)

Many participants had troubles with pretest 8. It looks as follows (the left spiral revolves around the left point, and the right spiral revolves around the right point):

 

Challenge: suppose we want a solution that uses floating point arithmetics to fail. In order to do that, we want to construct a test such that the polygons don't collide but pass really close to each other. How small a (positive) distance we can achieve, given the same constraints for the number of points and the points' coordinates?

497E - Subsequences Return

Consider some string; how does one count the number of its distinct subsequences? Let us append symbols to the string consequently and each time count the number of subsequences that were not present before. Let's append a symbol c to a string s; in the string s + c there are as many subsequences that end in c as there were subsequences in s overall. Add all these subsequences to the number of subsequnces of s; now each subsequence is counted once, except for the subsequences that end in c but were already present in s before; these are counted twice. Thus, the total number of subsequences in the new string is twice the total number of subsequences in the old string minus the number of subsequences in the old string which end in c.

This leads us to the following solution: for each symbol c store how many subsequences end in c, denote cntc. Append symbol c; now cntc becomes equal to the sum of all cnt's plus one (for the empty subsequence), and all the other cnt's do not change.

For example, consider the first few symbols of the Thue-Morse sequence:

ε — (0, 0)

0 — ( 0 + 0 + 1 = 1, 0)

01 — (1, 1 + 0 + 1 = 2)

011 — (1, 1 + 2 + 1 = 4)

0110 — ( 1 + 4 + 1 = 6, 4)

...

Let us put the values of cnt in the coordinates of a vector, and also append a coordinate which is always equal to 1. It is now clear that appending a symbol to the string alters the vector as a multiplication by some matrix. Let us assign a matrix for each symbol, and also for each string as a product of matrices for the symbols of the strings in that order.

Now, consider the prefix of the sequence ai of length km. Divide it into k parts of length km - 1; x-th (0-based) of these parts can be obtained from the 0-th one by adding x modulo k to all elements of the part. Let us count the matrices (see above) for the prefixes of length km, and also for all strings that are obtained by adding x to all of the prefixes' elements; denote such matrix Am, x.

It is easy to see that if m > 0, then . This formula allows us to count Am, x for all  and all x from 0 to k - 1 in  time. Now, upon having all Am, x we can multiply some of them in the right order to obtain the matrix for the prefix of the sequence ai of length n.

Unfortunately, this is not quite enough as the solution doesn't fit the time limit yet. Here is one way to speed up sufficiently: note that the product in the formula  can be divided as shown: Am - 1, x... Am - 1, k - 1 × Am - 1, 0... Am - 1, x - 1 (if x = 0, take the second part to be empty). Count all the "prefixes" and "suffixes" products of the set Am, x: Pm, x = Am, 0... Am, x - 1, Sm, x = Am, x... Am, k - 1. Now Am, x = Sm - 1, xPm - 1, x. Thus, the computation of Am, x for all x and a given m can be done as computing all Pm - 1, x, Sm - 1, x using O(k) matrix multiplications, and each Am, x is now can be found using one matrix multiplication. Finally, the solution now works in  time, which fits the limits by a margin.

Challenge: solve the problem for k ≤ 100.

Codeforces Round #282 Editorial

By matrix, 8 years ago, In English 495A - Digital Counter

For each digit x you can count the number of digits y that because of some broken sticks x is shown instead of y by hand. for example when x = 3, y can be 3, 8 and 9. Let's denote this number by ax. Then if the input is xy (the first digit shown in the counter is x and the second is y) the answer will be ax × ay.

495B - Modular Equations

If a < b then there is no answer since . If a = b then x can be any integer larger than a. so there are infinite number of answers to the equation. The only remaining case is when a > b. Suppose x is an answer to our equation. Then x|a - b. Also since  then b < x. These conditions are necessary and sufficient as well. So the answer is number of divisors of a - b which are strictly greater than b which can be solved in . 494A - Treasure

Consider a string consisting of '(' and ')' characters. Let's build the following sequence from this string:

a0 = 0

for each 1 ≤ i ≤ |s| ai = ai - 1 + 1 if si = '(' and ai = ai - 1 - 1 otherwise. (The string is considered as 1-based index).

It can be proven that a string is beautiful if the following conditions are satisfied:

for each 0 ≤ i ≤ |s| ai ≥ 0.

a|s| = 0

Using the above fact we can prove that if in a beautiful string we remove a ')' character and put it further toward the end of the string the resulting string is beautiful as well. These facts leads us to the following fact: if we can move a ')' character further toward the end of string it is better if we'd do it. This yields the following greedy solution:

We'll first put exactly one ')' character at each '#' character. Then we'll build the sequence we described above. if the first condition isn't satisfied then there is no way that leads to a beautiful string. So the answer is -1. Otherwise we must put exactly a|s| more ')' characters in the place of last '#' character. Then if this string is beautiful we'll print it otherwise the answer is -1.

494B - Obsessive String

We call an index i(1 ≤ i ≤ |s|) good if t equals si - |t| + 1si - |t| + 2... si. To find all good indexes let's define qi as the length of longest prefix of t which is a suffix of s1s2... si. A good index is an index with qi = |t|. Calculating qi can be done using Knuth-Morris-Pratt algorithm.

Let's define ai as the number of ways to choose some(at least one) non-overlapping substrings of the prefix of s with length i (s1s2... si) so t is a substring of each one of them and si is in one the chosen substrings(So it must actually be the last character of last chosen substring). Then the answer will be .

Also let's define two additional sequence q1 and q2 which will help us in calculating a.





The sequence a can then be calculated in O(n) as described below:

If i is not a good index ai = ai - 1 since in each way counted in ai the substring containing si also contains si - 1 so for each of these ways removing si from the substring containing it leads to a way counted in ai - 1 and vice-versa thus these two numbers are equal. If i is a good index then ai = q2i - |t| + i - |t| + 1. To prove this let's consider a way of choosing substring counted in ai. We call such a way valid. The substring containing si can be any of the substrings sjsj + 1... si (1 ≤ j ≤ i - |t| + 1). There are i - |t| + 1 valid ways in which this substring is the only substring we've chosen. Number of valid ways in which substring containing si starts at sj equals to q1j - 1. So the total number of valid ways in which we've chosen at least two substrings are equal to  which is equal to q2j - 1. So ai = q2i - |t| + i - |t| + 1.

494C - Helping People

We'll first create a rooted tree from the given segments which each node represents a segment. We'll solve the problem using dynamic programming on this tree. First of all let's add a segment [1, n] with probability of being chosen by Malek equal to 0. The node representing this segment will be the root of the tree. Please note by adding this segment the rules described in the statements are still in place.

Let's sort the rest of segments according to their starting point increasing and in case of equality according to their finishing point decreasing. Then we'll put the segment we added in the beginning. A segment's father is the right-most segment which comes before that segment and contains it. Please note that since we added segment [1, n] to the beginning every segment except the added segment has a father. We build the tree by putting a segment's node child of its father's node.

In this tree for each two nodes u and v which none of them are in the subtree on another the segments representing these two nodes will not overlap. Also for each two nodes u and v which u is in subtree of v segment representing node u will be inside(not necessarily strictly) segment representing node v. We define mxi as the maximum money a person in the segment i initially has. mxi can be calculated using RMQ. Let's define ai, j as the probability of that after Malek finishes giving his money the maximum in the segment i is at most {mx}i + j. The properties of the tree we built allows us to calculate ai, j for every i and j in O(q2) (since 1 ≤ i, j ≤ q). If number of the segment we added is k then the answer will be .

Calculating ai, j is described below:

Suppose f is a child of i and suppose Malek doesn't accept the i-th recommendation. Then since we want the maximum number after money spreading to be at most mxi + j in segment i and since f is inside i we want the maximum number after money spreading to be at most mxi - mxf + j. If Malek accepts the recommendation then we want it to be at most mxi - mxf + j - 1. So if probability of i-th recommendation being accepted by Malek be equal to pi then . Using this formula we can calculate ak, j recursively and calculate the answer from it in O(q2). The overall complexity will be O(nlgn + q2). nlgn for creating RMQ used for calculating the array mx and q2 for the rest of the algorithm.

494D - Birthday

We solve this problem by answering queries offline. We'll first store in each vertex v number of vertices such as x for which we must calculate f(v, x) . starting from the root. We'll keep two arrays a and b. Suppose we're at vertex v right now then ai equals d(i, v)2 and bi equal d(i, v). Having these two arrays when moving from vertex v to a child with an edge with weight k one can note that bi for all is inside subtree of v decreases by k and all other bis gets increased by k. Knowing this fact one can also update array a as well. To calculate f(v, x) it's enough to be able to calculate sum of ais for all i inside subtree of x. Handling each of these operations is a well known problem and is possible using a segment tree. Overall complexity is O((n + q)lgn). There is an online solution using dynamic programming as well.

494E - Sharti

Let's first solve this problem for another game: Suppose that we've an n × n table. Each cell have some(possibly zero) marbles on it. During each move the player chooses a square with side-length at most k which its lower-right cell has at least one marble, he removes one marble from it and puts one marble in every other cell of this square. One can notice that in such game each marble is independent of the others and doesn't affect other marbles. So one can see this game as some separate games played on some tables. More formally for each marble placed in a cell such as (i, j) consider the game when played on a i × j table which the only marble placed on it is at its lower-right cell. Let's denote the Grundy number of this game by gi, j. Then according to Grundy theorem the first player has a winning strategy if and only if the xor of gi, j for every cell (i, j) having odd number of marbles on it is positive.

To calculate gi, j note that the first move in such game must be choosing a square with its lower-right cell being the lower-right cell of table. So the only thing to decide is the side-length of chosen square at the first move. Let's say we choose the first square width side length l. Grundy number of the next state will be equal to xor of gc, d for every i - l < c ≤ i, j - l < d ≤ j. Using this fact one can calculate gi, j for all (1 ≤ i, j ≤ a) (a being an arbitrary integers) in O(a3).

If we calculated the first values of gi, j one can see a pattern in the Grundy numbers. Then one can prove that gi, j = min(lowest_bit(i), lowest_bit(j), greatest_bit(k)) where lowest_bit(x) =  the maximum power of 2 which is a divisor of x and greatest_bit(x) =  the maximum power of 2 which is not greater than x.

Now let's prove that our first game(the game described in the statement) is actually the same as this game. Suppose that a player has a winning strategy in the first game. Consider a table containing one marble at every cell which is white in the table of the first game. We'll prove that the same player has winning strategy in this game as well. Note that a cell is white in the first game if and only if the parity of marbles in the second game is odd so there is at least one marble on it. So as long as the other player chooses a square with its lower-right cell having odd number of marbles in the second game, his move corresponds to a move in the first game so the player having winning strategy can counter his move. If the other player chooses a square with its lower-right cell having even number of marbles, it means the cell had at least 2 marbles on it so the player can counter it by choosing the same square which makes the parity of every cell to be the same after these 2 moves. And since it can be proven that both of the game will end at some point then the player has winning strategy in this game as well. The reverse of this fact can also be proven the same since if a player has a winning strategy there is also a winning strategy in which this player always chooses squares with lower-right cell having odd number of marbles(since otherwise the other player can counter it as described above) and counters the moves of the other player at which he chose a square with lower-right cell having even number of marbles by choosing the same square(since the Grundy number by countering in this way won't change the Grundy number and thus won't change the player with winning strategy).

So if we consider a table having one marble at each of the cells which are in at least one of the rectangles given in the input we only need to calculate the Grundy number of this state and check whether it's positive or not to determine the winner. To do this for each i(1 ≤ i ≤ greatest_bit(k)) lets define ai as the number of cells (x, y) which are contained in at least one of the given rectangles, 2i|x and 2i|y. Lets also define agreatest_bit(k) + 1 = 0. Then according the fact we described above about gi, j the number of 2is which are xored equals ai - ai + 1. Knowing this calculating the Grundy number of the initial state is easy. Calculating ai is identical to a very well-known problem which is given some rectangles count the number of cells in at least one of them and can be solved in O(mlgm) (m being number of rectangles). So overall complexity will be O(mlgmlgk).

If there is any problem in the editorial please feel free to note that to us.

Thank you.

Codeforces Round #281 (Div. 2) Editorial

By albertg, 8 years ago, translation, In English 493A - Vasya and Football

We need 2 arrays — for the first and second team, in which we must save "status" of the player — is he "clear", yellow carded or sent off. Then while inputing we must output the players name if he wasn't sent off, and after the event he must be sent off.

493B - Vasya and Wrestling

We need to vectors in which we will save points of first and second wrestlers, and two int-s, where we will save who made the last technique and what is the sum of all the numbers in the input. If the sum is not zero, we know the answer. Else we pass by the vectors, checking are there respective elements which are not equal. If yes — then we know the answer, else everything depends on who made the last technique.

493C - Vasya and Basketball

We need an array of pairs — in each pair we save the distance and the number of team. Then we sort the array. Then we assume that all the throws bring 3 points. Then we pass by the array and one of our numbers we decrease on 1 (which one — it depends on the second element of array). Then we compare it with our answer. In the end — we print our answer.

493D - Vasya and Chess

If n is odd, then black can win white doing all the moves symetric by the central line. Else white can win putting his queen on (1,2) (which is the lexicographicly smallest place) and play symetricly — never using the first row.

493E - Vasya and Polynomial

Let's discuss 2 case. 1) t!=1 и 2) t=1.

1) If our function is not constant (n>=1) than a is greater all the coefficients, so the only polynom can be the number b — in the a-ary counting system. We must only check that one and constant function.

2)if t=1 must be careful:

in case 1 1 1: the answer is inf,

in case 1 1 n: the answer is 0

in case 1 а а^x(x-integer, x>0): the answer is 1

in the other cases P(1) is greater than other coefficients.

Codeforces Round #280 (Div. 2) Editorial

By Wild_Hamster, 8 years ago, translation, In English 492A - Vanya and Cubes.

In fact need to do what is asked in the statement. We need to find in a cycle the maximum height h, counting, how many blocks must be in i-th row and adding these values to the result. Iterate until the result is not greater than n.

Jury's solution: 8924831

492B - Vanya and Lanterns.

Sort lanterns in non-decreasing order. Then we need to find maximal distance between two neighbour lanterns, let it be maxdist. Also we need to consider street bounds and count distances from outside lanterns to street bounds, it will be (a[0] - 0) and (l - a[n - 1]). The answer will be max(maxdist / 2, max(a[0] - 0, l - a[n - 1]))

Time complexity O(nlogn).

Jury's solution: 8924823

492C - Vanya and Exams.

Sort (ai, bi) in non-decreasing order for number of essays bi, after that go from the beginning of this sorted pairs and add greedily the maximal number of points we can, i.e. add value min(avg * n - sum, r - ai), while total amount of points will not be greater, than avg * n.

Time complexity O(nlogn).

Jury's solution: 8924807

492D - Vanya and Computer Game.

Let's create vector rez with size x + y, in which there will be a sequence of Vanya's and Vova's strikes for the first second. To do this, we can take 2 variables cntx = cnty = 0. Then while cntx < x and cnty < y, we will check 3 conditions:

1) If (cntx + 1) / x > (cnty + 1) / y, then add into the vector word “Vova”, cnty++.

2) If (cntx + 1) / x < (cnty + 1) / y, then add into the vector word “Vanya”, cntx++.

3) If (cntx + 1) / x = (cnty + 1) / y, then add into the vector word “Both” 2 times, cntx++, cnty++.

Then we are able to respond on each query for О(1), the answer will be rez[(ai - 1)mod(x + y)].

Time complexity O(x + y).

Jury's solution: 8924773

492E - Vanya and Field.

As long as gcd(dx, n) = gcd(dy, n) = 1, Vanya will do full cycle for n moves. Let's group all possible pathes into n groups, where 1 - th, 2 - nd, ... , n - th path will be started from points (0, 0), (0, 1), …, (0, n - 1). Let's look on first path: (0, 0) - (dx, dy) - ((2 * dx) mod n, (2 * dy) mod n) - ... - (((n - 1) * dx) mod n, ((n - 1) * dy) mod n). As long as gcd(dx, n) = 1, among the first coordinates of points of the path there will be all the numbers from 0 to n - 1. So we can write in the array all relations between the first and second coordinate in points for the path, that starts in the point (0, 0), i.e. y[0] = 0, y[dx] = dy, ... , y[((n - 1) * dx) mod n] = ((n - 1) * dy) mod n. Now we know, that all points with type (i, y[i]), where 0 ≤ i ≤ n - 1, belong to the group with start point (0, 0). In that case, points with type (i, (y[i] + k)modn) belong to the group with start point (0, k). Then we can add every point (xi, yi) to required group k for О(1): (y[xi] + k) mod n = yi, k = (yi - y[xi] + n) mod n. Then we need just to find group with the maximal amount of elements, it will be the answer.

Time complexity O(n).

Jury's solution: 8924746

P.S. Sorry for my bad English, I hope, I will correct this editorial as much, as possible.

Codeforces Round #279 (Div. 2) Editorial

By HolkinPV, 8 years ago, translation, In English 490A - Team Olympiad The teams could be formed using greedy algorithm. We can choose any three children with different skills who are not participants of any team yet and form a new team using them. After some time we could not form any team, so the answer to the problem is minimum of the number of ones, twos and threes in given array. We can get O(N) solution if we add children with different skills into three different arrays. Also the problem could be solved in O(N2) — every iteration find new three children for new team.

490B - Queue This problem can be solved constructively. Find the first student — it is a student with such number which can be found among ai and could not be found among bi (because he doesn’t stand behind for anybody). Find the second student — it is a student standing behind the first, number ai of the first student equals 0, so his number is a number in pair [0, bi].

After that we will find numbers of all other students beginning from the third. It can be easily done using penultimate found number. The number of the next student is a number bi in such pair where ai equals to number of penultimate found student number (that is a number in pair [ans[i - 2], bi]). Look at the sample to understand the solution better.

490C - Hacking Cypher At first, let’s check all prefixes of specified number — do they have remainder 0 when divided by the a? It can be done with asymptotic behavior O(N), where N -length of specified number C. If we have remainder of division by a of prefix, which ends in position pos, we can count remainder in position pos + 1: rema[pos + 1] = (rema[pos] * 10 + C[pos + 1]) % a.

Then we need to check suffixes.If we have remainder of division by b of suffix, which begin in position pos, we can count remainder of position pos - 1: remb[pos - 1] = (C[pos - 1] * P + remb[pos]) % b, where P — it is 10^(L - 1) module b, L — length of suffix (P we can count parallel).

Now let’s check all positions pos — can we cut specified number C in this position. We can do it if next four conditions performed: prefix of number C, which ends in pos is divisible by a; suffix of number C, which begin in pos + 1 is divisible by b; length of prefix and suffix more than 0; first digit of suffix is different from 0. If all four conditions performed we found answer. If we did not find any such positions, than print NO.

490D - Chocolate We can change the numbers by dividing their by two or by dividing their by three and multiply two. Firstly remove all 2 and 3 from factorization of chocolate and determine equals their square or not. If their squares are not equals answer doesn’t exists. Otherwise calculate of difference between number of three in factorization, we should remove this amount of threes from the some chocolate, it depends from the sign, and recalculate difference between number of two in factorization and do the same.

490E - Restoring Increasing Sequence Let’s iterate on specified numbers and try to make from current number minimal possible, which value more than value of previous number. Let’s current number is cur, previous number is prev.

If length of number cur less than length of number prev — let’s print NO, this problem has not solution.

If length of number cur more than length of number prev — replace all signs ? in number cur to digit 0, except case, when sign ? in first position — replace him on digit 1, because numbers in answer must be without leading zeroes.

Another case when lengths of numbers a and b are equal. Let’s iterate on positions pos, in which prefix number cur more than prefix of number prev. Now we need to try for this position make minimal possible number, which more than prev. In all positions posi, which less than pos, replace all ? on prev[posi]. In all positions posi, which more than pos, replace all ? on digit 0. If cur[pos] =  = ? than make cur[pos] = max(prev[pos] + 1, 9).

If received number less or equal to prev — this position is bad. From all good positions choose minimal number, received with operations above and assign him number cur and will continue iteration. If count of such positions is 0 we need to print NO.

490F - Treeland Tour The problem is generalization of finding maximal increasing subsequence in array, so it probably can be solved using dynamic programming. We will calс dynamic d[(u, v)], the state is directed edge (u, v) in tree. Value d[(u, v)] means the maximum number of vertices where the band will have concerts on some simple path ended in vertex v going through vertex u. Also the concert in vertex v must be certainly.

To calc d(u, v) we should consider all such edges (x, y) that there is simple path started in x, going through y, u and ended in v. These edges can be found using dfs from vertex u which is not going through vertex v. All edges used by dfs should be reoriented. So if r[y] < r[v] then d[(u, v)] = max(d[(u, v)], d[(x, y)] + 1). The solution needs O(N2) time and O(N2) memory. The memory could be O(N) if you get indexes of directed edges without two-dimensional array.

Codeforces Round #278 Editorial

By taorunz, 8 years ago, In English 488A - Giga Tower The answer b is very small (usually no larger than 10), because one of a + 1, a + 2, ..., a + 10 has its last digit be 8.

However, b can exceed 10 when a is negative and close to 0. The worst case is a =  - 8, where b = 16.

Anyway b is rather small, so we can simply try b from 1, and check whether a + b has a digit 8.

488B - Candy Boxes Let's sort the four numbers in ascending order: a, b, c, d (where x1, x2, x3, x4 are used in problem statement). So .

With some basic math, we can get a: d = 1: 3 and a + d = b + c.

Solution 1:

If n = 0, just output any answer (such as {1, 1, 3, 3}). If n = 1, just output {x, x, 3x, 3x}, where x is the known number. If n = 4, just check whether the four known numbers meet the condition.

If n = 2, let x, y denote the known numbers (x ≤ y). No solution exists if 3x < y. Otherwise we can construct a solution {x, y, 4x - y, 3x} (certainly other solutions may exist).

If n = 3, let x, y, z denote the known numbers (x ≤ y ≤ z). No solution exists if 3x < z. Otherwise the solution can only be {x, y, z, 3x},  or {x, y, x + z - y, z}.

Solution 2:

The known numbers are no larger than 500, so all numbers are no larger than 1500 if solution exists. We enumerate x from 1 to 500, y from x to 3x, then {x, y, 4x - y, 3x} is a solution. For each solution, check if it matches the known numbers.

Solution 3:

If n = 0, just output any answer (such as {1, 1, 3, 3}). If n = 1, just output {x, x, 3x, 3x}, where x is the known number. If n = 4, just check whether the four known numbers meet the condition.

Otherwise, we can enumerate the 1 or 2 missing number(s), and check if the four numbers meet the condition.

487A - Fight the Monster It is no use to make Yang's ATK > HP_M + DEF_M (Yang already can beat it in a second). And it's no use to make Yang's DEF > ATK_M (it cannot deal any damage to him).

As a result, Yang's final ATK will not exceed 200, and final DEF will not exceed 100. So just enumerate final ATK from ATK_Y to 200, final DEF from DEF_Y to 100.

With final ATK and DEF known, you can calculate how long the battle will last, then calculate HP loss. You can easily find the gold you spend, and then find the optimal answer.

487B - Strip We can use dynamic programming to solve this problem.

Let f[i] denote the minimal number of pieces that the first i numbers can be split into. g[i] denote the maximal length of substrip whose right border is i(included) and it satisfy the condition.

Then f[i] = min(f[k]) + 1, where i - g[i] ≤ k ≤ i - l.

We can use monotonic queue to calculate g[i] and f[i]. And this can be implemented in O(n)

We can also use sparse table or segment tree to solve the problem, the time complexity is  or (It should be well-implemented).

For more details about monotonic queue, you can see here

487C - Prefix Product Sequence The answer is YES if and only if n is a prime or n = 1 or n = 4.

First we can find . If n occurs in {a_1,…,a_{n-1}} in the prefix product sequence 0 will occur twice which do not satisfy the condition.

So an must be 0 from which we know a1a2... an - 1 = (n - 1)!. But for any composite number n > 4 we have (See the proof below). So we can know that for all composite number n > 4 the answer is NO.

For n = 1, 1 is a solution.

For n = 4, 1, 3, 2, 4 is a solution.

For any prime number n, let ai be . If there are two same number ai, aj. Then we get i / (i - 1) ≡ j / (j - 1) which leads to i ≡ j, which is a contradiction. So all n numbers will occur exactly once. And this is a solution.

Also, we can find a primitive root g of n and $g^{0}, g^{1}, g^{n-3}, g^{3}, g^{n-5}, \cdots } is also a solution.

Proof:

For a composite number n > 4 it can either be written as the products of two numbers p, q > 1.

If p ≠ q, then we immediately get pq|(n - 1)!.

If p = q, note that n > 4 so 2p < n, we have p2|(n - 1)!

So n|(n - 1)! always holds which means 

487D - Conveyor Belts This problem can be solved by classic data structures.

For example, let's try something like SQRT-decomposition. Let's divide the map horizontally into some blocks. For each grid, calculate its destination when going out the current block (or infinite loop before going out current block).

For each modification, recalculate the affected block by brute force. For each query, we can just use the "destination when going out the current block" to speed up simulation.

Let S be the size of a block, then the time for each modification is O(S), for each query is O(nm / S), since at most O(nm / S) blocks, and at most 1 grid of each block are visited.

The total time complexity is O(nm + qnm / S + pS), where p is the number of modifications. Let , the complexity can be the best: .

This task can also be solve by segment tree. The time complexity is , or , depending on implementation.

487E - Tourists First we can find out all cut vertices and biconnected components(BCC) by Tarjan’s Algorithm. And it must form a tree.

From the lemma below, we know that if we can pass by a BCC, then we can always pass any point in the BCC.

We use a priority queue for each BCC to maintain the minimal price in the component.

For each modification, if the vertex is a cut vertex, then modify itself and its related BCCs’ priority queue. If not, modify the priority queue of its BCC.

For each query, the answer is the minimal price on the path from x (or its BCC) to y (or its BCC). We can use Link-Cut Trees or Heavy-Light Decomposition with Segment Trees.

To be more exact, we can only modify the father BCC of the cut vertex in order to guarantee complexity(otherwise it would be hacked by a star graph).When querying, if the LCA of x and y is a BCC. Then the father of the LCA(which is a cut vertex related to the BCC) should also be taken into account.

The time complexity is  or .

Lemma: In a biconnected graph with n ≥ 3 points, for any three different vertices a, b, c, there is a simple path to from a to b going through c.

Proof: Consider a biconnected graph with at least 3 vertices. If we remove any vertex or any edge, the graph is still connected.

We build a network on the graph. Let's use (u,v,w) to describe a directed edge from u to v with capacity w. For each edge (u,v) of the original graph, we build (u,v,1) and (v,u,1). Build (S,c,2), (a,T,1) and (b,T,1). For each vertex other than S,T,c, we should give a capacity of 1 to the vertex.

In order to give capacity to vertex u, we build two vertices u1,u2 instead of u. For each (v,u,w), build (v,u1,w). For each (u,v,w), build(u2,v,w). Finally build (u1,u2,1).

Hence, if the maximal flow from S to T is 2, there is a simple path from a to b going through c.

Now we consider the minimal cut of the network. It is easy to find that minimal cut <= 2, so let's prove minimal cut > 1, which means, no matter which edge of capacity 1 we cut, there is still a path from S to T.

If we cut an edge like (u1,u2,1), it is equivalent to set the capacity of the vertex to 0, and equivalent to remove the vertex from the original graph. The graph is still connected, so there is still a path in the network.

If we cut other edges, it is equivalent to remove an edge from the original graph. It is still connected, too.

Now we have minimal cut > 1, which means maximal flow = minimal cut = 2. So there is always a simple path from a to b going through c.

Codeforces Round #277(Div. 2) Editorial

By laoriu, 8 years ago, In English 486A - Подсчёт функции

If n is even, then the answer is n / 2, otherwise the answer is (n - 1) / 2 - n =  - (n + 1) / 2.

486B - OR в матрице

Hint of this problem is presented in its statement. " where  is equal to 1 if some ai = 1, otherwise it is equal to 0."

To solve this problem, do 3 following steps:

Assign all aij (1 ≤ i ≤ m, 1 ≤ j ≤ n) equals to 1. If some bij = 0, then do assignments: aik = atj = 0 (1 ≤ k ≤ n, 1 ≤ t ≤ m) (that means, assign all elements in row i and column j of matrix a to 0). Then we have matrix a which need to find. Just check whether from matrix a, can we produce matrix b. If not, the answer is obviously "NO". Complexity: We can implement this algorithm in O(m * n), but it's not neccesary since 1 ≤ m, n ≤ 100.

486C - Преобразование в палиндром

Assuming that cursor's position is in the first half of string(i.e 1 ≤ p ≤ n / 2) (if it's not, just reverse the string, and change p to n - p + 1, then the answer will not change).

It is not hard to see that, in optimal solution, we only need to move our cusor in the first half of the string only, and the number of "turn" is at most once.

Therefore, we have below algorithm:

Find the largest index r before p in the first half of the string (p ≤ r ≤ n / 2) such that sr different to sn - r + 1. (si denote ith character of our input string s)

Find the smallest index l after p (1 ≤ l ≤ p) such that sl different to sn - l + 1.

In optimal solution, we move our cusor from p to l and then from l to r, or move from p to r and then from r to l. While moving, we also change character of string simultaneously (if needed) (by press up/down arrow keys).

Be careful with some corner case(for example, does'nt exist such l or r discribed above).

Complexity: O(n).

486D - Допустимые множества

Firstly, we solve the case d =  + ∞. In this case, we can forget all ai since they doesn't play a role anymore. Consider the tree is rooted at node 1. Let Fi be the number of valid sets contain node i and several other nodes in subtree of i ("several" here means 0 or more). We can easily calculate Fi through Fj where j is directed child node of i: . Complexity: O(n).

General case: d ≥ 0. For each node i, we count the number of valid sets contain node i and some other node j such that ai ≤ aj ≤ ai + d (that means, node i have the smallest value a in the set). How? Start DFS from node i, visit only nodes j such that ai ≤ aj ≤ ai + d. Then all nodes have visited form another tree. Just apply case d =  + ∞ for this new tree. We have to count n times, each time take O(n), so the overall complexity is O(n2). (Be craeful with duplicate counting)

Here is my code.

486E - Наибольшие возрастающие подпоследовательности

LIS = Longest increasing subsequence.

Solution 1 (Most of participant's solutions): Let F1i be the length of LIS ending exactly at ai of sequence {a1, a2, ..., ai} and D1i is the number of such that LIS. Let F2i be the length of LIS beginning exactly at ai of sequence {ai, ai + 1, ..., an} and D2i is the number of such that LIS. // Calculates F1i and F2i is familiar task, so I will not dig into this. For those who have'nt known it yet, this link may be useful)

// We can calculate D1i and D2i by using advanced data structure, like BIT or Segment tree.

l = length of LIS of {a1, a2, ..., an} = max{F1i} = max{F2j}.

m = number of LIS of {a1, a2, ..., an} = 

Let Ci be the number of LIS of {a1, a2, ..., an} that ai belongs to. Index i must in group:

1) if Ci = 0

2) if 0 ≤ Ci < m

3) if Ci = m

How to calculate Ci? If (F1i + F2i - 1 < l) then Ci = 0, else Ci = D1i * D2i. Done!

We have an additional issue. The number of LIS of {a1, a2, ..., an} maybe very large! D1i, D2i and m maybe exceed 64-bits integer. Hence, we need to store D1i, D2i and m after modulo some integer number, call it p.

Usually, we will choose p is a prime, like 109 + 7 or 109 + 9. It's not hard to generate a test such that if you choose p = 109 + 7 or p = 109 + 9, your solution will lead to Wrong answer. But I have romeved such that tests, because the data tests is weak, even p is not a prime can pass all tests.

Solution 2: // Some notation is re-defined.

Let F1i be the length of LIS ending exactly at ai of sequence {a1, a2, ..., ai}.

Let F2i be the length of LIS beginning exactly at ai of sequence {ai, ai + 1, ..., an}.

l = length of LIS of {a1, a2, ..., an} = max{F1i} = max{F2j}.

Let Fi be the length of LIS of sequence {a1, a2, ..., ai - 1, ai + 1, ..., an} (i.e the length of LIS of initial sequence a after removing element ai).

Index i must in group:

1) if F1i + F2i - 1 < l, otherwise:

2) if Fi = l

3) if Fi = l - 1

How to caculate Fi? We have: Fi = max{F1u + F2v} among 1 ≤ u < i < v ≤ n such that au < av. From this formula, we can use Segment tree to calculate Fi. Due to limitation of my English, it is really hard to write exactly how. I will post my code soon.

Complexity of both above solution: O(nlogn).

Codeforces Round #276 — Editorial

By oversolver, 8 years ago, translation, In English 485A - Factory

Production will stops iff exists integer K ≥ 0 such a·2K is divisible by m. From this fact follows that K maximum will be about O(log2(m)). So if we modeling some, for example, 20 days and production does not stop, then it will never stop and answer is "No". Otherwise answer is "Yes".

485B - Valuable Resources

Let us find minimum length needed to cover points by Ox. It is Maximum(xi) - Minumum(xi). The same in Oy — Maximum(yi) - Minumum(yi). Since we need a square city to cover all the mines, then we need to set length of this square to the maximum from those two values.

484A - Bits

Let us define function f(L, R), that gives answer to the query. It looks follows:

if L = R then f(L, R) = L;

else if 2b ≤ L, where b — maximum integer such 2b ≤ R, then f(L, R) = f(L - 2b, R - 2b) + 2b;

else if 2b + 1 - 1 ≤ R then f(L, R) = 2b + 1 - 1;

else f(L, R) = 2b - 1.

Total complexity is O(logR) per query.

484B - Maximum Value

Let us iterate over all different aj. Since we need to maximize , then iterate all integer x (such x divisible by aj) in range from 2aj to M, where M — doubled maximum value of the sequence. For each such x we need to find maximum ai, such ai < x. Limits for numbers allow to do this in time O(1) with an array. After that, update answer by value . Total time complexity is O(nlogn + MlogM).

484C - Strange Sorting

Note, that d-sorting is just a permutation (call it P), because it does not depends on characters in string. Look at shuffling operation in different way: instead of going to the next substring and sort it, we will shift string to one character left. It remains to understand that shift of string the permutation too (call it C). Now its clear, we need to calculate S·P·C·P·C... = S·(P·C)n - k + 1. And after that shift string for k - 1 character to the left for making answer to the shuffling operation. Here we use the multiplication of permutations. Since they are associative, that we can use binary algorithm to calculate (P·C)n - k + 1. Total time complexity is O(nmlogn).

484D - Kindergarten

Let us note, that in optimal answer any segment that making a group contains their minimum and maximum values on borders. Otherwise it will be better to split this segment to two other segments. Another note that is every segment in optimal solution is strictly monotonic (increasing or decreasing). Paying attention to the interesting points in sequence which making local maximums (i. e. ai - 1 < ai > ai + 1), local minimums (ai - 1 > ai < ai + 1), and point adjacent to them. Solve the problem by dynamic programming: Di is the answer in the prefix i. To calculate Di we need to look at no more than three previous interesting points and to previous Di - 1. Total time complexity is O(n).

484E - Sign on Fence

Let us note that we can use binary search to find answer to the one query. Suppose at some moment was fixed height h and need to know will fit the rectangle with width w and height h to the segment of fence from l-th to r-th panel. Let us build data structure that can answer to this question. This will be persistent segment tree with unusual function inside: maximum number of consecutive ones in segment (maxOnes). In leaves of segment tree will be only numbers 0 and 1. To calculate this function need to know some other values, specifically:

len — length of the segment in vertex of segment tree, prefOnes — length of prefix that consists only of ones, sufOnes — length of the suffix consist only of ones.

These functions are computed as follows:

maxOnes is equal to max(maxOnes(Left), maxOnes(Right), sufOnes(Left) + prefOnes(Right));

prefOnes equals prefOnes(Right) + len(Left) in case of len(Left) = prefOnes(Left), and prefOnes(Left) otherwise;

sufOnes equals sufOnes(Left) + len(Right) in case of len(Right) = sufOnes(Right), and sufOnes(Right) otherwise;

len = len(left) + len(Right);

Left и Right — it is left and right sons of vertex in segment tree.

As mentioned above, tree must be persistent, and it must be built as follows. First, builded empty tree of zeros. Next in position of highest plank need to put 1. The same doing for planks in decreasing order. For example if fence described with sequence [2, 5, 5, 1, 3] then bottom of segment tree will changed as follows:

[0, 0, 0, 0, 0] -> [0, 1, 0, 0, 0] -> [0, 1, 1, 0, 0] -> [0, 1, 1, 0, 1] -> [1, 1, 1, 0, 1] -> [1, 1, 1, 1, 1].

And we need to remember for all hi their version of tree. Now to answer the question we need to make query in our segment tree (that corresponding to height h) on segment [l, r]. If maxOnes form this query less than w, then rectangle impossible to put (otherwise possible).

Building of tree will take O(nlogn) time and memory. Time complexity to the one query will take O(log2n) time.

Codeforces Round #275 Editorial

By danilka.pro, 8 years ago, translation, In English 483A - Counterexample Problem author gridnevvvit

This problem has two possible solutions:

Let's handle all possible triples and check every of them for being a counterexample. This solution works with asymptotics O(n3logA) Handle only a few cases. It could be done like this:

  if (l % 2 != 0)       l++;       if (l + 2 > r)     out.println(-1);   else     out.println(l + " " + (l + 1) + " " + (l + 2));   Jury's solution: 8394832

483B - Friends and Presents Problem author gridnevvvit

Jury's solution is using binary search. First, you can notice that if you can make presents with numbers 1, 2, ..., v then you can make presents with numbers 1, 2, ..., v, v + 1 too. Let f(v) be the function returning true or false: is it right, that you can make presents with numbers 1, 2, ..., v. Let f1 be the number of numbers divisible by x, f2 — the number of numbers divisible by y, and both — number of numbers divisible by x and by y (as soon as x and y are primes, it is equivalent to divisibility by x·y). Then to first friend at first we shold give f2 - both numbers, and to second friend f1 - both numbers. Then we must check, could we give all other numbers divisible neither by x nor by y.

This solution works with 

Jury's solution: 8394846

483C - Diverse Permutation / 482A - Diverse Permutation Problem author gridnevvvit

Let's see, what's the solution for some k = n - 1:

1 10 2 9 3 8 4 7 5 6

At the odd indexes we placed increasing sequence 1, 2, 3 .., at the even — decreasing sequence n, n - 1, n - 2, ... First, we must get the permutation the way described above, then get first k numbers from it, and then we should make all other distances be equal to 1.

This solution works with O(n).

Jury's solution: 8394876

483D - Interesting Array / 482B - Interesting Array Problem author gridnevvvit

We will solve the task for every distinct bit. Now we must handle new constraint: l[i], r[i], q[i]. If number q[i] has 1 in bit with number pos, then all numbers in segment [l[i], r[i]] will have 1 in that bit too. To do that, we can use a standard idea of adding on a segment.

Let's do two adding operation in s[pos] array — in position l[i] we will add 1, and in posiotion r[i] + 1 — -1. Then we will calculate partial sums of array s[pos], and if s[pos][i] > 0 (the sum on prefix length i + 1), then bit at position pos will be 1, otherwise — 0.

After that, you can use segment tree to check satisfying constraints.

Jury's solution: 8394894

483E - Game with Strings / 482C - Game with Strings Problem author gridnevvvit

Let's handle all string pairs and calculate the mask mask, which will have 1-bits only in positions in which that strings have the same characters. In other words, we could not distinguish these strings using positions with submask of mask mask, then we must add in d[mask] 1-bits in positions i и j. This way in d[mask] we store mask of strings, which we could not distinguish using only positions given in mask mask. Using information described above, we can easily calculate this dynamics.

Now, when we have array d calculated, it is not hard to calculate the answer. Let's handle some mask mask. Now we should try to make one more question in position pos, which is equal to adding one more 1-bit in mask in position pos. After that we may guess some strings, they are 1-bits in mask s = d[mask] ^ d[mask | (1 << pos)]. Then you have to calculate number of bits in s quickly and update the answer.

Jury's solution: 8394918

482D - Random Function and Tree Problem author RoKi

Let's calculate d[v][p] dynamics — the answer for vertex v with size of parity p.

At first step to calculate this dynamic for vertex v we should count all different paintings of a subtree visiting all children in increasing order of their numbers. By multiplying this number by 2 we will get paintings visiting children in decreasing order. Now some paintings may count twice. To fix that, let's have a look on a some subtree of a vertex v.

Consider all the parities of children subtrees visited by our function (0 or 1). First thing to note is that among these parities exist two different values, the subtree will have different paintings with different ordering (you can prove it yourself). Otherwise, all our children sizes have the same parity.

If all sizes are even, this subtree will be counted twice. Otherwise, if sizes are odd, we are interested only in odd count of visited subtrees. This way, we must subtract from our dynamic the number of ways to paint any number of children with even subtree sizes and odd number of children with odd subtree sizes.

Jury's solution: 8394936

482E - ELCA Problem author danilka.pro

Let's split all M requests in  blocks containing  requests each. Every block will be processed following way:

First using dfs we need to calculate  for every vertex v, where u is every ancestor of v, sizei — size of subtree of vertex i, including itself. This value shows how will the answer change after removing or adding vertex v as child to any other vertex, furthermore, answer will change exactly by pathv·sizev (decreasing or increasing).

Then we will calculate chv the same way — the number of all possible vertex pairs, which have LCA in vertex v. This value shows how the answer changes after changing Vv — if Vv changes by dVv, answer changes by chv·dVv.

Then mark all vertexes, which occur in our block at least once (in worst case their number is ). Next, mark every vertex being LCA of some pair of already marked vertexes, using DFS. We can prove that final number of these vertexes is at most . After all this we got 'compressed' tree, containing only needed vertexes. Parent of vertex i in compressed tree we will call vertex numbered Pi.

On the image above example of this 'compression' way is given. Vertexes colored red are vertexes in request block, blue — vertexes marked after LCA, dotted line — Pv → v edges in compressed tree.

Example of compressed tree

On such compressed tree we need to calculate one new value Cv for every vertex v — the size of a vertex, lying on a way from Pv to v after Pv on main (non-compressed) tree (son of a Pv vertex in main tree).

Now we should process request on changing parent of vertex v from pv to u on a compressed tree. The answer will change by pathv·sizev. Now for every vertex i, lying on a way from root to Pv vertex, two values will change: sizei will be decreased by sizev, but chi will be decreased by sizev·(sizei - Ct), (Pt = i), but pathi will stay unchanged. For every other vertex j only pathj will be changed: it will be decreased by . After that, we got compressed subtree where subtree of a vertex v is missing. Next, doing the same way as above, all values are changed considering that v (and all it's subtree) is a children of a vertex u. Do not forget to change Cv too.

Let's see, how the value-changing request of a vertex v is to be processed. As described above, the answer will be changed by chv·dVv. For every vertex i lying in vertex v subtree only pathi will be changed (it could be easy done using Cto values), all other values stay unchanged.

This solution has  complexity, but in N = M case it has to be .

Codeforces Round #274: editorial

By Nerevar, 8 years ago, translation, In English I am happy to present you author's ideas of solutions. Editorial of the first five problem is authored by — HolkinPV and gridnevvvit, editorial for the last two problems is written by me.

479A - Expression In this task you have to consider several cases and choose the best one:

int ans = a + b + c; ans = max(ans, (a + b) * c); 	ans = max(ans, a * (b + c)); 	ans = max(ans, a * b * c);

	cout << ans << endl; 479B - Towers The task is solved greedily. In each iteration, move the cube from the tallest tower to the shortest one. To do this, each time find the position of minimum and maximum in the array of heights (in linear time).

479C - Exams, 480A - Exams The solution is again greedy. Sort the exams by increasing ai, breaking ties by increasing bi. Let’s consider exams in this order and try to take the exams as early as possible. Take the first exams in this order on the early day (b1). Move to the second exam. If we can take it on the day b2 (i.e. b1 ≤ b2), do it. Otherwise, take the second exam on the day a2. Continue the process, keeping the day of the latest exam.

std::sort(a, a + n);  // а is the array of pairs, where first element is the date in schedule, and second is the early date of passing int best = -1; for(int i = 0; i < n; i++) { if (best <= a[i].second) { 		best = a[i].second; 	} else { 	 	best = a[i].first; 	} }	 479D - Long Jumps, 480B - Long Jumps It is easy to see that the answer is always 0, 1 or 2. If we can already measure both x and y, output 0. Then try to measure both x and y by adding one more mark. If it was not successful, print two marks: one at x, other at y.

So, how to check if the answer is 1? Consider all existing marks. Let some mark be at r. Try to add the new mark in each of the following positions: r - x, r + x, r - y, r + y. If it become possible to measure both x and y, you have found the answer. It is easy to check this: if, for example, we are trying to add the mark at r + x, we just check if there is a mark at r + x + y or r + x - y (by a binary search, since the marks are sorted). Make sure that the adde marks are in [0, L].

479E - Riding in a Lift, 480C - Riding in a Lift The task is solved by a dynamic programming. State is a pair (i, j), where i is the number of trips made, and j is the current floor. Initial state is (0, a), final states are (k, v), where v is any floor (except b).

It is easy to see the transitions: to calculate dp(i, j), let’s see what can be the previous floor. It turns out that all possible previous floors form a contiguous segment (with a hole at position j, because we can’t visit the same floor twice in a row). So, dp(i, j) is almost equal to the sum of values dp(i - 1, t), where t belongs to some segment [l, r] (the values of l and r can be easily derived from the conditions from the problem statement). Using pretty standard technique called “partial sums” we can compute dp(i, j) in O(1), so overall complexity is O(NK).

Jury solution: 8322623

480D - Parcels Let’s make two observations.

First, consider the parcels as time segments [ini, outi]. It is true that if at some moment of time both parcel i and parcel j are on the platform, and i is higher than j, then .

Second, let’s imagine that there are some parcels on the platform. It turns out that it is enough to know just a single number to be able to decide whether we can put another parcel on top of them. Let’s denote this value as “residual strength”. For a parcel (or a platform itself) the residual strength is it’s strength minus the total weight of parcels on top of it. For a set of parcels, the residual strength is the minimum of individual residual strengths. So, we can put another parcel on top if it’s weight does not exceed the residual strength.

These observations lead us to a dynamic programming solution. Let the top parcel at the given moment has number i, and the residual strength is rs. Make this pair (i, rs) the state of DP, because it is exactly the original problem, where the platform strength is rs and there are only parcels j with . In d(i, rs) we will store the answer to this instance of the original problem.

Which transitions are there? We can choose a set of parcels i(1), i(2), ... i(k) such that

outi(j) ≤ ini(j + 1), i.e. segments do not intersect (but can touch) and are sorted; the weight of each of these parcels does not exceed rs. This choice corresponds to the following sequence of actions: first put parcel i(1) on the top of i. This gets us to the state i(1), min(rs - wi(1), si(1)), so we add up the answer for this state and the cost of i(1). Then we take away all parcels, including i(1), and put the parcel i(2) on top of i, and so on.

As the number of states in DP is O(NS), all transitions should take linear time. It can be achieved by making an inner helper DP. This give a solution in O(N2S). Note that for simplicity the platform can be considered as a parcel too.

480E - Parking Lot Let’s denote the car arrivals as events.

Consider the following solution (it will help to understand the author’s idea): let’s consider all empty square in the table. There a too many of them, but imagine that we can afford to loop through all of them. If we fix a square, we can find out when it is no longer empty: find the first event that belongs to this square. Let this event has number x, and the size of the square is k. Now we can update the answers for all events with numbers less than x with a value of k.

The model solution use the idea of Divide and Conquer. Let’s make a recursive routine that takes a rectangular sub-table, bounded with r1, r2, c1, c2 (r1 ≤ r2, c1 ≤ c2), and a list of events that happen inside this sub-table. The purpose of the routine is to consider how maximal empty squares in this sub-table change in time, and to update the answers for some of the events.

Let’s assume that c2 - c1 ≤ r2 - r1 (the opposite case is symmetric). Take the middle row r = (r1 + r2) / 2. Virtually split all the squares inside the sub-table into those which lie above r, those which lie below r, and those which intersect r. For the first two parts, make two recursive calls, splitting the list of events as well. Now focus on the squares that intersect the row r.

Using initial table, for each cell (r, c) we can precompute the distance to the nearest taken cell in all four directions (or the distance to the border, if there is no such cell): up(r, c), down(r, c), left(r, c) и right(r, c). Using this values, build two histograms for the row r: the first is an array of values up(r, c), where c1 ≤ c ≤ c2; the second is an array of values down(r, c), where c1 ≤ c ≤ c2. I say histograms here, because these arrays actually can be viewed as heights of empty columns, pointing from the row r upwards and downwards. Lets call the first histogram “upper”, the second one — “lower”. Now consider all events inside the sub-table in the order they happen. Each event changes a single value in a histogram. If after some event x the maximum empty square found in the histograms has size k, and the next event has number y, we can update answers for all events with numbers x, x + 1, ..., y - 1 with the value of k.

It remains to learn to find a maximum square in two histograms. It can be done by a two-pointer approach. Set both pointers to the beginning. Move the second pointer until there is such square in histograms: there is a square with side length k if (minimum on the interval in the upper histogram) + (minimum on the interval in the upper histogram) — 1 >= k. When the second pointer can not be moved any more, update the answer and move the first pointer. To find the minimum in O(1), author’s solution creates a queue with minimum in O(1) support. That is, the maximum square can be found in linear time.

Let’s try to estimate the running time. Each call of the routine (omitting inner calls) costs O(len·q), where len is the shortest side of the sub-table, and q is the number of events in it. If we draw a recursion tree, we will see that each second call len decreases twice. The total cost of all operations in a single level of a recursion tree is O(NK), where K is the total number of events. As long as we have O(logN), overall complexity is O(NKlogN).

Codeforces Round #273 English Editorial (C is available now!)

By xuanquang1999, history, 8 years ago, In English Hello everyone. I have noticed the absence of round 273's editorial, so I decided to write one. This is the first time I write an editorial, so hope everyone like this!

I didn't know how to solve C and E yet, so it would be appreciated if someone help me with these problems.

Also, how to use LaTex in codeforces? I want to use this so my editorial would be more clear to read.

UDP: Actually, there's a (well-hidden) tutorial for this round, but it's written in Russian (with a English version using google translate in comment section). If you can read Russian, click here.

UDP2: Problem C is now available!

A — Initial Bet Since the coin only pass from this player to other player, the coins sum of all player won’t change in the game. That mean, we’ll have 5*b = c1+c2+c3+c4+c5. We’ll put sum = c1+c2+c3+c4+c5. So, if sum is divisible by b, the answer will be sum/b. Otherwise, the answer doesn’t exist.

Be careful with the case 0 0 0 0 0 too, since b > 0, answer doesn’t exist in this case.

My solution: 11607374

Complexity: O(1)

B — Random Teams If a team have a participants, there will be a*(a-1)/2 pairs of friends formed.

For the minimum case, the participants should be unionly – distributed in all the team. More precisely, each team should not have more than one contestant compared to other team. Suppose we’ve already had n div m contestant in each team, we’ll have n mod m contestant left, we now should give each contestant left in first n mod m teams.

For example, with the test 8 3, we’ll first give all team 8 div 3 = 2 contestants, the result now is 2 2 2. We’ll have 8 mod 3 = 2 contestants left, we should each contestant in the first and the second team, so the final result is: 3 3 2.

The maximum case is more simple, we should give only give one contestant in first m-1 teams, and give the last team all the contestant left. For example with above test, the result is 1 1 6.

Since number of the contestant in one team can be 10^9, the maximum numbers of pairs formed can be 10^18, so we should use int64 (long long in c++) to avoid overflow.

My solution: 11607784

Complexity: O(1)

C — Table Decorations spiderbatman has a great idea for this problem. You can read his comment here.

The order of the balloons isn't important, so instead or r, g, b, we'll call them a[0], a[1], a[2] and sort them in ascending order. We'll now have a[0] <= a[1] <= a[2].

There's two case:

2*(a[0]+a[1]) <= a[2]. In this case, we can take a[0] sets of (1, 0, 2) and a[1] sets of (0, 1, 2), so the answer is a[0]+a[1].

2*(a[0]+a[1]) > a[2]. In this case, we can continuously take a set of two balloon from a[2] and a balloon from max(a[0], a[1]) until a point that a[2] <= max(a[0], a[1]). At this point, max(a[0], a[1])-a[2] <= 1, and since max(a[0], a[1]) - min(a[0], a[1]) <= 1 too, max(a[0], a[1], a[2]) - min(a[0], a[1], a[2]) <= 1. All we have to do left is take all possible (1, 1, 1) group left. Since we only take the balloons in group of 3, (a[0]+a[1]+a[2]) mod 3 doesn't change, so there will be at most (a[0]+a[1]+a[2]) mod 3 balloons wasted. We go back to the beginning now. The answer is (a[0]+a[1]+a[2]) div 3.

My solution: 11614150

Complexity: O(1)

D — Red-Green Towers For more convenient, we’ll call a function trinum(x) = (x*(x+1))/ 2, which is also the number of blocks needed to build a tower with height x.

First, we’ll find h, the maximum height possible of the tower. We know that h <= trinum(l+r). Since (l+r) <= 2*10^5, h <= 631, so we can just use a brute-force to find this value.

Now, the main part of this problem, which can be solved by using dynamic programming. We’ll call f[ih, ir] the number of towers that have height ih, can be built from ir red block and trinum(ih)-ir green blocks.

For each f[ih, ir], there’s two way to reach it:

Add ih red block. This can only be done if ih <= ir <= min(r, trinum(ih)). In this case, f[ih, ir] = f[ih, ir] + f[ih-1, ir-ih].

Add ih green block. This can only be done if max(0, trinum(ih)-g) <= ir <= min(r, trinum(ih-1)). In this case, f[ih, ir] = f[ih, ir] + f[ih-1, ir-ih].

The answer to this problem is sum of all f[h, ir] with 0 <= ir <= r.

We will probably get MLE now...

MLE solution: 11600887

How to improve the memory used? We'll see that all f[ih] can only be affected by f[ih-1], so we'll used two one-dimension arrays to store the result instead of a two-dimension array. The solution should get accepted now.

Accepted solution: 11600930

Complexity: O(r*sqrt(l+r))

E — Wavy numbers Unfinished...

Codeforces Round #272 Editorial

By drazil, 8 years ago, In English First I want to thank all the problem solvers! Hope you had or are going to have a good time with Dreamoon!

If you think there's something that can be improved in this editorial please let me know!

Definitions used in this editorial: ⌈⌉ stands for ceiling function. ⌊⌋ stands for floor function.  stands for real division. For non-negative integer a and positive integer b, div(a, b) stands for integral division, . For non-negative integer a and positive integer b, mod(a, b) stands for module operation, a = div(a, b) * b + mod(a, b). length(string) is the length of string. For non-negative integer a ≤ b, A[a..b] stands for the set of A[a], A[a + 1], A[a + 2]... A[b - 1] when A is an array and the substring of A consists of ath to (b - 1)th character(inclusive) of A when A is a string. For such substring we have length(A[a..b]) = b - a. C(a, b) stands for the combination function, the ways of selecting a elements from a group of b elements.

476A - Dreamoon and Stairs We can show that the maximum number of moves possible is n and minimal moves needed is , so the problem equals to determine the minimal integer that is a multiple of m in the range . One way to find the minimal number which is a multiple of m and greater than or equal to a number x is , we can compare this number to the upper bound n to determine if there is a valid solution. Although best practice is O(1), O(n) enumeration of each possible number of moves would also work. time complexity: O(1) sample code: 8212169 explanation of sample code: The  can be calculated in the following c++ code if a is non-negative and b is positive: (a+b-1)/b Because / in c++ is integral division so (a+b-1)/b would result in  Let a = div(a, b)b + mod(a, b) = db + m, . Which means if , otherwise div(a + b - 1, b) = d + 1. Can be translated to if , otherwise div(a + b - 1, b) = div(a, b) + 1. Which matches the value of .

476B - Dreamoon and WiFi The order of moves won't change the final position, so we can move all '?'s to the end of the string. We have the following information: 1. the correct final position 2. the position that Dreamoon will be before all '?'s 3. the number of '?'s We can infer that the distance and direction dreamoon still needs to move in the '?' part from 1. and 2., and furthur translate that to how many +1s and -1s dreamoon will need to move. What's left is a combinatorial problem, the probability would be . So we can compute that formula within O(n) time assuming n is the length of commands, but since N is small so we can brute force every possible choice of '?' with some recursive or dfs like search in O(2n) time complexity. Note that the problem asks for a precision of 10 - 9, so one should output to 11 decimal places or more. time complexity: O(n), assuming n is the length of commands. sample code: 8215177

476C - Dreamoon and Sums / 477A - Dreamoon and Sums If we fix the value of k, and let d = div(x, b), m = mod(x, b), we have : d = mk x = db + m So we have x = mkb + m = (kb + 1) * m. And we know m would be in range [1, b - 1] because it's a remainder and x is positive, so the sum of x of that fixed k would be . Next we should notice that if an integer x is nice it can only be nice for a single particular k because a given x uniquely defines div(x, b) and mod(x, b). Thus the final answer would be sum up for all individual k:  which can be calculated in O(a) and will pass the time limit of 1.5 seconds. Also the formula above can be expanded to . Dreamoon says he's too lazy to do this part, so if you use O(1) solution you just computed the answer faster than Dreamoon!!! Note that no matter which approach one should be very careful of overflowing of the integer data type of the used language. For example one should do a module after every multiplication if using 64-bit integer type. And pay attention to precedence of operations: take c++ for example a+b%c would be executed as a+(b%c) instead of (a+b)%c, another c++ example a*(b*c)%m would be executed as (a*(b*c))%m instead of a*((b*c)%m). Thanks saurabhsuniljain for pointing out the preceding problem and examples in the comment! time complexity: O(1) sample code: 8215188

476D - Dreamoon and Sets / 477B - Dreamoon and Sets The first observation is that if we divide each number in a set by k, than the set would be rank 1. So we could find n sets of rank 1 then multiple every number by k. For how to find n sets of rank 1, we can use {6a + 1, 6a + 2, 6a + 3, 6a + 5} as a valid rank 1 set and take a = 0 to n - 1 to form n sets and thus m = (6n - 1) * k. The proof that m is minimal can be shown by the fact that we take three consecutive odd numbers in each set. If we take less odd numbers there will be more than 1 even number in a set which their gcd is obviously a multiple of 2. And if we take more odd numbers m would be larger. The output method is straight forward. Overall time complexity is O(n). time complexity: O(n) sample code: 8215198

476E - Dreamoon and Strings / 477C - Dreamoon and Strings First let A[i] to be the minimal length L needed so that substring s[i..i + L] can become pattern p by removing some characters. We can calculate this greedily by keep selecting next occurrence of characters in p in O(length(s)) time for a fixed i, so for all i requires O(length(s)2). Next we can do a dp D[i][j] where D[i] is the answer array for s[0..i]. D[i] can contribute to D[i + 1] with 0 or 1 removal and to D[i + A[i]] with A[i] - length(p) removal(s). In other words, D[i][j] can transition into tree relations D[i + 1][j] = D[i][j] //not delete s[i], D[i + 1][j + 1] = D[i][j] //delete s[i], and D[i + A[i]][j + A[i] - length(p)] = D[i][j] + 1 //form a substring p by deleting A[i] - length(p) characters. Calculate forwardly from D[0] to D[length(s) - 1] gives the final answer array as D[length(s)]. Calculating D[i] requires O(length(s)) time for a fixed i, so for all i takes O(length(s)2) time. time complexity: O(n2), n = length(s) sample code: 8215203

Another solution: Let k = div(length(s), length(p)). We can run an edit distance like algorithm as following (omitting the details of initialization and boundary conditions):

for(i=0;i<n;i++)     for(j=0;j<k*p;j++)         if(s[i]==p[j%length(p)])             D[i][j] = D[i-1][j-1]          D[i][j] = min(D[i][j], D[i-1][j] + (j%length(p)!=length(p)-1)) That means remove cost is 1 when it is in the middle of a p and 0 elsewhere because p need to be consecutive(thus no need to be actually remove outside of a p). Then D[n][t * length(p)] is the minimal number of removals to have t non-overlapping substring of p. So we have answer[D[n][t * length(p)..(t + 1) * length(p)] = t. And after the maximal t is reached, decrease answer by 1 for every length(p). time complexity: O(n2) sample code: 8215394

477D - Dreamoon and Binary Let Xb be the binary string of number X. An ideal sequence can be expressed as a partition of Xb: P1 = Xb[1..p1], P2 = Xb[p1..p2], ... PK = Xb[pK - 1..length(Xb)] where Pi ≤ Pi + 1. The length of operations of such sequence is PK + K. We can calculate the number of different ideal sequences by dp. State D[i][j] stands for the answer of state that we have print Xb[1..j] and last partition is Xb[i..j]. A possible way of transition is that a state D[i][j] can go to state D[i][j + 1] and D[j][k] where k is the minimal possible position such that value of Xb[j..k] is equal to or greater than the value of Xb[i..j] and Xb[j] is 1 since we can't print any leading 0. Note that D[j][k + 1] can also derived from D[i][j] but it will covered by D[i][j] → D[j][k] → D[j][k + 1], so we don't need to consider this case to avoid redundant counts. If we can determine k for each i, j pair in O(1) then we can compute this dp in O(length(Xb)2) in the following manner:

for(j=0;j<n;j++)     for(i=0;i<j;i++)         compute the transitions of D[i][j] So let's look into how to calculate the value k for a given i, j pair. If the value of Xb[j..2j - i] is equal to or greater than Xb[i..j] than k is 2j - i because if k is less than 2j - i would make length of the new partition less than the previous partition thus its value would be lesser. And if k can't be 2j - i, the value of 2j - i + 1 is always a valid choice because it would make the length of the new partition greater than the previous one. So for each length L if we know the order of Xb[i..i + L] and Xb[i + L..i + 2L] in O(1) time we can calculate k in O(1) time(can be easily shown by assuming L = j - i). One way of doing such is using prefix doubling algorithm for suffix array construction to build a RMQ structure for query in O(1) time. The prefix doubling algorithm requires O(nlgn) precompute time. Note there is still a various of ways to do this part of task in the same or better time complexties. And for the shortest length part we can compute the minimal parts needed so far for each state along with the preivous dp. Then compare all states ends with j = length(Xb). Overall we can solve this problem in O(length(Xb)2) with caution in details like boundaries and module operations. time complexity: O(n2), n = length(Xb) Note the sample code use a nlgnlgn version of prefix doubling algorithm sample code: 8215216

477E - Dreamoon and Notepad Although swapping two parts of a query would result in different answer, if we reverse the lines length alltogether then the answer would stay the same. So we only analyze queries where r2 ≥ r1. The answers would comes in several types, we’ll discuss them one by one: 1. HOME key being pressed once: the answer will be 1(HOME) + r2 - r1(down keys) + c2(right keys). Note that this is the best answer if the HOME key is ever pressed once, so we won’t consider HOME key anymore. This step is O(1) for a single query, thus O(q) in total. 2. direct presses r2 - r1 down keys and no or one END key in those rows: because the cursor position will be reset to the row length if we go down to a row with length less than current cursor position, the possible positions that can be at row p if we start at end of each previous rows can be track with a stack. The position directly pressing only down keys from r1 to r2 is min(c1, the length of first row after r1 in stack). We can use a binary search to get the first row after or equal r1 in stack. From that row till r2 in the stack are the positions possible when pressing ONE END key (pressing more won’t get more possible positions), we can use a binary search to find the position closest to c2 which is the best. We can sort all queries and use O(qlgn) time for queries and O(n) time for maintaining stack, so O(qlgn + n) in total. 3. go back some rows and press one or no END key at the row: we only interested in END OF rows in stack constructed in 2.. We can use a binary search in stack to identify the range of rows interested. For those lengths of row less than c2(also can use a binary search to locate) we only need to consider the first one encountered(closest to r1), note still need to consider if it needs an END key for this case. For those lengths of row greater than or equal to c2, the answer would be r1 + r2 - 2 * (row reached) + (length of the row) - c2 + (1 if length of the row greater than c1). The terms related to row in the previous formula is 2 * (row reached) + (length of the row) + (1 if length of the row greater than c1). We can identify the range with and without +1(last term) and query in a segment tree of the minimal value of 2 * (row reached) + (length of the row) for each range. Thus the time need here is O(nlgn) for maintaining segment tree and O(qlgn) for query while sharing with the stack of 2., so O(nlgn + qlgn) in total. 4. go beyond r2 some rows and press no or one END at the row: this needs a reversed stack and very similar approach of 3.. The time complexity is the same as 2. and 3.. So the total time complexity is O((n + q)lgn), note this problem is very hard to get the code right. time complexity: O((n + q)lgn) sample code: 8212528

Codeforces Round #271 (Div. 2) Editorial

By scipianus, 8 years ago, In English 474A - Keyboard

This is an implementation problem, therefore most of the solution fit in the time limit. We can even save the keyboard in 3 strings and make a brute force search for each character to find its position and then print the left/right neighbour.

474B - Worms

There are two solutions:

We can make partial sums (sumi = a1 + a2 + ... + ai) and then make a binary search for each query qi to find the result j with the properties sumj - 1 < qi and sumj ≥ qi. This solution has the complexity O(n + m·log(n))

We can precalculate the index of the pile for each worm and then answer for each query in O(1). This solution has the complexity O(n + m)

474C - Captain Marmot

For each 4 points we want to see if we can rotate them with 90 degrees such that we obtain a square. We can make a backtracking where we rotate each point 0, 1, 2 or 3 times and verify the figure obtained. If it's a square we update the minimal solution. Since we can rotate each point 0, 1, 2 or 3 times, for each regiment we have 44 configurations to check. So the final complexity is about O(n).

474D - Flowers

We can notate each string as a binary string, instead of red and white flowers. A string of this type is good only if every maximal contigous subsequence of "0" has the length divisible by k. We can make dynamic programming this way : nri = the number of good strings of length i. If the i-th character is "1" then we can have any character before and if the i-th character is "0" we must have another k - 1 "0" characters before, so nri = nri - 1 + nri - k for i ≥ k and nri = 1 for i < k. Then we compute the partial sums (sumi = nr1 + nr2 + ... + nri) and for each query the result will be sumb - suma - 1. This solution has the complexity O(maxVal + t), where maxVal is the maximum value of bi.

474E - Pillars

We have to find a substring i1, i2, ..., ik such that abs(hij - hij + 1) ≥ D for 1 ≤ j < k. Let's suppose that the values in h are smaller. We can make dynamic programming this way : besti = the maximal length of such a substring ending in the i-th position, besti = max(bestj) + 1 with j < i and hj ≥ D + hi or hj ≤ hi - D. So we can easily search this maximum in a data structure, such as an segment tree or Fenwick tree. But those data structure must have the size of O(maxH) which can be 109. For our constraints we mantain the idea described above, but instead of going at some specific position in the data structure based on a value, we would normalize the values in h and binary search the new index where we should go for an update or a query in the data structure. Therefore, the data structure will have the size O(n). The complexity of this solution is O(n·log(n)).

474F - Ant colony

For each subsequence [L, R] we must find how many queens we have. A value is "queen" only if is the GCD of (sL, sL + 1, ..., sR). Also, we must notice that the GCD of (sL, sL + 1, ..., sR) can be only the minimum value from (sL, sL + 1, ..., sR). So for each query we search in a data structure (a segment tree or a RMQ) the minimum value and the GCD of (sL, sL + 1, ..., sR) and if these two values are equal then we output the answer R - L + 1 - nrValues, where nrValues is the number of values in the subsequence equal to the GCD and the minimum value. The complexity of this solution is O(n·log(n)·log(valMax) + t·log(n)·log(valMax)), where valMax is the maximum value of si.

Codeforces Round #270 Editorial

By cgy4ever, 8 years ago, In English 472A - Уроки дизайна задач: учимся у математики

One way to solve this is by bruteforce: there are O(n) different ways to decomose n as sum of two number. If we can check if a number is a prime in O(1) then the whole algorithm can run in O(n). You can use Sieve of Eratosthenes to do the pre-calculation.

And another way is try to prove this theorem. The prove is simple: if n is odd number, then 9 and (n-9) is an answer (n-9 is an even number at least 4, so a composite number), and if n is even number, then 8 and (n-8) is an answer (n-8 is an even number at least 4, also must be a composite number).

472B - Уроки дизайна задач: учимся у жизни

This task can be solve by greedy: the k people with highest floor goes together, and next k people with highest floor goes together and so on. So the answer is 2 * ((f[n]-1) + (f[n-k]-1) + (f[n-2k]-1) + ...) .

It is a bit tricky to prove the correctness of greedy, since people can get off the elevator and take it again. We can give a lower bound of the answer by flow analysis: between floor i and floor i+1, there must be no more than (# of f[i] >= i+1) / k times the elevator goes up between these 2 floors, and then there be same number of times goes down. We can find this lower bound matches the answer by above greedy algorithm, so it means the greedy algorithm gives an optimal answer.

472C - Уроки дизайна задач: недетеминированность

This one laso can be solved by greedy, let's think in this way: let pick one with smallest handle, then we let him/her use min(firstName, secondName) as handle. And go for the next one (2nd mallest handle), now he/she must choose a handle greater than handle of previous person, and if both meet this requirement, he/she can pick a small one.

This time the correctness of this greedy solution can be proved by exchange argument.

Note that if we change the goal of this problem: ask number of different permutations they can get, then it will be very hard. (I tried it for hours but can't solve.)

472D - Уроки дизайна задач: обратные задачи

Let's think it in the following way: for the minimal length edge, it must belong the the tree, ..., for the k-th minimal length edge(a, b), if there is already an path between a-b, then it can not be an edge of tree anymore, otherwise it must be edge of tree, why? Because otherwise there must be a path from a to b in the tree, that means a and b can be connected by edges with less length, but a and b is not connected.

So this Kruskal style analysis gives us this theorem: if there is an answer, then the answer must be the MST of that graph. (You can also guess this theorem and try to prove it.)

You can solve MST in O(n^2 log n), and then there are many way to check distance between notes on tree: you can just simply do dfs or bfs from each node, it can run in O(n^2). Or if you have pre-coded LCA algorithm, it can run in O(n^2 log n).

472E - Уроки дизайна задач: учимся у игр

First let's solve some special cases:

If the initial board and the target board contains different orbs, then there can't be a solution.

If n = 1 (or m = 1), then we can try all O(m^2) (or O(n^2)) possible moves.

And for the other cases, there always have solution. We first hold the orb with number target[1][1] in initial board. Then we want to move other orbs to their position.

So let's come up with a process to move orb from (a, b) to (c, d): it must be some continue path from (a, b) to (c, d), so we want to build a single move: it will move an orb from (a, b) to an adjacent cell (c, d). How to do that? We can move our touching orb to (c, d) first, and then move to (a, b). But there are some concerns: in this move, the touching orb shouldn't pass any already-done cells, and it shouldn't pass (a, b) when we get to (c, d).

That means we need a good order to move orbs. We can do it in this way: first, as long as there are more than 2 rows, we move the orbs to last row (from left to right or right to left). And then it must be 2xm boards: we do it column by column from right to left. We can find that in this order, there always exist paths for our touching orb to get (c, d).

472F - Уроки дизайна задач: меняем цель задачи

You need to know some knowledge about linear algebra and notice the operation of xor on 32 bit integers equals to + operation in a 32 dimension linear space. If you don't know, you should learn it from the editorial of similar tasks, for example, Topcoder SRM 557 Div1-Hard.

We need to know some basic properties of our operation:

we can swap two number a and b by: a^=b, b^=a, a^=b.

This operation is inversible, the inverse is itself.

By property 1 we can do the Gaussian elimination of each set of vectors.

By property 2 we can use this way to build an answer: use some operation to make A[] into a base (linear independent vectors that the span will be A[]), then transfer it into a base of B[], then use the inverse of Gaussian elimination to recover B[].

So now we have two bases: {a1, a2, ..., ax} and {b1, b2, ..., by}. If there exists some bi such that it can't be expressed as a linear combination of {a1, a2, ..., ax}, the solution can't exists.

Otherwise there always exists a solution: first we build b1 and put it in the first position. Suppose b1 = a2 ^ a3 ^ a8, then we swap any of them, say, a2 into position one, and then xor it with a3 and a8, then we get b1. Note that after this operation {a1, a2, ..., ax} will remain a base. And we need to ensure we don't erase already-done numbers in a.

472G - Уроки дизайна задач: увеличиваем ограничения

Let's start with a simpler task: we have string A and B (|A|, |B| <= n), we have q queries and each query we ask the Hamming distance between A and a substring of B with length equals to |A|.

How to solve this? We need to notice compute A with different offset of B is similar to the computation of convolution, so it can be done by FFT.

We use +1 to replace '1' and we use -1 to replace '0', and then we do the convolution of A and reverse B. We can extract the answer of all possible query of "the Hamming distance between A and a substring of B with length equals to |A|."!

Then let's come back to our problem, how to use this way to make a faster solution? We can use a way like sqrt decompose: we divide A into L blocks, for each block, we compute the convolution of this part with B, it will takes O(n*L*logn). And for each query, we can use the pre-calculated results to speedup (if a whole block contains in the query, we can compute it in O(1)). So each query needs no more than O(L) operation.

If n = q then this solution can run in O((n*logn) ^ 1.5). But in practice it has some issues: for example, we can use bit operation to speedup like __builtin_popcount(). I tried to set constraints to fail solution with only bit optimization, but seems I failed: I apologies to allow this kind of solutions passed. (I used __builtin_popcount() to test such solution, but in fact cnt[x<<16] + cnt[x>>16] is much faster than the builtin fucnion)

(Also, you can use your knowledge about real world computers to solve this task: http://codeforces.com/contest/472/submission/8014415)

Codeforces Round #269 Editorial

By marat.snowbear, 8 years ago, In English 471A - MUH and Sticks Given six sticks and their lengths we need to decide whether we can make an elephant or a bear using those sticks. The only common requirement for both animals is that four leg-sticks should have same length. This means that the answer "Alien" should be given only if we can't find four sticks for the legs. Otherwise we will be able to make some animal. The type of the animal will depend on the relation of the remaining sticks' lengths. If they are equal then it will an elephant, if they are different we will have a bear.

So this algorithm should solve the problem:

Find the number which appears at least four times in the input.

If no such number exist then the answer is "Alien".

Otherwise remove four entries of that number from the input.

After removing that number you will have two numbers left, compare them and decide whether it's an elephant or a bear.

One shortcut for this problem might be to sort the input array, then if it's a bear or an elephant then 3rd and 4th elements in the sorted should be animal's legs. So you can assume that one of these numbers is the length of the leg and count how many times you see this number in the input.

Author's solution: 7977022

Since the numbers in the input are very small you can implement 'brute force' solution as well. By brute force solution in this case I mean that you can actually check all possible values for leg-length, head-length and body-length. If in total they give the same set as the input then you found a matching, all you need is to check whether it's a bear or an elephant. And it's an alien if you checked all possible combinations and found nothing matching to the input. Though in this case the brute force solution is not easier than another one.

Checking all possible lengths solution: 7975645

It seems that there were two common mistakes people were making in this problem:

Not taking into account that legs can be of the same length as body or head. So you can't just count the number of distinct numbers in the input to decide which type of animal is that. We assumed that people might make such a mistake, there was a relevant warning in the statement.

Trying to sort the input and then check whether some elements in this array are equal to other elements and based on this comparison decide which type of animal is that. People were simply making mistakes when deciding which elements to compare. The correct way to implement this is:

 // 0-indexing below, array is assumed to be sorted

     if (l[0] == l[3]) cout << (l[4] == l[5] ? "Elephant" : "Bear"); else if (l[1] == l[4]) cout << "Bear"; else if (l[2] == l[5]) cout << (l[0] == l[1] ? "Elephant" : "Bear"); else cout << "Alien"; Solution: 7977214

This solution seems to be shorter but there are many failed solutions like this because people were not paying enough attention to the details. So I would prefer implementing more straightforward approach.

Hope you liked the pictures!

471B - MUH and Important Things You need to check whether exist three pairwise different permutations of the indices of the input which result in array being sorted. Generally you can count the number of total permutation which give non-decreasing array. This number might be very large and it might easily overflow even long integer type. And what is more important is that you don't actually need to count the exact number of such permutations.

Let's tackle this problem from another angle. Assume you already sorted the input array and you have the corresponding permutation of indices. This already gives you one array for the result, you only need to find two more. Let's look for any pair of equal numbers in the input array, if we swap them then we will get another valid permutation. And if we find one more pair of equal numbers then swapping them you can get third permutation and that will be the answer. You need to keep in mind here that one of the indices when swapping the second time might be the same as one of the numbers in the first swap, that's ok as soon as second index is different. So all you need to do is to find two pairs of indices which point to the equal elements.

The entire algorithm is as follows:

Transform the input array into array of pairs (tuples), first element of the pair will be the number given in the input array, the second element will be the index of that number.

Sort that array of pairs by the first element of the pairs. Then the second elements will give you one correct permutation.

Scan this array in order to find possible swaps. You just iterate over this array and check if the first element in the current pair equals to the first element of the previous pair. If it equals you remember the indices of these two pairs. You stop scanning the array as soon as you have two swaps.

Then you check how many swaps you have, if you have less than two swaps then there are no three distinct permutations.

Otherwise you have two swaps which means that you have an answer. So you print the current permutation, then you execute the first swap (you just swap those two elements you remembered in the first swap), then you print the permutation array received after executing that swap. And you execute the second swap and print the permutation array third time.

Author's solution: 7977528

471C - MUH and House of Cards Card house. This problem required some maths, but just a little bit. So in order to start here let's first observe that the number of cards you need to use for a complete floor with R rooms equals to:

C = Crooms + Cceiling = 2·R + (R - 1) = 3·R - 1

Then if you have F floors with Ri rooms on the i-th floor then the total number of cards would be:



where R is the total number of the rooms in the card house.

This already gives you an important property — if you divide N + F on 3 then the remainder of this division should be 0. This means that if you have found some minimum value of floors somehow and you found maximum possible number of floors in the house, then within that interval only every third number will be a part of the solution, the rest of the numbers will give a non-zero remainder in the equation above.

Now let's think what is the highest house we can build using N cards. In order to build the highest possible house obviously you need to put as few cards on each floor as you can. But we have a restriction that every floor should have less rooms than the floor below. This gives us the following strategy to maximize the height of the house: we put 1 room on the top floor, then 2 rooms on the floor below, then 3 rooms on the next floor, etc. In total then the number of cards we will need equals to:



This is minimum number of cards we need in order to build a house with F floors. This gives us a way to calculate the maximum height of the house we can build using N cards, we just need to find maximum F which gives Nmin <  = N. Mathematicians would probably solve the quadratic inequation, programmers have two options:

Check all possible F until you hit that upper bound. Since Nmin grows quadratically with F then you will need to check only up to  numbers. This gives  time complexity and fits nicely in the given time limit.

The second approach would be a binary search. Using binary search to find maximum number of the floors would give you O(logN) time complexity. This was the intended originally solution but it was decided to lower the constraints in order to allow sqrt solutions as well.

Now that you know the maximum number of the floors in the house you might need to correct it a bit because of that remainder thing we discussed above, this might make your maximum height one or two floors lower. Looking again at the remainder discussion on top we can see that starting from here only every third number will be valid for an answer. Now you can either count them brutally (back to  solution) or you can simply calculate them using this formulae:

ans = (Fmax + 3 - 1) / 3 (integer division)

That seems to be it, just don't forget to use longs all the time in this problem.

Author's O(logN) solution: 7977863

Authors  solution: 7977888

471D - MUH and Cube Walls In this problem we are given two arrays of integers and we need to find how many times we can see second array as a subarray in the first array if we can add some arbitrary constant value to every element of the second array. Let's call these arrays a and b. As many people noticed or knew in advance this problem can be solved easily if we introduce difference arrays like that:

aDiffi = ai - ai + 1 (for every i =  = 0..n - 1)

If we do that with both input arrays we will receive two arrays both of which have one element less than original arrays. Then with these arrays the problem simply becomes the word search problem (though with possibly huge alphabet). This can be solved using your favourite string data structure or algorithm. Originally it was intended to look for linear solution but then we made time limit higher in case if somebody will decide to send O(NlogN) solution. I haven't seen such solutions (that is understandable) but some people tried to squeeze in a quadratic solution.

Linear solution can be made using Z-function or KMP algorithm. In order to add a logarithmic factor you can exercise with suffix array for example. I had suffix array solution as well, but it's a lot messier than linear solution.

There is one corner case you need to consider — when Horace's wall contains only one tower, then it matches bears' wall in every tower so the answer is n. Though for some algorithms it might not even be a corner case if you assume that empty string matches everywhere. Another error which several people did was to use actual string data structures to solve this problem, so they converted the differences to chars. This doesn't work since char can't hold the entire range an integer type can hold.

I didn't think that switching to difference arrays will be that obvious or well-known, so I didn't expect that this problem will be solved by that many people.

Author's Z-function O(n + w) solution: 7978022

Author's suffix array O((n + w)·log(n + w)) solution: 7978033

471E - MUH and Lots and Lots of Segments Given a set of horizontal/vertical lines you need to erase some parts of the lines or some lines completely in order to receive single connected drawing with no cycles.

First of all let's go through naive N2 solution which won't even remove cycles. In order to solve this problem you will need a DSU data structure, you put all your lines there and then for every pair of horizontal and vertical line you check if they intersect and if they do you join them in DSU. Also your DSU should hold the sum of the lengths of the joined lines. Initially it should be equal to the line lengths. Since there might be up to N2 / 4 intersections between lines we receive a quadratic solution.

Now let's get rid of cycles. Having the previous solution we can do it pretty easily, all we need is to change the way we were connecting the sets in DSU if some lines intersect. Previously we were simply asking DSU to join them even if they already belong to the same set. Now what we will do is when finding some pair of lines which intersects and is already joined in DSU instead of asking DSU to join them again we will ask DSU to decrement their length sum. In terms of the problem it is equivalent to erasing a unit piece of segment in the place where these two lines intersect and this will break the cycle. With this change we already have a correct solution which is too slow to pass the time limits.

Now we need to make our solution work faster. We still might have up to N2 / 4 intersections so obviously if we want to have a faster solution we can't afford to process intersections one by one, we need to process them in batches. All our lines are horizontal and vertical only, so let's do a sweep line, this should make our life easier.

Let's assume that we're sweeping the lines from the left to the right. Obviously then the code where the intersections will be handled is the code where we process the vertical line. Let's look at this case closer. We can assume that we're going to add some vertical line on with coordinates (x, y1, x, y2), we can also assume that there are some horizontal lines which go through the given x coordinate, we track this set of lines while sweeping left to right. So we're going to add a vertical line and let's say that it has n intersections with horizontal line. Previously we were handling each intersection separately, but you can see that if some horizontal lines already belong to the same set in DSU and they go next to each other then we don't need to handle them one by one anymore. They already belong to the set in DSU so there is no need to join them, we might only need to count the number of them between y1 and y2 coordinates, but that can be calculated in logarithmic time. So the trick to get rid of quadratic time complexity is to avoid storing horizontal lines one by one and store instead an interval (across y coordinate) of horizontal lines which belong to the same set in DSU. I will call these intervals chunks. You will need to manipulate these chunks in logarithmic time and you will need to locate them by y coordinate so you need to store them in a treap or a STL map for example with y coordinate serving as a key.

To be clear let's see what data each of these chunks will hold:

struct chunk{ 	int top, bottom; // two coordinates which describe the interval covered by the chunk 	int id; // id of this chunk in DSU. Several chunks might have the same id here if they belong to the same set in DSU }; And we agreed that data structure which holds these chunks can manipulate them in logarithmic time.

Let's now get into details to see how exactly it works. While sweeping we will have one of three possible events (listed in the order we need to handle them): new horizontal line starting, vertical line added, horizontal line finishing. First and third operation only update our chunks data structure while the second operation uses it and actually joins the sets. Let's look into each of these operations:

horizontal line start. We need to add one more chunk which will consist of a single point. The only additional operation we might need to do happens when this new line goes through some chunk whose interval already covers this point. In this case we need to split this covering chunk into two parts — top and bottom one. It's a constant number of updates/insertions/removals in our chunk data structure and we agreed that each of these operations can be done in logarithmic time so the time complexity of a single operation of this time is O(logN). It should be also mentioned here that during processing a single operation of this type we might add at most two new blocks. Since in total we have no more than N operations of this type them it means that in total we will have no more than 2·N blocks created. This is important for the further analysis.

vertical line. In this operation we need to find all chunks affected by this vertical line and join them. Each join of two chunks takes logarithmic time and we might have up to n chunks present there, so we might need up O(NlogN) time to draw a single vertical line. This doesn't give us a good estimate. But we can see that we have only two ways to get new chunks — they are either added in the step 1 because it's a new line or one chunk is being split into two when we add a line in between. But we have an upper bound on total number of the chunks in our structure as shown above. Ans since we have such an upper bound then we can say that it doesn't matter how many chunks will join a single vertical line because in total all vertical lines will not join more than 2·N chunks. So we have an amortized time complexity analysis here, in total all vertical line operations will take O(NlogN) time.

There are some other details we need to handle here. For example we need to avoid cycles correctly. This margin is too narrow to contain the proof but the formulae to correct the length sum is like this:

d = y2 - y1 - (Nintersections - 1) + Ndistinctsets - 1

where d — the number you need to add to the sum of the lengths in DSU

Nintersections — number of horizontal lines intersecting with the given vertical line, I used a separate segment tree to get this value in O(logN)

Ndistinctsets — number of distinct sets in DSU joined by this vertical line, you need to count them while joining

So this gives you a way to correct the lengths sums. There is one more thing that needs to be mentioned here — it might happen that your vertical line will be contained by some chunk but will not intersect any horizontal lines in it. In this case you simply ignore this vertical line as if it doesn't overlap any chunk at all.

horizontal line end. Finally we came here and it seems to be simple. When some horizontal line ends we might need to update our chunks. There are three cases here:

a. This line is the only line in the chunks — we simply delete the chunk then.

b. This line lays on some end of the interval covered by the chunk — we update that end. In order to update it we need to know the next present horizontal line or the previous present horizontal line. I used the same segment tree mentioned above to handle these queries.

c. This line lays inside some chunk — we don't need to update that chunk at all.

And that's it! In total it gives O(NlogN) solution.

Author's solution: 7978166 (that chunk data structure is called 'linked_list' in the code because originally I thought it would be a linked list with some way to manipulate it quickly and later I removed all the list functionality).

This editorial was written very late in the night, I'm pretty sure there are tons of typos here, I will proof read it tomorrow, but please don't hesitate to report typos and some minor error to be fixed in private messages.

Codeforces Round #268 Editorial

By amiya, 8 years ago, In English I'll upload my example solutions and will post links to them as soon as it becomes possible.

All the problems in Div 1 don't have the unique solution. I list several solutions to each problems. There are also some interesting bonus problems. I can't solve some of them yet :( If you have interesting ideas, feel free to share and discuss your ideas in the comments. :)

My English is poor, so if there are some mistakes or something you can't understand, you can also discuss it in the comments.

469A - I Wanna Be the Guy

I Wanna Be the Guy is an interesting game. I strongly recommend it to you.

The problem itself is easy. Just check if all the levels could be passed by Little X or Little Y.

7894174

469B - Chat Online

This problem is not hard. Just iterator over all possible t, and check if the schedule of Little X and Little Z will overlap.

7894252

Bonus:

p, q ≤ 50, l, r ≤ 109 p, q, l, r ≤ 105 468A - 24 Game

Solution 1:

If n ≤ 3, it's easy to find that it's impossible to make 24, because the maximal number they can form is 9.

If n > 5, we can simply add n - (n - 1) = 1, 24 * 1 = 24 at the end of the solution to the number n - 2.

So we can find the solution of 4, 5 by hand. 1 * 2 * 3 * 4 = 24, (5 - 3) * 4 * (2 + 1) = 24

7894267

Solution 2:

We can find the pattern like that n + (n + 3) - (n + 1) - (n + 2) = 0, and find the solution of 4, 5, 6, 7 by hand or brute forces.

Solution 3:

A knapsack-like solution.

7894283

468B - Two Sets

Solution 1:

If we have number x and a - x, they should be in the same set. If , it's obvious that . The contraposition of it is , that means if , a - x should in the set B. Same as the number x, b - x.

So we can use Disjoint Set Union to merge the number that should be in the same set.

If a - x doesn't exist, x can not be in the set A. If b - x doesn't exist, b can not be in the set B.

Then check if there are any conflicts among numbers which should be in the same set.

There are many other solutions to solve this problem based on the fact that x, a - x, b - x should be in the same set, like greedy, BFS and 2-SAT.

7894313

Solution 2:

If a = b, it's easy to find the solution.

We regards every number as a node. Every number x links to number a - x and number b - x.

The degree of every node is at most 2. So this graph consists of a lot of chains and cycles, and some node may have self loop.

We only need to check if the lengths of all the chains are even or the chain ends with a self loop.

7894323

Bonus:

Prove there is no cycle in the graph described in the solution 2.

Divided all the numbers from [0, n - 1] into two sets that have parameters a, b. Can you solved it in O(1)?

468C - Hack it!

Define . , so we should find a pair of number a, b that 

Solution 1:

First we choose x randomly. Then we can use binary search to find the minimal d that  .

So  is very small, between 0 and . If , after choosing x atmost 9 * len + 2 times, we can definitely find a pair that 

7894341

Solution 2:

We can use binary search to find the minimal d that g(d) ≥ a, g(d) ≥ 2a, ...

This solution is similar to the first one.

7894452

Solution 3:

We can use binary search to find the minimal d that g(d) ≥ a. And we use two pointers to maintain an interval [l, r] that  until we find .

I can't prove the correctness of this algorithm, but it performs well in practice.

7894356

Solution 4:

Thanks ZhouYuChen for his talented idea.

If x < 1018, we can get f(1018 + x) = f(x) + 1. That means if we shift the interval [x + 1, x + 1018] by 1, the result will be increase by 1 too. And it also not hard to find that g(10x) = 45 * x * 10x - 1. So if , [a - x, a - x + 1018 - 1] is the answer.

It's easy to see that upper bound of the answer is a, because of pigeonhole principle (among g(0), g(1), ..., g(a) at least two are equal). So big integer is not required in this problem.

If solution 3 is correct, the upper bound of the answer can be 2 * 1016.

7878473

Bonus:

Prove or disprove that solution 3 is correct.

468D - Tree

I am sorry that this problem coincides with that one.

d(u, v) = depu + depv - 2 * depLCA(u, v), so the answer is:



depi there means the distance between node i and root.

We choose centroid of tree as root (let's denote it u), so we can make every pair (i, pi) are in different subtrees, that means depLCA(i, pi) = 0.

So the answer is .

The next part of this problem is find the lexicographically smallest solution.

We regards it as finding the lexicographically smallest matching in a bipartite graph.

For a subtree, if the amount of nodes in this subtree in the left part > the amount of nodes not in this subtree in the right part, the perfect matching doesn't exist. So the amount of nodes in this subtree in the left part + the amount of nodes in this subtree in the right part should be no more than the amount of nodes unmatched, while the root is an exception.

We can use a segment tree to maintain it easily. We determined the minimum possible pi from 1 to n. If there is a subtree that the amount of nodes in this subtree in the left and right part is equal to the amount of nodes unmatched, we must select a node from it, so pi equal to the node in this subtree with the minimum id. Otherwise, we can choose a node with the minimum id that is not in the same subtree with i.

7894417

468E - Permanent

The permanent can be obtained as follows: for each (e1, e2, ..., et) such that x1, xe2..., xet are distinct and ye1, ye2, ..., yet are distinct, add  to the answer.

It can be proved by the formula :

,

where s and t are subsets of the same size of {1, 2, ..., n} and ,  are their respective complements in that set.

Construct a undirected graph G with 2n vertices v1, v2, ..., v2n, where the edge weight between vertex vi, vn + j is Ai, j - 1. We only need to know the sum of weight of all matchings that we choose t edges. The weight of matching is the product of all edge weights in the matching.

We only need to know the sum of the weights that we choose x edges in the each connected components.

The number of nodes in a connected component is s and the number of edges in this connected component is t.

Algorithm 1:

Because it's a bipartite graph, so the number of vertices in one part is at most s / 2. So we can use state compressed dp to calculate the ways to choose x edges in this connected component. The complexity is O(2s / 2 * s2).

Algorithm 2:

We can choose a spanning tree. The number of edges in spanning tree of these vertices is s - 1, and the number of non-tree edges is t - s + 1. So we can enumerate all the non-tree edge, use tree dp to calculate the ways. The complexity is O(2t - s * s2).

Combined with these two algorithm, the complexity is O(min(2s / 2, 2k - s) * s2)) = O(2k / 3 * k2).

Разбор задач Codeforces Round #267 (Div. 2)

By Yury_Bandarchuk, 8 years ago, In Russian 467A - Юра и заселение

В этой задаче нужно было просто посчитать количество пар, у которых qi - pi ≤ 2

Асимптотика: O(N)

467B - Федя и новая игра

В этой задаче нужно было уметь считать количество различных битов в двух числах. Как вариант, можно просто побежать по битам и посчитать количество различных. Ещё, как вариант, если исходные два числа X и Y, то количество различных битов равнялось бы количеству единиц в числе X xor Y, где xor — операция исключающего или.

Асимптотика O(M·N)

467C - Юра и работа

Решение этой задачи — динамическое программирование. Изначально нужно посчитать psumR, где psumR — сумма на префиксе массива p длиной R.

Обозначим dpi, j — максимальная прибыль которую может получить Юра, если мы уже выбрали i последовательностей и последний элемент в i-ой последовательности имеет индекс j.

Очевидно, что если i·m > j, то dpi, j = 0. Иначе dpi, j = max(dpi, j - 1, dpi - 1, j - m + psumj - psumj - m) Ответом будет dpk, n.

Ещё нужно было не забыть использовать long long при вычислениях.

Асимптотика: O(N·K)

467D - Федя и реферат

Первое, что нужно сделать, чтобы облегчить себе работу — перевести все строки в нижний регистр. Затем словам дать номера. Различным словам дать различные номера, а одинаковым — одинаковые.

Затем, из всех строк нужно построить граф. Пусть каждое слово — просто вершина. А пара слов синонимов X и Y — ребро между вершинами, которые отвечают за данные слова. Ребра ориентированные. Также, для каждого слова мы должны хранить его длину и количество букв «R». Будем использовать номера, данные словам, для построения графа.

После создания графа, у нас мог быть петли, кратные ребра, циклы. Поэтому нужно сжать все сильно связные компоненты в одну вершину. После чего задача состоит в том, чтобы посчитать dpver — пара, отвечающая за минимальное количество букв «R» и минимальную длину слова с минимальным количеством букв «R», которым можно заменить слово, за которое отвечает вершина ver.

Пересчет очевиден — dpver = max(dpnextVev, dpver), где nextVer — все вершины, в которые можно пойти из ver. Максимум из двух пар берется как у pair в C++.

Затем нужно пройти по всем словам текста, получить номер вершины, который соответствует нужному слову. Пусть это ver. Тогда к ответу нужно прибавить dpver.

Также, важно было не забыть использовать long long при вычислениях.

Асимптотика: , где w — множество всех слов, которые есть в тексте и в словаре.

467E - Леша и сложная задача

Данная задача решалась жадно.

Алгоритм решения такой:

Набираем числа из массива a по очереди, пока в последовательности набранных чисел(далее G) не найдется нужная нам четверка. Напоминаю, что нужная четверка чисел имеет вид: [c1, c2, c3, c4] = [x, y, x, y]. Если набрали такую четверку чисел, то добавляем в ответ. Очищаем G и v (далее будет описано, что такое v).

Очевидно, что этот алгоритм оптимален.

Для удобности сжимаем числа в массиве a. То есть каждому числу присваиваем его порядковый номер в отсортированном списке всех уникальных чисел из массива a. Это делается, потому что в дальнейшем нам удобнее использовать числа порядка O(N). Теперь как быстро узнать, что в G найдется нужная нам четверка.

Давайте для каждого уникального числа X хранить список его позиций в G. Назовем этот список vX. Теперь просто можно обработать операцию добавления числа в G. Пусть добавляемое число — это X. Добавим число X в список G. Пусть i — позиция добавленного числа в список G.

Теперь давайте добавим позицию i в список vX.

Можно заметить такой факт:

Если размер списка vx равен 4, то мы нашли нужную нам четверку.

Можно заметить ещё один факт:

Если до добавления мы не нашли нужную четверку чисел, а после добавления нашли, то последнее добавленное число является последним в четверке. То есть наше последнее добавленное число равно c4. Значит мы знаем позицию последнего числа из четверки. Давайте переберем позицию числа c2. Всего возможных позиций числа c2 не больше двух, так как всего позиций, на которых стоит число c2, не больше трех (смотреть предыдущий факт). Одна позиция уже занята числом c4. Итого остается максимум две позиции. Пусть мы проверяем, то что c2 имеет позицию L, а c4 имеет позицию R. Остается только проверить существование таких c1 и c3, что c1 = c3 и их позиции P и Q соответственно. P и Q должны удовлетворять следующим условиям: 1 < P < L, L < Q < R. Это очень легко проверить. Давайте заведем массив T. Ti =  максимальное j, что Gi = Gj. Поддерживать такой массив не составляет труда. Теперь проверка будет требовать только одного запроса: Максимум на отрезке [1, L - 1] в массиве T. Пусть результат запроса равен Z. Если он удовлетворяет условию L < Z < R, то четверка существует. Этим запросом мы нашли позицию числа c3 в списке G. По этим данным мы можем восстановить четверку.

Чтобы найти максимум на отрезке за , можно воспользоваться деревом отрезков или деревом Фенвика.

Итоговая асимптотика: .

Editorial Codeforces Round #266 (Div. 2)

By Antoniuk, 8 years ago, translation, In English 466A - Cheap Travel Solution of this problem is based on two claims: — If m·a ≤ b then there is no point to buy a ride ticket. — Sometimes it is better to buy summary more ride tickets for amount of rides than we need. If we receive profits bying ride tickets then number of such ones will be . For the remain n - m·x rides we must choose the best variant: to buy separate ticket for each ride, or to buy ride ticket and use it not fully.

Complexity: O(1) Solution: 7784793

466B - Wonder Room Let’s assume that a ≤ b.

First of all, let’s consider the situation when we can already accommodate all the students. If 6·n ≤ a·b then answer is a·b a b.

Otherwise, we have to increase one of the walls(maybe, both). Let’s do it in the following way: iterate the size of the smallest wall newa ( ), after that we can calculate the size of another wall as . For all this newa and newb if b ≤ newb we choose such a pair that has the smallest area of a room.

Obviously to undestrand, that there is no point to consider  because we can decrease it and receive room of smaller area when we know that .

Complexity:  Solution: 7784788

466C - Number of Ways First of all, notice that if sum of all elements is equal S then sum of each of three parts is equal . Therefore, if S is not divided by 3 — then answer is 0. Otherwise, let’s iterate the end of first part i (1 ≤ i ≤ n - 2) and if sum of 1..i elements is equal  then it means that we have to add to the answer the amount of such j (i + 1 < j) that the sum of elements from j-th to n-tn also equals .

Let’s create an array cnt[], where cnt[i] equals 1, if the sum of elements from i-th to n-th equals  and 0 — otherwise. Now, to calculate the answer we have to find the sum cnt[j] + cnt[j+1] + ... + cnt[n] faster then O(n). There are a lot of required ways to do this, but the easiest one is to create a new additional array sums[] where in j-th element will be cnt[j] + cnt[j+1] + ... + cnt[n]. It is easy to calculate in such way: sums[n] = cnt[n], sums[i] = sums[i+1] + cnt[i] (i < n).

Thus, we receive very simple solution: for each prefix of initial array 1..i with the sum that equals  we need to add to the answer sums[i+2].

Complexity: O(n) Solution: 7784781

466D - Increase Sequence Lets use dynamic programming to solve this problem. dp[i][opened] — the number of ways to cover prefix of array 1..i by segments and make it equal to h and remain after i-th element opened segments that are not closed.

Consider all possible variants opening/closing segments in each position: - ] closing one segment - [ opening one new segment - [] adding one segment with length 1 - ][ closing one opened segment and opening a new one - - do nothing

Lets understand how to build dynamic. It is obviously to understand that a[i] + opened can be equal h or h - 1. Otherwise, number of such ways equals 0.

Consider this two cases separately:

1) a[i] + opened = h It means that number of opened segments after i-th as max as possible and we can’t open one more segment in this place. So there are two variants: - [ Opening a new segment. If only opened > 0. dp[i][opened] += dp[i-1][opened + 1] - - Do nothing. dp[i][opened] += dp[i-1][opened]

Other variants are impossible because of summary value of a[i] will be greater than h(when segment is finishing in current position — it increase value, but do not influence on opened, by the dynamic definition.

2) a[i] + opened + 1 = h Here we consider ways where i-th element has been increased by opened + 1 segments, but after i-th remain only opened not closed segments. Therefore, there are next variants: - ] — closing one of the opened segments(we can do it opened + 1 ways). dp[i][opened] += dp[i-1][opened + 1] * (opened + 1) - [] — creating 1-length segment. dp[i][opened] += dp[i-1][opened] - ][ — If only opened > 0. Amount of ways to choose segment which we will close equals opened. dp[i][opened] += dp[i-1][opened] * opened

Start values — dp[1][0] = (a[1] == h || a[1] + 1 == h?1:0); dp[1][1] = (a[1] + 1 == h?1:0)

Answer — dp[n][0].

Complexity: O(n) Solution: 7784697

466E - Information Graph Let’s introduce all structure of the company as a graph(if у is the head of х then we add edge y -> x). It is obviously to understand that after each operation our graph will be the set of trees. Actually, the third query — to check is our vertex belong to the subtree of the vertex which has received data package. Graph that we will receive after doing all operations we call final. Also, we will say that two vertexes belong to the same connectivity component if they belong to the same component in graph that we can have from final by changing directed edge to undirected.

Consider the following statement: vertex у is the parent of vertex х in current graph(after doing first i queries) if у and х belongs to the same conectitive component and in final graph у is the parent of х.

We will solve this problem offline. After each query of adding data package we will immediately answer all the questions about this package. Besides that, use disjoint set union to define is this vertex belong to the same component or not. To answer the question we need to check that y is the parent of x in final graph and that x and y is currently belong to the same connectivity component. Final graph we will build before doing this algorithm because we know all queries. Check that y is the parent of x in final tree we can simply in O(1) by arrays of entry-time and output-time which we can calculate use dfs(v —parent u <=> (in[v] ≤ in[u] and out[u] ≤ out[v]).

Complexity: O(n * u(n)), where u — inverse Ackerman function. Solution: 7784662

Codeforces Round #265 Editorial

By Endagorion, 8 years ago, In English I'll upload my example solutions and will post links to them as soon as it becomes possible.

Some of the problems editorials contain an additional challenge which is apparently harder to comprehend than the original problem. Feel free to share and discuss your ideas in the comments. =)

465A - inc ARG

If we add 1 to a number, its binary representation changes in a simple way: all the least significant 1's change to 0's, and the single following 0 changes to 1. It suffices to find the length of largest suffix which contains only 1's, suppose its length is l. Then the answer is l + 1 except for the case when all the string consists of 1, when the answer is l.

It is amusing that div1E problem is concerned with addition of 1 to a binary integer as well. =)

465B - Inbox (100500)

Optimal strategy is as follows: for every segment of consecutive 1's open the first letter in segment, scroll until the last letter in segment, if there are more unread letters left, return to list.

It is easy to show that we can not do any better: observe the moment we read the last letter from some segment of consecutive 1's. There are no adjacent unread letters now, so we either have to scroll to some read letter or return to list of letters, either way we make an operation which does not result in reading an unread letter, so every segment (except for the last) must yield at least one such operation.

464A - No to Palindromes!

If string s contains a non-trivial palindromic substring w, then it must contain palindromic substring of length 2 or 3 (for instance, center of w). Therefore the string is tolerable iff no adjacent symbols or symbols at distance 1 are equal.

Now for the lexicographically next tolerable string t. t is greater than s, so they have common prefix of some size (maybe zero) and the next symbol is greater in t than in s. This symbol should be as right as possible to obtain minimal possible t. For some position i we can try to increment si and ensure it's not equal to si - 1 or si - 2. If we find some way to do this, the suffix can always be filled correctly if only p ≥ 3, as at most two symbols are forbidden at every moment. Every symbol from suffix should be as small as possible not to make conflicts. So, a greedy procedure or some kind of clever brute-force can be implemented to solve the problem in O(n). Cases p = 1 or 2 are easy, as only strings of length at most 1, and at most 2 respectively fit.

This is an application on general approach to generate next lexicographical something: try to increment rightmost position so that suffix can be filled up in some way, then fill the suffix in least possible way.

As pointed out in Russian discussion, this problem is a simplified version of the problem from some previous round: 196D - The Next Good String. We were not aware of this and apologize for the misfortune. Luckily, no copied solutions from that problem were spotted. If you enjoyed this simple version, you may want to try the harder one know. =)

464B - Restore Cube

There are several ways to solve this problem. We'll describe the most straightforward one: we can generate all possible permutations of coordinates of every point and for every combination check whether given point configuration form a cube. However, number of configurations can go up to (3!)8 > 106, so checking should work quite fast.

One way to check if the points form a cube is such: find minimal distance between all pairs of points, it should be equal to the side length l. Every vertex should have exactly three other points at distance l, and all three edges should be pairwise perpendicular. If these condition are met at every point, then configuration is a cube as there is no way to construct another configuration with these properties. This procedure performs roughly 82 operations for every check, which is fast enough. There are even more efficient ways of cube checking exploiting various properties of cube.

There are various optimizations to ensure you fit into time limit. For instance, applying the same permutation to coordinates of all points keeps every property of the cube, therefore we can fix order of coordinates for one point and permute all other. This single trick speeds up the algorithm 6 times, which allows some less efficient programs to be accepted.

A challenge: apparently, checking may be done as follows: find the length side l, then count number of pairs on distance l, , . A cube must contain exactly 12 pairs of first kind, 12 pairs of second kind and 4 pairs of third kind. Can you prove that this condition is sufficient for configuration to form a cube? Is it true if we allow points to have non-integer coordinates? Can you propose an even easier algorithm for checking?

464C - Substitutes in Number

It is quite diffcult to store the whole string after each query as its length grows exponentially and queries may change it dramatically. The good advice is: if you can't come up with a solution for a problem, try solving it from the other end. =)

Suppose we know for some sequence of queries that digit d will turn into string td for every digit. Then string s = d1... dn will turn into td1 + ... + tdn (+ for concatenation). Denote v(s) numeric value of s. Then v(s) can be expressed as v(tdn) + 10|dn|(v(tdn - 1) + 10|dn - 1|(...)). So v(s) can be computed if we know md = v(td) and sd = 10|td| for all d. As we need answer modulo P = 109 + 7 we can store these numbers modulo P.

Now prepend some new query di → ti to given sequence. How will md and sd change? Clearly, for all d ≠ di these numbers won't change, and for di they can be computed according to the rule above. This recounting is done in O(|ti|) time. After adding all queries, find answer for s using the same procedure in O(|s|) time. Finally, our time complexity is . The code for this problem pretty much consists of the above formula, so implementation is as easy as it gets once you grasp the idea. =)

Optimized simple solutions which just replaced substrings could manage to pass pretests. Sorry for that.

A challenge: this problem has a natural modification when you have to give an answer after each query. Using algorithm described above it can be solved offline in O(n2) time. Can we do better than this? What if we are limited to answer online?

464D - World of Darkraft - 2

This problem required some skill at probabilities handling, but other than that it's quite simple too.

Denote number of earned coins as X, and number of earned coins from selling items of type i as Xi. Clearly X = X1 + ... + Xk, and EX = EX1 + ... + EXk (here EX is expectation of X). As all types have equal probability of appearance, all Xi are equal, so EX = kEX1. Now to find EX1.

If we look only at the items of one type, say, 1, items generation looks like this: with probability  we get nothing, and with probability  we get out item with level distributed as usual. Denote dn, t expectation of earned money after killing n monsters if we have an item of level t at the start. Clearly, d0, t = 0 (we have no opportunity to earn any money), and , which is equal to  = . To get the answer note that EX1 = dn, 1. The sad note is that this DP has Ω(n2) states, which is too much for .

Maybe if we cut off some extremely-low-probability cases we can do better? For instance, it is clear that probability of upgrading an item descreases with its level, so apparently it does not get very high. We know that expected number of tries before first happening of event with probability p in a series of similar independent events is 1 / p. Therefore, expected number of monsters we have to kill to get item of level T is . So, in common case our level can get up to about , which does not exceed 500 in our limitations. We would want to set such bound B that ignoring cases with t > B would not influence our answer too much. That can be done with rigorous bounding of variance of T and applying some bounding theorem, or with an empirical method: if we increase the bound and the answer doesn't visibly change, then this bound is fine. It turns out B ≥ 700 is good enough for achieving demanded precision. Thus solution with  complexity is obtained (here we assert that , and constant C is buried in the big O).

A challenge: suppose we have the same rules of killing monsters and obtaining items, but now we are free to choose whether to sell a new item or an old one. We act so that to maximize our number of coins in the end. What is the expected number of coins if we act optimally?

Now it is sometimes more profitable to sell a powerful item, but sometimes it isn't. How fast a solution can you come up with?

464E - The Classic Problem

This seems to be a simple graph exercise, but the problem is with enormous weights of paths which we need to count and compare with absolute precision to get Dijkstra working. How do we do that?

The fact that every edge weight is a power of two gives an idea that we can store binary representation of path value as it doesn't change much after appending one edge. However, storing representations explicitly for all vertices is too costly: the total number of 1's in them can reach Ω(nd) (d is for maximal xi), which doesn't fit into memory even with bit compression woodoo magic.

An advanced data structure is needed here which is efficient in both time and memory. The good choice is a persistent segment tree storing bit representation. Persistent segment tree is pretty much like the usual segment tree, except that when we want to change the state of some node we instead create a new node with links to children of old node. This way we have some sort of ''version control'' over tree: every old node is present and available for requests as its subtree can never change. Moreover, all queries are still processed in  time, but can create up to  new nodes.

What queries do we need? Adding 2x to binary number can be implemented as finding nearest most significant 0 to x-th bit, setting it to 1 and assigning 0's to all the positions in between. Usual segment tree with lazy propagation can do it, so persistent tree is able to do it as well.

Comparing two numbers can be done as follows: find the most singificant bit which differs in two numbers, then number with 0 in this bit is smaller; if no bits differ, then numbers are clearly equal. That can be done in  if we store hashes of some sort in every node and perform a parallel binary search on both trees. Time and memory limits were very generous so you could store as many different hashes as you wanted to avoid collisions.

That concludes the general idea. Now we use this implementation of numbers as a black-box for Dijkstra algorithm. Every operation on numbers is now slowed by a factor of , so our solution has  complexity. However, great caution is needed to achieve a practical solution.

First of all, in clueless implementation comparison of two "numbers" may require  additional memory as we must perform "push" operation as we descend.  memory is too much to fit even in our generous ML. There are plenty of ways to avoid this, for instance, if we want to push the value from node to children, we actually know that the whole segment consists of equal values and can answer the query right away.

I would like to describe a clever trick which optimizes both time and memory greatly and also simplifies implementation. It allows to get rid of lazy propagation completely. Here it comes: initially build two trees containing only 0's and only 1's respectively. Now suppose we want to assign some value (0, for instance) on a segment and some tree node completely lies inside of query segment. Instead of creating a new node with a propagation mark, we can replace the node with corresponding node from tree filled with 0. This way only  new nodes are created on every query (which is impossible to achieve with any kind of propagation which would require at least ), and also nodes need to store less information and become lighter this way. Also, no "push" procedure is required now.

No challenges for this problem as it is challenging enough itself. =) Implementing this problem is a great exercise for anyone who wants to become familiar with complicated structures and their applications, so solving it in the archive is advisable.

That's pretty much it. If there are still questions, you may ask them in the comments. Thanks for reading!

Codeforces Round #264 Tutorial

By NelsonMondialu, 9 years ago, In English 463A - Caisa and Sugar. This is a simple implementation problem.

Sample solution.

463B - Caisa and Pylons. We have to use greedy method. Start from the first element and pass all the elements in order(also update by the energy).When energy < 0, add abs(energy) to solution and energy becomes 0 or we can find the answer by binary search.

Sample solution.

463C - Gargari and Bishops. We preprocess the sum for all the diagonals(principals and secondary diagonals) in two arrays(so that for every element i,j we can find sum of elements which are attacked in O(1) time).Also for avoiding the intersection,we need to find two cells so that for one the sum of row and column is even and for the other one the sum of row and column is odd.Finally,we analyze every cell ,we see if the sum of row and column is even or odd,and update that two positions(solutions).

Sample solution.

463D - Gargari and Permutations.We can build a directed acyclic graph with n nodes.If j is after i in all vectors then we add in graph edge (i,j).Now we have to find the longest path in this graph. Another way is using dp.

Sample solution with graph.

Sample solution with dp.

463E - Caisa and Tree. We use an array of dynamic stacks for every prime factor.We start a DFS from node 1.For node 1 we decompose its value in prime factors and push it to every prime factor's stack.To answer the question for x,we need to see the y (y belongs to the chain from 1 to x) that has a common prime factor with x,so the stacks will help us to see the earliest update(so the nearest y). For every x ,we decompose x to prime factors,look in the array and see the earliest update of the prime factors' stacks(if exists,of course). Also when we get back to fathers recursively,we need to pop from the prime factors' stacks. For every update we have to start dfs again.

Sample solution.

Codeforces Round #263 Tutorial

By snuke, 9 years ago, In English Div2 A Appleman and Easy Task (Author: EnumerativeCombinatorics)

This is a simple implementation problem. You can solve by searching adjacent cells of every cell.

Div2 B Appleman and Card Game (Author: EnumerativeCombinatorics)

This is simple greedy problem, but it seemed to be reading-hard. The statement says, "Choose K cards from N cards, the score of each card is (the number of cards which has the same character in K cards. (not in N cards)"

It is clear that this total score is (the number of 'A' in K cards)^2 + (the number of 'B' in K cards)^2 + ... + (the number of 'Z' in K cards)^2 This value will be maximized by the simple greedy algorithm, take K cards from most appearred character in N cards, the second most appearred character in N cards, and so on.

Div1 A / Div2 C Appleman and Toastman (Author: hogloid)

First I describe the algorithm, and explain why it works.

Sort {ai} in non-decreasing order. Then, for i-th number, add (i + 1) * ai to the result.(i=1...n-1) For n-th number, add n * an to the result. Actually, when you multiply all numbers by -1,the answer will be the minimal possible value, multiplied by -1.

It's Huffman coding problem to find minimal possible value. Solving Huffman coding also can be solved in O(nlogn)

In Huffman coding, push all the numbers to a priority queue. While the size of the queue is larger than 2, delete the minimal and second-minimal element, add the sum of these two to the cost, and push the sum to the queue. Here, since all the numbers are negative, the pushed sum will be remain in the first in the queue. Analyzing this movement will lead to the first algorithm.

Div1 B / Div2 D Appleman and Tree (Author: hogloid)

Fill a DP table such as the following bottom-up:

DP[v][0] = the number of ways that the subtree rooted at vertex v has no black vertex. DP[v][1] = the number of ways that the subtree rooted at vertex v has one black vertex. The recursion pseudo code is folloing:

DFS(v):  DP[v][0] = 1  DP[v][1] = 0  foreach u : the children of vertex v   DFS(u)   DP[v][1] *= DP[u][0]   DP[v][1] += DP[v][0]*DP[u][1]   DP[v][0] *= DP[u][0]  if x[v] == 1:   DP[v][1] = DP[v][0]  else:   DP[v][0] += DP[v][1] The answer is DP[root][1].

UPD: The above code calculate the DP table while regarding that the vertex v is white (x[v]==0) in the foreach loop.

After that the code thinks about the color of vertex v and whether we cut the edge connecting vertex v and its parent or not in "if x[v] == 1: DP[v][1] = DP[v][0] else: DP[v][0] += DP[v][1]".

Div1 C / Div2 E Appleman and a Sheet of Paper (Author: snuke)

For each first type queries that p_i > (the length of the paper) — p_i, you should express the operation in another way: not fold the left side of the paper but fold the right side of the paper. After such query you need to think as the paper is flipped.

Let's define count[i] as the number of papers piled up at the segment [i,i+1] (absolute position). For each query of first type you can update each changed count[i] naively.

Use BIT or segment tree for count[i] because you can answer each second type queries in O(log n). The complexity of a first type query is O((the decrement of the length of the paper) log n) so total complexity of a first type query is O(n log n).

Div1 D Appleman and Complicated Task (Author: EnumerativeCombinatorics,snuke)

First, we ignore the already drawn cell and dependence of cells. If we decide the first row, then the entire board can decided uniquely. We call 'o' is 1, and 'x' is 0. Then,

a[i][j] = a[i-2][j] xor a[i-1][j-1] xor a[i-1][j+1]

For example, I'll explain n=5 case. Each column of first row is a, b, c, d, and e. "ac" means a xor c.

a   b   c   d   e b   ac  bd  ce  d c   bd  ace bd  c d   ce  bd  ac  b e   d   c   b   a Each character affects the following cells (denoted 'o').

o.... .o... ..o.. ...o. ....o .o... o.o.. .o.o. ..o.o ...o. ..o.. .o.o. o.o.o .o.o. ..o.. ...o. ..o.o .o.o. o.o.. .o... ....o ...o. ..o.. .o... o.... Generally we can prove the dependence that a[0][k] affects a[i][j] if k<=i+j<=2(n-1)-k and |i-j|<=k and k%2==(i+j)%2. ... (*)

We can separate the problems by (i+j) is odd or even.

Each (i,j), we can get the range of k that affects the cell (i,j) by using formula (*). So the essence of this problem is that "There is a sequence with n integers, each of them is 0 or 1. We know some (i,j,k) where a[i]^a[i+1]^...^a[j]=k. How many possible this sequences are there?" We can solve this problem by using union-find. At first, there is n*2 vertices. If k is 1, we'll connect (i*2,(j+1)*2+1) and (i*2+1,(j+1)*2), if k is 0, we'll connect (i*2,(j+1)*2) and (i*2+1,(j+1)*2+1) (note that i<=j). If both i*2 and i*2+1 are in the same set for any i, the answer is 0. Otherwise the answer is 2^((the number of sets-2)/2).

Also, it is possible to solve odd number version. (How many ways to fill all the empty cells with 'x' or 'o' (each cell must contain only one character in the end) are there, such that for each cell the number of adjacent cells with 'o' will be "odd"? ) I'll hope for your challenge for odd-number version!!

Div1 E Appleman and a Game (Author: hogloid,snuke)

Let C be the number of characters(here, C=4)

Given string S, the way to achieve minimum steps is as follows: Append one of the longest substring of T that fits current position of string S. Appending a not-longest substring can be replaced by appending longest substring and shortening the next substring appended.

Let dp[K][c1][c2] be defined as :

the minimum length of string that can be obtained by appending a string K times and that starts by character c1 and whose next character is c2. Note that next character is not counted in the length.

dp[1] can be calculated as follows:

For every string of length L expressed by C characters, if the string is not included in T, update the dp table as dp[1][the string's first character][its last character]=min(dp[1][its first character][its last character],L-1)

For any (c1,c2), dp[1][c1][c2] is smaller than or equal to log_C(T+1)+2 (since the kind of strings of length log_C(T+1)+2 that start by c1 and end by c2 is equals to T+1). Therefore for L=1...log(T+1)+2, try all the strings as described above.

Also we can use trie that contains all substrings of T of length log_C(T+1)+2, and find what can't be described as a substring of T by one step.

Since dp[k+1][c1][c2]=min(dp[k][c1][c3]+dp[1][c3][c2] | c3=1...C), we can use matrix multiplication to get dp[K].

For a integer K, if there is (c1,c2) such that dp[K][c1][c2]<|S|, the answer is greater than K. Otherwise,the answer is smaller than or equal to K.

Since answer is bigger or equal to 1 and smaller or equal to |S|, we can use binary search to find the ansewr.

O(T*((log T)^2+C^2)+C^3(log |S|)^2)

BONUS: Is there any algorithm that solves in O(1) or O(C^foo)(that is, not depended on |S|) for each |S| with pre-calc?

Some hints: Maximal value of dp[1][*][*] — Minimal value of dp[1][*][*] <= 2

(let's call the maximal value dp[1][i][j]=L. Here, any C^(L-2) strings are contained in T as substring, so for any (c1,c2), dp[1][c1][c2]>=L-2)

Maximal value of dp[1][k][*] — minimal value of dp[1][k][*] <=1 ( k=1...C)

Maximal value of dp[1][*][k] — minimal value of dp[1][*][k] <=1 ( k=1...C)

Even if we use these hints and make C=3, the implementation would be not easy.

If you come up with smart way, please comment here :)

Codeforces Round #262 (Div. 2) Editorial

By vitux, 9 years ago, translation, In English 460A - Vasya and Socks

At this problem you need to model what written in statements. Also, it can be proved, that answer can be calculated using formula:  , where ⌊ x⌋ is the integer part of x.

7536107

460B - Little Dima and Equation

Obviously S(x) can take only integer values and 1 ≤ S(x) ≤ 81. Let's check S(x) from 1 to 81, and calculate B * S(x)A + C. After that if sum of digits of this number is equal to S(x), it is positive and less than 109, than it is a solution.

There could be bug because of using C++ pow() function.

7536153

460C - Present

Note,that answer is positive integer not greater than 109 + 105. Using binary search on answer, we will find answer. Really, we can check in O(n) if some height is achievable. We go from left to right. For current flower we calculate how much times it need to be watered to stand not lower than checking value. If cuurent flower need to be watered for h times, we will star h segments in current flower. We would keep array, in which st[i] — number of segments, which starts in i-th flower. Also, we will keep variable, in which we will keep number of segments, which cover current flower. This variable could be updated at O(1). Really, to get new value we just need to subtract st[i  -  w], and, if we create new segments, to add st[i]

Also, it can be proved that simple greedy algorithm works. At every of m iterations we can find the leftmost flower with the smallest height and water the segment, which begins in it. Primitive realisation works at O(nm), so you need to use data structure, which can add on segment and find minimum at segment. For example, you can use segment tree with lazy updation or sqrt-decomposition. Such solutions works longer, but faster than TL

Prove: Consider any optimal sequence of moves (using which max. answer reachs). Consider initially the leftmost smallest flower, and suppose all segments which covers it.(suppose, there are at least 1 segment, because else answer is initial height of this flower, so we can put a segment to start in this flower, and answer would not change). Suppose that there are no segments, which starts from current flower. Consider the rightests of segments.(If there are more than one, than any of them). Than, we can move this segment to start in the initially leftmost smallest flower, and the answer would not change. Really, flowers, which earlier was at this segments were higher, than leftmost smallest, and were watered not least times. So, after we moved the answer had not decreased. So, new sequence is also optimal. So, there is sequence of moves, which consists the segment, which starts at the initially leftmost smallest flower. So, let use this. Similary to other of m days, and it would be optimally. 7536171

460D - Little Victor and Set

If r - l ≤ 4 we can all subsets of size not greater than k. Else, if k = 1, obviously that answer is l. If k = 2, answer is 1, because xor of numbers 2x and 2x + 1 equls 1. If k ≥ 4 answer is 0 because xor of to pairs with xor 1 is 0.

If k = 3, we can choose numbers 2x and 2x + 1 with xor 1. So we need to know, if we can get xor equals 0. Suppose that there are 3 such numbers x, y and z (r ≥ x > y > z ≥ l) with xor equals 0. Consider the most non-zero bit of number x. At the same bit of y it's also 1, because xor equls 0, and y > z. Consider the next bit of numbers. If z have 0 there, we have to do next: set the previous bit of numbers x and y equals 0, and set current bit equals 1. Obviously xor still equals 0, z hadn't changed and numbers x and y stood closer to z, so they are still at [l, r].And x > y.Consider the next bit of numbers. If z has zero here than we will change most bits of x и y at the same way and so on. z > 0, so somewhen we will get to bit in which z has 1. Since xor equals 0, the same bit of x would be 1 because x > y, and y would have 0 there. At the next bits we will change bit in x to 0, and in numbers y and z to 1.Finally z would be greater or equal than before, and x would be less or greater than before, and x > y > z would be correct. So, we have the next: if such numbers x, y and z exist than also exist numbers:

1100…000

1011…111

0111…111

with xor equals 0. There are not much such triples, so we can check them.

7536186

460E - Roland and Rose

Formal statement: 2 natural numbers are given: R — radii, and N — number of points. You have to choose N unnesessarily distinct points A1, A2, ...AN which are lying inside or on side of circle, such that

 takes its maximal value.

At first let  be a vector from (0, 0) to point Ai. Value of  is equal , what is equal to , and it can be rewritten as . It makes us think that it is more profitable take point which are close to circle, such that |ai2| would be as big as can, but value of  as little as can. After that it becomes obvious, that if N is even, than it's enough to take any diameter and place half of points to the start and another half to the finish of it. Now we're trying to formulate our guessians strictly. Let's take an optimal set of points. Let's mark coordinats as (x1, y1), (x2, y2), ..., (xn, yn).Let's first N - 1 points are fixed, and we can move last point — (x, y). In terms of x, y we'd like to maximize

 We left out all squares without x, y. Maximization of this x, y function is equivalent to maximization of



 So, we've reduced our problem to finding the furthest integer point from . Now we can declare: the furthest point is placed at one vertex of convex hull of all integer points inside the circle.

Proof. Let  be a point T, and the furthest integer point inside P (convex hull) is X(obviously, it placed somewhere in convex hull). Lets extend TX beyond X to intersection with one side of polygon — let it be AB, and lets mark point of intersection as X'. Clearly TX' ≥ TX. It's easy to see, that one of angles  and  is obtuse, so, according to properties of obtuse triangles on of inequalities holds: TA ≥ TX' ≥ TX or TB ≥ TX' ≥ TX, so, we can replace X to A or B, and distanse TX will increase.

So, we can assume, that every point in optimal set belongs to the convex hull. So, solution is check all sets of points from convex hull and check values on this sets. If R ≤ 30, then convex hull contains no more than 36 points — it's easy to check with computer. So, brute force will take  time, and it passes TL easily (depending on realizations and optimizations).

For those, who interested in realization of algorithm: at first we place convex hull to some vector(and points become ordered). After that we build recursion function with the next parameters:1) how many points in the set on this iteration 2) vector with points 3) sum x-coordinats of points from set 4) sum of squares of x- coordinates 5) sum of y-coordinates 6) sum of squares of y-coordinates.

On each iteration we take last point from set, and trying to add all points, starting with this, and finishing on the end of convex hull — it starts new iteration of recursion. Also, we recalculate meaning of cur value in fast way using parameters 3, 4, 5 and 6.

On the last iteration, when we took N points, we are comparing value on this set with maximal value. If maximal value is less, than cur value, then maxvalue = curvalue, and bestvector = cursetofpoints. After recursion we output maxvalue and bestvector.

7536206

UPD Editorial of problem C was expanded

Codeforces Round #261 Editorial

By Erfan.aa, 9 years ago, In English 459A - Pashmak and Garden Four vertices of a square with side length a (and sides parallel to coordinate axis) are in this form: (x0, y0), (x0 + a, y0), (x0, y0 + a), (x0 + a, y0 + a).

Two vertices are given, calculate the two others (and check the ranges).

Total complexity : O(1)

Sample solution: 7495194

459B - Pashmak and Flowers If all numbers are equal then answer will be n * (n - 1) / 2, otherwise the answer will be cnt1 * cnt2, where cnt1 is the number of our maximum elements and cnt2 is the number of our minimum elements.

Total complexity : O(n)

Sample solution: 7495202

459C - Pashmak and Buses For each student consider a sequence of d elements from 1 to k that shows the bus number which is taken by this student on each day. Obviously, there are kd different sequence at all, so if n > kd, pigeonhole principle indicates that at least two of this sequences will be equal, so that two students will become close friends and no solutions exist. But if n ≤ kd, then we can assign a unique sequence to each student and compute the answer. For computing that, we can find the first n d-digits numbers in k-based numbers.

Total complexity : O(n * d)

Sample solutions: 7495236

459D - Pashmak and Parmida's problem First of all, we can map the given numbers to integers of range [1, 106]. Let li be f(1, i, ai) and let ri be f(i, n, ai), we want to find the number of pairs (i, j) such that i < j and li > rj. For computing lis, we can store an array named cnt to show the number of occurence of any i with cnt[i]. To do this, we can iterate from left to right and update cnt[i]s; also, li would be equal to cnt[ai] at position i (ri s can be computed in a similar way).

Beside that, we get help from binary-indexed trees. We use a Fenwick tree and iterate from right to left. In each state, we add the number of elements less than li to answer and add ri to the Fenwick tree.

Total complexity : O(n * logn)

Also we can solve this problem using divide and conquer method. You can see the second sample solution to find out how to do this exactly.

Sample solutions: 7495225 7495225

459E - Pashmak and Graph In this problem, a directed graph is given and we have to find the length of a longest strictly-increasing trail in it.

First of all consider a graph with n vertices and no edges, then just sort the given edges by their weights (non-decreasingly) and add them to the graph one by one.

Let dp[v] be the length of a longest increasing trail which ends in the vertex v. In the mentioned method, when you're adding a directed edge xy to the graph, set dp[y] value to max(dp[y], dp[x] + 1) (because of trails which ends in y and use this edge). You need to take care of the situation of being some edges with equal weights; for this job we can add all edges of the same weights simultaneously.

Total complexity : O(n + m * logm)

Sample solution: 7495216

Codeforces Round #260 — Editorial

By netman, 9 years ago, translation, In English Warning: my English is very bad.

456A - Laptops

Solution: 7407613;

In this task you need to check the existense of such pair i and j, such that i ≠ j, a[i] < a[j], b[i] > b[j]. If such i and j exist, Alex is happy.

There is very simple solution. Let's check that for all i a[i] = b[i]. If this condition is true we should print "Poor Alex". We can easy prove it. Let's sort arrays a and b like pair of numbers in increasing order. We can see that Alex is happy if we have at least one inversion in array b, i.e there is such pair i and j that b[i] > b[j] и i < j (). i.e it means that array b is not sorted and it's means that a ≠ b.

456B - Fedya and Maths

Solutions: 7407625, 7407631;

In this task you need to calculate formula that given in the statement, but it's hard to calculate it with the naive way.

But we can transform our formula to this:



This formula is right because 5 is prime number and it's coprime with 1, 2, 3, 4.

φ(5) = 4 To solve this task we should be able to calculate remainder of division n by 4 and calculate formula for small n.

Asymptotics — .

There is also another solution. It uses a fast exponentiation, but not binary exponentiation. The idea of this exponentiation is the same as that of the binary exponentiation. Let we want to fast calculate xnmodP. Algorithm is very simple. Let process digits of n moving from end to begin. Let Result — current result and K — x(10i), i — number of the currently processed digit (digits are numbered from the end. Used 0-indexation). During processing of digits, we must update result: , c[i] — i-th digit of the number n (digits are numbered from the end).

Asymptotics — .

456C - Boredom / 455A - Boredom

Solutions: 7407649, 7407655;

In this task we need to maximize the sum of numbers that we took. Let precalc array cnt. cnt[x] — number of integers x in array a. Now we can easily calculate the DP:

f(i) = max(f(i - 1), f(i - 2) + cnt[i]·i), 2 ≤ i ≤ n;

f(1) = cnt[1];

f(0) = 0;

The answer is f(n).

Asymptotics — O(n).

456D - A Lot of Games / 455B - A Lot of Games

Solutions: 7407663, 7407670;

To solve this problem we need the prefix tree(trie), which will have all the strings from the group. Next we will calculate the two DP: win[v] — Can player win if he makes a move now (players have word equal to prefix v in the prefix tree(trie)). lose[v] — Can player lose if he makes a move now (players have word equal to prefix v in the prefix tree(trie)).

if v is leaf of trie, then win[v] = false; lose[v] = true;

Else win[v] = (win[v] or (not win[i])); lose[v] = (lose[v] or (not lose[i])), such i — children of vertex v.

Let's look at a few cases:

If win[v] = false, then second player win (first player lose all games).

If win[v] = true и lose[v] = true, then first player win (he can change the state of the game in his favor).

If win[v] = true and lose[v] = false, then if , then first player win, else second player win.

Asymptotics — .

456E - Civilization / 455C - Civilization

Solutions: 7407681, 7407683;

You can see that the road system is a forest. For efficient storage component we need to use DSU. First, we need to build the initial system of roads. For each component of the initial road system, we must find the diameter of component. This can be done using a DFS or BFS. Let a — any vertex of component. Let b — furthest vertex from vertex a. Let c — furthest vertex from vertex b. Diameter equal to distance from b to c. This algorithm for finding the diameter is correct only for tree. For each component in the DSU, we know its diameter.

Now it is very easy to answer the query of the $1$st type: To know the component which contains the vertex x and output diameter of this component. Query of the $2$nd type also very easy to process: Let u — of component in which lie the vertex x, v — of component in which lie the vertex y. If u ≠ v, then we can merge components: The diameter of the new component is computed as follows:

 Asymptotics — O(n·A - 1(n)), где A - 1(n) — inverse Ackermann function.

455D - Serega and Fun

Solutions: 7407693, 7407699, 7407703;

Let's change the query type 1 to two more simple requests:

Erase a number from r-th position. Insert this number after (l - 1)-th position.

Now let's keep our array as  blocks. In each block will store the numbers themselves in such a manner as in the array a and will store an array cnt. cnt[x] — number of integers x in block. This requires O(n sqrtn) space.

Now we can fast process the queries of the 1st type. We can erase number from r-th position in  operations. And we can insert this number after (l - 1)-th position in  operations. Also we can fast recalc cnt after transformations.

Also we can fast process the queries of the

Unable to parse markup [type=CF_TEX]

O (\ sqrt n) $ numbers are in blocks, which are partly lie within the boundaries of the query. To keep the size of the blocks close to , we need rebuild our structure after each -th query of the 1st type. We can rebuild structure in O(n) operations.

Asymptotics — .

455E - Function

Solutions: 7407711, 7452418;

In this problem you should quickly be able to compute the function described in the statement.

You may notice that this task is equivalent to next task:

Go through the array a, starting from the position of y, making (x - 1) step. Step might be: step to the left or to stay in place.

Function is calculated as follows: , ki — how many times we visited the i th element of the array a.

For a fixed l is clear, it is most optimally that a minimum on the interval [l, y] has been visited by (x - (y - l)) times, and all the other numbers once.

You may notice that optimally to a[l] was a minimum.

From all this we can conclude that for a fixed l answer is — sum[y] - sum[l] + a[l]·(x - (y - l)), where sum — an array of prefix sums of array a.

Above formula can be written as follows:

sum[y] - sum[l] + a[l]·(x - (y - l)) = sum[y] - sum[l] + a[l]·(x - y + l) = sum[y] - sum[l] + a[l]·l + a[l]·(x - y) = sum[y] + (a[l]·(x - y) + a[l]·l - sum[l])

You may notice that in brackets something like the equation of the line — K·X + B. That's very similar to the equation of the line: a[l]·(x - y) + a[l]·l - sum[l], where K = a[l], X = (x - y), B = a[l]·l - sum[l].

Now we must find minimum for all l and fixed X = (x - y).

We have n lines, i. e. for every element in array a one line (Ki, Bi).

Answer for query equal to:

, where (Ki, Bi) — i-th line. Ki = a[i], Bi = a[i]·i - sum[i].

For fast answer calculation we must use Convex Hull Trick with segment tree. In every vertex of segment tree we keep all lines for segment of this vertex. This requires  space, because each line lies in  vertices. And we can answer query in  operations. Because we visit  vertices and each vertex need in  operations. You can learn the theory about Convex Hull Trick here.

Codeforces Round #259 Editorial

By MinakoKojima, 9 years ago, In English Overview There are 3 normal tasks accompanied with 2 challenge tasks in div 1 as we usually do. You can check the Statistics by By DmitriyH for detail.

Problem B, C is by sevenkplus, problem D is by xlk and problem A, E is by me.

Problem E is rather complicated then hard, it means if you carefully broke down the problem into smaller ones, it became quite straightforward. During the contest, only kcm1700 managed to solve it successfully.

Problem D, which decided the round boiled down to the following nice Dynamic Programming subproblem: you are given 220 numbers. For each position i between 0 and 220 - 1, and for each distance j between 0 and 20, what is the sum of the numbers with such indexes k that k and i differ in exactly j bits? The fun part is not how to do it T times, it is how to do it even once on 106 numbers.

Petr solve A, B, C, D steadily and fast who indisputably, is the winner of the round. The second place came to msg555, closely followed by cgy4ever. It is worth mentioning that, cgy4ever solved Problem D in the last few seconds which is quite impressive.

Editorial Problem 2A. Little Pony and Crystal Mine Brief description: Draw the grid graph as the problem said.

Analysis: Just a few basics of your programming language. It's easy.

Problem 2B. Little Pony and Sort by Shift Brief description: Ask the minimum unit shift you need to sort a array.

Analysis: Just a few basics of your programming language. It's not hard.

Problem A. Little Pony and Expected Maximum Brief description: Calculate the expected maximum number after tossing a m faces dice n times.

Analysis: Take m = 6, n = 2 as a instance.

6 6 6 6 6 6 5 5 5 5 5 6 4 4 4 4 5 6 3 3 3 4 5 6 2 2 3 4 5 6 1 2 3 4 5 6 Enumerate the maximum number, the distribution will be a n-dimensional super-cube with m-length-side. Each layer will be a large cube minus a smaller cube. So we have:

 Calculate in may cause overflow, we could move the divisor into the sum and calculate (i / m)n instead.

Problem B. Little Pony and Harmony Chest Brief description: You are given sequence ai, find a pairwise coprime sequence bi which minimizes 

Analysis: Since {1, 1 ..., 1} is a pairwise coprime sequence, the maximum element of bi can never greater then 2mx - 1. Here mx is the maximum elements in ai. So what we need consider is the first a few prime factors. It is not hard to use bitmask-dp to solve this:

    for (int i = 1 ; i <= n ; i ++) {     	for (int k = 1 ; k < 60 ; k ++) {     		int x = (~fact[k]) & ((1 << 17) - 1);     		for (int s = x ; ; s = (s - 1) & x) {                 if (dp[i - 1][s] + abs(a[i] - k) < dp[i][s | fact[k]]){                     dp[i][s | fact[k]] = dp[i-1][s] + abs(a[i]-k);                 }     		if (s == 0) break;             }     	}     } Here dp[i][s]: means the first i items of the sequence, and the prime factor have already existed. And fact[k]： means the prime factor set of number k.

Problem C. Little Pony and Summer Sun Celebration Brief description: Given a undirected graph with n nodes and the parity of the number of times that each place is visited. Construct a consistent path.

Analysis: There is no solution if there is more than 1 connected component which have odd node (because we can't move between two component), otherwise it is always solvable.

This fact is not obvious, let's focus on one component. You can select any node to start, denoted it as r (root). Start from r, you can go to any other odd node then back. Each time you can eliminate one odd node. After that, if r itself is odd, you can simply delete the first or last element in your path (it must be r).

The only spot of the above method is the size of the path can been large as O(n2). We need a more local observation. Let's check the following dfs() function:

void dfs(int u = r, int p = -1){          vis[u] = true;     add_to_path(u);

    for_each(v in adj[u]) if (!vis[v]){         dfs(v, u);         add_to_path(u);     }

    if (odd[u] && p != -1){         add_to_path(p);         add_to_path(u);     } } This dfs() maintain the following loop invariant: before we leave a node u, we clear all odd node in the sub-tree rooted at u as well as u itself.

The only u can break the invariant is the root itself. So after dfs(), we use O(1) time to check weather root is still a odd node, if yes, delete the first or last element of the path (it must be r).

After that, all the node will been clear, each node can involve at most 4 items in the path. So the size of the path will less than or equal to 4n. Thus the overall complexity is O(n + m).

Problem D. Little Pony and Elements of Harmony Brief description: Given you a vector e and a transformation matrix A. Caculate eAt under modulo p.

Analysis: Let's consider the e = [1 1 ... 1]. After a period, it will be ke where k is a const. So we know that [1 1, ..., 1] is an eigenvector and k is the corresponding an eigenvalue.

The linear transformation has 2m eigenvectors.

The i(0 ≤ i < 2m)-th

eigenvector is [(-1)^f(0, i) (-1)^f(1, i) ... (-1)^f(2^m-1, i)], where f(x, y) means that the number of ones in the binary notation of x and y.

We notice that the eigenvalue is only related to the number of ones in i, and it is not hard to calc one eigenvalue in O(m) time. To decompose the initial vector to the eigenvectors, we need Fast Walsh–Hadamard transform.

Also check SRM 518 1000 for how to use FWT. http://apps.topcoder.com/wiki/display/tc/SRM+518

In the last step, we need divide n. We can mod (p * n) in the precedure and divide n directly.

Problem E. Little Pony and Lord Tirek Brief description: n ponies (from 1 to n) in a line, each pony has:

si: the start mana. mi: the maximum mana. ri: mana regeneration per unit time. Also, you have m operations called Absorb Mana t l r. For each operations, at time t, count how many mana from l to r. After that, reset each pony's mana to 0.

Analysis: Key Observation The income of a operation, is only relevant with the previous operation. In other words, what we focus on is the difference time between adjacent operations.

Weaken the problem Let us assume si = 0 and ri = 1 at the beginning to avoid disrupting when we try to find the main direction of the algorithm. Also it will be much easier if the problem only ask the sum of all query. One of the accepted method is following:

Firstly, for each operation (t, l, r), we split it into a insert event on l, and a delete event r + 1. Secondly, we use scanning from left to right to accumulate the contributions of each pony.

In order to do that, you need a balanced tree to maintenance the difference time between adjacent operations, and a second balanced tree to maintenance some kind of prefixes sum according to those "difference".

The first balanced tree could been implemented by STL::SET. For each operation, you need only constant insert and delete operations on those balanced tree, thus the overall complexity is O(nlogn).

General solution Instead of scanning, now we use a balanced tree to maintenance the intervals which have same previous operation time and use a functional interval tree to maintenance those ponies. For each operation, we use binary search on the first balanced tree, and query on the second balanced tree. Thus the overall complexity is O(nlog2n).

Codeforces Round #258 Editorial

By PraveenDhinwa, 9 years ago, In English 451A - Game With Sticks

From a grid of size n * m, if we remove an intersection point, then the grid after removing the sticks passing through it, will of size n - 1, m - 1.

Notice when the grid consists of a single horizontal stick and m vertical sticks, If we pick any intersection point, then the updated grid will be only made of vertical sticks. You can see that there is no intersection point in the grid now.

So ans(n, m) = ans(n - 1, m - 1) ^ 1. ans(1,  * ) = 1 ans( * , 1) = 1

So we can notice that answer will depend on the parity of minimum(m, n). You can prove it using the previous equations. You can also check this by seeing the pattern.

So finally if min(n, m) is odd, then Akshat will win. Otherwise Malvika will win.

You can also observe that "players will play optimally" is useless in this case.

Complexity : O(1)

Solution codes

my solution 451B - Sort the Array

Note that if from a given sorted array, if reverse a segment, then the remaining array will be arranged in following way. First increasing sequence, then decreasing, then again increasing.

You can find the first position where the sequences start decreasing from the beginning. Call it L. You can find the first position where the sequences start increasing from the end. Call it R.

Now we just need to reverse the segment between a[L] to a[R].

Here is outline of my solution which is easy to implement. First I map larger numbers to numbers strictly in the range 1, n. As all the numbers are distinct, no two numbers in the mapping will be equal too.

Let us define L to be smallest index such that A[i]! = i. Let us also define R to be largest index such that A[i]! = i.

Note that if there is no such L and R, it means that array is sorted already. So answer will be "yes", we can simply reverse any of the 1 length consecutive segment.

Otherwise we will simply reverse the array from [L, R]. After the reversal, we will check whether the array is sorted or not.

Complexity: O(nlogn)

Solution codes

my solution 451C - Predict Outcome of the Game

Let x1 be number of wins of first team in the first k games. Let x2 be number of wins of second team in the first k games. Let x3 be number of wins of third team in the first k games.

Note that x1 + x2 + x3 = k ---(1) |x1 - x2| = d1. — (a) |x2 - x3| = d2. — (b)

Note that |x| can be x and -x depending on the sign of x.

Case 1: Assume that x1 > x2 and x2 > x3. x1 - x2 = d1 ---(2) x2 - x3 = d2 ---(3)

Adding 1 and 2, we get 2x1 + x3 = d1 + k --(4) Adding 2 and 3, we get x1 - x3 = d1 + d2 ---(5).

Now solve (4) and (5), we will get values of x1 and x3. By those values, compute value of x2. Now we should check the constraints that x1 ≥ x2 and x2 ≥ 3.

Now comes the most important part. Number of wins at the end of each team should be n / 3. So if n is not divisible by 3, then our answer will be definitely "no".

Note that if all of the x1, x2, x3 are  ≤ n / 3, then we can have the remaining matches in such a way that final numbers of wins of each team should be equal.

Now you have to take 4 such cases. Implementing such cases in 4 if-else statements could incur errors in implementation. You can check my code to understand a simple way to implement it.

I will explain idea of my code briefly, basically equation (a) and (b) can be opened with either positive or negative sign due to modulus. So if our sign is negative we will change d1 to be  - d1. So if we solve a single equation and replace d1 by  - d1, we can get solution for the second case.

All the cases can be dealt in such way. Please see my code for more details.

Complexity: O(1) per test case.

Solution codes

my solution 451D - Count Good Substrings

Merging Step: We have to convert string like "aaaabbbaabaaa" into "ababa".

Important Observation A substring made of the string will be a "good" palindrome if their starting and ending characters are same. If the starting and ending characters are same, then the middle characters after merging will be alternating between 'a' and 'b'. eg. "abaa" is not a palindrome, but it is a good palindrome. After merging step it becomes "aba". Note that in the string left after merging, the consecutive characters will alternate between 'a' and 'b'.

So if we are currently at the ith character, then we can have to simply check how many positions we have encountered upto now having the same character as that of ith. For counting even and odd separately, we can make count of a's and b's at even and odd positions.

So if we are at ith position, for counting even good palindromes, you just need to add count of number of characters a's at odd position. For counting odd good palindromes, you just need to add count of number of characters a's at even position.

Complexity: O(n) where n is length of string s.

Solution codes

my solution Note that you can also consult following comment for alternate editorial.

451E - Devu and Flowers

The number of ways to choose N items out of R groups where each item in a group is identical is equal to the number of integral solutions to x1 + x2 + x3...xR = N, where 0 ≤ xi ≤ Li, where Li is the number of items in ith group. Number of integral solutions are coefficient of xN in [Product of (1 + x + x * x + ...xLi) over all $i$].

You need to find coefficient of xs in (1 + x + x2 + x3 +  + ..xf1) *  *  * (1 + x + x2 + x3 +  + ..xfn).

Using sum of Geometric progression we can say that (1 + x + x2 + x3 +  + ..xf1) = (1 - x(f1 + 1)) / (1 - x).

Substituting in the expression, we get (1 - x(f1 + 1)) / (1 - x) *  *  * (1 - x(fn + 1)) / (1 - x).

= (1 - x(f1 + 1)) * .. * (1 - x(fn + 1)) * (1 - x)( - n).

Now we can find xs in (1 - x) - n easily. It is .

You can have a look at following link. to understand it better.

So now as s is large, we can not afford to iterate over s.

But n is small, we notice that (1 - x(f1 + 1)) * .. * (1 - x(fn + 1)) can have at most 2n terms.

So we will simply find all those terms, they can be very easily computed by maintaining a vector<pair<int, int> > containing pairs of coefficients and their corresponding powers. You can write a recursive function for doing this.

How to find  % p. As n + s - 1 is large and s is very small. You can use lucas's theorem. If you understand lucas's theorem, you can note that we simply have to compute .

Complexity: O(n * 2n).

Another solution based on inclusion exclusion principle.

Please see the following comments to get the complete idea. Comment 1 Comment 2 Comment 3

Solution codes

my solution (Java) another (C++) Inclusion Exclusion based solution

Codeforces Round #257 Editorial

By jzzhu, 9 years ago, In English 450A - Jzzhu и дети You can simply simulate it or find the last maximum ceil(ai / m).

450B - Jzzhu и последовательности We can easily find that every 6 numbers are the same. It's like {x, y, y - x,  - x,  - y, x - y, x, y, y - x, ...}.

449A - Jzzhu и шоколад / 450C - Jzzhu и шоколад We assume that n ≤ m (if n > m, we can simply swap n and m).

If we finally cut the chocolate into x rows and y columns (1 ≤ x ≤ n, 1 ≤ y ≤ m, x + y = k + 2), we should maximize the narrowest row and maximize the narrowest column, so the answer will be floor(n / x) * floor(m / y).

There are two algorithms to find the optimal (x, y).

Notice that if x * y is smaller, the answer usually will be better. Then we can find that if k < n, the optimal (x, y) can only be {x = 1, y = k + 1} or {x = k + 1, y = 1}. If n ≤ k < m, the optimal (x, y) can only be {x = 1, y = k + 1}. If m ≤ k ≤ n + m - 2, the optimal (x, y) can only be {x = k + 2 - m, y = m}, because let t = m - n, n / (k + 2 - m) ≥ (n + t) / (k + 2 - m + t) ≥ 1.

floor(n / x) has at most  values, so we can enum it and choose the maximum x for each value.

449B - Jzzhu и города / 450D - Jzzhu и города We consider a train route (1, v) as an undirected deletable edge (1, v).

Let dist(u) be the shortest path between 1 and u. We add all of the edges (u, v) weighted w where dist(u) + w = dist(v) into a new directed graph.

A deletable edge (1, v) can be deleted only if it isn't in the new graph or the in-degree of v in the new graph is more than 1, because the connectivity of the new graph won't be changed after deleting these edges. Notice that you should subtract one from the in-degree of v after you delete an edge (1, v).

449C - Jzzhu и яблоки / 450E - Jzzhu и яблоки Firstly, we should notice that 1 and the primes larger than N / 2 can not be matched anyway, so we ignore these numbers.

Let's consider each prime P where 2 < P ≤ N / 2. For each prime P, we find all of the numbers which are unmatched and have a divisor P. Let M be the count of those numbers we found. If M is even, then we can match those numbers perfectly. Otherwise, we throw the number 2P and the remaining numbers can be matched perfectly.

Finally, only even numbers may be unmatched and we can match them in any way.

449D - Jzzhu и числа Firstly, we can use inclusion-exclusion principle in this problem. Let f(x) be the count of number i where Ai&x = x. Let g(x) be the number of 1 in the binary respresentation of x. Then the answer equals to .

Now the task is to calculate f(x) for every integer x between 0 and 220. Let fk(x) be the count of number i where Y0&X0 = X0 and X1 = Y1 (they are defined below).

We divide x and Ai into two parts, the first k binary bits and the other 20 - k binary bits. Let X0 be the first part of x and X1 be the second part of x. Let Y0 be the first part of Ai and Y1 be the second part of Ai.

We can calculate fk(x) in O(1):



The problem can be solved in O(n * 2n) now (n = 20 in this problem).

449E - Jzzhu и квадраты Consider there is only one query.

 

Let me descripe the picture above.

A grid-square can be exactly contained by a bigger square which coincide with grid lines. Let L be the length of a side of the bigger square. Let i be the minimum distance between a vertice of the grid-square and a vertice of the bigger square. Let f(L, i) be the number of cells which are fully contained by the grid-square.

We can divide a grid-square into four right triangles and a center square. For each right triangle, the number of cells which are crossed by an edge of the triangle is L - gcd(i, L). Then, the number of cells which are fully contained by the triangle is [i(L - i) - L + gcd(i, L)] / 2.

f(L, i) = (L - 2i)2 + 2[i(L - i) - L + gcd(i, L)] = L2 - 2iL + 2i2 - 2L + 2gcd(i, L)

Firstly, we enum L from 1 to min(N, M). Then the task is to calculate .  can be calculated by the following steps:

Enum all of the divisor k of L and the task is to calculate the count of i where gcd(i, L) = k.

The count of i where gcd(i, L) = k equals to φ(L / k).

Finally, .

If there are multiple queries, we can calculate the prefix sum of ,  and , then we can answer each query in O(1).

Codeforces Round #256 — Editorial

By oversolver, 9 years ago, translation, In English 448A - Rewards

Solution:7139559

Because rewards of one type can be on one shelf, lets calculate number of cups — a and number of medals — b. Minimum number of shelves that will be required for all cups can be found by formula (a + 5 - 1) / 5. The same with shelves with medals: (b + 10 - 1) / 10. If sum of this two values more than n then answer is "NO" and "YES" otherwise.

448B - Suffix Structures

Solution:7139584

Consider each case separately. If we use only suffix automaton then s transform to some of its subsequence. Checking that t is a subsequence of s can be performed in different ways. Easiest and fastest — well-known two pointers method. In case of using suffix array we can get every permutation of s. If it is not obvious for you, try to think. Thus, s and t must be anagrams. If we count number of each letter in each string, we can check this. If every letter appears in s the same times as in t then words are anagrams. In case of using both structures strategy is: remove some letters and shuffle the rest. It is possible if every letter appears in s not less times than in t. Otherwise it is impossible to make t from s. Total complexity O(|s| + |t| + 26).

448C - Painting Fence

Solution:7139610

To solve this problem we need to understand some little things. First, every horizontally stroke must be as widely as possible. Second, under every horizontally stroke should be only horizontally strokes. So, if bottom of fence painted by horizontally stroke then number of this strokes must at least min(a1, a2, ..., an). These strokes maybe divides fence into some unpainted disconnected parts. For all of these parts we need to sum they answers. Now its clearly that solution is recursive. It takes segment [l, r] and height of painted bottom h. But we must not forget about situation when all planks painted with vertically strokes. In this case answer must be limited by r - l + 1 (length of segment). With given constrains of n we can find minimum on segment by looking all the elements from segment. Complexity in this case will be O(n2). But if we use for example segment tree, we can achieve O(nlogn) complexity.

448D - Multiplication Table

Solution:7139620

Solution is binary search by answer. We need to find largest x such that amount of numbers from table, least than x, is strictly less than k. To calculate this count we sum counts from rows. In i th row there will be . Total complexity is O(nlog(nm)).

448E - Divisors

Solution:7139644

Learn how to transform Xi into Xi + 1. For this we need to concatenate lists of divisors for all elements of Xi. To do this efficiently, precalculate divisors of X (because for every i Xi consist of its divisors). It can be done by well-known method with  complexity. How to calculate divisors of divisors? Need to know that for the given constrains for X maximum number of divisors D(X) will be 6720 (in the number 963761198400), so divisors of divisors can be calculated in O(D2(X)) time. With this lists we can transform Xi into Xi + 1 in O(N) time, were N = 105 — is the limit of numbers in output. Now learn how to transform Xi into X2i. What says Xi? Besides what would be X after i steps, it can tell where goes everyone divisor of X after i - 1 steps. Actually, Xi is concatenation of all Yi - 1, where Y is divisor of X. For example, 103 = [1, 1, 1, 2, 1, 1, 5, 1, 1, 2, 1, 5, 1, 2, 5, 10] = [1] + [1, 1, 2] + [1, 1, 5] + [1, 1, 2, 1, 5, 1, 2, 5, 10] = 12 + 22 + 52 + 102. How to know which segment corresponds for some Y? Lets pos(Y) be the first index of Y in Xi. Then needed segment starts from pos(prev(Y)) + 1 and ends in pos(Y), where prev(Y) is previous divisor before Y in sorted list of divisors. So, to make X2i from Xi we need to know where goes every element from Xi after i steps. We know all its divisors — it is one step, and for every divisor we know where it goes after i - 1 step. Thus, we again need to concatenate some segments in correct order. It also can be done in O(N) time. How to find now Xk for every k? The method is similar as fast exponentiation:

Xk = [X] when k = 0,

if k is odd then transform Xk - 1 to Xk,

if k is even then transform Xk / 2 to Xk.

This method takes O(logk) iterations. And one small trick: obviously that for X > 1 Xk starts from k ones, so k can be limited by N. Total complexity of solution is .

Codeforces Round #FF(255) Editorial

By dzy493941464, 9 years ago, In English The editorial is updated.

447A - DZY любит хэши We just need an array to store the numbers inserted and check whether a conflict happens. It's easy.

447B - DZY любит строки Firstly the optimal way is to insert letter with maximal wi. Let {wi}. If we insert this character into the k'th position, the extra value we could get is equal to . Because of wsi ≤ num, when k = n + 1, we can get the largest extra value.

So if we insert the k letters at the end of S, we will get the largest possible value.

446A - DZY любит последовательности We can first calculate li for each 1 ≤ i ≤ n, satisfying ai - li + 1 < ai - li + 2 < ... < ai, which li is maximal.

Then calculate ri, satisfying ai < ai + 1 < ... < ai + ri - 1, which ri is also maximal.

Update the answer , when ai - 1 + 1 < ai + 1.

It's easy to solve this problem in O(n).

446B - DZY любит модификации If p = 0, apperently the best choice is choosing the row or column which can give greatest pleasure value each time.

Ignore p first,then we can get a greatest number ans. Then if we choose rows for i times, choose columns for k - i times, ans should subtract (k - i) × i × p.

So we could enumerate i form 0 to k and calculate ansi - (k - i) * i * p each time, max {ansi - (k - i) * i * p} is the maximum possible pleasure value DZY could get.

Let ai be the maximum pleasure value we can get after choosing i rows and bi be the maximum pleasure value we can get after choosing i columns. Then ansi = ai + bk - i. We can use two priority queues to calculate ai and bi quickly.

446C - DZY любит числа Фибоначчи As we know, 

Fortunately, we find that 

So, 

With multiplicative inverse, we find,







Now, 

As you see, we can just maintain the sum of a Geometric progression 

This is a simple problem which can be solved with segment tree in .

446D - DZY любит игры Define important room as the trap room. Let w(u, v) be equal to the probability that DZY starts at u (u is a important room or u=1) and v is the next important room DZY arrived. For each u, we can calculate w(u, v) in O(n3) by gauss elimination.

Let Ai be equal to the i'th important room DZY arrived. So Ak - 1 = n, specially A0 = 1. Let ans be the probability for DZY to open the bonus round. Easily we can know . So we can calculate ans in (a is equal to the number of important rooms) by matrix multiplication.

So we can solve the problem in . we should optimize this algorithm.

We can find that each time we do gauss elimination, the variable matrix is unchanged. So we can do gauss elimination once to do preprocessing in O(n3). Then for each time calculating w(u, v), the only thing to do is substitute the constants. In this way we can calculate w(u, v) in O(n3).

In this way, we can solve this problem in 

446E - DZY любит мосты Let n = 2m. For convenience, we use indices 0, 1, ..., n - 1 here instead of 1, 2, ..., n, so we define a0 = an.

Obviously this problem requires matrix multiplication. We define row vector , and matrix , where bii = 1, . The answer is row vector .

Since n can be up to 3 × 107, we need a more efficient way to calculate. Let  denote the matrix  when m = k. For example, 

Define , then we can easily find that



where  denotes the identity matrix.

For an n × n matrix  and a constant r, we can prove by induction that 

Let α1, α2 be two 1 × n vectors, then we have 

This result seems useful. Suppose we want to find , where , we have

 so we just need to find , which is a self-similar problem. By recursion, it can be solved in time T(n) = T(n / 2) + O(n) = O(n).

Codeforces Round #254 Editorial

By xyz111, 9 years ago, In English DIV2A-DZY Loves Chessboard Just output the chessboard like this:

WBWBWBWB...

BWBWBWBW...

WBWBWBWB...

...

Don't forget to left '-' as it is. The time complexity is O(nm).

check the C++ code here.

DIV2B-DZY Loves Chemistry It's easy to find that answer is equal to 2n - v, where v is the number of connected components.

check the C++ code here.

DIV1A-DZY Loves Physics If there is a connected induced subgraph containing more than 2 nodes with the maximum density. The density of every connected induced subgraph of it that contains only one edge can be represented as , where u, v are the values of the two nodes linked by the edge. The density of the bigger connected induced subgraph is at most .

If , and for every edge, . Then we'll have u + v < Bc, and , and , it leads to contradiction.

So just check every single node, and every 2 nodes linked by an edge.

The time complexity is O(n + m).

check the C++ code here.

DIV1B-DZY Loves FFT Firstly, you should notice that A, B are given randomly.

Then there're many ways to solve this problem, I just introduce one of them.

This algorithm can get Ci one by one. Firstly, choose an s. Then check if Ci equals to n, n - 1, n - 2... n - s + 1. If none of is the answer, just calculate Ci by brute force.

The excepted time complexity to calculate Ci - 1 is around

 where .

Just choose an s to make the formula as small as possible. The worst excepted number of operations is around tens of million.

check the C++ code here.

DIV1C-DZY Loves Colors The only thing you need to notice is that if there are many continuous units with the same uppermost color, just merge them in one big unit. Every time painting continuous units, such big units will only increase by at most 3. Then you can use STL set to solve it. But anyway, a segment tree is useful enough, check the C++ solution here.

The time complexity is .

DIV1D-DZY Loves Strings We can solve a subproblem in which all the query strings are characters only first. The problem becomes calculating the shortest substring containing two given characters.

If character ch appears more than T times in S, use brute force with time complexity O(|S|) to calculate all the queries containing ch. Obviously, there are at most O(|S| / T) such ch in S.

Otherwise, we consider two sorted sequences, just merge them with time complexity O(T)(Both of the two characters appear at most T times). Being merging, you can get the answer.

So the complexity is O(TQ + |S|2 / T). We can choose , then the complexity is .

And short substring is almost the same with characters.

Check the C++ code here.

DIV1E-DZY Loves Planting Firstly, use binary search. We need to determine whether the answer can be bigger than L. Then, every pair (i, Pi) must contain at least one edge which length is bigger than L. It's a problem like bipartite graph matching, and we can use maxflow algorithm to solve it.

We create 2 nodes for every node i of the original tree. We call one of the nodes Li, and the other Ri. And we need a source s and a terminal t. Link s to every Li with upper bound 1, and link Ri to t with upper bound xi. Then if the path between node a and node b contains an edge with value larger than L, link La and Rb with upper bound 1. This means they can match. Every time we build such graph, we must check O(N2) pairs of nodes, so number of edges of the network is O(N2).

We can make it better. Consider the process of \texttt{Divide and Conquer} of a tree, This algorithm can either based on node or edge. And The one based on edge is simpler in this problem. Now, there are two subtrees Tx, Ty on two sides, we record the maximum edge from every node i to the current edge we split, we call it MAXLi.

Suppose Lx is in Tx and Ry is in Ty (it is almost the same in contrast). We create two new nodes Gx, Gy in the network to represent the two subtrees. Add edges (Li, Gx, ∞) (i is in Tx) and edges (Gy, Ri, ∞) (i is in Ty). If i is in Tx and MAXLi > L, we add an edge (Li, Gy, ∞). If j is in Ty and MAXLj > L, we add an edge (Gx, Rj, ∞).

Then use maxflow algorithm. The number of nodes in the network is O(N) and the number of edges in the network is . So the total complexity is  with really small constant.

Check the C++ code here.

This is what I supposed DIV1-E will be. And thank subscriber for coming up with a really good algorithm with time complexity O(nα(n)) 7025382. And maybe others have the same idea. This is my mistake, and I feel sorry for not noticing that, I'm too naive, and not good at solving problems. Please forgive me.

Codeforces #253 editorial

By qwerty787788, 9 years ago, translation, In English As my english is not very good, please if you see any mistake write me a private message about it.

443A - Anton and Letters

In this task you are to count the number of different letters in the set. In my opinion the easiest way to do this looks like this. You just iterate over all small latin letters and check if the string contains it (with built-in functions).

443B - Kolya and Tandem Repeat

Let's add k question marks to the string. Than we can check all possible starting and ending positions of tandem repeat in a new string. We can check each of them in time O(n + k). We only need to check that some symbols are equal (in our task question mark is equal to every symbol).

442A - Borya and Hanabi

It's obvious that the order of hints doesn't metter. There are 10 types of hints, so we can try all 210 vartiants of what other players should do. Now we need to check if Boris can describe all of his cards. He can do it iff he can distinguish all pairs of different cards. He can do it if somebody told at least one distinction. It can be a hint about color of one of cards (if they don't have same one) or it can be hint about value of some card.

442B - Andrey and Problem

Let's sort all friends in such a way that pi ≤ pj iff i ≤ j. If there is pi = 1 Andrey should ask only this friend. Now we can assume that all probabilities are less then 1. What should we maximize?



Let , . Assume we already have some group of people we would ask a help. Let's look what will happen with the probability of success if we add a friend with probability pi to this group:



It means adding a new people to group will increase a probability of success only if S < 1. Now let's look at another question. We have some group of people with S < 1. And we want to add only one friend to this group. Which one is better? Let the probability of the first friend is pi and the second friend is pj. It's better to add first one if

Δi - Δj = P·pi·(1 - S) - P·pj·(1 - S) = P·(1 - S)·(pi - pj) > 0. As S < 1 we get pi > pj.

But it's only a local criteria of optimality. But, we can prove that globally you should use only a group of people with the biggest probabilities. We can use proof by contradiction. Let's look at the optimal answer with biggest used suffix (in the begining of editorial we sort all friends). Of all such answers we use one with minimum number of people in it. Where are two friends i and j (pi < pj) and i-th friend is in answer and j-th isn't. Let's look at the answer if we exclude i-th friend. It should be smaller because we used optimal answer with minimum numer of people in it. So adding a new people to this group will increase success probability. But we know that adding j-th is better than i-th. So we have found a better answer.

So we have a very easy solution of this problem. After sorting probabilities we should you some suffix of it. Because of sorting time complexity is O(nlogn).

442C - Artem and Array

It's obvious that we should never delete the first and last elements of array. Let's look at the minimum number. Let it be x and there are n elements in the array. We can subtract x from all elements and the answer for the problem will decrease on (n - 2)·x, becouse we will do n - 2 delitions of middle elements and each of this delitions will not give Artem exectly x more points.

If minimal element was the first or the last one, we can not to count it now (it equals to 0 now, so it will not affect the answer now). If it locates in the middle of array, we can prove that there is exist an optimal solution when Artem deletes this element on first move. We can prove it by contradaction. Let's look at the optimal answer where the minimal element is deleted on the minimal possible move (but not on first one). We can prove that we can delete it earlier. If move which is exactly before deleting minimum uses element of array which isn't a neighbour of minimual one we can swap this two delitions and it will not affect the answer. If those elements are neighbours we can write down the number of points which we obtain in both cases and understand that to delete minimum first is the best choice.

So, in this task we need to maintain a set of all not deleted elements and to find a smallest alive element. All of it we can do with built-in data structures in time O(nlogn).

442D - Adam and Tree

First, let's solve the task with already built tree. We can do it with easy dymanic programming. We will count the answer for subtree with an edge to the parent. If we can count it for all vertices we can calculate the answer for the whole tree as maximum of answers for children of root. How to calculate it for one vertex? Suppose we already know answers for children of this vertex. We should color the edge to the parent in the same color as edge to the child with maximum answer. Let two maximum answers for child be max1 and max2 then the answer for this vertex would be max(max1, max2 + 1) if max1 ≥ max2.

What changes when we can add new vertices? Nothing. We can calculate the value of dynamic programming for new vertex (it always would be 1) and recalculate value for its parent. If it doesn't change we should stop this process, in another case we continue recalculations of dynamic programming values: go to its parent and recalculate answer for it and so on. If we maintain two maximums for each vertex in O(1) the asymptotic of the algorithm would be O(nlogn).

To prove it we can use some facts about Heavy-light decomposion. We can use the way Heavy-light decomposion splits edges of tree as our decomposition. We know that answer for such decomposition will be less than logarithm of the number of vertices. So each value of dynamic programming will be increased not more than O(logn) times.

442E - Gena and Second Distance

To solve this problem we can use a binary search. How do we check that answer if not less than R? It means that we can draw a circle with such radius which center locates in the rectangle and there are no more than one point inside this circle. How could we check it? We always can shift this circle in such a way that at least one point would be on its border. We can try all points as one which is on border. Than we should draw a circle with center in it and intersect it with n - 1 circles built on other points. If there is a point on this circle which is covered with no more than one other circle, than answer is greater or equal R. Finding such point is almost a typical problem which can be solved in O(klogk) where k — number of intersections points of circles.

We described a solution which works in O(logAnswer·n2·logn). But we can make it faster. Let's try all vertices as centers of circles and inside this loop make a binary search. We can make one optimize: if we can't find a point on circle with radius which is equal to the best now known than we shouldn't do a binary search in this point (because we can't increase the answer). It can be proved that this solution in avarage case works in O(logAnswer·nlog2n + n2logn) if we shuffle points. It's true because a binary search will be used in avarage only logn times. To prove this fact let's look at probability of binary search to be used in i-th step. If all values are different and shuffled it is . It is known that sum of first n elements of this sirie is bounded by logn.

In this task there are some technical issues you need to know about. For example, we would do a binary search only O(logn) times if we find a stricly incresing subseqence of answers. That's why before using a binary search we should check that we can obtain not current answer but current answer plus some small value. Also we need to understand what "small value" is (it should be something like eps·curAnswer, where eps = 10 - 9, in another case you will probably have some problems with accuracy).

Also one interesting fact about this problem. If you write a solution with time compexity equal to O(logAnswer·n2·logn), it will work very fast on random tests becaue there are will be a very small number of circle intersections.

Codeforces Round #252 (Div. 2) Editorial

By danilka.pro, 9 years ago, translation, In English 441A - Valera and Antique Items Problem author gridnevvvit

You need to implement what written in statement. You could act like that: let's calculate qi — minimum item price from seller i. Then if qi < v, we can make a deal with seller i, otherwise we can't.

Jury's solution: 6850474

441B - Valera and Fruits Problem author gridnevvvit

Let's start counting days from 1 to 3001. Let current day be i. Additionally, we'll have cur variable — number of fruit we didn't collect previous days. Suppose now fruit is ripen current day. If now + cur ≤ v, we need to add now + cur to answer and update cur value (cur = 0). Otherwise we add v to answer, but cur value need to be updated as follows. Let tv = max(v - cur, 0). Then cur = now - tv. In other words, we try to collect fruits that will not be collectable next day.

Additionally, problem could be solved with , but this is not required.

Jury's solution: 6850502

Bonus. Suppose fruit can be collected at days ai, ai + 1, ..., ai + Ti, where Ti — some number for each tree. How to solve this task optimally?

Additionaly, for every day there will be its own v (maximum number of fruit collected).

441C - Valera and Tubes Problem author gridnevvvit

The solution is pretty simple. First we need to make such route that visits every cell exactly one time. It is not difficult:

Initially we stay in (1, 1) cell. Moving from left to right, we should reach (1, m) cell. Move to the next line, in (2, m) cell. Moving from right to left, we should reach the most left sell of 2nd line, (2, 1). Move to the next line. Repeat 1. and 2. while we have not all cells visited.  

After that, we can easily find the solution: you can make first (k - 1) tubes length be 2, and the last k tube will consist from cells left.

Jury's solution: 6850508

441D - Valera and Swaps Problem author danilka.pro

In this task you should represent permutation as graph with n vertexes, and from every vertex i exists exactly one edge to vertex p[i]. It's easy to understand that such graph consists of simple cycles only.

If we make swap (i, j), edges  and  will become edges  and  respectively. Then if i and j is in the same cycle, this cycle will break:

 

but if they are in different cycles, these cycles will merge into one:

 

this means that every swap operation increases number of cycles by one, or decreases it by one.

Assuming all above, to get permutation q from permutation p, we need to increase (or decrease) number of cycles in p to n - m. Let c — number of cycles in p. Then k always equals |(n - m) - c|.

For satisfying lexicographical minimality we will review three cases:

1) n - m < c

It's easy to understand, that in this case you must decrease cycles number by merging cycles one by one with cycle containing vertex 1. This way every swap has form (1, v), where v > 1. Because every cycle vertex is bigger than previous cycle vertex, this case can be solved with O(n).

2) n - m > c

In this case you should break cycle for every vertex, making swap with smallest possible vertex (it should be in this cycle too). This could be done if represent cycle by line . As soon as every cycle is broken with linear asymptotics, this case solution works with O(n2).

Bonus: this way of representing cycle lets us optimize solution to  asymptotics, you may think how.

3) n - m = с

Besause in this case k = 0, there is nothing need to be swapped.

It's highly recommended to inspect jury's solution: 6850515

441E - Valera and Number Problem author gridnevvvit

We will solve the task by calculating dynamic d[i][mask][last][cnt] — possibility of getting v which 8 last bits equals mask, 9th bit equals last, cnt — number of consecutive bits (following 9th bit) and equal to last, after i steps.

Good, but why we left other bits? It's clear, that using operation  +  = 1 we can change only first 0 bit with index  ≥ 9.

Transitions is pretty obvious: we add 1 or multiply by 2 (it's recommended to see them in jury's solution). Perhaps, you should ask following question. For example, we have number x = 1011111111 in binary representation.

And at this moment, we make  +  = 1. According to all above, we must go to d[1][0][1][2] condition, but we can't do that because we don't have any information about 1 in 10th position. But, as we can not change any bit with index  ≥ 9 (mask = 0) we make transition to d[1][0][1][1].

Jury's solution: 6850523

Bonus. Let us have other pseudocode.

// input x, k, p   for(i = 0; i < k; i += 1) {    if (x is even) {      rnd = random number from interval [1, 100]      if (rnd <= p)        x *= 2;      else        x += 1;    } else {       x *= 2;    } }   s = 0;   while (x is even) {   x /= 2;   s += 1; }   As before, you must find expected value of s.

How effectively you can solve this problem? Can you prove your solution?

Your corrections of my bad English are welcome, thank you.

Codeforces Round #251 Editorial

By PraveenDhinwa, 9 years ago, In English 439A - Devu, the Singer and Churu, the Joker

For checking whether there is a way to conduct all the songs of the singer, you can conduct the event in the following way.

First singer will sing a song. Then during 10 minutes rest of the singer, the joker will crack 2 jokes(each of 5 minutes) Then singer will again sing a song, then joker, etc. After the singer has completes all his songs, the joker will keep on cracking jokes of 5 minutes each. Hence minimum duration of the even needed such that sing could sing all his songs will be t1 + 10 + t2 + 10 + ... +tn = sum + (n - 1) * 10 where sum denote the total time of the songs of the singer.

So for checking feasibility of the solution, just check whether sum + (n - 1) * 10 ≤ duration or not?.

If it is feasible, then time remaining for joker will be the entire duration except the time when the singer is singing the song. Hence time available for the joker will be duration - sum. In that time joker will sing  songs.

Solution codes

my solution 439B - Devu, the Dumb Guy

You can formulate the problem in following way. Given two arrays a and b. Find minimum cost of matching the elements of array a to b. For our problem the array a will be same as b. The array b will have content x, x — 1, , 1, 1. For a general version of this problem, we can use min cost max flow(min cost matching), but for this problem following simple greedy solution will work.

Sort the array a in increasing and b in decreasing order (or vice versa). Now match ith element of the array a with ith element of array b. Proof:

It can be easily proved by exchange argument.

Solution Codes

my solution 439C - Devu and Partitioning of the Array

Let us first try to find the condition required to make sure the existence of the partitions.

Notice the following points.

If the parity of sum does not match with parity of number of odd partitions (k - p) , then we can't create the required partitions. eg. a = [1;2], k = 2, p = 0, Then you can not create two partitions of odd size, because then sum of the elements of the partitions of the array will be even whereas the sum of elements of the array is odd.

If number of odd elements in a are less than k - p (number of required partitions with odd sum), then we can not do a valid partitioning.

If number of even elements are less than p, then we can not create even partitions simply by using even numbers, we have to use odd numbers too. Notice the simple fact that sum of two odd numbers is even. Hence we will try to include 2 odd elements in our partitions too. So if we can create oddsRemaining / 2 partitions in which every partition contains 2 odd elements, then we can do a valid partitioning otherwise we can't. Here oddsRemaining denotes the number of odd elements which are not used in any of the partitions made up to now.

Let oddElements denotes the number of odd elements in array a. Similarly evenElements denotes the number of even elements.

So the answer exists if

Number of possible odd partitions are  ≥  k - p i.e. oddElements ≥ k - p. Number of possible even partitions are  ≥  p i.e. evenElements + (oddRemaining) / 2 ≥ p. where oddRemaining is oddElements - (k - p). For generating the actual partitions, you can follow the same strategy used in detecting the existence of the partitions. We will first generate any valid p partitions (forget about the condition of using the entire array), then we can simply include the remaining elements of the array in the last partition and we are done.

Solution Codes

[user:Gerald]'s solution

my code

439D - Devu and his Brother

You can solve the problem in two ways.

By using ternary search Let us define a function f. Function f(k) = cost needed to make array a elements  ≥  k + cost needed to make array b elements  ≤  k

Instead of proving it formally, try checking the property on many random test cases. You will realize that f is convex.

Claim: f is convex:

Proof:

It is fairly easy to prove. See the derivative of f.

 = — (# of elements of b > k) + (# of elements of a < k)

The first term (without sign) can only decrease as k increases whereas second term can only increase as k increases.

So, 

By using the fact that optimal values are attainable at the array values: All the extremum points will lie in the elements from the any of the arrays because f is convex and  at the event points (or the points of array a and b).

For learning more about ternary search, you can see following topcoder discussion

Another smart solution

Please see following comment of goovie and proof is given in the reply by himank

Solutions Code

ternary search solution my solution using 2nd fact [user:Gerald] solution [user:triveni] solution using smart solution 439E - Devu and Birthday Celebration

There are two possible solutions.

dp solution

Let P(n, f) be total number of ways of partitioning n into f segments such that each ai is positive. With some manipulations of the generating function, you can find that this is equal to .

So 

Let F(n, f, g) denotes partitions of n into f parts such that gcd of all the ai's is g.

Note that F(n, f, 1) = P(n, f) — sum of F(n, f, g) over all possible gcd g's. So g will be a divisor of n.

In other words, 

As .



You can implement this solution by a simple dp.

You can pre-calculate factorials which will help you to calculate .

Complexity of this solution will be nlogn over all the test cases.

Please note that this solution might get time limit exceeded in Java. Please read the comment.

Mathematical solution

Note that F(n, f, 1) = P(n, f) — sum of F(n, f, g) over all possible gcd g's (g > 1 such that g is a divisor of n.

In other words, 

As F(n, f, g) = .







Now you have to use Möbius inversion formula.

Theorem:

If f and g are two arithmetic functions satisfying



then 

So In our case: g(n) is P(n, f) and f(n) is F(n, f, 1).

For proving complexity: Use the fact that total number of divisors of a number from 1 to n is 

Please also see xorfire comment for understanding the relation between mobius function and the solution using inclusion exclusion principle.

Solution Codes

my solution using mobius function [user:Gerald]'s code based on first solution [user:Balajiganapathi,2014-06-05]'s inclusion exclusion principle

Codeforces Round #250 Editorial

By vfleaking, 9 years ago, In English 437A - Ребенок и домашняя работа We enumerate each choice i, and then enumerate another choice j (j ≠ i), let cnt = 0 at first, if choice j is twice longer than i let cnt = cnt + 1, if choice j is twice shorter than i let cnt = cnt - 1. So i is great if and only if cnt = 3 or cnt =  - 3.

If there is exactly one great choice, output it, otherwise output C.

437B - Ребенок и множество We could deal with this by digits.

Because lowbit(x) is taking out the lowest 1 of the number x, we can enumerate the number of the lowest zero.

Then, if we enumerate x as the number of zero, we enumerate a as well, which a × 2x is no more than limit and a is odd. We can find out that lowbit(a × 2x) = 2x.

In this order, we would find out that the lowbit() we are considering is monotonically decresing.

Because for every two number x, y, lowbit(x) is a divisor of lowbit(y) or lowbit(y) is a divisor of lowbit(x).

We can solve it by greedy. When we enumerate x by descending order, we check whether 2x is no more than sum, and check whether there is such a. We minus 2x from sum if x and a exist.

If at last sum is not equal to 0, then it must be an impossible test.

Why? Because if we don't choose a number whose lowbit = 2x, then we shouldn't choose two numbers whose lowbit = 2x - 1. (Otherwise we can replace these two numbers with one number)

If we choose one number whose lowbit = 2x - 1, then we can choose at most one number whose lowbit = 2x - 2, at most one number whose lowbit = 2x - 3 and so on. So the total sum of them is less than 2x and we can't merge them into sum.

If we don't choose one number whose lowbit = 2x - 1, then it's just the same as we don't choose one number whose lowbit = 2x.

So the total time complexity is O(limit).

437C - Ребенок и игрушка The best way to delete all n nodes is deleting them in decreasing order of their value.

Proof:

Consider each edge (x, y), it will contribute to the total cost vx or vy when it is deleted.

If we delete the vertices in decreasing order, then it will contribute only min(vx, vy), so the total costs is the lowest.

437D - Ребенок и зоопарк First, there is nothing in the graph. We sort all the areas of the original graph by their animal numbers in decreasing order, and then add them one by one.

When we add area i, we add all the roads (i, j), where j is some area that has been added.

After doing so, we have merged some connected components. If p and q are two areas in different connected components we have merged just then, f(p, q) must equals the vi, because they are not connected until we add node i.

So we use Union-Find Set to do such procedure, and maintain the size of each connected component, then we can calculate the answer easily.

437E - Ребенок и многоугольник In this problem, you are asked to count the triangulations of a simple polygon.

First we label the vertex of polygon from 0 to n - 1.

Then we let f[i][j] be the number of triangulations from vertex i to vertex j. (Suppose there is no other vertices and there is an edge between i and j)

If the line segment (i, j) cross with the original polygon or is outside the polygon, f[i][j] is just 0. We can check it in O(n) time.

Otherwise, we have , which means we split the polygon into the triangulation from vertex i to vertex k, a triangle (i, k, j) and the triangulation from vertex k to vertex j. We can sum these terms in O(n) time.

Finally,the answer is f[0][n - 1]. It's obvious that we didn't miss some triangulation. And we use a triangle to split the polygon each time, so if the triangle is different then the triangulation must be different, too. So we didn't count some triangulation more than once.

So the total time complexity is O(n3), which is sufficient for this problem.

438D - Ребенок и последовательность The important idea of this problem is the property of .

Let .

So, .

If k = 0,  remains to be x.

If k ≠ 0, .

We realize every time a change happening on x, x will be reduced by at least a half.

So let the energy of x become . Every time when we modify x, it may take at least 1 energy.

The initial energy of the sequence is .

We use a segment tree to support the query to the maximum among an interval. When we need to deal with the operation 2, we modify the maximum of the segment until it is less than x.

Now let's face with the operation 3.

Every time we modify an element on the segment tree, we'll charge a element with  power.

So the total time complexity is : .

By the way, we can extend the operation 3 to assign all the elements in the interval to the same number in the same time complexity. This is an interesting idea also, but a bit harder. You can think of it.

438E - Ребенок и двоичное дерево Let f[s] be the number of good vertex-weighted rooted binary trees whose weight exactly equal to s, then we have:

f[0] = 1



Let F(z) be the generating function of f. That is, 

And then let 

So we have:

F(z) = C(z)F(z)2 + 1

`` + 1'' is for f[0] = 1.

Solve this equation we have:



So the remaining question is: how to calculate the multiplication inverse of a power series and the square root of a power series?

There is an interesting algorithm which calculate the inverse of a power series F(z):

We use f(z) ≡ g(z) (mod zn) to denote that the first n terms of f(z) and g(z) are the same.

We can simply calculate a formal power series R1(z) which satisfies R1(z)F(z) ≡ 1 (mod z1)

Next, if we have Rn(z) which satisfies Rn(z)F(z) ≡ 1 (mod zn), we will get:

(Rn(z)F(z) - 1)2 ≡ 0 (mod z2n)

Rn(z)2F(z)2 - 2Rn(z)F(z) + 1 ≡ 0 (mod z2n)

1 ≡ 2Rn(z)F(z) - Rn(z)2F(z)2 (mod z2n)

R2n(z) ≡ 2Rn(z) - Rn(z)2F(z) (mod z2n)

We can simplely use Fast Fourier Transform to deal with multiplication. Note the unusual mod 998244353 (7 × 17 × 223 + 1), thus we can use Number Theoretic Transform.

By doubling n repeatedly, we can get the first n terms of the inverse of F(z) in  time. It's because that 

We can just use the idea of this algorithm to calculate the square root of a power series F(z):

We can simply calculate a power series S1(z) which satisfies S1(z)2 ≡ F(z) (mod z2n)

Next, if we have Sn(z) which satisfies Sn(z)2 ≡ F(z) (mod zn), we will get:

(Sn(z)2 - F(z))2 ≡ 0 (mod z2n)

Sn(z)4 - 2Sn(z)2F(z) + F(z)2 ≡ 0 (mod z2n)

Sn(z)2 - 2F(z) + F(z)2Sn(z) - 2 ≡ 0 (mod z2n)

4F(z) ≡ Sn(z)2 + 2F(z) + F(z)2Sn(z) - 2 (mod z2n)

4F(z) ≡ (Sn(z) + F(z)Sn(z) - 1)2 (mod z2n)



So, 

By doubling n repeatedly, we can get the first n terms of the square root of F(z) in  time.

That's all. What I want to share with others is this beautiful doubling algorithm.

So the total time complexity of the solution to the original problem is .

My code

There is an algorithm solving this problem using divide and conquer and Fast Fourier Transform, which runs in . See the C++ code and the Java code for details.

Codeforces Round #249 (Div. 2) Editorial

By HolkinPV, 9 years ago, translation, In English 435A - Queue on Bus Stop The problem could be solved in one cycle by groups. The solution could be implemented in this way:

int result = 1; int people = 0;

for(int i = 0; i < n; i++) {     if (people + a[i] <= m)         people += a[i];     else     {         result++;         people = a[i];     } }

cout << result << endl; 435B - Pasha Maximizes The problem could solved by greedy algorithm. We will try to pull maximum digits to the beginning. The algorithm could be described in this way:

1) Consider every position in the number from the first, assume that the current position is i 2) Find the nearest maximum digit from the next k digits of the number, assume that this digit is on position j 3) If this maximum digit is greater than current digit on position i, then make series of swaps, push this digit to position i, also decrease k, that is do k = k - (j - i)

435C - Cardiogram This problem is technical, you should implement what is written in the statement. First, you need to calc coordinates of all points of the polyline. Also create matrix for the answer. Coordinate y could become negative, so it is useful to double the sizes of the matrix and move the picture up to 1000. In the end you should print the answer without unnecessary empty rows.

To paint the cardiogram you should consider every consecutive pair of points of the polyline and set characters in the answer matrix between them. If the polyline goes up then set slash, otherwise set backslash. To understand the solution better please paint the first test case on the paper, mark coordinates of the points and find what values to set in cycles in your program.

435D - Special Grid Values n and m are not so large, so the solution with complexity O(max(n, m)3) should pass. It means that you should consider all triangles and check all conditions in O(1).

To make this check you should precalc arrays of partial sums on all diagonals, rows and columns. After that you could check, that there is no black nodes on the side using one sum-query.

Some hints about this problem and the implementation:

all correct triangles are isosceles right triangles; either all legs or hypotenuse of the triangle is parallel to the sides of the grid; if you know how to solve the problem for two types of the triangles, you can get the whole solution making 4 rotates of the matrix. 435E - Special Graph To solve this problem you have to paint different correct colorings on the paper. After it you could observe that there are two types of them: vertical and horizontal.

Vertical colorings looks like this:

acbcbd... bdadac... acbcbd... bdadac... acbcbd... bdadac... ......

In other words, each vertical has only two colors, odd verticals have equal colors, even verticals have two others. The order of the colors on every vertical could be arbitrary.

Horizontal colorings are the same, they are rotated by 90 degrees. Of course, there are both vertical and horizontal colorings, but it doesn't change the solution.

So, you should consider every type of described colorings and check them. That is, you could choose what colors are on the verticals or what colors are on horizontals and check that obtained coloring matches the given matrix.

The solution's complexity is O(n × m).

Codeforces Round #248 Editorial

By huzecong, 9 years ago, In English If you have any questions or suggestions, or if you have a solution different to ours that you want to share with us, feel free to comment below :)

Author solutions are added.

Div. 2 A — Kitahara Haruki's Gift Denote G as the sum of the weight of the apples. If G / 100 is not an even number, then the answer is obviously "NO". Otherwise, we need to check if there is a way of choosing apples, so that the sum of the weight of the chosen apples is exactly .

A simple O(n) approach would be to enumerate how many 200-gram apples do we choose, and check if we can fill the rest with 100-gram apples. We can also solve this problem using a classic knapsack DP.

Solution: 6712942

Div. 2 B — Kuriyama Mirai's Stones Sort sequence v to obtain sequence u. Sorting can be done in  using quicksort. Now we are interested in the sum of a interval of a given sequence. This can be done by calculating the prefix sum of the sequence beforehand. That is, let . The sum of numbers in the interval [l, r] would then be svr - svl - 1. We can deal with sequence u likewise.

Preprocessing takes O(n) time, and answering a query is only O(1). The total complexity would be .

Solution: 6713020

Div. 2 C / Div. 1 A — Ryouko's Memory Note Suppose we're merging page x to page y. Obviously page x should be an element of sequence a, otherwise merging would have no effect. Enumerate all possible values of x, and denote sequence b as the elements of a that are adjacent to an element with value x. If one element is adjacent to two elements with value x, it should appear twice in b. However, if one element itself is x, it should not appear in b.

For example, suppose we have a = {2, 2, 4, 1, 2, 1, 2, 3, 1}, then sequence b for x = 2 would be b = {4, 1, 1, 1, 3}, where the 6-th element appears twice.

Problem remains for finding a optimum value for y. Let m be the length of sequence b. When merging x to y, the change in answer would be



We only care about the left part, as the right part has nothing to do with y. We can change our problem to the following:

Given n numbers on the number axis, find a number x so that the sum of the distance between x and the n given numbers is minimum. This is, however, a classic problem. We have the following conclusion:

The number x in the problem should be the median of the n numbers. Proof:

Consider the case where n is odd. Proof is similar for cases where n is even.

We choose an arbitary number as x. Suppose there are l numbers on the left of x, and r numbers on the right of x. If x is the median, then l = r, so what we're going to prove is that optimal answer cannot be achieved when l ≠ r.

Suppose l < r, consider what would happen to the answer if we add d(d > 0) to x (Here we assume that adding d to x does not affect the values of l and r). The distance between x and all the numbers on the right would decrease by d, while the distance between x and all numbers on the left would increase by d. So the answer would decrease by (r - l)d, which is a positive value, since l < r.

So x would keep increasing until l = r, when optimal answer can be achieved. Thus x is the median of the n numbers.

This brings us to our solution. Simply sort sequence b and find its median, then calculate the answer. The final answer would be the optimal one from all possible values of x. The complexity is , as the sum of the length of all b sequences does not exceed 2n.

About the pretests: Pretests for this problem are deliberately made weak, in order to make hacking more fun. None of the pretests contains adjacent numbers with the same value.

Solution: 6712939, 6713018

Div. 2 D / Div. 1 B — Nanami's Digital Board Consider a similar problem: find the maximum light-block of the whole board. Constraints to this problem are the same as the original problem, but with no further operations.

A brute-force idea would be to enumerate all four edges of the block, checking can be done with two-dimensional prefix sums, so the time complexity is O(n4). Obviously it would receive a TLE verdict.

Why should we enumerate all four edges? Let's enumerate the lower- and upper-edge, and now our problem is only one-dimensional, which can be easily solved in O(n) time. Now our complexity is O(n3), still not fast enough.

Let's try to enumerate the lower-edge only, and now what we have is an array up[], denoting the maximum "height" of each column. To be specific, suppose the lower-edge is row x, then up[i] is the maximum value such that (x, i), (x - 1, i), ..., (x - up[i] + 1, i) are all light. If we choose columns l and r as the left- and right-edge, then the area of the maximum light-block with these three sides fixed would be



Let , what if we enumerate h, and find the leftmost l and the rightmost r? To be more specific, we enumerate a column p, and let the height of this column be the height of the block. Now we want to "stretch" the left and right sides of the block, so we're looking for the leftmost column l such that . Similarly look for the rightmost column r, then the maximum light block with its lower-edge and a point in the upper-edge fixed would be (r - l + 1)·up[p].

This approach can be optimized with disjoint-set unions (abbr. DSU). Imagine that initially the up[] array is empty. Let's add the elements of up[] one by one, from the largest to the smallest. Maintain two DSUs, and denote them as L and R.When we add an element up[i], set the father of i as i + 1 in R, so that i will be "skipped" during the "find" operation of DSU. Similarly set the father of i as i - 1 in L. Simply find the root of i in L and R, and we would have l and r.

Now this problem can be solved in quasi-quadratic time. We can actually further optimize it to quadratic time using monotonic queues, but we'll not talk about it here. Let's go back to the original problem.

Suppose there are no modifications, operations only contain queries. Then we could simply maintain the up[] array of every row, and similarly maintain down[], left[] and right[] arrays. Use the approach described above to achieve quasi-linear time for the answering of a query.

Now consider modifications. Modification of a single pixel only changes the values of O(n + m) positions of the arrays. So modifications can be handled in linear time.

The total complexity for the algorithm is O(n2 + qn·α(n)), where α(n) is the inverse of the Ackermann function, which is often seen in the analysis of the time complexity of DSUs.

Solution: 6712937, 6713016

Div. 2 E / Div. 1 C — Tachibana Kanade's Tofu A straightforward brute-force idea would be to enumerate all numbers in the interval [l, r], and count how many of them have a value greater than k. This approach is way too slow, but nevertheless let's try optimizing it first.

The enumeration part seems hard to optimize, so let's consider what is the fastest way of calculating the value of a string. This is a classic problem that can be solved using an Aho-Corasick automaton (abbr. ACA). Build an ACA with the given number strings, and simply "walk" in the automaton according to the string to be calculated.

Consider a common method when dealing with digits — split the interval [l, r] into two, [1, r] minus [1, l - 1]. Then use DP to solve an interval, take [1, r] for instance. Consider filling in the numbers one by one, we need to record in the states of the DP the position in the string, and a flag denoting whether we're "walking on the edge of the upper bound", that is, whether the numbers we've filled are the prefix of the upper-bound r.

How can we use the approach above in this problem? Can we combine this approach with our ACA? The answer is yes, further record in the states of the DP the ID of the node we're currently "standing on" in the ACA. Consider the transfer of this DP, enumerate which number we're going to fill in, and check using our flag if the current number will be greater than the upper-bound. Appending a number to the end of our string would result in a change of the ID of the node in our ACA, so "walk" along the transferring edge in the ACA.

What about the limit of values? Simply record the current value in our DP state, during transfer, add the value stored in the ACA's node to the value stored in our state.

The tricky bit is the leading zeros. Numbers can't have leading zeros, but number strings can. How can we distinguish leading zeros from zeros in the middle of the number? We keep another flag, denoting whether we're still dealing with leading zeros.

So finally our state looks like f[len][node][val][upper_bound_flag][leading_zero_flag], where len, node, and val are current length of number, ID of current node in ACA, and current value of number respectively. Let N be the total length of all number string, and L be the length of r, the total complexity would be O(NLkm), since the number of states is O(NLk) and transfer takes O(m) time.

Solution for the approach above: 6712934 Solution for a different approach: 6713013

Div. 1 D — Nanami's Power Plant We can use a flow network to solve the problem.

For each variable xi, create ri - li + 2 points, and denote them as node(i, li - 1) to node(i, ri). Edges are as follows:

Link source to each node(i, li - 1) with capacity of infinity. Link each node(i, ri) to sink with capacity of infinity. Link each node(i, x - 1) to node(i, x) with capacity of MAX - fi(x). Here MAX is a number greater than every possible value of the variables. Let C be the value of the minimum cut of this network. If there are no further restrictions, it is obvious that MAX·n - C is the maximum profit.

Now consider the restrictions. Suppose a restriction is xu ≤ xv + d, then for each node(u, x), link it to node(v, x - d) (if exists) with a capacity of infinity. If there exists a solution, MAX·n - C will be the optimal profit.

We want to prove that the edges with infinite capacity can really restrict our choice of values for variables. Note that a valid solution is correspondent to a cut of the graph. It can be proved that if a restriction is not satisfied, there will be a augmenting path in the graph. You can verify this by drawing the graphs. And because we are looking for the minimum cut, in this case the maximum sum, there can be no valid solution with a greater sum.

About the time limit: The time limit for this problem is 5 seconds, which is by far greater than this solution actually need. We set the time limit to 5 seconds because of possible worst-case complexity of the maximum flow algorithm, although in "real-life" cases that complexity is never achieved.

About the solution: This solution takes advantage of the fact that there are few possible values for the variables. And also the fact that functions are all quadratic is no use here, so statements may be quite misleading. If you have any ideas on how to solve the problem with a larger range for variables, or a solution using the fact that functions are quadratic, please share it in the comments :)

Solution: 6712933, 6713009

Div. 1 E — Furukawa Nagisa's Tree In order not to mess things up, we use capital letters X, Y and K to denote the values in the original problem.

First, we can build a directed graph with n2 edges. Let E(i, j) be the edge from node i to node j. If path (i, j) is good, the color of E(i, j) is 0, otherwise it is 1.

We want to calculate the number of triplets (i, j, k) that satisfies (i, j), (j, k) and (i, k) are all good or all not good. It equals the number of directed triangles, the color of whose three edges are the same. (The triangle is like: )

Calculating this is difficult, so let us calculate the number of directed triangles whose three edges are not all the same.

Let in0[i] be the number of in-edges of node i whose color is 0. Similarly define in1[i], out0[i], out1[i]. Let



We can see that the answer is twice the number of triangles whose three edges are not all the same. So we can see the answer of the original problem is n3 - p / 2.

It's certain that out0[i] + out1[i] = in0[i] + in1[i] = n, so we only need to calculate out0 and in0.

Let us calculate out0 first. We can use the "Divide and Conquer on trees" algorithm to solve this in  time. Choose a root i and get its subtree, we can get all the values of the paths from a node in the subtree to node i. We save the values and the lengths of the paths.

For a path from node j with value v and length l, we want to find a node k which makes G(S(j, k)) ≡ X (mod Y). Let H(i, j) be the sequence of the value of nodes on (i, j) except node i, then

G(S(j, k)) = G(S(j, i)) + G(H(i, k))·Kl = v + G(H(i, k))·Kl

As (v + G(H(i, k))·Kl) ≡ X (mod Y), so G(H(i, k)) = (X - v) / Kl. As Y is a prime number, we can get (x - v) / Kl easily. Let z = (x - v) / Kl, then the problem becomes that we need to calculate how many paths from node i to a node in the subtree except node i, whose value is z, this can be done by doing binary search on a sorted array. So we can get out0, and in0 likewise.

With these two arrays we can calculate the answer. The total complexity is .

Solution: 6707988, 6712931

Editorial Codeforces Round #247 (Div. 2)

By KaiZeR, 9 years ago, translation, In English 431A - Black Square To solve this problem, you must only do the process described in statement.

for i = 1 .. s.size()  if (s[i] = '1') ans += a[1];  else ... Complexity: O(N) Solution: 6676675

431B - Shower Line In this problem, according to the small limits, we can brute all permutations and choose the best answer of all. The easeast way to do this — use standart C++ function next_permutation, or simply write 5 for. For each permutation we can simulate the process, which was described in a statement, or notice that first with second student, and second with the third will communicate one time, and third with fourth student, and fourth with fifth — will communicate two times. Another pairs of students will never communicate to each other during they stay in queue.

Complexity: O(n!) Solution: 6676695

431C - k-Tree This problem can be solved by dinamic programming. Let's Dp[n][is] — number of ways with length equals to n in k-tree, where if is = 1 — there is exists edge with length at least d, is = 0 — lengths of all edges less then d. Initial state Dp[0][0] = 1. Transition — iterate all edges which can be first on the way in k-tree, then problem transform to the same, but with less length of the way (because subtree of vertex son is the k-tree).

Dp[n][0] = Dp[n-1][0] + ... + Dp[n-min(d-1,n)][0] Dp[n][1] = Dp[n-1][1] + ... + Dp[n-min(d-1,n)][1] + (Dp[n-d][0] + Dp[n-d][1]) + ... + (Dp[n-min(n,k)][0] + Dp[n-min(n,k)][1])

See solution for more details.

Complexity: O(nk) Notice that this solution can be easy midify to O(N) complexity, only precalc partial sums. But it is not neccesary to solve this problem in such way. Solution: 6676700

431D - Random Task We will search n by binary search. Such function is monotone, because the amount of numbers with exactly k 1-bits on a segment n + 2 ... 2·(n + 1) more or equal than amount of such numbers on segment n + 1 ... 2·n. Last statement is correct, because of n + 1 and 2·(n + 1) have equals number of 1-bits. To find the amount of numbers on segment L...R, which have exactly k 1-bits, it is sufficient to can calculate this number for segment 1...L, then the answer will be F(1...R) - F(1..L - 1). Let's understand how we can calculate F(1...X). Iterate number of bit will be the first(from biggest to smallest) which is different in X and numbers, which amount we want to calculate. Let the first difference will be in i-th bit(it's possible, if in X this bit equals to 1, because we consider all numbers do not exceed X). Then other smallest bits we can choose in any way, but only amount of 1-bits must equals to k. We can do this in Cik - cnt ways, where cnt — the number of 1-bits in X, bigger then i, and Cnk — binomailany factor. Finally, you should not forget about X (if it, of course, has k one bits).

long long F( X )    Ans = 0 , cnt = 0;    for i = Max_Bit...0       if (bit(X,i) == 1) Ans += C[i][K - cnt] , cnt ++;    if (Bit_Counts(X) == K) Ans ++;       return Ans; Асимптотика: O(log2(Ans)) Решение: 6676713

431E - Chemistry Experiment First of all let's understand the statement. We have n tubes. At the beginning of each of them there are a few amount of mercury is poured. We want be able to perform two types of queries:

Make the amount of mercury in p- th tube equals to x. Given the number v — the amount of water that must be optimally pour these tubes. What does it mean optimally? That mean we pour water in some of the tubes in the way, when maximum volume of liquid for all tubes, where we poured water, will be as small, as possible. Well, actually now turn to the solution. Use binary search to find an answer, in particular, will sort out the amount of mercury in a tubes(let it equals to d), such that in the tubes with smaller volume of the liquid can be poured all v liters of water and the maximum liquid level does not exceed d. Let the number of tubes, with the amount of mercury less than d is equal t.

Now the problem is reduced to learning how to count the total amount of water that we can to pour into each of t least tubes, such that the level of the liquid in each of them is equal d.

Let a[i] — the total amount of mercury in the tubes which exactly have i liters mercury and b[i] — number of tubes which the volume of mercury is equal i. Then t = b[0] + ... + b[d - 1] and v1 = t * d - (a[0] + a[1] + ... + a[d - 1]) — the total maximum amount of the water which can be poured. If v1 < v, then obviously this space is not enough for pour all the water, otherwise quite enough and so the answer will be no more than d. When we found the smallest d, we can say that the answer is equal d — (v1 — v) / t.

To quickly find for a[0] + a[1] + ... + a[d - 1] and b[0] + ... + b[d - 1], and perform queries of the first type, you can use the Fenwick tree. Асимптотика: O(qlog2(n)) Решение: 6676668

Codeforces Round #246 (Div. 2) Editorial

By HolkinPV, 9 years ago, translation, In English 432A - Choosing Teams In this problem you should count number of students who can participate in ACM, divide it by 3 and round down. It could be done like this:

int cnt = 0;

for(int i = 0; i < n; i++)     if (5 - a[i] >= k)         cnt++;

int ans = cnt / 3; 432B - Football Kit Count for every team number of games in home kit. For team i it equals to sum of n - 1 games at home and some away games with such teams which home kit color equals away kit color of team i. To count number of such away games you could calc array cnt[j] — number of teams with home color kit j. The solution could be implemented in this wasy:

for(int i = 0; i < n; i++)     cnt[ x[i] ]++;

for(int i = 0; i < n; i++) {     ans_home[i] = n - 1;     ans_home[i] += cnt[ y[i] ];

    ans_away[i] = 2 * (n - 1) - ans_home[i]; } 432C - Prime Swaps The solution can be described by pseudo-code:

Consider elements of permutation from 1 to n

While current element i is not sutiated on position i

Let the position of element i equals pos

Find maximum prime integer p which is less or equal than $pos — i + 1

Swap element in positions pos and pos - p + 1

It could be proved that such algorithm makes less than 4n swaps (for example, by implementing the algorithm)

This algorithm should be implemented optimally. You should maintain positions of elements of permutation. Swap function in author's solution:

void doSwap(int i, int j){     int x = a[i], y = a[j];     a[j] = x, pos[x] = j;     a[i] = y, pos[y] = i;     result.push_back(make_pair(i, j)); } 432D - Prefixes and Suffixes The problem could be solved using different algorithms with z and prefix functions. Let's describe the solution with prefix function p of string s. Calc prefix function and create a tree where vertices — integers from 0 to |s|, edges — from p[i] to i for every i. The root of the tree is 0. For every vertex v calc the number of values p[i] = v — that is cnt[v]. Then for every v calc the sum all values cnt[u] for every u in to subtree of v.

The general answer to the problem is:

Find all lenghts of the prefixes which matches the suffixes — these values are |s|, p[|s|], p[p[|s|]], p[p[p[|s|]]]... For every such length L the answer to the problem is sum[L] + 1.

432E - Square Tiling This is popular test 6 :)

13 5

AAAAA AAAAA AAAAA AAAAA AAAAA BBBBB BBBBB BBBBB BBBBB BBBBB AAACA AAABB AAABB The problem could be solved in a standard way — try to fill the table from the first cell to the last and try to put the miminum letter.

Consider the first row. Obviously it begins from some letters A (to be exact min(n, m) letters A). When we put some letters A in the first row, we should put several letters A in some next rows to make a square. The next letter could be only B.

Describe the solution in general. Assume that we have already considered some rows. Consider row i. Some cells in this row could be already painted. Consider unpainted cells from left to the right. For every such cell consider its color from A to Z. Two cases should be considered:

Put in this cell the minimum possible letter (neighbours have no such letter)

If the previous cell in this row was not painted at the beginning of considering row i, now it is already painted. We should try to merge the current cell with the square of the previous cell.

Choose the best case from these cases. Try to get the answer on test n = 13 m = 5 to understand the algorithm better.

Codeforces Round #245 — Editorial

By fchirica, 9 years ago, In English 430A - Points and Segments (easy) The problem asks you to output “-1” if there is no solution. A natural question is now: “when there is no solution”? Try to come up with a test like this!

After some analysis, you’ll see anyhow we draw the points and the lines, there will always be a solution. By manually solving small cases, you might already have found the pattern. But for now, let’s assume anyhow we draw points and lines, there will always be a solution. Let’s have a fixed set of points. Then, anyhow we draw a line, there should still be a solution. So, we need to find a coloring of points, such as for every line, |number of red points which belong to it – number of blue points which belong to it| <= 1.

Suppose anytime you color a point with red you assign it +1 value. Also, anytime you color it with blue you assign it -1 value. Then, for a segment, the drawing is good if S = sum of values assigned to points that belong to segment is between -1 and 1 (in other words |S| <= 1). Let’s sort points increasing by abscissa. It’s useful because now, for a segment, there will be a contiguous range of points that belong to that segment. For example, suppose my current segment is [3, 7] and the initial set of points was {4, 1, 5, 2, 8, 7}. Initially, points that belong to the segment would be first, third and sixth. Let’s sort the points by abscissa. It looks like {1, 2, 4, 5, 7, 8}. You can see now there is a contiguous range of points that belongs to [3, 7] segment: more exactly third, fourth and fifth.

We reduced problem to: given an array, assign it either +1 or -1 values such as, for each subarray (contiguous range), the sum S of subarray’s elements follows the condition |S| <= 1. Before reading on, try to come up with an example by yourself.

My solution uses the pattern: +1 -1 +1 -1 +1 -1 ... Each subarray of it will have sum of its elements either -1, 0 or 1. How to proof it? When dealing with sums of subarrays, a good idea is to use partial sums. Denote sum[i] = x[1] + x[2] + ... + x[i]. Then, sum of a subarray [x, y] is sum[y] – sum[x – 1]. Partial sums for the pattern looks like: 1 0 1 0 1 0 .... Hence, there are 4 possible cases:

1/ sum[x – 1] = 0 and sum[y] = 0. sum[y] – sum[x – 1] = 0

2/ sum[x – 1] = 1 and sum[y] = 1. sum[y] – sum[x – 1] = 0

3/ sum[x – 1] = 0 and sum[y] = 1. sum[y] – sum[x – 1] = 1

4/ sum[x – 1] = 1 and sum[y] = 0. sum[y] – sum[x – 1] = -1

Hence, each subarray sum is either -1, 0 or 1. So, general algorithm looks like: sort points by abscissa, assign them red, blue, red, blue, ... and then sort them back by original order and print the colors.

430B - Balls Game This is an implementation problem. There is not so much to explain. Perhaps the trick at implementation problems is to divide code into smaller subproblems, easy to code and then put them together. I don’t know if this is the universally truth, but this is how I approach them. Here, there are two main parts: the part when you insert a ball between 2 balls and the part when you see how many balls are destroyed after the move. We can keep an array a[] with initial configuration of balls, then for each insertion create an array b[] with current configuration after the insertion. If my ball is inserted after position pos, b is something like this: b = a[1....pos] + {my_ball} + a[pos+1....n].

For now we have array b[] and we need to know how many balls will disappear. The problem statement gives us an important clue: no 3 balls will initially have the same color. This means, any time, at most one contiguous range of balls of same color will exist with length at least 3. If it exists, we have to remove it. Then, we have to repeat this process.

So algorithm is something like bubble sort: while b[] array has changed last step, continue algorithm, otherwise exit it. Now, search an i for which b[i] = b[i + 1] = b[i + 2]. Then, take the maximum j > i for which b[k] = b[i], with i < k <= j. You have to remove from b[] the subarray [i...j] and add j – i + 1 to the destroyed balls. You’ll need to return this sum – 1, because the ball you added wasn’t there at beginning. Pay attention on case when you can’t destroy anything, you need to output 0 instead of -1. There are O(n) positions where you can insert the new ball, for each of them there are maximal O(n) steps when balls are deleted and deleting balls takes maximal O(n) time, so overall complexity is O(n ^ 3).

Note: in my solution, I don’t actually do deletion. If I have to delete a range [i, j] I create a new array c[] = b[1...i – 1] + b[j+1....n] and then copy c[] into b[] array. This guarantees O(n) time for deletion.

429A - Xor-tree There is something to learn from “propagating tree” problem, used in round #225. It’s how the special operation works. I’ll copy paste the explanation from there (with some modification, corresponding to the problem):

Let’s define level of a node the number of edges in the path from root to the node. Root (node 1) is at level 0, sons of root are at level 1, sons of sons of root are at level 2 and so on. Now suppose you want to do a special operation to a node x. What nodes from subtree of x will be flipped? Obviously, x will be first, being located at level L. Sons of x, located at level L + 1 will not be flipped. Sons of sons, located at level L + 2, will be flipped again. So, nodes from subtree of x located at levels L, L + 2, L + 4, ... will be flipped, and nodes located at levels L + 1, L + 3, L + 5 won’t be flipped. Let’s take those values of L modulo 2. All nodes having remainder L modulo 2 will be flipped, and nodes having reminder (L + 1) modulo 2 will not. In other words, for a fixed x, at a level L, let y a node from subtree of x, at level L2. If L and L2 have same parity, y will be flipped, otherwise it won’t. We’ll use this fact later. For now, let’s think what should be our first operation. Let’s consider some nodes {x1, x2, ..., xk} with property that x1 is son of x2, x2 is son of x3, ... xk-1 is son of xk and parity of levels of these nodes is the same. Suppose by now we fixed {x1, x2, ..., xk-1} (their current value is equal to their goal value), but xk is still not fixed. After some time, we’ll have to fix xk. Now, by doing this, all nodes {x1, x2, ..., xk-1} will get flipped and hence unfixed. We’ve done some useless operations, so our used strategy is not the one that gives minimal number of operations.

What we learn from this example? Suppose I want to currently fix a node X. There is no point to fix it now, unless all ancestors Y of X with property level(Y) = level(X) (mod 2) are fixed. But what if an ancestor Y of X is not fixed yet and level(Y) != level(X) (mod 2)? Can I fix node X now? The answer is yes, as future operations done on Y won’t affect X. But, by same logic, I can firstly fix Y and then fix X, because again operations done on Y won’t affect X. We get a nice property: there is no point to make an operation on a node X unless all ancestors of X are fixed.

How can we use this property? What should be the first operation? We know that node 1 is the root, hence it always won’t have any ancestor. All other nodes might have sometimes not fixed ancestors, but we know for sure, for beginning, node 1 won’t have any unfixed ancestor (because it won’t have any). So, for beginning we can start with node 1. More, suppose node 1 is unfixed. The only way to fix it is to make an operation on it. Since it’s unfixed and this is the only way to fix it, you’ll be obligated to do this operation. This means, in an optimal sequence of operations, you’ll be obligated to do this operation, too.

So, if node 1 was unfixed, we did an operation on it. If it was already fixed, we’re done with it. What are next nodes we know for sure that will have all ancestors fixed? Sons of 1, because they have only one ancestor (node 1), which we know it’s fixed. We can only fix them by doing operations of them (doing operations on node 1 / sons of them won’t affect them). Since eventually they have to be fixed and only way to be fixed is to do an operation on them, in an optimal sequence of operations, we’ll have to make operations on them. Let’s move on. What are next nodes that we know for sure all ancestors of them will be fixed? Sons of sons of 1. We can fix them by doing an operation of them, or by doing an operation on 1. But doing an operation on 1 isn’t helpful, because even if it fixes this node, it unfixes 1. Then, you’ll have to do one more operation on 1, which will unfix current node, so we do two useless operations. It turns out, the only way to fix them is to do an operation on them.

Generally, suppose all ancestors of node x are fixed. We get the current value of node x after the operations done on ancestors of x. If the current value is not the expected one, we’ll have to do an operation on node x (this is the only way to fix the node x). Now, after node x is fixed, we can process sons of it. This strategy guarantees minimal number of operations, because we do an operation only when we’re forced to do it.

This leads immediately to an O(N ^ 2) algorithm, by every time we need to do an operation to update it to nodes from its subtree. How to get O(N)? Suppose we are at node x and want to know its current value after operations done for its ancestors. Obviously, it is defined by initial value. If we know number of operations done so far by even levels for its ancestors, number of operations done so far by odd levels and current level, we can determine the current value. Suppose these values are (initial_value, odd_times, even_times, level). We observe that 2 operations cancel each other, so we can take this number modulo 2. If level mod 2 = 0, then only even_times will matter, and current_value = (initial_value + even_times) % 2. Otherwise, current_value = (initial_value + odd_times) % 2.

We can send (even_times, odd_times and level) as DFS parameters, so current_value can be calculated in O(1), and overall complexity is O(N).

429B - Working out The particularity of this problem which makes it different by other problem of this kind is that paths need to cross exactly one cell and Iahub can go only right and down, Iahubina can go only right and up. Let's try to come up with a solution based on these facts. A good start is to analyze configurations possible for meeting cell. Iahub can come either from right or down and Iahubina can come either from right or up. However, if both Iahub and Iahubina come from right, they must have met in other cell as well before (the cell in the left of the meet one). Similarly, if one comes from up and other one from down, their paths will cross either on upper cell, lower cell or right cell.

Only 2 possible cases are: Iahub comes from right, Iahubina comes from up or Iahub comes from down, Iahubina comes from right. By drawing some skatches on paper, you'll see next cell visited after meeting one will have the same direction for both of them. More, they will never meet again. So Iahub comes from right, goes to right, Iahubina comes from up, goes to up or Iahub comes from down, goes to down and Iahubina comes from right, goes to right.

 

In the drawing, Iahub's possible visited cells are blue, Iahubina's possible visited cells are red and meeting cell is purple. Denote (X, Y) meeting cell.

For first case, Iahub comes from (1, 1) to (X, Y — 1) by going down or right. Next, he goes from (X, Y + 1) to (N, M) by going down or right. Iahubina goes from (M, 1) to (X + 1, Y) by going up or right and then from (X — 1, Y) to (1, M) by going with same directions. In second case, Iahub goes from (1, 1) to (X — 1, Y) and then from (X + 1, Y) to (N, M) and Iahubina goes from (M, 1) to (X, Y — 1) and then from (X, Y + 1) to (1, M).

We can precalculate for dynamic programming matrixes and we're done.

dp1[i][j] = maximal cost of a path going from (1, 1) to (i, j) only down and right.

dp2[i][j] = maximal cost of a path from (i, j) to (1, m) going only up and right.

dp3[i][j] = maximal cost of a path from (m, 1) to (i, j) going only up and right.

dp4[i][j] = maximal cost of a path from (i, j) to (n, m) going only down or right.

And here is my full implementation of recurrences (C++ only):

for (int i = 1; i <= n; ++i)     for (int j = 1; j <= m; ++j)         dp1[i][j] = a[i][j] + max(dp1[i - 1][j], dp1[i][j - 1]); for (int j = m; j >= 1; --j)     for (int i = 1; i <= n; ++i)         dp2[i][j] = a[i][j] + max(dp2[i - 1][j], dp2[i][j + 1]); for (int i = n; i >= 1; --i)     for (int j = 1; j <= m; ++j)         dp3[i][j] = a[i][j] + max(dp3[i + 1][j], dp3[i][j - 1]); for (int i = n; i >= 1; --i)     for (int j = m; j >= 1; --j)         dp4[i][j] = a[i][j] + max(dp4[i][j + 1], dp4[i + 1][j]); Also, pay attention that meeting points can be cells (i, j) with 1 < i < n and 1 < j < m. (why?)

429C - Guess the Tree The constrain n <= 24 immediately suggest us an exponential solution. 24 numbers seems to be not too big, but also not too small. What if we can reduce it by half? We can do this, by analyzing problem’s restriction more carefully.

The problem states that each internal node has at least two sons. After drawing some trees likes these, one may notice there are a lot of leafs in them. For a tree with this property, number of leafs is at least (n + 1) / 2. We’ll proof this affirmation by mathematical induction. For n = 1, affirmation is true. Now, suppose our tree has n nodes, and the root of it has sons {s1, s2, ..., sk}. Let’s assume subtree of s1 has n1 nodes, subtree of s2 has n2 nodes, ..., subtree of sk has nk nodes. By induction we get that s1 has at least (n1 + 1) / 2 leafs, ..., sk has at least (nk + 1) / 2 leafs. Summing up, we get that our tree has at least (n1 + n2 + ... + nk + k) / 2 leafs. But n1 + n2 + ... + nk = n – 1. So it has at least (n + k – 1) / 2 leafs. But, by hypothesis k >= 2, so our tree has at least (n + 1) / 2 leafs.

For n = 24, there will be at least 13 leafs, so at most 11 internal nodes. It looks much better now for an exponential solution! Before presenting it, we need one more observation. Suppose we sorted c[] array decreasing. Now, the father of node i can be only one of nodes {1, 2, ..., i – 1}. Nodes {i + 1, i + 2, ..., n} will have at most as much nodes as node i, so they can’t be father of i. By doing this observation we can start algorithm: start with node 1 and assign its sons. Then, move to node 2. If it does not have a father, we won’t have one, so current configuration is good. If he has a father (in this case node 1), then tree is connected so far. So we can assign children of node 2. Generally, if a node i does not have a father when it’s processed, it won’t have in future either. If it has, the tree is connected so far, so we add children of i.

Let’s introduce the following dynamic programming. Let dp[node][mask][leafs] = is it possible to create a tree if all nodes {1, 2, ..., node} have already a father, exactly leafs nodes don’t have one and internal nodes corresponding to 1 in bitmask mask also don’t have one? If you never heart about “bitmask” word, this problem is not good for you to start with. I recommend you problem E from round #191, where I explained more how bitmasks work. Back on the problem. If node has 1 in its bit from the mask, then we know for sure the tree can’t be built. Otherwise, let’s assign sons for node. We take all submasks of mask (number obtained by changing some bits from 1 to 0) and make sum of degrees for corresponding nodes. Denote this number as S. These are the internal nodes. How about the leafs? We need to have available L = c[node] – S – 1 leafs. If L is <= than leafs, we can use them. If L < 0, obviously we can’t build the tree. Will remain obviously leafs – L leafs. The new mask will be mask ^ submask. Also, we need to iterate to node + 1. If dp[node+1][mask ^ submask][leafs – L]. One more condition that needs to be considered: node needs to have at least 2 sons. This means L + cnt > 1 (where cnt are number of internal nodes used). When do we stop the dp? When c[nod] = 1. If mask = 0 and leafs = 0, then we can build the tree. Otherwise, we can’t.

Let’s analyze the complexity. There are O(2 ^ (n / 2)) masks, each of them has O(n) leafs, for each O(n) node. This gives O(2 ^ (n / 2) * n ^ 2) states. Apparently, iterating over all submasks gives O(2 ^ (n / 2)) time for each submask, so overall complexity should be O(4 ^ (n / 2) * n ^ 2). But this complexity is over rated. Taking all submasks for all masks takes O(3 ^ (n / 2)) time, instead of O(4 ^ (n / 2)) time. Why? Consider numbers written in base 3: for a mask and a submask we can assign 3 ternary digits to each bit:

0 if bit does not appear in mask

1 if bit appears in mask but not in submask

2 if bit appears in mask and in submask

Obviously, there are O(3 ^ (n / 2)) numbers like this and the two problems are equivalent, so this step takes O(3 ^ (n / 2)) and overall complexity is O(3 ^ (n / 2) * n ^ 2).

429D - Tricky Function Let’s define S[i] = a[1] + a[2] + ... + a[i]. Then, f(i, j) = (i – j) ^ 2 + (S[i] – S[j]) ^ 2. Trying to minimize this function seems complicated, so we need to manipulate the formula more. We know from the maths that if f(i, j) is minimized, then also f’(i, j) = sqrt ( (i – j) ^ 2 + (S[i] – S[j]) ^ 2) is also minimized. Does this function look familiar to you? Suppose you get two points in 2D plane: one having coordinates (i, S[i]) and the other one having coordinates (j, S[j]). One can see that f’(i, j) is exactly euclidean distance of those points. So, if f’(i, j) is a distance between two points in plane, when is achieved minimal f’(i, j)? For the closest two points in plane (the points which are located at minimal distance). So, having set of points (i, S[i]), we need to compute closest two points from this plane. There is a classical algorithm that does this in O(n * logn).

429E - Points and Segments The problem asks you to check the property for an infinity of points. Obviously, we can’t do that. However, we can observe that some contiguous ranges on OX axis have the same rx and bx values. Like a sweep line algorithm, a possible change may appear only when a new segment begins or when an old one ends. So let’s consider set of points formed by all li reunited with set of points formed by all ri. Sort the values increasing. Suppose the set looks like {x1, x2, ..., xk}. Then ranges [0, x1) [x1, x2) ... [xk-1, xk) [xk, infinity) are the only ones that need to be considered. If we can take an arbitrary point from each range and the property is respected for all points, then the drawing is good.

We need to color segments. But each segment is a reunion of ranges like the ones from above. When you color a segment, all ranges from it will be colored too. So, after coloring the segments, for each range, |number of times range was colored with blue – number of times range was colored with red| <= 1.

It’s time to think creative. We can see ranges as vertexes of a graph and segments as edges. For example, if a segment is formed by ranges {Xi, Xi+1, ..., Xj-1, Xj} we add an undirected edge from i to j + 1. We need to color the edges. We divide the graph into connected components and apply same logic for each component. Next, by graph I’ll refer to a connected graph.

Let’s assume that our graph has all degrees even. Then, it admits an eulerian cycle. Suppose {x1, x2, ..., xk} is the list of nodes from the cycle, such as x1-x2 x2-x3 ... xk-x1 are the edges of it, in this order. We apply a rule: if xi < xi+1, we color edge between xi and xi+1 in red. Otherwise, we color it in blue. What happens for a node? Whenever a “red” edge crosses it (for example edge 1-5 crosses node 4) a “blue” edge will always exist to cross it again (for example edge 6-2 crosses node 4). This is because of property of euler cycle: suppose we started from a node x and gone in “left”. We need to return to it, but the only way to do it is an edge which goes to “right”. So, when degrees of graph are all even, for every point on OX axis, difference between rx and bx will be always 0.

Let’s solve the general case now. Some nodes have odd degree. But there will always be an even number of nodes with odd degrees. Why? Suppose the property is respected for some edges added so far and now we add a new one. There are two cases:

1/ the edge connects two nodes with odd degree. in this case, the number of nodes with odd degrees decreases by 2, but its parity does not change.

2/ the edge connects one node with odd degree and one node with even degree. Now, degree of “old” odd one becomes even and degree of “old” even one becomes odd. So number of nodes with odd degrees does not change.

So suppose the nodes with odd degrees are X1 X2 ... Xk (k is even). Assume X1 < X2 < ... < Xk. If we add one more edge to each of these nodes, an euler cycle would be possible. However, we can’t “add” edges, because edges are segments from the input. But we can imagine them. Of course, this we’ll create an imbalance between red and blue edges, but let’s see how big it is. What if we add a fictive edge between X1 to X2, between X3 to X4, ..., between X(k – 1) to Xk? In this way, all those nodes will have even degree. So for each Xi (i odd) we add a dummy vertex Yi and some dummy edges from Xi to Yi and from Yi to Xi+1. Now let’s see the effect: if the fictive edges existed, the balance would be 0. But they do not exist, so one of rx or bx will decrease. So now |rx – bx| <= 1, good enough for problem’s restrictions.

Codeforces Round #244 (Div. 2) Editorial

By Bidhan, 9 years ago, In English The round statistics are nicely put by DmitriyH.

427A - Police Recruits ( Author : Bidhan ) Maintain a variable, sum. Initially sum=0, it keeps the number of currently free police officers. With every recruitment operation, add the number of officers recruited at that time to sum. When a crime occurs, if sum > 0 then decrease the number of free officers by one, otherwise no officers are free so the crime will go untreated.

Model solution : 6546268

427B - Prison Transfer ( Author : Bidhan ) The severity of crimes form an integer sequence. Find all the contiguous sequences without any integer greater than t. If the length of any sequence is L, then we can choose c prisoners from them in L - c + 1 ways.

Model solution : 6546272

427C - Checkposts ( Author : Bidhan ) Find the strongly connected components of the graph. From each component we need to choose a node with the lowest cost. If there are more than one nodes with lowest cost, then there are more than one way to choose node from this component.

Model solution : 6546275

427D - Match & Catch ( Author : msh_shiplu ) O(n2) dynamic programming solution : Calculate the longest common prefix ( LCP ) for each index of s1 with each index of s2. Then, calculate LCP for each index of s1 with all the other indexes of it's own ( s1 ). Do the same for s2. Now from precalculated values, you can easily check the length of the shortest unique substring starting from any of the indexes of s1 or s2. Suppose i is an index of s1 and j is an index of s2. Find the LCP for i and j. Now, the minimum of the length of LCP, length of shortest unique substring starting from i, length of shortest unique substring starting from j is the answer for i,j. Now we need to find the minimum answer from all possible i,j pair. This problem can also be solved in  by suffix array and in O(n) using suffix automaton.

Model solution : 6546277

427E - Police Patrol ( Author : Bidhan ) Trying to place the police station on existing criminal locations is the best strategy. Calculate the cost from the leftmost criminal location, then sweep over the next locations. By doing some adjustments on the cost of the previous location will yield the cost of the current location.

Model solution : 6546283

Codeforces Round #243 tutorial

By Sereja, 9 years ago, translation, In English 426A - Sereja and Mugs Lets count the sum of all elements Sum and value of the maximal element M. If Sum - M ≤ S then answer is yes, otherwise — no.

426B - Sereja and Mirroring Lets solve problem from another side. We will try to cut of matix as many times as we can. Cut means operation, reversed to operation described in statement. To check, can we cut matrix we need to check following conditions: 1). n mod 2 = 0 2). ai, j = an - i + 1, j for all 1 ≤ i ≤ n, 1 ≤ j ≤ m.

425A - Sereja and Swaps Lets backtrack interval on which will contain maximal sum. To improve our sum we can swap not more then k minimal elements from the interval to k maximal elements that don't belong to interval. As n isn't big we can do it in any way. Author solution sort all elemets from interval in increasing order and all elements that don't belong to interval by descreasing order. We will swap elements one by one while we haven't done k swaps and we have some unswaped elements in first set and we have some unswaped elemets in second set and swap is optimal(we will optimize the answer after this swap). Author solution works in time O(n3·log(n)).

Is there some ideas how to solve this problem in time O(n) or O(n·log(n)) ?

425B - Sereja and Table Note, that if we have two arrays x[1..n], 0 ≤ xi ≤ 1 and y[1..m], 0 ≤ yi ≤ 1, then described matrix can be showed as next one: ai, j = xi xor yj. If n ≤ k, then we can backtrack array x and using greedy find best y. Otherwise there will be atleast one i, such that we will not change any cell in row number i. So we can simply bruteforce some row and use it like x. Then we use greedy and find y. From all possible rows we choose most optimal. Such row will be as number of mistakes is lower then number of rows, so it isn't possible to have atleast one mistake in each row.

Greedy means next algorithm: for every element of y we will look, will it be better to choose it like 0 or 1. To find better choise, we will count number of different bits in x and current(lets it be j) column. If number of different if lower then count of same cells we will set yj = 0, otherwise yj = 1.

425C - Sereja and Two Sequences In thgis problem we will use dynamic programming: dpi, j — minimal pozition of deleted element in second array, such that we have made first operation j times and have deleted not more then i elements from first array.

Lets decided how to calculate transfers. Standing in pozition dpi, j we can change nothing and go to pozition dpi + 1, j, by other words make transfer dpi + 1, j:  = min(dpi + 1, j, dpi, j). What happens when we make first operation with fixed prefix(by i-th element) in first array? We should find element in second array with number greater dpi, j and value equal to ai, lets its pozition is t, so we need to make transfer dpi + 1, j + 1:  = min(dpi + 1, j + 1, t).

How to find required element quickly: lets just do vector of pozition in second array for all different elements that contains in second array. Then we can simply use binary search.

425D - Sereja and Squares Lets line x = k contain not more then  points. Then for each pair of points on this line (lets it be (k, y1) and (k, y2)) check: is there squere that contain them as vertexes. So we should check: is there(in input) pair of points (k - |y2 - y1|, y1) and (k - |y2 - y1|, y2), or pair (k + |y2 - y1|, y1) and (k + |y2 - y1|, y2).

Lets delete all watched points, and reverse points about line x = y. Then each line x = k will contain not more then  points. Will solve problem in the same way.

Now we should learn: how to check is some pair of points(on one vertical line) in input. Lets write all of this pairs in vectors. Each vector(for every line) will contain pairs that we should check on it. Suppose, that we check it for line number k. Lets mark in some array u for all points with x-coordinate equal to k uy = k. Now to check is our pair with y-coordinates (y1, y2) on line we can simply check following condition: uy1 = uy2 = k.

425E - Sereja and Sets First, lets look at F(S). First, we sort all intervals by second coordinte and then go by them in sorted order. And if current interval don't intersected with last taken to the optimal set, we get our current to the set.

Our solution will be based on this greedy. Solution of the problem is next dynamic: 1). number of position of second coordinte of interval 2). number of intervals in good set 3). second coordinate of last taken interval to the optimal set

How should we make transfers? Lets note that when we know dpi, count, last we can change last by i, or not change at all. Lets look what happens in every case. In first case last is changed by i, so we should take to optimal set atleast one of the inervals: [last + 1, i], [last + 2, i], ..., [i, i], number of such intervals i - last, number of ways to get at least one of them is 2i - last - 1. All other intervals: [1, i], [2, i], ..., [last, i] we could get as we wish, so we have 2last ways. So total number of transfers from dpi, count, last to dpi + 1, count + 1, i is (2i - last - 1)·(2last). If we count number of transfers from dpi, count, last to dpi + 1, count, last, we can simply use number 2last(as described early).

Also we shouldn't forget about trivial case dpi, 0, 0.

So now we have quite easy solution.

Codeforces Round #242 (Div. 2) Editorial

By pkhaustov, 9 years ago, In English 424A - Squats

The problem is to find the number of standing hamsters. If it is less than half, we should make the required number of hamsters standing. Otherwise we should make some hamsters sitting.

424B - Megacity

We can sort all the cities by their distance to the Tomsk city di. After that we are to find the smallest index t for which the total population p0 + p1 + ... + pt >  = 106. In such case the answer is dt. We can sort all cities in O(NlogN) and find the value of t in O(N). Limits for N allow O(N2) sorting or any other O(N2) solution.

424C - Magic Formulas

Consider the following formulas:



Let . Lets compute the following function for each i (0 ≤ i ≤ n). One can do it in O(n) using .

Lets transform ci:

 Also:

 Thus:

 That means, if n / i is odd, , otherwise — . ci can be computed in O(1), that's why the complexity of the whole solution — O(n).

424D - Biathlon Track

Due to the time limit for Java some of O(N4) solution got Accepted. The authors solution has complexity O(N3·logN). The main idea is to fix the top-border and bottom-border. Then, using some abstract data type, for each right-border we can find the most suitable left-border in O(logN) time. For example we can use set in C++ and its method lower_bound. For better understanding lets have a look at the following figure:

 

For such rectangle we fix the upper-border as row number 2 and bottom-border as row number 5. Also, we fix right-border as column number 6, and now we are to find some left-border. Now we can split the time value for any rectangle for two summands. One of them depends only on left-border and another one — on the right-border.

 

With the blue color the summand that depends only on the right-border is highlighted. With the red and yellow color — the other summand is highlighted. The red-colored value should be subtracted and the yellow-colored should be added. For any blue right-border's value we are to find the closest red-yellow left-border. That is the problem to be solved with the help of STL Set or any other similar abstract data type.

424E - Colored Jenga

A classical DP-problem on finding expected number.

Lets define some function F(S) for some state — the expected number of minutes to finish the game from this state. For each color we can compute the probability of showing this color by the simple formula , where c — the number of dice's faces of this color. Now we are to find the probability PL to stay in this state for the next minutes. That is the probabilty of showing black color plus the probabilities of showing colors with no blocks of that color to be removed from the tower. Now we can find the value via the following formula:

 The only problem is to find how to encode the state. To reduce the number of states we can assume that there is only 18 different type of levels, but not 27. For better time-performance it is better to use hashing. The solution for this problem requires good understanding of DP and quite good implementing skills.

Codeforces Round #241 — editorial

By marat.snowbear, 9 years ago, translation, In English 416A - Guess a number! Let's use the usual Div 2 problem A approach — the naive one. We will track the interval which might contain the number we're guessing. With each of the query we update this interval. If at the end the interval is non-empty then we output any number from it, otherwise the result is "Impossible".

Submission: 6606892

416B - Art Union All we need is to iterate over all painters and for each painter to iterate over all pictures. In the inner loop we also remember when the painter finished working on the picture to make sure that the next painter will not start working on it earlier.

Submission: 6606994

416C - Booking System Let's solve this one greedy. All we need to notice is that the optimal solution will be to place first the groups with biggest sum which they are ready to pay. For each such group it will be optimal to allocate the smallest matching table. The input limits allow to do a full search when looking for a table.

Submission: 6617198

416D - Population Size One thing to notice for this problem is that if we cover some interval with a progression then it will better (at least no worse) to include as many elements to the right of it as possible. So the solution is to greedy — find the leftmost number not covered by a progression, start a new progression with that number (the interval covered by that progression will be of size 1) and then try to extend this interval to the right as far as possible. Repeat this step until all the numbers are covered. One thing you should pay attention to is which numbers can be covered by one arithmetic progression, for example:

If there are no fixed numbers in the interval then we can cover it with one progression.

If there is only one non-fixed number in the interval then we can cover this interval with one progression.

If there are more than one non-fixed numbers in the interval then we can calculate the parameters of the progression (start value and difference). All non-fixed numbers should match those parameters. Difference should be integer.

If the progression is ascending and there are some non-fixed numbers in the beginning then those numbers should match positive numbers in the progression.

Same way if the progression is descending then we can include numbers from the right side only while matching progression term is positive.

Submission: 6607174

416E - President's Path Let's look at the graph given to us in the example:

 

We need to count the count of the edges on all the shortest paths between each pair of vertices. Let's do something easier first — instead of counting all the edges we will count only those which have the destination vertex on its side. For example here are the edges belonging to shortest paths from 4 to 2 which are connected to vertex 2:

 

Let's denote this number like this: inEdgessource, v — number of edges which go into vertex v on some shortest path from source to v. In the given example inEdges4, 2 = 3. Let's also denote the set Ssource, dest — it is a set of the vertices which belong to at least one shortest path from source to dest. For example S4, 2 = {1, 2, 3, 4}. With these two variables it can be seen that the answer for vertices source and dest will be:



In other words the answer for vertices s and d will be equal to the sum of inEdgess, v for all vertices v, which belong to any shortest path from s to d. So the only thing left is to calculate these S and inEdges. Both of them can be easily calculated if you have minimum distances between all pairs of vertices. And these distances can be calculated using the Floyd-Warshall. So the full solution is:

Calculate minimum distances between all pairs of vertices using Floyd-Warshall algorithm.

Count inEdges. Simply iterate over all source vertices and all edges. For each edge check whether any of its ends belong to any shortest path from source.

Calculate the answer. Let's have three loops to iterate over the vertices — — source, destination и mid. First two vertices are those for which we're calculating the answer. Third vertex is the vertex which should belong to any shortest path (basically we're checking whether v belongs to Ssource, dest). If mid belongs to any shortest path from source to dest then we add inEdgessource, mid to the answer.

Each step has a complexity O(n3).

Submission: 6607257

P.S.: Please feel free to let me know about any typos, errors, etc using the private messages.

Codeforces Round #240 Editorial

By matrix, 9 years ago, In English Hi!

415A - Mashmokh and Lights

For this problem for each light j you could just iterate over all pressed buttons and find the first button bi that bi < j. Then you could output bi and move to next light.  

415B - Mashmokh and Tokens

For this problem you can find the number of tokens you can save if you initally have k tokens in O(1). Then you can calculate the answer for all of numbers in O(n).

Suppose  by p. then p * b ≤ w * a. then .

Suppose initially we have k tokens. Let  then we need to find such maximum k0 that .

So k0 will be equal to . so we can calculate k0 in O(1).

414A - Mashmokh and Numbers

In each turn Bimokh will at least get one point so the result is at lease . So if  the answer is -1.

Let's denote . Then you could output x and 2x as the first two integers in the sequence then output  consecutive integers and also one random integer(distinct from the others) if n is odd. Based on the following fact, Bimokh's point will equal to  which is equal to k.

.

Also you must consider some corner cases such as when n = 1.

414B - Mashmokh and ACM

Lets define dp[i][j] as number of good sequences of length i that ends in j.

Let's denote divisors of j by x1, x2, ..., xl. Then 

This yields O(nk sqrt(n)) solution which is not fast enough. But one could use the fact that the following loops run in O(n log(n)) in order to achieve O(nk log(n)) which is fast enough to pass the tests.

for (i = 1; i <= n; i++)  //loop from 1 to n    for (int j = i; j <= n; j += i)  //iterating through all multiples of i that are at most n 414C - Mashmokh and Reverse Operation

Build a complete binary tree with height n. So its i-th leaf corresponds to i-th element of the initial array. For each vertex v lets define its subarray as the subarray containing the elements that have a leaf corresponding to them in subtree rooted at v.

For each non-leaf vertex v, suppose its left child's subarray contains elements [a..b] of the array and its right child contains elements [b + 1..c] of the array. We'll calculate two numbers for this vertex. number of pairs (i, j)(a ≤ i ≤ b ≤ j ≤ c) that ai > bj and number of pairs (i, j)(a ≤ i ≤ b ≤ j ≤ c) that ai < bj. We'll call the first calculated number, normal number and the other one reverse number. Calculating these numbers can be done using merge-sort algorithm in O(n  *  2n). We'll

Initially write normal number for each vertex on it. We'll define a vertex's type as type of the number that is written on them. Let's define height of a vertex v equal to its distnace to the nearest leaf. Also let's define switching a vertex as switching the number written on it with the other type number(if normal number is written on it change it to reverse number and vise-versa).

Initially sum of writed numbers is equal to number of inversions in the initial array. Now when query h is given, by switching all vertices with height at most h, the sum of writed numbers will become equal to the number of inversions in the new array. The only question is how to perform such query fast? One can notice that in a height h, always all of the vertices has the same type. So we can calculate two numbers for each height h. The sum of normal numbers of vertices with height h and the sum of their reverse numbers. Then instead of switching vertices in a height one by one each time, one can just switch the number for that height. The sum of numbers of heights after each query will be the answer for that query. since there are n height each query can be performed in O(n) so the total running time will be O(nq  +  n  * 2n).

414D - Mashmokh and Water Tanks

Let's suppose instead of a tank there is a pile at each vertex and instead of water the game is played on tiles.

Let's denote distance of each vertex q from the root by depth(q). Also Let's label each tile with number of the vertex it was initially put on. Suppose initially there was a tile at each of vertices v and u and after some move tile u and v are in the same vertex's pile. Then one can prove that there were exactly |depth(v) - depth(u)| moves at which vertex containing the tile at vertex with less depth was closed and the vertex containing the other tile wasn't.

Suppose after i-th move, there was xi tiles inside the root's pile and xj is the maximum among these numbers. Suppose tiles a1, a2, ...axj were on the root after j-th move. Then the other tiles that we put inside the tree at the beginning have no effect in the final result. Then we can suppose that only these tiles were initially put on tree.

So we can assume that all tiles we place at the beginning will reach to the root together. Suppose hi of these tiles were put at a vertex with depth i and d1 is the maximum depth that there is at least a tile in that depth. So as to these tiles reach to the root together we must pay . Then we want to minimize the number of needed coins so at the beginning there must not be two consecutive depth i and i + 1 that i + 1 ≤ d and there is a tile at depth i and an empty vertex at depth i + 1. In other words if we denote the minimum depth that initially there is a tile inside it as d0 then there must be a tile at each vertex with depth more than d0 and less than or equal to d1.

Let's iterate over d1. Then for each d1 we can calculate d2, the minimum depth that we can pay the needed price if we put a tile at each vertex with depth at least d2 and at most d1. Let's denote this needed price as p0. Then we can also put  at depth d2 - 1. So we can calculate maximum number of tiles that we can put on the tree so that they all reach to root together for a fixed d1. So the maximum of these numbers for all possible d1 will be the answer.

Since by increasing d1, d2 won't decrease one can use two-pointers to update d2 while iterating over d1. Let's denote number of the vertices with depth i as cnti. Then we can save and update the following values.





Then the needed price is equal to (d1 * s) - t. So as long as (d1 * s) - t > p we must increase d2. This yields an O(n) solution.

414E - Mashmokh's Designed Problem

Let's define the dfs-order of a tree as the sequence created by calling function dfs(root). We'll build another sequence from a dfs-order by replacing each vertex in dfs-order by '+1' and inserting a '-1' after the last vertex of its subtree. Note that all vertices of a particular subtree are a continuous part of dfs-order of that tree. Also note that for each vertex v if the +1 corresponding to it is the i-th element of sequence, then v's distance from root(which we'll denote by height of v) is equal to sum of elements 1..i.

Suppose we can perform the following operations on such sequence:

For each i, find sum of the elements 1..i.

For each i find the biggest j(j < i) so that sum of elements 1..j of the sequence equals p.

Using these two operations we can find LCA of two vertices v and u, so since distance of u and v equals to height(u) + height(v) - 2 * height(LCA(u, v)) we can answer the second query. Also the third query can be answered using the second operation described above.

As for the first query it cuts a continuous part of sequence and insert it in another place. This operation can be done using implicit treap. Also we can use the treap as a segment tree to store the following values for each vertex v. Then using these values the operations described above can be done. All of these operation can be done in O(logn).

Sum of the elements in its subtree(each vertex in the treap has a value equal to +1 or -1 since it corresponds to an element of the sequence.)

Let's write the values of each vertex in the subtree of v in the order they appear in the sequence. Then lets denote sum of the first i numbers we wrote as ps[i] and call elements of ps, prefix sums of the subtree of v. Then we store the maximum number amongst the prefix sums.

Also we'll store the minimum number amongst prefix sums.

Codeforces Round #239 Editorial

By izban, 9 years ago, translation, In English Sorry for my poor English. If you find a mistake, write me a private message, I'll fix it. Some problems have not been translated yet, now you can try to read the Russian version of editorial with Google Translate.

408A - Line to Cashier

In this problem you were to find waiting the time for every queue by summing up the purchases of all the people, and return the minimum.

408B - Garland

In this problem it is necessary to find the garland with the maximal length, which can be composed of elements that we have. First, if you need some color, but you don't have it, then the answer is -1 Otherwise, answer is always exists. Let's sum the answers for all the colors separately. Suppose we have a pieces of a garland of some color, and we need b pieces. Then we have to add min(a, b) to the answer: if a >  = b we will use b 1 meter pieces, in the other case if a < b we will use all a pieces.

407A - Triangle

In this problem you have to locate the right triangle with cathetuses a, b on a plane with its vertices in integer points. If the required layout exists, then cathetus a always can be represented as a vector with integer coordinates A{x;y}, and a2 = x2 + y2. Iterate over all possible x (1 ≤ x ≤ a - 1), check, that y = sqrt(a2 - x2) is integer. Vector, ortogonal to vector {x;y}, is { - y;x}. Take vector B{ - y / g;x / g}, where g = gcd(x, y). The triangle can be located on the plane if and only if b % |B| = 0, where |B| — length of vector B. The candidate for the answer — triangle (0;0)(x;y)( - y / g * b / |B|;x / g * b / |B|), but don't forget about checking that the hypotenuse isn't parallel to coordinate axes.

407B - Long Path

In this problem you had to simulate route of character in graph. Note that if you are in vertice i, then edges in all vertices with numbers less than i are turned to pi. It gives us opportunity to see a recurrence formula: let dpi be number of steps, needed to get from vertice 1 to vertice i, if all edges are rotated back, into pi. Then dpi + 1 = 2dpi + 2 - dppi. Answer will be dpn + 1.

BONUS: Can you solve this task without statement pi ≤ i? I don't know the solution, it seems difficult.

407C - Curious Array

In this problem you had to find how to add binomial coefficients in array offline. Let's see, how problem changes due to increasing k from small to big values.

1) All queries have K = 0 Every time you add 1 on subsegment. For solve this task you can add 1 at some array b[] in b[L] 1, then substract 1 from b[R+1], and after doing all queries make array a[] as array of prefix sums of array b[].

2) All queries have K = 1 Arithmetic progression 1 2 3 4 ... is added on subsegment For solve this task you can add 1 at some array c[] in c[L] 1, then substract 1 from c[R+1], and after doing all queries make array b[] as array of prefix sums of array c[]. Actually you added 1 1 ... 1 on every subsegment at each query. If you will substract (R — L + 1) from c[R+1], and make array a[] as array of prefix sums of array b[], then it will be an answer: 1 1 ... 1 became 1 2 3 ... (R-L+1).

3) K is arbitrary Summaring previous results one can see that if we will do

a[K+1][L] += 1 a[j][R+1] -= C(k + 1 — j + r — l, k + 1 — j) for all 1 <= j <= K + 1 and after that do a[i][j] = a[i][j-1] + a[i+1][j] (making a[i] as array of prefix sums array a[i+1]), a[0] will be the answer. What is C(k + 1 — j + r — l, k + 1 — j)? This number is need for each query affect only on segment L..R, and you can see, why is it so, in Pascal's Triangle.

If this explanation is not clear for you, you can try to see other participants solutions (for example, Xellos's one).

407D - Largest Submatrix 3

In this task you have to find largest by area submatrix, consisting from different numbers. Let's see solutions from slow to fast.

1) Solution by O(n6): Iterate through two opposite vertices submatrix-answer and check that all numbers are different.

2) Solution by O(n4): Let's fix Up and Down borders submatrix-answer (O(n2)). Use two pointers method to iterate Left and Right borders: while in submatrix there are no equal numbers, increment Right, while there are equal numbers — increment Left. Every check — (O(n)), increments — (O(n)).

3) Solution by O(n3logn): Let's construct function maxR(Left) (let's consider that Up <= Down are fixed): maximal value Right, so that in submatrix (Up, Down, Left, Right) there is no equals numbers. You can see that maxR(i) <= maxR(i + 1) is true for every i. How values of this function changes by shift Down to Down-1? Every value maxR(Left) can only be the same (if segment(Down, Down, Left, maxR(Left)) only added new numbers), or it can decrease. When maxR(Left) is decreasing? Only when one of the numbers from added segment have already been in the current submatrix. Shift Down to down let's see all numbers in row Down. For each number (let it be in column j) find indices i and k so i <= j, there is number, equal to a[Down][j] between rows Up and Down-1, i — maximal; k >= j, there is number, equal to a[Down][j] between rows Up and Down-1, k — minimal. When you find these indices (it is easy to find them using set, when you store all columns where number x was between Up and Down for all numbers x), you can try to update maxR[i] with j — 1, maxR[j] with k — 1. It will be enough, if you also update for all i = m..1 maxR[i] = min(maxR[i], maxR[i + 1]). Now maxR(Left) is correct, and you can check answer for these Up and Down by O(n).

4) Now, solution by O(n3). It requires understanding previous solution. Previous solution, despite good asymptotics, requires to store a lot (about 160 000) sets, where you will store about 160 000 elements. Even at n = 200 it works very slow. Let's get rid of log. Set is using only for finding nearest left and right elements, which are in rows from Up to Down, and equal to current. Note that when you do Up = Up — 1, nearest element comes near (by column) to a[i][j], so we can find all numbers, for which the nearest element will be in new row Up, and update them nearest number, and do that in O(n2). This solution uses O(n2) memory and O(n3) time.

BONUS: Can you solve this task faster than O(n3)? I spend a lot of time and I didn't come to any solution, but I can't show that there is not solution faster.

407E - k-d-sequence

In this problem you have to find longest subsegment, satisfying the condition.

Reduce problem to d = 1.

If d = 0, then answer is longest subsegment from equal numbers, this case we solve separately.

If d ≠ 0, then notice that if on some subsegment there are two numbers ai, aj so that ai%d ≠ aj%d, then this segment can't be good. Divide the sequence to consequent subsegments numbers, equal by modulo d, and divide each number by d, and solve task separately with every segment, consider that d = 1.

Notice that segment [L, R] is good if and only if when max(L, R) — min(L, R) — (R — L) <= k, and there are no equal numbers. It is easy to exlain: if there are no equal numbers, then max(L, R) — min(L, R) — (R — L) is exactly number of numbers is needed to add for segment to consist of all numbers from min(L, R) to max(L, R).

For all L lets find such maxR[L], that on segment [L..maxR[l]] there are no equal numbers, and maxR[L] is maximal. It can be done by O(nlogn) by many ways, for example you can use map.

Let's learn how we can maintain array a[R] = max(L, R) — min(L, R) — (R — L). If we have such array, then we have to find rightmost R such that a[R] <= k to get an answer.

We will need two stacks and segment tree with operations "Add number on segment", "Find min element on segment", "Find rightmost number doesn't exceed k". Let's iterate L from right to left (n downto 1). How does function max(L, R) look like with fixed L? It's values represent a set of segments so that maximum on the segment is leftmost element of segment, and these maximums are increasing. (example: for array 6 4 8 0 7 9 function max(1, R) will be 6 6 8 8 8 9). How function changes with shift L to left? Some segments are absorbed by new element, if new element is bigger than maximum on segment. Maximums on segments are increasing, so we can keep them all in stack, and when we need to add new element we have to only pop some segments from stacks while maximum on top of stack is less then new element, and push new segment after that. If every operation with stack will be accompanied with right operation with segment tree, we can store array a[R] = max(L, R). For get array a[R] = max(L, R) — min(L, R) we need only to maintain second similar stack. For get array a[R] = max(L, R) — min(L, R) we need add -1 on all suffix when we are shitfing L.

Now query "Find fightmost number less of equal k". First, segment tree divides segment of request to log(n) segments with length powers of two. Let's choose rightmost segment with minimum <= k, and do iterative deeping there to find element that we need.

So, for every L we get query on segment L..maxR(L) on rightmost number less or equal k. It is one of candidates to an answer. We are doing O(n) operation with stack, and every requires query to segment tree, so asymptotics is O(nlogn).

Codeforces Round #238 Tutorial

By gen, 9 years ago, In English 405A - Gravity Flip Observe that in the final configuration the heights of the columns are in non-decreasing order. Also, the number of columns of each height remains the same. This means that the answer to the problem is the sorted sequence of the given column heights.

Solution complexity: O(n), since we can sort by counting.

405B - Domino Effect If the first pushed domino from the left was pushed to the left at position l, all dominoes at prefix [1;l] fall down, otherwise let l be 0. Similarly, if the first pushed domino from the right was pushed to the right at position r, all dominoes at suffix [r;n] also fall down, otherwise let r be n + 1. Now, in the segment (l;r) there will remain vertical dominoes and blocks of dominoes supported by the equal forces from both sides.

When does a domino at position p in segment (l, r) remains standing vertically? One way is that it is not pushed by any other domino. This could be easily checked by looking at the pushed dominoes closest to p (from both sides). It is pushed by dominoes, only if the closest from the left was pushed to the right, and the closest from the right was pushed to the left. Suppose these dominoes are at positions x and y, x < p < y. Then, the only way that the domino is still standing is if it is positioned at the center of the block [x;y], which could be checked by .

Solution complexity: O(n) / O(n2), depends on implementation.

406A - Unusual Product Written as a formula, the problem asks to find the value of

 Suppose that i ≠ j. Then the sum contains summands AijAji and AjiAij. Since the sum is taken modulo 2, these summands together give 0 to the sum. It follows that the expression is always equal to the sum of the diagonal bits:

 Now, each query of type 1 and 2 flips the value of exactly one bit on the diagonal. Thus we can calculate the unusual product of the original matrix, and flip its value after each query of type 1 and 2.

Solution complexity: O(n + q), if we don't take the reading of the input into account... :)

406B - Toy Sum Let's define the symmetric number of k to be s + 1 - k. Since in this case s is an even number, k ≠ s - k.

Note that (k - 1) + (s + 1 - k) = s, i.e., the sum of a number and its symmetric is always s. Let's process the given members x of X. There can be two cases:

If the symmetric of x does not belong to X, we add it to Y. Both give equal values to the respective sums: x - 1 = s - (s + 1 - x). The symmetric of x belongs to X. Then we pick any y that neither y and symmetric of y belong to X, and add them to Y. Both pairs give equal values to the respective sums, namely s. How to prove that in the second step we can always find such y? Let the number of symmetric pairs that were processed in the step 1 be a, then there remain  other pairs. Among them, for  pairs both members belong to X, and for other  pairs none of the members belong to X. To be able to pick the same number of pairs for Y, as there are in X, we should have

 which is equivalent to , as given in the statement.

Solution complexity: O(s) / O(n).

406C - Graph Cutting It can be proved that only graphs with an odd number of edges cannot be partitioned into path of length 2. We will construct a recursive function that solves the problem and also serves as a proof for this statement.

The function partition(v) will operate on non-blocked edges. It will partition the component of vertex v connected by the non-blocked edges into paths of length 2. If this component has an odd number of edges, the function will partition all the edges of the component, except one edge (u, v); the function then will return vertex u, expecting that the parent function call will assign it to some path.

The function works as follows: find all vertices that are adjacent to v by the non-blocked edges, call this set adjacent. Then block all the edges from this set vertices to v. For each u in adjacent, call partition(u). Suppose partition(u) returned a vertex w. That means we can pair it into the path (v, u, w). Otherwise, if partition(u) does not return anything, we add u to unpaired, since the edge (v, u) is not yet in any path. We can pair any two vertices of this set u, w into a single path (u, v, w). We pair as much of them as possible in any order. If from this set a single vertex, u, is left unpaired, the function will return u. Otherwise the function will not return anything.

The function could be implemented as a single DFS:

partition(v) :     adjacent = { u | not blocked[(u,v)] }     for(u : adjacent)         blocked[(u,v)] = true

    unpaired = {}     for(u : adjacent)         int w = partition(u)         if(w = 0)             add(unpaired, u)         else             print(v,u,w)

    while(size(unpaired) >= 2)         int u = pop(unpaired)         int w = pop(unpaired)         print(u,v,w)

    if(not empty(unpaired))         return pop(unpaired)     else         return 0 Solution complexity: O(n + m).

406D - Hill Climbing Note that the path of each hill climber is strictly convex in any case. Let's draw the paths from all hills to the rightmost hill. Then these paths form a tree with the "root" at the top of the rightmost hill. We can apply the Graham scan from the right to the left to find the edges of this tree. Each pop and insert in the stack corresponds to a single edge in the tree.

 

Now it is easy to see that for each team of climbers, we should calculate the number of the lowest common ancestor for the corresponding two vertices in the tree. The size if the tree is n, so each query works in .

Solution complexity: .

406E - Hamming Triples Let's look at the Hamming graph of all possible distinct 2n strings, where each two strings are connected by an edge with length equal to the Hamming distance between these strings. We can observe that this graph has a nice property: if we arrange the vertices cyclically as a regular 2n-gon with a side length of 1, then the Hamming distance between two strings is the length of the shortest route between these vertices on the perimeter of the polygon.

For example, the figure shows the graph for n = 3. The gray edges have length 1, the orange edges have length 2 and the blue edges have length 3. That is the corresponding Hamming distance.

 

Now, we can convert each string coded by a pair (s, f) to an integer (f + 1)·n - s. The new numbers will be 0, 1, ..., 2n - 1 and correspond to the same cyclical order on the perimeter of the polygon. The given strings are mapped to some subset of the vertices. Now we have to find the number of triangles (possibly degenerate) with maximal perimeter in this subgraph. It will be useful to keep the new converted numbers sorted.

First, we can figure out what this perimeter could be. If there exists a diameter in the full graph, so that all of the points are on one side of the diameter, the perimeter is 2d, where d is the length of the longest edge:

 

Then any triangle with two vertices at the longest edge points and the third one being any point has the maximal perimeter. Since the numbers are sorted, the longest edge in this case will be produced by two cyclically adjacent elements, which is not hard to find.

If for any diameter this does not hold, then the maximal perimeter is 2n. This can be proved by taking two different points a, b and drawing two diameters with them as endpoints; since it is not the previous case, there shoud be a third point c in area where the perimeter of triangle a, b, c is 2n.

The tricky part is to count the triples in this case. We do this by working with the diameter (0, n). There can be several cases:

A maximum triangle has vertices 0 and n. This a simple case: with any other vertex as the third the triangle has perimeter 2n. A maximum triangle has vertex 0, but not n. Then the second vertex should be in interval [0, n), and the third in interval (n + 1, 2n - 1], and the clockwise distance between the second and the third should not exceed n (since then the perimeter of the triangle would be less than 2n). We count the number of such triples iterating two pointers (one in each of these intervals). For each pointer in the first interval, all points from n + 1 till the second pointer will make a maximal perimeter triangle. We similarly solve the case where the maximal triangle has vertex n, but not 0. The maximal triangle does not have 0 or n as its vertices. Then one vertex of the triangle should be on one side of diameter (0, n), and two should be on the opposite side. To count them, we iterate a vertex pointer on the first side, say, (0, n); let the diametrally opposite vertex on the opposite side be x. Then the second vertex can be any in [n + 1, s], and the third can be any of the [s, 2n - 1]. It is easy to calculate these numbers using partial sums on the circle. Note that s can be both the second and the third vertex (since strings can repeat). So we iterate this pointer over all one side vertices and update the answer. Similarly we solve the case where a single vertex is on the other side, and two on this side. One only needs to be careful with the formulas in each case.

Solution complexity: , because of the sorting.

Post Scriptum What were your solutions? Feel free to share any solutions or thoughts! For example, was there a solution to DivI E simpler than in this tutorial?

Codeforces Round #237 (Div. 2) Editorial

By Igor_Kudryashov, 9 years ago, translation, In English 404A - Valera and X

In this problem it was needed to check the constraints described in statement. You can use two sets here. You should insert diagonal elements of matrix into the first set, and the other elements into the second. Element ai, j belongs to the main diagonal if i = j and belongs to the secondary diagonal if i = n - j + 1. After you split all elements into sets you should check if the sets sizes are equal to one and the elements from this sets differ from each other.

404B - Marathon

Let's notice that after Valera run 4·a meters he will be in the same point from which he started. Valera will have run i·d meters before he gets i-th bottle of drink. Let's calculate the value  — how many laps he will run. Then he have already run L = i·d - c·4·a meters on his last lap. It is easy to get Valera's position from this L. For example, if 2·a ≤ L ≤ 3·a then Valera will be in the point with coordinates (3·a - L, a). You can consider the other three cases in the same manner.

404C - Restore Graph

First of all let us notice that it must be only one 0 in d. Also d[start] = 0 means that start is the vertex from which Valera calculated the distance to the other vertices. Let's notice that every vertex u with d[u] = i must be adjacent only to the vertices v such that d[v] ≥ i - 1. Besides there is always must be such neighboor v0 of u, that d[v0] = i - 1. Let's build sought graph by adding one vertex to the existing graph. We will add vertex in order of increasing their distance to start. Initially, we have one vertex with number start in our graph. When we add vertex u with d[u] = i let's consider such vertices v that d[v] = i - 1. Let's choose the vertex with minimal degree among them. If this value is equal to k, then there is no solution. In other case let's add u to our graph and add the edge (u, v) to the answer. If there are no vertices with distance i - 1 to start then the answer is also  - 1. If everything fine we will get the answer which is tree, so the number of edges in it equals n - 1 ≤ 106.

404D - Minesweeper 1D

This problem can be solved by using dynamic programming. Let's calculate d[i][type] — the number of correct ways to fill the prefix of length i so that the last filled cell has one of the 5 types. These types are the following:

the cell contains "0"

the cell contains "1" and the cell to the left of it contains bomb

the cell contains "1" and the cell to the left of it doesn't contain bomb

the cell contains "2"

the cell contains bomb

When we try to fill next cell we check two conditions. Firstly value of the filled cell in given string must be equal to either what we want to write or "?". Secondly new prefix must remain filled correct. For example, if we are in state (i, 1) (it means that the cell i contains "0") then we can fill next cell by "0" and go to the state (i + 1, 1) or fill next cell by "1" and go to the state (i + 1, 3). We cannot write "2" because both neighbours of the cell with "2" must contain bomb. Obvious, we cannot place bomb after "0". Note that, when we place "1" after "0" we go to the state (i + 1, 3), but when we place "1" after bomb we go to the state (i + 1, 2). You can consider other ways of going from one state to another in the same manner.

404E - Maze 1D

Let's consider the case when the last move of the robot is equal to "R". If the last move is equal to "L" then we can replace all "L" by "R" and vise versa and the answer doesn't change. Let's show that Valera doesn't need more than one obstacle. Suppose Valera placed obstacles somewhere. We will say that the number of obstacle is the number of cell containing it. Let's consider the rightmost obstacle obs1 among the obstacles with negative numbers and the leftmost obstacle obs2 among the obstacles with positive numbers. Obvious robot cannot go to the left of obs1 and to the right of obs2. So the needed number of obstacles is not greater than two. Let's show that Valera doesn't need to place obstacles to the cells with numbers greater than zero. Suppose he place obstacle to the cell with number a > 0. If robot doesn't try to go to this cell then its obstacle is out of place. If robot try to go to this cell then it will visit finish cell more than once. It is because robot needs to go to the right on its last move, but it can't do it from cell a - 1 and it has already visited all cells to the left of a. So Valera doesn't need more than one obstacle and its obstacle must have number less than zero.

Let's now check if Valera can do without obstacles. If so the robot won't skip moves and will stop in some cell. Than Valera can choose this cell as finish and the answer will be one. We have to consider only one case when Valera must place one obstacle.

Firstly let's notice that if Valera place obstacle to some cell, the finish cell can be restored uniquely. It means that the number of ways to choose where to place obstacles and finish cell is equal to the number of ways to choose one cell to place one obstacle. Suppose Valera placed obstacle in the cell with number b < 0 and robot completed its instructions successfully. Notice, that in that case robot skipped some moves of type "L", completed all moves of type "R" and went to the right on its last move to the unvisited cell. If we shift Valera's obstacle to the right on one cell then robot is going to skip not less moves of type "L" than in the previous case. It means that the finish cell can either go to the right or remains the same. But last time robot visited this cell on its last move, so it is going to visit a new finish cell on its last move either. This means that there is such cell p < 0 that if Valera place obstacle to the cells c ≥ p then robot will be able to complete its instructions successfully, but if Valera place obstacle to the cells d < p then robot will not. This cell p can be found by using binary search and simple simulation on each iteration. Time complexity is O(n log n).

Editorial Codeforces Round #236

By gridnevvvit, 9 years ago, translation, In English 402A - Nuts Let's fix some value of boxes ans. After that we can get exactly cnt = ans + min((k - 1) * ans, B) of sections. So, if cnt * v ≥ a, then ans be an answer. After that you can use brute force to find smallest possible value of ans.

402B - Trees in a Row Let's fix height of the first tree: let's call it a. Of course, a is an integer from segment [1, 1000]. After that, for the fixed height a of the first tree we can calculate heights of the others trees: a, a + k, a + 2k, and so on. After that you should find minimal number of operations ans to achive such heights. After that we can use brute force to find smallest possible ans for each a from 1 to 1000. For best height of the first tree you should print all operations.

402C - Searching for Graph / 403A - Searching for Graph I will describe two solutions.

First. Consider all pairs (i, j) (1 ≤ i < j ≤ n). After you should ouput the first 2n + p pairs in lexicographical order.

It's clear to understand, that it is enough to prove, that 0-interesting graph is correct or  - 3 -interesting graph is correct. We will prove for  - 3 -interesting graph, that it is correct. This graph consists of triangles, which have an common edge 1 — 2. Let's fix some subset of vertexes, which does not contains vertexes 1 and 2. In such sets there are no edges. Let's fix some subset, which contains exactly one vertex (1 or 2). In such subsets there are exactly k - 1 edges, where k is the size of such subset. In other subset there are exactly 2 * (k — 2) + 1 edges, where k is the size of such subset.

Second. Let's use some brute force, to build graphs with 0-interesting graphs with sizes 5, 6, 7, 8, 9 vertexes. Now, to build p-interesting graph with n vertexes, We will build 0-interesting graph, and after that we will add to it p another edges, which is not in the graph. We will build 0-interesting graphs using the following approach: Let's took k disjointed components, from graphs with number of vertexes from 5 to 9, in such way that there are exactly n vertexes in graph.

402D - Upgrading Array / 403B - Upgrading Array I will describe two solutions.

First. Dynamic programming approach. Let's calculate an DP d[i][j] — which is the best possible answer we can achieve, if current prefix has length i and we used operation of Upgrading last time in position j. It is clear to understand, that we should iterate i from n to 1, and j from n to i. There are only two transitions:

First, d[i - 1][j] = max(d[i - 1][j], d[i][j]) — we will not use operation of upgrading of array in the current position. Second, d[i - 1][i - 1] = max(d[i - 1][i - 1], d[i][j] + f(tgcd[j]) * i - f(tgcd[i - 1]) * i — we are using an operation of upgrading. f(a) — is a beauty of the number. tgcd[i] — gcd of all numbers on the prefix of length i. You can use function, which works in  to calculate the beauty. Also you can make your solution more faster, it you will precalculate some small primes. Also you can use map < int, int >  to store calculated values. DP base d[n][n] = curBeauty — is a current beauty of the array. Second. Greedy. Let's find position r, which can upgrade our answer. If there some values of r — we will take most right position. We will add this position to the answer and upgrade our answer. Why it's correct? Let's fix an optimal solution (sequence of position, where we used an upgrading operation) r1 > r2 > ... > rk. Also we have an solution which was built by using greedy l1 > l2 > ... > lm. It's clear, that r1 ≤ l1, because all position with  > l1 cannot upgrade anything (otherwise greedy will choose it as first position). In other hand, r1 ≥ l1, because otherwise we can upgrade in position l1 and make answer better. So, r1 = l1, and after that we can use our propositions for big indexes i.

402E - Strictly Positive Matrix / 403C - Strictly Positive Matrix Let's look at the matrix a as a connectivity matrix of some graph with n vertices. Moreover, if aij > 0, then we have directed edge in the graph between nodes (i, j). Otherwise, if aij = 0 that graph does not contains directed edge between pair of nodes (i, j). Let b = ak. What does bij means? bij is the number of paths of length exactly k in our graph from vertex i to vertex j. Let pos is an integer, such that a[pos][pos] > 0. That is, we have a loop in the graph. So, if from the vertex pos achievable all other vertexes and vice versa, from all other vertices reachable vertex pos, then the answer is YES, otherwise the answer is NO. If reachability is missing, it is clear that for any k akipos = 0. If reachability there, we will be able to reach self-loop, use self-loop "to twist", and after that we will go to some another vertex.

403D - Beautiful Pairs of Numbers First, we can note, that length of sequence is not greater then 50. Ok, but why? Because all numbers bi - ai are different, so 0 + 1 + ... + 50 > 1000. Let's imagine, that sequence from input is a sequence of non-intersecting segments. So, ci = bi - ai + 1 is length of segment i. Also, . After that let's calculate the following DP: d[i][j][k] — — number of sequences for which following holds: c1 < c2 < ... < ci, ci ≥ 1 , c1 + c2 + ... + ci = j and maximal number is less then k (upper bound of sequence). This DP will helps us to calculate number of ways to set length to each segment in sequence. It's simple to calculate such DP:

base d[0][0][1] = 1, d[i][j][k + 1] = d[i][j][k + 1] + d[i][j][k] — we increase upper bound of sequence; d[i + 1][j + k][k + 1] = d[i + 1][j + k][k + 1] + d[i][j][k] — we are adding upper bound to the sequence. We can calculate such DP, by using only O(N2) of memory, where N = 1000. After that we should multiply d[i][j][k] on i!, because we need number of sequences ci, where order does not matter.

After that we can calculate answer for n, k. Let's , where x — some upper bound of sequences. After that we should calculate next number: how many ways to set to distances between segments? It's clear, that we can increase distance between some segments, but we have only n - len such operations. It's well known, that answer number of ways equals to C(n - len + k, k). So, for each n we should sum by len following values: sum[len] * C(n - len + k, k).

Note, that we need array C[n][k] (binomials) where n ≤ 2000, k ≤ 2000.

403E - Two Rooted Trees First, for each vertex of the first and second tree we calculate two values in[s], out[s] — the entry time and exit time in dfs order from vertex with number 1. Also with each edge from both trees we will assosiate a pair (p, q), where p = min(in[u], in[v]), q = max(in[u], in[v]) (values in, out for each vertex we take from tree with another color). Now for each tree we will build two segment trees (yes, totally 4 segment trees). In first segment will store all pairs in following way: we will store a pair in node of segment tree if and only if (node of segment tree is a segment (l, r)) left element of pair lies in segment (l, r). In second segment tree we will store a pair if and only if right element of the pair lies in segment (l, r) All pairs in segment trees we will store in some order (in first segment tree — increasing order, in the second tree — decreasing order). Such trees use  of memory, also you can build it in .

Good. How to answer on query (l, r) — erase all edges from tree for which exactly one vertex have value in[s] in segment (l, r)? We will go down in our segment tree. Let's imagine, that now we in some node of segment tree. Because we store all pairs in the first segment tree in increasing order of the right element, so answer to the query is a some suffix of the array of pairs. After we can add they to the answer (if it not erased yet). After that we should modify our segment tree: for each node, where we work with suffixes, we should erase all pairs from such suffix. So, this solution in .

My solution to E: 6052738

Codeforces Round #235 (Div. 2) — Tutorial

By EG0R, 9 years ago, translation, In English Problem А We must sum all numbers, and reduced it to zero by the operations +x and -x.

Solution А

Problem B You must identify the array of numbers contests that remember Sereja, as employed. If we want to find maximal answer, we must count the number of immune cells. If we want to find mininum answer, we must do the following:

if i-th element is free and (i+1)-th element is free, and i<x then we using round type of "Div1+Div2" and answer++, i-th and (i+1)-th elements define as employed. if i-th element is free and (i+1)-th element is employed then we usign round type "Div2" and answer++, i-th element define as employed.

Solution B

Problem C n — the number of cards containing number 0 and m — the number of cards containing number 1. We have answer, when ((n-1)<=m && m <= 2 * (n + 1)). If we have answer then we must do the following:

if (m == n - 1) then we derive the ones and zeros in one, but we must start from zero.

if (m == n) then we derive the ones and zeros in one.

if (m > n && m <= 2 * (n + 1)) then we must start form one and we derive the ones and zeros in one, but in the end must be one. And if we in the end and we have ones, then we try to stick to one unit so that we have. For example, we have 10101 and two ones, after we have 110101 and one ones, and then we have 1101101.

Solution С

Problem D This problem we can be attributed to the dynamic programming. We must using mask and dynamic.

We have dynamic dp[i][x], when i — mask of reshuffle and x — remainder on dividing by m.

if we want to add number a[j], we must using it:

dp[i or (1 shl (j-1)),(x*10+a[j]) mod m] := dp[i or (1 shl (j-1)),(x*10+a[j]) mod m] + dp[i,x]; In the end we must answer to divide by the factorial number of occurrences of each digit.

  for i:=0 to 9 do

   for j:=2 to b[i] do

     ans:=ans div int64(j); Solution D

Problem E If first participant of the contest will contain at point (x1;y1) and second participant of the contest will contain at point (x2;y2), then we need to satisfy two conditions:

L*L <= (abs(x1-x2)*abs(x1-x2) + abs(y1-y2)*abs(y1-y2)) <= R*R

gcd(abs(x1-x2),abs(y1-y2)) == 1

Since the hall can potentially be of size 100,000 x 100,000, even considering each possible size of R or L once will take too much time. And if we iterate value abs(x1-x2) and iterate value abs(y1-y2) then it will take much time too. But if we iterate only value abs(x1-x2) we can find confines of value abs(y1-y2). We can do so:

L*L<=(abs(x1-x2)*abs(x1-x2)+abs(y1-y2)*abs(y1-y2))<=R*R

L*L - abs(x1-x2)*abs(x1-x2) <= abs(y1-y2)*abs(y1-y2) <= R*R - abs(x1-x2)*abs(x1-x2)

Number of options to place the square in hall n*m will be (n-abs(x1-x2)+1)*(m-abs(y1-y2)+1). The first quantity is easy to obtain, while the second requires a little more work. To calculate the second quantity, we note that, although w could have a large variety of prime divisors, it does not have very many of them. This important insight allows us to quickly find the sum: we find the prime factors of w, then we use the inclusion-exclusion principle to calculate the sum of all numbers between L and R that are divisible by at least one of the numbers.

Unfortunately, my fault, in the round hit the problem that was previously used on another competition. Since it does not comply Codeforces, problem E will be deleted.

Solution E

Sorry for my English.

Codeforces Round #234 (Div. 2) — Tutorial

By Berezin, 9 years ago, translation, In English 400A — Inna and Choose Options

Not difficult task. Let's iterate param a. If 12 % a != 0, continue. Calculate b = 12 / a. Let's iterate column (from 1 to b) and for each it's cell (i, j) check, if it contains X or not. Cell (i, j) — is ((i–1) * a + j) -th element of string.

400B — Inna and New Matrix of Candies

In the final version of statement we must choose all lines we haven't finish already. If it is a string where we have S...G — answer  - 1.

Otherwise, the answer is the number of distinct distances, as one step kills all distances of the minimal length.

400C — Inna and Huge Candy Matrix

Let's note that the number of 90 clockwise make sence only by modulo 4. Horizontal — by modulo 2, and 90 counterclockwise — by modulo 4, and 1 such rotation is 3 clockwise rotations.

90 clockwise: newi = j; newj = n–i + 1 don't forget to swap(n, m).

Horizontal: newj = m–j + 1

400D — Dima and Bacteria

If the distribution is correct, after deleting all ribs with cost more than 0 graph will transform to components of corrects size. Also, the nodes are numereted so we should turn dfs for the first node of each type and be sure that we receive exact all nodes of this type and no ohter.

Now simple floyd warshall, and put in each cell of adjacent matrix of components the minimal weight between all ribs from 1 component to another.

400E — Inna and Binary Logic

Let's solve this for each bit separately. Fix some bit. Let's put 1 if the number contains bit and 0 otherwise. Now we receive the sequence, for example 11100111101.

Now let's look on sequence of 1 without 0, for this sequence current bit will be added to the sum on the first stage (with all numbers single) on the second stage (with all neighbouring pairs) on the third stage and so on, the number of appiarence for sequence of neighbouring 1 is a formula which depends on the length of sequence only.

The last is to learn how to modificate. For each bit let's save the set of sequence of 1. When the bit is deleted, one sequence is sepereted on two, or decreases its length by 1. When the bit is added, new sequence of length 1 appears, or some sequence increases its lentgh by 1 or two sequence transform to 1 biger sequence.

Codeforces Round #233 Editorial

By .o., 9 years ago, In English Please write here if you had written some comments about any suggestions or questions on the announcement. There are a bunch of notification emails but I couldn't read most of them :(

Here are the final top 100 : Div1, Div2. Congrats to the winners!

(These links are all from google search cache, so it may be disappear)

First of all, we are sorry to make this round unrated. This is an unexpected incident, and I believe that everyone in Codeforces would understand that. And second, we're sorry for estimating the difficulties of the problems wrong.

Actually, I thought that somebody would get Accepted on 398A - Cards within 5 minutes. But there wasn't any submissions during the first 4 minutes, and many people got wrong answer on pretests! I think almost everybody who solved this got at least one wrong answer.. I'm really sorry for measuring A easy. I think what cgy4ever said is right — it would be better not asking to print the sequence.

At first, I purposed 398C - Tree and Array as B(!!) because ainta solved it very easily than I expected. (I could hardly solve this, and thought it must be at least D, before I heard ainta's solution.) We're sorry for giving this problem the same score with 398B - Painting The Wall, which was much easier than 398C - Tree and Array. Next time I'll remember that ainta is really a genius :)

Congrats to four people who solved 398C - Tree and Array during the contest! : cgy4ever, Shef, SillyHook06, and Qwaz.

We are surprised that Petr solved 398E - Sorting Permutations during the contest! Even though he implemented by Java, his solution is faster than ours :p Congratulations to him!

Actually, we purposed an another problem for Div1-E, but the same problem popped out at OpenCup last Sunday, so we couldn't use that. Thanks to Gerald, who helped us preparing a new problem in such a short time. By the way, can you guess what problem was that? :D

...

399A - Pages — Author : .o. You can solve this problem by just following the statement. First, print << if p - k > 1. Next, iterate all the integers from p - k to p + k, and print if the integer is in [1..n]. Finally, print >> if p + k < n.

Time complexity: O(n). Code : 5926588 399B - Red and Blue Balls — Author : xtalclr Change the blue balls to bit 1, and blue balls to bit 0. Interpret the stack as an integer represented in binary digits. Now, one may see that a single operation decreases the integer by 1, and will be unavailable iff the integer becomes zero. So the answer will be 2a1 + 2a2 + ... + 2ak where the (ai + 1)-th (1 ≤ i ≤ k) ball is blue in the beginning.

Time complexity: O(n) Code : 5926598 398A - Cards — Author : .o. Let the number of o blocks p, and the number of x blocks q. It is obvious that |p - q| ≤ 1 and p, q ≤ n. So we can just iterate all p and q, and solve these two problems independently, and merge the answer.

1. Maximize the value of x12 + x22 + ... + xp2 where x1 + x2 + ... + xp = a and xi ≥ 1.

Assign a - p + 1 to x1, and assign 1 to x2, x3, ..., xp. The value is (a - p + 1)2 + (p - 1). 2. Minimize the value of y12 + y22 + ... + yq2 where y1 + y2 + ... + yq = b and yi ≥ 1.

For all , assign  to yi. For all , assign  to yj. The value is . The proof is easy, so I won't do it. With this, we can solve the problem. We can print y1 xs, and then x1 os, ...

Time complexity: O(n). Code : 5926607 Bonus: Is there any solution faster than O(n)? We tried to use ternary search, but we couldn't prove that was correct. 398B - Painting The Wall — Author : ainta This can be solved by dynamic programming. Let T[i, j] the expected time when i rows and j columns doesn't have any painted cells inside.

Let's see all the cases. If we carefully rearrange the order of rows and columns, we can divide the wall into 4 pieces.

 

Choose a cell in rectangle 1. The size of this rectangle is i × j. The expectation value is T[i - 1, j - 1]. Choose a cell in rectangle 2. The size of this rectangle is i × (n - j). The expectation value is T[i - 1, j]. Choose a cell in rectangle 3. The size of this rectangle is (n - i) × j. The expectation value is T[i, j - 1]. Choose a cell in rectangle 4. The size of this rectangle is (n - i) × (n - j). The expectation value is T[i, j]. Merging these four cases, we can get:

T[i, j] = 1 + {T[i - 1, j - 1] × i × j + T[i - 1, j] × i × (n - j) + T[i, j - 1] × (n - i) × j + T[i, j] × (n - i) × (n - j)} / n2

Moving the T[i, j] on the right to the left, we can get the formula which can be used to calculate the value T[i, j]. There are some corner cases, like i = 0 or j = 0, but it can be simply handled.

Time complexity: O(n2) Code : 5926617 398C - Tree and Array — Author : .o. There are two intended solutions. One is easy, and the other is quite tricky.

Easy Solution

Make a tree by the following method.

For all , make an edge between vertex i and  with weight 1. For all , make an edge between vertex i and i + 1 with weight . You can see that  are all good pairs. In addition, (1, 3) is also a good pair. So we can print the answer.

But, if n = 5, this method doesn't work because (1, 3) is not a good pair. In this case, one may solve by hand or using random algorithm.

Time complexity: O(n) Code: 5926624 Bonus I: Is there any method to make more than  good pairs? Bonus II: Is there any method that the maximum weight is relatively small and make at least  good pairs? Tricky Solution

If you got stuck with the problem, one can run any random algorithm that solves small cases, and merge these cases. With this approach, we can even limit the weight to a very small constant!

But I think this is not a good solution, so I won't mention about unless anybody wants to know the details. I came up with this solution, and tried to purpose this as D. It seems all the 6 people who passed pretests during the contest didn't use this solution :)

Time complexity: ??? Code : 5926632 398D - Instant Messanger — Author : .o. Let xi an integer representing the state of the i-th user. If user i is online, xi  =  1, otherwise, xi  =  0. Also, let Si the set consisting of i-th friends.

One can see that the queries become like this:

Online/Offline: change the value of xi to 1  -  xi. Add: add u to set Sv, and v to set Su. Delete: delete u from set Sv, v from set Su. Count: calculate . Let's use sqrt-decomposition to perform these queries. Let user u heavy if |Su| ≥ C, or light otherwise. Also, we will define some arrays and sets:

Hu is a set that stores friends with user u who are heavy users. O[u] stores the sum of . If the Online/Offline(u) query is given,

If u is a light user: for all , change the value of O[v]. It takes O(|Su|) time. Otherwise: just update the state of itself. If the Add(u, v) query is given,

If vertex u becomes heavy if we add this edge, for all , add v into Hw and update the value of O[w]. This can be done in O(C). If vertex u is still light even if we add the edge, update O[v]. This can be done in constant time. If vertex u is heavy (after the operations above), update Hv. Add u to set Sv, and v to set Su. If the Delete(u, v) query is given,

Delete u from set Sv, and v from set Su. Update the value of O[*], Hu and Hv. Because for all |Hw| ≤  E| /  C, this can be done in O(|E| / C). If the counting query is given,  will be the answer. Because |Hu| ≤ |E| / C, it will take O(|E| / C) time.

So for each query, O(|E| / C) or O(C) time is required. To minimize the time, .

Time complexity:  Code : 5926635 We can also solve this by dividing the queries into  parts. For each block, use O(n + m + q) time to build the online & offline state and the answer table for each vertices. For each query, you can use  time to get the answer. If you want more details, please ask in the comments.

Time complexity:  Code : 5926640 398E - Sorting Permutations — Author : xtalclr, eyTns, and great help of Gerald Here is the draft solution.

Feel free to ask of or discuss about the solutions! Unfortunately, I don't know how to read or write Russian, so if you ask me in Russian, I can't response to it. (also, I think the Russian editorial won't be available..) Sorry for that.

Codeforces Round #232 Editorial (restored)

By Kostroma, 9 years ago, translation, In English Div2-A Create an array used of 100 elements. i-th element for the segment (i, i + 1).

For every student except Alexey set used[i]  =  true for each segment (i,  i  +  1) in the segment of that student. After that for each subsegment (i,  i  +  1) of Alexey's segment add 1 to result if used[i]  =  false.

Div2-B First of all, calculate how many L's we can bring so that the result will not exceed N. It's .

Now, if R·K  ≥  N we may increase any of K numbers by 1. At some moment sum will be equal to N becase sum of K R's is greater than N. So answer in this case is YES.

If R·K  <  N, we can't get K or less numbers because their sum is less than N. But we can't get more than K numbers too, because their sum is more than N. So answer is NO.

Complexity: O(1) for every query. Overall complexity: O(t).

Div1-A/Div2-C Let's factorize all n numbers into prime factors. Now we should solve the problem for every prime independently and multiply these answers. The number of ways to split pk into n multipliers, where p is prime, is equal to C(k  +  n  -  1,  n  -  1) (it can be obtained using the method of stars and bars, you can read about it here, choose 'combinatorics'). So we have a solution that needs  time.

Div1-B/Div2-D First of all, let's consider n  +  1  =  p is prime. Then we can prove by induction that the answer is . Base for p  =  3 is obvious. If this equality holds for p, and q is the next prime, then answer for q is equal to answer for p plus q  -  p equal summands , that is , that's we wanted to prove.

Next using that the distance between two consecutive primes not exceeding 109 does not exceed 300, we can find the answer as a sum of the answer for the maximal prime not exceeding n and several equal summands . We see that the denominator is a divisor of 2pq, which fits in long long.

Div1-C/Div2-E We can write all vertices in the list in order of dfs, then the descendants of the vertex from a segment of this list. Let's count for every vertex its distance to the root level[v].

Let's create two segment trees st1 and st2. If we are given a query of the first type, in st1 we add x  +  level[v]·k to the segment corresponding to the vertex v, in st2 we add k to the segment corresponding to the vertex v.

If we are given a query of the second type, we write st1.get(v) - st2.get(v) * level[v].

The complexity is O(qlogn).

You can use any other data stucture that allows to add to the segment and to find a value of an arbitrary element.

Also there exists a solution using Heavy-Light decomposition.

Div1-D Let's prove a useful fact: sum of number of invertions for all permutations of size k is equal to . The prove is simple: let's change in permutation p for every i pi to k  +  1  -  pi. Then the sum of number of invertions of the first and the second permutations is , and our conversion of the permutation is a biection.

Now we suppose that we are given a permutation of numbers from 0 to n  -  1.

Let's go at p from left to right. What permutations are less than p?

Permutations having first number less than p0. If the first number is a  <  p0, than in every such permutation there are a inversions of form (first element, some other element). So in all permutations beginning with a there are a·(n  -  1)! inversions of this from. Moreover, there are inversions not including the first element, their sum is sumAll[n  -  1]. Then, counting sum for all a we have  inversions. Permutations beginning with p0. At first, we should count the number of inversions, beginning in p0. There are cnt·p0 of this form, where cnt is the number of permutations beginning with p0 and not exceeding p. Then we should count the inversions not beginning in the beginning. But it is the same problem! The only exception is that if p1  >  p0, there are p1  -  1 available numbers less than p1, but not p1. So we get a solution: go from left to right, keep already used numbers in Fenwick tree, and then solve the same problem, assuming that the first number is not pi but pi - (the number of used numbers less than pi). The last we should do is to count the number of permutations not exceeding the suffix of p and beginning the same. It can be precomputed, if we go from right to left. In this case we should do the same as in the first part of solution, but consider that the minimal number is a number of already used numbers less than current.

Div1-E We will describe an algorithm and then understand why it works.

For every prime we will maintain a list of intervals. At the first moment for every pi we add in its list interval [0;ai), other primes have an empty list.

Then we go from big primes to small. Let's consider that current prime is p. If in its list there exists an interval [x;y), $x < k, y > k$, we divide it into two parts [x;k) and [k;y).

Then for every interval [x;y), x  ≥  k (in fact, in this case x  =  k) we add to the answer for p y  -  x. For intervals, where y  ≤  k, we add to list of every prime divisor of p  -  1 invterval [x  +  1,  y  +  1). If p  -  1 has some prime if more than first power, we should add this segment several times.

After that we should conduct a "union with displacement" operation for every prime which list was changed. If in one list there are 2 invervals [x,  y), [z,  t) so that y  ≤  z  >  x, we replace them with one interval [x,  y  +  t  -  z) (so we added t  -  z to the right border of the first interval). Then we go to next (lesser) p.

Why does it works? If we take function φ one time, for every prime p which divides n, n is divided by p and multiplied by p  -  1 (or, the same, by all prime divisors p  -  1 in corresponding powers).

Now we can observe that intervals in lists contains the numbers of iterations, when the number contains the corresponding prime number. Bigger primes do not affect smaller, so we can process them earlier. If after i-th iteration the number contains prime number p, after i  +  1-th iteration it contains prime divisors of p  -  1, and we add segments in accordance with this. The k-th iteration is the last, so the existence of the interval [k,  x) means that after k-th iteration we have (x  -  k)-th power of this prime. From this it is clear why we unite the intervals if that way.

Why does it work fast?

Because we precalculated the minimal prime divisor of each number up to MAXPRIME using linear Eratosthenes sieve. (Well, it's not necessary)

Because for each prime there's no more than  intervals, because for each [a,  b) range . Practically there is no more than 6 segments at once.

Any questions about the editorial are welcome! Especially the English one :)

This post was restored from google cache, and I have edited formula once again. If you notice some mistake, please send be a private message.

Unofficial editorial for Codeforces Round #230 (just a little bit late)

Автор Maksim1744, 2 года назад, По-английски Yesterday I saw this blog and thought that one bad editorial is better than zero good ones, right? So, enjoy it!

Here are links to contests: Div. 1, Div. 2

Div2A

Editorial 393A - Nineteen Looking at examples and thinking about different cases lead to the idea that the best result would be to build a string which starts with nineteenineteenineteen... . The first word nineteen  requires 3 letters n , 3 letters e , 1 letter i  and 1 letter t . Every next occurrence of nineteen  requires the same set of letters, but we need only two letters n  for each new word. In other words, we can start with n , and then every word will need exactly two extra n -s. Let cnt[c]  denote the number of characters c  in the string. Then the answer is min(⌊cnt[n]−12⌋,⌊cnt[e]3⌋,cnt[i],cnt[t]) . (In theory this minimum could be −⌊12⌋ , but in C++ it is equal to zero, so everything works fine)

Code Div2B

Editorial 393B - Три матрицы We can write this system of equations, using the fact that B[j][i]=−B[i][j]  and A[i][j]=A[j][i] {A[i][j]+B[i][j]=W[i][j]A[j][i]+B[j][i]=W[j][i]⇒{A[i][j]+B[i][j]=W[i][j]A[i][j]−B[i][j]=W[j][i] From that, it is easy to conclude that A[i][j]=W[i][j]+W[j][i]2  and B[i][j]=W[i][j]−W[j][i]2 .

By the way, there is some interesting math connected to this problem: link

Code Div2C/Div1A

Editorial 392A - Заблокированные точки Let's look at all pairs of neighboring points such that one of them is special and the other one is not. I claim that it is necessary and sufficient to block at least one point in every such pair

Proof Now let's look at these pairs. For simplicity, we will look at only 18 -th of a circle.

This one And let's draw all horizontal pairs with a point inside the selected piece.

Segments There are also some vertical segments, but it can be proven with some geometry that the segments on the neighboring horizontal line are either on the same x-coordinate, or one is shifted by one. This means that if we choose the leftmost point in each of these segments, we will cover all vertical pairs as well.

With some symmetry, this can be done for other pieces of a circle.

There is only one thing left — we need to bring all pieces together. It is easy when two pieces share a horizontal or vertical line, but in the other case, we need another picture.

Picture 1 In this case, everything is already fine, we don't have any "leaks" between parts

Picture 2 In that case, we don't have any leaks either, but we have overlapping segments, and that means that we case save 1 point here and 4 points total.

All we need now is to calculate the number of segments in a circle sector (it is n/2–√+1 ) and differentiate these two cases.

Code Div2D/Div1B

Editorial 392B - Ханойская башня First, understand this solution of the standard Hanoi puzzle, if you don't know it. I will use the same idea to solve this problem. Let's create a function calc(from,to,n)  which will count the minimal cost to move n  disks from from  to to . If n=1  then we either move the disk directly to to , or we first move it to the mid  (the remaining rod) and only then move to to . If n>1  then again, there are two possible strategies. Either we use moves from standard solution — move n−1  disks to mid , move 1 disk from from  to to , then move n−1  disks to to . Or we can make more moves but possibly with less cost: move n−1  disks to to , then 1 disk from from  to mid , then n−1  disks back to from , then 1 disk to to , and finally n−1  disks to to . Here are pictures for both cases:

Case 1 Case 2 For moving n−1  disks we will make recursive calls. If we just do that, we will have an exponential solution, which is not very nice. But we only have 3×2×n  different calls — 3 options for from , 2 for to  and n . That means that we can just store every value which we already counted (or I can say a fancy word memoization, which means the same thing)

Code Div2E/Div1C

Editorial 392C - Еще одна последовательность чисел This is obviously some matrix-exponentiation problem. We just have to figure out the matrix. Well, let's look at what we have

Ai(k)=Fi⋅ik=(Fi−1+Fi−2)⋅ik=Fi−1⋅((i−1)+1)k+Fi−2⋅((i−2)+2)k==∑kj=0(kj)Fi−1(i−1)j+∑kj=0(kj)Fi−2(i−2)j⋅2k−j==∑kj=0(kj)Ai−1(j)+∑kj=0(kj)Ai−2(j)⋅2k−j Then we just have to store Ai−1(j)  and Ai−2(j)  for every j∈[0;k] . And also we have to store the sum, so the matrix will be of size 2(k+1)+1 , resulting in O(k3logn)  in total.

If you need more information about matrix exponentiation, consider watching the video from Errichto. Oh, and I almost forgot. He says exponentation instead of exponentiation. Now you will not able to forget this, enjoy! Here is the link :) (Errichto, no offence, if you are reading this :) )

Code Div1D

Editorial 392D - Три массива Let forget about a  for a minute and solve the problem for two arrays. Of course, it can be done with something like two pointers, but it is not extendable to three arrays (at least I don't know how). We need a more general approach. First, let's assume that b  has all elements, which c  contains. We can achieve that by copying c  at the end of b  (it is easy to see that this will not improve the answer).

Suppose for some number k  it has only one occurrence in b  and only one in c . And b[i]=c[j]=k . Then we denote pos[i]=j . Now, if k  has multiple occurrences in c , we will take the smallest j . If it has multiple occurrences in b , we will set the first pos[i]  to j  and others to 0 . Why that? Good question. Now the answer for the problem is mini((i−1)+maxj>ipos[j]) . The expression in the brackets corresponds to the case when we take i  first elements from b . Then we look for all other elements (j>i ) and choose the shortest prefix of c  which contains all these elements. That explains why we write the first occurrence of k  in c  to pos . And we fill other values with zero because we don't need them if we already took the first occurrence in b .

Now get a  back. What changes if we have some numbers in a ? Well, in that case, we can set pos[i]=0  for all occurrences of that number in b  (not only all except first). That means that if we iterate over prefix of a  from 0  to n  then we will have to change some pos  to zero. But I prefer changing zeros to some values, so we will iterate from n  to 0 .

Well, let's iterate. Suppose we decided not to take prefix of length i  in a , and instead took prefix of length i−1 . If there are some occurrences of a[i]  before i , then nothing changes in pos . But if there is no a[i]  before i , we have to update some pos  and recalculate mini((i−1)+maxj>ipos[j]) . I believe there are different structs that can do it, I will describe what I used.

In the expression, there are maximums on the suffix. They can be stored as pairs (p,m)  which means that up to position p  maximum on a suffix is at least m  (maximum-on-a-suffix is a non-increasing function, obviously). Now, to calculate the answer, we don't have to go through all i . We only need to consider such indices p  that some pair (p−1,?)  exists in our set. That means that we have to check exactly one option for every pair of adjacent pairs. Remember, we only have to add pairs to this set. And it is easy — add a pair and remove enough pairs before it (while their m  less than new m ). With every addition or removal, we have O(1)  additions or removals of options for an answer. Current answers can be stored in a multiset since we only need the minimal value. And if we are looking at a prefix i  of a , then we have to update the answer with i  + (the smallest value from multiset).

This is probably not the cleanest explanation, so there is a random picture which can help:

Picture Code Div1E

Editorial 392E - Удаляем подстроки There will be three different dp , let's get that out of the way. I wanted to make 4 , but in the end decided to merge two of them.

Also, before everything, let's update v  with v[i]=maxj(v[j]+v[i−j]) . Because sometimes we want to remove segment of length 5 , but 2+3  gives more points.

First, let's discuss what a good substring is. It is either increasing, decreasing, or increasing up to something and then decreasing. And in any case, the difference between neighboring elements is exactly 1.

dp_mon[l][r]  — the biggest score we can get from segment [l;r]  if in the end we are left with monotonous sequence, starting from w[l]  and ending with w[r]  (that means that we cannot remove w[l]  or w[r] ). If we can't do that, dp_mon[l][r]=−∞ .

dp_all[l][r]  — the biggest score we can get from removing the whole segment [l;r] .

dp[l][r]  — the best score we can get on segment [l;r]  (no restrictions).

The answer will be dp[1][n] .

When we have these dp , it is not very hard to calculate them. To get dp_mon[l][r]  we either have to remove everything in between (if |w[l]−w[r]|=1 ), or for each number between l  and r  check if it can be in that monotonous sequence, and if it can, split by this number and add two dp_mon[l][j]+dp_mon[j][r]  (with intersection, yes).

Now dp_all . First, let's update it with every dp_all[l][j]+dp_all[j+1][r] . Now suppose there is an option, where we can't split the segment into two pieces. Consider the last segment we removed. It is some subsequence of our [l;r]  segment. Elements of that subsequence split this segment into pieces. Each of these pieces is independent of each other. That means that if the first element of the subsequence is w[j]  then [l;j−1]  and [j;r]  are independent and we already updated the answer with the sum of dp_all , and similarly with r . There is one case, though. When this subsequence starts at w[l]  and ends in w[r] . But that's what we have dp_mon  for! Now for every element on [l;r]  we have to check if this subsequence is increasing from w[l]  to w[j]  and then decreasing from w[j]  to w[r] . That means that we add two dp_mon  and after that remove this subsequence with a score of v[len_of_subsequence] . The length can be calculated from |w[l]−w[j]|  and |w[j]−w[r]| .

The last is dp . That's the easiest one. Either we remove everything — this is dp_all , or there is some element which we decided not to remove. Then, as discussed in previous paragraph, it is enough to update dp[l][r]  by every dp[l][j]+dp[j+1][r] .

And I know that probably some of dp  are useless, but I feel like it is easier to understand the solution with multiple dp  with different purposes.

Code This is my first editorial (and first blog too), so any suggestions, improvements, etc are welcome.

Codeforces Round #229 (Div. 2) Editorial [Unofficial]

Автор AkiLotus, история, 4 года назад, По-английски Since the original data has been lost during the dark days of Codeforces, no version of the editorial has been re-released, and I feel the round itself is quite educational, so I decided to give a try.

390A - Инна и будильники Approach The criterion shows that we can only use either vertical segments or horizontal segments. Since there is no limit on the segments' length, we can see that it's always optimal to use a segment with infinite length (or may be known as a line).

We can see that the vertical line x = a will span through every alarm clocks standing at positions with x-coordinate being equal to a. In a similar manner, the horizontal line y = b will span through every alarm clocks standing at positions with y-coordinate being equal to b.

So, if we use vertical lines, the number of segments used will be the number of distinct values of x-coordinates found in the data. Similarly, the number of horizontal segments used will be the number of distinct values of y-coordinates found.

The process can be implemented by a counting array, or a map.

Time complexity:  for regular arrays, or  for maps.

Solution 1 (Map) Solution 2 (Array) 390B - Инна, Дима и песня Approach From the constraints given, for the i-th song, provided there exists corresponding xi and yi values, then the following inequality must hold: 2 ≤ xi + yi ≤ 2·ai. Thus, if any bi is either lower than 2 or higher than 2·ai, then no xi and yi can be found, thus, Sereja's joy will surely decrease by 1.

Amongst all pairs of  that xi + yi = bi, the pair with the highest value of xi·yi will be one with the equal value of xi = yi (this can be proven by the famous AM-GM inequality). Thus, if bi is divisible by 2, we can easily pick . Also, from this, we can see (either intuitively or with static proofs) that the lower the difference between xi and yi is, the higher the value xi·yi will be. Thus, in case bi being odd, the most optimal pair will be  or  (the order doesn't matter here).

Time complexity: .

Solution 390C - Инна и коробки с конфетами Approach The query content looks pretty confusing at first, to be honest. Since k is static throughout a scenario, we can group the boxes into k groups, the z-th box (in this editorial let's assume that the indices of the boxes start from 0) falls into group number .

Then, each query can be simplified as this: "Is that true that among the boxes with numbers from li to ri, inclusive, the candies lie only in boxes of group ?

To make sure the answer for a query being "Yes", Dima has to remove candies from all candied-box in all groups other than , while in that exact group, fill every empty box with a candy. Obviously, we'll consider boxes with indices between li and ri inclusively only.

We can make k lists, the t-th (0-indexed) list stores the indices of candied boxes in group t.

We'll process with each query as the following:

Obviously, given from the criteria, each range will consist of exactly  boxes per each group. Let's denote . Traverse all groups, for the t-th group (again, 0-indexed), let's denote xt as the number of candied boxes of group t in the given range. This value can be calculated quickly through binary searching the constructed lists above. If group t is not the group being demanded to have candies (group ), we'll need to perform xt actions (removing candies). Otherwise, we'll need to perform A - xt actions (adding candies to empty boxes). Time complexity: .

Solution 390D - Инна и матрица конфет Approach We can see that the most optimal placement will be choosing k cells being nearest to cell (1, 1) (yup, including (1, 1) itself). To find these k points, we can simply do a BFS starting from (1, 1), with traceback feature to construct the paths to get to those cells. However, keep in mind that any cell being candied will later on become obstacles for the following paths. Thus, to avoid blocking yourself, you should transfer candies to the farthest cells first, then getting closer. Thus, cell (1, 1) will be the last one being filled with candy.

Time complexity:  or , based on implementation (I myself did , since the difference isn't too much).

Solution 390E - Инна и большая матрица конфет Approach Let's denote A as the total number of candies on the board, Ri as the total number of candies on the i-th row (1 ≤ i ≤ n), Cj as the total number of candies on the j-th column (1 ≤ j ≤ m).

Also, let's denote  and .

Let's considered the 2nd type of query first. Denoting the answer for the query as f(x1, y1, x2, y2), we can see that f(x1, y1, x2, y2) = R(x1, x2) + C(y1, y2) - A (you can draw a simple diagram and validate this function).

Thus, the problem is now reduced to calculating R(x1, x2), C(y1, y2) and A:

A can be easily calculated. After each query of the 1st type with parameters x1, y1, x2, y2, v; A will be increased by v·(x2 - x1 + 1)·(y2 - y1 + 1). The calculation of R(x1, x2) and C(y1, y2) makes us thinking about some kinds of data structures that support range sum update and range sum query. Segment trees and Fenwick trees can both work on that. Personally I used segment trees, they fit in just right for the memory limit (I implemented it by vectors, regular arrays will obviously be safer). Time complexity: .

Solution

Codeforces Round #228 — Editorial

Автор cgy4ever, 9 лет назад, По-английски You can find the editorial and my solutions here: https://github.com/cgy4ever/CF228

389A - Fox and Number Game

First we know that: in the optimal solution, all number will be equal: otherwise we can pick a and b (a < b) then do b = b — a, it will make the answer better.

Then we need an observation: after each operation, the GCD (Greatest common divisor) of all number will remain same. It can be proved by this lemma: if g is a divisor of all number of x[], then after the operation, g is still the divisor of these numbers, and vice versa.

So in the end, all number will become the GCD of x[].

Another solution that can pass is: While there exist x[i] > x[j], then do x[i] -= x[j]. We can select arbitrary i and j if there exist more than 1 choice.

389B - Fox and Cross

Let's define the first # of a shape is the cell contain # that have the lexicographical smallest coordinate. Then the first # of a cross is the top one.

Then let x be the first # of the given board. (If the board is empty, then we can draw it with zero crosses.) x must be covered by a cross, and x must be the first # of the cross. (You can try 4 other positions, it will cause a lexicographical smaller # in the board than x)

So we try to cover this x use one cross, if it leads some part of the cross covers a '.', then there will be no solution. If not, we just reduce the number of # in the board by 4, we can do this again and again.

389C - Fox and Box Accumulation / 388A - Fox and Box Accumulation

We need some observation:

There exists an optimal solution such that: in any pile, the box on the higher position will have a smaller strength.

Let k be the minimal number of piles, then there exists an optimal solution such that: The height of all piles is n/k or n/k+1 (if n%k=0, then all of them have the height n/k).

We can prove them by exchange argument: from an optimal solution, swap the boxes in it to make above property holds, and we can ensure it will remain valid while swapping.

Then for a given k, we can check whether there exist a solution: the i-th (indexed from 0) smallest strength needs to be at least i/k.

So we can do binary search (or just enumerate, since n is only 100) on k.

389D - Fox and Minimal path / 388B - Fox and Minimal path

First we need to know how to calculate the number of different shortest paths from vertex 1 to vertex 2: it can be done by dp: dp[1] = 1, dp[v] = sum{dp[t] | dist(1,t) = dist(1,v) — 1}, then dp[2] is our answer.

We need to do dp layer by layer. (first we consider vertexes have distance 1 to node 1, then vertexes have distance 2 to node 1 and so on.) So we can construct the graph layer by layer, and link edges to control the dp value of it.

My solution is construct the answer by binary express: If k is 19, then we need some vertexes in previous layer such that the dp value is 16, 2 and 1. So we just need a way to construct layer with dp value equals to 2^k.

In the first layer, it contains one node: 1, it has the dp value 1. In the next layer, we can construct 2 nodes, with dp value equals to 1. (We use [1 1] to denote it). And the next layer is [1 1 2], then [1 1 2 4], [1 1 2 4 8] and so on. So we need about 30 layers such that gets all 2^k where k < 30. It uses about 500 nodes.

389E - Fox and Card Game / 388C - Fox and Card Game

First let's consider the case which all piles have even size. In this case, we can prove: in the optimal play, Ciel will gets all top most half cards of each pile, and Jiro gets the remain cards.

We can prove by these facts: Ciel have a strategy to ensure she can get this outcome and Jiro also have a strategy to ensure this outcome. (For Jiro this strategy is easy: just pick the card from pile that Ciel have just picked. For Ciel it's a little bit harder.)

Why we can conclude they are both the optimal strategy? Ciel just can't win more, because if she played with Jiro with above strategy, Jiro will get the bottom half of each pile.

Then we come back with cases that contain odd size piles. The result is: for odd size pile, Ciel will get the top (s-1)/2 cards and Jiro will get the bottom (s-1)/2 cards. Then what about the middle one? Let's denote S is all such middle cards. Then we define a reduced game: In each turn, they pick one card from S. The optimal play for this game is easy: Ciel gets the max one, and Jiro gets the 2nd largest one, and Ciel gets the 3rd largest one and so on.

We can prove Ciel have a strategy to get: all top half parts + cards she will get in the optimal play in the reduced game. And Jiro also have a strategy to get: all bottom half parts + cards he will get in the optimal play in the reduced game. And these strategy are optimal.

388D - Fox and Perfect Sets

A perfect set correspond to a linear space, so we can use base to represent it. We do the Gauss–Jordan elimination of vectors in that set, and can get an unique base. (Note that we need to to the all process of Gauss–Jordan elimination, including the elimination after it reached upper triangular)

And we can construct the bases bit by bit from higher bit to lower, for a bit:

We can add a vector to the base such that the bit is the highest bit of that vector. And at this time, all other vector will have 0 in this bit.

Otherwise we need to assign this bit of each vector already in the base. If now we have k vector, then we have 2^k choices.

And when we do this, we need to know what's the maximal vector in this space. It's not hard:

If we add a vector, then in the maximal vector, this bit will be 1.

Otherwise, if we don't have any vector in base yet, then this bit will be 0. Otherwise there will be 2^(k-1) choices results in this bit of maximal vector will be 0, and 2^(k-1) choices results in 1.

So we can solve this task by DP bit by bit.

388E - Fox and Meteor Shower

All tasks beside this are very easy to code. And this one focus on implementation.

We can represent the orbit of each meteor by a line in 3D space. (we use an axis to represent the time, and two axis to represent the position on the plane.)

Then the problem becomes: we have some lines in 3D space (they are not complete coincide), find a largest clique such that each pair of lines touch at some point.

We need this observation: If there are 3 lines in the optimal clique, and these 3 lines are not share a common point, then all line in this clique will on a plane.

By using this observation, we only need to consider 2 cases:

All lines in the clique have a common point.

All lines in the clique are on the same plane.

Both are easy tasks in theory, but it needs some coding.

There are two ways:

Use integer anywhere. Note that the coordinates of intersection can be rational number, but can't be irrational, so we could do this. We can use some way to encode the plane, direction.

Use floating number. To count same number of points, we can sort (x, y, z) by using the following compare function: if (abs(A.x — B.x) > eps){return A.x < B.x} otherwise { if(abs(A.y-B.y)>eps){return A.y < B.y} otherwise return A.z < B.z}.

Editorial Codeforces Round #227 (Div. 2)

By gridnevvvit, 9 years ago, translation, In English 387A - George and Sleep I will describe the simple solution. Let George woke up in the h0 hours and m0 minutes, and he slept for h1 hours and m1 minutes. Let's get the number hp = h0 - h1 and mp = m0 - m1. If mp < 0, then you should add to mp 60 minutes and subtract from hp one hour. After that if hp < 0, then add to it 24 hours. You can print the answer in C++ by using the following line:

printf("%02d:%02d", h[p], m[p]). The complexity is O(1) time and O(1) memory.

Author's solution: 5850831

387B - George and Round Consider the number of requirements of the difficulties, which we will cover, and we will come up with and prepare new problem to cover other requirements. It is clear that if we decided to meet the i out of n requirements, it would be better to take those with minimal complexity. Let's simplify i most difficult problems to lightest requirements. If all goes well, then we update the answer by value n - i.

The complexity is: O(n2) time / O(n) memory. Note, that there is an solution with complexity O(n + m).

Author's solution: 5850888

387C - George and Number Let's obtain the following irreducible representation of a number p = a1 + a2 + ... + ak, where  +  is a concatenation, and numbers ai have the form x00..000 (x — is non zero digit, and after that there are only zeroes). Let's determine largest index i, such that a1 + a2 + ... + ai - 1 < ai. If there are no such index i then i = 1. After that is k - i + 1. You can compare numbers by using length of number and first digit. You can prove these solution as home task : )

The complexity is: O(n) time / O(n) memory.

Author's solution: 5850919

387D - George and Interesting Graph To solve this problem you should know about bipartite matching.

Let's consider the center of graph i. After that let's remove arcs that have form (i, u) or (u, i). Let's there are cntWithI arcs of such type. Let's Other = m - CntWithI — number of other arcs.

After that we should found maximal bipartite matching on the bipartite graph. This graph has following idea: left part of this graph is indegrees of all vertexes except vertex i, right part of this graph is outdegrees of all vertexes except vertex i. Also if there an arc (i, j) in our graph then in our bipartite graph there an arc (i, j), where i — vertex from left part, j — vertex from the right part. Let's size of bipartite matching on the bipartite graph equals to leng. Then answer for the current vertex i equals to 2n - 1 - cntWithI + Other - leng + (n - 1) - leng. After that you should update global answer. Why it is correct? It is simple to understand that if we will found bipartite matching on the bipartite graph we will cover maximal number of requirements on in/out degrees. Because of that, we will remove all other arcs, except of maximal matching, and after that we will add this maximal matching to full matching by adding (n - 1) - leng arcs. Note, it is important, that self-loops are not forbidden. Withoud self-loops problem is very hard, I think.

The complexity is: O(n2m) time / O(n + m) memory.

5850946

387E - George and Cards Let's calculate arrays pos[i] — position of number i in permutation p and need[i] — equals to one if we should remove number i from permutation p, and zero if we shouldn't remove i from permutation p.

Let's a1, a2, ..., an - k — numvers, which we should remove. It is clear to understand that we should remove these number in increasing order. It is simple to proof this statement.

Let's iterate i from to 1 to n. Also we the current number we will have special set (set <>in с++, TreeSet in Java) of positions of non-erased numbers (which are smaller then i) of permutation. These position can create an ``obstacle'' for current position of number i. It is simple to support this special set. Also we can add to this set numbers  - 1 and n. Now it is easy to find length og the maximal sub-array, where current number is a minimum. You can prosess such query by using standart functions of programming language (lower and higher in Java). After that we should use Fenwick tree to determine quantity of numbers which are not removed on the maximal sub-array.

The complexity is:  time / O(n) memory.

Very simple implementation on Java: 5850986

Codeforces Round #226 (Div. 2) — Editorial

By CleRIC, 9 years ago, translation, In English 385A - Bear and Raspberry

In this task required to understand that the answer max(a[i] - a[i - 1] - c),i = 2..n and don't forget that the answer not negative as Bear can not borrow in the debt barrel of honey.

385B - Bear and Strings

In this problem you could write a better solution than the naive. To do this, you can iterate through the first cycle of the left index l considered substring and the second cycle of the right index r considered substring (l ≤ r). If any position has been substring "bear", means all the strings x(l, j) (i ≤ j), also contain "bear" as a substring. So we can add to the answer |s| - j + 1 and exit from the second cycle. Also needed to understand, that if the string x(l, j) was not a substring "bear", then in row x(l, j + 1) substring "bear" could appear only in the last four characters.

385C - Bear and Prime Numbers

In order to solve given problem, contestant should solve several subproblems :

1) First one is to compute amount of entries of each natural number between 2 and 107 in given list. This subproblem can be solved by creating array count of 107 elements and increasing corresponding element when scanning input.

2) Second one is to compute f(n).

First of all, we need to find all primes less than 107 and then for each prime n compute f(n).

How to compute f(2)? We should sum count[2],count[4],count[6],count[8],...

How to compute f(5)? We should sum count[5],count[10],count[15],count[20],...

How to compute f(n)? We should sum count[n],count[2·n],count[3·n],count[4·n],...

It can be seen that given algo is very similar to Sieve of Eratosthenes. (Info here http://e-maxx.ru/algo/eratosthenes_sieve) So we can use this algo if we change it a little bit. Also, we will store results of calculation in array, e.g. pre. Namely, pre[n] = f(n).

3) Now we can calculate partial sums of pre array. It can be made in a single pass just adding pre[i - 1] to pre[i].

4) If we know partial sums of array then we can calculate sum of array elements between l and r in time proportional O(1), just calculate pre[r] - pre[l - 1].

5) Now we can read queries and immediately response to them. You shouldn't forget that right boundaries of intervals can be greater than 107, so you can always decrease it to 107, because all numbers in given list are less than 107.

385D - Bear and Floodlight

In this task, it is crucial to understand that whether there is lighted part of road with length dist then next part should be lit in a such way that leftmost lighted point is touching with dist.

Let's suppose that road is lit from l to d. How we can find rightmost point on X axis that would be lit by next floodlight?

We can just use concepts of vector and rotation matrix.

Let's find vector (dx, dy) from floodlight to point on X axis (d, 0). (dx, dy) = (d - x, 0 - y).

Next point to rotate vector by angle degrees. We can use rotation matrix for this purpose.

(dx, dy) = (dx·cos(angle) - dy·sin(angle), dx·sin(angle) + dy·cos(angle))

Next, we should make second component dy of (dx, dy) equal to 1 by multiplying on coefficient k.

Now we can determine rightmost lighted point of X axis. It is x - y·dx.

You shouldn't forget that there is possibility for rightmost point to be infinitely far point.

From now on we can forget about geometry in this task.

Let's find fast way to determine optimal order of floodlights.

To achieve this goal, we can use dynamic programming approach. Namely, let's calculate answer for subsets of floodlights. Each subset would be represented as integer where k bit would be 1 if k floodlight is presented in subset and 0 if it is not, i.e. so named binary mask.

For example, dp[6] — (6 — 1102) is optimal answer for subset from 2 and 3 floodlight.

Now, let's look through subsets i in dp[i]. In subset i let's go through absent floodlights j and update result for subset where j floodlight is present, i.e. dp[ i or 2j ] = max(dp[ i or 2j], dp[ i ] + calc_rightmost_lighted_point() ). As we can calculate rightmost lighted point, so updating of answer shouldn't be a problem.

385E - Bear in the Field

In this task there are several problems that should be concerned:

1) Simple modeling of bear movement would cause TLE due to t  ≤  1018.

2) Task can't be solved by separating x and y axes because x and y depends on each other.

3) Also, we can't use standart method of cycle finding via modeling for a short time and checking on collisions because coordinates limitations are very large.

Let's say we have matrix (xi, yi, dxi, dyi, ti, 1).

If we multiply previous matrix by following matrix long long base[6][6] = {

{2,1,1,1,0,0},

{1,2,1,1,0,0},

{1,0,1,0,0,0},

{0,1,0,1,0,0},

{0,0,1,1,1,0},

{0,0,2,2,1,1} };

we will have get parameters on next step.

Where did the matrix? Let us write out how to change parameters with each step and see the similarity matrix.

x = 2·x + 1·y + 1·dx + 0·dy + 0·t + 0·1.

y = 1·x + 2·y + 0·dx + 1·dy + 0·t + 0·1.

dx = 1·x + 1·y + 1·dx + 0·dy + 1·t + 2·1.

dy = 1·x + 1·y + 0·dx + 1·dy + 1·t + 2·1.

t = 0·x + 0·y + 0·dx + 0·dy + 1·t + 1·1.

1 = 0·x + 0·y + 0·dx + 0·dy + 0·t + 1·1.

So if we calculate t - 1 power of base and then multiply (sx, sy, dx, dy, t, 1) by it we will calculate parameters at moment t.

Power of matrix can be calculated via binary power modulo algo due to associativity of matrix multiplication. More info at http://e-maxx.ru/algo/binary_pow

Using trivial matrix multiplication algo we will solve this task in time proportional 63·log(t).

Codeforces Round #225 — Editorial

By fchirica, 9 years ago, In English 384A - Кодер Usually, when you don’t have any idea how to approach a problem, a good try is to take some small examples.

So let’s see how it looks for N = 1, 2, 3, 4 and 5. With C I noted the coder and with * I noted an empty cell.

 

By now you should note that answer is N ^ 2 / 2 when N is even and (N ^ 2 + 1) / 2 when N is odd. Good. Generally, after you find a possible solution by taking examples, you need to prove it, then you can code it.

In order to proof it, one needs to do following steps:

1/ prove you can always build a solution having N ^ 2 / 2 (or (N ^ 2 + 1) / 2) pieces.

2/ prove that N ^ 2 / 2 (or (N ^ 2 + 1) / 2) is maximal number – no other bigger solution can be obtained.

For proof 1/ imagine you do coloring like in a chess table.

 

The key observation is that by placing all coders on black squares of table, no two coders will attack. Why? Because a piece placed at a black square can attack only a piece placed at a white square. Again, why? Suppose chess table is 1-based. Then, a square (i, j) is black if and only if i + j is even. A piece placed at (i, j) can attack (i + 1, j), (i – 1, j) (i, j + 1) or (i, j – 1). The sum of those cells is i + j + 1 or i + j – 1. But since i + j is even, i + j + 1 and i + j – 1 are odd, hence white cells.

Depending on parity of N, number of black cells is either N ^ 2 / 2 or (N ^ 2 + 1) / 2. For N even, one can observe that there are equal amount of black and white cells. Total number of cells is N ^ 2, so number of black cells is N ^ 2 / 2. For N odd, number of black cells is number of white cells + 1. We can imaginary add a white cell to the board. Now, number of black cells will be also equal to number of white cells, so answer is (N ^ 2 + 1) / 2.

2/ Two coders attack each other if they are placed at two adjacent cells, one black and other one white. One needs to prove that adding more than number from 1/ will cause this to happen. If you place a coder at a white cell, you won’t be able to place at least one coder at a black cell, so in best case you don’t win anything by doing this. Hence, it’s optimally to place all coders on same color cells. Since cells colored in black are always more or equal to white ones, it’s always optimally to choose black color. But number from 1/ is the number of cells having black color. Adding one more piece will force you to add it to a white color cell. Now, you’ll have a piece placed at a black colored cell and one placed at an adjacent white colored cell, so two coders will attack. Hence, we can’t place more than number from 1/ pieces.

Code: http://pastie.org/8651801

384B - Мультизадачность Let’s start by saying when array A[] is sorted:

1/ is sorted in ascending order when i < j and A[i] <= A[j]. It is NOT sorted when i < j and A[i] > A[j].

2/ is sorted in descending order when i > j and A[i] <= A[j]. It is NOT sorted when i > j and A[i] > A[j].

Iahub can choose 2 indices i, j and swap values when A[i] > A[j]. If A[i] <= A[j], he’ll ignore operation. Hence, if he wants to sort all arrays in ascending order, he chooses indices i, j when i < j and perform operation. Otherwise, in all his operations he uses indices i, j such as i > j. A “good” operation is when choosing indices i < j for ascending order sorting and i > j for descending order sorting. By doing only good operations, after an array is sorted, it will stay sorted forever (for a sorted array, all good operations will be ignored).

From here we get our first idea: use any sorting algorithm you know and sort each array individually. When print swaps done by sorting algorithm chosen, print them as good operations. However, sorting each array individually can cause exceeding M * (M — 1) / 2 operations limit. Another possible solution would be, after you did an operation to an array, to update the operation to all arrays (you printed it, so it counts to M * (M — 1) / 2 operations limit; making it to all arrays will help sometimes and in worst case it won’t change anything). However, you need to code it very careful in order to make this algorithm pass the time limit. Doing this in a contest is not the best idea, especially when implementation could be complicated and you have no guarantee it will pass time limit.

So what else can we do? We can think out of box. Instead of sorting specific N arrays, you can sort all possible arrays of length M. Find a sequence of good operations such as, anyhow I’d choose an array of size M, it will get sorted ascending / descending.

I’ll show firstly how to do for ascending sorting. At position 1 it needs to be minimal element. Can we bring minimal element there using good operations? Yes. Just do “1 2” “1 3” “1 4” ... “1 M”. It basically compares element from position 1 to any other element from array. When other element has smaller value, swap is done. After comparing with all M elements, minimal value will be at position 1. By now on I’ll ignore position 1 and move to position 2. Suppose array starts from position 2. It also needs minimal value from array, except value from position 1 (which is no longer in array). Hence doing “2 3” “2 4” “2 5” ... “2 M” is enough, by similar reasons. For a position i, I need minimal value from array, except positions 1, 2, ..., i – 1. I simply do “i i+1” “i i+2” ... “i M-1” “i M”. By arriving at position i, array will be sorted ascending. The algorithm is simply:

for (int i = 1; i < M; ++i)

for (int j = i + 1; j <= M; ++j)

cout << i << “ “ << j << “\n”;

This algorithm does exactly M * (M — 1) / 2 moves.

Can you find out how to sort array in descending order? Try to think yourself, then if you don’t get it read next. At first position of a descending array it needs to be maximal value. Similarly to ascending order, we can do “2 1” “3 1” “4 1” ... “M 1”. When I’m at a position i and I compare its value to value from position 1, doing operation “i 1” checks if A[i] > A[1]. If so, it swaps A[i] and A[1], so position 1 will contain now the maximum value so far. Similarly to logic from ascending order, when I’m at position i, I need maximum value from array except positions 1, 2, ..., i – 1, so I do “i+1 i” “i+2 i” ... “M i”. Algorithm is:

for (int i = 1; i < M; ++i)

for (int j = i + 1; j <= M; ++j)

cout << j << “ “ << i << “\n”;

Obviously, this does as well M * (M — 1) / 2 operations worst case. All algorithm is about 10 lines of code, much better than other solution, which requires two manually sorts and also has a chance to exceed TL.

Code: http://pastie.org/8651809

384C - Доим коров A good strategy to approach this problem is to think how optimal ordering should look like. For this, let’s calculate for each 2 different cows i and j if cow i needs to be milked before or after cow j. As we’ll show, having this information will be enough to build optimal ordering. It is enough to consider only cases when i < j, case when i > j is exactly the opposite of case i < j. For formality, I’ll call the optimal ordering permutation and lost milk the cost of permutation.

So, for an optimal permutation P let’s take 2 numbers i < j and see in which cases i should appear before j in permutation (i is before j if P[pos1] = i, P[pos2] = j and pos1 < pos2; otherwise we’ll call i is after j). We have 4 possible cases:

1/ A[i] = 0 and A[j] = 0

If we put i before j, no additional cost will be added. Since j is in right of i and i only adds cost when it finds elements in left of i, j won’t be affected when processing i. When processing j, i will be already deleted so it won’t affect the cost either. Hence, we can put i before j and no cost will be added.

2/ A[i] = 0 and A[j] = 1

Here, i and j can appear in arbitrary order in permutation (i can be before or after j). No matter how we choose them, they won’t affect each other and cost will remain the same.

3/ A[i] = 1 and A[j] = 0

As well, here i and j can appear in arbitrary order. If we choose i first, j will be in right of it, so cost of permutation will increase by one. If we choose j first, i will be in left of it so cost of permutation will increase as well. No matter what we do, in this case cost of permutation increases by 1.

4/ A[i] = 1 and A[j] = 1

Here, i needs to be after j. This adds 0 cost. Taking i before j will add 1 cost to permutation (since j is in right of i).

Those 4 cases show us how a minimal cost permutation should look. In a permutation like this, only case 3/ contributes to final cost, so we need to count number of indices i, j such as i < j and A[i] = 1 and A[j] = 0 (*). If we show a permutation following all rules exists, task reduces to (*).

By cases 2/ and 3/ it follows that in an optimal permutation, it only matters order of elements having same value in A[]. We can put firstly all elements having value 0 in A[], then all elements having value 1 in A[]. We can order elements having value 0 by case 1/ and elements having value 1 by case 4/. More exactly, suppose i1 < i2 < ... < im and (A[i1] = A[i2] = ... = A[im] = 0) and j1 > j2 > ... > jn (A[j1] = A[j2] = ... = A[jn] = 1). Then, a permutation following all rules is {i1, i2, ..., im, j1, j2, ..., jn}. This permutation can always be built.

Hence, task reduces to (*): count number of indices i, j such as i < j and A[i] = 1 and A[j] = 0. We can achieve easily an O(N) algorithm to do this. Let’s build an array cnt[j] = number of 0s in range {j, j + 1, ..., N} from array A. We can easily implement it by going backwards from N to 1. The result is sum of cnt[i], when A[i] = 1.

Code: http://pastie.org/8651813

384D - Вулканы Our first observation is that if there is a path from (1, 1) to (N, N), then the length of path is 2 * N – 2. Since all paths have length 2 * N – 2, it follows that if there is at least one path, the answer is 2 * N – 2 and if there isn’t, the answer is -1. How to prove it? Every path from (1, 1) to (N, N) has exactly N – 1 down directions and exactly N – 1 right directions. So, total length for each path is N – 1 + N – 1 = 2 * N – 2.

So we reduced our problem to determine if there is at least one path from (1, 1) to (N, N). This is the challenging part of this task, considering that N <= 10 ^ 9. How would you do it for a decently small N, let’s say N <= 10^3 . One possible approach would be, for each row, keep a set of reachable columns. We could easily solve this one by doing this: if (i, j) denotes element from ith row and jth column, then (i, j) is (is not) reachable if:

if (i, j) contains a volcano, then (i, j) is not reachable. Otherwise, if at least one of (i – 1, j) and (i, j – 1) is reachable, then (i, j) is reachable. Otherwise, (i, j) is not reachable.

What’s the main problem of this approach? It needs to keep track of 10^9 lines and in worst case, each of those lines can have 10^9 reachable elements. So, worst case we need 10^9 * 10^9 = 10^18 operations and memory.

Can we optimize it? We can note for beginning that we don’t need to keep track of 10^9 lines, only m lines are really necessarily. We need only lines containing at least one obstacle (in worst case when each line contains only one obstacle, we need m lines). How to solve it this way? Suppose line number x contains some obstacles and lines x + 1, x + 2, x + 3 do not contain any obstacle. Suppose we calculated set S = {y | cell (x, y) is reachable}. How would look S1, S2, S3 corresponding to lines x + 1, x + 2, x + 3? For S1, we can reach cell (x + 1, ymin), where ymin is minimal value from set S. Then, we can also reach {ymin + 1, ymin + 2, ..., N}, by moving right from (x + 1, ymin). So S1 = {ymin, ymin + 1, ..., N}. How do S2 and S3 look? It’s easy to see that they’ll be as well {ymin, ymin + 1, ..., N}. So we get following optimization: suppose set of lines containing at least one obstacle is {L1, L2, ..., Lk}. We need to run algorithm only for lines L1, L1 + 1, L2, L2 + 1, L3, L3 + 1, ..., Lk, Lk + 1.

It looks like we didn’t make anything with this optimization. Even if we calculate for m lines, each line can still have 10^9 reachable positions. So worst case we perform 10^14 operations. We need something better for managing information from a line. You can note that for a given line y, there are a lot of positions having consecutive values. There are a lot of positions (x, y) and (x, y + 1) both reachable. This should give us following idea: what if instead of keeping reachable positions, we keep reachable ranges? That is, for each line x we keep a set of ranges S = {(a, b) | all cells (x, k) with a <= k <= b are reachable}.

How many ranges can it be for a line? If the line contains m obstacles, there are m + 1 ranges. Suppose for line x all cells are reachable, but for line x + 1 cells (x + 1, 3) (x + 1, 5) (x + 1, N – 1) are blocked. Then, the ranges of reachable cells are [1, 2] [4, 4], [6, N – 2] and [N, N]. By now, we get worst case m lines and worst case each line having m elements, so in worst case we’d have to handle m * m = 10 ^ 10 events. This may still look too much, but happily this bound is over estimated. If a line has o obstacles, there can be at most o + 1 ranges. If lines L1, L2, ..., Lk have {o1, o2, ..., ok} obstacles, there’ll be at most o1 + o2 + ... + ok + k ranges. But o1 + o2 + ... + ok = m and also k is at most m (proved above why we’re interested in at most m lines), so in worst case we get m + m = 2 * m ranges. Yaay, finally a decent number of states for this problem :)

So, we iterate each line we’re interested in. Let’s find set of ranges for this line, thinking that all cells from line above are reachable. This is easy to do. After we get our ranges like all cells from above can be visited, let’s think how having obstacles above can influence current ranges. After adding ranges from above, current ranges can’t increase (obviously), they can only decrease, remain the same or some of them can become empty. So, let’s take each range [a, b] from current line and see how it will transform after adding ranges from previous line.

Given range [a, b], it can transform only in [a’ , b] with a’ >= a. If a’ > b, then obviously range is empty. Why second number of range keeps constant? Let a’ smallest reachable column from current line which is in range [a, b]. It’s enough to check a’ >= a, as if a’ > b, range will be empty. It’s obviously why we need to keep a’ smallest value possible >= a: we’re interested to keep range as big as possible and as less as we cut from left, as big it is. Once we’ve found a’ in range [a, b] (or a’ > b if range is empty) all cells {a’ + 1, a’ + 2, ..., b} are reachable as well by going right from a’, so if interval is not empty, then second number defining it remains b.

Next question is how to find a’ fast enough. In order a point a’ to be reachable on current range, it also needs to exist a range on previous line containing it. If the range from previous line is [pa, pb] then a’ needs to follow 3 conditions:

a’ minimal such as

pa <= a’ <= pb

a’ >= a

What if instead of finding a’ we find [pa, pb]? Then a’ is max(pa, a). In order a’ to be as small as possible, since a is constant, pa needs to be as small as possible. So we reduced it to:

pa minimal pb >= a’ >= a <=> pb >= a

Intervals from previous line are disjoint, no 2 intervals cross each other. It means that if pb is minimal, than pa is minimal too (if we increase pb, then pa will increase too, so it won’t be minimal). Hence, you need to find an interval [pa, pb] such as pb is minimal and pb >= a. Then, a’ is max(a, pa). This is easy to do if we sort all intervals from previous line increasing by second value (pb), then we binary search for value a.

Finally, after running algorithm for all lines, last range from last line has second number N (assuming ranges are sorted increasing by second value), then there exist a path, otherwise there does not exist. This algorithm should run O(m * logm) worst case, good enough to pass.

Code: http://pastie.org/8651817

384E - Дерево подвижных сумм This is kind of task that needs to be break into smaller subproblems that you can solve independently, then put them together and get solution.

Let’s define level of a node the number of edges in the path from root to the node. Root (node 1) is at level 0, sons of root are at level 1, sons of sons of root are at level 2 and so on.

Now suppose you want to do an operation of type 1 to a node x. What nodes from subtree of x will be added +val (a positive value)? Obviously, x will be first, being located at level L. Sons of x, located at level L + 1 will be added –val. Sons of sons, located at level L + 2, will be added value +val again. So, nodes from subtree of x located at levels L, L + 2, L + 4, ... will be added a +val, and nodes located at levels L + 1, L + 3, L + 5 will be added a –val. Let’s take those values of L modulo 2. All nodes having remainder L modulo 2 will be added a +val, and nodes having reminder (L + 1) modulo 2 will be added –val. In other words, for a fixed x, at a level L, let y a node from subtree of x, at level L2. If L and L2 have same parity, +val will be added to y. Otherwise, -val will be added to y.

From here we have the idea to split nodes of tree in 2 sets – those being located at even level and those being located at odd level. What still makes the problem hard to solve? The fact that we have a tree. If nodes from a subtree would be a contiguous sequence instead of some nodes from a tree, problem would be simpler: the problem would reduce to add / subtract values to all elements of a subarray and query about a current value of an element of array. So, how can we transform tree to an array, such as for a node x, all nodes from subtree of x to be a subarray of array?

The answer is yes. We can do this by properties of DFS search. Before reading on, make sure that you know what is discovery time and finish time in a DFS search. Let’s build 3 arrays now – discover[], representing nodes in order of their discover times (a node is as before in discover as it has a small discover time), begin[] = for a node, in which time it was discovered and end[] = what’s last time of a discovered node before this node finishes. For a subtree of x, all nodes in the subtree are nodes in discover from position begin[x] to end[x].

Example: suppose you have tree 1-5; 1-6; 6-7; 6-4; 4-2; 4-3

Discover is {1, 5, 6, 7, 4, 2, 3}.

begin is {1, 6, 7, 5, 2, 3, 4}.

end is {7, 6, 7, 7, 2, 7, 4}.

What’s subtree of node 6? elements of discover from position begin[6] to end[6]. In this case, from 3 to 7, so elements {6, 7, 4, 2, 3}. You can see it’s correct and take more examples if you want :)

Now, we reduced problem to: you’re given an array A. you can perform 2 operations:

1/ increase all elements from a range [x, y] to a value val (val can be negative, to treat subtractions)

2/ what’s current value of an element from position pos.

Those who solved “Iahub and Xors” from my last round, CF 198, should probably say they saw something similar before. If you didn’t solve problem before, I encourage you to do it after you solve this one, it uses a similar idea to what will follow now. Also, if you don’t know Fenwick trees, please read them before moving on. An alternative would be for this task using segment trees with lazy update, but I see this one more complicated than needed.

I’ll use now a not so common approach when dealing with data structures. Instead of keeping in a node the result, like you usually do, I’ll keep just an auxiliary information. So what algorithm proposed does:

Let A an array, initially with all elements 0.

When you need to update range [x, y] with value val, you simply do A[x] += val and A[y + 1] -= val.

When you need to answer a query about position pos, you output A[1] + A[2] + ... + A[pos].

Implemented brute force, you get O(1) per update and O(N) per query. However, these both are operations supported by a Fenwick tree, so you can get O(logN) per operation.

It may not be very clear why this algorithm works. Let’s take a closer look: an update needs to add value val only to range [x, y]. When you query a position pos, let’s see if algorithm handles it correctly:

1/ pos < x. In this case, result must not be affected by my update. Since pos < x and I only updated 2 values with indices >= x, when doing A[1] + A[2] + ... + A[pos] it won’t matter at all I did that update – at least not for this query.

2/ x <= pos <= y. Here, for a pos, I need to add value val only once. We add it only at A[x] – in this way it will be counted once, and it will be considered for each elements from range [x, y] (since an element at position p from range [x, y] has p >= x, in A[1] + A[2] + ... + A[p] I’ll have to consider A[x]).

3/ pos > y. Here I don’t have to consider the query. But it would be considered when processing A[x]. But if I add to A[y + 1] value –val I’ll just cancel the value previously added.

Code (actually we use just one Fenwick tree instead of 2, can you think why it works? :) ) : http://pastie.org/8651824

383D - Антиматерия Author's solution The problem is: given an array, iterate all possible subarrays (all possible elements such as their indexes are consecutive). Now, for a fixed subarray we need to know in how many ways we can color its elements in black and white, such as sum of black elements is equal to sum of white elements. The result is sum of this number, for each subarray.

Let’s solve an easier problem first. This won’t immediately solve the harder version, but it will be useful later. Suppose you’ve fixed a subarray. In how many ways can you color it with black and white? Suppose subarray has N elements and sum of them is M. Also, suppose for a coloring, sum of blacks is sB and sum of whites is sW. For coloring to be valid, sB = sW. But we also know that sB + sW = M (because each element is colored by exactly one color). We get that 2 * sB = M, so sB = M / 2. The problem is now: in how many ways can we color elements in black such as sum of blacks is M / 2 (after we fix a black coloring, we color with white non colored elements; sum of white colored elements is also M / 2). This is a well known problem: Knapsack problem. Let ways[i][j] = in how many ways one can obtain sum j from first i elements. When adding (i + 1) object, after ways[i] is calculated, for a fixed sum j we can do 2 things: add (i + 1) object to sum j or skip it. Depending of what we chosen, we add value ways[i][j] to ways[i + 1][j + value[i + 1]] or to ways[i + 1][j]. The result is in ways[N][M / 2]. This works in O(N * M) time.

An immediate solution can be obtained now: take all subarrays and apply above approach. This leads to an O(N ^ 2 * M ^ 2) solution, which is too much. One can reduce complexity to O(N ^ 2* M) by noting that processing subarray [i, j] can be done with already calculated values for subarray [i, j – 1]. Hence, instead of adding N elements, it’s enough to add 1 element to already calculated values (element from position j). Sadly, O(N ^ 2 * M) is still too slow, so we need to find something better. The solution presented below will look forced if you didn’t solve some problems with this technique before. It’s hard to come with an approach without practicing this kind of tasks. But don’t worry, as much as you practice them, as easily you’ll solve those problems.

We’ll solve task by divide and conquer. Complexity of this solution is O(N * M * logN). Let f(left, right) a function that counts number of colorings for each subarray [i, j], such as subarray [i, j] is included in subarray [left, right] (left <= i <= j <= right). Answer is in f(1, N). The trick is to define a value med = (left + right) / 2 (very frequent trick in divide and conquer problems, called usually a median). We can next classify [i, j] subarrays in 3 types:

1/ i <= med j <= med

2/ i > med j > med

3/ i <= med j > med

We can solve 1/ and 2/ by calling f(left, med) and f(med + 1, right). The remained problem is when i <= med and j > med. If we solve 3/ in O((right – left) * M) time, this will be enough to overall achieve O(N * M * logN) (for this moment trust me, you’ll see later why it’s so :) ).

Let’s denote by i1 last i1 elements from subarray [left, med]. Also, let’s note by i2 first i2 elements from subarray [med + 1, right]. For example, let left = 1 and right = 5, with array {1, 2, 3, 4, 5}. med is 3 and for i1 = 2 and i2 = 1, “left” subarray is {2, 3} and “right” subarray is {4}. By iterating i1 from 1 to med – left + 1 and i2 from 1 to right – med and then unite subarrays i1 and i2, we obtain all subarrays described in 3/ . Let’s denote by j1 sum of a possible black coloring of i1. Similarly, j2 is sum of a possible black coloring of i2.

Suppose we fixed i1, i2, j1 and j2. When it’s the coloring valid? Let S sum of united subarrays i1 and i2 (S = value[med – i1 + 1] + value[med – i1 + 2] + ... + value[med] + value[med + 1] + ... + value[med + i2 – 1] + value[med + i2]). Now it’s time to use what I explained at the beginning of solution. The coloring is good only when j1 + j2 = S / 2. We can rewrite the relation as 2 * (j1 + j2) = sum_of_elements_from_i1 + sum_of_elements_from_i2. We can rewrite it even more:

2 * j1 + 2 * j2 — sum_of_elements_from_i1 — sum_of_elements_from_i2 = 0

2 * j1 – sum_of_elements_from_i1 = sum_of_elements_from_i2 – 2 * j2 = combination_value

This relation is the key of solving problem. You can see now that relation is independent in “left” and “right” side. We calculate left[i1][j1] and right[i2][j2] = in how many ways can I obtain sum of blacks j1 (j2) from first i1 (i2) from left (right) side. Let’s calculate also count[value] = in how many ways can I obtain combination_value equal to value in the right side. For some fixed (i2, j2) I add to count[sum_of_elements_from_i2 – 2 * j2] value right[i2][j2]. In this way count[] is calculated correctly and completely. Now, let’s fix a sum (i1, j1) in the left side. We’re interested how many good colorings are such as there exist a coloring of j1 in i1 elements (the endpoint of “left” is fixed to be i1 and I need to calculate endpoints i2 for right, then to make colorings of i2). A coloring is good if combination_value of (i1, j1) and (i2, j2) is equal. Hence, I need to know in how many ways I can color i1 elements to obtain sum j1 and also I need to know in how many ways I can color elements from right to obtain same combination_value as it’s in the left. It’s not hard to see that answer for a fixed (i1, j1) is left[i1][j1] * count[2 * j1 – sum_of_elements_from_i1]. This takes O((right – left) * M) time.

The only thing remained in the problem is to see why complexity is O(N * M * logN). We can assume N is a power of 2 (it not, let’s round N to smallest power of 2 bigger than N; complexity for N is at least as good as complexity for this number). Draw a binary complete tree with N nodes. Each node corresponds to an appeal of f(). For a level, exactly O(N * M) operations are performed. To see why:

For level 1, there’ll be 1 node performing N * M operations.

For level 2, there’ll be 2 nodes performing (N / 2) * M operations. Summing up we get O(N * M).

For level 3, there’ll be 4 nodes performing (N / 4) * M operations. Summing up we get O(N *M) as well.

and so on.

So for each level we perform O(N * M) operations. A binary complete tree has maximum O(logN) levels, so overall complexity is O(N * M * logN).

Code: http://pastie.org/8651826

Solution fount by contestants This was totally unexpected to us :) Good job finding it, you guys are really smart.

We observe that x units of antimatter is the same thing as -x units of matter. Then we can consider that an element produces either x or -x units of matter. A valid substring is one that can have the sum of the elements 0. The problem is reduced to finding how many different substrings can we have with sum 0 (a substring is different than another one if it has different indices, or if at least one element produces matter in one and antimatter in the other).

This problem can be solved with dynamic programming. We will hold D[i][j] = the number of substrings that end in element i, and have sum j. It's easy to see that D[i + 1][j] = D[i][j — x] + D[i][j + x], where x is the value of the current element (we can put either -x or x). After we finish computing all the values for current i, we add to the solution D[i][0] (how many valid substrings do we have). After that, we add 1 to D[i][0], meaning that there is an empty substring starting at position i (however, we don't need to add it to the answer).

For a code, check passing submissions during contest.

383E - Гласные Author's solution Let's iterate over all possible vowel sets. For a given set {x1, x2, ..., xk} we're interested in number of correct words from dictionary. After a precalculation, we can do it in O(k).

Suppose our current vowel set is {x1, x2, ..., xk}. How many words are covered by the current vowels? By definition, we say a word is covered by a set of vowels if at least one of 3 letters of word is in vowel set. We can calculate this number using principle of inclusion and exclusion. We’ll denote by |v1, v2, v3, ...| = number of words containing ALL of vowels v1, v2, v3, ... . Using principle of inclusion and exclusion we get:

number_of_words_covered = |x1| + |x2| + .. + |xk| — |x1, x2| — |x1, x3| — .... + |x1, x2, x3| + |x1, x2, x4| + .... + |xk-2, xk-1, xk|. This formula is simply a reformulation of principle of inclusion and exclusion. You can easily observe that |v1, v2, ..., vk| makes sense only when k is at most 3, as no word from input can contain 4 or more letters (and hence can’t contain 4 or more vowels).

Example:

Suppose words are abc, abd and bcd.

|a| = 2 (first 2 words both contain character a).

|a, b| = 2 (as well, first 2 words contain characters a and b).

|b| = 3 (all 3 words contain character b).

|a, b, d| = 1 (only second word contains all 3 characters).

Also, note how principle of inclusion and exclusion works. number of words covered for vowels {a, b} is |a| + |b| — |a, b| = 2 + 3 – 2. Indeed, answer is 3.

We divide our problem in 3 subproblems. First one, for a vowel set, compute sum of |a|, where a is a letter from subset. Second, compute sum of |a, b|, where both a and b are letters from set. Third, compute sum of |a, b, c|, where a, b, c are letters from set. As stated, the answer is number_from_1st_step + number_from_3rd_step – number_from_2nd_step. If you followed me, you’ll see that we want to compute results for each subproblem in O(queryLetters).

First subproblem can be solved trivially in O(queryLetters). Let array single[], with following meaning: single[c] is how many words contain character c. It can be trivially precomputed in O(24 * N). Note that if a word contains twice/third times a character c, it needs to be counted only one (e.g. word aba will add only 1 to single[a]). For compute result of this subproblem for a given set of vowels, I’ll take all letters from set. If letter belongs to set, I add to result single[letter]. This step can be also be solved in O(1), but there’s no need, since other subproblems allow only an O(queryLetters) solution.

For second and third subproblems it’s a little more difficult. I’ll present here how to solve second subproblem and some hints for third one (if you understand second, with hints you should be able to solve third one by your own).

Similarly to first step, I’ll define a matrix double[c1][c2] = how many words contain both characters c1 and c2. A trivially solution would be, for a given vowel set, take all combinations of letters c1 and c2 that belong to set and add to result value double[c1][c2]. However, this solves each query in O(queryLetters^2), which is too slow.

Note, if we’d have 12 letters, instead of 24, this approach would be fast enough. From here it comes a pretty classical idea in exponential optimization: meet in the middle attack. We split those 24 letters in 2 groups: first 12 letters and last 12 letters. The answer for a subset is sum of double[c1][c2] (when c1 and c2 belong to current vowel set) when

1/ c1 and c2 belong to first 12 letters

2/ c1 and c2 belong to last 12 letters

3/ c1 belongs to first 12 letters and c2 belongs to last 12 letters

1/ and 2/ can be immediately precalculated as stated above, in O(2 ^ 12 * 12 ^ 2). We’ll remember results for each half using bitmasks arrays. Let Half1[mask] = sum over double[c1][c2], when c1 and c2 are in first 12 letters and correspond to 1 bits of mask. Half2[mask] is defined similarly, but for last 12 letters (e.g. subset {a, c, d} corresponds to bitmask 2^0 + 2^2 + 2^3 = 13 in first half and subset {m, n, p} corresponds to bitmask 2^0 + 2^1 + 2^3 = 11 for second half). Now, for a given subset, one can answer first 2 parts in O(queryCount) worst case (read input for a query and convert it to bitmasks).

How to answer 3? With another precalculation, of course. We know c1 letter needs to be in first 12 letters and c2 needs to be in last 12 letters. The precalculation we do here is: mixed_half[mask][i] = sum over |c1, c2|, when c1 belongs to first half and is a 1 bit of mask and c2 is i-th character of second half. Hence, for a query, we can fix character from second half (c2, by iteration of query letters from second half) and know sums of |c1, c2| between it and all available characters from first half after we do this precalculation. Also, precalculation is done trivially in O(2 ^ 12 * 12^2): fix mask, fix i and then iterate over 1 bits from mask and add double[c1][c2].

Third subproblem is left, but it can be done similarly to second one. Instead of double[c1][c2], we’ll have triple[c1][c2][c3] = how many words contain all 3 characters c1, c2 and c3? We also do meet in the middle here, divide those 24 letters into 2 sets of 12 letters. We have 4 cases:

1/ c1, c2, c3 belong to first half

2/ c1, c2, c3 belong to second half

3/ c1, c2 belong to first half and c3 to second half

4/ c1 belongs to first half and c2, c3 to second half

1/ and 2/ are done brute force, like in second subproblem (the only difference is we choose 3 characters instead of 2, having complexity O(2 ^ 12 * 12 ^ 3)). For 3/ and 4/ we also precompute 2 matrixes:

mixed_two_one[mask][i] = c1 and c2 belong to mask from first half and c3 is i-th character from second half

and

mixed_one_two[mask][i] = c1 is i-th character from first half and c2, c3 belong to mask from second half.

Those can also be calculated in O(2 ^ 12 * 12^3).

So precalculation part is O(2 ^ 12 * 12 ^ 3) = 7077888 operations.

For calculate answering queries complexity, take all numbers from 0 to 2^24 — 1 and sum their bit count. This is a well known problem, the sum is 0 * C(24, 0) + 1 * C(24, 1) + ... + 24 * C(24, 24) = 201326592. In total we get 208404480 operations. C++ source makes them in 2 seconds.

Code: http://pastie.org/8651829

Solution fount by contestants Like in D1 D task, official solution was over complicated. This solution is more simple to understand, code and it's more elegant. If someone wants to complicate his life, (s)he can code also official solution :)

Let's start by assigning a bitmask to each word in following way: ith bit is 1 if and only if letter ('a' + i) appears in the current word. For example, for word acd, its bitmask is 2^0 + 2^2 + 2 ^ 3 = 13 and for word aab its bitmask is 2^0 + 2^1 = 3. After reading the words from dictionary, we store a matrix cnt[mask] = how many words from dictionary correspond to mask?

We iterate bitmasks from 0 to 2^24 — 1, this time corresponding to each possible question of Iahubina. Let's focus on a bitmask X. We need to get sum of cnt[mask], when mask and X share at least one common bit having value 1 (formally (X AND mask) > 0). In order to do this, we need a reduction which may be not so obvious.

What if instead of counting all words containing at least one of vowels {w1, w2, ..., wk} we count all words which don't contain ANY of vowels {w1, w2, ..., wk}? Suppose this number is ret. Then, all words containing at least one of vowels is N — ret. From all words, we erase those words which do not contain any vowels from set {w1, w2, ..., wk} (and which obviously are wrong words). Obviously, it's left only words containing at least one vowel, so good words. Now, for a word not to contain any of vowels {w1, w2, ..., wk} it needs to contains ONLY vowels from set {"a", "b", "c", ..., "x"} \ {w1, w2, ..., wk} (set of allowed letters from which we erased vowels w1, w2, ..., wk}.

And this is reduction we needed. For a bitmask X we need to calculate sum of cnt[mask], where mask is a subset of X (we can set some bits from X from 1 to 0 in order to obtain mask). For a mask, let's keep this sum in res[mask]. We can calculate res array using divide and conquer.

Let's make a function solve(left, right), which completes array res in the way described above, if we consider only elements cnt[k] with left <= k < right (for simplicity, I'll consider elements which do not lie in this range to be equal to 0). Now we need to solve for a range [left, right]. Let's have in res1[] = solve(left, med) and in res2[] = solve(med, right), where med = (left + right) / 2. We need to put together res1[] and res2[] in order to obtain res[].

for (int i = left; i < med; ++i) res[i] = res1[i];

Numbers in [left, med] have most significant bit equal to 0. We can only keep it 0 and add what we calculated before. We can't add any element from res2[], because those elements have most significant bit equal to 1 and we're not allowed to change bit 0 into bit 1.

for (int i = med; i < right; ++i) res[i] = res1[i — med] + res2[i];

Here, most significant bit is 1. Adding res1[] corresponds to changing bit from 1 to 0, adding res2[] corresponds to leaving bit 1.

Of course, we need to threat the base case here, too. When left + 1 = right, res[left] = cnt[left]. We can keep only one array res[] instead of 3, I explained it this way only for simplicity. Also, there is no need for keeping separate arrays for res[] and cnt[], one can solve all task with only one array. In order to get res[], we simply call solve(0, 2^24).

Complexity of solution is O(2 ^ 24 * 24). I leave the proof homework, it's almost identical to complexity proof of D1 D "Author solution" (that with building a binary tree).

For a reference solution, check Endagorion's AC source during contest.

Codeforces Round #224 (Div. 2) Editorial

By HolkinPV, 9 years ago, translation, In English 382A - Ksenia and Pan Scales

This problem is just a technic problem. So, you should take weights one by one and place the current one into the side of the scales that contains lower number of weights. At the end you should output answer in the correct format.

382B - Number Busters

In the problem you should understand, what is the structure of Artur's operation. You can see that this operation is near operation (b + x) % w (To see that just apply b = w - b - 1). There is nothing hard to get the formula of changing a during the operation. So, if you have k operations, you can see, that b = (b + k·x) % w, a = a - (b + k·x) / w, c = c - k. When you've got all the formulas, you can solve the problem using binary search.

382C - Arithmetic Progression

This problem is about considering cases:

1) If n = 1, the answer is -1. Because of any two numbers is arithmetical progression. 2) If array is constant, the answer if that constant. 3) If you have arithmetical progression initially, you can compute its difference d. In this case you should just to output minVal - d, and maxVal + d, where minVal is minimum value among a[i], and maxVal is maximum value among a[i]. But in case of n = 2, also you should check (a[0] + a[1]) / 2. If this number is integer, it is needed to be output. 4) Else, the answer has at most one integer. You find this integer you should sort the sequence, and find the place where the number is missed. If such a place exists you should add the corresponding number to the sequence, else, the answer is 0. 5) In all other cases the answer is 0.

382D - Ksenia and Pawns

In this problem from every cell except # there is one next cell. That's why this graph is almost functional graph. If this graph contains a cycle, then answer is -1 because the length of the cycle is at least two.

In the other case, there are no cycles in the graph. Let's find the longest path in it, denote is as len. Then is answer is at least 2·len - 1 because we can put the two pawns in the first two cells of this path.

But in some cases we could get the answer 2·len if there are two non-intersecting by vertices (not #) paths of length len. They are non-intersecting because if they intersect in some cell then they will be equal to the end (and the statement says that such moves are invalid).

So, we should check if the graph contains two non-intersecting by vertices (not #) paths of length len. It could be done in any way. For example, using dfs searches.

382E - Ksenia and Combinatorics

In this problem you should count trees with some properties. It can be done using dynamic programming. The main idea is that the maximum mathing in tree can be found using simple dynamic dp[v][used] (v -- vertex, used — was this vertex used in matching). So you should to count the trees tou should include in state of the dynamic values dp[v][0]$ and dp[v][1].

In other words, you should use dynamic programming z[n][dp0][dp1] — number of rooted trees with n vertices and values of dynamic in root dp[root][0] = dp0 and dp[root][1] = dp1. But in simple implementation this solution will get TL. There are two ways to get AC. The first is to opltimize code and make precalc. The second is to optimize asymptotics.

The author's solution uses the second way. To optimize solution you should mark that values dp0 and dp1 differs at most by one. That is dp0 = dp1, or dp0 = dp1 + 1. So the first dynamic becomes r[n][dp0][add]. Another optimization is there are not so many triples (n, dp0, add) with non-negative values (about 250), so you can you use lazy programming to calculate this dynamic.

Comments that describe other solutions:

Codeforces Round #223 — Tutorial

By Sereja, 9 years ago, translation, In English 381A - Sereja and Dima Simply do the process described in the statment.

381B - Sereja and Stairs Calculate the amount of each number. For all the different numbers — maximum possible times of use isn't more than 2 times. For the maximum is is only — 1.

380A - Sereja and Prefixes Generate the first number 100000. Will in turn handle the requests, if the request gets to the point of adding one number, just print it. Otherwise see what element will meet our and just print it from precalculated array.

380B - Sereja and Tree Lets generate a tree as described in the statment. For each request to add items we just add a segment for a certain level. At the request of the number of items we just go through all the lower levels, considering the leftmost and the rightmost vertex in the subtree. To each level will take all intervals that it owns and for each check — whether it intersects with the interval that we have generated in the current stage. If so, simply add items to the set. The complexity of solving O(n·m).

380C - Sereja and Brackets We will support the segments tree. At each vertex will be stored: av — the maximum length of the bracket subsequence bv — how many there it open brackets that sequence doesn't contain cv — how many there it closed brackets that sequence doesn't contain If we want to combine two vertices with parameters (a1, b1, c1) and (a2, b2, c2), we can use the following rules: t = min(b1, c2) a = a1 + a2 + t b = b1 + b2 - t c = c1 + c2 - t

380D - Sereja and Cinema In order that no one would be upset, every person except first should sitdown near someone else. Now when any human comes we know that for one side of him there will not be any people. Will use it. We will support the interval exactly occupied seats. If the first person is not known, it is possible that we have 2 such intervals. Now only remains to consider carefully all the cases that could be, because at each iteration we know exactly how many people will sit on some certain place.

380E - Sereja and Dividing Note that at any particular segment we are interested not more than 60 numbers. The greatest number enters with a coefficient of 1/2, the following — 1 /4, 1 /8, and so on. Thus to solve the problem we need to know for each number: how many segments to include it as a maximum , as a second maximum , a third , and so on until the 60th .

What to know such information is sufficient to find 60 numbers large jobs left and right. This can be done carefully written the set or dsu.

Now, with this information we can calculate by countind number of segments which contain our element. It is not difficult to do, knowing the positions of elements , large then current . Let the position of elements on the left: p1> p2> ... > Ps1. And positions right: q1 < q2 < ... < qs2. So we should add value .

All details can be viewed in any accepted solution.

Codeforces Round #222 — Problem Analysis

By dalex, 9 years ago, translation, In English Link to announcement and discussion.

And here is the problem analysis.

A div 2: 378A - Playing with Dice Make three counters: for wins of both players and for a draw. Iterate over all six ways how they can throw a dice. For each way determine who wins or there is a draw and increment the corresponding counter.

B div 2: 378B - Semifinals You can think a bit and understand that you should consider only corner cases: k = 0 and . All other cases will be something between them.

If k = 0, we should choose n biggest elements from two sorted lists, one of the ways is to use two pointers method. And if , we just mark first  people in each list.

A div 1 / C div 2: 377A - Maze Start BFS or DFS from any free cell. As the maze is connected, this search will visit all s free cells. But we can stop the search when it visits s - k free cells. It's obvious that these s - k cells are connected to each other. Remaining k cells can be transformed into the walls.

Solutions which every move transform the cell which has the minimal number of neighbours passed pretests. However, it's wrong. Here is the counter-test:

.... .#.. ..## ..## Top-left cell has no more neighbours than any other cell but we cannot transform it into the wall.

B div 1 / D div 2: 377B - Preparing for the Contest It's obvious that the time needed to fix all bugs is the monotonic function: if we can do it for some time, we can do it for greater time. So we can use binary search in these problem. We should learn how to check if some time t is enough.

At first sort all bugs by their complexity and all students by their skills. Let's consider the hardest bug. Who can fix it? It can be fixed by student whose skills is not less that this bug's complexity. Push all such students into the priority queue (sorted by students' price) and pop the cheapest student. As we check time t, this student must fix t hardest bugs (he definitely can do it). Save that information and go to the next bug which has not been fixed yet. Again push all students which can fix it to the priority queue and pop the cheapest one. And so on. If at some moment priority queue is empty, time t is not enough. If we spent too much 'money' — it's not enough as well. Otherwise we get the correct schedule.

C div 1 / E div 2: 377C - Captains Mode There are some observations that do the problem very simple. The first one is that we always should pick the strongest hero. But we cannot say something similar about the bans — in different situations different bans are the best. But the most important observation is that we should consider only m strongest heroes. Indeed, in every game where only strongest heroes are picked, no hero except m strongest can be picked. That's why we don't need to ban them and therefore we don't need to consider them.

So now we have only 20 heroes. It means we can solve the problem using the dynamic programming with bitmasks: dpmask will be the difference between the teams' strengths when only those heroes are picked or banned whose bits are set to 1 in the mask. At every state we try to pick or ban every available hero and go to the other state. The simpliest way to implement it is the recursion with memoization. The answer will be stored in dp2m - 1.

Unfortunately, we couldn't estimate the real complexity of this problem (despite it has the simple solution, this solution is not so easy to think of — standard 1500 points for problem C would be better) and set too big TL (many solutions written in C++ whose complexity is m2·2m passed — we should have been set TL to 1 second or even to 0.75 seconds). So if you solved it in m2·2m, you may assume that you're just lucky and your correct verdict is Time Limit Exceeded.

Why it can be solved in m·2m? There is no point of missing a ban — if we ban the weakest hero, nothing will change since the weakest hero won't be picked.

Also this problem has weak pretests so you could hack solutions without bitmasks with almost any big random test.

D div 1: 377D - Developing Game Let's note that every answer is characterized with two numbers L and R so that max{li} ≤ L, R ≤ min{ri}, and L ≤ vi ≤ R. If we know L and R, we can check every person and choose those who satisfies the conditions above.

Let's imagine a plane with the coordinate axes: one of the axes will be L, and the other will be R. If the point (L, R) on this plane is the optimal answer, people included in this answer for sure satisfy the conditions li ≤ L ≤ vi and vi ≤ R ≤ ri. These conditions specify the rectangle on the plane. Since we should find the maximum number of people, we should find such point (L, R) that it is inside the maximum number of the specified rectangles.

Now it's the standard problem that can be solved using the scanline through one axis and the segment tree built on the other axis. The hardest part is to reduce the original problem to it.

E div 1: 377E - Cookie Clicker First of all, throw away the buildings which cannot be used in any optimal answer: for each vi remain only one building that has speed equal to vi and minimal ci. Also throw away all buildings whose speed is less than the speed of the fastest building which has ci = 0.

It's fairly obvious that at any time we should use the fastest building. And if some building is used in the optimal answer, it should be bought and used immediately when we have enough money (I will use the word 'money' instead of 'cookies').

Let's imagine the plane (x, y) where x axis stands for the time and y axis stands for the money. We will maintain the graph of the function y = f(x) — 'maximal number of money that can be obtained at the time x' and process the buildings one by one, changing the graph. This function is the union of the line segments with the slopes equal to vi, and each of these line segments is active on a certain segment [xli, xri] of the axis x.

For example, at the beginning the graph is just the line y = v1x, where v1 is the speed of building that can be bought for 0 units of money. Let the next building's price is c2. Find the minimal point x02 where value of our function is greater or equal to y = f(x02) ≥ c2 and buy this building at the moment x02. Then we should make the line y = y02 + v2x where y02 = f(x02) - c2 is the amount of money remaining after the purchase. Now we have two lines. Till some moment the first line is better (not till x02, maybe later), but as v2 > v1 there exists a moment of time (it's ceil(x12) where x12 is the x-coordinate of the lines' intersection) when the second line becomes better. Now we know the segments where a particular line is better than the others.

Continue add all buildings to the graph this way. Line segments should be stored in stack, as in all problems with convex hull, and every step remove unnecessary line segments from the stack (these are the lines those position in the stack is after the line which has an intersection with the currently added line). After we process all buildings, we use our graph to find the minimal time when we have S untis of money.

If we also should say which building we must use, we can store for any line segment its 'parent' — the line segment which was active when the current one was bought. With such parent array it's not hard to restore the sequence of buildings in the answer. We removed this part from the problem to make it a bit easier.

Codeforces Round #221 Tutorial

By boleyn.su, 9 years ago, In English 376A - Lever

writer: boleyn.su

O(n):

Let mid = position of ^

Let value(x) = x if x is a digit , 0 otherwise.

Let sum = value(i-th char)*(i-mid)

If sum = 0 then answer = balance

Else if sum<0 then answer = left

Else answer = right

376B - I.O.U.

writer: oGhost

O(n^4):

Let f[i][j] = how many money i owes j

#It can be proved we only need to loop n times.

Loop n times do:

For i,j,k in [1..n]

    If f[i][j]>0 and f[j][k]>0 then

       Let  delta = min (f[i][j], f[j][k])

       Decrease f[i][j] and f[j][k] by delta

       Increase f[i][k] by delta Answer will be sum{f[i][j]}

O(m+n):

Let owe[i] = 0 for all i

#Suppose there is an agnecy to help people with debts.

#If you owe someone, you give money to the agency.

#If someone owes you, you get money from the agency.

For each ai, bi, ci

Increase owe[ai] by ci

Decrease owe[bi] by ci Ansewr will be sum{owe[i]|owe[i]>0}

375A - Divisible by Seven

writer: oGhost

O(n):

Because permutation of 1, 6, 8, 9 can form integers that mod 7 equals 0, 1, 2, 3, 4, 5, 6.

So you can construct answer like this: nonzero digits + a permutation of 1, 6, 8, 9 + zeros.

375B - Maximum Submatrix 2

writer: oGhost

O(n*m):

#We can get right[i][j] by O(n*m) dp.

Let right[i][j] = how many continuous 1s is on cell (j, i)'s right.

Let answer = 0

For all column i

Sort right[i] #You can use O(n) sorting algorithm

For j in [1..n]

    If right[i][j]*(n-j+1) > answer then answer = right[i][j]*(n-j+1) 375C - Circling Round Treasures

writer: whd

#T = number of treasures, B = number of booms

O(n*m*2^(T+B)):

#State(i, j, ts, bs) means:

# 1. You are at cell (i, j)

# 2. If the i-th bit of ts is 0 i-th treasure cross even edges of current path, otherwise odd edges.

# 3. If the i-th bit of bs is 0 i-th boom cross even edges of current path, otherwise odd edges.

Let dis[i][j][ts][bs] = min step to go to reach state (i, j, ts, bs).

Then we can use bfs algorithm to calculate dis.

The answer will be max{value(ts) — dis[Si][Sj][ts][0]}

375D - Tree and Queries

writer: whd

O(nlogn) or O(nlog^2n):

Use binary search tree and merge them by rank.

Use binary search tree that supports O(n) merging to get O(nlogn) solution.

O(n*sqrt(n)):

Dfs the tree to transform the problem to:

Given a[i], query [l,r] k. To solve this problem:

Build sqrt(n) bucket, put query [l,r] into (l/sqrt(n)+1)-th bucket

For each bucket

    For thoese queries whose r is also in the bucket (l/sqrt(n) equals r/sqrt(n)), a brute-froce O(n) solution exists.

    For thoes queries whose r is not in the same bucket, let we sort them by l. We will get l[i[1]]<=l[i[2]]<=..<=l[i[k]]<=r[i[k]]<=r[i[k-1]]<=..<=r[i[1]](do not forget we get l[] and r[] by dfs the tree!). Solving them can be done in O(n) too.

Since we only have O(sqrt(n)) buckets, the total time is O(n*sqrt(n)). 375E - Red and Black Tree

writer: boleyn.su

This problem can be solved by integer programming:

min sum{c[i]*x[i]}

subject to

    sum{A[i][j]*x[j]} >= 1 for all i

    sum{x[i]} = R

    x[i] = 0 or 1 for all i

where

    c[i] = 1 if node i is black, 0 otherwise

    A[i][j] = 1 if distance between i and j is no greater than X, 0 otherwise

    R = number of red nodes. As it is known, integer programming is NP-hard.

Thus, this cannot be the solution.

But we can prove the following linear programing's solution is same as the integer programming's.

min sum{c[i]*x[i]}

subject to

    sum{A[i][j]*x[j]} >= 1 for all i

    sum{x[i]} <= R

    x[i] >= 0 for all i

where

    c[i] = 1 if node i is black, 0 otherwise

    A[i][j] = 1 if distance between i and j is no greater than X, 0 otherwise

    R = number of red nodes. And the known fastest algorithm to solve linear programming is O(n^3.5).

But in fact due to the property of this problem, using simplex algorithm to solve linear programming is even faster. I think it can be O(n^3), but I have no proof.

So just use simplex to solve the linear programming problem above.

The tutorial is not finished yet. More details will be added later.

UPD

Thanks to Codeforces users, a lot of details supposed to be added can be found in comments. I am adding something that is not clearly explained in the comments or something that I want to share with you.

Div1C:

There are few questions about this one. So I am explaining it more clearly.

#State(i, j, ts, bs) means:

# 1. You are at cell (i, j)

# 2. If the i-th bit of ts is 0 i-th treasure cross even edges of current path, otherwise odd edges.

# 3. If the i-th bit of bs is 0 i-th boom cross even edges of current path, otherwise odd edges.

Let dis[i][j][ts][bs] = min step to go to reach state (i, j, ts, bs).

Then we can use bfs algorithm to calculate dis.

About the bfs algorithm:

We know dis[Si][Sj][0][0] = 0.

For state(i, j, bs, ts) we can goto cell (i-1, j), (i+1, j), (i, j-1) and (i, j+1). Of course, we cannot go out of the map or go into a trap. So suppose we go from cell (i, j) to cell (ni, nj) and the new state is (ni, nj, nts, nbs). We can see if a treasure is crossing through the edge (i, j) - (ni, nj), if i-th treasure is, then the i-th bit of nts will be 1 xor i-th bit of ts, otherwise, the i-th bit of nts and ts will be same. The same for nbs.

We can reach state (ni, nj, nts, nbs) from (i, j, ts, bs) in one step, so we just need to start bfs from state(Si, Sj, 0, 0) to get the min dis of all state. The answer will be max{value(ts) — dis[Si][Sj][ts][0]}

My submission: 5550863

Div1D:

To our surprise, there seems to be many different solutions to Div1D, which is very good. In fact, we thought about changing this problem so that only online algorithm will be accepted, but we didn't have much time to change it. I guess if we only accept online algorithm, the problem will be less interesting becasue we might not have so many different solutions. So, not changing it is a good decision.

However, it may(some solution is hard to change to solve the online-version, so I use 'may') be quite simple to solve the online-version of this problem if you have solved the offline-version. You just need to use persistent data structure when implementing binary search trees. You can get more detail from wiki.

Div1E:

The meaning of the integer programming:

We use x[i] to stand whether node i is red or not. So we have:

x[i] = 0 or 1 for all i

There is a beautiful tree, for each node, exists an red node whose distance to this node is no more than X. So we have:

sum{A[i][j]*x[j]} >= 1 for all i

There are only R red node. So we have:

sum{x[i]} = R

And we need to minimize the swap number, and in fact the swap number equals to number of nodes that changed from black to red. So we need to minimize:

sum{c[i]*x[i]} After changing it to linear programming:

Firstly, it is obvious that the solution of the linear programming will not be worse than integer programming, because integer programming has stronger constraint.

So we only need to show the solution of the linear programming will not be better than integer programming.

To prove this, we need to show for an optimal solution, there will be an solution which is as good as it and all x[i] is either 0 or 1.

1. Because for "sum{A[i][j]*x[j]} >= 1 for all i", there is no need to make some x[i] > 1. It is obvious that if the solution has some x[i] > 1, we can increase x[i] for nodes that are red in the first place, so that there will not be any x[i] > 1 and this solution is as good as the old one.

2. We need to prove in an optimal solution, making some x[i] not being an integer will not get btter solution. It is really hard to decribe it. So just leave you a hint: use the property of trees to prove and consider leaves of the tree. My submission: 5523033

There is a nice DP solution too, check this submission 5516578 by Touma_Kazusa.

Codeforces Round #220 (Div. 2) разбор

By Berezin, 9 years ago, translation, In English 374A — Inna and the pink pony

Lets find a solution for shifting a candy from the position (x1, y1) into position (x2, y2). On each step we shift (increase or decrease) x1 by a and y1 by b.

It is not difficult to understand that if |x2 - x1| is not divisible by a and |y2 - y1| is divisible by b answer doesn't exist.

We should also note that |x2 - x1| / a and |y2 - y1| / b Should be both even or odd as shifting is performed at a time for both values.

We should also look up for a corner case when step dropes us out from the board.

Now we can determine the way from (x1, y1) to (x2, y2) as max(|x1 - x2| / a, |y1 - y2| / b).

Lets calculate it for all corners and choose minimum or determine that the answer doesn't exist.

374B — Инна и девять

We can divide the task into subtasks because if two adjacent digits have sum none-9 the number transformation doesn't depends on other side relatively to the position between this two digits. It means we should divide our task into subtasks of kind: x or xyxyxyx...xyxy where x + y = 9. We should multiply all such answers because we are looking for the whole number of variants.

For x answer is 1. What should we do for xyxyxy? Let its length is s. Then if s is even we simply receive s / 2 nines. If s is odd one digit (any of them) will stay. Thus each sequence xyxyxyxyx...xyxyxy with odd length s increases the answer IN s times.

374C — Inna and Dima

Our task is tranformed to the task of finding cycle or maximal way, but lets solve it without any graphs.

Lets run dfs from each digit D, memorizing all already calculated tasks. If we come into the cell we have already been (in one of the previous D) than we should simply add the maximal way length to our current length. Way length is increased not in each cell but only when we come into A. If we come into the cell we have already been on current step (in our dfs running) this is the cycle and we should stop the algorithm. Don't forget to change the color of cell after droping from recursiong because you will receive "false cycle". Simply set the colour to current when come into the cell but decrease it before end of recursion for this cell.

374D — Inna and sequence

Lets note that not more than n numbers, thus it will be not more than n dropings. We will run this process using data structure Segment Tree (you can use another structures). Lets calculate the number of numbers in current segment. When the number is added we should simply go down from the root to the leaf and increase value for each segment on the way by 1. Deletetion — vice versa. If there is enough numbers in the left subtree we should go into the right one, othervise — into the left one. Don't forget to shift the ai position by decreasing on i as all numbers are droped immidiately. And don't forget to break the cycle as soon as you reach first ai such that there is no number to be droped out from it.

374E — Inna and babies

We will make the binary search to find the answer. For each time let's generate our segments and rotate them to transform them into horizontal and verticle. We can use transformation (x, y) to (x + y, x - y). Don't forget to make the union of all segments which were at the one diagonal and have an intersection. You should sort all segments of one type and iterate through them updating the size of the segment. Now we should only determine if there is at least one rectangle. For example we can iterate each verticle segment updating the set of all horizontal which begin not later than our verticle. For each verticle (the left one) we should iterate the right verticle and now calculate the set of horizontal which not only begin not later than the left verticle but also don't end earlier than the right one. Now we should only determine is ther is two or more horizontal segments from the set which satisfy also y-conditions for current vertical.

Codeforces Round #219 editorial

By DEGwer, 9 years ago, In English Sorry for late.

This is the editorial of Codeforces Round #219. Div2 A, Div2 B, Div1 C are made by kagamiz, and other problems are made by me.

373A - Collecting Beats is Fun /\_/\

First, you need to count the occurence of each number (1 through 9). If none of them are greater than 2 * k, Cucumber boy is able to press the panels in perfect timing.

Complexity is O(1).

My solution : http://ideone.com/CwQtBv

373B - Making Sequences is Fun /\_/\

Naive simulation (subtracting S(i) * k from w while w >= 0) won't finish in 2 seconds.

At first, these two facts will make it easier to solve the problem : 1. k doesn't matter for solving this problem, so you can simply divide w with k at the first point. 2. S(10^x) + S(10^x + 1) + ... + S(10^(x+1) — 1) = 9 * x * 10^x .

There are many ways to solve this problem, and I'll show you 2 ways.

Binary Search Let's define f(n) as \sum_{k=1}^{n} S(n). This problem can be solved by finding largest x that satisfies f(x) — f(m — 1) <= w. If x satisfies the given inequation, also x — 1, x — 2, ... satisfies inequation since S(x) is always positive. So it can be solved by using binary search. By using fact2, you can quickly simulate the value of f(n). The answer can be rather large, so be careful not to cause overflow by too large upper bound. Overall complexity is O(log |upper_bound — lower_bound|).

Cumulative Sums Let's think to speed up naive solutions that I've written at first. If you use fact 2, the number of simulation will reduce from O(|answer|) to O(1). Also, simulation will be much easier if you add S(1) + ... + S(m-1) to w. Please see my source code for further detail.

DEGwer's solution (Solution 1) : http://ideone.com/cU78oe My solution(Solution 2) : http://ideone.com/NjxlwP

373C - Counting Kangaroos is Fun / 372A - Counting Kangaroos is Fun /\_/\

Because of the number of holding-held relations is at most , We can assume that first half of kangaroos do not hold any kangaroos, and last half of kangaroos are not held by any kangaroos. So we can split kangaroos in two set, such that first set contains the kangaroos whose size is in smaller half and second set contains the kangaroos whose size is in larger half, and use easy greedy algorithm. The time conplexity is O(N log N) for sorting and O(N) for greedy, so the time conplexity is O(N log N).

my solution: http://ideone.com/w8ch4w

373D - Counting Rectangles is Fun / 372B - Counting Rectangles is Fun /\_/\

We can precalculate all rectangles, in O(N^2M^2) with using consecutive sums for 2D. And then we use 4D consecutive sums, we can answer the queries. The time conplexity is O(N^2M^2+Q).

my solution: http://ideone.com/QOjwse

373E - Watching Fireworks is Fun / 372C - Watching Fireworks is Fun /\_/\

I think most of the participants came up with simple DP algorithm : dp[i][j] := the maximum happiness value that you can gain when you're on poisition j at i th launching. Each value in table can be calculated by this formula : dp[i][j] = max[k =  - t * d..t * d](dp[i — 1][j + k] + b[i] — |a[i] — j|) where t = t[i] — t[i — 1].

If you look up for all k, since the table's size is O(mn), the overall complexity will be O(mn^2), and its too slow to solve the problem. Now, We're going to make this algorithm faster. Since the second term in the DP formula doesn't depend on k, you have to find maximum value of dp[i — 1][j + k] faster. Using segment tree or sparse table can fasten finding from O(n) to O(log n), but the overall complexity is still O(mn log n), and the solution will get time limit exceeded.

Intended solution uses sliding window maximum (see this page http://people.cs.uct.ac.za/~ksmith/articles/sliding_window_minimum.html) for some information), since the interval [j — t * d, j + t * d] is independent for all the fireworks. It can be implemented by simple array or deque. This will speed up to calculate formula, and overall complexity will be O(mn).

kcm1700 has submitted faster solution than our intended one during contest! It's complexity is O(m^2). Please read his comment (http://codeforces.com/blog/entry/9907#comment-153963) for further information.

My solution : http://ideone.com/Unrfaa kcm1700's solution : http://codeforces.com/contest/372/submission/5431649

372D - Choosing Subtree is Fun /\_/\

We can use two pointers, which treat the interval of the consecutive numbers of node on tree. All we have to do is answer the query which requires the minimal number of size of subtree which contains all the vertices in the set, after the "add vertices to the set" and "delete verticesto the set" operations. We can calculate the distance between two nodes with LCA algorithm, then when we order the nodes by dfs order, we can answer the "add vertice" query that adds the vertice which is numbered s in dfs order, and assume that previous numbered vertices in dfs order in the set is t, and next is u, we can get rid of the "add" query that $(current size of subtree)+distance(s,t)+distance(t,u)-distance(s,u), and "delete" so on. The time conplexity of LCA algorithm is O(log N), so we can solve this problem in O(Nlog N).

There is another solution which uses heavy-light decomposition and segment tree. This solution is O(Nlog^2 N), which also pass.

my solution (heavy-light decomposition): http://ideone.com/XfJPsS

372E - Drawing Circles is Fun /\_/\

All circles we must consider pass through O, so we can consider the operation inversion. At this operation, the point (x, y) will be . From now, we think the plane as the plane after inversed. "The circumcircles of triangles OAB and OCD have a single common point, and the circumcircle of triangles OAD and OBC have a single common point" can be said, after the inversion, ABCD is parallelogram. And we can say it "the diagonal AC and BD have a common midpoint and the inclination of AC and BD are different". So all we have to do is make the list of the midpoints and inclination of all pairs of points and the line passes through them, and sort this array, and do some multiplication. It can be solved in O(N^2 log N).

my solution: http://ideone.com/x3Xrqe

Codeforces Round #218 (Div. 2): Tutorial

By MikeMirzayanov, 9 years ago, translation, In English The tutorial has been prepared by Fefer_Ivan and NALP.

371A - K-Periodic Array For array to be periodic, elements 1, 1 + k, 1 + 2 * k, … must be equal. Also, elements 2, 2 + k, 2 + 2 * k, … must be equal. And so on up to k. So each element of the array is a part of exactly one group. And there are k groups total. Each such group is independent. Let’s consider some group of elements, that contain a ones and b twos. All elements in this group must be equal. So we either change all ones to twos or all twos to ones. First option will require a changing operations and second one — b changing operations. For the optimal solution, you should select the operation with smaller number of changing operations required.

371B - Fox Dividing Cheese It is easy to see that the fox can do three type of operations: divide by 2, divide by 3 and divide by 5. Let’s write both given numbers in form a = x·2a2·3a3·5a5, b = y·2b2·3b3·5b5, where x and y are not dibisible by 2, 3 and 5. If x ≠ y the fox can’t make numbers equal and program should print -1. If x = y then soluion exists. The answer equals to |a2 - b2| + |a3 - b3| + |a5 - b5|, because |a2 - b2| is the minimal number of operations to have 2 in the same power in both numbers, |a3 - b3| is the minimal number of operations to have 3 in the same power in both numbers, and |a5 - b5| is the same for 5.

371C - Hamburgers Let's use binary search approach. For given number of hamburgers (say, x) let's find the minimal number of money needed to cook them. Say, for one hamburger Polycarpus needs cb bread pieces, cs sausages pieces, cc cheese pieces. So for x hamburgers he needs: cb·x, cs·x and cc·x pieces (by types). Since he already has nb, ns and nc pieces, so he needs to buy:

bread: max(0, cb·x - nb), sausages: max(0, cs·x - ns), cheese: max(0, cc·x - nc). So the formula to calculate money to cook x hamburgers is:

f(x) = max(0, cb·x - nb)·pb + max(0, cs·x - ns)·ps + max(0, cc·x - nc)·pc Obviously, the function f(x) is monotonic (increasing). So it is possible to use binary search approach to find largest x such that f(x) ler.

371D - Vessels The naive solution for this problem will work like this. Let us store an amount of water in each vessel in some array v. If we need to know how much water is in some vessel, we just take the number from the array. If we need to pour x units of water into vessel number i, we must follow the simple procedure: 1. If x = 0 then all water is poured and we must end the procedure 2. If i > n then all remaining water is spilled on the floor and we must end the procedure 3. If x units of water can fit into the i-th vessel, then add x to v[i] and end the procedure 4. Fill i-th vessel completely and subtract used amount from x. 5. Assign i = i + 1. 6. Go to the first step.

In the worst case scenario such procedure can iterate through all vessels each time. For example, if there are n vessels and each vessels have capacity of one unit of water, each query like 11n will take O(n) time to process.

To make this solution faster we should notice, that once completely filled, vessel can be skipped during the algorithm above because it can not consume any more water.

So instead of i = i + 1 assignment should be like i = findNextNotFilledVessel(i).

To implement this function we can use different structures. For example, we can use sorted set of numbers (set in C++, TreeSet in Java). Let store the set of indices of unfilled vessels. So to find next not filled vessel from i-th vessel, we must find smallest number, that is contained in set and is strictly greater than i. There are built-in methods for it (upper_bound in C++, higher in Java).

Also, each time we fill the vessel, we must erase corresponding index from the set.

So now we can see, that algorithm can not complete more that O((m + n)logn) operations for all queries. Because on each iteration of the pouring procedure either the vessel is filled (which can only happen n times during the whole runtime), or we run out of water (or vessels) and the procedure is stopped. So there will be only total of O(m + n) iterations of the pouring procedure and each iteration require one lookup in the sorted set, which takes O(logn) operations. So the total number of needed operations is O((m + n)logn).

371E - Subway Innovation It is easy to see that you need to minimize the sum of pairwise distances between k stations. The main idea to do it is to sort them and the required stations will form a continuous segment. It is easy to prove by contradiction.

Huge constraints do not allow to use straight-forward method to find required segment. Let’s call f(i, k) — sum of pairwise distances of k stations starting from the i-th. To find f(0, k) you need to start from f(0, 0) = 0 and use transformation from calculated f(0, i) to f(0, i + 1). You can use equation:



 = f(0, i) + xi·i - sum(0, i - 1) where sum(l, r) means xl + xl + 1 + ... + xr. We can precalculate sum[i] = x0 + x1 + ... + xi and use equation sum(l, r) = sum[r] - sum[l - 1] to find sum(l, r) in O(1).

Actually we need f(0, k), f(1, k) and so on (and find minimal value among them).

To recalculate f(i, k) to f(i + 1, k) you need exclude xi and include xi + k. Using the method like in the previous paragraph: f(i + 1, k) = f(i, k) - (sum(i + 1, i + k - 1) - xi·(k - 1)) + (xi + k·(k - 1) - sum(i + 1, i + k - 1)).

Codeforces Round #217 (Div. 2): tutorial

By Nerevar, 9 years ago, translation, In English 370A - Rook, Bishop and King There are two approaches to this task. The first is use BFS to find the shortest path three times. The second is to notice that:

A rook can reach the destination in one or two moves. If the starting and the destination fields are in the same row or column, one move is enough. A bishop can reach only fields that are colored the same as the starting cell, and can do this in at most two moves: if the starting and the destination fields are on the same diagonal, one move is enough. To find this out, check that r1 - c1 = r2 - c2 OR r1 + c1 = r2 + c2. A king should make max(|r1 - r2|, |c1 - c2|) moves.     int r1, c1, r2, c2;     cin >> r1 >> c1 >> r2 >> c2;     if (r1 == r2 || c1 == c2) cout << 1; else cout << 2;     cout << " ";     if ((r1 + c1) % 2 != (r2 + c2) % 2) cout << 0; else {         if (r1 + c1 == r2 + c2 || r1 - c1 == r2 - c2) cout << 1; else cout << 2;     }     cout << " ";     cout << max(abs(r1 - r2), abs(c1 - c2)) << endl; 370B - Berland Bingo It is good idea to think about cards as set of numbers. It is easy to see that card a can’t be finished before b if b is subset of a. So all you need is to find such cards (sets) which do not have other card (other set) as subset.

Since there are at most 1000 cards, you may iterate through all pairs and check that one card contains other in naive way like:

bool contains(vector<int> a, vector<int> b) // b in a? {     forn(i, b.size())     {         bool in = false;         forn(j, a.size())             if (a[j] == b[i])                 in = true;         if (!in)             return false;     }

    return true; } 370C - Mittens Let’s show that if the most frequent color appears not more than  times, than all children can get mittens of distinct colors. One way to construct such solution is to sort all left mittens in the order of decreasing frequency of their colors: for the input 1 2 1 2 3 1 3 3 1 we get 1 1 1 1 3 3 3 2 2. To obtain the sequence of right mittens, rotate the sequence of left mittens to the left by the maximum color frequency (in the example it is 4, so we get the sequence 3 3 3 2 2 1 1 1 1). Then just match the sequences (1 — 3, 1 — 3, 1 — 3, 1 — 2, 3 — 2, 3 — 1, 3 — 1, 2 — 1, 2 — 1). It can be easily shown that all pairs consist of distinct colors.

OK, but what to do if there is a dominating color that appears more than half times? Use exactly the same algorithm! It will maximize the number of pairs of distinct colors.

370D - Broken Monitor There are a lot of correct approaches to solve the problem. But there are much more incorrect :)

One way to solve the problem is following. It is easy to see that in possible answer there are two opposite sides each containing w. In opposite case frame can be shrinked. So the size of frame is dx or dy, where dx = maxx - minx + 1 and dy = maxy - miny + 1 (minx, maxx, miny, maxy are coordinates of left/right/top/bottom ws). Obviously, you should choose max(dx, dy) as a size.

Now we know the size of the required frame. How to find it’s leftmost-topmost corner?

The set of possible xs is: minx, maxx - size + 1 and 0. Indeed, you may move frame to the left until it will abuts to w by left size/right size of abuts to the left side of monitor.

Similarly, the set of possible ys as y-coordinate of leftmost-topmost corner: miny, maxy - size + 1, 0.

Now the solution looks like:

find minx, maxx, miny, maxy dx = maxx-minx+1, dy=maxy-miny+1 size = max(dx, dy) foreach x in {minx, maxx-size+1, 0}     foreach y in {miny, maxy-size+1, 0}         if frame_correct(x, y, size)             print answer             exit algorithm All you need is to write frame_correct. You may iterate through frame and check that all cells inside monitor and calculate the number of ws on it. If all the cells are inside and calculated number equals to total number of w, then return true.

This solution works in O(nm).

370E - Summer Reading For each book number that is in the sequence, find the leftmost and the rightmost position of this number. In other words, for each such book number we find a segment of positions that should consist of this number. If for some pair of numbers there segments intersect, it is impossible to construct the answer. The same thing happens if some segment has length more than 5. It is reasonable to separately handle the case when all given numbers are zeroes. In this case, fill in the numbers greedily, spending 2 days on each book (probably, except the last one).

So, we have some blocks of numbers and gaps between them. Lets do the following DP: each state of DP is described by two values (i, j): i means the number of block (lets enumerate them consecutively), j means how far to the right will this block eventually extend (if there is a gap after this block, it is possible that we fill some prefix of this gap with the same book number that is in the block). It is clear that j - i will not exceed 5, so we actually can describe the state by values (i, j - i), which may sound more convenient. So, the number of states is linear. Lets say that D(i, j) is true if it it possible to correctly fill all the gaps that come before the i-th block, under condition that the i-th block extends to the position j, and D(i, j) is false otherwise. To calculate the value of D(i, j), lets try to extend the i-th block to the left in all (not so many) possible ways (to replace some number of consecutive zeroes that are in the gap just before the i-th block). Then, try to fix where the previous block can actually end (fix the state D(i - 1, k), where D(i - 1, k) is true, of course). To make a transition in DP, we should check whether it possible or not to fill the rest of the gap between the (i - 1)-th block and the i-th block. Lets say that (i - 1)-th block consists of number x, the i-th block consists of number y, and there are f still unfilled positions in the gap. Than the gap can be correctly filled if and only if 2·(y - x - 1) ≤ f ≤ 5·(y - x - 1).

If you understand this DP, it won’t be difficult for you to find out how to construct the answer from it.

Editorial Codeforces Round #216 (Div. 2)

By gridnevvvit, 9 years ago, translation, In English 369A - Valera and Plates We will use greedy algorithm. Let's now i-th day, and current dish is a dish of first type. Then if we have the bowl, let's use it. Otherwise we will increase the answer. If the current dish is a dish of the second type, we first try to get the plate, and then the bowl. If there are no plates/bowls at all, then we will increase the answer.

Author's solution: 5306397

369B - Valera and Contest In this task you are to determine such array a1, a2, ..., an, that following conditions are met:

r ≥ a1 ≥ a2 ≥ ... ≥ an ≥ l; ; ; It's clear to understand, that value sk should be distributed evenly between the first k elements. For example, you can use following algorithm:

remainder = (s_k mod k); for(int i = 0; i < k; i++)  { 	a_i = s_k / k + (remainder > 0); 	remainder = remainder - 1; } If k ≠ n, you should use same algorithm with other elements, but there are to distribute value sall - sk.

Some participants forgot about test, where k = n. They received RE11.

Author's solution: 5306414

369C - Valera and Elections Consider all the roads that we need to repair. Mark the ends of u, v white. After that, we will consider a simple dynamic programming d[v] (v is the vertex) on the tree that for each vertex in the tree determines the number of white vertexes in the subtree. It is easy to calculate this by using a recursive function calc(v, prev) (v is the current node, and prev its immediate ancestor):

calc(v, prev) { 	d[v] = 0;  	if (white[v]) 		dv += 1;  	for all vertexes u such that there is the edge (u,v) or (v,u), u != prev: 		calc(u, v); 		d[v] += d[u];   } After that we will add to answer all white vertexes v such that next condition is correct: d[v] = 1

Author's solution: 5306500

369D - Valera and Fools Let's p[A] is the pA from the statement.

It's clear to understand that you can discribe the state by using pair of integers (A, B), where A is a number of the fool with smallest index, B — the second fool from the left. It is clear to understand that fool with indexes j ≥ B will be living. After that we will use bfs on the states (A, B).

State (0, 1) is always visitable, because it is initial. We will push it in the queue. After that, there are only three transitions from current state (A, B).

(B + 1, B + 2) — this transition is possible if and only if p[A] > 0 and there are some fool with index j ≥ B, which has non-zero value p[j] > 0. (A, B + 1) — this transition is possible if and only if p[A] > 0 и there are no fool with index j ≥ B, which has p[j] = 100. (B, B + 1) — this transition is possible if and only if p[A] ≠ 100 and there are some fool with index j ≥ B, which has non-zero value p[j] > 0. After that you are to determine number of states, which has distance from state (0, 1) less or equal to k. Also you should be careful, that if there are only one fool, that he doesn't shot.

Author's solution: 5306516

369E - Valera and Queries Let's calculate sets xs[y] — all segments, whose right borders are exactly equal to y. Now we reduce our task to another. For each query we will count the number of segments that doesn't belong to any one point. Let's it will be the value v. Then the answer to the query is n - v. We add to our request the point 0 and a point MV + 1, where MV = 1000000. Let points request have the form x1 < x2... < xn. Consider the xi and xi + 1. Let pi is the number of segments that lie strictly inside xi and xi + 1. Then v = p1 + p2 + ... + pn - 1. We will use following algorithm to find the values pi. Let consider all such pairs (x, xi + 1) for all requests and to add them to a second set xQ[y] — all pairs whose right boundary is equal to r. Then to find the values p of pairs (xi, xi + 1) we will iterate ascending the right border. Additionally, we will support Fenwick's tree, which can make  +  = 1 at the point, and can calculate sum of the prefix. Let i — the current right border. Then we can find out the value p for all pairs (l, r), with the right border is equal to the i (l, i). Let j left border of the pair. Then the answer for the pair is the value of S - sum(j), where S — all added to the Fenwick's left borders, and sum(j) — sum of the prefix j. After that, for the current coordinate i we need to consider all segments in the set xs[i]. Let j left boundary of the segment. Then we need to make  +  = 1 at the point j in our Fenwick's tree. The total solution complexity is .

Authors solution: 5306535

Codeforces Round #215 — tutorial

By Sereja, 9 years ago, translation, In English Разбор задач Codeforces Round #215 368A - Sereja and Coat Rack Each time we will go through the array and look for the minimal element which is not yet marked. If we find an item, we add it to the answer and mark it, otherwise we will subtract the penlty from answer.

368B - Sereja and Suffixes We will count value ansi — number of different elements on the suffix from i. For calculation will walk from the end of the array, and we count ansi = ansi + 1 + newai, newai equals to 1, if element ai has not yet met and 0 otherwise.

367A - Sereja and Algorithm If you look at what is written in the statment, it becomes clear that the algorithm finishes its work, if we can get a string like: xx, yy, zz, zyxzyxzyx... and all its cyclic shuffles. To check you just need to know the number of letters x, y and z separately. Quantities can be counted using partial sums.

367B - Sereja ans Anagrams We will divide the sequence on min(n, p) sequences. 1-st, (1 + p)-th, (1 + 2·p)-th, ... element will go to the first sequence, 2-nd, (2 + p)-th, (2 + 2·p)-th... will go to the second sequence and so on. Now you need to find an answer for each of them, considering that p = 1. This can be solved by a simple method. You can go along the sequence from left to right and count the number of occurrences of each number. If the number of occurrences of each number will match the number of occurrences of the same number in the second sequence, then everything is OK.

367C - Sereja and the Arrangement of Numbers Clear that we need to collect as many of the most expensive properties that would have been possible to build the array. Note that having n numbers, we have m = n·(n - 1) / 2 binding ties. See that this is a graph in which to do Euler path, adding as little as possible edges. For n%2 = 1 — everything is clear, and for n%2 = 0, you need to add an additional n / 2 - 1 rib. Why? This is your homework :)

The detailed explanation can be found here.

367D - Sereja and Sets Replace out sets by array, where the element — the number set to which its index belongs. Now take all the consequitive sub-arrays with lengths of d and find a set of elements that were not found in that sub array. Clearly, if we as a response to select a subset of such set, it does not fit us. Remember all those "bad set." As we know all of them, we can find all the "bad" subsets. Now we choose the set with maximum count of elements which is not a bad set. It is better to work here with bit masks.

367E - Sereja and Intervals We assume that the intervals are sorted, and in the end we will multiply the answer by n!, We can do so, as all segments are different.

Consider two cases n > m and n ≤ m. It would seem that you need to write different dynamics for them, but not difficult to show that in the first case the answer is always 0 . The second case is the following dynamics : dpi, l, r, i — how many numbers we have considered , l, r — only in this interval will be present number i. Also, we will need an additional dynamic si, l, i — how many numbers are considered , l — how many segments are already closed , and i does not belong to any segment . There will be 4 transfers, since every number we can not begin and end with more than one segment.

Now we should add x to our solution, it is quite simple: just add another parameter 0 / 1 in our dynamics, if we had such a element in the beginning of some interval or not. With out dynamics, it is not difficult.

For more details check out any solution that passed system tests.

Codeforces Round #214 (Div. 2) — Tutorial

By Berezin, 9 years ago, translation, In English 366A — Dima and Guards

The solution doesn't exist only if the mimimal way to bribe is grater than n. Otherwise we can increase the gift price to make price1 + price2 = n.

Let's find the miminal way to bribe. We should buy that gift for old lady which costs less. It means, if we have 2 guards with params a b c d, then minimum bribe price will be min(a, b) + min(c, d). Let's choose the guard with the minimal bribe price. If the minimal bribe price is greater than n, answer -1. Otherwise, the possible answer is, for example: Guard number, min(a, b), n–min(a, b).

366B — Dima and To-do List

Dima can make k–1 tasks, so Inna always tells him off for each k-th taks, beginning from the chosen place. So for the numbers with same modulo by k the answer will be the same. We should find the answer with minimal first task number so it is eniugh to calculate the sums of “tellings of” for tasks 0, 1... k–1. We can do it in such way: Determine the array int sum[k]. And put the number into appropriate bucket while reading:

sum[I mod k] +  = a[i]. Now we should simply find first i with minimal sum[i].

Complexity: O(N).

366C — Dima and Salad

Let's calculate dinamic: d[num][balance] where num – last looked fruit, balance — difference between sum of colories and sum of tastes. Let's multiply each b by k. The answer will be d[n][0].

d[num][balance] = maximal possible sum of tastes under conditions.

Step: from d[num][balance] we can relax answers:

d[num + 1][balance] = max(d[num + 1][balance], d[num][balance]) – if we don't choose a fruit

d[num + 1][balance + a[i] - b[i]·k] = max(d[num + 1][balance + a[i] - b[i]·k], d[num][balance] + a[i]) – if we choose a fruit.

Balance can be negative, so in programming languages which don't support negative indexation, indexes should be shifted by the biggest negative number for balance. If we determine the balance as sum(b·k) - sum(a) it will be the sum of all tastes.

366D — Dima and Trap Graph

The answer for some path is a range under which we can go all the way, and this range is the intersection of all the ranges on the path. We can conclude it because the number is valid for path if it is valid for all ranges in the path. We will iterate all ribs. Let the left board of range on a rib is the left board of our intersection. It means we can't use ribs whith left board greater than ours. Lets iterate all right boards, determining the answer as the range from fixed left board to the chosen right. This answer exists if we have any path from the first node to the last. Let's check if the graph is connected if we leave only ribs with left board not greater than our and right board not less than our. If the graph is connected — let's update the answer. Right board can be found by binary search so the complexity is O(M2·logM).

366E — Dima and Magic Guitar

There are many solutions for this task. I will describe my, you can deal with other by looking participants code. To find the answer we should calculate maxDis[k][k], where maxDis[i][j] – maximal complexity from note i to note j.

Now we should only iterate the song updating answer for each pair of adjacent notes. Let's think how we can calculate the matrix.

For each place (x1, y1) on the guitar let's iterate pairs (x2, y2) with y2 ≤ y1.

If (x2 ≤ x1) distance will be x1–x2 + y1–y2. So we should find minimal x2 + y2 in submatrix from (0, 0) to (x, y).

If (x2 ≥ x1) distance will be x2–x1 + y1–y2. So we should find maximal x2–y2 in submatrix from (n–1, 0) до (x, y).

We will calculate this values for each note. We need too much memory so we should memorize only one previous row for each note. For each place we will update dinamics for both variants according to already calculated and for our own note (which is in this cell) we will also compare (i + j) or (i–j) with current value in the cell.

Complexity O(N·M·K)

Codeforces Round #213 Editorial

By tunyash, 9 years ago, In English That's a part of final editorial. I'm sorry for delay. Please, report me about mistakes and unclear moments in solutions and in my english.

A div2

Task was to find the least digit, that is not contained in the given number and compare with given k.

B div2

Good sequence may contain only zeroes or contain some positive number. In the second case such a sequence is not longer than sequence {0, 1, 1, 2, 3, 5, 8, ..., x, y} where y > 109 and x ≤ 109. That's possible to find it using dummy algorithm. In the first case you may use binary search of two pointers.

A div1

Let's notice that sum in the rectangle (x1, y1, x2, y2) is sum(x1, x2)·sum(y1, y2). Where sum(l, r) = sl + sl + 1 + ... + sr. Then, we have to calc sum(l, r) for every pair (l, r) and count how many segments give us sum x for any possible x (0 ≤ x ≤ 9·|s|). In the end we should enumerate sum on segemnt [x1, x2] and find . There is corner case a = 0.

B div1

We may assume that John may exchange any subset of his items x to any other subset y, such as s(x) + d ≥ s(y) (it does not matter if x intersects y). We can find all possible sums in subset of elements of the given set of items using standard dp (knapsack problem). John should always exchange all his current set of items to another, because if he had exchanged some subset of x (current set) z to y, we can say that he had exchanged x to . So, we have to find shortest sequence of sets a, such as s(ai + 1) - d ≥ s(ai) for any possible i and a0 = {}. This subtask could be solved using following greedy algorithm. ai, i > 0 is maximal correct sum such as ai ≤ ai - 1 + d. Consider optimal answer c and our answer a. Let k is the first position where ak ≠ ck obiviously ak > ck (because ak selected as maximal as possible). Then consider q such as qi = ci for i ≠ k and qk = ak. q is either optimal. Applying similar operations we will obtain a. So, a is optimal.

C div1

We expected many unproved, but tested solutions. I think that careful prove of my solution with pen and paper is very difficult. So I will use some statistic-based facts.

Consider the set of divisors of number k. One can check that it's beautiful set. If factorisation of k has the form  where αi ≥ 3 and pi is distinct primes, set of divisors of k which is less than  is also beautiful. How to prove item 2? Consider set A of pairs of divisors of k (ai, bi) such as ai·bi = k and ai < bi. Obiviously (if k is not complete square) any divisor will be contained only in one pair. It's easy too see that . Consider some element of factorisation of k pα such as  and it is not true that . Let f(x) is maximal number s such as . f(ai) + f(bi) = α. For every q such as  numbers q, q·p, ..., q·pα will be divisors of k. That implies that  where d is number of divisors of . So in  pairs both numbers are divisible by p. So set {a0, ..., a|A|} is beautiful. But there are some pairs with f(ai) = α.  is equivalent approval. It's always possible to find such k as number of it's divisors is bigger than 2·w where w is number of elements in required set. You may write following dp to find it. dp[i][j] is minimal k which is constructed of first i primes ans has j divisors.  About 10 primes is enough to cover all k. Now we can construct beautiful sets with more than k elements. Using item 4 we will understand that constructed answer is very beautiful (about 60% of elements divisible by every possible p) and we can always delete extra elements. Last items is not strict, but one can check it with his computer.

D div1

Consider random element ar of a. With probabillity   where g is ghd of a. Let xi = gcd(ai, ar). There are no more than d distinct xi where d is number of divisors of ar. We can find number of ai such as  for every k in O(d2). (D is set of divisors of ar) Repeat item 1 x times we will get correct solution with probabillity 1 - 2 - x. There is the way to solve this problem O(n·plog + d·2plog) for iteration where plog is the maximal number of distinct primes in factorisation of ar.

E div1

Let's find number of rectangles whick consist k ones and intersect  in cartesian coordinate system. It's possible to do it in n2·k. We need to find closest k ones on the top and on the bottom of the  and enumareate all segments [l, r] such as 1 ≤ l ≤ r ≤ n and find closest k ones on the top and on the bottom of the segments merging results for rows. If we have k closest ones on the top and on the bottom of the segment we will find number of rectangles consists k ones and cross  on [l, r] in O(k). Then we should find number of rectangles, which don't cross . Let's rotate table by 90 degrees, solve similar problem for two halfs of the table and so on.  for square-shaped tables.  

At the picture 1 two closest ones on the top (black cells) lying on the 4'th and 2'nd horizontals. Closest ones on the bottom lying on the 5'th and 7'th. Then if k = 2 there are zero correct rectangles with two "ones" on the tom. There are four rectangles which consist one "one" on the top and one "one" on the bottom. You can see how segment grows up at the pictures 2, 3 and 4. Every time you should merge closest k ones of the added row with closest k ones of the current segment.

Codeforces Round #212 (Div. 2). Tutorial. Part 1.

By FunkyCat, 9 years ago, translation, In English 362A - Two Semiknights Meet

Autors have proposed different solutions. One can notice that if semiknights did not have a meeting after first step (it is not necessary they have a meeting in "good" square), they will not meet at all. This fact appears from board size and possible semiknight's moves. As the initial semiknight's squares are considered good for the meeting the semiknights have arrived to the one square and then they move together to one of the initial squares and meeting will count.

362B - Petya and Staircases

One has to note that the number of dirty stairs  ≤ 3000. Petya can reach stair number n if the first and the last stairs are not dirty and there are not three or more dirty stairs in a row. So let sort the array of dirty stairs and go through it, checking for three or more consecutive dirty stairs. Also one need to check if the first or the last stair is in this array.

362C - Insertion Sort

The number of times swap is called equals the number of inversions in the input permutation. It’s easy to see that it is reasonable to swap only such elements ai, aj that i < j and ai > aj (otherwise the number of inversions will increase). Let di, j be the number of permutation of elements with indices from 0 to i inclusive which are strictly less than j. Then, after swapping elements with indices i and j, the number of inversions will be old - 2 * (di, ai + dj, aj - di, aj - dj, ai) - 1, where old is the number of inversions in the initial permutation. It is sufficient to search all pairs of elements and pick those which help to minimize the number of inversions. The reader may prove the correctness of the formula as a supplementary task.

362D - Fools and Foolproof Roads

If the given graph contains less than q connectivity components, then there’s no solution. Otherwise it’s optimal at first add edges that connect different components and afterwards all remaining edges (they will be connect edges from one component). For the first phase you can use greedy algorithm: each time you select two components, current weight of which is minimal, and connect them with an edge. For example, you can store weights of all components in the current graph in some data structure (like set in С++). For the second phase it’s enough to find any component that contains two or more vertices (because loops are forbidden) and add all remaining edges between some two vertices of this component. If some action cannot be successfully executed (for example, you added all the edges and number of connectivity components if greater than q), then there’s no solution.

Asymptotics — O(n + m + plogn).

362E - Petya and Pipes

Construct the following flow network. Water tank 1 is the source, water tank n is the sink. Every pipe from water tank u to water tank v is presented as two arcs — the first one with capacity cuv and cost 0 and the second one with infinite capacity and cost 1. Thus, the answer is the maximum flow with cost not greater than k. It can be found by standard augmenting paths algorithm.

UPD1. Tutorial for problems A and B added. UPD2. Tutorial for problem C added.

Codeforces Round #211: tutorial

By Nerevar, 9 years ago, In English 363A - Soroban Not so much to say about this problem. You need to extract the digits of the given number (read it as string or repeteadly divide by 10 and take the remainders). Then carefully do the mapping of digits to its' representation.

363B - Fence Another easy problem. We need to calculate the sum of every consequtive segment of k planks. One way to do this is to calculate partial prefix sums: . Then the sum of heights of the planks i, i + 1, ..., i + k - 1 is si + k - 1 - si - 1. The other approach is to calculate the sum of the first k planks: h1 + h2 + ... + hk. By subtracting h1 and adding hk + 1 we get sum of k planks starting from the second plank. Then, by subtracting h2 and adding hk + 2 we get sum of k planks starting from the third plank, and so on.

363C - Fixing Typos The general idea of the solution is the following: while there are three consequtive equal characters, remove any one of them. After that we can only have typos of the second type. So, if we have one couple of equal characters immediately after another couple of equal characters (xxyy), we need to decide which character to remove, x or y? Let's find the leftmost typo of the second type in the string. It is easy to see that we can always remove the character from the second couple.

All these can be done in a single pass. Go through the characters of the given string and build the resulting string ans. Let's denote the current character as ch. If ch is equal to the last two characters of ans, skip ch. If ch is equal to the last character of ans and ans[length(ans) - 2] = ans[length(ans) - 3] (assume that ans is 1-indexed), skip ch. Otherwise, append ch to ans.

363D - Renting Bikes Let's do a binary search over the number of boys that can rent a bike. So let's say that we want to check whether it possible for k boys to rent bikes. If some k boys can rent a bike, then the k "richest" boys (with the most amount of personal money) also can do that. It is easy to see that if they can rent bikes, they can rent k cheapest bikes (if we first sort the bikes in increasing order of price, it will be just the first k bikes).

So, take k richest boys and try to match them with k cheapest bikes, spending as much common budget as possible. The following algorithm works (try to understand and prove it before asking questions): take the boy with least number of money (of course, among the considered k richest) and try to give him the cheapest bike. If the boy has ehough personal money to rent this bike, use his money to do this. Otherwise, use all his money and take some money from the common budget. Continue this process with the second cheapest bike and the second "poorest among the richest" boys. This process can end in two ways: we will either run out of budget and fail to rent k bikes, or we will successfully rent these bikes.

363E - Two Circles Correct solution will be published later.

Codeforces Round #210 editorial

By RomaWhite, 9 years ago, translation, In English 361A - Levko and Table Matrix,in which all diagonal elements equal k and other elements equal 0, satisfied all conditions.

For example, if n = 4 and k = 7, our matrix will be

7 0 0 0

0 7 0 0

0 0 7 0

0 0 0 7

361B - Levko and Permutation gcd(1, m) = 1, so if n = k, there is no suitable permutation.

It is well known that gcd(m, m - 1) = 1. Lets construct following permutation. It has exactly k good elements.

n - k  1  2  3  ...   n - k - 1  n - k + 1  n - k + 2  ...   n

360A - Levko and Array Recovery Let's find such value b[i] that a[i] ≤ b[i] for all indeces i. Let's simulate all operations and diff[i] will be the difference between current value of i-th element and its initial value. If we have operation of first type, we change values of diff[i]. If we have operation of second type, we know that a[i] + diff[i] ≤ m[i], so a[i] ≤ m[i] - diff[i]. We will get array b when we union all this inequalities.

Let's prove that either b satisfied all conditions or there is no such array. It can be two cases, why b does not suit:

 — it's impossible due to construction of array b.

 — b[i] is a maximal possible value of a[i], so  can't be bigger.

360B - Levko and Array Let's solve this problem using binary search. We need to check whether we can achieve an array, when c(a) will be at most x. Lets make dp. dp[i] means minimal number of elements with indeces less than i, which we need to change, but we don't change i-th element. Let's iterate next element j, which we don't change. Then we know that we can change all elements between i and j. It is equivalent to such condition

|aj - ai| ≤ (j - i)·x

Difference between neighboring elements can be at most x. The maximal possible difference increases by x exactly j - i times between elements i and j, so this inequality is correct.

360C - Levko and Strings Let's count amount of such substrings of t that are bigger than corresponding substring of s and begin at the position i.

If t[i] < s[i], this amount equals 0.

If t[i] > s[i], this amount equals n - i.

If t[i] = s[i], then let's find such nearest position j,  j > i , that t[j] ≠ s[j]. If t[j] > s[j], needed amount of substrings will be n - j. If t[j] < s[j], needed amount of substrings will be 0.

We can rephrase this: If t[i] > s[i], it will be (1 + pref)·(n - i) new substrings, where pref means how many last elements in s and t is equal.

Let's make dp. dp[i][sum] means that we viewed i positions, have sum needed substrings and s[i] ≠ t[i]. Lets iterate their common prefix pref.

If t[i] < s[i], dp[i][sum] +  = dp[i - pref - 1][sum]·(s[i] - 'a') — we can count this value using partial sums.

If t[i] > s[i], dp[i][sum] +  = dp[i - pref - 1][sum - (1 + pref)·(n - i)]·('z' - s[i]). Let's iterate pref.

Let's note that sum - pref·(n - i) ≥ 0, so pref ≤ sum / (n - i) and pref ≤ k / (n - i). This means that third cycle will make at most k / (n - i) iterations when we find value of dp[i][sum]. Let's count total number of iterations:

  =    <  k·(n + k·log  k).

360D - Levko and Sets p is prime, so there exist primitive root g modulo p(We don't need to find it, but we know that it exists). We can write ai = gri. Note, that i-th set consists of all numbers , where cj ≥ 0, or we can write it as .

By Fermat's little theorem ap - 1 = 1 mod p we have that ak mod p = ak mod (p - 1) mod p. So  can be equal to all values k·t modulo p - 1, where t = gcd(b1, b2, ... , bm, p - 1). Note that t doesn't depend on ri, so we can assign g = gt. Then all elements of i-th set will be gri·k, where k ≥ 0. Now we can replace bi by qi, where qi = gcd(ri, p - 1), as we do with bi at the beginning. Then all elements of i-th set will be gqi·k, where k ≥ 0. This means that if we write all values g0, g1, ..., gp - 2 in a line, i-th set will contain every qi-th element.

Now we need to find union of this sets.Let's do it using inclusion-exclusion principle. All our numbers are divisors of p - 1. Let's dpi be the coefficient near i in inclusion-exclusion principle(i is a divisor of p - 1) and we can find this values, adding all qi alternatively.

Also we need to find qi. Let's find volume of the i-th set. It is equal to . From the other side it is equal to such minimal number di, that aidi = 1 mod p (di is a cycle). From aip - 1 = 1 mod p we have that p - 1 is divisible by di. So we can find di as a divisor of p - 1. And .

360E - Levko and Game Algorithm:

Firstly we will solve problem if first player can win.

Let's make all roads that we can change equal to r[i] and do two Dijkstra's algorithms from vertices s1 and s2. Let's d1[i] be the distance from s1 to i, d2[i] be the distance from s2 to i. Consider a road, that we can change, from a to b. If d1[a] < d2[a], we will set length of such road equal to l[i] and do two Dijkstra's algorithms again. We run such process until any road changes its length.

If d1[f] < d2[f] after all changes then first player wins.

If we replace condition d1[a] < d2[a] by d1[a] ≤ d2[a], we can check if Levko can end this game with a draw.

Proof:

Let's call "edges" only roads which Levko can change. When we do Dijkstra's algorithm we use all roads, not only edges.

Let's prove that if there exist such edges values that first player wins, there exist values of edges such that first player wins and all this values equal either l[i] or r[i]. Consider shortest pathes of both players. If only first player goes on edge from a to b, we can set its value l[i]. Proof: there must hold d1[a] < d2[a] because first player goes on it and wins. This condition holds after change of value of this edge. If second player goes on this edge, he loses because d1[f] ≤ d1[a] + d(a, b) + d(b, f) < d2[a] + d(a, b) + d(b, F) = d2[f]. If second player doesn't go on this edge, he loses because shortest path of first player became smaller(d(x, y) — shortest path from x to y). If only second player goes on edge from a to b, we can set its value r[i]. Proof: Shortest path of the first player doesn't change and shortest path of second player can only become larger. If no player go on edge, we can set its value r[i]. Proof: Shortest pathes of both players doesn't change. If both players go on edge from a to b, we can set its value l[i]. Proof: Shortest pathes of both players decrease by (initial value of this edge — l[i]). After every such operation first player wins again and all edges become either l[i] or r[i].

Consider result of our algorithm. Let's call edge "good" if its value is equal to l[i] and "bad" if its value equals r[i]. (a) Let's prove that after performing all operations we will have d1[a] < d2[a] for all good edges (a, b). If we have d1[a1] < d2[a1] for edge (a1, b1) and after changing value of (a2, b2) this condition doesn't hold. We have d1[a1] >  = d2[a1], d1[a2] < d2[a2]. We change only one edge and shortest path from s2 to f become shorter so edge (a2, b2) lies on this path. d2[a1] = d2[a2] + d(a2, b2) + d(b2, a1) > d1[a2] + d(a2, b2) + d(b2, a1) ≥ d1[a1]. Contradiction. (b) Let's prove that after performing all operations we will have d1[a] ≥ d2[a] for all bad edges. We can continue our procces otherwise. (c) Let's prove that if condition d1[a] < d2[a] holds for some edge but we doesn't change it on this iteration, this continion holds after this iteration. Proof is same as in (a). (d) Let's prove that if any subset of good edges is equal to l[i] and d1[a] < d2[a], ift also holds when we make all good edges equal l[i]. Let's simulate all procces and use (c).

Lets prove that for all edges values(not necessary only l[i] or r[i]), d1[a] ≥ d2[a] for all bad edges (a, b). Assume that we have such edge. Consider shortest path of first player to its beginning. If there exist bad edges (a1, b1) on this path, there must holds inequality d1[a1] < d2[a1]. Consider first of this bad edges (a, b). Then shortest path of first player to a doesn't consist any bad edge. Consider problem,m which is equivalent to our problem but finish is in vertex a. good and bad edges will be same. Let's change all value of edges as we do in item 1. Note? that all bad edges will be equal to r[i]. So only subset of good edges can be equal to l[i] and d1[a1] < d2[a1]. By (d) we have that we can set all good edges l[i] and condition d1[a1] < d2[a1] will be satisfied. So we have contradiction thst this edge is bad.

This means that if first player goes on any bad edge, he loses. So we can set r[i] to all this edges. So we can set l[i] to some subset of good edges. By (d) we have that if we have d1[f] < d2[f] for some subset of good edges, this condition will be true if we set all good edges l[i].

Note that proof will be same if we want to check whether Levko can end a game with a draw.

Editorial Codeforces Round #209 (Div. 2)

By gridnevvvit, 9 years ago, translation, In English I'm not good in English. So, if you find an mistake in editorial, please, send me a private message.

359A - Table If there are some good cell, which is located in the first row or in the first column, the answer is two. Similarly, if If there are some good cell, which is located in the last row or in the last column, the answer is two. Otherwise, the answer is four.

Авторское решение: 4968279

359B - Permutation The answer is a slightly modified permutation 1, 2, ..., 2n. Let's reverse numbers 2i - 1 and 2i for each 1 ≤ i ≤ k. It's not hard to understand, that this permutation is good.

Авторское решение: 4968385

359C - Prime Number Obviously, the answer is xv. Let sum = a1 + a2 + ... + an. Also let si = sum - ai (the array of degrees). After that let's find value v by the following algorithm: Let's consider a sequence of degrees as decreasing sequence. Now we will perform the following operation until it's possible to perfom it. Take the minimum degree v from the array of degrees and calculate the number of elements cnt, which have the same degree. If cnt multiples of x, then replace all cnt elements by cnt / x elements of the form v + 1. Since the sequence of degrees is a decreasing sequence, we can simply assign them to the end. If cnt is not a multiple of x, then we found the required value v. Also you need to check, that v is not greater then sum. Otherwise, v will be equals to sum.

Авторское решение: 4968346

359D - Pair of Numbers Quite simple note: if the pair (l, r) satisfies the condition 1 from the statements, then min(l, r) = GCD(l, r), where min(l, r) is smallest number ai from the segment (l, r) and GCD(l, r) is a GCD of all numbers from the segment (l, r). Calculate some data structure that will allow us to respond quickly to requests GCD(l, r) and min(l, r). For example, you can use Sparce Table. Solutuions, that uses segment tree, is too slow. So I think, you should use Sparce Table. So, now our task quite simple. Let's use binary search to find greatest value of r - l:

lf = 0;  //left boundary of binary search rg = n;  //right boundary of binary search while (rg - lf > 1) {   int mid = (lf + rg) / 2;   if (ok(mid))   //ok(mid)     lf = mid;   else     rg = mid; } ok(mid) is the function, that determines, is there some segment where min(l, r) = GCD(l, r) and mid = r - l (mid — is fixed value by binary search). If there is some good segment, you should update boundaries of binary search correctly. After that, it's very simple to restore answer.

Some information about Sparce Table

Авторское решение: 4968587

359E - Neatness You should write recursive function, that will turn on the light in all rooms, where it's possible. Also this function will visit all rooms, which it may visit. Let this function is called paint(x, y), where x, y is the current room. Paint(x, y) will use following idea: Let's look at all neighbors. If there is a light in the current direction (rule 3 from the statement), and the room (nx, ny) (current neighbor) has not yet visited, we will call our recursive function from (nx, ny). Also, we will turn on the light in all rooms, were we were. If some room is not visited by paint(x, y) and lights is on in this room, the answer is "NO". Otherwise, the answer is "YES". After that let's calculate value dist(x, y) by using bfs. dist(x, y) — is a minimal possible distance from the start to the current position (x, y). It's possible to use in our bfs only rooms, where lights is on. After that we will write the same function repaint(x, y). Repaint(x, y) will use following idea: Let's look at all neighbors. If there is a light in the current neighbor (nx, ny) and dist(nx, ny) > dist(x, y) ((x, y) — current room), let's call our recursive function from (nx, ny).After that we will come back to room (x, y). If there is no such neigbor (nx, ny), turn off the light in the room (x, y). Also you should look at my solution for more details.

Авторское решение: 4968657

Codeforces Round #208 (Div. 2) Разбор

By Sereja, 9 years ago, translation, In English 358A - Dima and Continuous Line Author — Berezin

If our line has self-intersections, that some pair of semi-circles exists, which intersect each other. Let points x1 < x2 are connected with a semi-circle and points x3 < x4 are connected with another semi-circle. Then this semis-circles intersect if one of the conditions is true:

1). x1 < x3 < x2 < x4 2). x3 < x1 < x4 < x2

Let’s iterate trough all pairs of semi-circles, and check if the semi-circles intersect each other. So, the solution will have complexity O(N2) what satisfied the constrains.

358B - Dima and Text Messages Author — Berezin

It’s clear, that adding new random symbols means, that we can simply omit them, they don’t change the structure of the phrase:  < 3word1 < 3word2 < 3... wordN < 3. Let’s determine the phrase before inserting random elements: s = " < 3" + word1 + " < 3" + ... + " < 3" + wordN + " < 3". Lets i —is an index in s, we are waiting for. At the beginning i = 0; we will iterate though the sms and when we will meet the symbol which equals to si we will simply increment i.

if at some moment |s| ≤ I we found all needed symbols and answer is yes, otherwise – no.

358C - Dima and Containers Author — Berezin

We know all the numbers at the beginning, so, it’s clear, that we want pop three maximums. We can “precalculate “ maximums with finding next zero and iterating through all numbers between two zeroes. We should do pops from different containers, so let’s save maximums in the top of the stack, in the beginning of the queue and on the beginning of the dek. (you can do this in some other way) We should determine, where will be stored the 1st, 2nd and 3rd maximum. For example, the first(the biggest one) – in the stack, second – in queue, and the third – in dek. “trash” – other numbers we can save into the end of the dek. Also you need to catch cases, when two or less numbers are between zeroes.

358D - Dima and Hares Author — Sereja

Let’s look at the first hare: we chose them befoe second, or after. If it is chosen after the second, than the solution from the 2nd hare to the last doesn’t depend on the first one, otherwise, we will receive the same but before the second hair will be obviously the feed hair. So, we have two dinamics: 1). d0i — answer for suffix as a separate task. 2). d1i — answer for suffix if the previous hair for this suffix is feed already. Movements: d0n  =  an d1n  =  bn d0i  =  max(ai  +  d1i  +  1,  bi  +  d0i  +  1) d1i  =  max(bi  +  d1i  +  1,  ci  +  d0i  +  1) answer is d01;

358E - Dima and Kicks Author — Sereja

The first thing to understand is that the answer is the divisor of maximal-length sequence of standing one by one ones. (1111…11) Let’s iterate trough this number. Now we should check the table knowing the value of K. Let’s find the most left of ones, and choose from them the most top. Let it be (X, Y). then after each step Dima can appear inly in cells which look like: (X + K * a, Y + K * b). Let such cells are the vertexes of the graph. And sequences of ones – the ribs. We will build the graph. We should check that there are no additional ones in table. We should also check if the graph is connected and has en Euler’s path. The value of K is the next answer under the all conditions. The correct implementation will have the complexity O(N * N * log(N)). In reality it will be never achieved.

Codeforces Round #207: tutorial

By Nerevar, 9 years ago, translation, In English 357A - Group of Students In this problem you need to iterate over all possible values of passing rate from 1 to 100 and for each value calculate the sizes of two groups.

357B - Flag Day Let's process the dances in the given order and determine the colors of dancers' clothes. If there are no dancer from some previous dance, we can give the dances different colors arbitrarily. And if there is such dancer, we already know the color of his clothes. So, we arbitrarily distribute the other two colors between the remaning two dancers.

356A - Knight Tournament Let's the current fight (l, r, x) consists of K knights fighting. Then all we have to do is to find all these knights in time O(K) or O(KlogN). There are several ways to do that, let's consider some of them.

The first way is to store the numbers of all alive knights in std::set (C++) or TreeSet (Java). Then in C++ we can use lower_bound method to find the first knight in the fight that is alive, and to iterate over this set, each time moving to the next alive knight. In Java we should use subSet method.

    set<int> alive;     for (int i = 0; i < n; i++)         alive.insert(i);              for (int i = 0; i < m; i++) {         int l, r, x;         scanf("%d%d%d", &l, &r, &x);         l--, r--, x--;                 set<int>::iterator it = alive.lower_bound(l);         vector<int> toErase;                 while(it != alive.end()){             int cur = *it;                         if(cur > r)                 break;                             if(cur != x){                     toErase.pb(cur); answer[cur] = x;             }             it++;         }

        for (size_t j = 0; j < toErase.size(); j++)             alive.erase(toErase[j]);     } The second way is to define array next with the following meaning:

if knight v is alive, then next[v] = v; if knight v is out of tournament, next[v] points to some knight u (next[v] = u), such that there are no alive knights between v and u; To find the first alive knight starting from the knight v we need to follow this links until we find the first knight w with next[w] = w. In order not to pass the same links too many times, we will use the trick known as path compression (it is used in Disjoint Set Union). Note that you should handle the case when the current knight is the last knight and is out of tournament.

    int getNext(int v){         if(next[v] == v)             return v;         return next[v] = getNext(next[v]);     }

    ...

     int cur = getNext(l);      while(cur <= r){         if(cur == x){             cur = cur + 1;         }else{             answer[cur] = x;             next[cur] = cur + 1;         }

        cur = getNext(cur);     } 356B - Xenia and Hamming Let's denote the length of the first string as lenX, the length of the second string as lenY. Let L = LCM(lenX, lenY). It's obvious that L is a period of the long strings a and b, so we can find the distance of its' prefixes of length L and multiply the answer by . Let's fix the position i in the string x and think about all characters from the second string it will be compared with. It it easy to conclude that it will be compared with such yj that i ≡ j (mod g), where g = GCD(lenX, lenY). For each possible remainder of division by g and for each character c we can calculate count(r, c) — the number of characters c that appear in y in such positions j that j mod g = r. When calculating the Hamming distance, the character xi will be compared with exactly count(i mod g, xi) characters from y that are equal to it, all other comparisons will add one to the distance.

private void solve() {         Scanner in = new Scanner(System.in);         long n = in.nextLong(), m = in.nextLong();         String x = in.next(), y = in.next();         int lenX = x.length(), lenY = y.length();         int g = gcd(lenX, lenY);         long L = lenX * (long)lenY / g;         long answer = L;         int[][] count = new int[g][26];         for (int j = 0; j < lenY; j++) {             count[j % g][y.charAt(j) - 'a']++;         }         for (int i = 0; i < lenX; i++) {             answer -= count[i % g][x.charAt(i) - 'a'];         }         System.out.println(answer * (n * lenX / L));     } 356C - Compartments In the problem you should come up with some right greedy algorithm. One of correct approaches acts as follows:

Firstly, it joins all "twos" and "ones" (to get "threes"). Several "ones" should be moved. Then you should consider two cases depend on amounts of "ones" and "twos". If initially you have more "ones", you should try to join remaining after the first point "ones" into groups of three. If initially you have more "twos", you should try to join remaining after the first point "twos" into groups of three. You can get two "threes" from three "twos". After the first point and the second point some "ones" or "twos" can remain. You shouldn't come up with common solution. Else you should just to consider all possible cases. To solve the problem you should follow your common sense (is it greedy?). Writing naive solution (bfs search) for stress purposes is not so bad for proving correctness of your solution.

356D - Bags and Coins It's easy to see that bags and their relations "lies directly in" should form directed forest. Each vertex should be given value ci — the number of coins in the corresponding bag. Let's denote the sum of values cj in the subtree of vertex i as fi. The following conditions should be met:

fi = ai then sum of fi of roots equals s. It's clear that one of the bags with largest ai must be the root of some tree. It's quite easy to see that the solution exists if and only if there exists a subset ai1, ai2, ..., aik such that ai1 + ai2 + ... + aik = s and this subset contains at least one bag with the largest ai. It's obvious that it is necessary condition, the sufficiency is also easy to see: let's suppose we have such subset. Then all bags from the subset, except one of the largest, will be roots of the signle-vertex trees (i.e. ci = ai for them). All bags that are not in the subset we will consequentially put into the largest bag, forming the "russian doll" (this tree will be directed chain).

So, we reduced the task to the well-known subset-sum problem: from the items a1, a2, ... an find the subset with the given sum s. This problem is NP-Complete, and with these constraints is solved in a following way: let T(i, j) = 1 if it is possible to obtain sum j using some of the first i items, and T(i, j) = 0 otherwise. Then . The i-th row of this table depends only on the previous row, so we don't have to store the whole table in memory. Also we should use the fact that the values of the table are zeroes and ones, and we can use bit compression and store each row in an array of int's of size . To get the i-th row, we should calculate the bitwise OR of the previous row and the previous row shifted to the left by ai positions. That is, we can find out whether it possible to obtain the sum s in approximately  operations. To find the actual way to obtain s, we need to use the following trick: for every possible sum j we will remember the value first(j) — the number of such item that after considering this item it became possible to obtain j. This allows us to restore the solution.

356E - Xenia and String Problem During the contest most of participants write the solutions that are very similar to the author's one. One of the author's solution uses hashes (but there exist solution without it), you can see short description of the solution below:

For each position i calculate with hashes the maximal value of Li, such that substring s[(i - Li + 1)..(i + Li - 1)] is Gray string. Also, calculate the maximal value Pi, that substring s[(i - Pi + 1)..(i + Pi - 1)] differs from some Gray string in at most one position. You can see that Pi ≥ Li. If Pi > Li, also remember position and letter in the position, that differs Gray string and the substring.

You can see, that if we don't need to change letters, then the answer for the problem is , where f(L) = 12 + 32 + 72 + ... + L2. So, calculate an answer without changes.

Next, iterate through all positions and letters in it. What is the new answer for the problem? Look at all Gray strings that occurs in our string and touches our fixed position. After we change this position the string will not be Gray string anymore (so we should subtract the squired length of the string from our answer). Look at all Gray strings that differs in exactly fixed position from some substring of the string. If we change the letter in the position to the fixed letter, all such strings will be added to the answer (and we should add their squired lengths).

Summary, with Pi and Li we need to calculate for each position and letter, how the answer differs if we change the letter in the position to the fixed one. For that reason we should use offline update (+=) on the segment. After the values will be calculated we can update our answer with all possible values.

Codeforces Round #206 — Editorial

By Alex_2oo8, 10 years ago, translation, In English 355A - Vasya and Digital Root

If d = 0, the there is the only number with , so, if k = 1, the answer is 0, otherwise — No solution.

If d > 0, then one of correct numbers is d × 10k - 1.

Time complexity: O(1) + O(k) for the output.

355B - Vasya and Public Transport

If we buy a ticket of the fourth type, we don't have to buy anything else, so, the answer is min(c4, answer using tickets of first three types).

Now, when we don't have ticket of the fourth type, we can solve the task separately for buses and trolleys.

Solving the problem only for buses: if we buy a ticket of the third type, we don't have to buy anything else, so, the answer is min(c3, answer using tickets of first two types).

Without tickets of type three, we can solve the problem separately for each bus. If we buy a ticket of the second type, we will spend c2 burles and if we buy ai tickets of the first type, we will spend (ai × c1) burles. So, the answer for bus i is min(c2, ai × c1).

Now it is not difficult to obtain the following solution:

  function f(x, k) {     res = 0;     for i = 1 .. k       res = res + min(c2, x[i] * c1);

    return min(c3, res);   }

  ans = min(c4, f(a, n) + f(b, m)); Time complexity: O(n + m).

354A - Vasya and Robot

Brute force how many times we will use operation from the left. So, if we use it k times, then it's clear, that we will take first k items by the left operations and last (n - k) items by the right operations. So, robot will spend sumLeft[k]·l + sumRight[n - k]·r energy plus some penalty for the same operations. To minimize this penalty we should perform the operations in the following order LRLRL ... RLRLLLLL ..., starting from the bigger set. For example, if k = 7, n - k = 4, we should perform operations in this order: LRLRLRLRL LL. So, we will have to pay the penalty two times (7 - 4 - 1).

sumLeft[i] — sum of first i weights, sumRight[i] — sum of last i weights.

Solution in pseudocode:

  ans = inf;   for i = 0 .. n {     curr = firstSum[i] * l + lastSum[n-i] * r;     if ( i > n - i ) curr = curr + (2i - n - 1) * Ql;     if ( i < n - i ) curr = curr + (n - 2i - 1) * Qr;

    ans = min(ans, curr);   } Time complexity: O(n).

354B - Game with Strings

We will say that cell (r, c) corresponds to a string s, if there exist correct path, which ends in the cell (r, c) and this path corresponds to a string s.

Let call a set of cells which corresponds to some string s a state. One state can correspond to different strings. We can't brute force all possible strings, because their count —  is too big, but we can brute force all possible states. It's not hard to observe that all cells that corresponds to some string s lies on same diagonal, so the total count of states is 21 + 22 + ... + 2n - 1 + 2n + 2n - 1 + ... + 22 + 21 = O(2n). In implementation we can denote state with diagonal number (from 1 to 2n - 1) and bitmask of cells corresponding to this state (2n).

From each state we can move to 26 different states (actually less) and all possible moves depends on the state, not on the string. On the image you can see an example of move: from state, which is highlighted in blue by letter a we will move to the state, which is highlighted in yellow.

 

Now, for each state we can calculate a value of (count of letters A  -  count of letters B) in the string, starting from this state. If at the moment is first players turn (an even diagonal), we have to maximize this value, otherwise — minimize. It can be implemented as recursion with memoization.

The winner can be determined by the value of state, which corresponds to the single cell (1, 1).

Complexity: O(2n × (n + alpha)), where alpha is the size of alphabet.

354C - Vasya and Beautiful Arrays

The problem was to find greatest d, such that ai ≥ d,  ai mod d ≤ k holds for each i.

Let m = min(ai), then d ≤ m. Let consider two cases:



. In this case we will brute force answer from k + 1 to m. We can check, if number d is a correct answer in the following way:

We have to check that ai mod d ≤ k for some fixed d, which is equals to , where . Since all these intervals [x·d..x·d + k] doesn't intersects each with other, we can just check that , where cnt[l..r] — count of numbers ai in the interval [l..r].

Time complexity: O(maxA log maxA), proof is based on the sum of harmonic series.

354D - Transferring Pyramid

 

This tasks is solvable with dynamic programming. First of all let consider solution with complexity O(n3).

Let dp[i][j] be the answer for the highlighted in blue part (minimal cost of transferring all special cells that lies inside this area). Then dp[n][0] will be the answer for our original problem.

How to recalculate such DP? It's clear that in the leftmost column (inside the blue area) we will choose at most one cell as the top of some subpyramid. If we choose two, then the smallest one will lie fully inside the biggest one (as the orange subpyramid lies inside the blue one). Now, let brute force the cell, which will be the top of subpyramid in this column in time O(n) and we will obtain the following transition:

To simplify the formulas, let assume that .

  0 ≤ k ≤ i, where k is the height on which we will choose our top cell, or 0, if we don't choose any subpyramid in this column. sumUp[i][p] — count of special cells in the i-th column at height starting from p, this cells we will have to transfer one by one, using the first type operations.

We can reduce the complexity by one n, if we will recalculate out DP in the following way:

 0 ≤ k ≤ i;

 for all j > 0.

The proof that this is correct is quite simple and is left to the reader. :)

Also, we can observe that it is not profitably to take some subpyramid with height greater than , because for such subpyramid we will pay  > 3k, but if we transfer all cells using the first type operations we will pay only 3k. So, the second dimension (j) in out DP can be reduced to .

Also, to receive AC, you should store only last 2 layers of the DP, otherwise there will be not enough memory.

Time complexity: .

354E - Lucky Number Representation

Author's solution, much more complicated than suggested by many participants during the competition, easy solution will be described below.

First of all, let write a DP with complexity O(N * lucky_count(N)), where lucky_count(N) is the count of lucky numbers  ≤ N, lucky_count(10n) = 3n. As we can see, for all sufficiently large N solution exists. Really — for every N > 523.

Now, we can say that for N ≤ 10000 we have a solution, which is found using DP. Let's solve the task for larger values of N.

Next and key idea is to separate the task into two parts: N = N1 + N2. Let's choose N1 and N2 in such way that for them it was easy to find a solution and then merge these two solutions into one. Let N1 = N mod 4000, N2 = N - N1. Here we can have a problem that there is no solution for number N1, in this case we can do N1 = N1 + 4000, N2 = N2 - 4000.

Now it is guaranteed that solutions exists for both N1 and N2, moreover, the solution for number N1 will contain only numbers of not more than 3 digits ( < 1000). The proof is quite easy: if N1 < 4000 — it is obvious; else — if the solution uses some number of the form (4000 + some_lucky_number), we can replace it with just some_lucky_number and receive a correct solution for number (N1 - 4000), but is doesn't exist!

So, the solution for number N1 we have found using DP, now let's find the solution for N2. If it will contains only of numbers of the form (some_lucky_number × 1000), then we will be able to easily merge this solution with solution for N1, so, let's find such a solution. Here we will use the fact that N2 is divisible by 4. For simplicity, let's divide N2 by 1000 and in the end multiply all Ans2(i) by the same 1000. Let P = N2 / 4. Now, let's construct the solution. Consider, for example, P = 95: we will walk through digits of this number, last digit — 5, means that we want to put digit 4 at the last decimal position of five answer numbers — ok, put it and in the last, sixth, number leave there digit 0. Go forward, digit 9 — we don't have nine numbers, but we can replace seven fours with four sevens, then to the second position we have to put (9 - 7) fours and 4 sevens, in total — 6 numbers, exactly as much as we have.

Thus, if next digit d ≤ 6, we just put to the first d answer numbers digit 4 to the next position; if d > 6, then we put 4 sevens and (d - 7) fours. In all other numbers we just leave digit 0 at this position.

If Ans1(i) — answer for N1, Ans2(i) — for N2, the the answer for N will be just Ans(i) = Ans1(i) + Ans2(i).

Time complexity for one number: O(logN).

During the competition many participants have wrote the following solution:

dp[i][j] — can we put the digit to the last i decimal positions of the answer number in such way that we will get correct last i digits in the sum and with carry to the next position equals to j. Then the solution exist iff dp[19][0] = true. To restore the answer we just have to remember for each state the previous state. Base — dp[0][0] = true. Transition — brute force how many fours and sevens we will put to the i-th position.

Codeforces Round #205 (Div. 2) Editorial

By Igor_Kudryashov, 9 years ago, translation, In English 353A - Domino

Let's denote the sum of numbers on the upper halves of pieces as s1, and the sum on the lower halves — s2. If this sums are even, than the answer is obviously 0. Note, that if the numbers on both halves of piece have the same parity, than parity of s1 and s2 won't change after rotation this piece. If the numbers on halves have different parity, than parities of both s1 and s2 will change after rotation. Therefore, if s1 and s2 have different parities, than the answer is  - 1. If both s1 and s2 are odd, than we should check, if there is a piece with numbers of different parities. If so, the answer is 1, otherwise, the answer is  - 1.

353B - Two Heaps

Let's say for shortness, that we put numbers, that are painted on cubes, in piles, instead of cubes themselves.

Note, that the answer is the product of c1... c2, where ci is the number of different numbers in the i-th pile. Let's consider that all numbers are different. In this case the answer is n2. Now, let's suppose that we have two equal numbers and all the other are different. Then, if we put them in different piles, the answer will be n2, but if we put them in one — n·(n - 1). Obviously, the first case give greater product.

Thinking in similar manner, you can conclude, that we should do the following. Take numbers, that appear more than once, and put one of them in the first pile, one of them in the second pile and the other put aside. After that, divide the numbers, that appears once, in two equal part and put the first part in the first pile and second part in the second pile. Finally, take the numbers, that we put aside, and separate them in two pile in any kind.

353C - Find Maximum

Let's see on the highest bit of m. If it equals to zero, than for any  there is a zero on the (n - 1)-th position, so an - 1 doesn't affect the answer and we can put it aside and find the answer for smaller number of elements.

If the highest bit of m equals to 1, than an - 1 for some x will present in f(x), but for some will not. Let's consider such x, that a{n - 1} will present in f(x) with zero coefficient. It is obvious that . In this case f(x) will have maximum value when x = 2n - 1 - 1. Try to update the answer by this value.

Now we should analyze the case, when , find the maximum value of f(x) for all such x and try to update the answer by this value. Let's note, that in all such x there is 1 in (n - 1)-th position. Therefore we can find the maximum value of f(y) for all  and add an - 1 to it.

353D - Queue

Note that if there are some girls in the begining of the line, they will never move. So let's remove them and will consider that the first schoolchildren in the line is a boy. Also note, the relative order of the girls doesn't change. Let's calculate for each girl such moment of time ti, that after it she won't move forever. Note, that for i-th girl ti ≥ ti - 1. Let's calculate ti in order from left to right. Let's denote yi is the position in the line where i-th girl will stop, ans xi is her current position. Therefore it is needed xi - yi second for girl to reach her finish position. So if xi - yi > ti - 1, then ti = xi - yi. Let's manage the case when xi - yi ≤ ti. The girl with number (i - 1) will be on yi-th position by ti - 1-th second, so ti ≥ ti - 1 + 1. Let's consider such moment of time p, when i-th girl stand right after (i - 1)-th, but not on yi-th position. After that, in (p + 1)-th moment of time (i - 1)-th girl and the boy standing in front of her will swap their positions, but i-th girl will save her position. Then since p + 2-th second till ti - 1 both girls will change their positions. Finally, at (ti - 1 + 1) - th second i-th girl will occupy her position. Therefore, ti = ti - 1 + 1 in this case.

353E - Antichain

Let's divide our graph on chains. Denote chain as the maximal sequence of the edges, which have the same direction. If there are more than 2 edges in each chain, then the answer is the number of such chains.

If there is a chain containing only one edge (u, v), then brute vertex, which we will take in maximal antichain (also consider the case, when we take none of them). Let's suppose we brute the vertex v. After that we put aside this vertex and all vertices, which is comparable with v. In received graph we can find the size of the maximal antichain by uning dynamic programming with O(n) time complexity. Let's show how to do this.

Write all remaining vertices in line and renumerate them from left to right by the numbers from 1 to k. After that we are going to calculate di — the size of the maximal antichain among vertices with numbers j ≥ i. So if i > k, then di = 0. In other case we can skip i-th vertex and try to update di by the value of di + 1. Also we can try to take i-th vertex to the answer. In this case we should skip all vertices, that are reachable from i-th, or the vertices, from which we can reach i-th, take the answer from the next vertex, add 1 to it and try to update the answer.

Codeforces Round #204 — tutorial

By Sereja, 9 years ago, translation, In English Editorial for Codeforces Round #204 352A - Jeff and Digits Solution is looking for few cases: 1. If we do not have zeros, then the answer is -1. 2. If we have less than 9 fives, then the answer is 0. 3. Otherwise, the answer is: 4. 1. The maximum number of fives divisible by 9 4. 2. All zeros, we have

352B - Jeff and Periods We will go through the array from left to right. At each step, we will store the arrays: 1. nextx — the last occurrence of the number x 2. periodx — period, which occurs x 3. failx — whether a time when the number of x no longer fit

Now, when we get a new number we considering the case when it is the first, second or occurred more than twice. All the cases described in any past system testing solution.

351A - Jeff and Rounding Initially, we should remember the number of integers — C. On next step we will round down all numbers and count the sum. Now we can change the sum, rounding up some numbers, with those not matter what kind of, the main thing — how many. Consider a couple what we could get: 1. (int, int) (c1) 2. (int, double) (c2) 3. (double, int) (c3) 4. (double, double) (c4)

Iterate over the number of pairs of the first type. Then we know the total number of second and third type and number of the fourth type: 1. c2 + c3 = C - 2c1 2. c4 = N - (c1  +  c2  +  c3) Check to see if you can get such numbers (enough for us count of integers and real numbers, respectively). We find that we can round up from c4 to c4 + c2 + c3 numbers. We will find the best choise.

351B - Jeff and Furik ote that after each step, the number of inversions in the permutation is changed by 1. Let us turn to the inversions of the permutation — let them be I pcs. It is clear that when we have one inversion, then the answer — 1. Now we will see how to use it further: 1. it is clear that after a Jeff's step inversions will become lower by 1 2. it is clear that after a Furik's step inversions will be on 1 lowerwith porbability of 0, 5, and on 1 greater with probability of 0, 5. 3. we have the formula for an answer ansI = 1 + 1 + ansI - 1 - 1 × 0.5 + ansI - 1 + 1 × 0.5 4. after transformation we have ansI = 4 + ansI - 2.

351C - Jeff and Brackets How to solve the problem for small NM? Just use the dynamic programming dpi, j — minimum cost to build i first brackets with the balance j. Transfers are simple: 1. dpi, j + ai + 1 -> dpi + 1, j + 1 2. dpi, j + bi + 1 -> dpi + 1, j - 1 3. we make transfers only when balance will be non-negative 4. starting state dp0, 0 = 0

In this problem, we can assume that the balance will never exceed 2N. The proof is left as homework.

And by using this fact problem can be done by erecting a matrix to the power: 1. lets Ti, j — cost of transfer from balance i to balance j, using N brackets 2. (TM)0, 0 — answer to the problem

351D - Jeff and Removing Periods After the first request we can sort the numbers and for further moves will be able to remove all occurrences of a certain number. So the answer is the number of different numbers + 1 if there is no number, occurrence of which form an arithmetic progression.

Number of different numbers on a segment — standart problem, can be done O(N1.5) with offline algorithm.

The problem about finding the right number will be solved in a similar algorithm: 1. lets sort queries like pairs (li / 300, ri), we use integer dividing 2. learn how to move from the interval (l, r) to intervals (l - 1, r), (l + 1, r), (l, r - 1), (l, r + 1) with complexcity O(1) 3. by means of such an operation will move from one segment to the next, in the amount of the operation algorithm will works O(N1.5)

It remains to learn how to make the change on the interval by 1 element. Such a problem can be solved quite simply: 1. we craete deque for all value of numbers in array 2. depending on changes in the segment will add / remove items to the start / end of the respective deque 3. check whether the resulting deque is arithmetic progression. it will be homework.

351E - Jeff and Permutation We make the zero step, replace the elements on their modules.

The first thing you need to understand the way in which we will build our response. After selecting a few ways to understand the fact that initially you need to determine the sign of the largest numbers.

Consider the case where the current step we have only one maximal element. It is clear that if you put a sign - all the elements on the left of this will form an inversion, while on the right there will be no inversions. If we do not put a sign - it will all be the opposite. We select the best one and cross out the number of the array, it will not affect to some inversion.

Now we should understand how to read the response when the highs more than one. We write the dynamics dp[i][j] — how much inversions can you get, when we looked at the first i higest values and j from them lefted as possitive. Of these dynamics is not difficult to make the transition and get the answer.

And so we have a simple and short algorithm: 1. Iterates until the array is not empty 2. Find all the maximal elements 3. Calculate dynamics and find right signs 4. Remove elements from an array

For more details view any passed system tests solution.

Editorial Codeforces Round #203 (Div. 2)

By gridnevvvit, 9 years ago, translation, In English 350A - TL Let's v = min(ai), p = max(ai), c = min(bi). So, if max(2 * v, p) < c, then answer is max(2 * v, p), else answer is  - 1.

Author solution: 4632352

350B - Resort Input data represents a graph, by using a array of parents of every vertex. Because every vertex has at most one parent, we can use following solution: we will go up to parent of vertex v (prev[v]) until not found vertex with the outcome degree  ≥ 2. It is better to calculate outcome degrees in advance. After all, we will update the answer.

This algorithm works in O(n).

Author solution: 4632399

350C - Bombs First of all, Let's sort all point by increasing of value |xi| + |yi|, all points we will process by using this order. We will process each point greedily, by using maximum six moves. Now we want to come to the point (x, y). Let's x ≠ 0. Then we need to move exactly |x| in the dir direction (if x < 0 the dir is L, x > 0 — R). Similarly we will work with y-coordinates of point (x, y). Now we at the point (x, y), let's pick a bomb at point (x, y). After that we should come back to point (0, 0). Why it is correct to sort all point by increasing of Manhattan distance? If you will look at the path that we have received, you can notice that all points of path have lower Manhattan distance, i.e. we will process this points earlier.

This solution works in 

Authors solution: 4632478

350D - Looking for Owls It's possible to solve this problem by using only integer calculations. Normalization of the line Ax + By + C is following operation: we multiply our equation on the value , where g = gcd(A, gcd(B, C)), if A < 0 (orA = 0andB < 0) then sgn equals to  - 1, else sgn equals to 1.

Now the solution. We will have two maps (map<> in С++, TreeMap(HashMap) in Java) to a set of points (it's possible that some points will have multiply occurrence into the set). In first map we will store right boundaries of the segments, in second — left boundaries (in increasing order).

In advance for every segment we will build a normalized line, and for this normalized line we will put in our maps left and right segments of the segment.

After all, for every fixed line let's sort our sets.

Let's fix two different circles. After that, let's check that distance beetween them is greater then sum their radiuses, also you should check that circles has same radius. We can assume that we builded a line between centers of circles (x1, y1) and (x2, y2). Perpendicular to this line will have next coefficients (center of the segment [(x1, y1), (x2, y2)] also will belong to the next line) A = 2(x1 - x2), B = 2(y1 - y2), C =  - ((x1 - x2) * (x1 + x2) + (y1 - y2) * (y1 + y2)). After that you need to calculate values cntL, cntR by using binary search on set of points that lie on this line. cntL — amount of left boundaries that lie on the right side of point ((x1 + x2) / 2, (y1 + y2) / 2), cntR -- amount of right boundaries that lie on the left side of the point ((x1 + x2) / 2, (y1 + y2) / 2). After that you should add to answer value cntV - cntR - cntL,l where cntV — amount of segments, that lie on the nolmalized line.

Total complexity: .

solution: 4632546

350E - Wrong Floyd Let's do the following: construct the graph with the maximum possible number of edges and then remove the excess. First of all, you can notice that if k = n answer is  - 1. Else let's fix some marked vertex, for example a1. Let's put in our graph all edges except edges beetween a1 and x, where x — an another marked vertex.

So, why this algorithm is correct? If Valera's algorithm is wrong, then there are a ''bad'' pair of vertexes (i, j). ``Bad'' pair is a pair for that Valera's algorithm works wrong. So, there are not marked vertex v on the shortest path from i to j, and v ≠ i, and v ≠ j. Without loss of generality, we can assume, that distance beetween i and j equals to 2, but Valera's algorithm gives greater answer. There are some cases, that depends on the type of vertexes i, j. But we can look only at the case where (i, j) are marked vertexes. First, add to the graph all edges beetween not fixed (i, j) vertexes. Second, add to the graph edges beetween some fixed vertex (i or j) and some not marked vertex. Third, add to the graph edges beetween i and some marked vertex v, where v ≠ j. It's simple to understand, that if we add some another edge, the Valera's algorithm will work correctly. Total amount of edges is .

BONUS Simple bonus. For same contrains (n, m, k) can you build a graph, where Valera's code works correctly?

Код: 4632600

Editorial for Codeforces Round #202

By caustique, 9 years ago, translation, In English 349A - Cinema Line In the problem you need to decide whether cashier can give a change to all customers if the price of the ticket is 25 rubles and there's 3 kinds of bills: 25, 50 and 100 rubles. There's no money in the ticket office in the beginning.

Let's consider 3 cases.

Customer has 25 rubles hence he doesn't need a change. Customer has 50 rubles hence we have to give him 25 rubles back. Customer has 100 rubles hence we need to give him 75 rubles back. It can be done in 2 ways. 75=25+50 и 75=25+25+25. Notice that it's always worth to try 25+50 first and then 25+25+25. It's true because bills of 25 rubles can be used both to give change for 50 and 100 rubles and bills of 50 rubles can be used only to give change for 100 rubles so we need to save as much 25 ruble bills as possible. The solution is to keep track of the number of 25 and 50 ruble bills and act greedily when giving change to 100 rubles — try 25+50 first and then 25+25+25.

349B - Color the Fence In the problem you're asked to write the largest possible number given number of paint that you have and number of paint that you need to write each digit.

Longer number means larger number so it's worth to write the longest possible number. Because of that we choose the largest digit among those that require the least number of paint. Let the number of paint for that digit d be equal to x, and we have v liters of paint total. Then we can write number of the length .

Now we know the length of the number, let it be len. Write down temporary result – string of length len, consisting of digits d. We have supply of v–len·x liters of paint. In order to enhance the answer, we can try to update the number from the beginning and swap each digit with the maximal possible. It's true because numbers of the equal length are compared in the highest digits first. Among digits that are greater than current we choose one that we have enough paint for and then update answer and current number of paint.

If the length of the answer is 0 then you need to output -1.

348A - Mafia In the problem you need to find out how many games you need to play in order to make all people happy. It means that each of them played as many games as he wanted.

Let the answer be x games. Notice that max(a1, a2, …, an) ≤ x. Then i-th player can be game supervisor in x–ai games. If we sum up we get  — it's the number of games in which players are ready to be supervisor. This number must be greater or equal to x — our answer.







 Don't forget about that condition: max(a1, a2, …, an) ≤ x.

348B - Apple Tree In the problem you need to find out minimal number of apples that you need to remove in order to make tree balanced.

Notice, that if we know the value in the root then we know values in all other vertices. The value in the leaf is equal to the value in the root divided to the product of the powers of all vertices on the path between root and leaf.

For every vertex let's calculate di — minimal number in that vertex (not zero) in order to make tree balanced. For leaves di = 1, for all other vertices di is equal to k·lcm(dj1, dj2, ..., djk), where j1, j2, ..., jk — sons of the vertex i. Let's calculate si — sum in the subtree of the vertex i. All that can be done using one depth first search from the root of the tree.

Using second depth first search one can calculate for every vertex maximal number that we can write in it and satisfty all conditions. More precisely, given vertex i and k of its sons j1, j2, ..., jk. Then if m = min(sj1, sj2, ..., sjk) and  — minimal number, that we can write to the sons of vertex i, then it's worth to write numbers  to the sons of vertex i. Remains  we add to the answer.

348C - Subset Sums This problem is about data structures.

First step of the solution is to divide sets to heavy and light. Light ones are those that contains less than  elements. All other sets are heavy.

Key observation is that every light set contains less than  elements and number of heavy sets doesn't exceed  because we have upper bound for sum of the sizes of all sets.

In order to effectively answer queries, for every set (both light and heavy) we calculate size of the intersection of this set and each heavy set. It can be done with time and memory . For every heavy set we create boolean array of size O(n). In i-th cell of this array we store how many elements i in given set. Then for each element and each heavy set we can check for O(1) time whether element is in the set.

Now let's consider 4 possible cases:

Add to the light set. Traverse all numbers in the set and add the value from the query to each of them. Then traverse all heavy sets and add (size of intersection * the value from the query). Time is .

Add to the heavy set. Just update the counter for the heavy set. Time is O(1).

Answer to the query for the light set. Traverse all numbers in the set and add values to the answer. Then traverse all heavy sets and add to the answer (answer for this heavy set * size of intersection with the set in the query). Time is .

Answer to the query for the heavy set. Take already calculated answer, then traverse all heavy sets and add (answer for this heavy set * size of intersection with the set in the query). Time is .

We have O(n) queries so total time is .

348D - Turtles In the problem you're asked to find the number of pairs of non-intersecting paths between left upper and right lower corners of the grid. You can use following lemma for that. Thanks to rng_58 for the link. More precisely, considering our problem, this lemma states that given sets of initial A = {a1, a2} and final B = {b1, b2} points, the answer is equal to the following determinant:

 where f(x, y) — is equal to the number of paths from point x to point y. You can calculate this function using dynamic programming. Finally we need to decide what sets of initial and final points we choose. You can take A = {(0, 1), (1, 0)} and B = {(n - 2, m - 1), (n - 1, m - 2)} in order to make paths non-intersecting even in 2 points.

348E - Pilgrims Let’s build a simple solution at first and then we will try to improve it to solve problem more effectively given the constraints.

For every vertex let’s find the list of the farthest vertices. Let’s find vertices on the intersection of the paths between current vertex and each vertex from the list that don’t contain monasteries. If we remove any of these vertices then every vertex from the list is unreachable from the current monastery. For every vertex from the intersection increment the counter. Then the answer for the problem is the maximum among all counters and the number of such maxima.

Let’s solve the problem more effectively using the same idea. Let’s make the tree with root. For every vertex we will find the list of the farthest vertices only in the subtree. While traversing the tree using depth first search we return the largest depth in the subtree and the number of the vertex where it was reached. Among all of the sons of the current vertex we choose the maximum of depths. If maximum is reached one time then we return the same answer that was returned from the son. If the answer was reached more than one time then we return the number of the current vertex. Essentially, we find LCA of the farthest vertices according to the current vertex. Before quitting the vertex we increment the values on the segment between current vertex and found LCA. One can use Eulerian tour and segment tree for adding on the segment.

Finally, the last stage of solving the problem – to solve it for the case when the farthest vertex is not in the subtree of the current vertex. For solving of that subproblem we use the same idea that was used in the problem of the finding the maximal path in the tree. For every vertex we keep 3 maximums – 3 farthest vertices in the subtree. When we go down to the subtree, we pass 2 remaining maximums too. In that way, when we’re in any vertex, we can decide whether there’s a path not in the subtree (it means, going up) of the same or larger length. If there’re 2 paths of the same length in the subtree and not in the subtree, it means that for the pilgrim from the current monastery there’s always a path no matter what town was destroyed. If one of the quantities is larger then we choose the segment in Eulerian tour and increment the value on the segment. The case where there’s several paths (at least 2) out of the subtree of the same maximal length, is the same with the case in the subtree.

LCA and segment tree can be solved effectively in O(logN) time per query so the total memory and time is O(NlogN).

Codeforces Round #201 Editorial

By MinakoKojima, 9 years ago, In English  

Overview In DIV 1, there are 4 interesting problems together with a normal one. We think it is reasonable because we can't have a round fullly with intelligence. Problem A, C have weak pretests while others intended to be strong. About more then 200 participants solve A in the early 45mins, then a few of them start from C while most of the other start from B.

Problem B is a rather standard problem, but if you're unfamiliar with the algorithm, it can be very hard. Problem C is a more intersting problem. As the name implies, there was a similar version in the previous round before, but this time it has a brand new constrains.(So here we have a psychology experiment: could different constrains make people thinking in a slightly different way?ww)

The standard solution of problem C is O((b - a) + nlogn). The first expected correct solution was written by zeliboba. http://codeforces.com/contest/346/submission/4512654

After that, some people start to solve problem D. Problem D looks like a hard dp problem on a graph at the first glance, the key point is how to avoid the circle in the transfer equation. It turn out to be elegant after you could found a right order of the evaluation. Problem E is challenging which you need find a way to transform the original question into a smaller scale, and cut off many many corner cases ... And in the very end, you find a way like binary search to get O(logn) as the time complexity. No one manage to solve problem E during the contest, maybe Petr is the man who closest to it.

The winner comes to cgy4ever, because he found the draw-black in his previous C submission during the very beginning even when there is nobody hack him! He resubmit it decisively and get back when finished problem D. After that, he use the same trick which made him failed before to hack others and got a handsomely rewards. The second place went to rng_58, because of the combination of decent speed in A, B, C, D.

Problem B belongs to me, problem C belongs to CMHJT and others belong to UESTC_Nocturne. The illustrator of problem C is Chairman Miao(貓主席).

Editorial Problem A. Alice and Bob Brief description: Alice and Bob play a game, the rules are as follows: First, they will get a set of n distinct numbers. And then they take turns to do the following operations. During each operation, either Alice or Bob can choose two different numbers x and y from the set, as long as |x - y| is not in the set, then they add it to the set. The person who can not choose two numbers successfully will lose the game. The question is who will finally win the game if both of them do operations optimally. Remember that Alice always goes first.

Analysis: First, no matter what happend, the number set we get at the very endding will be same all the time. Let's say d = gcd{xi}. Then the set in the endding will be some things like {d, 2d, 3d, ... max{xi}}. So there is always max{xi} / d — n rounds. And what we should do rest is to check the parity of this value.

Problem B. Lucky Common Subsequence Brief description: You have been given two strings s1, s2 and virus, and you have to find the longest common subsequence of s1 and s2 without virus as a substring.

Analysis: This is a rather classical problem, let's say if there is no virus, then it is the classical **LCS ** problem. You can solve this by a O(n2) dynamic programing.

When consider about the virus, we should add 1 more dimension on the state to trace the growth of the virus. It can be done by wheather Aho-Corasick automation, or KMP when there is only one virus in this case. The overall time complexity is O(n3).

Problem C. Number Transformation II Brief description: You have a number b, and want to minus it to a, what you can do in each step is weather subtract 1 or b mod xi from b. And we ask what is the minimum number of steps you need.

Analysis: I bet there is a few people know the greedy method even if he/she have solved the early version before.

Codeforces #153 Div 1. Problem C. Number Transformation

Let dp[k] denotes the minimum number of steps to transform b+k to b. In each step, you could only choose i which makes b+k-(b+k) mod x[i] minimal to calc dp[k]. It works bacause dp[0..k-1] is a monotone increasing function. Proof: - Say dp[k]=dp[k-t]+1.If t==1, then dp[0..k] is monotone increasing obviously.Otherwise dp[k-1]<=dp[k-t]+1=dp[k] (there must exist a x[i] makes b+k-1 also transform to b+k-t,and it is not necessarily the optimal decision of dp[k-1]). So dp[k] is a monotone increasing function, we can greedily calc dp[a-b].

In the first glance, it looks like something which will run in square complexity. But actually is linear. That is because, we could cut exactly max{xi} in each 2 step. It can be proof by induction.

So the remians work is to delete those same xi, and watch out some situation could cause degeneration. Many of us failed in this last step and got TLE

Problem D. Robot Control Let's dp from t to s.

dp[u] = min(min(dp[v]) + 1 , max(dp[v])) | u->v

Here dp[u] means, the minimum number of orders mzry1992 needs to send in the worst case. The left-hand-side is sending order while the right-hand side is not. At the beginning, we have dp[t] = 1, and dp[s] will be the answer.

We can see there is circular dependence in this equation, in this situation, one standard method is using Bellman-Ford algorithm to evaluate the dp function.

But it is not appropriate for this problem.

(In fact, we add a part of targeted datas in pretest, these datas are enough to block most of our Bellman-Ford algorithm, although there is still a few participator can get accepted by Bellman-Ford algorithm during the contest.

Check rares.buhai's solution

dp[u] = min(min(dp[v]) + 1 , max(dp[v])) | u->v

The expected solution is evaluating the dp function as the increased value of dp[u] itself. Further analysis shows, wheather we decided sending order or not in u can be judged as the out-degree of u.

 while (!Q.empty()) {     u = Q.front(), Q.pop_front()     for each edge from v to u         --out_degree[v] 	if (out_degree[v] == 0) {            relax dp[v] by dp[u]            if success, add v to the front of Q 	} 	else{ 	   relax dp[v] by dp[u] + 1 	   if success, add v to the back of Q         }	   } Check Ra16bit's solution to see how it works.

Problem E. Doodle Jump Brief description: You have been give a, p, n, h (gcd(a, p) = 1), For each ai mod p, (i∈[1, n]), check weather the maximum distance in neighborhood after sorting is <= h.

Analysis: Take a =5, p =23 for example ... Divided the numbers in group.

0  5  10  15  20 2  7  12  17  22 4  9  14  19 1  6  11  16  21 3  8  13  18 We start a new group when the number > P

We found the difference between the elements of the first group is 5, The subsequent is filling some gap between the them ...

After some observation we could found that we should only consider into one gap ...(e.g. [0, 5] or [15, 20] or [20, 25] ... )

0  5  10  15  20 2  7  12  17  22 4  9  14  19 1  6  11  16 That says .. a =5, p =23 is roughly equal to some things in small scale?

So let's check it in detail. Lemma 1. In any case, the gap after 20 won't better than any gap before it.

0  5  10  15  20  2  7  12  17  22 4  9  14  19 1  6  11  16 For example, in this case, the gap after 20 is: 20, 22 And it has 16 in [15, 17] but no 21.

Is there any chance that [20, 23] is better than [15, 20]?

No, that is because, when there is no 21, then (19+5)%23 = 1, go to next floor. and there is no corresponding gap after 20 ([22, 24]) for this gap ([17, 19])

So we only need to consider [15, 20] ... and we found [15, 20] is roughly equal to [0, 5]

e.g. :    15 20 17 19 16 18  equal:     0  5  2  4  1  3 we say 'roughly' because we havn't check some boundary case like there is 3 but on 18 ...

0  5  10  15  20  2  7  12  17  22 4  9  14  19 1  6  11  16  21 3  8  13  If it happend, we should remove the number 3. .. If we can remove the element 5, then we can from a=5, p=23 to a'=2, p'=5 ...(n' = an/p, a' = a-p%a, if there is 3 but no 18, n'=n'-1)

The rest things is to discuss wheather 5 is necessary or not.

Let's we have:

0 2 4 1 3 If the 2*n'<5, then there is only one floor, the answer is max(2, 5-2*n'). If there is more than one floor, we could conclude that 5 is useless.

Proof: Elemets in 1st floor is:

0 a 2a 3a ... Let's say the maximum elements in 1st floor is x, then the minimum element in the 2nd floor is b0 = x+a-p, because b0 — a = x-p, so the difference between b0 and a is equal to the difference between x and p. That is, we can consider [b0, a] rather than [x, p], when there is a element insert in [b0, a], there must be some element insert in [x, p] in the same position.

So we have have succeeded to transform our original problem into a small one. Of couse, this problem havn't been solved, we haven't consider the time complexity. Says a' = a — p%a, when p = a+1, then a' = a-1, but we have a equal to 10^9, it won't work.

But, let's we have A1, A2, ... An ... and we subtract d from all of them, the answer won't be changed. So we can use p%a substitute for a-p%a, this is equivalent to we subtract %p% from all of them ...

So we set a' = min(a-p%a, p%a), so a'<=a/2, therefore, the final time complexity is O(logn).

You can check Petr 's solution for detail.




Codeforces Round #500 (based on EJOI 2018) — Editorial

By cdkrot, history, 5 years ago, In EnglishD2A author: 300iq, cdkrot, developer: 300iq

1013A - Piles With StonesIt can be simply showed that the answer is «Yes» if and only if the sum in the first visit is not less than the sum in the second visit.

D2B author: isaf27, developer: cdkrot

1013B - AndClearly, if it is possible then there are no more than 2 operations needed.

So we basically need to distinguish 4 outcomes —  - 1, 0, 1 and 2.

The answer is zero if there are already equal elements in the array.

To check if the answer is -1 we can apply the operation to each element of the array. If all elements are still distinct, then it couldn't be helped.

To check if the answer is one we can bruteforce the element a to apply the operation to, and if this operation changes this element, we can check if there is an a & x element in the array.

In all other cases answer is two.

D1A author: isaf27, developer: isaf27

1012A - Photo of The SkyAt first let's sort array a, so we can assume that a1≤a2≤⋯≤a2⋅n.

Note that area of rectangle with bottom-left corner in (x1,y1), and up-right corner in (x2,y2) is (x2−x1)⋅(y2−y1).

So the task is to partite array a into 2 multisets (sets with equal elements) X and Y of size n, such that (max(X)−min(X))⋅(max(Y)−min(Y)) is minimal among all such partitions (min(X) — minimum in multiset X, max(X) — maximum in multiset X).

Let's look at such partition

There are 2 cases:

Minimum and maximum are in one multiset. Let's assume that they are both in X. Then max(X)−min(X)=a2⋅n−a1. We need to minimize max(Y)−min(Y). If index of min(Y) in a is i, and max(Y) is j, htne j−i≥n−1, because there are n elements in Y. So we can use Y={ai,ai+1,…,ai+n−1} and desired difference will not increase. So as Y it is optimial to use some segment of length n.Minimum and maximum are not in one multiset. Let's assume that minimum in X, and maximum in Y. Then note, that maximum in X always ≥an, because size of X is n. And minimum in Y will be ≤an+1, because size of Y is n. So (max(X)−min(X))⋅(max(Y)−min(Y))≥(an−a1)⋅(a2⋅n−an+1), so you can use prefix of length n as X and suffix of length n as Y.So answer is minimum of (a2⋅n−a1)⋅(ai+n−1−ai) for each 2≤i≤n and (an−a1)⋅(a2⋅n−an+1). That is, you can simply check all contigious subsets as first set and all the remaints as the second one.

Complexity is O(n⋅log(n)).

Jury's solution (isaf27): 40973089

D1B author: 300iq, developer: Flyrise

1012B - Chemical tableOne of the way to solve this problem is to interprete the cells in 2d matrix as an edge in the bipartite graph, that is a cell (i, j) is an edge between i of the left part and j of the right part.

Note, that each fusion operation (we have edges (r1, c1), (r1, c2), (r2, c1) and get edge (r2, c2)) doesn't change the connected components of the graph.

Moreover, we can prove, that we can obtain each edge in the connected component by fusion.

Let's examine example edge (x, y), and some path between x and y (since they lay in one connected component). Since the graph is bipartite, the length of this path must be odd, and it is  ≥ 3, otherwise the edge already exists.

So we have this path. Take first three edges and make the corresponding fusion, replace this three edges with the brand new fused edge. The length of the path decreased by 2. Repeat until the path is a mere edge.

This way, the number of edges to add (cells to buy) is just number of connected components minus one.

D1С author: pashka, developer: cdkrot

1012C - HillsThe problem's short statement is: "we allowed to decrease any element and should create at least k local maximums, count the minimum number of operations for all k".

Notice, that any set of positions, where no positions are adjacent could be made to be local maximums — we just need to decrease the neighbouring hills to some value.

Let's introduce the following dynamic programming:

dp[prefix][local_maxs] – the minimum cost if we analyze only given prefix, have the specified number of local maximums ("good hills to build on") and we make a local maximum in the last hill of this prefix.

Th dumb implementation of this leads to O(n2) states and O(n4) time — in each state we can brute force the previous position of local maximum (n) and then calculate the cost of patching the segment from previous local maximum to current one.

A more attentive look says that it is, in fact O(n3) solution — on the segment only first and last elements need to be decreased (possibly first and last elements are same).

To get the full solution full solution in O(n2) we need to optimize dp a little bit. As we noticed in the previous paragraph, there is one extreme situation, when the first and elements are same, let's handle this transition by hand in O(1) for each state.

Otherwise, funny fact, the cost of the segment strictly between local maximums is the cost of it's left part plus it'cost of it's right part. Seems like something we can decompose, right?

Since our goal is to update state (prefix, local) now the right part is fixed constant for all such transitions. And we need to select minimum value of dp[i][local - 1] + cost(i, i + 1) where i <  = prefix - 3.

This can be done by calculating a supplementary dp during the primarily dp calculation — for example we can calculate f[pref][j] = min dp[i][j] + cost(i, i + 1) for i ≤ pref.

D1D author: tourist, developers: qoo2p5, VArtem

1012D - AB-StringsThe solution is basically like following:

Note that we can compress equal adjacent letters.

Now we can do a dynamic programming with params (first letter of s, length of s, first letter of t, length of t).

However, the amount of transactions and even states is too large. But we can write a slow, but surely correct solution, and examine the transactions, which are made in dp.

Basically, the most typical transaction is to just make a swap of first group in s with first group in t. However there special cases, like when the first letters are the same or when the lengths are very small.

Running a slow dynamic programming helps to get all the cases for the solution.

Formally, the correctness of this algorithm can be proven by induction and the large cases analyses, which we skip for clarity.

Another approach is to consider different first operations, and then go a greedy after it algorithm. See the second solution for the details. We don't prove it.

The first solution: 40971595 and the second solution: 40971634.

D1E author: isaf27, developer: isaf27

1012E - Cycle sortLet's solve an array if a is permutation and the sum of cycle sizes is unlimited.

It's known that each permutation is composition of some non-intersecting cycles. If permutation is sorted answer is 0. If permutation is 1 cycle and some fixed indexes answer is 1, you should take this cycle to get this answer. If permutation is composition of ≥2 cycles answer should be ≥2, because it's impossible to use 1 cycle. In this case it's possible to make the answer with 2 cycles. Let's define inversed permutation for our permutation as composition of this cycles (p11→p12→⋯→p1k1→p11),…,(pm1→pm2→⋯→pmkm→pm1) (all cycles, except cycles with length 1). We can sort permutations using this 2 cycles: (p11→p12→⋯→p1k1→p21→⋯→pm1→pm2→⋯→pmkm→p11) (all cycles, written in a row) and (pm1→pm−11→…p11→pm1) (first elements of cycles in inversed order). This solution used sum of cycle sizes t+m, there t — number of non-fixed elements and m — number of cycles with size 1.

Now let's solve problem for permutation, if we can use sum of cycle sizes ≤s. Each solution should use sum of cycle sizes ≥t, because we should shift each non-fixed element. So if s<t answer is −1. Let's call each cycle from m cycles bad, if each of it's element shifted exactly 1 time in the answer. It can be proved, that each bad cycle should be used in the answer. Let's define x as number of bad cycles and y number of other cycles. So x+y=m. Sum of cycles in the answer ≥t+y. So, t+y≤s ==> y≤s−t ==> x=m−y≥m+t−s. Number of cycles in the answer ≥x+min(y,2). It's true, because each of x bad cycles are in answer and other y cycles can be sorted using ≥min(y,2) cycles. We should take x as maximal as possible, because if we increase x by 1 sum min(y,2)+x won't increase. Minimal x, that we can use is max(0,m+t−s). So we get y=m−max(0,m+t−s)=m+min(s−t−m,0)=min(s−t,0)=s−t (because s≥t). So answer in this case if max(0,m+t−s)+min(s−t,2). We can build it, if we use x=max(0,m+t−s) any of m cycles, and for other y=s−t cycles do same construction as in previous case.

Let's solve problem for array. Let's define b as sorted array a and t as count of 1≤i≤n, such that ai≠bi. Our solution will sort some permutation p, such that api=bi, for all i. Answer for permutation is max(0,m+t−s)+min(s−t,2). In this formula s и t fixed. So to minimize the answer we should minimize m. So we should sort array using array with as minumal as possible number of cycles. To do it let's build directed graph: vertexes is number in array, let's add edge from ai to bi for all i, such that ai≠bi. It's easy to see, that we should take euler cycle in each component of this graph and build permutation with this cycles to make number of cycles in permutation as minimal as possible.

To code this solution without building graph let's take first any sorting permutation. After that, we can merge cycles. If ai=aj and i and j in different cycles of permutation, we can merge this cycles using swap(pi,pj). So let's merge all possible cycles using DSU for components.

Time complexity: O(n∗log(n)).

Jury's solution (by isaf27): 40973023

D1F author: GlebsHP, developers: demon1999, PavelKunyavskiy

1012F - PassportsLet's solve the P = 1 case first. We'll use dynamic programming on subsets. Let's try to add visas to subset in order of application. Notice that if we only have one passport, every visa processing segment should lie between some two consecutive trips. For convenience, let's find all these segments beforehand.

Define dp[A] as the minimum day, before which all visas from set A can be acquired. Try all possible i as a visa which Gleb will apply for next. Now we have to find minimum possible day of application d, such that d ≥ dp[A], segment [d, d + ti] does not intersect with any trip, and d + ti < si. Such d can be found in O(n) by a linear search over precalculated free segment. Relax the value of  with d + ti. If dp[{1..n}] <  + ∞ then there is a solution that can be restored using standard techniques. Total time complexity is O(2n n2), that can be too slow for n = 22.  

Let's generalize this solution for P = 2. Still, Gleb can apply for a visa only when he is in Innopolis. However, the last day of visa processing can be during some trip, but only if all trips between the day of visa application and the day of visa acquisition use another passport. We will slightly change the definition of dp[A]: now this value is equal to the minimum possible day, by which it's possible to finish processing all visas from set A with one passport, assuming all trips not from A use another passport. By this definition, calculation of DP transition is a little bit different: when trying to add visa i we have to find minimum d, such that d ≥ dp[A], during day d Gleb is in Innopolis, and segment [d, d + ti] does not intersect with half-closed intervals [sj, sj + lenj) for all . This can be implemented similarly to the first part in O(n). Total running time is O(2n n2), that can pass system tests with some optimizations.

We'll optimize the solution down to O(2n n). To do that, we process all transition from set A in O(n) total time. Sort all visas in order of increasing ti. Then the optimal visa application day d will be increasing if visa processing time ti increases. Now we can apply two pointers technique to get O(n) total processing time for one set and O(2n n) for all sets.

After calculating dp[A] for all subsets, we have to try all partitions of {1..n} into two sets A and B and check if both A and B can be done with one passport each. This is equivalent to dp[A] <  + ∞. If there are two such sets that dp[A] <  + ∞ and dp[B] <  + ∞, then we have found the answer, otherwise there is no answer.

Credits to all jury members, who contributed to this round and EJOI: tourist, PavelKunyavskiy, niyaznigmatul, 300iq, GlebsHP, pashka, qoo2p5, VArtem, demon1999, Flyrise, ifsmirnov, isaf27, yeputons, cdkrot.

Codeforces Round #499 — editorial

By VladProg, 5 years ago, translation, In English1011A - Stages

Author: Mike Mirzayanov (MikeMirzayanov).

Tutorial1011A - StagesThe problem can be solved by the following greedy algorithm.

Sort letters in increasing order. Let's try to add letters in this order. If the current letter is the first in the string, then add it to the answer. Otherwise, check: if the current letter is at least two positions later in the alphabet than the previous letter of the answer, add it to the response, otherwise go over to the next letter.

As soon as there are k letters in the answer, print it. If after this algorithm the answer has less than k letters, print -1.

Complexity: O(nlogn).

Solution1011B - Planning The Expedition

Author: Mike Mirzayanov (MikeMirzayanov).

Tutorial1011B - Planning The ExpeditionLet ci be the number of food packages that equal to i. Calculate the array c.

For any d we can calculate the maximum number of people k, who can participate in the expedition for d days. To do this, we'll go over all the elements of the array c. Let now be considered ci. If ci≥d, we can decrease ci by d and increase k by 1, that is, take d daily food packages for one person. If still ci≥d, repeat the algorithm, and so on. That is for i-th iteration number k increases by ⌊cid⌋. After all the iterations the number k will be the required number of people.

It is clear that the answer does not exceed m (every day at least one food package is used).

Let's iterate d from m to 1, each time checking whether the answer can be equal d. To do this, we calculate the maximum number of people k, who can participate in the expedition for d days. If k≥n, then the answer is d. If no answer was received on any iteration, then the answer is 0.

Complexity: O(m2).

Bonus. Try to improve the complexity to O(mlogm).

Solution1011C - Fly / 1010A - Fly

Author: Vladislav Zavodnik (VladProg).

Tutorial1010A - FlyFirst, we learn how to determine if a rocket can fly the entire route. Consider an element from an array a[] or b[]. We denote it by t. If t=1 (that is, one ton of fuel can carry only one ton (cargo + fuel)), then fuel can only take it to ourselves, and we need to take a rocket and a useful cargo (the mass of which is positive). That is, if t=1 at least for one t, it is necessary to deduce −1, otherwise, do the following calculations.

It is clear that arrays a[] and b[] will be processed by the computer of the rocket in that order: a1,b2,a2,b3,a3,b4,a4,…,bn−1,an−1,bn,an,b1. We will process this sequence from the end. Let at the current iteration the mass of the payload (including fuel that will not be used at this iteration) is s tons, the current element from the array a[] or b[] is t, the mass of fuel that will be used at this iteration (it must be found), is x. We assign before the iterations s=m. We form the equation:

total mass = mass that all fuel can transport

s+x=txx=st−1By this formula, you can find fuel in this iteration. For the next iteration to the payload weight, you need to add mass of fuel (since this fuel needs to be brought to this iteration), that is, perform the assignment s=s+x. In the end, it is necessary to deduce s−m.

Complexity: O(n).

Bonus. In fact, it does not matter in which order to process arrays a[] and b[] (from the beginning, from the end or in general mixed): the answer from this will not change. Try to prove it by yourself.

Solution1011D - Rocket / 1010B - Rocket

Author: Vladislav Zavodnik (VladProg).

Tutorial1010B - RocketFirst we learn the sequence p[]. For this print the query "1" n times. If the answer is "0" (that is, the distance to Mars is equal to one), then immediately terminate the program. Otherwise, it is clear that the correct answer is "1" (that is, the distance to Mars is greater than one). If i-th answer of rocket is "1", then p[i]=1 (that is, the rocket answered the truth), otherwise p[i]=0 (untruth). On this, we will spend no more than n queries, within the given constraints it is 30.

Now you can find the number x using binary search. For each answer, you need to check: if the corresponding element of the sequence p equals to 0, then the answer sign must be changed. On this, we will spend no more than ⌈log2m⌉ queries, within the given constraints it is 30.

The total number of queries does not exceed n+⌈log2m⌉≤30+30=60.

Complexity: O(n+logm)Bonus. Try to solve a similar problem but with a constraint 1≤m≤1073741853.

Solution1011E - Border / 1010C - Border

Author: Vladislav Zavodnik (VladProg).

Tutorial1010C - BorderNote that the condition "the last digit in the record of Natasha's tax amount in the number system with the base k will be d" is equivalent to the condition "the remainder of dividing the tax on k will be d".

Let g=GCD(a1,a2,…,an). It is stated that the original problem is equivalent to the problem where n=1 and the only banknote is g.

Evidence. We prove this with the help of the Bézout's identity. It follows that an equation of the form a1x1+a2x2+⋯+anxn=c, where at least one of the parameters a1,a2,…,an is not zero, has a solution in integers if and only if c⋮GCD(a1,a2,…,an). Then in this task Natasha can pay xi banknotes of the i-th nominal value for each i, where 1≤i≤n, and the amount of tax (a1x1+a2x2+⋯+anxn) can be any number c, multiple g. (Here some xi<0, But Natasha can add for each par a sufficiently large number, multiple k, that xi became greater than zero, the balance from dividing the amount of tax on k from this will not change.) Therefore, you can replace all pars with one par g and the answer from this will not change.

Now we can sort out all the numbers of the form gxmodk, where 0≤x<k (further the remainder of the sum, divided by k will cycle repeatedly) and output them in ascending order.

Complexity: O(n+logm+klogk), where m is the greatest ai.

Bonus. Try to improve the complexity to O(n+k).

Solution1011F - Mars rover / 1010D - Mars rover

Author: Vladislav Zavodnik (VladProg).

Tutorial1010D - Mars roverLet's count the bit at each vertex. This can be done using depth-first search on this tree. Now for each vertex, let's check: whether the bit on the output of the scheme will change if the bit in the current vertex is changed. If all the vertices on the path from this vertex to the output of the scheme. If at least one of them does not change, then the output of the scheme does not change, and vice versa: if the output of the scheme is changed, then each vertex on the path under consideration will change. Now the solution can be implemented as follows. For each vertex, let's make a note: whether the bit on the output of the scheme will be changed if the bit on the current vertex is changed. For output of the scheme, this note is true. Now let's do the depth-first search on this tree. If note at the current vertex is equal to false, then at the inputs to it we make the note equal false, otherwise, for each input to this vertex, we do the following. Let's see if the current vertex is changed if the current input is changed. If it is changed, then at this input we will make the note equal true, otherwise false.

Complexity: O(n).

Solution1010E - Store

Author: Vladislav Zavodnik (VladProg).

Tutorial1010E - StoreConsider 2 options:

m=0. This means that Natasha does not know about any moment when the store was closed. Let's find the numbers xl=min(xi), xr=max(xi), yl=min(yi), yr=max(yi), zl=min(zi), zr=max(zi), where (xi,yi,zi) are moments when store is open. For each query (xt,yt,zt) answer "OPEN", if xl≤xt≤xr, yl≤yt≤yr, and zl≤zt≤zr. Answer "UNKNOWN" otherwise.m≠0. Let's find the numbers xl=min(xi), xr=max(xi), yl=min(yi), yr=max(yi), zl=min(zi), zr=max(zi), where (xi,yi,zi) are moments when store is open. If there is at least one moment (xj,yj,zj), when the store is closed, and xl≤xj≤xr, yl≤yj≤yr and zl≤zj≤zr, then the answer is "INCORRECT". Otherwise, let's create a compressed two-dimensional segment tree. The first coordinate is number of the month in the year, the second coordinate is number of the day in a month. At each vertex of the tree of segments we store a pair of numbers — the greatest such number of a second z, when the store was closed, in this day of this month, that z≤zr, and the smallest such number of a second z, when the store was closed, in this day of this month, that z≥zl. Now every query (xt,yt,zt) we will handle like this. If xl≤xt≤xr, yl≤yt≤yr and zl≤zt≤zr, answer "OPEN". Otherwise, consider the parallelepiped given by the coordinates of opposite vertices (xl,yl,zl) and (xr,yr,zr) and consider each vertex in turn (xp,yp,zp) the parallelepiped under consideration. Let's make the query in the segment tree (xp,xt), (yp,yt). Let the received answer is (zfirst,zsecond). If the number zfirst or number zsecond is between numbers zp and zt, this means that there is such a time point (xj,yj,zj), when the store is closed, that xj is between xp and xt (the month of the year when the store is closed, is between the month in the year when the store is open, and the month in the year in the query), yj is between yp and yt (the day in the month when the store is closed is between the day in the month when the store is open and the day in the month in the query), zj is between zp and zt (second in a day, when the store is closed, is between a second in a day, when the store is open and a second in a day in the query), hence the answer to the query is "CLOSED". If the condition is not satisfied for any vertex of the parallelepiped, the answer is "UNKNOWN".Complexity: O(n+mlogm+klog2m).

Solution1010F - Tree

Authors: Ildar Gainullin (300iq) and Dmitry Sayutin (cdkrot).

Tutorial1010F - TreeLet bv=av−∑ato, (for each (v,to), such that to — is a son of v and tree have both vertices v and to), then all that we need is bv≥0 and ∑bv=x, so for fixed subset of vertices number of ways to arrange weights is just number of ways to partite x into such number of parts.

So let fi be number of ways to choose connected subtree of i vertices, that contains vertex 1, then answer is ∑fiCi−1x+i−1.

Then we need to calculate fi for each 1≤i≤n, and calculate Ci−1x+i−1 for each 1≤i≤n.

Let's use generating functions to calc fi.

Let dpv be generating function of ∑fi⋅xi, (if we will assume that v — root and we will look only at vertices inside subtree of v).

Then if vertex v — leaf, then dpv=x+1, if this vertex have one son, dpv=dptox+1, and if two, then dpv=dpldprx+1.

Then let maintain dpv as a sequence of polynomials a1,a2,…,ak, что dpv=(((a1+1)a2+1)…)ak+1).

Then if we have the representation of dpv in such format, we can find the exact value of polynomial in the sum of sizes of polynomials ⋅log2n.

For it you can note, that dpv is just a1a2a3…ak+a2a3…ak+…+ak+1.

And then with FFT you can calculate value and multiplication for left half (Pl(x) и Ql(x)), and for right half (Pr(x) и Qr(x)).

Then P(x)=(Pl(x)−1)Qr(x)+Pr(x), а Q(x)=Ql(x)Qr(x).

So, you can calculate exact value of dpv in T(n)=2T(n/2)+O(nlogn)=O(nlog2n) (Where n is sum of sizes of polynomials).

Then if v — leaf just add x into the sequence of polynomials.

If v have one son, then add x into the sequence of polynomials of a son, and take his sequence as a sequence for vertex v.

And if v have two sons, Let's take a son with the smaller size of a subtree, find its exact value as written, and add it into the sequence of another son.

Sum of sizes of smaller subtrees is O(nlogn), so we can find f in O(nlog3n).

Note, that you can find similar value when the tree is not binary too, for it you can find the exact value of all children without largest, and multiply it in O(nlog2(n)) with D&C.

To calculate Ci−1x+i−1 for each 1≤i≤n you can note, that when i=1 it is just 1, and to get a value for i+1 you need multiply current value on x+i−1 and divide on i.

Then you can find scalar multiplication of these two vectors, and solve the task in O(nlog3n).



Solution

Codeforces Round #498 (Div. 3) Editorial

By vovuh, history, 5 years ago, In English1006A - Adjacent Replacements

Tutorial1006A - Adjacent ReplacementsIt is easy to see that for the odd elements there is no changes after applying the algorithm described in the problem statement, and for the even elements there is only one change: each of the even elements will be decreased by 1. So we can iterate over all the elements of the array and print ai−(ai%2), where x%y is taking x modulo y.

Overall complexity is O(n).

Solution (Vovuh)1006B - Polycarp's Practice

Tutorial1006B - Polycarp's PracticeThe maximum possible total profit you can obtain is the sum of the k largest values of the given array. This is obvious because we can always separate these k maximums and then extend the segments corresponding to them to the left or to the right and cover the entire array. I suggest the following: extract k largest values of the given array and place a separator right after each of them (except the rightmost one).

Overall complexity is O(nlogn).

Solution (Vovuh)1006C - Three Parts of the Array

Tutorial1006C - Three Parts of the ArraySince the given array consists of positive integers, for each value of a, there can be at most one value of c such that sum1=sum3. We can use binary search on the array of prefix sums of d to find the correct value of c, given that it exists. If it does exist and a+c≤n, this is a candidate solution so we store it. Alternatively, we can use the two pointers trick – when a increases, c cannot decrease. Be careful to use 64 bit integers to store sums.

Overall complexity is O(nlogn) or O(n).

Solution (Vovuh, set)Solution (ivan100sic, two pointers)1006D - Two Strings Swaps

Tutorial1006D - Two Strings SwapsLet's divide all characters of both strings into groups in such a way that characters in each group can be swapped with each other with changes. So, there will be following groups: {a1,an,b1,bn}, {a2,an−1,b2,bn−1} and so on. Since these groups don't affect each other, we can calculate the number of preprocess moves in each group and then sum it up.

How to determine if a group does not need any preprocess moves? For a group consisting of 2 characters (there will be one such group if n is odd, it will contain a⌈n2⌉ and b⌈n2⌉), that's easy — if the characters in this group are equal, the answer is 0, otherwise it's 1.

To determine the required number of preprocess moves for a group consising of four characters, we may use the following fact: this group doesn't require preprocess moves iff the characters in this group can be divided into pairs. So if the group contains four equal characters, or two pairs of equal characters, then the answer for this group is 0. Otherwise we may check that replacing only one character of ai and an−i+1 will be enough; if so, then the answer is 1, otherwise it's 2.

Overall complexity is O(n).

Solution (Ne0n25)1006E - Military Problem

Tutorial1006E - Military ProblemLet's form the following vector p: we run DFS from the first vertex and push the vertex v to the vector when entering this vertex. Let tinv be the position of the vertex v in the vector p (the size of the vector p in moment we call DFS from the vertex v) and toutv be the position of the first vertex pushed to the vector after leaving the vertex v (the size of the vector p in moment when we return from DFS from the vertex v). Then it is obvious that the subtree of the vertex v lies in half-interval [tinv;toutv).

After running such DFS we can answer the queries. Let posi=vi+ki−1 (answering the i-th query). If posi is greater than or equal to n then answer to the i-th query is "-1".

We need to check if the vertex pposi lies in the subtree of the vertex vi. The vertex a is in the subtree of the vertex b if and only if [tina;touta)⊆[tinb;toutb).

If the vertex pposi is not in the subtree of the vertex vi then answer is "-1". Otherwise the answer is pposi.

Overall complexity is O(n+q).

Solution (mareksom)1006F - Xor-Paths

Tutorial1006F - Xor-PathsThis is a typical problem on the meet-in-the-middle technique.

The number of moves we will made equals n+m−2. So if n+m would be small enough (25 is the upper bound, I think), then we can just run recursive backtracking in O(2n+m−2) or in O((n+m−2m−1)⋅(n+m−2)) to iterate over all binary masks of lengths n+m−2 containing exactly m−1 ones and check each path described by such mask (0 in this mask is the move to the bottom and 1 is the move to the right) if its xor is k.

But it is too slow. So let's split this mask of n+m−2 bits into two parts — the left part will consist of mid=⌊n+m−22⌋ bits and the right part will consist of n+m−2−mid bits. Note that each left mask (and each right mask too) uniquely describes the endpoint of the path and the path itself.

Let's carry n×m associative arrays cnt where cntx,y,c for the endpoint (x,y) and xor c will denote the number of paths which end in the cell (x,y) having xor c.

Let's run recursive backtracking which will iterate over paths starting from the cell (1,1) and move to the right or to the bottom and maintain xor of the path. If we made mid moves and we are currently in the cell (x,y) with xor c right now, set cntx,y,c:=cntx,y,c+1 and return from the function. Otherwise try to move to the bottom or to the right changing xor as needed.

Let's run another recursive backtracking which will iterate over paths starting from the cell (n,m) and move to the left or to the top and maintain xor of the path except the last cell. The same, if we made n+m−2−mid moves and we are currently in the cell (x,y) with xor c right now, let's add cntx,y,kc to the answer (obvious, that way we "complement" our xor from the right part of the path with the suitable xor from the left part of the path). Otherwise try to move to the left or to the top changing xor as needed.

So, this is the meet-in-the-middle technique (at least the way I code it).

Overall complexity is O(2n+m−22⋅n+m−22).

Solution (Vovuh)

Editorial for Codeforces Round #497 by Skyglow

By SirShokoladina, history, 5 years ago, In English1008A - RomajiYou need to check if after every letter except one of for these "aouien", there goes one of these "aouie". Do not forget to check the last letter.

1008B - Turn the RectanglesYou need to iterate over the rectangles from left to right and turn each rectangle in such a way that its height is as big as possible but not greater than the height of the previous rectangle (if it's not the first one). If on some iteration there is no such way to place the rectangle, the answer is "NO".

1007A - Reorder the ArrayThe answer is n minus maximal number of equal elements.

Let the maximal number of equals be x. Let's proove that n−x is reachable. It's clear that for every permutation of the array the answer will be the same, so let's sort the array in non-decreasing order. Now we should just make a left shift on x. After it the n−x right elements will move to a position of a smaller element.

Now let's proove that the answer is no more than n−x. Let's consider some permutation. It's known that every permutation breaks into cycles. Let's look at two occurences of the same number in the same cycle. Then there is at least one number between them which will move on a postion of a non-smaller element. Even if it the same occurence and even if the length of the cycle is 1, we can say that for every occurence of this number there is at least one number which moves on a postion of a non-smaller one. So if some number occurs x times, there are at least x bad positions and therefore no more than n−x good positions.

To count the number of equals you can, for instance, use std::map.

1007B - Pave the ParallelepipedFirst solution.

First, for every natural number up to 105 we count its number of divisors in O(n−−√). Also for every unordered set of 3 masks (m1,m2,m3) of length 3 we check if there is а way to enumerate them in such a way that 1∈m1, 2∈m2 and 3∈m3. We will call such sets acceptable.

Now let's consider two parallelepipeds. For each dimension of the second parallelepiped let's construct a mask of length 3 which contains the numbers of the dimensions of the first parallelepiped for which the length of the first parallelepiped along this dimension is divisible by the length of the second parallelepiped along the chosen dimension. Now these three masks form an acceptable set iff we can pave the first parallelepiped with the second one.

Now for a given parallelepiped let's calculate for every mask of length 3 the number of possible lengths of the second parallelepiped which would produce this mask. We can do this by taking the GCD of the lengths of the first parallelepiped along the dimensions whose numbers are in the mask, and subtracting from it the calculated numbers for every submask.

Now let's iterate over acceptable sets of masks. For each different mask from the set which is included into the set k times we need to calculate the number of ways to take k unordered lengths which produce this mask, and multiply these numbers. The sum of these numbers is the answers to the query.

So for every query we need O(2m2) operations, where m=3 is the number of dimensions of the parallelepiped.

Second solution.

First, for every natural number up to 105 we count its number of divisors in O(n−−√).

Then for every query for every subset of numbers in it we keep their GCD and the number of its divisors. So for every subset of this three numbers we know the number of their common divisors.

Let's look at the parallelepiped (a,b,c). The way we orient it with respect to the large parallelepiped is determined by a permutation of size 3 — that is, which dimension would correspond to every dimension in the large one. Using the inclusion-exclusion principle on this permutations we can count how many there are such parallelepipeds (considering the orientation) that we can orient some way to then pave the large parallelepiped with it. Namely, we fix the set of permutations for which our parallelepiped shall satisfy. Then for every side of the small parallelepiped we know which sides of the large one it shall divide. To find the number of such sides of the small one we shall take the number of common divisors of the corresponding sides of the large one. Now to find the number of such small parallelepipeds we must multiply the three resultant numbers.

In such way every satisfying this criteria parallelepiped (not considering the orientation) with three different side lengths was counted 6 times, with two different lengths was counted 3 times, with one different length was counted 1 time. But it won't be difficult for us to use the same approach in counting such parallelepipeds, but with no less than two same side lengths: let's say the first and the second. To do this when we fix which permutations this parallelepiped shall satisfy we should just add the condition that its first and second side lengths must be equal, this means they both must divide both of the sets corresponding to them, so instead of this two sets we must take their union.

Let's add the resultant number multiplied by three to the answer. Now every parallelepiped with three different side length is still counted 6 times, with two different is now counted also 6 times, and with one different is counted 4 times. The number of satisfying parallelepipeds with equal sides is just the number of common divisors of all the sides of the large parallelepiped. Let's add it multiplied by two, and now every needed parallelepiped is counted 6 times. We divide this number by 6 and get the answer.

So for every query we need O(p(m)⋅2m!⋅m) operations, where p(m) is the number of partitions of m, and m=3 is the number of dimensions of the parallelepiped.

1007C - Guess two numbersFirst solution:

Let's keep the set of possible answers as a union of three rectangles forming an angle: A=[xl,xm)×[yl,ym), B=[xl,xm)×[ym,yr) and C=[xm,xr)×[yl,ym), where xl<xm≤xr and yl<ym≤yr. Let SA, SB and SC be their areas. We will denote such state as (xl,xm,xr,yl,ym,yr). The initial state is (0,n+1,n+1,0,n+1,n+1).

Now there are three cases.

SB≤SA+SC and SB≤SA+SB, then we will make a query (⌊xl+xm2⌋,⌊yl+ym2⌋).If SB>SA+SC, we will make a query (⌊xl+xm2⌋,ym).Finally, if SC>SA+SB, we will make a query (xm,⌊yl+ym2⌋).In case of every response to every query, the new set of possible answers will also form an angle.

Now we want to prove that the area of the angle decreases at least by a quarter every two requests.

In case (1) if the answer is 1, then we move to a state (⌊xl+xm2⌋+1,xm,xr,yl,ym,yr). We cut off at least half of A and at least half of B. But SA2+SB2=SA+SB4+SA+SB4≥SA+SB4+SC4=SA+SB+SC4. I.e. We have cut off at least a quarter already within just one request. If the answer is 2, the situation is similar. Finally, if the answer is 3, then we move to a state (xl,⌊xl+xm2⌋,xr,yl,⌊yl+ym2⌋,yr). We cut off at least quarter of A, at least half of B and at least half of C. But SA4+SB2+SC2≥SA4+SB4+SC4=SA+SB+SC4. We also have cut off at least a quarter within just one request. Thus in case (1) we cut off at least a quarter within one request.

In case (2) if the answer is 1, then we move to a state (⌊xl+xm2⌋+1,xm,xr,yl,ym,yr). We cut off at least half of A and at least half of B. But SA2+SB2≥SB2≥SB4+SB4≥SB4+SA+SC4=SA+SB+SC4. We have cut off at least a quarter within just one request. If the answer is 2, then we move to a state (xl,xr,xr,ym+1,yr,yr). But then if will be case (1), thus we will cut off at least a quarter with the next request. Finally, if the answer is 3, then we move to a state (xl,⌊xl+xm2⌋,xr,yl,ym,yr). We cut off at at least half of B. But SB2≥SB4+SB4≥SB4+SA+SC4=SA+SB+SC4. We also have cut off at least a quarter within just one request.

Case (3) is similar to case (2).

Thus the maximal number of requests will be no more than 1+2∗log4/3((1018)2)≈577.

Second solution:

Let's keep the set of possible answers in form of a ladder A. Then lets find minimal X such that S(A∩{x≤X})≥S(A)3. And lets find minimal Y such that S(A∩{y≤Y})≥S(A)3. ThenS(A∩{x≥X}∩{y≥Y})=S(A∖(A∩{x≤X−1})∖(A∩{y≤Y−1}))≥≥S(A)−S(A∩{x≤X−1})−S(A∩{y≤Y−1})≥S(A)−S(A)3−S(A)3=S(A)3.I.e. we cut off at least third of the area of the ladder on each request.

Thus the maximal number of requests will be no more than 1+log3/2((1018)2)≈205.

1007D - AntsSlow solution.

We need to choose one of two paths for each ant so that they will not contain a common edge. Let's make a 2-SAT, and for each ant, we will create two contrary vertices: one will denote that we take the first path, and another will denote that we take the second path. Then for every two paths which share an edge, we add a condition that they can't be taken together. Now we just need to check that the 2-SAT has a solution.

The complexity is O(nm2).

First solution.

Let's build a binary tree with m leaves for each edge. Each vertex of the tree will be associated with some vertex of the 2-SAT. The vertex of the tree which covers leaves from l to r will be associated with a vertex of the 2-SAT which says if the edge should be painted with a color from l to r. To build a vertex which is associated with a leaf we just need to add for every path of the ant which covers the current edge a condition which tells that if we take this path, then this vertex is true. And for every non-leaf vertex of the tree we need to add three conditions. First and second: if any of the vertices associated with the two sons is true, then the vertex associated with the current vertex is also true (l→v, r→v). And third: both vertices associated with the two sons can't be true (l→!r).

The trees will be persistent, which means that if the vertex we want already exists, we will reuse it.

Now we will build such trees recursively. First for the children, and then for the current edge. To build a tree for a new edge we first take an empty tree, then for each child, we recursively merge its tree with the current. If during the merge one of the vertices is empty, we return the second vertex. Then we add the paths which end in the current vertex.

You have to be careful not to add the edges which will not be present in the final tree. For example, you can first build a tree, and then go through the new vertices one more time and add the edges.

Then as in the previous solution, we check if there is a solution of this 2-SAT.

It can be shown that for a vertex of the binary tree which covers k leaves there will be created no more than 8k instances of this vertex, because there are at most 4k ends of the paths connected with these leaves and at most 8k−1 vertices which are the LCA of some set of these vertices. Now if we summarize it over all the vertices of the binary tree, we get approximately 8mlog(m).

So the total complexity is O(mlog(m))Second solution.

Let L=64 be the number of bits in a machine word.

Let's calculate a matrix 2m×2m of ones and zeros, where cell (i,j) is filled with 1 iff the paths i and j have a common edge. We will store this matrix as an array of bitsets.

Let's run a DFS which for every edge will return a set of paths that cover it. We will store such sets in a map from number of block to a bitmask of length L. We recursively calculate the sets for the children. Also for every path which starts in the vertex, we make a set containing only this path. Then if some sets share the same path, we remove it from both. Then we merge them by always adding the smaller map to the larger. While doing so we iterate over the elements of the smaller map and over the blocks of the larger map and add a block of edges to the matrix. For now, it is enough to add each edge to the matrix only in one direction. It can be shown that it works in O(mlog2(m)+m2⋅log(L)L).

Now we want to transpose the matrix and add it to itself to make it complete. To do it we divide it into blocks L×L, and transpose them one by one, then swap the blocks. Here is how we transpose a block.

Assume L=2K. We will make K iterations. On the i−th iteration we will divide the block into subblocks 2i×2i and in each block, we will swap the top right quarter and the bottom left quarter. Each iteration can be performed in O(L). We can prove by induction that after i iterations each subblock 2i×2i will be transposed.

This step works in O(m2⋅log(L)L).

It is easy to get a bitset of straight edges and a bitset of reversed edges of the 2-SAT for every vertex using this matrix. Now if we store the visited vertices in a bitset, we can implement the 2-SAT algorithm in O(m2L).

The total complexity is O(mlog2(m)+m2⋅log(L)L).

1007E - Mini MetroLet's enumerate the hours and the stations starting from zero. Let's add a station to the end with an infinite number of people and infinite capacity. It is obvious that it will not affect the answer. Also, every train now will be filled completely.

Let's calculate sa[p], sb[p] and sc[p]: the sum of a[i], b[i] and c[i] over the first p stations respectively.

Let d[p][s][z] (0≤p≤n+1, 0≤s≤t, 0≤z≤1) be the minimal number of trains (or ∞, if impossible) needed to hold on for s hours, if there were only the first p stations, so that every train we used would be filled completely. Herewith the initial number of people on the i-th station equals z⋅a[i].

Let g[p][s][z] (0≤p≤n+1, 0≤s≤t, 0≤z≤1)be the minimal number of trains (or ∞, if impossible) needed to hold on for s with a half hours (so that we can send some trains at the end), if there were only the first p stations, so that every train we used would be filled completely and every station except for the last would contain in the end 0 people. Herewith the initial number of people on the i-th station equals z⋅a[i].

Then the answer for the problem is d[n+1][t][1].

Lets calculate d and g using dynamic programming.

In order to calculate d[p][s][z] and g[p][s][z] lets consider the last hour from 0 to s−1 in which some train will take a person from the last station. Notice that in case of g[p][s][z] we do not consider the s-th hour though there could be such trains during this hour.

First case: There were no such trains. In this case we just need to check that the last station won't overflow and that d[p−1][s][z]≠∞. Then we can make transitions:d[p][s][z]←d[p−1][s][z],g[p][s][z]←val=⌈z⋅sa[p−1]+s⋅sb[p−1]k⌉.The second transition is made only if val⋅k≤z⋅sa[p]+s⋅sb[p].

(*) In case of g[p][s][z] it is obvious that such number will be needed in order to set to zero all the stations except for the last one, and this number can be achieved since we can hold on for s hours without taking a person from the last station.

Second case: denote the number of this hour by r. Then the plan is as follows:

First, we need to hold on for r with a half hours and do so that on every station except for the last there will be 0 people.Then we possibly send some more trains during the r-th hour.Then we need to hold on for s−r without the first half hours without sending a train which will take a person from the last station.Then in case of g[p][s][z] we send some more trains during the s-th hour.During the phase (1) it is beneficial to send as few trains as possible, be'cause we can always send additional trains during the phase (2) and nothing will change. Thus we send g[p][r][z] trains. If g[p][r][z]=∞, then the transition is impossible.On the phase (2) we cat calculate the initial number of people on the last station: m=z⋅sa[p]+r⋅sb[p]−k⋅g[p][r][z], and then calculate the minimal number of trains we need to send so that the last station doesn't overflow by the end of the(s−1)-th hour: x=⌈max(m+(s−r)⋅b[p−1]−c[p−1],0)k⌉. If x⋅k>m, then the transition is impossible, else it is benificial to send x trains.

During the phase (3) it is beneficial to send as few trains as possible, be'cause in case of d[p][s][z] it is the last phase, and in case of g[p][s][z] we can always send additional trains during the phase (4) and nothing will change. Notice in the beginning of phase (3) the first p−1 are empty and also we can assume we are starting from the beginning of an hour and we need to hold on for s−r hours. Thus we need to send d[p−1][s−r][0] trains. If d[p−1][s−r][0]=∞, then the transition is impossible.

Finally, on the phase (4) we need to send as few trains as possible so that all the stations except for the last one would contain 0 people. As in (*) we can see that on phases (3) and (4) we need to send in total at least val = ⌈(s−r)⋅sb[p−1]k⌉ trains, and we can achieve this number.

We can make transitions:d[p][s][z]←g[p][r][z]+x+d[p−1][s−r][0],g[p][s][z]←g[p][r][z]+x+⌈(s−r)⋅sb[p−1]k⌉.The second transition is made only if val⋅k≤(s−r)⋅sb[p].

Solution time is O(nt2).

Codeforces Round 496 (Div. 3): Problem Tutorials

By MikeMirzayanov, 5 years ago, translation, In English1005A - Tanya and StairwaysThe answer contains such elements ai that ai+1=1. Also add to the answer the last element an.

Code in C++ for details1005B - Delete from the LeftLet's find the value w — the length of the longest common suffix of s and t. You can easily find it in one linear loop: just compare the last letters of s and t. If they are equal then compare before the last letters of s and t. And so on.

The last w letters of s and t are two equal strings which will be the result of after optimal moves. So the answer is |s|+|t|−2⋅w.

Code in C++ for details1005C - Summarize to the Power of TwoYou should delete only such ai for which there is no such aj (i≠j) that ai+aj is a power of 2.

For each value let's find the number of its occurrences. You can use simple map standard data-structure. Do c[a[i]]:=c[a[i]]+1 for each element a[i].

Now you can easily check that ai doesn't have a pair aj. Let's iterate over all possible sums s=20,21,…,230 and for each s find calculate s−a[i]. If for some s: c[s−a[i]]≥2 or c[s−a[i]]=1 && s−a[i]≠a[i] then a pair aj exists.

Note that in C++ solutions, it's better to first check that s−a[i] is a key in c, and only after it calculate c[s−a[i]]. This needs to be done, since in C++ when you access a key using the "square brackets" operator, a default mapping key-value is created on the absence of the key. This increases both the running time and the memory consumption.

Code in C++ for details1005D - Polycarp and Div 3There are multiple approaches to solve this problem. We will use dynamic programming approach.

Let's calculate values of the array z[0…n], where z[i] is the answer for prefix of the length i. Obviously, z[0]:=0, since for the empty string (the prefix of the length 0) the answer is 0.

For i>0 you can find z[i] in the following way.

Let's look in the last digit of the prefix of length i. It has index i−1. Either it doesn't belong to segment divisible by 3, or it belongs.

If it doesn't belongs, it means we can't use the last digit, so z[i]=z[i−1]. If it belongs we need to find shortest s[j…i−1] that is divisible by 3 and try to update z[i] with the value z[j]+1. It means that we "bite off" the shortest divisible by 3 suffix and reduce the problem to a previous.

A number is divisible by 3 if and only if sum of its digits is divisible by 3. So the task is to find the shortest suffix of s[0…i−1] with sum of digits divisible by 3. If such suffix is s[j…i−1] then s[0…j−1] and s[0…i−1] have the same remainder of sum of digits modulo 3.

Let's maintain fin[0…2] — array of the length 3, where fin[r] is the length of the longest processed prefix with sum of digits equal to r modulo 3. Use fin[r]=−1 if there is no such prefix. It is easy to see that j=fin[r] where r is the sum of digits on the i-th prefix modulo 3.

So to find the maximal j≤i−1 that substring s[j…i−1] is divisible by 3, just check that fin[r]≠−1 and use j=fin[r], where r is the sum of digits on the i-th prefix modulo 3.

It means that to handle case that the last digit belongs to divisible by 3 segment, you should try to update z[i] with value z[fin[r]]+1. In other words, just do if (fin[r] != -1) z[i] = max(z[i], z[fin[r]] + 1).

Sequentially calculating the values of z[0…n], we obtain a linear O(n) solution.

Code in C++ for details1005E1 - Median on Segments (Permutations Edition)The segment p[l…r] has median equals m if and only if m belongs to it and less=greater or less=greater−1, where less is number of elements in p[l…r] that strictly less than m and greater is number of elements in p[l…r] that strictly greater than m. Here we've used a fact that p is a permutation (on p[l…r] there is exactly one occurrence of m).

In other words, m belongs p[l…r] and the value greater−less equals 0 or 1.

Calculate prefix sums sum[0…n], where sum[i] the value greater−less on the prefix of the length i (i.e. on the subarray p[0…i−1]). For fixed value r it is easy to calculate number of such l that p[l…r] is suitable. At first, check that m met on [0…r]. Valid values l are such indices that: no m on [0…l−1] and sum[l]=sum[r] or sum[r]=sum[l]+1.

Let's maintain number of prefix sums sum[i] to the left of m for each value. We can use just a map c, where c[s] is number of such indices l that sum[l]=s and l is to the left of m.

So for each r that p[0…r] contains m do ans += c[sum] + c[sum - 1], where sum is the current value greater−less.

Time complexity is O(nlogn) if a standard map is used or O(n) if classical array for c is used (remember about possible negative indices, just use an offset).

Code in C++ for details1005E2 - Median on Segments (General Case Edition)Let's define a function greaterCount(m) — number of subarrays with median greater or equal than m. In this case, the answer on the problem is greaterCount(m) − greaterCount(m+1).

The subarray a[l…r] has median greater or equal than m, if and only if notLess>less, where notLess is the number equal or greater than m elements, and less is the number of less than m elements.

In other words, instead of processing a[l…r] you can use the sequence x[l…r] containing −1 or/and +1. An element x[i]=−1, if a[i]<m. An element x[i]=+1, if a[i]≥m. Now, the median of a[l…r] is greater or equal than m if and only if x[l]+x[l+1]+⋯+x[r]>0.

Let's iterate over a from left to right. Maintain the current partial sum sum=x[0]+x[1]+⋯+x[i]. Additionally, in the array s let's maintain the number of partial sum for each its value. It means that before increase of i you should do s[sum]++. So if i is the index of the right endpoint of a subarray (i.e. r=i), then number of suitable indices l is number of such j that x[0]+x[1]+⋯+x[j]<sum. In other words, find sum of all s[w], where w<sum — it is exactly number of indices with partial sum less than sum.

Each time partial sum changes on −1 or +1. So the value "sum of all s[w], where w<sum" is easy to recalculate on each change. If you decrease sum, just subtract the value s[sum]. If you increase sum, before increasing just add s[sum].

Since indices in s can be from −n to n, you can use 0-based indices using an array s[0…2⋅n]. In this case, initialize sum as n but not as 0 (it makes sum to be non-negative on each step).

This solution works in O(n).

Code in C++ for details1005F - Berland and the Shortest PathsUse BFS to precalculate an array d — the array of the shortest path lengths from the Capital.

The condition to minimize sum of distances in each tree is equal to the fact that each tree is a shortest path tree. Let's think about them as about oriented outgoing from the Capital trees. Moving along edges of such trees, you always move by shortest paths.

An edge (u,v) can be included into such a tree if and only if d[u]+1=d[v] (since original edges are bidirectional, you should consider each of them twice: as (u,v) and as (v,u)). Let's focus only on edges for which d[u]+1=d[v]. Call them "red" edges.

To build a tree for each city (except the Capital) you should choose exactly one red edge finishing in this city. That's why the number of suitable trees is a product of numbers of incoming edges over all vertices (cities).

But we need to find only k of such trees. Let's start from some such tree and rebuild it on each step. As initial tree you can choose the first incoming red edge into each vertex (except the City). Actually, we will do exactly increment operation for number in a mixed radix notation.

To rebuild a tree iterate over vertices and if the current used red edge is not the last for the vertex, use the next and stop algorithm. Otherwise (the last red edge is used), use the first red edge for this vertex (and go to the next vertex) and continue with the next vertex. Compare this algorithm with simple increment operation for long number.

Code in C++ for details

Codeforces Round #495 (Div. 2) — Editorial

By BanRussiaAtIOI, 5 years ago, In English1004A - Sonya and HotelsOne hotel always can be built to the left of the first hotel. One more can be built to the right of the last hotel. Let's look at each pair of the adjacent hotels. If the distance between these two hotels is greater than 2⋅d, we can build one hotel at a distance of d to the right from the left hotel and one more at a distance of d to the left from the right hotel. If the distance between these two hotels is equal to 2⋅d, we can build only one hotel in the middle of them. Otherwise, we can not build a hotel between them.

1004B - Sonya and ExhibitionNote, that it is always optimal to use roses in even positions and lilies in odd positions. That is, the string 01010101010… is always optimal.

1004C - Sonya and RobotsLet's assume that our left robot is located in the p position. The robot could be there only if the value that is written there did not occur earlier. The number of possible locations of the second robot is equal to the number of distinct numbers on the segment [(p+1)…n]. Let dpi be the number of different numbers on [(p+1)…n]. Let's find these number from right to left. If ai occurs the first time dpi=dpi+1+1, otherwise, dpi=dpi+1.

1004D - Sonya and MatrixSuppose that a matrix has sizes n×m, zero is located at (x,y). Let a be the distance to the cell (1,1), and let b the distance to the cell (n,m). Obvious that the farthest distance from the zero cell will be to a corner cell. The maximum number in the list is equal to the maximum distance to a corner cell (let's assume that it is b).

We know that

n⋅m=t;a=x−1+y−1;b=n−x+m−y;n+m=a+b+2.And

a=n+m−b−2;x−1+y−1=n+m−b−2;y=n+m−b−x.Let's find the minimum i (i>0) such that the number of occurrences of i in the list is not equal to 4⋅i. We can notice that x=i. Let's look at each pair (n,m) (n⋅m=t). If we know n,m,x, and b, we can find y and restore the matrix. If it could be done, we already found the answer.

1004E - Sonya and Ice CreamThe editorial for the main solution with centroid decomposition will be published later.

Another Solution (without really formal proof)

It is possible to show, that if we have all weights equal to 1, then optimal answer is always a middle part of diameter of right length.

However, weights are arbitrary. Then we need to select a "weighted" middle part.

We can do it in a following way: set two pointers — one to the diameter beginning, and one to the end.

And while the number of vertices is greater k we move the pointer, which has moved less from it's end.

However, in fact, sometimes we need to look at the neighboring ±1 possible subpaths —- for example if the last step was the same distance, then the optimal move depends on where the edge was longer.

This way we need to count answer for ≤3 paths. To count the answer for path we can run few dfs's, each of them will cover only part of graph, which hangs on related vertex of the path.

Complexity is O(n).

The sketch of the proof is something like this:

Examine the diameter. Notice, that the answer should contain it's middle point (vertex, which is most close to 1/2) because the answer would be greater than the largest half of this diameter otherwise.

From this we already bounded our answer, but we need more.

Then we want to start to grow the way to the ends of the diameter, so that at least from the end of the diameter of the distance was small.

Not the fact that this will be enough (for example, if there are several diameters), but it is necessary.

Two pointers are needed because growing in two directions may be necessary unevenly.

1004F - Sonya and Bitwise ORWill be added soon.

Codeforces Round #494 (Div. 3) Editorial

By vovuh, history, 5 years ago, In English1003A - Polycarp's Pockets

Tutorial1003A - Polycarp's PocketsWe have to find the maximum number of elements with the same value (it can be done by counting). This number will be the answer because if there are no more than k elements with the same value in the array it is obvious that we cannot use less than k pockets, but we also doesn't need to use more than k pockets because of the other values can be also distributed using k pockets.

Overall complexity is O(n+maxAi).

Solution (Vovuh)1003B - Binary String Constructing

Tutorial1003B - Binary String ConstructingThis problem has several general cases:

x is even and a>b, then the answer is 01 repeated x2 times, then b−x2 ones and a−x2 zeroes;x is even and a≤b, then the answer is 10 repeated x2 times, then a−x2 zeroes and b−x2 ones;x is odd and a>b, then the answer is 01 repeated ⌊x2⌋ times, then a−⌊x2⌋ zeroes and b−⌊x2⌋ ones;x is odd and a≤b, then the answer is 10 repeated ⌊x2⌋ times, then b−⌊x2⌋ ones and a−⌊x2⌋ zeroes.I am sure that there are other more beautiful solution, but for me the easiest way to solve this problem is to extract general cases and handle it.

Overall complexity is O(a+b).

Solution (Vovuh)1003C - Intense Heat

Tutorial1003C - Intense HeatThis task is very straight-forward implementation problem. So we can iterate over all segments of the given array, calculate their sum, and if the length of the current segment is not less than k, try to update the answer with the mean of this segment.

Overall complexity is O(n2).

Solution (PikMike)1003D - Coins and Queries

Tutorial1003D - Coins and QueriesWe can solve the problem by the following way: firstly, for each power of 2 let's calculate the number of coins with the value equals this degree. Let's call it cnt.

It is obvious that we can obtain the value bj greedily (because all less values of coins are divisors of all greater values of coins).

Now let's iterate over all powers of 2 from 30 to 0. Let's deg be the current degree. We can take min(⌊bj2deg⌋,cntdeg) coins with the value equals 2deg. Let it be cur. Add cur to the answer and subtract 2deg⋅cur from bj.

If after iterating over all powers bj still be non-zero, print -1. Otherwise print the answer.

Overall complexity: O((n+q)logmaxAi).

Solution (Vovuh)1003E - Tree Constructing

Tutorial1003E - Tree ConstructingLet's construct a tree by the following algorithm: if d≥n, let's print "NO" and terminate the program. Otherwise let's keep the array deg of the length n which will represent degrees of vertices.

The first step is to construct the diameter of the tree. Let first d+1 vertices form it. Let's add d edges to the answer, increase degrees of vertices corresponding to this edges, and if some vertex has degree greater than k, print "NO" and terminate the program.

The second (and the last) step is to attach the remaining n−d−1 vertices to the tree. Let's call the vertex free if its degree is less than k. Also let's keep all free vertices forming the diameter in some data structure which allows us to take the vertex with the minimum maximal distance to any other vertex and remove such vertices. It can be done by, for example, set of pairs (distv,v), where distv is a maximum distance from the vertex v to any other vertex. Now let's add all vertices from starting from the vertex d+1 (0-indexed) to the vertex n−1, let the current vertex be u. We get the vertex with the minimum maximal distance to any other vertex, let it be v. Now we increase the degree of vertices u and v, add the edge between they, and if v still be free, return it to the data structure, otherwise remove it. The same with the vertex u (it is obvious that its maximal distance to any other vertex will be equals distv+1).

If at any step our data structure will be empty or the minimum maximal distance will be equals d, the answer is "NO". Otherwise we can print the answer. See my solution to better understanding.

Overall complexity: O(nlogn) or O(n) (depends on implementation).

Solution (Vovuh)1003F - Abbreviation

Tutorial1003F - AbbreviationLet eqi,j equals true if words si and sj are equal, otherwise it will be equals false. We can iterate over all pairs of words and compare they just using standard string comparator (constraints are really small so we can do it naively).

The next step is to calculate dynamic programming dpi,j, which will be equal to the maximum length of coinciding segments of words which starts in positions i and j, respectively. In other words, if dpi,j equals k, then s[i..i+k−1]=s[j..j+k−1], word by word. We can calculate this dynamic programming in reverse order (i:=n−1..0,j:=n−1..0) and dpi,j:=0 if si≠sj, else if i<n−1 and j<n−1, then dpi,j:=dpi+1,j+1+1, otherwise dpi,j:=1.

Let's keep the length of the text in the variable allsum. Then iterate over all starting positions of the possible abbreviation and all its possible lengths. Let the current starting position will be equals i (0-indexed) and its length will be equal j. Then we need to calculate the number of possible replacements by its abbreviation. Let it be cnt and now it equals 1. Let's iterate over all positions pos, at the beginning pos=i+j (0-indexed). If dpi,pos≥j then we can replace the segment of words which starts at the position pos with its abbreviation, so cnt:=cnt+1 and pos:=pos+j (because we cannot replace intersecting segments), otherwise pos:=pos+1.

After this we need to update the answer. The length of the segment of words s[i..j] can be calculated easily, let it be seglen. Also let segcnt be the number of words in the current segment of words. Then we can update the answer with the value allsum−seglen∗cnt+cnt∗segcnt.

Overall complexity is O(n3+n⋅∑i=0n−1|si|), where |si| is the length of the i-th word.

Solution (Vovuh)

Codeforces Round #493 — Editorial

By 300iq, history, 5 years ago, In EnglishAuthor — vintage_Vlad_Makeev

998A - BalloonsIt is easy to show, that if at least one solution exists, than it is possible to use the answer, which contains only one, minimal, element.

Suppose, that this set is not valid. Then one of the following holds:

Either n=1, and then there is no solutionOr n=2, and other element is equal to minimum, in this case it is ease to see that there are not solution too.Also, the limits were set in such way, that solution which bruteforces all 2n subsets and checks them also passes.

Author — MikeMirzayanov

998B - CuttingIt is possible to proof, that cut after i-th number can be done if and only if the prefix of length i contains equal number of odd and even numbers.

This way each cut can be done or not done independently of all other cuts (except the budget issue).

Why it is true?

Let's proof that criterion is sufficient. If you make some set of cuts, where each cut is valid according to criterion above, than the result would be correct — each part of result lies between to cuts, and if prefixes which correspond to cuts have same number of odds-evens, than the part between also will have these numbers equal.

Let's show that the condition is required — if there is some set of cuts, which produces correct parts, than each part has same number of odds-evens, and than all prefixes, which correspond to cuts also have the same number of odds-evens.

This way each cut can be done independently, so you can identify all valid cuts, order them by cut-price, and take greedy from the beginning of the list while the budget allows.

Author — 300iq

997A - Convert to OnesLet's partite consecutive elements of the same color into groups.

For example, we will split «00011001110» into «000» + «11» + «00» + «111» + «0».

Then it is obvious that it is useless to make moves within one group, and then (if we have at least two groups of color 0) for one move we can reduce by one (and can't reduce by two) the number of segments of color 0, paying for it either x or y (whatever).

Let's consider, for example, if we have a string «11001100», we can flip the segment [5…8], and turn it into a string «11000011», or, for example, invert the segment [3…4], turning the string into «111111111100> (Then the number of color groups 0 decreased from two to one).

But in the end you still need to do at least one inverting of the segment (which will be one at the end).

Then let p — number of groups of color 0.

If p=0, the answer is 0.

Otherwise, the answer is (p−1)⋅min(x,y)+yAuthor — cdkrot

997B - Roman DigitsTL; DR — among all the sequences, select the one, which contains the maximum number of 50, in case of tie, select one with largest number of 9. Bruteforce all configurations in such way, that each number is counted only in it's "maximum" configuration.

Since the length of sequence is fixed, we can solve problem not for digits {1,5,10,50}, but for digits {0,4,9,49}.

Let's solve the problem for digits {0,4,9} first.

We have a problem that some numbers have many representations. But this, in fact, is easy to deal with — if we have at least nine digits "4" than we can convert them no some number of "9" digits, and fill the rest with zeroes.

In this case, the solution is to bruteforce the number of "4" from 0 to min(8,n), and then from the remaining digits select any arbitrary number of "9", each such choice leads to an unique number.

Let's return to the original problem with {0,4,9,49}.

In this case we can also face the situation, when the number of 49 can be increased. We need to identify all pairs (x,y) where x,y≤50, such that they can be transformed to other pair (x′,y′) with detachment of few 49.

We can bruteforce all x, y, x′, y′ with four nested for-loops and check, that the sum of first differs from sum of latter by few number of 49 removed, in such case we mark the pair (x,y) as broken.

We can also note, that if some pair is marked as broken, than all "dominating" pairs also marked as broken.

When we discovered which pairs are good we can simply:

for number_of_4for number_of_9if pair_is_goodcount the answer, all remaining digits are either $$$0$$$ or $$$49$$$ and all such alternatives are unique.———

Another solution: if you examine the solution above precisely, you will notice that starting some reasonable n (you can easy proof a lowerbound like 50 or 100, but it is, in fact, 12), the function grows linearly.

So if n≤12, you count the answer in any stupid way, and otherwise, simply approximate it linearly using answer(12) and answer(13).

Author — cdkrot

997C - Sky Full of StarsLet Ai be the set of all colorings, where i-th line contains only one color, and Bi be the set of colorings, where i-th column contains only one color.

This way, you need to calculate |A1∪A2…An∪B1∪B2…Bn|.

As usual, we can use inclusion-exclusion formula to reduce the calculation of multiplications to calculation all possible intersections of sets above.

More over, due to the obvious symmetry, to calculate the size of intersection of some set of Ai and Bi it is not important to know exact indices — only number of taken A-s and number of B-s.

This way ans=∑i=0…n,j=0…n,i+j>0CinCjn(−1)i+j+1f(i,j)Where f(i,j) — is the number of colorings, where first i rows and first j columns are onecolored.

It turns out, that formula for f differs significantly depending on presence of zero in it's arguments.

Let's examine the case where zero is present, the f(0,k)=3k⋅3n(n−k).

Indeed, you should choose one color in each of the first k columns, and the rest should be painted in any way.

——

If both arguments are >0, that is, there is at least one one-colored column and at least one-colored row, than we can notice, that all one-colored rows and columns are in fact of one color.

This way, f(i,j)=3⋅3(n−i)(n−j)Since we should first select the globally common color, and then paint all the rest in any way.

Summation of all f-s gives solution with O(n2) or O(n2log) complexity, depending on implementation.

But we need to go faster.

—–

Let's sum all summands with i=0 or j=0 in a stupid way, in O(n).

Then examine all other summands. We have a formula:

ans=∑ni=1∑nj=1CinCjn(−1)i+j+13⋅3(n−i)(n−j)Let's replace our variables: i→n−i, j→n−j.

ans=3∑n−1i=0∑n−1j=0Cn−inCn−jn(−1)n−i+n−j+1⋅3ijSince Cn−in=Cin, (−1)2n=1, (−1)−i=(−1)i we have

ans=3∑n−1i=0∑n−1j=0CinCjn(−1)i+j+1⋅3ijNote, that (a+b)n=∑ni=0Cinaibn−i.

Using this, we can collect all summands for fixed i, however with fixed i we have not n summands, but n−1. We can workaround it by adding and removing the missing summand.

—–

Let's go:

ans=3∑n−1i=0∑n−1j=0CinCjn(−1)i+j+1⋅3ijans=3∑n−1i=0Cin(−1)i+1∑n−1j=0Cjn(−1)j⋅(3i)jans=3∑n−1i=0Cin(−1)i+1∑n−1j=0Cjn(−3i)jans=3∑n−1i=0Cin(−1)i+1[(1+(−3i))n−(−3i)n]—–

This formula has only O(n) summands, аnd hence can be evaluated fast enough.

To calculate powers of number fast, we can use binary pow method.

Author — cdkrot

997D - Cycles in productConsider an arbitrary cycle in a graph product.

Due to the definition of the product, the adjacent vertices in the cycle correspond to the transition by the edge either in the first tree or in the second tree.

This way, if you write the edges corresponding to one tree in a separate list, you will get a cycle in this tree.

Also, if we have a cycle in one tree of length a and a cycle of length b in the second tree, we can make Caa+b cycles in the product.

Thus, the problem is reduced to calculating for each length up to k the number of cycles in each tree separately, and then mixing them into cycles in the product.

—–

Let's select the centroid c of the tree and count all cycles, which go through it, delete centroid and then recursively count in remaining components.

How looks cycle which goes through c? We need to start in some vertex v, then go to c (not going through c in between), and then go back to v, possibly going through c.

Let's define two dp's: f[v][k] — number of ways to go from c to v by exactly k steps not going through c in between, g[v][k] — number of ways to go from c to v, but without previous limitation.

This way the answer for v through centroid c in convolution of f[v] и g[v]: ans[i+j]+=f[v][i]∗g[v][j].

Case where v=c should be processed separately, in this case we can simply ans[i]+=g[c][i].

How much time it takes to compute dp? In fact, it is O(nk), g[v][i] is equal to sum of g[u][i−1] where u is neighbor of v. Since the graph is tree, there are O(n) neighbors in total and O(nk) transitions.

f[v] is counted the same way, but with removed transitions through c. ——

The final complextiy is: O(nk2log(n)).

\O(log(n)) is for centroid decomposition.

On one level we need to compute dp O(nk) and then compute convolution O(nk2), so it is O(nk2log(n)).

Solution can be optimized with fast polynomial multiplication, leading to complexity O(nklog(k)log(n)), but it wasn't required.

Author — 300iq

997E - Good SubsegmentsLet's look at two solutions for all array, and each of them can be upgraded to subquadratic time for queries on subsegments.

First solution is Divide&Conquer.

Let's take a middle of the array and find number of segments, that contain it.

If minimum and maximum are at one side of middle, then by the end on the half where they are, you can restore the entire segment and check that it is correct (and remember it somewhere).

Else let them be on different sides.

Then let maximum will be at the right (other case are symmetric and you can solve them similarly), so we need r−l=max−min, but we already know r and max , so we can get r−max=l−min.

Then let's partite the elements into equivalence classes, where we broke into classes by r−max if element on the left and l−min if element on the right (where the max and min is the minimum and maximum on the segment to the middle m), then the segment l≤m<r (where the maximum on the left) is good if and only if when in the interval [l…m] there are no numbers less than minimum on the interval (m,…r] and the interval (m,…r] has no numbers larger than maximum on the interval [l…m], and l and r are in the same class.

Then, for one segment end, some interval of elements from its class is suitable (these intervals can be selected, for example, by stack or a binary search).

Also you need (don't forget it!) to go recursively to the left half and to the right half :)

And then you can apply the Mo's algorithm!

Let's move the left and right ends, run through the classes where this end lies, and add/subtract from the answer the size of the intersection of the interval of this class that fits this end and the interval of this class that current segment now contains, so this part works for O(nn−−√logn) (but operations are not so heavy, so it is working fast).

Also you need to not forget about the segments where the minimum and maximum contained at one side of the middle, they can be processed, for example, by passing with a sweep line with a fenwick tree, this part works in O(nlogn).

So we can upgrade D&C idea to O(nn−−√logn).



But let's look at the geometric interpretation of the problem.

Let good segments be points (l,r) on the plane!

Then the query is just the sum on the rectangle [1…l][r…n].

To solve the problem on the whole array, let's move the right end of the query, and for each left we will store r−l−(max−min), this can be stored in the segment tree (and you can recalculate it with stacks), and then you can note that values always are ≤0, so you can simply store in the segment tree the maximum and number of maximums, and at each time add this value to the answer.

In order to generalize this idea for a complete solution, let's split the field N×N into squares K×K

(Colors are not important, they are just for convenience).

Then let's go with the same sweep line from left to right, but we will store everything not in the segment tree, but in the sqrt decomposition.

And we will store for a piece of size K by y-coordinate the number of (good segments) points that we have already met in it.

So we can cut off from the original query



The lower part, leaving a horizontal strip of size ≤K.



We made it in O(n⋅k+n⋅nk).

With similar sweep line from top to bottom, and not from left to right, we can cut off the left part, leaving as a query a rectangle with sides <K.



Then you can create <K events of the form: "Add the sum on the vertical segment to the answer to i-th query", and these events can be processed by a sweep line from left to right with the segment tree , so you can solve this part in O(n⋅k⋅logn).

So we can get a solution in O(n⋅nk+n⋅k⋅logn), and choosing k=nlogn−−−−√ allows to solve the task in O(n⋅n⋅logn−−−−−−√).

Editorial for Codeforces Round #492 [Thanks u-Debug!]

By desert97, history, 5 years ago, In EnglishPreliminary, changes to come possibly.

996A - Hit the LotteryThe problem is to minimize x1+x2+x3+x4+x5 given that x1+5x2+10x3+20x4+100x5=n. It is pretty simple to see that we can operate greedily: take as many 100 as we can, then 20, then 10, etc.

The solutions works because each number in the sequence 1,5,10,20,100 is a divisor of the number after it.

996B - World CupFor gate k (where 1≤k≤n) we visit the gate at times k,k+n,k+2n,⋯ Therefore, the earliest Allen could enter from gate k is the time k+tn such that k+tn≥ak. Now, for each k, compute the minimal integer bk=k+tn such that k+tn≥ak. Now, find the integer k with minimum bk and output k.

995A - TeslaFirst, whenever any cars are directly to their parking spot, we should move them into the correct parking spot.

Now, we can view rows 2 and 3 as a cycle. In at most k moves, we can spin the entire cycle of cars counterclockwise. By repeating this 2n times, each car will have been adjacent to each parking space, and will have had some chance to park.

The exception to this rule is when there are no empty spaces in rows 2 and 3. In this case, no cars can even make a valid move, so the answer is −1. (This requires k=2n and no cars are initially adjacent to their parking space)

This process will can be implemented in O(nk) or O(n2) time, with at most 2nk+k≤10100, which fits below the 20000 move limit.

995B - Suit and TieWe describe a greedy algorithm that achieves the minimum number of swaps.

If the leftmost person is in pair a, swap the other person in pair a left, to the second position. Now the first two people are both in pair a, and we repeat the process on the remaining n−1 pairs of people recursively.

We now prove that this number of swaps is optimal, and we accomplish this by showing that every swap we made is 'necessary'.

For two pairs numbered a and b, we can consider the number of times people of pair a and b are swapped by our process. There are 3 possible relative orderings: aabb, abab, and abba.

In the case aabb, our algorithm will never swap a and b.

In the case abab, any correct swap sequence must swap a and b at least once, and our algorithm will swap the second a left of the first b when a is the leftmost person.

In the case abba, any correct swap sequence must swap a and b at least twice, and our algorithm will swap the second a left of both b when a is the leftmost person.

Therefore every swap in our greedy algorithm is necessary, so it is optimal.

We can directly simulate this algorithm in O(n2) time. We can also use data structures such as a binary indexed tree, or balanced binary search tree to compute the answer in O(nlogn). (Maybe it can be even done in O(n), anyone?).

995C - Leaving the BarWe first prove a claim which will help us significantly. The claim is that among any three vectors v1→,v2→,v3→ of lengths at most r, then some sum vi→+vj→ or difference vi→−vj→ has at length at most r.

Draw a circle with radius r centered at the origin. If we plot the vectors v1→,v2→,v3→,−v1→,−v2→,−v3→ from the origin, two of these will lie in the same 60∘ sector. Any two points in this sector will have distance at most r.

Therefore, as long as there are at least 3 vectors, two of them can be combined and the input constraints will still be satisfied. In the final step, we can combine two vectors of length at most r into one of length at most 2–√r.

Implementation can be done in a number of ways: for example, constructing a binary tree with the input vectors as leaves, or maintaining sets of signed vectors and merging small sets to large sets. These approaches can take O(n) or O(nlogn).

995D - GameOne can show by induction that the expected value of the game is E[f]=2−n∑x∈{0,1}nf(x).

Consider the first turn. For notation, let vi,0 be the expected value of the game when xi is set to 0, and let vi,1 be the expected value of the game when xi is set to 1. By induction, it is easy to see that vi,0+vi,12=E[f].Consider Allen's strategy. If it is Allen's turn, he will set xs=t, where 0≤s<n,0≤t≤1 are such that vs,t is maximal. As vi,0+vi,12=E[f] for all i, it is clear that vs,1−t is actually minimal among all the vi,j. This means that Bessie would have chosen to set xs=1−t if it were her turn. Therefore, the expected game value is vs,t+vs,1−t2=E[f].995E - Number ClickerOur first observation is that the game can be modeled the following way. Construct an undirected graph on {0,1,…,p−1} such that i is connected to i−1,i+1, and ip−2(modp).We want to find a path of length at most 200 between u and v in this graph. Running a BFS will take too long, so we need different techniques. We present two solutions, which both essentially use the fact that the graph is almost "random". This follows from some known number theoretic results on expander graphs (keyword is "Margulis expanders").

Solution 1: Generate p–√ random paths of length 100 from vertex u. Now, generate random paths from v of length 100 until some pair of endpoints coincide. By the birthday paradox, assuming that the graph is approximately random, the runtime will be O(p–√logp).Solution 2: We can try running a simultaneous BFS from both directions (starting at u and v). When they meet, make that path. If you are careful, it should be possible to cover ≤107 vertices, which should then run in time.

Additionally, our tester found a different solution. It suffices to find a path from u→1 of length 100. The way we do this is: pick a random x(modp). Now run the Euclidean algorithm on (ux(modp),x), using operation 2 for a normal subtraction step, and a 3 for the flipping the two entries step. It happens to take a few steps in most cases, but we have no proof.

995F - Cowmpany CowmpensationA immediate simple observation is that we can compute the answer in O(nD) with a simple dynamic program. How to speed it up though?

To speed it up, we need the following lemma.

Lemma 1: For a tree with n vertices, the answer is a polynomial in D of degree at most n.

We can prove this via induction, and the fact that for any polynomial p(x) of degree d, the sum p(0)+p(1)+⋯+p(n) is a polynomial in n of degree d+1.Now the solution is easy: compute the answer for 0≤D≤n and use interpolation to compute the answer for D>n. The complexity is O(n2) for the initial dp and O(n) for the interpolation step.

Codeforces Round #491 (Div.2), Editorial

By I_Remember_Olya_ashmelev, history, 5 years ago, translation, In English991A - If at first you don't succeed...

EditorialThere are 4 groups of students — those who visited only the first restaurant, who visited only the second, who visited both places and who stayed at home. One of the easiest ways to detect all the incorrect situations is to calculate number of students in each group. For the first group it is A - C, for the second: B - C, for the third: C and for the fourth: N - A - B + C. Now we must just to check that there are non-negative numbers in the first three groups and the positive number for the last group. If such conditions are met the answer is the number of students in the fourth group.

	int n1 = a - c;	int n2 = b - c;	int n3 = c;	int n4 = n - n1 - n2 - n3;

	if (n1 >= 0 && n2 >= 0 && n3 >= 0 && n4 > 0)		cout << n4;	else		cout << -1;In general you are recommended to view inclusion–exclusion principle.

Moreover the limitations allow to go over all possible numbers of students for each group (except for the third) in O(N3) and to check whether such numbers produce a correct solution. If no correct numbers found, just print  - 1:

	int n3 = c;	for (int n1 = 0; n1 <= n; n1++)		for (int n2 = 0; n2 <= n; n2++)			for (int n4 = 1; n4 <= n; n4++)				if (n1 + n3 == a && n2 + n3 == b && n1 + n2 + n3 + n4 == n) {					cout << n4;					return 0;				}	cout << -1;Solution1

Solution2

991B - Getting an A

EditorialIt is necessary to use the greedy approach: of course Vasya should redo the lowest grades firstly. So we have to sort the values in the ascending order and begin to replace the values by 5 until we get the desired result. In order to check whether the current state is suitable we may calculate the mean value after each iteration (O(N2) complexity in total), or just update sum of the grades and calculate the arithmetic mean in O(1) with O(N) total complexity (excluding sorting). For example:

bool check(int sum, int n) {	// integer representation of sum / n >= 4.5	return sum * 10 >= n * 45;}

int main() {	... // read integers to vector v and calculate sum	sort(v.begin(), v.end());	int ans = 0;	while (!check(sum, n)) {		sum += 5 - v[ans];		ans++;	}	cout << ans;}Of course, both approaches easily fit TL.

Finally, it is recommended to avoid floating-point operations while calculating the mean value.

Solution

991C - Candies

EditorialIt is easy to check that if for some value k the necessary condition is met (Vasya eats at least half of the candies), then it is met for each integer greater k.

ProofSo this problem can be solved using the binary search (answer) approach. In order to check whether selected k is applicable it necessary just to implement the process described in the problem statement.

bool check(long long k, long long n) {	long long sum = 0;	long long cur = n;	while (cur > 0) {		long long o = min(cur, k);		sum += o;		cur -= o;		cur -= cur / 10;	}	return sum * 2 >= n;}Since Petya eats 10% of candies, its amount decreases exponentially, so there will be only few days before all the candies will be eaten. In the worst case it is necessary 378 days. Formally the complexity of the solution is O(log(n)2).

Like in the previous problem it is recommended to avoid floating operations and to use only integer types.

Solution

991D - Bishwock

EditorialIn this problem we may use the greedy approach. Let's go through columns from left to right. If we are currently considering column i and we may place a figure occupying only cells at columns i and i + 1, we have to place this figure. Really if the optimal solution doesn't contain a bishwock at column i then column i + 1 may be occupied by at most one bishwock. So we can remove this figure and place it at columns i and i + 1, the result will be at least the same.

A bit harder question is — how exactly we should place the figure if all 4 cells of columns i and i + 1 are empty (in other cases there will be only one way to place a bishwock)? Of course, we should occupy both cells of column i. Moreover it does not matter which cell we will occupy at column i + 1 in this case. The cells of i + 1 may be used only for placing a bishwock in columns i + 1,i + 2. If column i + 2 has at most one empty cell we are unable to place such figure and the remaining empty cells of column i + 1 are useless at all. If both cells of column i + 2 are empty we may place a bishwock regardless of the position of the remaining empty cell at column i + 1.

It means that we don't have to place the figures actually — we have to calculate and update number of empty cells in columns. According to the described algorithm we may write such code:

	... // read strings s[0] and s[1]	int ans = 0;	int previous = 0;	for (int i = 0; i < n; i++) {		int current = (s[0][i] == '0') + (s[1][i] == '0');		if (current == 0)			previous = 0;		if (current == 1) {			if (previous == 2) {				ans++;				previous = 0;			}			else				previous = 1;		}		if (current == 2) {			if (previous > 0) {				ans++;				if (previous == 2)					previous = 1;				else					previous = 0;			}			else				previous = 2;		}	}Moreover this implementation can be simplified to just two cases:

	int ans = 0;	int empty = 0;	for (int i = 0; i < n; i++) {		int current = (s[0][i] == '0') + (s[1][i] == '0');		empty += current;		if (empty >= 3) {			empty -= 3;			ans++;		}		else			empty = current;	}Formally such algorithm may be considered as the dynamic programming. Of course it is not necessary to have a deep understanding of DP to write such implementation and solve the problem.

This problem also can be solved by more ''obvious'' DP approach (for example we may consider index of current column and state of the cells of the previous column as a state of DP). In this case the implementation will be a bit more complicated but it won't be necessary to prove described solution.

Solution1

Solution2

991E - Bus Number

EditorialAccording to the statement, digits of original bus number form a subset of digits of the number seen by Vasya. It is possible to iterate through all the subsets in 2k operations (where k is length of n). For each subset we need to check whether it is correct (contains all necessary digits) and transform it to ''normal'' state (sort the digits for example), in order to avoid conflicts with another subsets which differ only at the digits order. We have to keep only unique subsets.

	long long ans = 0;	for (int i = 1; i <= (1 << k); i++) {		string c;		for (int j = 0; j < k; j++)			if (i & (1 << j))				c += n[j];		ans += getans(c);	}Now for each subset of digits we have to calculate amount of corresponding correct bus numbers. It can be calculated in O(k) operations using permutations of multisets formula (see ''Permutations of multisets'' at the article about permutations and multinomial coefficients)

C = k! / (c0! * c1! * ... * c9!),

where k — total number of digits in the subset and ci — number of digits i:

long long fact[20];int c[10];

void split(string s, int *c) {	for (int i = 0; i < 10; i++)		c[i] = 0;	for (char ch : s)		c[ch - 48]++;}

long long getCount() {	long long ans = fact[accumulate(c, c + 10, 0)];	for (int i = 0; i < 10; i++)		ans /= fact[c[i]];	return ans;}Now, we have to subtract amount of bus numbers with leading zeroes from the result for this subset if it contains digit 0. This can be done in the very same way: if we place digit 0 at the first position of the number, we have to decrease k by 1 and decrease c0 by 1; the formula described above will calculate amount of ways to place remaining digits of the subset and this number should be subtract from the answer:

long long getans(string s) {	split(s, c);

	// check whether the string contains all digits	for (int i = 0; i < 10; i++)		if (c0[i] && !c[i])			return 0;

	// check whether we already processed such string	sort(s.begin(), s.end());	if (was.count(s))		return 0;	was.insert(s);

	long long ans = getCount();	if (c[0] > 0) {		c[0]--;		ans -= getCount();	}	return ans;}In total, even with such rough evaluation of complexity and naive implementation we get O(2k * k) operations, where k ≤ 19 — amount of digits in n. It is easy to check that the answer doesn't exceed 1018 so the standard 64-bit integer type will be enough.

Solution

991F - Concise and clear

EditorialAll the problem numbers (except for 1010, which is given in the samples) contain at most 10 digits. It means that we have to use at most 9 digits if we want to find a shorter representation. Notice that the length of sum of two integers is not greater than sum of the lengths of these integers, so in the optimal representation at most one term is a number while other terms are expressions containing * and/or ^. Each expression (not a number) contains at least 3 symbols, so the optimal representation can contain at most 3 terms. The maximal integer that can be represented in such manner is 9^9+9^9+9, but it contains only 9 digits while expressions with 3 terms always contain at least 9 symbols. So we proved that there always exists an optimal representation which is a sum of at most two terms.

So there exist only 3 types of representation of the original number:

n = a^bn = x+yn = x*ywhere x and y — some expressions (in the first case a and b are numbers), which doesn't contain +. Moreover in all the cases such expressions should contain at most 7 digits.

Let's find for each x ≤ n a shortest valid representation m[x], containing at most 7 symbols (if it exists and contains less digits than simple number x), and for each length d — set of integers s[d] which can be represented by an expression of length d. The standard containers (std::map and std::set в C++) are suitable for that:

map<long long, string> m;set<long long> s[10];

string get(long long x) {	if (m.count(x))		return m[x];	return toString(x);}

void relax(long long x, string str) {	// obviously not optimal	if (x > n || str.length() >= getlen(x))		return;

	// already have better	if (m.count(x) && m[x].length() <= str.length())		return;

	s[m[x].length()].erase(x);	m[x] = str;	s[str.length()].insert(x);}Firstly let's add all expressions a^b, there are about sqrt(n) such expressions.

void generatePowers() {	for (long long x = 2; x * x <= n; x++) {		long long c = x * x;		int p = 2;		while (c <= n) {			string tmp = toString(x) + "^" + toString(p);			relax(c, tmp);			c *= x;			p++;		}	}}Now lets consider the expressions containing several multipliers. The same way (as for addition) in such representation at most one multiplier is a number. Including that the expression can contain at most 7 digits we have only 2 possible ways:

x = a^b*c^dx = a^b*cwhere a, b, c and d are some numbers. Lets iterate through i — the length of the representation of the first multiplier and go over all values stored in s[i]. The second multiplier can have length at most d = 7 - i - 1 and the total number of ways to choose two multipliers will be small enough. The second multiplier should be selected from containers s[j] for length at most d (in the first case), or we should iterate from 1 to 10d (in the second case). After that we will have about k = 150000 numbers in m in total:

void generatePowerAndPower(int maxlen) {	for (int i = 1; i <= maxlen; i++)		for (int j = i; i + j + 1 <= maxlen; j++)			for (auto x : s[i])				for (auto y : s[j])					relax(x * y, get(x) + "*" + get(y));}

void generateSimpleAndPower(int maxlen) {	for (int i = 1; i + 2 <= maxlen; i++)		for (long long x = 1; x < p10[maxlen - 1 - i]; x++)			for (long long y : s[i])				relax(x * y, toString(x) + "*" + get(y));}

void precalc() {	generatePowers();	generatePowerAndPower(7);	generateSimpleAndPower(7);}Now lets go back to the representation of the original number. For the first case — a^b — we have already stored such values in m. For the cases x+y and x*y we may assume that the length of expression of x is not greater than 4. Now lets iterate through x among found representations of length up to 4, and among integers from 1 to 104. For each such x and for each of 2 cases we determine value of y uniquely, and the optimal representation of y is already stored in m or it is just a number. So, for each such x we can find optimal answer for n by at most two addressing to m i.e. in log(k) operations.

string ans;void relaxAns(string s) {	if (ans.length() > s.length())		ans = s;}

void check2() {	for (int i = 1; i * 2 + 1 < ans.length(); i++) {		for (long long x = 1; x <= p10[i]; x++) {			relaxAns(get(n - x) + "+" + get(x));			if (n % x == 0)				relaxAns(get(n / x) + "*" + get(x));		}		for (auto x : s[i]) {			relaxAns(get(n - x) + "+" + get(x));			if (n % x == 0)				relaxAns(get(n / x) + "*" + get(x));		}	}}

int main() {	... // read n, calculate powers of 10	precalc();	ans = get(n);	check2();	cout << ans;}Finally, the total algorithm complexity is O((sqrt(n) + k + 104) * log(k)).

Solution

Codeforces Round #490 (Div. 3) Editorial

By vovuh, history, 5 years ago, translation, In EnglishI'm really sorry for the issue with the problem D difficulty, it was much harder than i expected, and there was a big difficulty gap between problems C and D. I hope in the next rounds it will never happen again.

UPD: I'd like to say a big thanks to kevinsogo for the great help with tutorials and the round preparation in general.

999A - Mishka and Contest

Tutorial999A - Mishka and ContestYou can iterate over all the elements of the array from left to right. Count the number of problems Mishka will solve from the left end of the list and break if he cannot solve the next one. Let's denote the number of problems Mishka will solve from the left end of the list by lf. Do the same thing independently from right to left. Denote the number of problems Mishka will solve from the right end of the list by rg. Then the answer is min(n,lf+rg).

Time complexity — O(n).

Solution (Vovuh)999B - Reversing Encryption

Tutorial999B - Reversing EncryptionTo solve the problem, we can implement the encryption algorithm with a single change: we have to iterate over all divisors of n in increasing order.

Time complexity — O(n ⋅d(n)), where d(n) is a divisor count function for n. For example, maxi=1106d(i)=240.

Solution (Vovuh)999C - Alphabetic Removals

Tutorial999C - Alphabetic RemovalsLet the lowercase Latin letters be indexed from 0 to 25.

There are exists at least two different solutions:

If k=n exit the program. Otherwise, count the number of occurrences of each letter i from 0 to 25. Let it be cnt. Now, find the (alphabetically) smallest letter that will be in the resulting string. It can be done as follows: iterate over all i from 0 to 25, and if cnti≤k then subtract it from k, otherwise, i will be the smallest letter that will be in the resulting string. But we (possibly) need to remove some number of its leftmost occurrences. It is obvious that letters smaller than i will not appear in the resulting string. Also, the k leftmost occurrences of letter i will be removed. Now, let's iterate over all letters in string s from left to right and construct the resulting string res. If the current character of s (let it be sj) is smaller than i, then do nothing. If sj is greater than i, then add it to res. Otherwise sj=i. If k>0, then decrease k by one, otherwise, add sj to res. The time complexity is O(n).

Another solution is the following. Let's carry the vector of pairs (si,i) where si is the i-th character of s and i is its position. If we sort this vector with the standard compare function, it is easy to see that the first k elements of this vector will be removed from the input string. Then if we will sort the last n−k elements of this vector by its positions in the input string in increasing order, we will obtain the answer. The time complexity is O(nlogn).

Solution 1 (Vovuh)Solution 2 (Vovuh)999D - Equalize the Remainders

Tutorial999D - Equalize the RemaindersFor each i from 0 to m−1, find all elements of the array that are congruent to i modulo m, and store their indices in a list. Also, create a vector called free, and let k be nm.

We have to cycle from 0 to m−1 twice. For each i from 0 to m−1, if there are in list too many (i.e., >k) elements congruent to i modulo m, remove the extra elements from this list and add them to free. If instead there are too few (i.e., <k) elements congruent to i modulo m, remove the last few elements from the vector free. For every removed index idx, increase aidx by (i−aidx)modm.

After doing so (after two passes), we print the total increase and the updated array.

It is obvious that after the first m iterations, every list will have size at most k, and after m more iterations, all lists will have the same sizes. It can be easily proved that this algorithm produces an optimal answer.

The time complexity is O(n+m).

Solution (Vovuh)999E - Reachability from the Capital

Tutorial999E - Reachability from the CapitalThis problem is (almost) equivalent to the following: count the number of sources (the vertices with indegree equal to 0) in the given graph's condensation. Thus, there exist solutions with complexity O(n+m). However, the constraints in the problem are small, so solutions with complexity O(n⋅m) also pass.

One of these solutions is the following: first, let's mark all the vertices reachable from s as good, using a simple DFS. Then, for each bad vertex v, count the number of bad vertices reachable from v (it also can be done by simple DFS). Let this number be cntv. Now, iterate over all bad vertices in non-increasing order of cntv. For the current bad vertex v, if it is still not marked as good, run a DFS from it, marking all the reachable vertices as good, and increase the answer by 1 (in fact, we are implicitly adding the edge (s,v)). It can be proved that this solution gives an optimal answer.

Solution (Vovuh)Linear Solution (Vovuh)999F - Cards and Joy

Tutorial999F - Cards and JoyIt is obvious that we can solve the problem separately for each favorite number because each player has only one favorite number, and if the player gets a card not having his favorite number, his joy will not change.

Let dp[x][y] be the maximum possible total joy of x players with the same favorite number (it doesn't matter which one) and y cards (containing their favorite number) if the cards are distributed among the players optimally. Note that x∈[0,n] and y∈[0,k⋅n]. At the beginning, all entries of the dp table are zeroes. The transition in this dynamic programming depends on how many cards the x-th player will receive (which is between 0 and k). In other words, the dynamic programming transition will look like:

 for (int i = 0; i <= k; ++i) dp[x + 1][y + i] = max(dp[x + 1][y + i], dp[x][y] + h[i]),where h[i] is the joy of the player if he receives exactly i cards containing his favorite number. Note that h[0]=0.

After filling the dp table, the answer can be calculated very easily: ans=∑i=1105dp[fi][ci], where fi is the number of players with favorite number i and ci is the number of cards containing the number i.

Time complexity is O(n2⋅k2).

Solution (Vovuh)

Editorial of Round #489(Div.2)

By DmitryGrigorev, history, 5 years ago, In EnglishAll the problems have been prepared by us, — DmitryGrigorev and ----------.

(Idea of the problem — DmitryGrigorev)

992A - Nastya and an ArrayLet's notice that after one second we aren't able to decrease the number of distinct non-zero elements in the array more than by 1. It means that we can't make all elements equal to zero faster than after  seconds, where  is the number of distinct elements in the array initially. And let's notice that we are able to make it surely after  second, if we will subtract every second some number which is in the array, so all elements equal this number in the array will have become zero, and the number of distinct non-zero elements will be decreased.

So the answer is the number of distinct non-zero elements initially. Complexity is 

Code — 39423470

(Idea of the problem — GreenGrape)

992B - Nastya Studies InformaticsLet's consider some suitable pair . As , we can present number  as , and number  as , where we know that  and .

Let's consider too that from the restriction from the problem  we surely know the restriction for  and , that is .

Let's remember we know that  (because  is ,  is ). Then we can get . Dividing by :

.

.

Now if , answer equals 0.

Else as  is surely less than , we can just sort out all possible pairs  of divisors , such that  , and then to check that  and  are in the getting above restrictions. Complexity of this solution is .

Code — 39423481

(Idea of the problem — ----------)

992C - Nastya and a WardrobeLet's present we have initially  dresses.

What does occur in the first month? Initially the number of dresses is multiplied by 2, that is becomes . Then with probability  the wardrobe eats a dress, that is expected value of the number of dresses becomes . The same way after the second month expected value becomes . It's easy to notice that after -th month(if ) expected value equals . Eventually it will be only doubled(as the wardrobe doesn't eat a dress in the last month), that is will be equal .

Thus, answer of the problem is . Expressing it with , we get:

 = .

 = .

Thus, we need to calculate degree of 2 right up to . Complexity of the soltion is .

Let's notice that the case  we need to calculate separately, because wardrobe can't eat a dress when it doesn't exist. If  it's easy to proof that the number of dresses is never negative, that is the formula works.

Code — 39423497

(Idea of the problem — DmitryGrigorev)

992D - Nastya and a GameLet's call numbers which are more than 1 as good. Notice the following fact:

If a subsegment is suitable, it contains not more than 60 good numbers.

Indeed, let's assume that a subsegment contains more than 60 good numbers. In this subsegment . At the same time, as , and , there is . Therefore, this subsegment can't be suitable due to .

Let's keep all positions of good numbers in a sorted array. We sort out possible left border of a subsegment and then with binary search we find the next good number to the right of this left border. Then let's iterate from this found number to the right by the good numbers(that is we sort out the rightmost good number in a subsegment), until product of all numbers in the subsegment becomes more than  (it's flag which shows us, that product is too big for a suitable subsgment and we need to finish to iterate). We have shown above the number of iterations isn't more than 60. Now for sorted out the left border and the rightmost good number we only need to know the number of 1's which needs to be added to the right of the rightmost good number, as we can easily maintain sum and product in the subsegment during iterating. Then we need to check whether found number of 1's exists to the right of the rightmost good number. It can be checked if we look at the next good number's position.

Complexity is .

In order to check that  is more than , you shouldn't calculate  multiply by , due to overflow. You must only check that .

(Idea of the problem — DmitryGrigorev)

Code — 39423501

992E - Nastya and King-ShamansThis problem was inspired by idea which was offered by my unbelievable girlfriend :)

Solution I

In this problem we maintain two segment trees - with maximum and with sum. After every query we recalculate these trees in  for a query. Now we only have to understand, how to answer for a query? Let's call a prefix of the array as good in the case if we surely know that it doesn't contain a king-shaman. So either the first shaman is king and we are able to answer for the query, or we call the prefix with length 1 as good. Then let's repeat the following operation:

We call  as sum in the good prefix now. We find it using the segment tree with sums.We find the leftmost element which may be king-shaman yet. We can realise that it's the leftmost element, which doesn't lie in the good prefix (as there isn't king-shaman according the definition), which have a value at least . It can be done using segment tree with maximums, with descent.We check if this found shaman is king. If isn't, we can say that the good prefix finishes in this shaman now, because it was the leftmost shaman who might be king.Every operation works in . Let's notice, that one operation increases sum in the good prefix at least by two times. So, after  operations sum in the good prefix will become more than a maximal possible number in the array, so that we will be able to finish, because we will be sure that answer will be -1. Complexity of the solution is .

Solution II

Let pi be the prefix sums of a. We're gonna introduce fi = pi - 2·ai and reformulate the queries using these new terms.

Imagine we wanna change the value at j to val. Let δ = val - aj. Then fj will decrease by δ whereas fi > j will increase by δ.Imagine we wanna find the answer. Then it's sufficient to find any i satisfying fi = 0.Split f into blocks of size M. Each block will be comprised of pairs (fi, i) sorted by f. At the same time we will maintain overhead array responsible for lazy additions to blocks. How does this help?

Let b = j / M. The goal is to find the position of j, decrease its value and increase values for all i > j within this block. It can be done in a smart way in O(M) (actually, this can be represented as merging sorted vectors). You should also take care of the tail, i.e add δ to overheadj > b in O(n / M) time.We're asked to find such i that fi + overheadj / M = 0. All blocks are sorted, thus we can simply apply binary search in  overall.The optimal assignment is  which results into  total runtime.

The huge advantage of this approach is its independency from constraints on a (i.e non-negativity). Although we didn't succeed in squeezing this into TL :)

Solution III

Group the numbers according to their highest bits (with groups of the form [2k... 2k + 1] and separately for zeros). Inside each groups (no more than  of them) we maintain elements in increasing order of indexes.

It's easy to see that each group contains no more than two candidates for answer (since their sum is guaranteed to be greater than any of the remaining ones). This observation leads to an easy solution in  — we iterate over groups and check prefix sums for these candidates.

There's actually further space for optimizations. Let's maintain prefix sums for our candidates — this allows us to get rid of the extra log when quering the tree. Almost everything we need at this step is to somehow process additions and deletions — change the order inside two blocks and probably recalculate prefix sums. The only thing left is to stay aware of prefix sum changes for the remaining blocks. Luckily, they can be fixed in O(1) per block (if i > j then the sum increases by val - aj and stays the same otherwise).

The resulting comlexity is .

Code of the solution I — 39423519

Code of the solution II — 39418926. Try to optimize :)

Thank you tfg for the idea and the code of the solution III. Very good job!

Code of the solution III — 39392321

Codeforces Round #488 editorial

By AlexSkidanov, history, 5 years ago, In English994A - FingerprintsThe problem can be solved by iterating over every number of the sequence, then iterating over the sequence of fingerprints to check if the number corresponds to a key with a fingerprint, resulting in an O(n×m) solution.

994B - Knights of a Polygonal TableSort the knights by increasing the power. Now we can iterate over an array and greedy store set of k prevous knights with maximum if coins. After handling knight, if set contains less than k elements, we add current knight in set. Else if number of coins from current knight greater than from knight with minimum coins in set, we can replace this knight with current knight. You can store the set in vector, multiset or priority_queue. Be careful with overflowing and corner case k=0.

Time complexity is O(n⋅k) or O(n⋅log(k)).

994C - Two SquaresIt can be shown that if two squares intersect, then at least for one of the squares it is true that either one of its corners lies within the other square, or its center lies within the other square.

It is very easy to check if any corner or the center of the square rotated by 45 degrees lies within the square with sides parallel to the axes.

To check in the opposite directions in a similarly simple fashion, it is enough to rotate both squares by 45 degrees. To turn both squares by 45 degrees (with some scaling, which is OK) it is sufficient to replace each x coordinate with x+y and each y coordinate with x−y.

994D - Open CommunicationOne way to approach this problem is to

1. Iterate over each pair p1 communicated by the first participant, and do the following:

Iterate over all pairs p2 of the second participant that are not equal to p1 and count whether the first number of p1 appears in any of them and whether the second number of p1 appears in any of them. If only one of them appears, that number is a candidate to be the matching number. If after iterating over all pairs communicated by the first participant only one candidate number was observed, then we know with certainty that that number is the one, and can immediately return it.

2. Do (1) but iterating over the numbers communicated by the second participant in the outer loop.

3. If at this point no number was returned, the answer is either -1 or 0. It is -1 iff for some pair (a,b) communicated by one of the participants, there are both pairs (a,c) and (b,d) among pairs communicated by the other participants, such that c≠b and d≠a (but possibly c=d), since in that case if the first participant indeed has the pair (a,b), they can't tell whether the actual number is a or b. Otherwise the answer is 0.

994E - Careful ManeuveringOne way to solve the problem is to fix one spaceship in the left half and one spaceship in the right half, and assume that they shoot each other by the means of shooting towards one of the small spaceships. This gives us a coordinate of one small spaceship. Once we have it, iterate over all the large spaceships, mark those that are already shot.

Now all that is left is to find the best place to position the second spaceship. To do that, create a map from a coordinate to number of unmarked spaceships that would be destroyed if the second small spaceship is at that coordinate. Iterate over each unique spaceship coordinate on the left and each unique spaceship coordinate on the right, and increment the value in the map that corresponds to the position of the second small spaceship that would result in those two large spaceships shooting each other down by the number of large unmarked spaceships at the fixed coordinates.

Then update the final answer with the largest value in the map plus the number of marked spaceships and move to the next pair of spaceships in the outer loop.

This is a O((n×m)2) solution.

994F - Compute PowerFirst observe that if for some threshold there's a way to assign tasks in a way that they will finish computation, it is also possible for all higher thresholds.

Because of that, we can use binary search to find the threshold. Now the problem is reduced to figuring out if for a given threshold the tasks can be assigned in a way that the system doesn't blow up too early.

For that, observe that if the average power per processor exceeds a given threshold, it also means that the average power exceeds the threshold multiplied by the number of processors, which in turn means that the average power minus threshold multiplied by the number of processors exceeds 0. By regrouping summands, we can associate the value (power - threshold * num_of_processors) to each task, and reduce the problem to finding the mapping of tasks to computers that minimizes the sum of values of all the tasks assigned as the first task, and compare it to zero.

To do that, we can use sort the tasks by the power value in decreasing order and use dynamic programming. The dimensions are:

i: The current task considered

j: How many tasks that use strictly more power than the i - 1st task are assigned as the first task to some computer that doesn't have a second task yet.

k: How many tasks that use exactly as much power as the i - 1st task are assigned as the first task to some computer that doesn't have a second task yet.

Transitions involve either assigning the task as a first task to some computer that has no tasks yet (increasing k, increasing the value by the value of the i-th task) or assigning the task to some computer that has a first task (decreasing j, not changing the value). Whenever i-th task's power differs from i - 1st task, j increases by k, and k becomes equal to zero.

The minimal sum of task values is then equal to the minimum of dp[n][j][k] over all j, k. Update the state of the binary search depending on whether the minimal sum is greater than zero or not.

Note that this is O(n3) × log(precision). As an exercise, find a solution that is O(n2) × log(precision)

993E - Nikita and Order StatisticsFirst, we can find amount of numbers that less than x for each prefix of a (including empty prefix). We get array s of this values. You can see that for each i,j,i<j the truth that s[i]≤s[j] and if s[i]<s[j] then i<j.

Let's count array r such that r[i] is number of occurences i in s. Then answer for each d from 1 to k answer ans[d] is ∑i,j,i−j=dr[i]⋅r[j].

Let's create array v, v[i]=r[n−i].

If p=r×v then p[n+d]=∑i,h,i+h=n+dr[i]⋅v[h]=∑i,j,i+n−j=n+dr[i]⋅r[j]=∑i,j,i−j=dr[i]⋅r[j]=ans[d].

Multiplication r and v can be done by FFT. You should write it accuracy or use extended floating point types because values in p can reach 1010. Also you can use NTT by two modules and Chinese Remainder Theorem.

Case k=0 should be processed separately because of if s[i]≤s[j] it's not true that i<j. We can get answer easily by using set or array of labels.

Time complexity is O(n⋅log(n)).

993F - The Moral DilemmaFirst lets observe that for the original and the inverted circuit to return the same value for each input, for each possible input one of the two conditions must be met: either in the original circuit all the gates in the second layer return 0, or in the inverted circuit all the gates in the second layer return 0.

This in turn means, that for each input *each* gate in the second layer must return zero in either original or inverted circuit. Since its output only depends on at most two gates in the first layer, and at most four inputs, we can iterate over all possible configurations of gates in the first layer, gate in the second layer, and connections to the inputs to find all configurations that meet this criteria.

All these configurations will share an important property: for a gate to return zero for each input in either the original or inverted circuit, it must either return zero in the original circuit for all inputs, or return zero in the inverted circuit for all inputs.

Some of these configurations (e.g. and(nand(a,b),and(a,b))) always return 0 in one circuit, and 1 in the opposite circuit. Other configurations (e.g. and(and(a,b),nor(a,c))) return 0 in one circuit, and something depending on the input in another, but critically 0 for the case of all inputs equal to 1.

For a circuit to meet the condition in the problem, it needs to have gates such that all of them return zero in either original or inverted circuit, and at least one of them to return one in the other circuit. WLOG let's consider the case of all gates returning zero in the original configuration, and at least one returning zero in the inverted configuration. Such circuit has two properties:

1. The circuit only contains the following gates in the second layer: and(nand(a,b),and(a,b)), and(or(a,b),nor(a,b)), nor(nand(a,b),and(a,b)), nor(or(a,b),nor(a,b)), and(and(a,b),nor(a,c)), nor(nand(a,b),or(a,b)). The first four of them in the inverted graph will always return 1, and the last two will return something depending on the input.

2. The circuit contains at least one of the first four gate kinds, and having at least one such gate is sufficient for the circuit to meet the condition from the problem. The latter is easy to show: since each of the first four gate kinds always returns 1 in the inverted mode, having it is sufficient to have at least one gate return 1 in the second layer. To show the former, remember that the last two gates return zero in the inverted mode when all three inputs are ones. It means that no matter how many of last two kinds of gates we have, and no matter how they are wired with the inputs, if all the inputs are equal to 1, all such gates will return 0, and at least one gate of the first four kinds will be necessary to have at least one gate to return 1.

From here the solution is trivial: to find the largest subset of the gates in the second layer that would all return 0 in the original circuit, and at least one return 1 in the inverted, we choose the largest set of gates that belong to the abovementioned set, for as long as at least one of them belongs to the first four kinds. If no gate in the second layer belongs to the first four kinds, the desired subset doesn't exist.

Solution for the case when the inverted circuit has all gates in the second layer always return zero and original has at least one that returns one is solved similarly.

Codeforces Round #487 (Div. 2) Editorial

By cyand1317, history, 5 years ago, In EnglishSelamat petang!

The curtain has fallen on Codeforces Round #487 (Div. 2). Have you enjoyed the problems themselves? Or the stories? Or both? Neither?

I hadn't ever intended to create a hard contest, believe me... (╥﹏╥) The author will try to find ways to estimate the difficulty better in the future. Also, stronger pretests, notes taken.

Anyways, hope you've all enjoyed the challenges you've faced, and gained something from this round. Congratulations to those who performed well, and commiserations to those waiting for their next chance to shine (^_−)−☆

Below are the tutorials of all problems. Feel free to point out mistakes (if any) or share your ideas in the comments! I might be overcomplicating or confusing something > <

989A - A Blend of SpringtimeA cell can get its colours from at most three cells: itself and its two neighbouring cells (if they exist). In order to collect all three colours, all these three cells should contain a blossom, and their colours must be pairwise different.

Therefore, the answer is "Yes" if and only if there are three consecutive cells containing all three letters. Implement it in any way you like.

Bonus. Give a solution (that can be proved to be correct in all cases) in any language with the shortest code. The author achieved 72 bytes (including a Line Feed) in Ruby, can you beat them? ;)

Short Ruby solution989B - A Tide of RiverscapeOur very first observation is that when p≤n2, the answer can never be "No".

Under this case, find any dot si=".". At least one of si−p and si+p exists because p≤n2 and 1≤i≤n. We want to make si different from this character. In case this character is "0" or "1", replace the dot the other way round. In case it's a dot, replace the two dots differently with "0" and "1". After that, fill the remaining dots arbitrarily, and we obtain a valid answer.

If p>n2, we'd like to find a dot with a similiar property. That is, si=".", and si−p or si+p exists. Go over all dots, try find one, and carry out the same operation as above. If no such dot exists, the answer is "No".

Bonus. Prove the time complexity of the seemingly-brute-force solution below.

Bonus. In case the answer is "Yes", find the lexicographically smallest string that fulfill the requirements.

Bonus. Solve the bonus challenge with n≤105. (Estimated difficulty: Div. 2 C)

Noam's C++ solutionPython solution for the original problem as well as for the last challengeC++ seemingly-brute-force solution989C - A Mist of FlorescenceA picture is worth a thousand words.

There are enormous ways to solve this problem. What's yours? Fine-tune your input and parameters, depict your woods here and share with us in the comments! (Remember to clip and scale the image, though. You can surround the image with a spoiler tag to avoid taking up too much space.)

Note: in case jscolor doesn't load properly (a pop-up should appear when the colour inputs are clicked on), try refreshing once.

Shoutouts to Alexander Golovanov (Golovanov399) for his grid-drawing tool, on which our utility is based!

Model solution989D - A Shade of MoonlightThere are some ways to play around with formulae of kinematics, but here's an intuitive way.

With the concept of relative motion, let's not change the velocities of clouds, but the velocity of the moon instead. Namely, under a wind speed of w, consider the moon to be moving at a velocity of −w (seriously). This doesn't affect the relative positions of all objects.

Our next insight is to represent the passage of time with a vertical y axis. In this way, a cloud becomes a stripe of width l2√ tilted at 45∘, and the moon becomes a ray passing through the origin arbitrarily chosen above the curve y=|x|wmax.

The diagram for the first sample, where l=1 and wmax=2.Square-shaped intersections of sky blue stripes denote the intersections of clouds at different moments. The moon's track can be chosen in the range painted light yellow. Now we'd like to count how many squares above the x axis (because of the "future moment" constraint) have positive-area intersections with the yellow range.

Since wmax≥1, the tilt angle of the curve does not exceed 45∘ in either half-plane. Thus, a square has positive intersection with the range, if and only if its top corner lies strictly inside the range.

For a pair of rightwards-moving cloud u and leftwards-moving cloud v, their intersection in the diagram has a top corner of (12(xu+xv+l),12(xv−xu+l)). One additional constraint is xu<xv, which is a requirement for the square to be above the x axis.

For this point to be inside the allowed range, we need xv−xu+l>|xu+xv+l|wmax. Going into two cases where xu+xv+l≥0 and xu+xv+l<0 and solving linear inequalities, we get the following necessary and sufficient condition of valid pairs:

−(xv+l)≤ xu<min{(xv+l)⋅(w+1)w−1,−(xv+l)}orxu<min{(xv+l)⋅(w−1)w+1,xv}According to these formulae, go over each leftwards-moving cloud v, and find the number of u's with binary search. The overall time complexity is O(nlogn). It's recommended to calculate the fractions with integer floor-division, but... Lucky you.

Bonus. Solve the problem without the seemingly-weird constraint that no clouds intersect initially. This should be rather easy based on the original solution.

Bonus. Prove that the fractions above, when calculated with IEEE doubles (53 significand bits), will never cause wrong answers under the problem's constraints. (Tricky one, enjoy ;))

Model solution989E - A Trance of NightfallIs this a graph theory problem? Yes.

Let's consider a graph G=(V,E), where there is a vertex for each point in S (the terms "vertices" and "points" are used interchangeably hereafter), and an edge (u,v) of weight w whenever v can be reached from u in one move with a probability of w.

Finding out all the lines, removing duplicates, and building the graph can be done straightforwardly in O(n3) time.

Represent the graph as an adjacency matrix A. Now, given a fixed target vertex t, we'd like to calculate for each vertex u the probability of reaching t from u after m moves. Let f(m)u be this probability.

We can represent f(m) as an n×1 vector. Obviously f(0)=(0,…,0,1,0,…,0)T, where only the t-th element is 1. Here vT denotes transpose of v.

It's not hard to see that f(m)u=∑(u,v)∈EAu,v⋅f(m−1)v. Thus we can deduce that f(m)=A⋅f(m−1). By induction, f(m)=Am⋅f(0).

In this way, for each query (t,m), we can calculate f(m−1) in order to get for each u the probability of reaching t in m−1 steps.

You may ask, why m−1? It's because after the first move, the whole process can be determined by Kanno's position; but the first step is up to us to decide.

To be more precise, the process, therefore the desired probability, is determined after the l in the first move has been chosen. We should observe that if we select a point from which there are multiple candidates of l, we can always select a point on one of the candidates, making it the only candidate without decreasing the whole probability. It's because the average of a set of numbers never exceeds the largest among them.

Hence, we've proved that we only need to consider cases where there is only one candidate for l, and such cases are always valid. For each l, we should calculate the average of f(m−1)u such that the u-th point lies on l. With f(m−1) calculated, this should take no more than O(n2) time.

Now, one last thing remains: how to calculate f(m−1) quickly?

We utilize a trick that a multiplication of an n×n matrix and an n×1 vector takes O(n2) time. With A2i preprocessed for all non-negative integers i≤log2m in O(n3logm) time, we can perform O(logm) matrix-vector multiplications in order to calculate f(m−1) in O(n2logm) time.

Overall, the time complexity for the problem is O((n+q)⋅n2⋅logm).

If anybody is ever too lazy (:P) to do the fast-exponentiation step, setting m′=min{m,100} and applying O(m) matrix-vector multiplications also work well with the error toleration.

Bonus. Think of this problem in other ways that do not work. What's the difference, and where do the redundant calculations lie?

Bonus. Is the problem solvable with matrix diagonalization?

Bonus. In theory or in practice, try to show that the errors do not accumulate quickly in the matrix exponentiation processes for this problem.

Model solutionSee you next time! I hope I'll be welcomed. Cheers!

Codeforces Round #486 (Div. 3) Editorial

By vovuh, history, 5 years ago, In English988A - Diverse Team

Tutorial988A - Diverse TeamLet's write our "unique" function. Keep the array of the taken elements used. Iterate over all elements in the array a and if the current element is not used (used[ai]=false) then add its index i to the answer and set used[ai]:=true. When finished, check the number of distinct values (that is the size of answer array). If it is less than k, print "NO". Otherwise print "YES" and output the first k elements of the answer.

Solution (Vovuh)988B - Substrings Sort

Tutorial988B - Substrings SortFirstly, sort all the strings by their lengths (if there are several strings of the same length, their order does not matter because if the answer is "YES" then all the strings of the same length should be equal). Then for each i∈[1..n−1] check that si is a substring of si+1. If it doesn't hold for some i then the answer is "NO". Otherwise the answer is "YES" and the sorted array is the correct order of strings.

Solution (Vovuh)988C - Equal Sums

Tutorial988C - Equal SumsLet's calculate the array of triples t. Triple ti=(sumi,seqi,eli) means that the sum of the sequence seqi without the element at position eli will be equal to sumi. Triples can be easily calculated in a following manner: for each sequence find its sum, then iterate over all its elements and subtract each of them one after another. Now sort array t with the standard compare function. Finally the answer is "YES" if and only if there exist two adjacent elements with equal sums and different sequences (it is very easy to see). So if we find such a pair, then the answer will be "YES", otherwise the answer will be "NO".

Time complexity of the solution is O(∑i=0k−1ni⋅log∑i=0k−1ni).

Solution (Vovuh)988D - Points and Powers of Two

Tutorial988D - Points and Powers of TwoFirstly, let's prove that the size of the answer is not greater than 3. Suppose that the answer equals to 4. Let a,b,c,d be coordinates of the points in the answer (and a<b<c<d). Let dist(a,b)=2k and dist(b,c)=2l. Then dist(a,c)=dist(a,b)+dist(b,c)=2k+2l=2m (because of the condition). It means that k=l. Conditions must hold for a triple b,c,d too. Now it is easy to see that if dist(a,b)=dist(b,c)=dist(c,d)=2k then dist(a,d)=dist(a,b)∗3 that is not a power of two. So the size of the answer is not greater than 3.

Firstly, let's check if the answer is 3. Iterate over all middle elements of the answer and over all powers of two from 0 to 30 inclusively. Let xi be the middle element of the answer and j — the current power of two. Then if there are elements xi−2j and xi+2j in the array then the answer is 3.

Now check if the answer is 2. Do the same as in the previous solution, but now we have left point xi and right point xi+2j.

If we did not find answer of lengths 3 or 2 then print any element of the array.

The solution above have time complexity O(n⋅logn⋅log109) (because of we can check if the element is in the array with some data structure in O(logn)).

Solution (Vovuh)988E - Divisibility by 25

Tutorial988E - Divisibility by 25Let's iterate over all pairs of digits in the number. Let the first digit in the pair be at position i and the second at position j. Let's place these digits to the last two positions in the number. The first greedily goes to the last position and then the second goes to the position next to that. Now the number can contain a leading zero. Find the leftmost non-zero digit and move it to the first position. Then if the current number is divisible by 25 try to update the answer with the number of swaps. It is easy to show that the number of swaps is minimal in this algorithm. The only difference we can introduce is the number of times digit i, digit j and the leftmost non-zero digit swap among themselves. And that is minimized. You can also notice that the order of swaps doesn't matter and you can rearrange them in such a way that no leading zero appears on any step.

This solution has time complexity O(log3n). You can also solve this problem with O(logn) complexity because you have to check only four options of the two last digits (25, 50, 75, 00). It is always optimal to choose both rightmost occurrences of the corresponding digits. You can show that even if you are required to swap the chosen ones, there will be no other pair with smaller total amount of moves.

Solution (Vovuh)988F - Rain and Umbrellas

Tutorial988F - Rain and UmbrellasAny experienced contestant can easily guess that the problem can be solved with dynamic programming. Coordinates are not really large so you can precalculate the array rain0,rain1,…,raina−1, where raini is a boolean value — True if there exists some segment of rain to cover the segment between positions i and i+1 and False otherwise. This can be done in O(n⋅a) with the most straightforward algorithm. You can also precalculate another array umb0,umb1,…,umba, where umbi is the index of the umbrella of minimal weight at position i or −1 if there is no such umbrella.

Now let dp[i][j] be the minimal total fatigue you can take if you are holding umbrella number j on the end of the walk up to position i. If j=0 then you hold no umbrella. Initially all the values are ∞ and dp[0][0] is 0. You can either hold your umbrella, drop it or pick up the best one lying there (and drop the current one if any) when going from some position i to i+1. So here are the transitions for these cases:

dp[i+1][j]=min(dp[i+1][j],dp[i][j]+weightj) if j>0;dp[i+1][0]=min(dp[i+1][0],dp[i][j]) if rain[i]=False;dp[i+1][umbi]=min(dp[i+1][umbi],dp[i][j]+weight[umbi]) if umbi≠−1.The answer is equal to mini=0mdp[a][i]. If it is ∞ then there is no answer.

So you have a⋅m states and all the transitions are O(1).

Overall complexity: O(a⋅(n+m)).

There is also a solution in O(alog2a) with Convex Hull Trick using Li Chao tree. You can probably even achieve (n+m)log2(n+m) with some coordinate compression. Obviously this wasn't required for the problem as the constraints are small enough.

Solution (Vovuh)Solution (step_by_step)

Codeforces Round #485 Editorial

By Um_nik, history, 5 years ago, translation, In EnglishI want to apologize once more for queue problems. It has also aggravated some tight ML/TL issues which probably would be not so big otherwise. I hope you enjoyed the problems nevertheless.

987A - Infinity GauntletJust do what is written in the statement. Convenient way is to use map in C++ or dict in Python.

38799778

987B - High School: Become HumanWe need to compare xy with yx. Let's take logarithms of both sides. Now we need to compare ylnx with xlny. If you will compare this numbers with appropriate epsilon, it will get AC, but let's analyze a bit more and get solution in integers. Let's divide both sides by xy, now we need to compare lnxx with lnyy. That's the values of some function f(x)=lnxx taken in two points. Let's take a closer look on this function. You can take derivative or just look at the plot at WolframAlpha.



It's clear that this function have maximum at point e, and it is increasing on [1,e] and decreasing on [e,+∞). Considering only integer points, f(1)=0, f(3) is maximal, f(2)=f(4) (because 24=42=16), and values in points greater than 4 are decreasing but always positive. So, the order of x from larger f(x) to smaller f(x) is 3,2=4,5,6,…,+∞,1.

38799800 — logs38799811 — case analisys

987C - Three displaysLet's fix j. Now we can see that i and k are independent, so we can find best i by iterating over all i<j, checking if si<sj holds and choosing the one with smallest ci. Then do the same for k.

There are O(n) options for j, for each of them we will do O(n) operations. Total complexity is O(n2)38799824

986A - FairLet's find a cost to bring a good t in each town. To do this we will run BFS from all towns producing good t at once. Just add all that towns in queue and run usual BFS. Complexity of BFS is O(n+m), so total complexity of k BFSs will be O(k(n+m)).

Now for each town we should choose s cheapest goods. We can sort them in O(klogk), but we can use nth_element instead. It will put the s-th element in sorted order on place s, and all elements smaller will be to the left. Since we are interested only in their sum, we can just sum up first s elements after calling nth_element.

Another way to achieve O(k(m+n)) complexity is to run all k BFSs simultaneously, then for each town first s goods to reach it are the cheapest.

Bonus: solve the problem in O(s(m+n)) time.

38799831

986B - Petr and PermutationsEach swap change the parity of permutation. 3n and 7n+1 always have different parities, so the solution is just to calculate the parity of the given permutation and check if it is equal to parity of 3n or to parity of 7n+1.

To calculate the parity you can just calculate the number of inversions with your favorite method (Fenwick tree, Segment tree, mergesort or whatever) in O(nlogn) time. But it is easier to calculate the number of cycles in permutation in O(n) time.

38799840

I hope that Petr is not mad at me for my joke.

986C - AND GraphLet's build directed graph on m+2n vertices. There will be two types of vertices: (x,1) is a vertex for x from input and (x,2) is a vertex for all x between 0 and 2n−1.

There will be edges of three classes:

(x,1)→(x,2) for all x from input(x,2)→(x|(1≪k),2) for all x and k such that k-th bit of x is 0(∼x,2)→(x,1) for all x from input. Here ∼x=((2n−1)−x) — the complement of xLet's look at some path of form (a,1)→(x1,2)→(x2,2)→…→(xk,2)→(b,1). The transition from x1 to xk just change some 0 bits to 1. So, x1 is a submask of xk. a is x1 and b is the complement of xk. Now it is clear that a&b=0. The opposite is also true: whenever a&b=0, there is a path from (a,1) to (b,1).

The solution is simple now: iterate over all x from input, and if the vertex (x,1) is not visited yet, run a DFS from it and increase the answer by 1. It is clear that we will run DFS exactly once for each connected component of original graph.

Complexity — O(n2n)3879985038799853 — completely different solution with complexity O(6n / 2)

986D - Perfect EncodingThe problem asks to find integers bi such that ∏bi≥n and ∑bi is minimized.

Let's suppose that in optimal solution there is x≥4 among bi. It is better to split it to 2 and (x−2): the sum remains the same and the product is increased (or stays the same). So we will use only 2 and 3 as our bi. If there are at least three 2 among bi, we can replace them with two 3: the sum remains the same, the product is increased.

So, optimal solution looks like this: zero, one or two 2s and some 3s.

For now let's say that we try all three possibilities for the number of 2s. The problem now looks like "find ⌈log3n⌉".

The trick here is that we can estimate the answer very accurately. Let's say that the length of decimal form of n is L. Then log3n is very close to Llog10log3, the difference is not greater than 3. So it is easy to calculate the number p such that 3p<n/4<n<3p+6.

If we will calculate 3p, then we should adjust this a little bit by multiplying by 3 a few number of times. Multiplying by 3 can be done in linear time, comparing two numbers also in linear time. Let's now remember that we have tried all the possibilities for the number of 2s. We will do it not beforehand, but only now, because now each option can be checked in linear time.

To calculate 3p we will use binary exponentiation with FFT. If the length of the result is L, then the running time will be O(LlogL+L2logL+L4logL+…)=O(LlogL).

To reduce the running time you should store the numbers in base 1000, not in base 10. This will reduce the length of the number 3 times, and the numbers we are getting in FFT will be at most 5⋅1011 which is good enough to avoid precision issues.

In the end, running time is roughly equivalent to 4 FFT calls of size 219 which is not that big.

Total complexity — O(LlogL).

38799873

986E - Prince's ProblemLet's solve the problem offline and independently for all primes, then multiply the answers. The sum of powers of all primes is O((n+q)logC). To factorize numbers we will precalculate smallest prime divisor for all numbers using sieve.

For fixed prime p let's write its power bv in every vertex. Then if p is in x from query in power z, then the query become "calculate ∑vmin(bv,z)". Let's do the following. We will start with cv=0 in all vertices. Then we will iterate over w — the power of p — from 1 to maximal power in queries. If bv≥w, then increase cv by 1. Now in all vertices cv=min(bv,w) so to answer all queries with z=w we should just take sum on path. This can be done if we will maintain cv in Fenwick tree over Euler tour of our tree (this allows to calculate sum on path to root in O(logn) time, to get sum on arbitrary path we also need to compute LCA).

The number of queries to Fenwick tree is O((n+q)logC), so total complexity is O((n+q)logClogn).

38799881

I hope that PrinceOfPersia is not mad at me for my joke.

986F - Oppa Funcan Style RemasteredLet's understand the problem first. The rule f(x) must be bijective, because otherwise some platforms will be empty in k seconds. So we are looking for permutations p of size n. Let's say that cycles of the permutation have lengths c1,c2,…,cm. pk is an identity permutation if and only if ci divides k for all i. Also ci≠1. So, we need to check if there are such numbers ci for which all these holds:

n=∑cici≠1ci is a divisor of kIt is not profitable to use composite divisors of k because we can substitute each of them with any its prime divisor repeated necessary number of times.

Let's say that p1<p2<…<pm — the list of all distinct prime divisors of k. Then the problem is essentially: Check if there are nonnegative coefficients bi such that n=∑bi⋅pi.

If m=0 (k=1) answer is NO.

If m=1, then the answer is YES if and only if n is divisible by p1.

If m=2, then you have to say if there is a nonnegative solution to Diophantine equation. It can be done using extended Euclid algorithm.

And if m≥3, then p1≤k1/m≤k1/3≤105. Let's find d(r) — the minimal number equal to r modulo p1 that can be written in form ∑bi⋅pi. If we do this, the answer is obvious: YES if and only if n≥d(nmodp1). To find all the d we'll build a directed graph. It's vertices are the remainders modulo p1, and there is a directed edge from x to (x+pi)modp1 with weight pi for all x and i. Let's see that the path from 0 in this graph is a set of pi, its weight is the sum of pi and it leads to a remainder of this sum modulo p1. Therefore, d(r) is shortest path from 0 to r in this graph. There are p1 vertices and p1⋅m edges in this graph, so dijkstra's running time is O(mp1logp1)=O(mk1/mlog(k1/m))=O(k1/mlogk)=O(k1/3logk).

We also need to factorize k. Let's build sieve once and find all the primes up to K−−√ (K=1015). Then we can factorize numbers up to K in O(K√logK) just like in trivial O(K−−√) algorithm but trying only prime divisors.

Let's calculate complexity now. Let's say that number of all tests is t≤104 and number of different k is q≤50. Solutions for m=1 and m=2 works in O(1) and O(logn) time, so total time is O(tlogn). Solution for m≥3 works in O(k1/3logk), but this dijkstra should be done once for each k, for different n we should only check one condition using calculated distances. Therefore, total time for these solutions is O(qk1/3logk+t). Also there is sieve in O(K−−√loglogK) and factorization in O(k√logk) q times.

Total complexity — O(K−−√loglogK+q(k√logk+k1/3logk)+tlogn).

38799887

Разбор Codeforces #484 Round (Div. 2)

By AGrigorii, history, 5 years ago, translation, In English982A - RowSeating is the maximum when it does not exist two ones or three zeros together. It is also necessary to carefully process the ends of the series — it is necessary to check that you can not put a person on the most right or the most left chairs.

982B - Bus of CharactersNote that the final introvert-extrovert pairs are uniquely determined, and that using the stack, it is possible to recover which extrovert to which introvert will sit (note that the zeros and ones will form the correct bracket sequence). Then one of the solutions may be as follows:

Sort the array of the lengths of the rows in ascending orderFor each introvert write the number of the next free row and add it to the stackFor each extrovert write the last number from the stack and remove it from there982C - Cut 'em all!Note that if there is an edge that can be removed, we can do it without any problem. Let's consider such edge that in one of the obtained subtrees it is impossible to delete more anything else, and its removal is possible. What happens if we delete it in the tree? Relative to the other end of the edge, the odd-even balance of the subtree has not changed, which means that the edge has not been affected by further deletions. Which means if we remove it, the answer will be better.

This is followed by a greedy solution: in dfs we count the size of the subtree for each vertex, including the current vertex, and if it is even, then the edge from the parent (if it exists) can be removed.

982D - SharkLet's sort the array and insert the numbers in the sort order from smaller to larger. Using the data structure "disjoint set union" we can easily maintain information about the current number of segments, as well as using the map within the function of union, and information about the current size of segments (locations) too. Then it remains only to update the answer when it's needed.

982E - BilliardIf you symmetrically reflect a rectangle on the plane relative to its sides, the new trajectory of the ball will be much easier. Linear trajectory if be correct. One possible solution is:

If the vector is directed at an angle of 90 degrees to the axes, then write the if-s.Otherwise, turn the field so that the impact vector becomes (1, 1).Write the equation of the direct motion of the ball:  – 1·x + 1·y + C = 0. If we substitute the initial position of the ball, we find the coefficient C.Note that in the infinite tiling of the plane the coordinates of any holes representable in the form (k1·n, k2·m).Substitute the coordinates of the points in the equation of the line of the ball. The Diophantine equation a·k1 + B·k2 = Cis obtained. It is solvable if C | gcd(A, B). Otherwise, there are no solutions.Of all the solutions of this Diophantine equation, we are interested in the smallest on the positive half-axis.By finding k1, k2 it is easy to get the coordinates of the corresponding pocketRotate the field back if required.982F - The Meeting Place Cannot Be ChangedLet's assume that solution exists and will looking for solution relying on this assumption. At the end will check found "solution" in linear time, and if it is not real solution, then assumption wasn't right.

If solution exists, then intersection (by vertices) of all cycles is not empty. Let's take any one cycle and call it "main cycle". Let's imagine this "main cycle" as circle directed clockwise. And let's mark all required vertices of intersection of all cycles on this circle (this vertices are the answer).

Consider only cycles which leave "main cycle", come back to the "main cycle", and then moves on the "main cycle" to the begining. Every such cycle when comes back to the "main cycle" DOES NOT jump over any marked vertex of the answer, in terms of direction of the "main cycle" (otherwise answer not exists, but we assumed, that it exists) (if cycle comes back to the same vertex, then by definition it jumped over the whole "main cycle", not 0). Draw the arc from the vertex, where cycle comes back to the "main cycle" till the vertex, where it leaves "main cycle", in the direction of the "main cycle". Vertices not covered by this arc can't be the answer. Intersection of all considered cycles is marked by intersection of all such arcs.

Now was not considered only cycles which some times leave "main cycle" and some times comes back to it. But intersection of such cycle with the "main cycle" is the same as intersection of simple cycles from previous paragraph between adjacent leave/comebacks. Therefore such cycles may be ignored.

For searching the answer we must mark arcs between leaves/comebacks of the main cycle. We do this by starting dfs from all vertices of the "main cycle" and trying to come back to it as far as possible (distance measured as the number of vertices of the "main cycle" between leave and comeback). As were noticed early, cycles does not jump over the answer. Therefore dfses started between boundaries of the answer are aspires to this boundary in direction of the "main cycle". Therefore if we selected the most far vertex in one dfs(u) reached from one start point v0, this vertex for dfs(u) reached from other start point v1 will be the most far too. And we can run all dfses with common "used" array, caching the most far vertex in it.

Finally the solution is so: 1) find the "main cycle" and sort vertices in it, 2) start dfses from vertices of the "main cycle" and mark arcs between finish and start, 3) intersect all arcs and take answer from intersection, 4) verify answer by deleting it from graph and trying to find any other cycle, if it founded, then assumption was wrong and solution doesn't exists else print the answer.

Codeforces Round #483 [Thanks, Botan Investments and Victor Shaburov!] Editoral

By FalseMirror, history, 5 years ago, In English984A - Game

tutorial984A - GameFirst let's notice that the first player makes ⌈n−12⌉ turns and the second one makes ⌊n−12⌋.

So, if numbers are 1-indexed and sorted, first player can make the answer not more than (n−⌈n−12⌉)-th by deleting maximal number every time. The second can make it not less than (⌊n−12⌋+1)-th.

But n−⌈n−12⌉=⌊n−12⌋+1, because n−1=⌈n−12⌉+⌊n−12⌋.

So the answer has minimal and maximal values, which are the same. So the answer is (⌊n−12⌋+1)-th number ascending.

Asymptotics is O(n⋅log(n) or O(n2)Solution

984B - Minesweeper

tutorial984B - MinesweeperLet's make two-dimensional array d[n][m]. For each cell i,j if it has bomb in it we add 1 in d[g][h] where g,h is neighboring cell for i,j. Now d[i][j] is a number of bombs in neighboring cells of i,j and we can check validity of field according to the condition of the problem:

If there is a number k in the cell, then exacly k of neighboring cells have bombs.Otherwise, if cell has no bomb, then neighboring cells have no bombs.Solution

983A - Finite or not?

tutorial983A - Finite or not?First, if p and q are not coprime, divide them on gcd(p,q). Fraction is finite if and only if there is integer k such that q∣p⋅bk. Since p and q are being coprime now, q∣bk⇒ all prime factors of q are prime factors of b. Now we can do iterations q=q÷gcd(b,q) while gcd(q,b)≠1. If q≠1 after iterations, there are prime factors of q which are not prime factors of b⇒ fraction is Infinite, else fraction is Finite. But this solution works in O(nlog21018). Let's add b=gcd(b,q) in iterations and name iterations when gcd(b,q) changes iterations of the first type and when it doesn't change — iterations of the second type. Iterations of second type works summary in O(log1018). Number of iterations of the first type is O(log1018) too but on each iteration b decreases twice. Note that number of iterations in Euclid's algorithm is equal to number of this decreases. So iterations of first type works in O(log1018) summary. Total time complexity is O(nlog1018)Solution

983B - XOR-pyramid

tutorial983B - XOR-pyramidLet's calculate f(a) recursively and save arrays from each level of recursion. We get two-dimencional array dp[n][n] and dp[n][1]=f(a). Now let's view recursive calculation for f(al…ar). You can see what array of i-th level of recursion is dp[i][l…r−i+1]⇒dp[r−l+1][l]=f(al…ar) (numbeer of levels of recursion is length of segment). To calculate maximum of all sub-segments for each segment, replace dp[i][j] on max(dp[i][j],dp[i−1][j],dp[i−1][j+1]). Now answer of question l,r is dp[r−l+1][l]. Overall time complexity is O(n2+q).

Solution

983C - Elevator

tutorial983C - ElevatorThis problem is inspired by living in the house of 9 floors with the elevator, which can accommodate up to 4 people. What a surprise!

We have a strict order. So let's make dp[i][state] =  minimal possible time, where i means that first i employees already came in the elevator (and possibly came out).

So, what is a state? Let's store something what will allow us to determine the state. For this purpose we want to know the floor, where the elevator currently is, and number of people, who want to reach each floor. So, it's 10 integers. Let's estimate the number of states: floor takes 9 values, state can take  (Wow!). Also let's notice, that we don't want to visit floor of nobody in the elevator don't want to go there and the next person isn't on that floor. So we have not more than 5 interesting floors for each state. Let's say the total count of states is s = 5·256.

Now we've got two different solutions.

The fast one is we say we go from the floor a[i] to the floor a[i + 1] and iterate over the persons who we let come in on the way.

The slow one is to run Dijkstra for each i: from state we can go to the floor and let somebody come out or go to the floor a[i + 1]. Now, when we calculated answers for i - 1, we can calculate dp[i][state] = 1 + dp[i - 1][state], if state has floor equals to ai and there are no more than 3 people inside.

The answer will be in dp[n][floor = j & elevator is empty] for .

Asymptotics is O(n·s) or O(n·s·log(s))

Solution

983D - Arkady and Rectangles

tutorial983D - Arkady and RectanglesFirst let's compress the coordinates. Now all the coordinates are in [0,2n).

Now we do scanline on x coordinate with segment tree on y coordinate. Let's talk about segment tree structute. In each vertex we store:

Set of colors which cover the whole segment. If color covers a segment, we don't push it to it childs (colors[v])Maximal visible color in subtree which isn't in the answer (max[v])Minimal visible color in subtree (min[v])For the vertex max and min can be calculated as:

If colors isn't empty and max value in colors is more than max in children:If it's already in the answer or it's less than min in children, max=−1.Otherwise max=max in colorsOtherwise max=max in childrenIf colors isn't empty min=max(max in colors,min in children)Otherwise min=min in childrenNow in scanline we:

Add all the segments, starting at this pointRemove all the segments, ending at this pointWhile max[root] isn't −1 we put it into answer and recalculate everything by readding this segment to tree.At the end we know all visible colors and print the number of them.

Asymptotics is O(n⋅log(n)+n⋅log2(n))Solution

983E - NN country

tutorial983E - NN countryLet's say we go down when we go towards the root, and we go up when we go against the root. Also we say that vertex a lower than vertex b if a is closer to the root.

Each way from v to u can be represented as two parts: at first we go down from v to lca and then we go up from lca to u.

Let's say we have to use a buses to go from v to lca and b buses to go from lca to u. Let's learn how to calculate a and b fast. Firstly, notice that we can move down greedily. So we calculate lowest[v] as the lowest vertex, where we can go from v using only one bus. Secondly, notice that we can now build binary lifting on lowest.

The answer is either a+b or a+b−1. Let's say the lowest vertex we can go from v using a−1 buses is lv and for u and b−1 buses it's lu. lv and lu can be also calculated using binary lifting on lowest. Then, if there is a route connecting lv and lu, the answer is a+b−1 and it's a+b otherwise.

Let's calculate lv and lu for all the queries.

Now we build an euler's tour. For each we now know the interval, corresponding to it's subtree. Let's say it is [time_in[v],time_out[v]). Then we run dfs again and do the following: when we came into lv we ask for sum on [time_in[lu],time_out[lu]). Now for each way, starting in lv we add 1 to its other end. Now we run dfs for all of its children. And now we ask for sum on [time_in[lu],time_out[lu]) for the second time. If it changed the route connecting lv and lu exists.

Asymptotics is O(n⋅log(n)+m⋅log(n)+q⋅log(n)).

Read the solution for better understanding. It tried to make it as readable as possible.

Solution

Codeforces Round #482 (Div. 2) Editorial

By ArguteOnAir, 5 years ago, In EnglishHi Codeforces!

This is the editorial of Codeforces Round #482 (Div. 2). I hope you guys enjoy it.

979A - Pizza, Pizza, Pizza!!!

SolutionIf n = 0, the answer is obviously 0.

If n + 1 is even, we can make  diametric cuts. Otherwise, the only way is to make n + 1 cuts.

Time complexity: O(1).

Code979B - Treasure Hunt

SolutionWe all knew that the substrings with length 1 appear at most in the string. So, to make a string as beautiful as possible, we will choose the letter that firstly appears at most in the string and replace all the other letters with the chosen letter.

There is some cases. If n is less than or equal to the number of remaining letters, just add n to the beauty. If n is even after replacing all letters with the chosen, we can choose an arbitrary letter, replace it with some other letter, return it back and repeat the work till n reach 0. Otherwise, we will not replace all the other letters. Instead, we will replace the letters until there is 1 letter left (now n is even) then replace that one with another letter different from our chosen letter. After that, replace that letter with our chosen letter. Now n is even again, we repeat the work discussed above.

In conclusion, let's call our string s, our chosen letter a and its number of occurrences in the string fa, then our answer is min(fa + n, |s|). Be careful with n = 1.

Time complexity: , where  is the total length of the three strings.

Code979C - Kuro and Walking Route

SolutionWe can consider the city as a graph, in which every town is a vertex and every road connecting two towns is an edge. Since m < n, we can deduce that this graph is a tree. Now, instead of finding the number of pairs that Kuro can choose, we can find the number of pairs that Kuro cannot choose. In other words, we must find the number of pairs of vertices (u, v), in which the shortest path from u to v passes through x and then through y. But how can we do this?

If we take vertex y as the root of the tree, we can see that every pair of vertices that Kuro cannot choose begins from any node within the subtree of node x, and finishes at any node but within the subtree of node z, which z is a direct child of y lying on the shortest path from x to y. In total, the number of pairs of vertices that we are looking for is equal of n·(n - 1) - s[x]·(s[y] - s[z]), which s[i] denotes the size of the subtree of node i. We can implement this using simple DFS.

Time complexity: O(n).

Code979D - Kuro and GCD and XOR and SUM

SolutionWe first look at the condition . This condition holds iff both xi and v are divisible by ki. Therefore, if , we return -1 immediately, else we only consider numbers in a that are divisible by ki.

Finding the maximum XOR of xi with v in the array a reminds us of a classic problem, where the data structure trie is used to descend from the higher bit positions to the lower bit positions. But since we only consider v such that  and xi + v ≤ si, we build 105 tries, where the ith trie holds information of numbers in a that are divisible by i, and we only descend to a branch in the trie if the branch is not empty and the minimum value in the branch is  ≤ si - xi.

Adding a number into a is trivial by now: we update every uth trie where u divides the number we need to add into the array. Notice that we only add a number if the number doesn't exist in the array yet.

Time complexity: O(MAXlog(MAX) + qlog(MAX)2).

Code979E - Kuro and Topological Parity

SolutionThe problem asks us to find the number of different simple directed acyclic graphs with 1 → n forming its topological order to ensure the parity of the number of alternating paths to be equal to p. We will solve this problem using the dynamic programming approach.

Let's define even-white as the number of different nodes u colored in white that has an even number of alternating paths that end in u. In the same fashion, let's define odd-white as the number of different nodes u colored in white that has an odd number of alternating paths that end in u, even-black — the number of different nodes u colored in black that has an even number of alternating paths that end in u, and odd-black — the number of different nodes u colored in black that has an odd number of alternating paths that end in u. Let's also define dp[i][ew][ow][eb] as the number of different graphs following the requirements that can be built using the first i nodes, with ew even-white nodes, ow odd-white nodes and eb even-black nodes (the number of odd-black nodes ob = i - ew - ow - eb). We will figure out how to calculate such value. For the sake of simplicity, let's consider the current node — the {i}th node to be a white node.

We can notice a few things:

If none of the previous i - 1 nodes connects to the current node, the current node becomes an odd-white node (the only alternating path that ends the current node is the node itself).

How the previous white nodes connect to the current node does not matter. There are 2ow + ew - 1 ways to add edges between the previous white nodes and the current node.

How the previous even-black nodes connect to the current node does not matter, as it does not change the state of the current white node (i.e. odd-white to even-white or even-white to odd-white). There are 2eb ways to add edges between the previous even-black nodes and the current node.

If there are an odd number of previous odd-black nodes that have edges to the current node, the current node becomes an even-white node. There are  ways to do this.

If there are an even number of previous odd-black nodes that have edges to the current node, the current node becomes an odd-white node. There are  ways to do this.

In conclusion, we can figure out that:



It is worth mentioning that we can use the same analogy to process when the current node is black.

In total, we process through n4 states, with an O(n) iteration for each stage, so the time complexity is O(n5). However, with precomputation of  and  for every value of ob, we can optimize the time complexity to O(n4).

Time complexity: O(n4).

Code

Codeforces Round #481 (Div. 3) Tutorial

By fcspartakm, 5 years ago, translation, In English978A - Remove DuplicatesWe will store integers which we already met in a set exist. Let's iterate through the given array from the right to the left. Let the current element is equal to x. So, if x does not contain in exist we add x in a vector-answer ans and add x in exist.

After we considered all elements the answer sequence contains in the vector ans in reversed order. So we should reverse the vector ans and simply print all its elements.

978B - File NameLet's iterate through the given string from the left to the right. In a variable cnt we will store the number of letters "x" which were before the current letter in a row. If the current letter does not equal to "x" we should make cnt=0. In the other case, the current letter equals to "x". If cnt<2, we should increase cnt by one. In the other case, we should add one to the answer because the current letter should be removed.

978C - LettersWe should use that the letter queries are given in increasing order of room numbers. We will store in a variable sum the number of rooms in already considered dormitories (this variable should have 64-bit type) and in a variable idx we will store the minimum number of dormitory where the room from the current letter possibly is. Initially, sum=0 and idx=1.

We will iterate through the letters. Let the current letter should be delivered to the room x. While sum+aidx<x, we increase sum by aidx and increase idx by one. So, we got the dormitory number where room x is. It only remains to print two integers: idx (the dormitory number) and (x−sum) (the room number in this dormitory).

978D - Almost Arithmetic ProgressionIf n≤2 we can print 0, because each such sequence is an arithmetic progression.

Note, that an arithmetic progression is uniquely determined by the first two terms. So we should brute d1 from −1 to 1 — the change of the first element of the given sequence, and d2 from −1 to 1 — the change of the second element of the given sequence. Then a1=b1+d1 and a2=b2+d2. Also we will store cnt — the number of changed elements in the sequence.

Initially cnt=|d1|+|d2|. Now we need to iterate through the sequence from the third element to n-th. Let current element in the position i. It should be equals to ai=a1+(i−1)⋅(a2−a1). If |ai−bi|>1, then such arithmetic progression is unreachable. Else, if ai≠bi we should increase cnt on one.

After we considered all elements we should update the answer with the value of cnt, if for all i it was true that |ai−bi|≤1.

978E - Bus Video SystemFirstly we should find the minimum and maximum numbers of passengers, which could be in a bus if initially it was empty. Let b=0. We should iterate through the bus stops. For the i-th bus stop, we add ai to b and update with a value of b the minimum number of passengers minB and the maximum number of passengers maxB.

If maxB>w, it is an invalid case and we should print 0, because the maximum number of passengers should be less or equal to w.

Let lf is a minimum possible number of passengers in the bus before the first stop and rg — maximum possible.

If minB<0 then in the bus initially were at least −minB passengers. Because we should make lf=−minB, else, lf=0.

If maxB≤0, then rg=w, else, rg=w−maxB.

After that we should compare lf and rg. If lf>rg — print 0. In the other case, print rg−lf+1, because each of those values is correct.

978F - MentorsFirstly we should sort all programmers in non-decreasing order of their skills. Also we need to store initially numbers of the programmers (we can user array of pairs — skill and initial number of the programmer).

We will iterate through the programmers from the left to the right. The current programmer can be a mentor of all programmers to the left of him after sort and with who he are not in a quarrel. Let the number of programmers to the left is x. Subtract from x the number of already considered programmers, who skill equals to the skill of the current programmer (it can be done, for example, with help of map). Also lets brute all programmers with who the current programmer in a quarrel (we can initially save for each programmer the vector of programmers with who he in a quarell; by analogy with the stoe of graphs) and if the skill of the current programmer more than the skill of a programmers, with which he in a quarrel, we should decrease x on one, because this programmer is to the left of the current after sort and has been counted in x.

We should store by a number of the current programmer the value x as answer for him.

978G - Petya's ExamsIf in the current day there is no exam, we should prepare for an exam, for which questions already given, for which we prepare less than needed and which will be before other remaining exams.

For this we will use array cnt, where cnti equals to the number of days, which we already prepared for exam i. Initially, array cnt consists of zeroes.

Let's iterate through the days. Suppose exam x is in the current day. If cntx<dx, we did not have time to prepare for it and we should print -1. In the other case, in this day we will pass the exam x.

In the other case, let iterate through all exams and choose exam x, for which we need still to prepare (i. e. cntx<dx), for which already given the questions, and which will be before other remaining exams. If there is no such exam, we should relax in this day, else, in this day we should prepare for exam x. Also, we should increase cntx by one.

Codeforces Round #480 (Div. 2) Editorial

By Hasan0540, 5 years ago, In EnglishHello again,

Thank you for participating. It was a great experience for me and I learned a lot. Hope you learned something as well! I'll try to avoid the issues some of you complained about, next time.

The tutorial of problems [A-C] was written by Motarack, [D-E] by Dark, and all were reviewed by Reem. Thank you guys!

980A - Links and PearlsThe problem can be viewed as the following:

You have a cyclic array with the characters '-' and 'o', you want to rearrange the elements of the array such that the number of '-' characters after every 'o' character is the same.

So we want to distribute the '-' characters over the 'o' characters so that all the 'o' characters have the same number of '-' characters after them.

If we have a of 'o' and b of '-', then that can be done if and only if bmoda=0. When a=0, the answer is YES since the condition still holds.

980B - MarlinInstead of looking at the second path from (4,1) to (1,n), consider it as from (1,n) to (4,1).

Now when k is even, we can do the following: start from (2,2), put a hotel in that cell and another hotel in (2,n-1), then a hotel in (2,3) and one in (2, n-2), and so on until either the second row is full (expect for the middle column) or the number of hotels is k, if you still need more hotels then just do the same for the third row.

This works because going from (1,1) to (4,n) is identical to going from (1,n) to (4,1) since the constructed grid is symmetric.

Now if k=2∗(n−2) then just fill the the middle column (second and third row), and if k is odd then just add a hotel in middle column.

980C - PosterizedFirst, it's obvious that for each group we should choose the color with minimum value as the group's key. Now since we want to find the lexicographically smallest array, we iterate from the leftmost number in the array and minimize it as much as possible without considering the numbers to its right.

There are many ways to implement this, one of them is the following:

Iterate from left to right, for each number x, if it is already assigned to a group then ignore it. Otherwise, check the colors less than x in decreasing order until you find a color y that is assigned.

If we can extend the group of y to include x and the size won't be exceeding k, then we do extend it and assign all the colors between y+1 and x to the key of y's group. If the size will exceed k or such y was not found (set it to −1 in this case), we create a new group with key equals to max(y+1,x−k+1) and assign all colors in the range to it.

The complexity of this solution is O(n+c), where c is the size of the color range.

980D - Perfect GroupsFirst let us examine perfect squares; a perfect square is a number x that can be written as the product of an integer and itself y∗y. This means that for each prime factor of the number x, the frequency of that factor must be even so it can be distributed evenly between each of the two y's.

This leads to the idea that for every two numbers a and b in a group, for a prime factor pi, either both a and b have an even frequency of pi, or they both have an odd frequency of it.

So using that observation, for each number x in the array we can discard all pairs of equal prime factors (keeping one copy of each factor with an odd frequency).

For example, number 40 has factors 2,2,2,5, so we can just ignore the first pair of 2′s because they're redundant and transform it into 2,5, which is the number 10.

Now after replacing each number with the product of its odd factors, we can just count the number of distinct elements in each subarray as each element can be only grouped with its copies. This can be done by checking all possible subarrays and keeping a frequency array to count the number of distinct elements in it.

- Elements need to be mapped to non-negative integers between 1 and n so we don't use a set to count them.

- Need to be careful in case there's a zero in the subarray. Zeros can join any group, so unless the subarray contains only zeros, we can ignore them.

Solution Complexity: O(n×sqrt(maxai)+n2)980E - The Number GamesAs the final set of remaining districts need to be reachable from each other, this means that the resulting tree is a sub-graph of the original one.

Now, looking at the number of fans in each district, district i has 2i fans. This means that if we had a choice of including a district i in our solution and discarding all the districts with indices less than i then it'd be better than discarding district i and including all the others, as 2i=2i−1+2i−2+...+20+1.

This leads us to the following greedy solution:

Let's try to find which districts to keep instead of which to discard, let's first root the tree at district n, as we can always keep it, and go through the remaining districts by the order of decreasing index. Now at each step, if we can include district i into our solution by taking it and all of the nodes on the path connecting it to our current sub-graph, then we should surely do so, otherwise we can just ignore it and move on to the next district.

This can be implemented by building a parent sparse-table and using Binary Lifting at each district i to find the first of its ancestors that has been already included in our sub-graph. The distance to this ancestor represents the number of districts that need to be included in the games to have district i included. So if we can still include that many districts in our sub-graph then we will traverse through the path and mark them as included.

Solution Complexity: O(nlogn)980F - Cactus to TreeThe following solution is implemented in 136 lines, but most of it is a simple BFS and two DFS functions for finding bridges and marking cycles, the main part of the solution is implemented in 38 lines. Please check the code after (or while?) reading if it is not clear.

Note that if we run a BFS from a node u, the BFS spanning tree will represent the edges that we should keep to minimize the answer for node u. So we actually need to find the maximum length out of all shortest paths that starts at u and end at every other node.

We will first focus on finding the answer for each node on one cycle:

For each node u on the cycle, we can compute L[u], the length of the longest shortest path that starts at node u and uses only the edges that do not belong to the cycle. This can be done using BFS in O(n+m) for one cycle.

Using the computed values, we can find the final answer for all nodes on the cycle in O(klogk), or O(k), where k is the number of nodes on the cycle.

For a node u, we need to find a node v on the cycle such that L[v]+distance(u,v) is maximized, where distance(u,v) is the length of the shortest path between u and v on the cycle. Therefore, the answer with regards to each node u will be the maximum between L[u] and L[v]+distance(u,v), for each node v in the same cycle as u.

We can do this using a heap and prefix sums idea as follows: loop for 2k iterations over the cycle nodes, in the ith iteration (0≤i<2k) add the value L[cycle[imodk]]+2k−i to the heap with the time it was added in (time=2k−i, time is decreasing), that is, add the pair (L[cycle[imodk]]+2k−i,2k−i). Now at a given iteration j, pop from the heap all top values added at time greater than 2k−j+k/2, as distance(u,v) can't exceed k/2. Now assuming the top pair in the queue is (x,y), then x−(2k−j) is a possible answer for this node.

We need to do this again in counter-clockwise. Since we will visit each node four times, keep the maximum distance Zi found for each node i in the cycle and the final answer for that node will be max(Li,Zi).

Now if we have the answer for one cycle, when we move using an edge (a,b) to another cycle (or node), we only need to know one value to be able to solve the next cycle, that value is the maximum between Za and the length of the longest path that goes through bridges other than (a,b). This value is increased by 1 when passed since we will move through the edge (a,b).

Implementation:

Marking the bridges will help in deciding if an edge will take us outside a cycle or not so we can compute Li. Also removing the bridges will make it easy to find which nodes form each cycle.

We can find any BFS spanning tree and use it to find the length of the longest path that starts at a node and uses a bridge first, note that this distance goes only down as the tree is rooted at the starting node, but the values Lu for every u in the first cycle will be correct so we can start with them.

Solution: https://ideone.com/EEORpR

Codeforces Round #479 (Div. 3) Editorial

By vovuh, history, 5 years ago, translation, In English977A - Wrong Subtraction

Tutorial977A - Wrong SubtractionIn this problem you just need to simulate the process described in the statement (i.e. k times repeat the following operation: if n%10=0 then n:=n/10 else n:=n−1) and print the result.

Solution (Vovuh)977B - Two-gram

Tutorial977B - Two-gramThere are at least two different approaches to this problem:

You can iterate over all substrings of s of length 2 and calculate for each of them the number of its occurrences in s (and try to update the result with the current substring).

Also you can iterate over all two-grams in the alphabet and do the same as in the aforementioned solution.

Solution (Vovuh)977C - Less or Equal

Tutorial977C - Less or EqualIn this problem you can do the following thing: firstly, let's sort our array.

Let ans will be the answer. Then you have two cases: if k=0 then ans:=a0−1 otherwise ans:=ak−1 (for 0-indexed array).

Then you need to calculate the number of the elements of the array a that are less than or equal to ans. Let it be cnt. Then if ans<1 or cnt≠k then print "-1" otherwise print ans.

Solution (Vovuh)977D - Divide by three, multiply by two

Tutorial977D - Divide by three, multiply by twoLet deg3(x) be the maximum integer y such that 3y|x (x is divisible by 3y).

Our problem is to rearrange the given array in such a way that (easy to see it if we look at our operations) if it looks like ai1,ai2,…,ain, then for each k∈[1..n−1] the next inequality will be satisfied: deg3(aik)≥deg3(aik+1). And if deg3(aik)=deg3(aik+1) then numbers must be placed in increasing order (because of our operations). So we can store an array of pairs ans, when ansi=(xi,yi), xi=−deg3(ai), yi=ai. Then if we sort it in lexicographical order we can just print the second elements of the sorted array ans.

Solution (eddy1021)977E - Cyclic Components

Tutorial977E - Cyclic ComponentsLet's solve this problem for each connected component of the given graph separately.

It is easy to see that the connected component is a cycle iff the degree of each its vertex equals to 2.

So the solution is to count the number of components such that every vertex in the component has degree 2.

The connected components of the graph can be easily found by simple dfs or bfs.

Solution (Vovuh)977F - Consecutive Subsequence

Tutorial977F - Consecutive SubsequenceLet dp[x] be the answer for our problem if the last element of our subsequence equals to x.

Then we have an easy solution: let's store dp as a "std::map" (C++) or "HashMap" (Java). Initially for each i∈[1..n] dp[ai]=0. Then let's iterate over all ai in order of input and try to update dp[ai] with a dp[ai−1]+1 (dp[ai]=max(dp[ai],dp[ai−1]+1)).

Then the maximum element of dp will be our answer. Let it be ans. Then let's find any ai such that dp[ai]=ans. Let it be lst. Then for restoring the answer we need to iterate over all elements of our array in reverse order and if the current element ak=lst then push k to the array of positions of our subsequence and make lst:=lst−1.

Solution (Vovuh)

Codeforces Round #478 (Div. 2), Editorial

By Odin-, 5 years ago, In English975A - Aramic scriptOne can easily notice that we only differentiate between words when different letters exit, so one easy way to consider all the different words that belong to the same root as one, is to map every word to a mask of 26 bits; that is, for example, if letter 'b' exits in the ith word then we set the second bit in the ith mask to one, eventually, we insert all the masks in a set and the set size is the required answer.

Solution

975B - Mancalain this problem, we brute-force on the optimal hole to choose since there are only 14 holes, but how to calculate how many stones there will be after we start from the ith hole? the process of putting stones is repeating every 14 holes, suppose k is the number of stones in hand now so k/14 will be added to all holes and we simulate adding k mod 14 then we take the maximum answer from all the holes.

Solution

975C - Valhalla Siegenaive simulations will get TLE, so how to calculate fast how many people are going to die after the ith query, we can binary search on the prefix sum. Thus, we can tell how many people are going to die in O(log n) per query. Note: beware to handle the queries that do a partial damage for some warrior and include that partial damage in the later queries.

Solution

975D - GhostsThe condition for two points to meet in a moment of time T is for them to have the same X coordinates and the same Y coordinates.

Time when they have the same X coordinates is

X0i+VxiTx=X0j+VxjTxSo Tx should be

Tx=(X0i−X0j)/(Vxj−Vxi)Time when they will meet on Y axis

Ty=(aX0i−aX0j+b−b)/(Vyj−Vyi)In order for them to collide Ty=Tx so

(X0i−X0j)/(Vxj−Vxi)=(aX0i−aX0j+b−b)/(Vyj−Vyi)so

1/(Vxj−Vxi)=a/(Vyj−Vyi)So

aVxj−Vyj=aVxi−VyiMeaning that all ghosts with the same aVx−Vy will collide except if they were parallel.

the answer is two times the number of collisions.

Solution

975E - Hag's KhashbaIn this problem, we calculate the center of mass of the polygon (ie its centroid) and then we make it our reference point. we maintain its coordinates after each and every rotation.

Now when the pin is taken out from a vertex it leaves the other pin as a pivot for rotation we calculate the angle of current rotation. calculate the new coordinates of the center of mass after rotation, we should also store the initial distances from the center of mass, and the angle that the polygon had rotated around itself.

from the angle, coordinates of the center of mass and the initial distances from the center of mass it is possible to calculate the coordinates of any point in the polygon.

Note: when calculating the center of mass we should shift the polygon to the (0,0) because in some algorithms it uses point (0,0) in triangulation the polygon. if the polygon is very far from (0,0) accuracy will be lost. so better to either shift the polygon to (0,0) or use the first point of the polygon to form the sub-triangles of the polygon when calculating the center of mass.

Solution

Разбор VK 2018 Round 3 + Codeforces Round #477

By Endagorion, history, 5 years ago, translation, In English967A - Mind the GapThis problem requires you to carefully read and understand the statement. First, scan all the landing times, transforming each h and m pair into the number of minutes from the starting moment 60h+m. Then, there are three possibilities:

The first plane takes of not earlier than s+1 minutes from now. In this case we may put new takeoff right now.Otherwise, if there is a pair of planes with at least 2+2s minutes between them. In this case we may choose the earliest such pair and put a new takeoff at 1+s minutes after the first of these planes.Otherwise, we may always put a new plane in 1+s minutes after the last plane.Finally, print the answer in an h m format.

967B - Watering SystemIt's obvious that we should block several largest holes. Let's first sort them. After that, let's iterate through the number of blocked holes, maintaining the sum of sizes of non-blocked holes S. With the value S it is easy to compute if the flow from the first hole is large enough or not. Just output the number of blocked pipes at the first moment when the flow is large enough. The complexity is O(n).

925A - Stairs and ElevatorsFirst thing to mention is that we can use no more than one stairs or elevator per query. Indeed, optimal path is always a few sections horizontally, then a stair of elevator, then a few sections horizontally.

Then, we can note that we can always use one of the nearest stairs/elevators to start/finish. Using this fact, we can binary search in the sequence of stairs/elevators to find the optimal one, and choose the optimum between using a stairs and an elevator. Don't forget about the case where you don't have to reach any stairs/elevators.

The complexity is O(qlogn).

925B - Resource DistributionSuppose that the load of the first service was divided among k1 servers and the load of the second service was divided among k2 servers. In such case first service will be running on k1 servers of resource at least p1=⌈x1/k1⌉ and second service will be run on k2 servers of resource at least p2=⌈x2/k2⌉.

Suppose that p1≤p2, the remaining case will be dealt in the similar way. Remove all servers that have less than p1 resources, we are not going to use them. We may consider only assignments in which any server assigned to the first service has at most as many resources as any server assigned to the second service (otherwise we may swap them and the answer will still be correct). In such manner we may show that the first service may be assigned to the first k1 servers having at least p1 resource units and the second service may be assigned to the last k2 servers in ascending order of available resources.

Finally notice that if we fix k1, the optimal value of k2 is minimum such that the last k2 servers have at least p2 resource units. Calculate the minimum possible k2 in linear time, after that try each possible value of k1 and check if the first k1 servers having at least p1 resource units do not intersect with the last k2 servers (it may be checked in a single binary search).

We got a solution with running time of O(nlogn).

925C - Big SecretLet's assume that we've found a suitable permutation of all numbers, except all occurences of the number 1. When can we insert the 1's so that the new arrangement of numbers is again good? We can see that the XOR of all numbers before any occurence of the number 1 must be even, so there should an even number of odd numbers before it.

Suppose that there are x 1's in the input, and y odd numbers greater than 1. If x>y+1, then in any arrangement there is going to be a pair of 1's such that there are no odd numbers between them, hence the condition above cannot hold for both of them simultaneously. On the other hand, if x≤y+1, then it is possible to insert the 1's into any permutation of greater numbers. Indeed, we can place one instance of 1 at the start, and then place remaining 1's immediately after greater odd numbers.

Note that this argument works just as well if we consider numbers in the range [2k,2k+1) as "1's", and numbers in [2k+1,∞) as "numbers greater than 1". Note further that it doesn't matter how exactly we insert the "1's" since number of available gaps doesn't depend on that. Hence, we can go as follows: group the numbers by their leading bits. Make an empty list for the answer, and process the numbers in groups by decreasing of their leading bits. Suppose there are x numbers with leading bit k, and y greater numbers that have 1 in the k-th bit. If x>y+1, then there is no answer. Otherwise, insert the numbers from the current group as described above.

The complexity of this solution is O(nlogA), where A is the largest value among the numbers in the input.

925D - Aztec CatacombsLet us formualate a problem in terms of graph theory and make some observation. Denote the start and the finish vertices as s and t.

Observation 1. If vertices s and t are connected with a simple path consisting of k edges, then by the statement of the problem Indiana Johns may use it leading us to the answer of length k. Thus, the answer does not exceed d where d is the length of the shortest path between s and t if s and t are connected and ∞ otherwise. Let us call path consisting only of the original edges of the graph trivial and the paths including originally non-existent edges non-trivial.

Observation 2. The length of any non-trivial path is at least 4. Indeed, let s=v0−→e1v2−→e2⋯−→ekvk=t be the valid path in which some of the edges ei is missing in the original graph. Notice that the edge e1 may not be missing as by the moment we follow it, nothing was flipped yet, and e2 also may not be missing as it requires e2 to be same with e1 which was just flipped. Also note that e3 may not be the last edge in our path because otherwise it must be missing in the original graph (since the path is non-trivial), and we did not visit vertex v2 yet as v2≠v1 and v2≠v0=1. Thus, k≥4.

Observation 3. If d≤4, then the answer is d. It immediately follows from two previous observations: shortest trivial path has the length of d and shortest non-trivial has the length of at least 4.

Наблюдение 4. If d≥4 and there exists a vertex v2 at the distance of 2 from v0=s, then there exists a non-trivial path of length 4. Indeed, v0→v1→v2→v0→t is such path where v1 is a vertex through which the path of length 2 between v0 and v2 passes. Finally, note that v2 and v0 are not initially connected (otherwise the distance between v0 and v2 would be 1), hence when we visit v2, the edge v2→v0 is present. Similarly, by the moment of second visit of vertex v0 originally missing edge v0→t appears.

Observation 5. Any non-trivial path of length 4 looks exactly as described in an observation 4, first two initially existent edges, then newly appeared edge leading to s and finally newly appeared edge leading to t. It immediately follows from the explanation of the observation 2.

Observation 6. If d≥4 and there no vertex v2 located at the distance 2 from s, then s is connected with all vertices in its connected component and this component does not contain t.

Observation 7. If, under conditions of the previous observation, it we remove vertex s, then all the vertices initially adjacent to it will be distributed into several connected components. If all connected components are cliques, there are no valid paths. Indeed, after first transition we get into some clique and then we may only move inside it and it keeps shrinking until we get to an isolated vertex from which we can not go anywhere.

Observation 8. If any of the connected components adjacent with s is not a clique, then the shortest valid non-trivial path has a length of 5. Indeed, consider a connected component C initially connected with s that is not a clique. It is not a clique, hence it contains a vertex v1 of degree less than |C|−1. This vertex is not connected with a whole component C, thus there are vertices v2,v3∈C such that v3 is not connected with v1, while v1 and v2 are connected and v2 and v3 are also connected with an edge. It means that there is a non-trivial path v0→v1→v2→v3→v1→t.

The observations above cover all possible cases in this problem and also yield a solution working in linear time in terms of a size of the original graph.

925E - May HolidaysIn terms of trees we have a rooted tree whose vertices may be activated and deactivated, and each vertex has a limit for the number of deactivated vertices among its descendants. We are required to switch the state of some vertex, and after each query we report the number of activated vertices unsatisfied vertices. Let the balance of a vertex be equal to the difference between its limit of deactivated descendants and the actual number of deactivated vertices among its descendants. In such terms we are interested in the number of activated vertices with the negative balance.

Let's utilize the idea of sqrt-optimization. Consider a block of k consecutive queries, let us answer all of them. Suppose this query affects the state of vertices v1,v2,…,vl (l≤k), let us call such vertices interesting. Then, during the current query block, the balance will change only for the vertices that have at least one interesting vertex in its subtree.

Let's perform a classical trick of building the condensed tree containing the given interesting vertices. Namely, sort all the interesting vertices in order of their visit when doing DFS, and add all vertices of form lca(vi,vi+1) for all 1≤i<l to the set of interesting vertices. After such procedure all vertices whose balance may change may be splitted into O(k) vertical paths each of which ends in an interesting vertex.

Now we are going to consider separately the interesting vertices and the interior vertices of all paths between interesting vertices. In each of the paths the balance of all vertices is changed simultaneously, thus we may sort all the vertices in each path by balance and then group all vertices having the same balance together. Introduce a pointer that initially stands at the first satisfied group (with non-negative balance). When the balance of all groups is changed by 1, instead of actually changing the value of balance we may just shift the pointer by at most one position to the left or to the right (artificially changing the origin) and accounting at most one group the pointer has passed in the answer.

On each query we have to perform such an operation with every path and interesting vertex that is located above the queried vertex. Since each vertex and each path is processed in O(1), processing a single query takes O(k) time and processing all queries inside a block takes O(k2) time. It is possible to build all paths and groups in running time of a single DFS plus sort time (std::sort or counting sort) for grouping vertices of equal balance. This part of solution takes O(n) per each query block or O(nlogn) depending on used sorting algorithm.

If we use count sort, the resulting complexity will be O(mk(k2+n)), finally we can take k=Θ(n−−√) and get O(mn−−√) running time.

925F - Parametric CirculationFirst, let's use the classical reduction of lr-circulation problem to the maximum flow problem. Consider a network G′=(V∪{s,t},E′) where for each e=uv∈E there are three edges:

e0=uv with capacity ce0=re−lee1=sv with capacity ce1=lee2=ut with capacity ce2=leStatement: it is possible to provide a bisection between s−t flows of value ∑e∈Ele in G′ and lr-circulations in G. Indeed, consider a flow f′ in G′, that saturates all edges going from s (and all the edges leading into t at the same time). Let fe=f′e0+le. Notice that it is a correct circulation: for any vertex v

∑e∈δ+(v)fe=∑e∈δ+(v)f′e0+∑e∈δ+le=∑e∈δ+(v)f′e0+∑e∈δ+fe1=∑e∈δ−(v)f′e0+∑e∈δ−fe2=∑e∈δ−(v)f′e0+∑e∈δ−le=∑e∈δ−(v)fewhere the middle equation is immediately following from the conservation condition for any vertex from V for a flow f′.

On the other hand, the obtained circulation is indeed an lr-circulation because of how we got values of f′e. By performing all the steps in the reverse direction, we may recover a maximum flow in G′ by any lr-circulation that finishes our proof.

Now we are going to answer the following question: we have a parametric network G′(t) in which all capacities linearly depend on t, we have to find the probability that G′ allows a flow that saturates all edges from the source under condition that t is sampled from U[0,1].

Let us show that the set of t that allow existence of a sought flow is a segment. It follows from the fact that the value maxflow(t) of a maximum flow in G′(t) is concave: suppose f′(t1) is a an admissible flow in G′(t1) and f′(t2) is an admissible flow in G′t2. Then it is easy to see that λf′(t1)+(1−λ)f′(t2) is an admissible flow in G′(λt1+(1−λ)t2) for any λ∈[0,1] (as all the constraints on variables f′e are linear inequalities), from which immediately follows that maxflow(λt1+(1−λ)t2)≥λmaxflow(t1)+(1−λ)maxflow(t2).

Denote suml(t)=∑e∈El(t). Let us notices that gap(t)=suml(t)−maxflow(t)≥0 for any t and we are interested in precisely those values of t, such that gap(t)=0. Thus, the sought values of t form a segment as the function gap(t) is convex.

The remaining part of the solution is very simple: find a minimum of a convexvalue gap(t) over a segment [0,1]. If it is non-zero, then the answer is 0. Otherwise, we can locate the boundaries of an answer segment using two binary searches and print the difference between them.

While implementing such a solution, one may face several difficulties arising from the precision issues, so we will provide two observations that may help you deal with them.

One may notice that maxflow(t) is actually a piecewise linear function, all pieces of which have the integer slope. Actually, maxflow(t)=mincut(t)=mincut Ccost(C,t), and the cost of any fixed cut in G′(t) is a linear function of t with an integer slope. Thus, maxflow(t) is a lower envelope of a family of linear functions with integer slopes. The similar fact holds for a function gap(t) also. And we are interested in a horizontal segment in gap(t) which may be found using the binary search over a sign of a derivative gap′(t). Finally notice that calculating a derivative gap′(t) may be done by finding a maximum flow and adding up all slopes of capacities of the edges defining a minimum cut restricting given maximum flow (since exactly this cut provides a linear constraint defining a segment of a function gap(t), which a point t belongs to).

An alternative observation — consider only the points t such that t=k107 where k is integer. If we keep only such points on the sought segment, its length will decrease by no more than 2⋅10−7 which is allowed by a required answer precision. Finally, we can multiply all be and de by 107 and consider t to be an integer between 0 and 107 which allows you to implement a solution that only uses integer data types.

We get a solution with a running time of O(maxflow⋅logprec−1) where prec is a required precision equal to 10−6 under conditions of a given problem and maxflow is a running time of your favourite maximum flow algorithm. Practically you could use Dinic algorithm or Edmonds-Karp algorithm with capacity scaling.

Analysis of Codeforces Round #476 (Div. 2) [Thanks, Telegram!]

By KAN, 5 years ago, translation, In English965A - Paper AirplanesEach person should receive ⌈ns⌉ sheets. So, there should be at least k⋅⌈ns⌉ sheets in total, for them ⌈k⋅⌈ns⌉p⌉ packs are needed.

37617481

965B - BattleshipLet's compute for each cell four values: the number of cells where a part of the ship can be located to the right (r), to the left (l), up (u) and down (d), including the cell itself. Then, if k>1, then there are min(k,max(0,l+r−k))+min(k,max(0,u+d−k)) positions of the ship containing this cell, and if k=1 it's easy to check whether this value is 1 or 0. After that you should just print the maximum among all cells. This solution works in O(n3).

37617515

965C - Greedy ArkadyAs the limits on D are small, let's try all possible values of d — the number of times Arkady will receive candies. For a given d it's easy to compute xmin and xmax — the maximum and minimum values of x that suit these d and M. Then, with a fixed d it's easy to write the formula of how many candies Arkady gets: it's x⋅d candies. So it's obvious that we should choose xmax for the given d and update the answer.

Bonus 1: can you solve the task when the leftover is not thrown away, but is given to the next person?

Bonus 2: can you solve the task from bonus 1, but without the D≤1000 condition (just 1≤D≤n)?

37617552

965D - Одноразовые камниThis problem can be solved using many different approaches, most of them are based on different greedy solutions. We will discuss a solution with an easy-provable greedy.

First, let's do binary search for the answer. Let it be k. Then, assume that the stones are given by their positions x1,x2,…,xm, where m is the total number of stones. Also assume x0=0 and xm+1=w — the banks. Then, if for some i the condition xi+k−xi≤l is not satisfied, then k frogs can't cross the river. Indeed, consider the first jump for each frog that ends at a position further than xi. It can't end at xi+k or further because of the length of the jump, so it has to end at some stone at xi+1, xi+2, ..., or xi+k−1. But there are only k−1 such stones, so some stone is used by two frogs which is prohibited. Now, if xi+k−xi≤l is satisfied, the frogs can easily cross the river by using the route 0→xi→xi+k→xi+2k→… for the i-th frog.

So, the solution is to do the binary search for the answer and then compute the maximum distance between stones xi+k and xi. This can be done using two pointers technique.

37617576

965E - Короткий кодFirst, let's construct a trie of the names. Now a name is a token on some node in the graph, and we can move the token freely up to the root with the only constraint that no two tokens share the same node. We have to minimize the total depth of the nodes with tokens.

For each subtree let's compute the optimal positions of tokens that were initially in the subtree assuming that no token moves higher than the root of the subtree. It can be done easily with dynamic programming: if the current note has a token initially, then the answer is simply the union of this node and all the answers for the children. Otherwise, one of the tokens from children's answer should be moved to the current node. Obviously, it is the token with the highest depth. We can easily maintaining this using sets and smaller-to-larger optimization. This solution runs in O(mlog2m), where m is the total length of the strings.

Also, due to the specific structure of the tree (because it is a trie and there is a constraint on the total length of the strings), we can do the same simulation without any data structures in O(m) time.

37617599

Editorial Tinkoff Internship Warmup Round 2018 and Codeforces Round #475 (Div. 1 + Div. 2)

By voidmax, history, 5 years ago, translation, In EnglishThanks for participating in my contest!

It was my first round, I hope you enjoyed.

Editorial:964A - SplitsThere are 2 cases:

If weight of the split equals n, then the split consist of ones. Here we have only 1 option.

Else maximum number in the split is more then 1. Then we can replace all maximum numbers with twos and the rest we split into ones and weight will be the same. So, here we have n2 options.

Answer for this problem is n2 + 1.

964B - MessagesAdding C·k to account is equivalent to adding C to prices of all come, but not read messages. Then after every minute to every unread messages adds C - B. If C - B is positive, then answer is maximum when we read all messages at the time T. Otherwise we should read every message at the time it comes.

963A - Alternating SumLet Z=∑i=0k−1sian−ibi and q=(ba)k.

Let's notice that according equality is true: ∑i=0nsian−ibi=∑i=0(n+1)/k−1Z⋅qiWe can easily get values of Z, q. We only have to count the value of geometric progression.

Remember to handle the situation when q=1. In this case it is not necessarily means that a=b.

963B - Destruction of a TreeIf n is even, then the answer is always NO, because such trees have odd degree, but we can destroy only even number of edges.

For any odd n the answer exists.

Let's call dfs(i) from subtree i and destroy such nodes, that new subtree will be empty or for all alive nodes in connected component will be true, that they have odd degree.

Realisation of this dfs:

Call it from sons of i and recount degree of i, if it is even we destroy all subtree.

Assume, that after the destruction we have nonempty subtree. All nodes have odd degree, so amount of left nodes is even. So number of left edges is odd, but in start we have even count of edges, contradiction. That means, that we destroyed all nodes.

963C - Cutting RectangleThere are a lot of ways to solve this problem.

Let ai occurs in input cntai (sum of c) times аnd aj occurs cntaj. Then on a side of initial rectangle number of times ai occurs / number of times aj occurs is a ratio (cntai:cntaj). Analogically for b.

Let's build the smallest rectangle which satisfies this ratio and call him the base one. Then initial rectangle should consist of it.

The last step is to check that initial rectangle consists of base ones. To do this we'll iterate over all types of rectangles in input and if we find a mistake - print 0. In this way we will check no more than n+1 types of recktangles.

An answer for this task is number of divisors of ratio between the initial rectangle and the base one (it's not hard to see that this ratio equals to GCD of all ci)

963D - Frequency of StringLet M be the summary length of miNumber of different lengths of mi is O(M−−√). All mi are distinct, so summary number of their entries in s is O(MM−−√)).

Let's find all entries of every mi. To do this we can use Aho-Corasick's algorithm. Then we know entries of mi, it is not hard to calculate the answer.

963E - Circles of WaitingLet's call a sell "good", if for its coordinates the following condition is satisfied x2 + y2 ≤ R2.

For each good cell we consider the equation of its expected value:

f(x, y) = p1·f(x - 1, y) + p2·f(x, y + 1) + p3·f(x + 1, y) + p4·f(x, y - 1) + 1.

Then this problem can be reduced to solving the system of linear equations.

We can do this using Gauss's method with a complexity of O(R6), but this solution gets TL.

Now, we can see that we only need to calculate f(0, 0). So we will handle cells top down. While handling each row, we will relax values of all previous rows and a row of cell (0;0). Also we will iterate only for non-zero elements of each row. This solution has a complexity of O(R4).

Prove of the complexity:

Let's dye yellow all cells that we have already passed, green - all cells adjacent to them and black - all other cells. Then next cell which we will add is green. Note that its equation(for a moment of adding) doesn't include yellow cells. It consists of initially adjacent black cells and green cells. It's not hard to see, that then row includes only O(R) non-zero elements and the current green cell is inside of O(R) not visited rows. So one row in Gauss's method is handled inO(R2) and there are O(R2) rows. That's why this Gauss's method works in O(R4).

Divide by Zero 2018 and Codeforces Round #474 (Div. 1 + Div. 2, combined) Editorial

By apoorv_kulsh, 5 years ago, In English960A - Check the stringTraverse the string once and check if the ASCII value of all characters is greater than or equal or the ASCII value of the previous character. This ensures that the string does not have a,b,c in wrong order.

Also, while traversing the string, keep three separate counters for the number of 'a', 'b' and 'c' along.

Now, do a simple check on the condition for the count of 'c'.

The hack case for many solutions was to check that the count of 'a' is atleast 1 and the count of 'b' is atleast 1.

Set by : vntshh

Setter's solution960B - Minimize the errorThe problem can be interpreted as follows: array B is fixed and a total of k1 + k2 = K operations allowed on A. Let the array C be defined as Ci = |Ai - Bi| Now this is just a simple greedy problem where value of  is to be minimized after exactly K subtraction/addition operations spread over the elements of array C.

Till E is non-zero, the largest element is chosen and 1 is subtracted from it. This is done as currently we want to maximize the reduction in error per operation and decreasing an element x by 1 reduces error by x2 - (x - 1)2 = 2·x - 1.Once all the elements become zero, we can use the remaining moves to alternately increase and decrease the same element till we run out of moves.This can be implemented using a priority queue or by sorting the array C and iterating over it.

Expected complexity: O(N·K·log(N)) or O(N·log(N))

Set by : AakashHanda

Setter's solution960C - Subsequence CountingLet's call a subsequence valid if the difference of maximum element and minimum element is less than d.

For an array of size n with all the elements equal, there are 2n - 1 non-empty subsequences and all of them are valid. This is because for any subsequence, the difference of maximum element and minimum element is always zero.

We will use this observation in constructing the answer. Let's look at the binary representation of X. If the ith bit is set in X, we will add i equal elements (let's say y) in our final array. However this would give us 2i - 1 non-empty valid subsequences. To correct this, we will add a separate element y + d in the final array so that the final contribution of ith bit becomes 2i. We will carry out the same process for all the bits, keeping a counter of the previous

In this way, the length of the final array will never exceed  600 elements.

Expected Complexity : O(logX * logX)

Set by : 7dan

Setter's solution960D - Full Binary Tree QueriesLet us define the root of the tree to be at level L = 1.

Now, the level L for any value X can be found using this formula: L = 64 -  (Number of leading unset bits in X). In C++, you can conveniently calculate the leading unset bits by using __builtin_clzll(X).

Let us imagine each level of the tree as an array AL. Observe that we only need to consider L upto 60 due to the constraint that X ≤ 1018.

Queries of type 1 are equivalent to performing a cyclic shift of K on array AL.Queries of type 2 are equivalent to performing a cyclic shift of K on array AL , 2·K on array AL + 1 , 22·K on array AL + 2 ... 2Z·K on array AL + Z and so on. Since we only care about the first 60 levels, 0 ≤ Z ≤ 60 - L.Now,we can store the net shift SL of each level. Note that, for level L, we calculate SL under modulo 2L - 1 because there are exactly 2L - 1 values in some AL.

Finally, to answer queries of type 3, do the following:

Let the original index(0-indexed) of X in AL be P (P = X - 2L - 1). The new index after the shift will be  . The original value at this index was . We can find the parent of this value in the original tree by dividing V by 2 (Integer Division).Thus, We can now find all the values in the path from V to the root in the original tree. To get the values in the current tree, we just apply the opposite shift at each level to find the value and print it.Let the original value at index P in AL at some level L be V. The current value at this position after the shift will be the same as the value at index   in the original array. Let this value be Z. Now,. Print Z and set V = V / 2.Repeat Step 2 and stop when V = 0.Complexities of:

Query 1: O(1).Query 2: O(60).Query 3: O(60).Overall: O(60·Q)Refer to the code for further understanding.

Set by : Vicennial

Setter's solution960E - Alternating TreeAn important observation for the question is

A(u,v)=−A(v,u) if there are even number of nodes on the simple path from u to vA(u,v)=A(v,u) if there are odd number of nodes on the simple path from u to vHence A(u,v)+A(v,u)=0 for paths with even number of nodes.

Hence the task has been reduced to finding the total sum of alternating function of paths with odd number of nodes. Also we can make use of the fact that A(u,v)+A(v,u)=2∗A(u,v) , but this does not hold true when u=v, hence we must handle this case by subtracting ∑i=1nVi from the final answer.

Now with the help of a single dfs we can calculate

oddi the number of paths in the subtree of i with odd number of nodes ending at node i.eveni the number of paths in the subtree of i with even number of nodes ending at node i.In the first part of the solution, for each node i, we calculate its contribution to the alternating function for paths passing through this node but strictly lying within its subtree. For doing this we can merge two paths with either both having even or both having odd number of nodes ending at its children to create odd length paths.

For the case where both the paths have even number of nodes, the current node's contribution to the summation is Vi because its position in the sequence of nodes is odd . Similarly, we add −Vi for the other case. This can be done using a single dfs in O(n) time as we have oddi and eveni for all the nodes.

Now for the second part of the question, we have to consider the paths which end up outside the subtree. We have the information oddi and eveni . We have to merge these paths with those ending at parenti. How do we get this information? Note that oddi and eveni just represent paths strictly lying within the subtree of i but not the entire tree. An important observation for this computation is -

If node u has a total of x odd and y even length paths ending at it then, if v is the neighbour of u then v has a total of y odd and x even length paths ending at it. It is fairly simple to observe. We know oddroot and evenroot and since the subtree of root is the entire tree, we can use these values for our requirement. Now let's represent the total number of odd and even length paths ending at i by toddi and teveni respectively. From our previous observation,

if i is odd number of nodes away from the root node -

toddi=evenrootteveni=oddrootif i is even number of nodes away from the root node -

toddi=oddrootteveni=evenrootThe number of paths ending at parenti but lying strictly outside the subtree of i can be calculated -

odd length paths =toddparenti−evenieven length paths =tevenparenti−oddiNow we have to construct odd-length paths by merging paths in the subtree of i ending at node i with paths ending at parenti but strictly lying outside the subtree of i. For paths with odd-length component ending at i we must add Vi to the summation and −Vi otherwise.

Finally, the summation of contributions of each node yields you the total summation of alternating functions for all pair of nodes. This can be done for each node in O(n) time.

The overall time complexity of the solution is O(n).

Set by : rohitranjan017

Setter's solution960F - PathwalksThe problem is similar to Longest Increasing Subsequence, done on a graph instead of an array.

The solution for this problem can be obtained in the following ways:-

Approach1

Maintain a map for every node, consisting of weights and the corresponding max no of edges you can achieve for some path ending at that node at a given point. Now when you process the next edge, suppose ai bi wi , you query max no of edges having weight  < wi in map of node ai . Let's call this X. Now, you try to insert X + 1 for weight wi in map of node bi. Maintain it in such a way that no of edges for higher weights in a particular node is always larger than that for smaller weights. You can do this with (kind of) the conventional sliding window idea, by removing higher weight edges with smaller values than the current inserted answer in the map, or not inserting the current value at all because an equivalent or better answer exists for weights  ≤ wi for the node bi. Finally the max of all such X + 1 you encounter during processing the graph is the maximum number of edges in any given path.

Approach2

You can also solve this problem with the help of sparse/dynamic/persistent segment tree on every node of the graph. Suppose you are at the ith edge at some point in your processing, and the query was ai bi wi. Do a Range Max Query on segtree at node ai, uptil value wi - 1. Suppose this answer was X. Now update segtree at location bi with value of (X + 1). Store the max of all such (X + 1), and this is the length of longest path in your graph.

Set by : kr_abhinav

Setter's solution960G - Bandit BluesThe problem can be seen as to count the number of permutations such that the number of records from the front is A and the number of records from the back is B, where a record is an element greater than all previous.

let s(A, N) be the number of permutations such that for N elements exactly A records are present from front. Then s(A, N) can be calculated as

s(A, N) = s(A - 1, N - 1) + (N - 1) * s(A, N - 1)

Let's consider the smallest element if we have it as a record then we can place it on front and have the remaining A - 1 records in s(A - 1, N - 1) ways or we don't have it as a record than we can have the remaining A records in s(A, N - 1) ways and place this smallest element at any of the remaining N - 1 positions.

let h(A, B, N) be the number of permutations such that the number of records from the front is A and the number of records from the back is B.



k elements are chosen and placed before the largest record such that exactly A - 1 records are present in them in s(k, A - 1) ways and the remaining N - k - 1 after the largest record such that B - 1 records are present in s(N - k - 1, B - 1) ways.We choose the k elements in  ways.

Now we claim that



Proof — Consider permutations of length N - 1 with A + B - 2 records of which A - 1 are colored blue and B - 1 are colored green.

Note — Coloring a record means coloring the record and every element between this record and previous record.

We can choose permutations of N - 1 with A + B - 2 records ,then choose A - 1 of these records to be blue in  ways.

Also for any k between 0 and N - 1 we choose k elements to be in blue then make permutations in these k elements with A - 1 records and make permutations with exactly B - 1 records on remaining N - k - 1 elements, thus we have in total  ways.

Hence both are equivalent. Therefore calculating s(A + B - 2, N - 1) gives our answer. s(k, n) forms stirling number of first kind which can be calculated by coefficent of xk in x * (x + 1) * (x + 2) * ..... * (x + n - 1) using FFT.

Set by : apoorv_kulsh

Setter's solution960H - Santa's GiftThe actual cost of replacing all candies of flavour k in the subtree of vertex x is hk(x)⋅ck. Here, hk(x) is the number of vertices (candy) in the subtree of x with value (flavour) k and ck is the cost of replacing each candy of flavour k.

Error E(v) is defined as (hk(x)⋅ck–C)2 = hk(x)2⋅c2k+C2–2⋅hk(x)⋅ck⋅C.

Expectation of error E(v) can be written Exp[E(v)] = Exp[hk(x)2⋅c2k+C2–2⋅hk(x)⋅ck⋅C] = c2k⋅Exp[hk(x)2]+Exp[C2]–2⋅ck⋅C⋅Exp[hk(x)].

Exp[hk(x)] can be expressed as ∑nx=1hk(x)n. The above sum can be managed by adding or by subtracting the depth of node (assuming root to be of depth 1). Exp[hk(x)2] can be expressed as ∑nx=1hk(x)2n. It can be observed that for every pair of vertices with value k we need to add depth of LCA to the answer.

∑x=1nhk(x)2=∑fi=k∑fj=kDepth(LCA(i,j))=∑fi=k∑fj=kDist(i,j)/2–Depth(i)–Depth(j)Now we need to find the summation ∑fi=k∑fj=kDist(i,j).

To find sum we use centroid decomposition. We create a centroid tree from the given tree. Initially, no vertices have been inserted or updated. We update vertices one by one. While inserting a vertex with value k. We need to calculate its distance with all other vertices with the same value and add to the answer. To do so we maintain few things for a given vertex x in the centroid tree.

p(x) — Parent of vertex x in the centroid treehk(x) — Number of vertices currently present in the subtree of x with value vak(x) — ∑i∈subtree(x)distance(x,i)bk(x) — ∑i∈subtree(x)distance(p(x),i)The distance of any given vertex x with value k with other vertices of same value is given as ak(x)+dk(x).

Here, dk(x) is ∑i∈all ancestor of xdistance(i,x)⋅(hk(p(i)−hk(i))+ak(p(i))−bk(i))

For each vertex, we need to store for all values k present in the subtree. We can use a map for this purpose. In worst case, O(n⋅log(n)) memory will be used.

Set by : arnabsamanta

Setter's solutionDo give your feedback here : https://goo.gl/forms/xbsdMxnkA3XsG4092. Would love to hear your feedback, since that would help us get better!

Codeforces round #473 editorial

By mohammedehab2002, history, 5 years ago, In English959A - Mahmoud and Ehab and the even-odd gameIt's easy to see that if n = 0, the next player loses. If n is even, Mahmoud will choose a = n and win. Otherwise, Mahmoud will have to choose a < n. n is odd and a is even, so n - a is odd. Ehab will then subtract it all and win. Therefore, if n is even Mahmoud wins. Otherwise, Ehab wins. n = 1 doesn't follow our proof, yet Ehab still wins at it because Mahmoud won't be even able to choose a.

Code link (me) : https://pastebin.com/X3D08tg9

Code link (mahmoudbadawy) : https://pastebin.com/4u3RHE7n

Time complexity : O(1).

Bonus task : If there were multiple integers, and each player can choose which integer to subtract from, who will win?

Solution959B - Mahmoud and Ehab and the messageIt's easy to see that for every word, the minimum cost of sending it is the minimum cost of sending any word in its group. For each group, we'll maintain the minimum cost for sending a word in it (let it be costi) and for each word, we'll maintain its group (let it be groupi). For every word i in the message, we'll add costgroupi to the answer.

Code link (me) : https://pastebin.com/3RFeEkgD

Code link (mahmoudbadawy) : https://pastebin.com/sR5eZy7d

Time complexity : O((n + m)log(n) * len).

Bonus task : Try to solve the problem if the input was given as pairs of words that are synonyms (assuming synonymy is transitive).

Solution959C - Mahmoud and Ehab and the wrong algorithmThe first treeFor n ≥ 6, you can connect nodes 2, 3, and 4 to node 1 and connect the rest of the nodes to node 2. The real vertex cover is the set {1, 2} of size 2 while the found vertex cover will have size min(3, n - 3). As n ≥ 6, that value will be 3 which is incorrect.

For n < 6, the answer doesn't exist.

The second treeThere are multiple ways to construct it. One easy way is the star tree. Connect all the nodes to node 1. The real and the found vertex cover will be simply {1}. Another easy way is a path. Connect node i to node i + 1 for all 1 ≤ i < n. The real and the found vertex cover has size .

Code link (me) : https://pastebin.com/7J8B9fXx

Code link (mahmoudbadawy) : https://pastebin.com/54jZ8sGM

Time complexity : O(n).

Bonus task : Try to find an elegant proof that the answer for n < 6 doesn't exist for the first tree.

Solution959D - Mahmoud and Ehab and another array construction taskCommon things : Let's call a number "ok" if it could be inserted to array b, as a new element, without breaking any of the conditions (i.e it should be coprime with all the previously inserted elements). Let's call the maximum number that could be inserted in the worst case mx. For each integer from 2 to mx, we'll precompute its prime divisors with sieve.

First solution by meCreate an std::set that contains all the numbers from 2 to mx. That set has all the "ok" numbers and will be updated each time we insert a new element to array b. We'll insert the elements to array b greedily one by one. At index i, let cur be the minimum number in the set greater than or equal to ai i.e std::lower_bound(a[i]). If cur isn't equal to ai, the lexicographically greater condition is satisfied and we're no longer restricted to a, so, starting from index i + 1, we'll greedily choose cur to be the first (minimum) number in the set instead. We'll insert cur to b. Each time, we'll remove all the integers that aren't coprime with cur from the set. To do that, we'll loop over the multiples of its precomputed prime divisors and remove them from the set.

Code link (me) : https://pastebin.com/bg3Hi6r2

Second solution by KANLet used[i] indicate whether some prime is already a factor of one of elements in b (so we shouldn't use it). Each time we insert an element to b, we update used by iterating over its precomputed prime divisors and make them all used. We'll start inserting elements to b greedily one by one. To check if a number is "ok", we'll iterate over its precomputed prime divisors and check that all of them aren't used. While ai is "ok", we'll keep inserting it to b. We'll reach an integer that isn't "ok". In this case, we'll iterate naiively until we find an integer that is "ok" and insert it to b. The lexicographically greater condition is now satisfied and we can insert whatever we want (no restriction to a). Notice that starting from now, b will be sorted in increasing order. That's because if it's not, we can sort it and reach a better answer without breaking any of the conditions. The naiive solution is to loop starting from 2 until we find an "ok" integer for each i. However, as the array is sorted, we can loop starting from 2 the first time and then loop starting from bi - 1 + 1 and save a lot of loops that we're sure will fail!

Code link (me) : https://pastebin.com/Xh2QgqUf

Time complexity : O(mxlog(mx)). mx has an order of  because the nth prime is expected to be O(nlog(n)) and the number of primes less that n is expected to be .

959E - Mahmoud and Ehab and the xor-MSTFor convenience, let n be the label of the last node not the number of nodes (i.e n = ninput - 1).

Denote lsb(x) = x&( - x) as the value of the least significant bit set to 1 in x. The answer is , which means that node u is connected to node  for all 1 ≤ u ≤ n (node u is connected to node u without that bit).

Formal proofNow let's see how to calculate that quickly.

Math solutionLet f(x) be the number of integers y such that 1 ≤ y ≤ n and lsb(y) = x, then . f(i) > 0 if and only if i is a power of 2 so this sum is equivalent to . Basically, the first number y such that lsb(y) = x is x and then the period is 2 * x. Take 4 to see that. The integers y such that lsb(y) = 4 are {4, 12, 20, 28, etc.} Therefore,  for 1 ≤ x ≤ n and x is a power of 2.

Code link (me) : https://pastebin.com/dNuR9k0Y

DP solutionLet's see how the sequence of lsb(x) is constructed. We start with {1} and at the ith step, we copy the sequence and concatenate it to itself and add 2i in the middle.



Let . Let dp[i] = f(2i - 1).

You can see from the pattern above that dp[i] = 2 * dp[i - 1] + 2i - 1 for 1 < i (with the base case that dp[1] = 1). Let's find a recurrence for f(x). Denote msb(x) as the value of the most significant bit set to 1. The sum can be split into 2 parts : the sum from 1 to msb(x) and the sum from msb(x) + 1 to x. You can see that in the second sum, lsb(i) can never be equal to msb(x), so we can remove that bit safely without affecting the answer. Removing that bit is like xoring with msb(x) which makes the sum start at 1 and end at  which is . Therefore, . The first part can be calculated with the help of our dp because msb(x) is a power of 2 and the second part goes recursively. Basically, for each i such that the ith bit is set to 1, we add dp[i] + 2i to the answer.

Code link (me) : https://pastebin.com/wnhBZx2v

Time complexity : O(log(n)).

959F - Mahmoud and Ehab and yet another xor taskLet's solve a simpler version of the problem. Assume the queries only ask you to see whether the answer is 0 or positive instead of the exact answer. We can answer all the queries offline. We can keep a set containing all the possible xors of subsequences and update it for each prefix. Initially, the set contains only 0 (the xor of the empty subsequence). For each index i in the array, we can update the set by adding  to the set for all x in the set. The intuition behind it is that there's a subsequence with xor equal to x (as x is in the set) and if we add ai to it, its xor will be , so we should add it to the set. That's a slow solution to update the set, but we have some observations:-

If x is in the set and y is in the set,  must be in the set. To see that, let x be the xor of some elements and y be the xor of other elements.  must be the xor of the non-common elements (because the common elements will annihilate) so it must be in the set.If x is in the set and y isn't in the set,  can't be in the set. This could be proved by contradiction. Assume  is in the set, then, by the first observation,  must be in the set. This is equivalent to y which we said that it isn't in the set. Therefore,  isn't in the set.Basically, if ai is already in the set, we do nothing because updating the set would do nothing but extra operations according to the first observation, and if ai isn't in the set, we don't even waste a single operation without extending the set! That makes the total complexity O(n + maxAi) or O((n + maxAi)log(maxAi)) depending on implementation because each element is added to the set exactly once.

To solve our problem, let's see the naiive dynamic programming solution. Let dp[i][x] be the number of subsequences of the first i elements with xor x. . The intuition behind it is exactly the same as the intuition behind the set construction. Let's prove that dp[i][x] is equal for all x belonging to the set! Let's assume this holds true for i - 1 and see what happens in the transition to i. Notice that it holds true for i = 0. Let j be the value that dp[i - 1][x] is equal to for all x belonging to the set. If ai is in the set, and x is in the set,  is in the set (observation #1). Therefore, dp[i - 1][x] = j and  which makes dp[i][x] = 2 * j for all x in the set. Notice that the set doesn't change so dp[i][x] = 0 for all x that aren't in the set. If ai isn't in the set, we have 3 cases for x. If x is in the set,  isn't in the set. Therefore, dp[i][x] = j + 0 = j. If x is to be added to the set in this step,  is in the set. Therefore, dp[i][x] = 0 + j = j. Otherwise, dp[i][x] = 0. To summarize, we'll maintain the set. For each integer, if it's in the set, we'll just multiply j by 2. Otherwise, we'll update the set. We'll then answer all the queries for that prefix (saying 0 or j) depending on whether x is in the set.

Code link (me) : https://pastebin.com/Kfi0NWTi

Time complexity : O(n + maxAi) if you implement the "set" with a vector and an array.

Bonus task : Can you make this solution work online? Can you do that with maxAi < 230?

Solution

VK Cup 2018 Round 2 and Codeforces Round #472 Editorial

By cyand1317, 5 years ago, In EnglishLong time no see!

As VK Cup Round 2 and its two parallel rounds (Div. 1 and Div. 2) comes to a close, we're here to congratulate on all who did well on the contest and cheer for everyone who participated — the queue won't stop you!

Here are the detailed tutorials for the problems. Feel free to discuss in the comments!

Kudos to arsor for translating the tutorials into Russian!

957A - Tritonic IridescenceThe problem can be solved in different approaches. Here we describe one based on manually finding out all cases.

What causes the answer to be "Yes"? Of course, there cannot be adjacent segments that already have the same colour; but what else?

We can figure out that whenever two consecutive question marks appear, there are at least two ways to fill them.

But the samples lead us to ponder over cases with one single question mark: a question mark can be coloured in two different colours if it lies on the boundary of the canvas, or is between two adjacent segments of the same colour.

Putting it all together, we get a simple but correct solution.

There surely are dynamic programming solutions to this problem, and if you'd like a harder version, try this USACO problem. So to me seems like a notorious coincidence ._.

Model solutionAlternative solution (Errichto)(by cyand1317)

924A - Mystical MosaicNo row or column can be selected more than once, hence whenever a row r is selected in an operation, all cells in it uniquely determine the set of columns that need to be selected — let's call it Sr.

Let's assume a valid set of operations exists. Take out any two rows, i and j. If rows i and j are selected in the same operation, we can deduce that Si = Sj; if they're in different operations, we get . Therefore, if Si ≠ Sj and  hold for any pair of rows (i, j), no valid operation sequence can be found.

Otherwise (no pair violates the condition above), a valid sequence of operations can be constructed: group all rows with the same S's and carry out an operation with each group.

Thus, it's a necessary and sufficient condition for the answer to be "Yes", that for each pair of rows (i, j), either Si = Sj or  holds.

The overall complexity is O(n2m). It can be divided by the system's word size if you're a bitset enthusiast, and a lot more if hashes and hash tables release their full power.

Model solutionAlternative solution with DSU in O(nm alpha(n)) (skywalkert)Alternative solution in O(nm)(by cyand1317)

924B - Three-level LaserFirst of all, you can note that for fixed i and k setting j = i + 1 is always the best choice. Indeed, if X > Y, then  for positive B.

Then, let's fix i. Then j = i + 1, and what is the optimal k? We can define the energy loss as . As we need to minimize the loss, it's obvious that we should maximize Ek, so we should choose as large k as possible satisfying Ek - Ei ≤ U. This is a classic problem that can be solved with two pointers approach, this leads to O(n) solution, or with binary search approach, this leads to  solution. Both are acceptable.

Model solution(by KAN, prepared by fcspartakm)

924C - Riverside CurioDefine ti as the total number of marks (above or at or under the water level) on the i-th day. As ti = mi + 1 + di, minimizing  is equivalent to minimizing .

For the i-th day we would like to find the minimum value of ti.

Needless to say ti ≥ max{ti - 1, mi + 1} should hold.

On each day we can increase t by at most one, thus ti ≥ ti + 1 - 1, which is equivalent to the condition that ti ≥ tj - (j - i) holds for all j > i.

The first condition is straightforward — just go over from left to right and keep a record; but how to ensure that the second condition hold?

One of the approaches is going backwards. Go from right to left and keep a counter which, on each day, decreases by 1 and then is taken maximum with the ti currently at hand. This counter always records the minimum required ti value that satisfies the second condition. Assign this counter to ti along the way.

Based on such minimum decisions, raising any ti by any positive value does not allow other ti's to be reduced. Hence summing this value over all days provides us with an optimal answer in O(n) time.

Model solution(by cyand1317)

924D - Contact ATCStuck in tedious fractions produced by kinematic formulae? No, that's not the way to go. Forgetting about all physics, how does wind speed affect the time when a plane flies over the origin?

Consider a plane flying from left to right, passing through the origin. Initially it has speed vi - w and meets the origin at time t. As the wind speed goes from  - w to  + w, the plane's speed continually rises to vi + w, with t becoming smaller and smaller (this is true because w < |vi|). The similar holds for planes going from right to left, with the exception that t becomes greater and greater.

Then, how does wind speed affect the order in which a pair of planes pass the origin?

Imagine two planes, A and B. With wind speed  - w, they arrive at the origin at moments tA and tB, respectively. As the wind speed goes from  - w to  + w, tA moves smoothly and so does tB and suddenly... Uh! They become the same! That makes them a valid pair.

From this perspective we can conclude that for such a pair of planes A and B, if A arrives at the origin at moment tA and t'A with wind speed  - w and  + w, and B at tB and t'B respectively, they possibly meet at the origin iff (tA - tB)·(t'A - t'B) ≤ 0.

Oh, what's this? Inversion pairs, of course! Apply wind  - w and  + w to all the planes, find out the orders in which they arrive at the origin under the two winds, and count the pairs (A, B) where A goes before B in the first permutation, and after B in the second one. One detail to note is that in case of ties, pairs should be sorted by descending values of speed in the first pass and ascending in the second (the speeds cannot be the same since all planes are distinct). That leaves us only with a binary indexed tree to be implemented. The overall time complexity is .

Please note that it's recommended to use an integer pair to represent a fraction, since the difference between arrival times can be as little as 10 - 10 — though a floating point error tolerance of 5 × 10 - 12 passes all tests, its robustness is not so easy to control.

Model solution(by KAN, prepared by cyand1317)

924E - WardrobeThe first idea of the author's solution is to reverse the problem: change l to H - r and r to H - l, where H is the total height of the wardrobe. Now an important box is counted in the answer if and only if its top edge is within the segment [l, r]. We'll see later the profit of this operation.

Now, we'll build a wardrobe of arbitrary height using only a subset of the boxes, and choose the maximum possible answer. Why can we remove the constraint to use all boxes? We can always assume that we add all the boxes we don't take at the top of the boxes we take, and the answer won't decrease. So, we can do some kind of knapsack, where not taking a box means putting it on the top after considering all boxes.

What we don't know is how to compute the answer and in which order to consider the boxes in the knapsack. Ok, if we consider them in such an order that there is an optimal answer in which the boxes we "take" in the knapsack always come in this order, then computing the answer is easy: we can always assume that we put a new box on the top of already taken ones, and add 1 to the current answer if it is an important box and its top edge falls in the range [l, r].

Now we should find such an order. Note that in an optimal answer we can always arrange boxes in this order: some number of unimportant boxes, then some number of important boxes that don't increase the answer, then some number of important boxes that increase the answer, and after that a mix of important and unimportant boxes which don't count in the answer and that we consider as "not taken" in the knapsack. This means that we can first consider all unimportant boxes in the knapsack, and then all important ones. It's also easy to see that the order of unimportant boxes does not matter. However, it turns out that the order of important boxes matters.

To choose the order of important boxes, we can use an old, but good trick. Suppose two important boxes with heights ai and aj stand one on the other. Answer the question: "What is the condition such that if it is satisfied, then it is always better to put aj on the top of ai, and not vice versa?" Here we consider only the boxes that count in the answer and those under them, because other we simply "don't take" in the knapsack. It turns out that the condition is simple: aj ≤ ai, no matter do these boxes count in the answer or not. Here we used the fact that we inversed the problem, and the position of the top edge matters, not the bottom one. So, as we now know that it is always optimal to put the important boxes from largest to smallest (in the inversed problem), we can sort them in that order and perform the knapsack.

The complexity is . This can also be reduced to  where H is the height of the wardrobe, using a standard optimization for the knapsack.

Model solution(by KAN)

924F - Minimal Subset DifferenceLet f(x) be the minimal subset difference mentioned in the problem statement. The problem seems like a regular digit DP problem. However, it's a bit hard to reduce the number of DP states. Let's take a careful consideration.

For a given integer x, we can use knapsack DP to determine f(x). Denote the sum of digits of x as s(x). You can just calculate whether there is a subset such that the sum of the subset is a fixed number y, and then find the maximal y  which concludes f(x) = s(x) - 2y. By the way, this type of knapsack DP could be implemented by bitwise operation.

If we defined dp(len, sum, state) as the number of integers x such that the length of x is len, the digit sum is sum, and the knapsack DP array is state (an array only consisting 0 and 1, which could be represented as bit vector), the problem would be difficult to solve. For example, to represent x = 88888888899999999, a case of f(x) = 0, the length of state might be 73, which is a bit long vector. Although most of states satisfy dp(len, sum, state) = 0, there are still many states which might be used.

You may notice the order of digits is unnecessary for the knapsack DP. If we defined state as the number of appearance of digits 1, 2, ..., 9 (digit 0 is unnecessary), the number of states would be . Hence, we can apply knapsack DP for each state first and then calculate for digit DP.

Here are more details. Let's redefine dp(len, k, state) as the number of ways to arrange the lowest len digits of x such that f(x) = k and the other digits (higher than the lowest len digits) form the state (i. e. the number of appearance of digits 1, 2, ..., 9). We firstly search all the states such that the total number of appearance  ≤ 18 and f(x) = k, and then set dp(0, k, state) = 1. After searching, we calculate dp(len, k, new state) from dp(len - 1, k, state) > 0 by enumerating the len-th digit.

However, the number of dp(len, k, state) > 0 is still too large to calculate for digit DP. You should notice that in decimal representation it always has 0 ≤ f(x) ≤ 9 for any integer x. Furthermore, because of the distribution of digits, most of states are in cases of f(x) = 0, 1 (you can make a knapsack DP to prove). In addition, it is easy to show f(x) and s(x) always have the same parity, so we can apply inclusion-exclusion principle to solve the problem only in the cases of f(x) ≥ 2 and another counting problem with fixed parity of s(x).

The total time complexity in above is , where L ( = 18) is the maximal length of x, D ( = 9) is the maximal digit, and S ( ≈ 3·104) is the number of distinct states such that there exists dp(len, k, state) > 0 (0 ≤ len ≤ L, 2 ≤ k ≤ 9). However, it can hardly pass the tests with n = 5·104, because we have some fairly worse tests to maximize the times of dp access (e. g. l and r have a lot of 9 as digits and k = 1).

We could make a tradeoff between pretreatment and queries by several ways. For example, define dp(len, k, state, upp) as the similar but it memorizes that the len-th digit is less than upp. If we did that, the total time complexity would be , which is acceptable.

The aforementioned solution is not easy to code; you can use some advanced approach to get accepted, though. Here are bonuses for advanced solutions.

Bonus 1. Solve the problem in case of n = 5·105, 1 ≤ l ≤ r ≤ 1018 with the same limits of time and memory.

Bonus 2. Solve the problem in case of n = 105, 1 ≤ l ≤ r ≤ 10100 (answer in modulo some 32-bit integer) with the same limits of time and memory.

Model solution(by Claris and skywalkert)

My gratitude to the coordinators, problem authors, testers, and every participant. You made all this possible! Cheers \(^ ^)/

Codeforces Round #471 (Div. 2) Editorial

By GreenGrape, 5 years ago, translation, In English955A - Feed the catIt's optimal to buy buns either right after waking up or at 20:00 (if possible) because between the awakening and 20:00 cost doesn't change but cat's hunger does. There was one extra case when Andrew wakes up after 20:00 and has only one possible option of buying everything since he cannot turn back time.

Code: 36605296

955B - Not simply beatiful stringsSince order of letters in adorable strings doesn't matter, it doesn't matter in the initial string as well. Let d be the number of distinct letters in s. Consider the following cases one after another:

If |s| < 4 answer is «No» since lengths of adorable strings cannot be less than two;If d is more than 4 answer is also «No» since adorable strings contain two distinct letters;If d is equal to 4 answer is always «Yes» (we give two types of letters to string one and other two to string two);If d is equal to three answer is also «Yes» (based on the fact that length of s is no less than 4);If d is equal to two answer depends on whether there's a letter occuring only once (because that means that one of the strings will consist of letters of the same kind);If all letters are the same, answer is «No» (same as the previous case).Code: 36605336

955C - Sad powersLet's fix some power p. It's obvious that there are no more than  numbers x such that xp does not exceed 1018. At the same time, only for p = 2 this amoung is relatively huge; for all other p ≥ 3 the total amount of such numbers will be of the order of 106.

Let's then generate all of them and dispose of all perfect squares among them. Then answer to query (L, R) is equal to the amount of generated numbers between L and R plus some perfect squared in range. The first value can be calculated via two binary searches. The second one is . Note that due to precision issues the standard sqrt might produce incorrect values, so you can use additional binary searches instead.

Complexity: .

Code: 36605356

955D - ScissorsDenote lpos(x) — the minimum index in s that prefix of t of length x might start at, provided lpos(x) + x ≥ k (so this prefix can be enclosed in some k-substring of s as a suffix) or  - 1 if there are none.

Denote rpos(x) in the same manner  — the maximum index in s that suffix of t of length x might end at, under the same conditions (enclosing suffix in some k-substring of s as a prefix). It's clear that these array allow us to iterate over all possible prefix/suffix partitions of t and check their correctness.

Note that rpos is calculated as lpos on reversed strings. How do we obtain lpos? Let's calculate z-function of s with respect to t and say that z(i) is the maximum prefix of t starting at position i in s.

Which z(i) might influence lpos(x)? First of all, they must satisfy z(i) ≥ x. Second, as mentioned above, i + x ≥ k. This allows us to apply all updates naively and achieve O(n2).

To speed this up we will iterate over z in decreasing order and maintain viewed indexes in a set in such a way that at the moment we are up to calculate lpos(x) all i-s such that z(i) ≥ x will be in. Then lpos(x) will be equal to minimum j in the set satisfying j ≥ k - x. This allows us to reduce the complexity to .

Reverse both s and t and calculate rpos in the same way. Then the only thing left is to check whether for some x ≤ k values lpos(x) and rpos(m - x) can be combined to obtain the answer.

Code: 36605449

955E - IciclesFix some point T and launch the wave. Icicle at i will reach the floor in fT(i) = ai + |T - i| seconds. Krakozyabra will definitely stop at minimum icicle j such that fT(j) < j and wait for something to the left of it to fall. Note that some icicle to the right of j might also fall earlier than j itself. So the answer for this fixed T is max(min1 ≤ i < jfT(i), minj ≤ i ≤ nfT(i)). This approach gives us a O(n2) solution.

How to speed this up? Let's get rid of the absolute value. For i ≤ T absolute value is unfolded as fT(i) = ai + T - i and for i > T as fT(i) = ai - T + i.

Rewrite the inequality fT(i) < i according to the observations above. It's easy to see that for i ≤ T it is equal to T < 2·i - ai and for i > T — ai < T. Build some range max/min structure and find j assuming j < T, and if unsuccessfully — assuming j ≤ T with respect to the given inequalities. The only thing left is to carefully find minimums on suffix/prefix.

Complexity: .

Code: 36605502

955F - HeapsDenote heapk(u) as maximum depth of k-ary heap rooted at u, and dpk(u) as maximum depth of k-ary heap in the subtree of u (including u). Let vi — children of vertex u; sort them in order of descending heapk{vi}. Then heapk(u) = heapk(vk) + 1, and dpk(u) = max(heapk(u), maxj(dpk(vj))). So we can calculate dp for fixed k in  or in O(n), if we will use nth_element, so we can solve the problem in O(n2).

For simplicity, denote dpk(1) as pk. Let's suppose that k > 1. Note three facts:

pk ≤ logk(n);dpk(u) ≤ 2 when .heapk(u) ≥ heapk + 1(u).So we can solve the problem in . Let's solve task in O(n) when . For other k's let's go in descending order, and set the value of dp to 2 and push this value up to the root for each vertices, that have exactly k children.

Note, that the total number of vertices visited in pushes does not exceed n (Because if we arrive at vertex with dp = 2, it is useless to go up, because everything there has already been updated. Each vertex will be added exactly one time, so complexity of this part is O(n).

Let's use this idea to solve the problem in . For each  let's solve in O(n), and for  let's use the idea above. And when , dpk(u) does not exceed 3. Let f3(u) will be minimal k, such that heapk(u) is equal to 3. By definition, u will have at least k children, which are the heaps of depth 2, that is also vertices with at least k children. Let's sort v by number of their children; Then answer for u will be maximal k, such that children(vk) ≥ k. Let's precalculate it, and when let's go in descending order by k pushing up value 3 from each u with f3(u) = k. The total number of vertices visited in pushes does not exceed 2·n (At worst case, in each vertex will be pushed at first with value 2, and then with value 3). So we can solve the problem in , which is better but still not enough.

Let val(u, depth) — maximal k > 1, such that vertex u contain k-ary heap of depth depth (or  - 1, if there are no such vertex). This dp have  states; To recalculate val(u, depth) we need to sort val(vi, depth - 1) by descending order, and find maximal k, such that val(vk, depth - 1) ≥ k. So, with sort, complexity of this solution will be .

Let's go in descending order by k pushing up value x from each u with val(u, x) = k. The total number of vertices visited in pushes does not exceed n·logn because dpk(u) ≤ logk(n). So, the complexity of this solution wil be .

Code: 36605519

VK Cup 2018 Round 1 and CF Round #470 (div. 1 & 2) editorial

By majk, history, 5 years ago, In English948A - Protect SheepSuppose that there is a wolf and a sheep in adjacent cells. It is obvious that in this case, the answer "NO" — this particular wolf can always attack this sheep.

Otherwise, the answer is always "YES". The simplest way of protecting all sheep is to place a dog in every empty cell. Then no wolf can move and all sheep are safe and happy.

923A - Primal SportLet P(N) be the largest prime factor of N. Clearly, we can obtain N from any number in interval [N - P(N) + 1, N] by picking P(N) as the prime, and we cannot obtain N from any other number. By factorizing X2, we can find the range for X1. By factorizing all numbers from the range of X1, we can find intervals for X0. The answer is the minimum of their union. The solution works in , which is fast in practice.

Bonus: Solve it for Q queries of XK in .

923B - Producing SnowWe can directly simulate the process, but it takes  time, which is too slow. There are multiple approaches how to make this simulation faster. We present two of them.

In the first solution, instead of calculating the total volume of the snow melted, we first calculate two quantities: F[i] — the number of piles left after day i, and M[i] — the total volume of piles that disappear on day i. The answer will then be F[i] * T[i] + M[i].Calculate prefix sums of the temperatures. This way, when a snow pile is formed on day i, we can use binary search to determine on which day it will disappear completely. Denote this day by j and put j = N + 1 if the pile survives. We can note that on every day k between i and j - 1 inclusive, this pile will lose T[k] of its volume, which corresponds to increasing F[k] by one. Furthermore, we add the remaining volume to M[j].

To calculate all F[i]'s fast, we can again use prefix sums — adding 1 to interval can then be done by two additions.

The second solution can handle queries online. For each pile, we calculate how big it would be if it was created on the first day: .We maintain all existing piles in a multiset. When a day i starts, we add V'[i] into the multiset. Then we remove all piles with  — those are the piles that disappear on day i — and easily calculate the total volume of melted snow in them. All the piles left in the multiset contribute exactly .

As the multiset is sorted, and each pile is added and removed only once, the total complexity is .

923C - Perfect SecurityWe decrypt the message greedily, one number at a time. Note that  is a bijection on non-negative integers. For that reason, there is always a unique number from the key that lexicographically minimises the string. We can always pick and remove that number, output its xor with the current number from the encrypted text.

It remains to show how to do the above faster than . We build a trie on the numbers from the key, more precisely on their binary representation, starting from the most significant bit. To find the number Kj that minimises , one can simply search for Ai, bit by bit. That is, if the k-th most significant bit of Ai is 1, we try to follow the edge labelled 1, and 0 otherwise. If we always succeed in that, we have found Ai in the key multiset, and hence , which is clearly minimal. If at some bit, we do not succeed, we select the other branch (that is, if k-th bit of Ai is 1, but there is no such number in the key set, we pick 0 instead and continue. This solution uses  time, where W is the number of bits (here it is 30).

The same approach can be also implemented using multiset, which is probably faster to write, but has an extra  multiplicative factor, which may or may not fit into TL.

923D - Picking StringsFirst note that B can be always changed to C and vice versa: . Hence we can replace all C's with B's.

Furthermore, see that: .

The above implies the set of following rules:





We can translate these rules to the following:

the number of Bs can be increased by any non-negative even numberthe number of As before any B may change arbitrarilyThe only remaining thing is to determine what should happen to the number of trailing A's. There are three cases:

The number of B's is the same in the source and target  the number of trailing A's can decrease by any non-negative multiple of 3, as no application of the first rule occurs, and the second and third rule cannot affect trailing A's.There are some B's in the source and the number of B's increases  the number of trailing A's can decrease by any non-negative number. To decrease the number to k, just morph the k + 1-th A from the end to BB. To keep it the same, morph any B to AB and then to BBB to introduce extra B's as needed.There are no B's in the source, but some B's in the target  the number of trailing A's has to decrease by any positive integer.It is now easy to calculate prefix sums of the B and C occurrences, and calculate the number of trailing A's for every end position. The rest is just casework.

923E - Perpetual SubtractionWe can model this process as a Markov chain with N + 1 states with transition matrix



The task is to find R = AM·P. A naive solution using Matrix exponentiation is obviously too slow, as it uses  time. We need to improve upon it and we look for eigenvalue decomposition.

This is a triangular matrix, thus its eigenvalues are the elements on the main diagonal. Hence



We can show that the eigenvector corresponding to  is  (consult proof at the end).

Thus, we have 

To finalise the eigenvalue decomposition, we need to find the inverse of Q. It can be shown Q and Q - 1 are the same up to the sign (consult proof at the end): 

The advantage of eigendecomposition is that AM = Q·ΛM·Q - 1,  where the diagonal matrix Λ can be exponentiated in .

We can calculate the result as R = AM·P = Q·(ΛM·(Q - 1·P)) .

Performed naively, this runs in , which is still too slow. We obviously need to multiply with Q (and its inverse) faster.

Fortunately, both linear functions Q and Q - 1 are a convolution and we can compute the multiplication in  using FFT, which is a bit hinted by the modulus in which to compute the answer.

Proof of the eigenvectors

We show that  it holds



where the fifth equality can be proven by induction on i - k.

Proof of the inverse

Denote P = QQ - 1.

First, we show that the diagonal of the product only contains ones. This is easy, since the i-th row of Q has zeroes until i - 1-th column, i-th column of Q - 1 has zeroes starting from i + 1-th row, and Qi, i = Q - 1i, i = 1. Thus, Pi, i = 1. Next we show that the Pi, j = 0 for i ≠ j. When i > j, all the summands in the inner product are zero. It remains to show the claim for i < j.



Proof that Q and Q - 1 are convolutions

Put y = Q - 1x. We want to show that y can be computed by convolution. See that



hence y is a convolution of functions f and g up to some multiplicative factors.

The proof for Q is similar, we can just remove all the ( - 1)α terms.

923F - Public ServiceFor k ≥ 0, we call graph G a k-star, if we can remove k vertices to form a star, and we cannot remove k - 1 vertices to form a star. In this terminology, a 0-star is a star.

It should be rather obvious that if one of the graphs is a 0-star, then the answer is clearly No. This is because the minimum degree of a vertex in a tree is 1, and star has a vertex of degree N - 1, and the corresponding vertex in the merged graph would have degree at least N, which is clearly impossible.

Surprisingly, the answer is Yes in all other cases. We prove this by giving an explicit construction. There are three cases:

Assume that one of the graphs is 1-star. Without loss of generality let it be G. Denote v the vertex that can be removed to turn G into star, u its only neighbor, and w be the vertex of degree N - 2. In graph H, find any leaf and denote it w'. Let its only neighbour be u'. Furthermore, pick v' a vertex that is not adjacent to u' (such vertex always exists as H is not a star). Observe that mapping ,  and  does not introduce multiedges in the merged graph. Furthermore, all other edges in G are incident to w, but none of the unprocessed edges in H are incident to w'. We can thus map the remaining N - 3 vertices arbitrarily.

Mapping a 1-star G (in red), to arbitrary tree H (in blue). See that there are no multiedges between u, v, w, no multiedges from u, v, w to the rest of the graph (since u, v and w' have no neighbours there), and no multiedges in the rest of the graph (since  is a graph with zero edges).

N = 4 or N = 5: There are only five non-isomorphic trees on this many vertices. Two of them are 0-stars (for which the answer is No), two of them are 1-stars (that we handled in previous case). The only remaining graph is a path on five vertices. Two such graphs can always be merged together. For simplicity of implementation, we can simply try all 5! possible mappings.

All trees on 4 or 5 vertices.

Otherwise, we use induction. In G, find two leaves u and v such that d(u, v) ≥ 3 and  is not a star. This is always possible: either G is a 2-star, and then we can pick one of the neighbouring leaves of the vertex with highest degree and one other leaf, or we can pick any two leaves that are not adjacent to the same vertex. Do the same thing for H, finding u' and v'. Remove these pairs of vertices from the respective graphs and use induction to merge those smaller graphs. Now we can either map ,  or ,  — as only one of these mappings may introduce a multiedge.The above is relatively simple to implement in . To turn it into an  algorithm, we need to maintain a few additional information about the graph. Furthemore, note that a graph G is a k-star if and only if the maximum degree is |G| - k - 1.

The list vertices sorted by their degree, for instance using set of pairs. This is so that we can find the vertex with maximum degree easily, which is useful for testing k-starness.the set of vertices with a leaf neighbour, andthe set of leaves neighbouring a given vertex, so that we can find the leaves quicklyUsing the above, we can always find appropriate leaf and remove it in , which is sufficient.

Codeforces Round #469 editorial (+ bonuses!)

By vintage_Vlad_Makeev, history, 5 years ago, In EnglishBesides the editorial we prepared some challenges for you.

950A - Left-handers, Right-handers and AmbidextersIterate over size of the team. Now you know how many players should play with left hand, but are not left-handed (because there are no so much left-handed players). The same with right hand. Just check if sum of these values is not more than number of ambidexters.

BONUS (easy): Solve this problem in O(1) time.

BONUS (easy): Now you have many millipedes with n hands. Each millipede can either play with one hand or is ambidexter and can play with any hand. For each number of hand you know number of millipedes can play with it and number of ambidexters. Find out maximum number of team of millipedes in which there is equal amount of millipedes which play with some hand.

(Idea — MikeMirzayanov, developing — fcspartakm)

950B - Intercepted MessageLet's define  and  as sums of first  elements of  and  (, , , ).

 and  can be same file iff this three conditions are true:

 because we need to divide prefix into files. because we need to divide suffix into files. segments have same sum.It's easy to see that if two first conditions are true then the third are true too because  and because of this fact and condition from statement  answer is a number of non-empty prefixes with the same sum.

Time complexity is  if you use two pointers or  if you use some data structure.

BONUS (easy): You lost one block from second message and you interested in maximal possible number of files if you can insert this block anywhere in second message. In this case it graduated that .

(Idea — meshanya, developing — Zlobober, KAN)

949A - ZebrasSimple greedy works here. Let's go from left to right and assign each element to some subsequence. At each moment we have two types of already built subsequences: zebras ("0", "010", "01010", ...) and "almost zebras" ("01", "0101", "010101"). If next element of the string is '1' we should add it to some zebra making it "almost zebra". If there are no zebras at this moment it's impossible to divide string into zebra subsequences. If next element of the string is '0' we should add it so some "almost zebra" making it simple zebra. If there are no "almost zebra"'s now just create new zebra consisting of this '0'.

If there are no "almost zebra"'s at the end answer exists and built zebras satisfy all requirements otherwise there is no answer.

BONUS (easy): Find answer minimizing length of longest subsequence.

BONUS (hard): Find answer minimizing number of subsequences.

(Idea — Zlobober, developing — ch_egor)

949B - A Leapfrog in the ArrayIn odd position p value  will be set.

For even position p let's find out position from which value has arrived and iterate over such position until we will arrive to odd position for which we know answer.

At the moment of jumping to cell p there are  elements to the right of the position p. So there are  elements to the right of this position and jump to cell p was done from position . During each such jump length of jump decreases at least by 2 times, so there are no more than  jumps and solution works in .

(Idea and developng — Sender)

949C - Data Center MaintenanceFormally you are given a properly colored graph and you are asked to find out size of smallest non-empty subset such that after addition 1 modulo h to colors of vertices in this subset coloring will remain proper.

Let's build a directed graph with n vertices and edge from u to v iff u and v are connected by edge in original graph and . Now let's fix some vertex which color will be changed. It's clear that we should take into its set all vertices which are reachable from it. Now our problem is reduced to following problem: "Given directed graph find vertex with smallest number reachable from it vertices". It's just any vertex from smallest strongly connected component which is sink (strongly connected component such there is no strongly connected component reachable from it).

BONUS (medium): Given graph is not properly colored, but you don't have to minimize size of the set. Can you solve it?

BONUS ((NP?)-hard): Given graph is not properly colored, but you have to minimize size of the set.

(Idea — V--o_o--V, developer — Flyrise)

949D - CurfewLet's solve the problem in case when there is only one instructor (which moves from left to right and the only goal is to minimize number of bad rooms)

I claim, that the following greedy works:

Move through rooms from left to rightIf there are too many students inside room, send the excess students to the next roomIf there are not enough students, but it is possible to fulfill this room from rooms on the right (the sum  is at least b), then do it.If it's not possible, then send all students to the following room.If it is the last room, say that those students are hiding in it.This greedy can be implemented in  time: calculate the prefix sums on the initial ai, this way you can check if it is possible to move students from following rooms here fast.

To handle the removal students from following rooms you can maintain the current "debt" of students. When you first consider room you can repay the debt as much as you can and then check one of the cases above. Since the both left and right borders of segments are moving monotonously the debt will be "inherited" correctly.

Notice, that you can only consider "paths of different students never cross", that means if first student was initially in room i and moved to a, while the second student was in j and moved to b, then if i ≤ j than a ≤ b. Because otherwise you can swap students and nothing will change.

The proof of the greedy (you can possibly skip it).

Suppose there is a better answer, which completes the rooms a1, ..., ak, while the greedy solutions completes rooms b1, ..., bl, l < k.

We will assume that in optimal solution paths of students don't intersect, that all "excessive" students are hiding in last room and that all rooms in optimal answer are either full (b) or empty (0). Otherwise it's possible to change the "correct answer in such way, that number of good rooms will not decrease.

Let's i is smallest index when ai ≠ bi. Then ai > bi, because greedy solution would always fulfill the room ai if it would be possible (actually, greedy solution builts the lexmin solution).

But if ai > bi we can "patch" the supposed optimal solution and move all students which were sent to room bi to ai (we know it is possible by the greedy solution's answer).

This way we can increase the common prefix with any possible "best" answer hence contradiction.

Back to the problem with two instructors. Recall, that "paths of different students don't cross", hence there exists a "border", the number x from 0 to nb, where the first x students are going to the first instructor and all others to second.

One could have bruteforced that border and solved the both halfs of the array by the method above, but then the complexity will be n2·b which is too much. We need to search for the border more efficiently.

Let f(m) will be the answer for first instructor, when he is given m first students and g(m) is the answer for second instructor when he is given all students except first m ones.

It is easy to see, that f(m) in decreasing, while g(m) is increasing (both times it is not strict monotonicity). Indeed, the more students are given to instructor, than more opportunities he has (all excessive students can always hide, so it is not a problem).

We are searching for m where ans(m) = max(f(m), g(m)) is smallest possible.Let's introduce function z(m) = g(m) - f(m) — increasing (but still not strict).

Let's call m0 the smallest index, such that z(m0) ≥ 0. One can see, that a min(ans(m0 - 1), ans(m0)) is the final answer. Indeed, if one will try greater m's than m0, than the g(m) will be dominating in max, and hence ans(m0) is more optimal. Otherwise, if m < m0 - 1, then ans(m) is better.

Bonus (medium): Solve this problem in O(n) time.

Bonus (medium): Students became fat and can't hide under the bed! Can you solve it now?

(Idea — Sender, developer — cdkrot)

949E - Binary CardsThere are two observations required to solve this problem:

You don't have to take two cards with same number. If you took two cards with number x you can take card with number 2x and card with number x and answer will remain correct.If you took card with number x you don't have to take card with number  - x. You can take cards 2x and  - x instead.Consider all numbers. If there are no odd numbers you don't have to take 1 or  - 1 cards. Otherwise you have to take either 1 or  - 1. Try both possibilities and add value of taken card to all odd numbers. After this step all numbers are even, so you can just divide them by 2 and solve the same problem with divided number. After each step of this algorithm maximum possible absolute value of card is also divided by 2, so in worst case complexity will be , where C is a maximum absolute value of number. Solution of the equation is  so it's fast enough.

BONUS (medium-hard): n ≤ 1000, |ai| ≤ 1018.

BONUS (hard): n ≤ 105, |ai| ≤ 1018.

BONUS: What about ternary cards?

(Idea — Zlobober, developer — malcolm)

949F - AstronomyLet's shuffle lines randomly. Select some 4 points and find their intersection point. If it's not integer or is not in bounding box it's definitely not an answer. Otherwise let's check it. Iterate over points and check if there is another point on the line that going through answer and this point. To check it we need to build some structure that can check if some line is inside it. For example you can for each point sort other points by polar angle, or store polar angles in hash table (multiplying it by number of order C2 making different angles different). If there is no pair for some point let's stop checking it. This solution works in O(n3).

In fact no, it's O(n2).

I will write full formal proof soon, now I'll write just sketch of it.

Consider planar graph where vertices are all intersection points of some lines passing through two given points.Let's find expected number of lines checking.Divide vertices into 2 classes: heavy (with degree ) and light (with degree )Expected time of checking is sum of expected time checking light vertices and heavy verticesIt's quite easy to prove it for light vertices.To proof it for heavy vertices Szemerédi–Trotter theorem might be usefulBONUS (medium): It was a challenge to prepare tests for this problem. Which tests requires many points/lines checking?

BONUS: There are many solutions that works in this problem. I will be glad to see your approaches (correct or not, proved or not) in comments.

(Idea and developng — vintage_Vlad_Makeev)

Codeforces Round #468 and Technocup 2018 Final Round Analysis

By KAN, 5 years ago, translation, In English931A - Friends MeetingAt first understand the fact that friend should make their moves one be one and the friend who initially was left should move to the right and other friend should move to the left. Let len = |a - b|. Then the first friend will make cntA = len / 2 moves, and the second friend — cntB = len - len / 2 moves. So the answer is the sum of two arithmetic progressions cntA·(cntA + 1) / 2 and cntB·(cntB + 1) / 2.

The given constrains allowed to calculate this sums in linear time — simply iterate from 1 to cntA for the first sum and from 1 to cntB to the second.

944A - World CupInitially, we need to understand the following fact. Since the number of teams in each round is even, n should be a power of two.

We will solve the problem for the 0-indexing commands, so we decrease the given a and b on one.

For each round we will determine the number of the match, in which the teams with initial numbers a and b will play. The command a will play in the match number a / 2, and the command b will play in the match number b / 2.

If a / 2 = b / 2, then these teams will play in the same match, and we need to print the number of the current round as an answer. If the number of remaining teams equals to two — this will be the final match of the tournament.

If the match numbers not equal we consider the next round. In this case, the number of command a becomes a / 2 and the number of number b becomes b / 2. The number of teams which will go to the next round is n = n / 2. This process is always finite, because sooner or later will remain only 2 teams and in this round will be only one match — the final match of the tournament.

944B - Laboratory WorkThe average value of Anya measurements should be equal to the average value of Kirill's measurements, so the sum of all Anya measurements should be equal to the sum of all Kirill dimensions.

Let the minimum number in the Kirill's measurements is min and the maximum — max. Then, if (max - min) is less than or equal to one, Anya will not be able to write down any measurements that Kirill do not have, so all her measurements will coincide with his measurements.

There remains the case when (max - min) = 2. Each Anya measurement should be at least min and not more than max. We need to brute how many of minimal measurements equal to min Anya will write down from 0 to n. Then the numbers of measurements equal to (min + 1) and max can be uniquely determined.

Let sum is the necessary sum of all measurements, which is equal to the sum of all Kirill measurements, and cntMin is the current number of minimal measurements that Anya will write down. Then Anya needs to write remaining number of measurements such that their sum equals to leftSum = sum - cntMin cdotmin.

The minimum sum that Anya can get with the remaining measurements is minSum = (n - cntMin) cdot(min + 1), and the maximum is maxSum = (n - cntMin) cdotmax. Then, if leftSum < minSum or leftSum > maxSum, Anya can not take cntMin minimum values ​​and get the desired sum.

Otherwise, Anya should write the measurements equal to (min + 1) in the amount of (leftSum - minSum), and all remaining measurements will be equal to the max. After that, we need to update the answer with the number of coinciding values ​​of min, (min + 1) and max in Anya's and Kirill's measurements.

After we updated the answer, move to the next value cntMin.

944C - Peculiar apple-treeFirstly, let's formalize problem: we have tree with root in first inflorescence. Let's examine apples that can roll down to the base of tree in t-th moment of time. It is obvious this are apples initially situated in nodes at t distance from root.

Key idea of solution is that we can suppose that apples in nonroot nodes don't annihilate but roll down to the very root and annihilate in it. This assumption is correct because number of apples in root at the t-th moment depends only on parity of apples that got there at that moment.

Thus let's calculate cntt  — number of apples that will appear in root in root in t-th moment of time for each t. This can be performed by BFS or DFS.

Answer for this problem is sum of all cntt mod 2 (a mod b means calculating remainder a modulo b) for each t from 0 up to d, where d is maximal distance from root to node of tree.

944D - Game with StringIdea. Let's consider all possible c1 that will be first in t. Then, let's consider all possible numbers of second letter that Vasya will ask about — this will be d. If pair of letters (c1, c2) occurs only once at d distance, than if c2 opens second time, Vasya will be able to determine shift.

Solution. Let's loop through all letters at d distance from all c1 letters and for each symbol c2 we will calculate number of such letters. This can be done in O(cnt(c1)), where cnt(c1) is number of letters c1 in initial string. Now, if we fix such d after opening c1, that maximizes number of unique pairs(we will name it p) (c1, c2) at d distance, this will be optimal d, and conditional probability of victory in situation of fixed c1 equals p / cnt(c1).

Now we only need to sum up conditional probabilities for different c1. Probability of c1 equals cnt(c1) / n, thus answer is .

944E - Teodor is not a liar!Idea. The main idea is that set of point xi is bad(meaning that Sasha can't be sure, that Teodor hasn't lied, relying only on this information)  satisfies the following property: .

Solution. Firstly let's calculate cnt(xi) for each integer point in [1;m]. One way to do this is scanning line, which asymptotics is O(m + n). Other approach uses segment tree supporting segment addition queries. In this case asymptotics is O(n·log(m)) .

Now we only need to find longest sequence satisfying this property. Let's consider all possible xi in previous inequation(element that has peak cnt(xi)). Now the answer is length of longest nondecreasing sequence ending in xi +  length of longest nonincreasing sequence, starting in xi - 1. Both lengths can be found in O(1) if one precalculates this lengths for each 1 ≤ i ≤ m, using dynamic programming. Note that you should use O(m·log(m)) algorithm for calculating this dp, not O(m2), otherwise you will end up with TL verdict.

Total asymptotics of this solution is O(m·log(m)) for solution using scanning line or O((n + m)·log(m)) for solution using segment tree.

944F - Game with TokensNote that if black and white chip are placed in the beginning in points {x, y} with the same parity of x + y then black chip can't be on the manhattan distance 1 from white chip before white's move. So black chip can't block white chip and can't somehow affect the game. We can solve the problem independently for black chips with odd x + y, white chip with even x + y and for black chips with even x + y, white chip with odd x + y.

Note that we can solve the problem for black chips with even x + y if we move all of them on 1 upward and then solve the problem for odd x + y. Let's now consider only black chips with odd x + y.

Look at the image. If black chip is placed in black point then it can stop white chip placed in red, blue, yellow, green points if it will move up, down, left, right, respectively (i.e. white point can't make infinite number of move in these directions whatever moves it will make).

Note that one black chip can stop white chip only in one or zero directions. If there are four black chips that can stop white chip in different directions then black will win. Else white chip can move in some direction infinitely and white will win.

So, every black chip generates four angles of different types. If point {x, y} is contained in intersection of four angles of different types and x + y is even then we should count this point in answer.

Let's substitute every point {x, y} to point {x + y, x - y}. There are still four types of angles but now every coordinate of white chip must be even number. In particular, the first image will look like this:

Let's leave only points with even coordinates and divide every coordinate by two. Still every black chip generates four angles, white chip must be in intersection of four angles of different types but now there are no restrictions about parity of anything.

How to count points in intersection of four angles of different types effectively? Find for each type of angles and for each x-coordinate half-interval of y-coordinates such that every point in this half-interval will be in some angle of current type. If we can find these half-intervals then we can find for every x-coordinate length of intersections of four half-intervals and answer will be equal to sum of these lengths.

Let's consider angles of only one type because for other types we can do something symmetric. Let's these angles will have sides directed upward and rightward. Then for each x-coordinate half-interval is [Lx, ∞) where Lx is minimal y-coordinate of vertices of angles which aren't placed to the right from x. So we can sort all vertices by x and then write some easy scanline.

944G - Coins ExhibitionDenote obverse-up coin as 0 and reverse-up coin as 1. Then we are to compute the number of binary strings of length k such that n of the given segments have atleast one 0 and other m ones — atleast one 1.

Let dp[i][l0][l1] be the number of binary strings of length i such that the last zero is at position l0, the last one is at l1 and all restrictions are satisfied for all segments with right borders not exceeding i. The transitions then are straighforward: check all possible values for position i + 1 and relax l0 and l1 accordingly. Let the new values be l0' and l1'. Now consider all segments ending at i + 1. If there are such [l, r] among them demanding zero while l > l0' or demanding one while l > l1', this continuation doesn't suit. Otherwise add dp[i][l0][l1] to dp[i + 1][l0'][l1']. This works in O(k3 + n + m) if we precompute all segments ending in r for all r. Anyway, this is too slow.

The first thing to enhance is to notice that either l0 = i or l1 = i. Then we have to deal with dp0[i][l1] (implying l0 = i) and dp1[i][l0] (implying l1 = i). The transitions are the same, and the complexity becomes O(k2 + n + m). Still too slow :(

The further improvement is that all positions with no segments endings can be treated similarly since the transitions are equal. At the same time it doesn't matter whether the last zero is at l0 or l0 + 1 if there are no segments beginning at l0 + 1. Same applies to l1. Let's compress coordinates then, i.e. find all xi such that xi and xi + 1 are covered by different sets of segments.

Now it's time to slightly change the dp definition: let dp0[i][l1]be the number of binary strings of length xi such that the last digit is 0, the last 1 is somewhere between xl1 - 1 + 1 and xl1 and all restrictions are satisfied for all segments with endings not exceeding xi. dp1[i][l0] is denoted in a similar fashion.

Consider the possible transitions. Without loss of generality we'll account for transitions from dp0[i][l1] to some dp?[i + 1][?]. The goal is to somehow append a binary string of length (xi + 1 - xi) to the existing one. There are three major cases:

All additional digits are 0, then we jump to dp0[i + 1][l1] with coefficient 1 (there's only one way to construct a string of zeros).All additional digits are 1, then we jump to dp1[i + 1][i] with coefficient 1. Note that the last zero remains at xi.There are some 0 and some 1. Then the jump is to dp0[i + 1][i + 1] and dp1[i + 1][i + 1] with coefficients equal to 2xi + 1 - xi - 1 - 1 since only the last digit if fixed. This is possible iff xi + 1 - xi > 1.Moreover, we have to consider all segments ending at xi + 1 and discard those not satisfying the restrictions. This works in  (extra logarithm is for fast powers).

There's only one step left to a full solution. Note that in the dp above you can separate digit-adding from constraint-accounting transitions and treat them one after another. That means that you can first apply all transitions from  to  disregarding segments endings at xi + 1 and then null dp0[i + 1][l1], where l1 < l, where [l, xi] is an arbitrary segment applying 1-constraint and null dp1[i + 1][l0], where l0 < l, where [l, xi] is an arbitrary segment applying 0-constraint. Futhermore note that transitions with coeffitients not equal to 1 are applied only to  and  while values of  where j < i are either  or 0. That means we can store two arrays dp0[l1] and dp1[l0], implying i being equal to the current value. Now when jumping from i to i + 1 we have to relax  and , and null some prefix of dp0 and some prefix of dp1 depending on beginnins of segments ending at xi. The new values of  and  are easy to obtain via sum of elements in this arrays and xi + 1 - xi. With a properly chosen data structure the complexity becomes  with O(n + m) memory. This is now enough to get ac.

There's an alternative approach: you can just keep track of the first non-nulled element since it can only increase. This also helps maintain the current sum of values without using specific data structures. This works in  (including sort).

Thanks GreenGrape for translation!

Codeforces Round #467, Editorial

By niyaznigmatul, 5 years ago, translation, In English937A - OlympiadDrop all participants with zero points. Then the answer is simply the number of distinct points among the remaining participants.

Prepared by vintage_Vlad_Makeev

937B - Vile GrasshoppersThe first observation is that the optimal branch shouldn't be divisible by anything in range [2..p]. Let us decrease y until its minimal divisor (other than one) is greater than p.

Why does this approach work? Note that the the nearest prime less or equal to y is valid. At the same time the prime gap of numbers less than billion doesn't exceed 300 and we're gonna factorize no more than 300 numbers in total. Therefore the complexity is .

Prepared by GreenGrape

936A - Save Energy!There are repeated segments in the cooking process, that are between two consecutive moments, when Julia turns the stove on. Let's call such segment a period. Consider two cases:

If k ≤ d, when Julia comes, the stove is always off, that means period = d.In other case Julia comes to the kitchen p times between two turnings on, when the stove is still on, and does nothing. In this case p is a number such that p·d < k — the stove is on, (p + 1)·d ≥ k — the stove is off. Then the period is (p + 1)·d and p is equal to ⌈ k / d⌉ - 1. So period = ⌈ k / d⌉·d.Let's say the chicken consists of 2t independent parts. On the working stove two parts of the chicken are prepared per minute. If the stove is off, one part is prepared. Let's find the number of prepared parts during one period: cooking = 2k + (period - k) = k + period and we need num = ⌊ 2t / cooking⌋ whole periods. After that we still have carry = 2t - num·cooking parts left to cook.If carry > 2k, chicken will be prepared after carry - k minutes: k minutes the stove will be on and carry - 2k it will be off. Thus the answer is num·period + carry - kOtherwise carry parts become ready after carry / 2 minutes and answer is num·period + carry / 2.Prepared by dusja.ds

936B - Sleepy GameNote that the answer is sequence of adjacent vertices of even length such that the last vertex of this sequence has no outgoing edges.

Build state graph as follows:

State is pair (v, parity), where v is vertex of initial graph and parity is parity of count of vertices on path from s to v. For every edge uv of initial graph add edges  and  in state graph. So there exists path from (s, 1) to (v, parity) if and only if there exists path from s to v in initial graph of parity parity.

Lets find all reachable from (s, 1) states using BFS or DFS. If there is state (v, 0) among them such that v has no outgoing edges in initial graph, then Petya can win. He can move along vertices in path from (s, 1) to (v, 0) in state graph.

Otherwise we need to check if Petya can make 106 moves for drawing a tie. If there is a tie then the chip visited some vertex twice, because n < 106. Therefore it is sufficient to check if there is a cycle in initial graph reachable from s. In this case Petya can play as follows: move to any vertex of cycle and then move along the cycle as long as it requires to draw a tie.

Prepared by pashka and YakutovDmitriy

936C - Lock PuzzleThe answer is «NO» only in the case when multisets of letters in s and t differ. In all other cases there is a solution.

Let's construct the solution uses  operations. To do that, you need to «add» two symbols to current already built substring using five operations. You can do it, for example, using the following method (the underlined string is chosen as β):

...x...abc  cba......xcba......x  x......abcx......abc  cbax......cbax...y..  ..ycbax.....ycbax...  .....ycbaxIf we had abc as suffix, after these operations, we get ycbax, which is two symbols longer. Choosing x and y accordingly, we can maintain maintain the invariant, that the suffix of current string always contains monotone (increasing or decreasing) sequence. After we make this sequence have length n, the entire string is either a cyclic shift or a reversed cyclic shift of t. You can do cyclic shift by k in three operations: «shift n - k», «shift k», «shift n». This way, we get a  solution.

Prepared by dusja.ds and VArtem

936D - World of TankAt first arrange a pair of facts:

If there is a path which doesn't contain blowed cell you can easily convert it to path which does. So it's enough to check such paths to determine answer.Tank can accumulate shots when it moves without turns. In other words: consider tank makes 100 steps without turns and shots, so lets say that tank accumulate 100 steps. If t equals to 3 tank was able to make 33 shots on that part of path. Accumulating steps is the same as deferred shots. Tank gains steps and when it's necessary to make some shots we can choose position of shots on this straight part of path in such way that tank blows obstacles. But when the tank changes its row you should flush accumulated steps to minimum of t and old value because accumulated steps has sense only on hte straight line without shots because otherwise it may be impossible to choose correct positions for shots.The second step is solution with asymptotics O(n):

Using dynamic programming: dp[i][j] — maximal number of accumulated step if tank is in cell with coordinates (i, j) and -1 if it's impossible.

You should update dynamic's values from previous cell in the same row or cell in another row but in the same column.

Check that dp[i][j - 1] ≠  - 1 (otherwise tank can't be in the (i, j - 1) cell) after that update value by dp[i][j - 1] + 1 if there is no obstacle in cell (i, j) and by dp[i][j - 1] - t + 1 otherwise.

Before updating by cell in another row you should update both of them ((1, j) and (2, j) if rows numerated from 1) by cells in previous column and only after that you can update them be each other.

Store for each cell (i, j) was it updated from (3 - i, j) or (i, j - 1). Start from last column and iterate to the zero one to restore the path.

When you restore path you can easily calculate number of obstacles which should be blowed for each part of path without shots. So now you have to choose places for them.

Consider any part of the path from any turn to the next one. Let there are s obstacles, so all of them must be destroyed by the tank. Let the first cell of this path's part has coordinates (i, j) and dp[i][j] equal to k, so the first shot on this part can be not earlier than (i, j + t - k), the next one not earlier than (i, j + 2t - k) and so on. Place shots in that position and tank will correctly blow up all obstacles. It obviously follows from dynamic programming's definition.

Complexity: O(n).

The third step is prooving that tank can turn only to cells which are immediately after an obstacle (if obstacle is in cell with coordinates (i, j) then tank turns to cell (i, j + 1)).

Consider any path which is one of soloutions. Consider the first turn in this path which doesn't fit the constraint above. Then consider the nearest obstacle in the same row as row where tank will be after turn, but with smaller number of a column.

If tank turns to the cell which immediately after that obstacle then it can move along that row to current position, eliminates unnecessary turns, so the considered turn will be eliminated.Otherwise tank was in another row, so you can easily turn and do the same actions to eliminate such turn.Repeat this actions you transform any path to path which has only turns to cells immediately after obstacles.

Sort obstacles in order of increasing their column's number. So due to fact that tank can turn only in certain points it isn't necessary calculates DP for all 2·n cells. Now m1 + m2 cells enough. So calculate the same DP for cells which are immediatel after obstacles, strore for each point the point where it was updated from to restore path. Restore path and for each part without turns calculate number of obstacles to destroy and place shots.

Complexity O(m1 + m2).

Prepared by dusja.ds and burakov28

936E - IqeaUnable to parse markup [type=CF_TEX]

Prepared by budalnik

[Editorial] Codeforces Round #466 (Div. 2)

By ch_egor, 5 years ago, translation, In English940A - Points on the lineIt's clear that diameter of the multiset of points equals to difference of coordinates of point with maximum coordinate and point with minimum coordinate. So we can iterate over all possible pairs of maximum and minimum point and check number of remaining points in O(n). This solution works in O(n3).

Of course, there are faster solutions.

(Developing — vintage_Vlad_Makeev, ch_egor, V--o_o--V, demon1999)

940B - Our Tanya is Crying Out LoudIf k = 1, then answer is obvious, , otherwise we will greedily decrease number.

During each moment of time we should consider following three cases:

If n < k, we can only n - 1 decrease number by 1, paying A coins each time. It can be done in  using formula.If n > k and n is not divisible by k, we can only decrease number  times by 1 paying A coins each time. This case can be also handled in  using formula.If n is divisible by k, it's always optimal to make number equals  paying  coins. If  then optimality is obvious. Otherwise assume we didn't make decreasing to t  now, but did it on interval  from number . In this case we paid  coins. It equals  or , with is not more optimal then decreasing to  and decreasing to  after that.Each case should be handled at most  times, so complexity of the solution is .

(Developing — ch_egor)

940C - Phone NumbersConsider 2 cases:

If n < k we should simply add k - n minimum symbols from s.If n ≥ k we need to replace all symbols in the suffix of first k symbols of string consisting of largest symbols to smallest symbols and next symbol before this suffix replace with next symbol that exists in the string.Complexity of this solution is .

(Developing — ch_egor)

940D - Alena And The HeaterNotice, that constraints on  and  generates only sequences  that equals 00001, 00000, 11110, 11111.

00000 on positions  means that .00001 on positions  means that .11111 on positions  means that .11110 on positions  means that .After all we get some constraints for minimum and maximum possible values of  and . Since it's guaranteed that answer exists minimum possbile value of  and maximum possible value  will always be a correct answer. Pay attention that  и .

This solution works in .

(Developing — halin.george)

940E - CashbackAt first let's solve this problem with  complexity. It can be done using dynamic programming. Let  be minimum cost of splitting prefix with length i.,  where  is a cost of  maximums on interval . During finding these values we can iterate over j from i - 1 to 0, storing sum of  minimums in some structure like std::multiset.

The important observation for faster solution is that it's always optimal to take segments with lengths 1 or c. Suppose we took segment with length less than c, then its cost doesn't depend on the way, we split it and it's possible to take it using segments with length 1. Suppose we took segment with length , , then it's possible to split it to some segment with length c and split other elements to segments with length 1. Suppose we took a segment with length , then it's not worse to take it as two segments with length . In other cases it's also possible to split segment to segments with lengths 1 and  without loosing of optimality.

It's easy to find cost of segment with length 1, to find cost of segment with length c, it's possible to store elements in range  in some data structure which can find minimum value fast. It can be queue with minimum or std::multiset;

Complexity is  or  depending on structure used.

(Developing — Sehnsucht)

940F - Machine LearningAt first let's find out minimum length of array, such that answer for it is c. For it on this segment there should be a number that has one occurrence, some number that has two occurrences, etc. Length of this segment will be . That's why answer won't exceed  for any query.

Let's compress numbers in such a way that numbers from array and from queries will be in range from 1 to n + q. Obviously this modification won't change answer, but now elements won't exceed .

Suppose for interval  we know number  of occurrences of each number and number of occurrences of each number of occurrences . Then we can find Mex of this set in . Moreover it's easy to update arrays  and  for segments , ,  and  in O(1) time.

We will represent each query as tuple of integers  where t — is a number of change queries before this, and segment . It's easy to see that t can also be changed by one in  time. Because of  will replace  to  in following part of editorial.

Let  and let's sort queries by triples  and will answer queries in this order. Border  will be increased by  for each sqaure of size   sum of movements of right border is . For each query borders  and  are moved by not more than   sum of movements is .

Solution has time complexity .

(Developing — cdkrot, ch_egor)

[Editorial] Codeforces Round #465 (Div. 2)

By Kammola, history, 5 years ago, In EnglishHello Codeforces,

I hope you liked the problems! Below you can find the tutorials for all problems.

935A - Fafa and his CompanyLet's try all values of l from 1 to n - 1 and check whether the remaining people could be distributed equally over team leaders (that is, l divides n - l). The number of valid values of l is our answer. Complexity: O(n).

The problem is also equivalent to finding the number of ways to divide the n employees into equal teams where each team contains more than one employee. It can also be solved in  by finding the number of divisors of n.

935B - Fafa and the GatesFafa visits the gates when he stands on the line y = x. This happens only when he makes an equal number of up and right moves. Fafa will pass the gates if he is currently at a gate and will make a move similar to the last one.

So, we can iterate over the moves in order from left to right keeping track of the number of up and right moves till now, and increment the answer if the next move is similar to the current one and the number of up and right moves are equal.

Complexity: O(n).

935C - Fifa and FafaLet p be Fafa's position and c be the flat center. Obviously, the largest wifi circle we can draw will touch the point p and a point on the flat circle border q. The diameter of the circle will be the distance between p and q. To maximize the area of the wifi circle, we will choose q to be the furthest point on the border from p. This point lies on the line connecting p and c. The center of wifi circle w will be the midpoint of the line segment connecting p and q.

If the point p is outside the circle, then the wifi circle will be the flat circle (w = c). If the point p lies on the flat center (p = c), then there are infinite number of solutions as q can be any point on the flat circle border.

Complexity: O(1)

935D - Fafa and Ancient AlphabetLet Suff1(i) and Suff2(i) be the suffixes of S1 and S2 starting from index i, respectively. Also, let P(i) be the probability of Suff1(i) being lexicographically larger than Suff2(i). P(i) is equal to the probability that:

S1[i] is greater than S2[i], orS1[i] is equal to S2[i] and Suff1(i + 1) is lexicographically greater than Suff2(i + 1).More formally,

The answer to the problem is P(0).

Complexity: O(n)

935E - Fafa and Ancient MathematicsWe can represent the arithmetic expression as a binary tree where:

each leaf node is a digit.each non-leaf node is an operator and the left and right subtrees are the operands.To maximize the value of the sub-expression represented by a subtree rooted at v, we will either:

put a plus (+) operator at v, and maximize the values of left(v) and right(v) subtrees, orput a minus (-) operator at v, and maximize the value of left(v) subtree and minimize the value of right(v) subtree.We can solve this task using DP keeping in mind the number of remaining operators of each type. The DP state will be (v, rem + , rem - ). However, this state will not fit in time or memory limits. Since min(P, M) ≤ 100, we can drop the larger of the last two parameters and implicitly calculate it from the other parameter and the subtree size.

935F - Fafa and ArrayLet's have a look at the relation of each element ai with its adjacent elements. Without loss of generality, assume ai has two adjacent elements bi and ci where bi ≤ ci. One of the following cases will hold for ai, bi and ci:

ai ≥ bi and ai ≥ ci.ai ≥ bi and ai < ci.ai < bi and ai < ci.For a query 1 l r x:

if there exists an element ai, where , such that case 1 holds, then it is the best element on which we can apply the add operation because it will increment f(A) by 2·x.if case 1 doesn't exist, then there is at most one element for which case 3 holds (you can prove this by contradiction). Let's assume that this case holds for element ai, where . Then we will either:increment the element aj where , j ≠ i and j = argmink{ck - ak}. The value of f(A) will be incremented by 2·max(0, x - (ck - ak)).increment the element ai. The value of f(A) will be incremented by 2·max(0, x - (ci - ai)) - 2·min(bi - ai, x).if neither case 1 nor case 3 exists, then we can only the second option of the previous case.For a query 2 l r x: the only affected elements will be al - 1, al, ar, ar + 1.

We can use segment trees to answer queries in O(logn) time.

Complexity: 

Analysis of Codeforces Round #464

By KAN, 5 years ago, translation, In EnglishI'm sorry for the delay, it took some time for me to translate analysis to English.

939A - Love TriangleIt is enough to check if there is some i such that fffi = i, i. e. f[f[f[i]]] == i.

Problem author: KAN, preparation: KAN.

939B - Hamster FarmThe easies way to solve this problem is to find the minimum number of hamsters that can be left on the farm. If Dima byes boxes of the i-th type, there are  hamsters left on the farm. So we should find such a type x, that the value  is minimum among all x; The number of boxes to buy is then equal to .

Problem author: KAP, preparation: KAP.

939C - Convenient For EverybodyInitially, compute prefix sums: for each i the total number of people in timezones from the first to the i-th. Let's loop through all possible starting times of the competition. Each starting time gives as one or two segments of timezones, in which people will compete in the contest. We can easily compute the total number of participants in O(1) with the use of prefix sums. The total complexity is O(N).

Problem author: KAP, preparation: demon1999.

939D - Love RescueLet's build a graph with 26 vertices representing the 26 letters of English alphabet. When we buy a spell of form (c1, c2), add an edge between vertices c1 and c2. It's easy to see, that it is possible to change a letter a to a letter b if and only if there is a path between corresponding vertices in the graph. So our task is to add the minimum possible number of edges such that characters s1[i] and s2[i] are in one connected component for each i (here s1 and s2 are the given strings).

Let's now take an empty graph and add edges between vertices s1[i] and s2[i] for each i. These edges, as we already know, add constraints on the final graph (these letters should be in a single connected component in the final graph). Let's compute the number of connected components in the graph — let it be k. Let's consider one connected component, let its size be xi. Note that the spell we should buy should connect all these vertices in a single component. We can do this using at least xi - 1 edges, and the edges that suit us are any spanning tree of this component, that can be found using a dfs, or just connect one vertex of this component to all the others. So the total number of spells is . This is the answer to the problem.

Problem author: ZhNV, preparation: ZhNV.

939E - Maximize!Let's first prove some lemmas we will use in the solution. Let a0, ..., an be integers that are at the current moment in S, sorted in increasing order.

Lemma 1. Let the maximum element in optimal s be an. Then the rest of the elements in s form a prefix of a.

Proof: let it be wrong. Let's consider ai (i < n) — the first element of a, that is not in s. We know that in s some element aj is presented (i < j < n). Let's replace in s aj with ai, the average mean(s) will not increase, because ai ≤ aj, max(s) will not change, so max(s) - mean(s) will not decrease.

Lemma 2. Let  — the value that we want to maximize in case of s consisting of an, and a prefix of a of length i, i. e. elements a0, ..., ai - 1. A claim: , where sign(x) denotes the sign of x.

Proof: . Because the denominator is always  > 0, then .

Lemma 3. Let's denote for a fixed n . f(i) is non-decreasing for increasing i.

Proof: f(i + 1) = f(i) + ai - ai + 1(i + 2) + ai(i + 1) = f(i) - (i + 2)(ai + 1 - ai). ai + 1 - ai ≥ 0, because a is sorted. Then f(i + 1) - f(i) =  - (i + 2)(ai + 1 - ai) ≤ 0, i. e. f(i + 1) - f(i) ≤ 0, this means that f(i) does not decrease when i increases.

Let's solve the problem now. Let's keep the current answer for the query of type 2, let it be ans. When a new operation of type 1 comes, let's update it with the optimal value of max(s) - mean(s) in case max(s) = an, where an is the newly added element. To find this optimal value, let's do binary search for f(i) and find the minimum value of i, such that f(i) ≤ 0. Lemmas prove us that this prefix of length i is optimal for fixed max(s) = an. Now update the value of ans with the value . To compute the values  fast, we should maintain the array of prefix sums in a — one more element is added to this array each time a query of type 1 comes.

Problem author: SYury, preparation: kuzmichev_dima.

939F - CutletLet's use dynamic programming approach. Solve the following subproblem: let t be the seconds passed since the start of cooking, and t0 seconds among them the cutlet was preparing on the current side; what is the minimum number of flips needed to reach this state? This can be easily computed using answers for subproblems (t - 1, t0), (t - 1, t0 - 1), in which the cutlet lays on the same side, and (t - 1, t - 1 - t0) and (t - 1, t - t0), in which the cutlet lays on the other side. You should carefully consider the number of flips needed for each transition, and check if it is possible, according to Arkady's availability. The complexity of this solution is O(n2), which is not enough.

For full solution, it is enough to consider only moments that correspond to start of some segment Arkady's availability, because between these moments we can make at most two flips, otherwise the result is obviously not optimal. In such case to compute the answer for subproblem (t = li, t0) it is enough to compute minimum among answers for subproblems (t' = li - 1, t'0), where t' — the time of the start of the previous time segment — is fixed, and t'0 changes within several segments, the bounds of which depend on the number of flips between moments li - 1 and li seconds, and parameters li - 1, ri - 1, li, t0. For effective computing of minimums you can use the queue of minimums, because the bounds of the segments increase with the increase of t0. The total complexity is O(nk). You can also use other data structures for computing minimum, and the complexity of such solutions is .

Problem author: KAP, preparation: KAN.

ICM Technex 2018 and Codeforces Round #463 (Div. 1 + Div. 2, combined) Editorial

By TooDumbToWin, 5 years ago, In English932A - Palindromic SupersequenceLet reverse(s) be the reverse of string s. Now, s + reverse(s) will always have s as a subsequence (as first half) and it is a palindrome with size less than 104. So, it may be one of the possible solutions.

Code932B - Recursive QueriesIf we can show that for all integers n ≥ 10, we have n > f(n) then we can use bottom up dp for calculating g(n) for all the integers 1 ≤ n ≤ 106 in O(n). And as 1 ≤ g(n) ≤ 9, using partial sum arrays for each possible value of g(n), we can answer the queries in O(1).

For the proof that for all integers n ≥ 10, we have n > f(n), let us assume an integer n ≥ 10 of length k ≥ 2 which can be represented as nknk - 1... n2n1 where ni ≠ 0 for all 1 ≤ i ≤ k. We have assumed that ni ≠ 0, as even if any of the ni = 0, it will neither affect n nor f(n) in our proof given below.

Given, f(n) = nk × nk - 1 × ... × n2 × n1 and n = n1 + 10 × n2 + ... + 10k - 1 × nk.

As f(n) ≤ 9k - 1 × nk,

9k - 1 × nk < 10k - 1 × nk and

10k - 1 × nk ≤ n.

So, f(n) < n and hence we can use bottom up dp for calculating g(n) for all values of n.

Also, we can observe that the integer n reduces pretty much quickly to a single digit while calculating g(n), so we can directly calculate g(n) for all 1 ≤ n ≤ 106 without using dp as well.

Code932C - Permutation CycleFor f(i, j) = i and g(i) = k, there must exist a cycle of length k beginning from index i and ending at the same index i of permutation P. While generating a permutation P, we are constrained to generate cycles of length either A or B as g(i) for all 1 ≤ i ≤ N must be equal to either of them.

Let us try to generate a cycle of length k for indices i till i + k - 1 using only the integers i till i + k - 1, each once. If P[i] = i + k - 1 and P[j] = j - 1 for all i < j ≤ i + k - 1, we in turn get a cycle of length k for each of the indices i till i + k - 1, that is f(j, k) = j for all i ≤ j ≤ i + k - 1.

So, if there exists a solution (x, y) where x ≥ 0 and y ≥ 0, for Ax + By = N, we can in turn generate a permutation P satisfying our needs. Otherwise, no such permutation is possible.

So, now for any one of the solution (x, y), generate x cycles of length A, beginning from indices 1, A + 1, A * 2 + 1 ... A * (x - 1) + 1 and then beginning from indices A * x + 1, A * x + 1 + B, ... A * x + 1 + B * (y - 1), generate y cycles of length B.

Code932D - TreeThe main idea is that we will use binary lifting. Twice. Let's consider the following O(Q × N) algorithm — for every vertex u (when inserted) find the closest vertex v above it with w[v]  ≥  w[u]. Lets have an array nxt[], such that nxt[u]  =  v. Then the query will be done by simply jumping to the vertex in nxt[], until our sum becomes larger than X. Obviously this is O(Q × Depth) = O(Q × N).

To speed it up, we will have 2 binary liftings. The first one will be for finding the nxt[] and the second one will be for answering the queries. For the first one we will store the 2i-th parent and the maximum weight on the path and for the second one, we will store the 2i-th nxt[] vertex and the sum of the weights on the path. Well that's all and in such a way you can achieve .

Thanks to radoslav11 for nice and short editorial in comments.

Code932E - Team WorkThe required sum can be expressed as .



Differentiating the above equation and multiplying by x, we get



Differentiating and multiplying by x again, we get



Repeating the process (multiplying by x and differentiating) k times, and replacing x = 1, we get the desired sum.

This can be done using dynamic programming.

Consider dp[a][b][c] to be the value of the function xb(1 + x)c after performing the differentiation and multiplying by x, a times at x = 1. So, our final answer will be dp[k][0][n].

 after 1 operation, the above function becomes:

 or 

So, dp[a][b][c] = b * dp[a - 1][b][c] + c * dp[a - 1][b + 1][c - 1]

Take care of special cases when a = 0 or b = 0.

The above dp seems to be 3 dimensional but actually has O(k2) states since b + c is constant reducing one dimension.

Code932F - Escape Through LeafThe problem can be solved by dynamic programming. Let dp[i] be the minimum cost to reach a leaf from ith node. Then,  where j ≠ i. This is equivalent to finding the minimum y at x = a[i] among lines y = b[j] * x + dp[j]. Thus, convex hull trick of dp optimization can be used to find the minimum value. Once the value is calculated for a node, a line with slope b[i] and y-intercept dp[i] is added to the hull.

However,at all times, we need to maintain a lower convex hull of only the nodes in the current subtree. The trick of merging small to large can be used here. While we are at a node i, we form a convex hull for the subtree rooted at each child. The convex hulls of the light children can then be merged into the convex hull of the heavy child. Once the convex hull for the entire subtree is formed, a query for the minimum value at x-coordinate a[i] in the lower hull gives the value of dp[i].

The merging of small to large has time complexity of O(nlogn) while the addition of a line into the hull requires time O(logn).

Complexity: O(nlog2n)

Code932G - Palindrome PartitionLet n be the length of the string s. Consider the string t = s[0]s[n - 1]s[1]s[n - 2]s[2]s[n - 3]...s[n / 2 - 1]s[n / 2]. The problem can be reduced to finding the number of ways to partition string t into palindromic substrings of even length.

Proof: Let k be the total number of partitions. Let pi = pk - i + 1 = x1x2x3...xm where m denotes length of pi and xj denotes jth character of pi. The part of string t corresponding to these two partitions is x1xmx2xm - 1...xm - 1x2xmx1 which is an even length palindrome. Similarly, the converse is also true.

Dynamic programming can be used to solve the problem. Let dp[i] be the number of ways to partition t[1...i] into even length palindromes. Then,  where t[j + 1...i] is an even length palindrome. Of course for odd i, dp[i] = 0.

As discussed in thisblog, we can use an eertree to implement the solution. On the other hand, we can avoid the use of any suffix structure by following the algorithm described in thispaper.

Complexity: O(|s|log|s|)

Code 1Code 2

Codeforces Round #462 Editorial

By Tommyr7, history, 5 years ago, In EnglishHi, all!

This is not Tommyr7, but the impostor behind the round again (guess who I am? :P). The statements are written by me. Thank you, everyone, and hope you've all enjoyed the round!

Any feedback on problems and tutorials are welcome — we look forward to doing even better in the future!

Here are some of the detailed tutorials!

Tutorials934A - A Compatible PairAuthor quailty / Preparation quailty / Tutorial quailty

Tutorial934A - A Compatible PairWe can do as what we are supposed to do — hide one of the Tommy's lantern, and then take one non-hidden lantern from Tommy and one lantern from Banban so that the product of their brightness is maximized and the minimum between all cases becomes our answer. This is a straightforward O(n2m) solution. Also, there are many other ways to solve the problem but needs overall consideration.

By the way, there were 10 pretests at first where most of contestants failed on the last one. However, considering not to make the judger running with heavy loads, I took away 3 pretests and the pretest 10 was taken by mistake. I must apologize for the extremely weak pretests that make tons of hacks now. But it looks not so bad from the result...

Solution (quailty)934B - A Prosperous LotAuthor Tommyr7 / Preparation cyand1317 / Tutorial cyand1317

Tutorial934B - A Prosperous LotWhat's the maximum number of loops in an integer no greater than 1018? Since 8 is the only digit with two loops, we tend to use as many eights as possible. It can be seen that the answer is 36, achieved by 888 888 888 888 888 888. Thus if k > 36, the answer does not exist under the constraints.

There are tons of approaches to the following part. Share yours in the comments!

The author considers 8 and 9 as lucky numbers and uses only 8 and 9 to construct a valid answer. In particular, the output consists of  eight(s) and  nine(s).

Bonus. Solve the problem with the shortest code! The tester's Python solution is 51 bytes including a line break, can you beat them? ;)

Solution (Tommyr7)933A - A Twisty MovementAuthor visitWorld / Preparation visitWorld / Tutorial visitWorld

Tutorial933A - A Twisty MovementSince 1 ≤ ai ≤ 2, it's equivalent to find a longest subsequence like 1 * 2 * 1 * 2 * . By an easy dynamic programming we can find it in O(n) or O(n2) time. You can see O(n2) solution in the model solution below. Here we introduce an O(n) approach: Since the subsequence can be split into 4 parts (11...22...11...22...) , we can set dp[i][j](i = 1...n, j = 0..3) be the longest subsequence of a[1...i] with first j parts.

Solution (visitWorld)933B - A Determined CleanupAuthor Tommyr7 / Preparation cyand1317 / Tutorial cyand1317

Tutorial933B - A Determined CleanupFor simplicity's sake, we present a rather intuitive approach rather than a rigorous proof (can be obtained by induction).

For a given polynomial f(x), what's its remainder taken modulo (x + k)?

Let f(x) = q(x)·(x + k) + p. Let

Simulating the process of polynomial long division f(x) divided by (x + k), we get

Try it yourself! A simple pattern emerges from the results. Let's take a closer look!

p = a0 + ( - k)·a1 + ... + ( - k)d·adAnd there's another constraint: 0 ≤ ai < k.

Base negative k, that's it! The coefficients a0, a1, ..., ad is the base  - k representation of p. It surely exists, and is unique! We can also deduce that , which is why there is no constraint on the output d.

If you aren't familiar with negative bases, please refer to Wikipedia. But that doesn't matter! You may as well come up with an algorithm for converting to negative bases on your own. For an example, refer to the “Calculation” section in the aforementioned page.

Solution (Tommyr7)933C - A Colourful ProspectAuthor quailty / Preparation quailty / Tutorial quailty

Tutorial933C - A Colourful ProspectIt seems the problem can be solved with case analysis at first sight. Okay let's try to do so...

For n = 1, it's trivial and the answer is, of course, 2.

For n = 2, there are two cases:

If the two circles are intersect, the answer is 4;Otherwise, the answer is 3.For n = 3... well I think it's really a tough job, so think about general case will probably make our lives better.

The main solution is based on Euler's formula for planar graph. This formula tells us that if we denote the number of vertices in a connected graph by v, the number of edges by e and the number of faces (or regions) by f, we have f = e - v + 2. Since the circles can form several components, denoted the number of which by c, the formula for general planar graph should be f = e - v + c + 1.

So what we need to do is to calculate v, e, and c. It's easy to see that v is the number of unique intersection between circles. As for e, we can calculate the number of edges on each circle, which is equal to the unique intersection on each circle. The only special case is a single circle, and we can consider it as a graph without vertices and edges but forms one component, or a vertex with an edge to itself. Anyway it doesn't matter when v = e. The last one is c, which can be obtained easily with the help of dsu or dfs/bfs.

The total complexity is , but why I leave this special case as a problem instead of a general case? Reread the first sentence of this tutorial and you will get the answer :)

Here I want to show you the test #113, which is made by hands.

Guess how many regions in this graph?

Bonus. Construct three circles within the given constraints that share one common intersection with at least one non-integral coordinate.

And also, unfortunately, this problem coincides with this problem and I am really sorry for this issue.

Solution (quailty)Solution (cyand1317)933D - A Creative CutoutAuthor skywalkert / Preparation skywalkert / Tutorial skywalkert

Tutorial933D - A Creative CutoutFor the sake of explanation, let's use  to represent the binomial coefficient  and construct a coordinate system such that each coordinate axis parallels to one of the lattice edges, the origin is the center of concentric circles and each unit of length in this system is as long as the length of a lattice edge.

For f(n), we could figure out the contribution of each lattice point (x, y) is

Defining L as x2 + y2, we could conclude for the answer the contribution of each lattice point (x, y) is

which is a small-degree polynomial of L. Tips: prove  with mathematical induction or others.By using , we could form the answer as

where  is the coefficient calculated from the original polynomial.The remaining part to solve this problem is just to enumerate all the possible integers x, q and then calculate ,  in constant time. The total complexity is .

By the way, the standard solution has hardcoded some closed forms to calculate the partial sum of small powers fast, but you can precalculate  and then enumerate x.

Please be careful with 64-bit integer overflow, for example, 1012·109 ≥ 264. Although there is a pretest in case of m = 232 to reject brute force and some solutions with obvious overflow, it is highly probable to fail in the case of large input such as m = 1012. The probability of failure is increasing when the number increases. Take care.

Bonus. Solve the problem with 1 ≤ m ≤ 1018.

Solution (skywalkert)Solution (demon1999)933E - A Preponderant ReunionAuthor skywalkert / Preparation skywalkert / Tutorial skywalkert

Tutorial933E - A Preponderant ReunionThe author was inspired by 100705B1 - Rasta-making and then made this problem.

Noticing that there are no two consecutive positive integers after the game ends, the final sequence can be divided into some intervals which consist only zero elements such that the gap between every two adjacent intervals is at most one element (may positive).

Let's try to solve a general version of this problem first. In this version, we don't need to decrease two consecutive positive integers by their minimum. We can decrease any two consecutive integers by 1 many times (even if integers are negative) and our task is to eliminate all two consecutive positive integers such that the cost as small as possible.

We can prove by contradiction or adjustment that there are no negative elements in the best solution for the general version (because the original elements are non-negative). Furthermore, the cost of the best solution for the general version is less or equal to that of the best solution for the original version.

Let's consider the cost for the general version to make such an interval [l, r] (i. e. pl, pl + 1, ..., pr) become all non-positive (1 ≤ l ≤ r ≤ n). Before concluding the formula, you may assume p0 = pn + 1 = 0.

Let cl = pl,  ci = max(pi - ci - 1, 0) (i = l + 1, l + 2, ..., r). We can construct a series of operations to make them become non-positive such that the cost can be represented as . Let's call the cost of such an interval [l, r] as f(l, r). Similarly, we know the actual minimal cost is less or equal to f(l, r).

If the length of an interval [l, r] is greater than 2, there is an observation that

which implies any interval whose length is greater than 2 can be replaced by the cases of length 1 and 2.We can easily prove that f(l, r) is the actual minimal cost in the cases of length 1 and 2. In addition, if we get any of the best solutions for the general version, we can construct a series of operations which is valid both in the general version and the original version. So we can conclude that the cost of the best solution for the general version is greater or equal to that for the original version. With one conclusion we mentioned above, we know that the minimal costs for the original version and the general version are equivalent.

Denote dp(i) as the minimum cost the first i elements have used if the i-th element is going to be the right endpoint of such an interval. It's easy to compute dp(n) in .

After picking up all the intervals for the best solution, construction can be implemented by greedy. For example, utilize the descensions at the inner of intervals first, and then make use of the descensions at the edge of intervals.

Please note that there may be at most one element that belongs to no interval at the head or the tail of the final sequence. Also, the descensions should operate on positive integers.

Solution (skywalkert)Thank you everyone!

Happy Valentine's Day and happy Lunar New Year!

Разбор Codeforces Round #461 (Div. 2)

By GreenGrape, 5 years ago, translation, In EnglishNote that the number of hacks is palindromic!

922A - Cloning ToysConsider a few cases:

If y = 0, the answer is always «No».If y = 1, then the answer «Yes» is possible only if x = 0; if x > 0, the answer is «No».We can observe that the original was cloned y - 1 times to produce the requested amount of originals, then the additional copies were created by cloning the copies emerged from cloning the original. As every cloning of a copy results in additional two, we need to check whether (x - y + 1) is divisible by 2. We also need to take care of the case when (x - y + 1) is less than zero — in this case, the answer is also «NO».

Time complexity: O(1).

Code: 35036267

922B - Magic ForestConsider some triple (a, b, c) for which  holds. Due to xor invertibility, we can see that . So, we only need to iterate through two of three possible sides of the xorangle as the third can be deduced uniquely.

Time complexity: O(n2)

One could also apply some constant optimizations (and put some pragmas) get O(n3) solution with small constant accepted.

Code: 35036334Code (bless pragmas): 35036420

922C - Cave PaintingConsider the way remainders are obtained.

Remainder k - 1 can be obtained only when n is taken modulo k.Remainder k - 2 can either be obtained when taken modulo k - 1 or k. Since the remainder modulo k is already fixed, the only opportunity left is k - 1.Proceeding this way, we come to a conclusion that if answer exists, then   = i - 1 holds.This condition is equal to (n + 1) mod i = 0, i. e. (n + 1) should be divisible by all numbers between 1 and k. In other words, (n + 1) must be divisible by their LCM. Following the exponential growth of LCM, we claim that when k is huge enough, the answer won't exists (more precisely at k ≥ 43). And for small k we can solve the task naively.

Complexity: .

Code: 35036537

922D - Robot Vacuum CleanerDenote  as the noise function. We are gonna sort the string set in the following way: for each pair (a, b) we will put a earlier if . The claim is that the final concatenation will be optimal.

Let A be the number of subsequences sh in a, B — in b. Then , . A and B are reduced, and the comparator turns into sa·hb > sb·ha. This is almost equivalent to  (except the degenerate case when the string consists of s only), meaning that the sort is transitive.

Now suppose that this is all false and in the optimal concatenation for some pair of strings (a, b) the aforementioned statement doesn't hold. Then it can be easily shown that you can change their positions and the answer will only get better.

Time complexity: .

Code: 35053688

922E - BirdsThe problem can be solved by utilizing dynamic programming.

Let us denote by  the maximum possible remaining amount mana for the state (n, k), where n stands for the number of nests passed by and k stands for the number of birds summoned.

The base is  as we have passed by no nests, have summoned no birds and have W mana at our disposal in the beginning. Let us also initialize all other states with ∞.

The transitions are as follows: consider us having walked to the next nest and summoned k additional birds from there, therefore proceeding from the state (i - 1, j - k) to (i, j) (of course, it is reasonable to require that the answer for (i - 1, j - k) is not ∞). After we have proceeded, X units of mana would be replenished (taking summoned birds into consideration, the amount of mana at the moment is bounded above by W + (j - k)·B). The summoning would cost us  mana. If after the replenishing and the summoning the remaining amount of mana is nonnegative, we update the answer for the state (i, j):

The answer is the maximal k among reachable states (those not equal to ∞).

Time complexity: . Note that the constant in the square is no more than .

Code (backward dp): 35036591Code (forward dp): 35036674

922F - DivisibilityLet the sought pairs be the edges in a graph with n vertices. Then the problem is reduced to finding such a vertex subset that the induced graph contains exactly k edges.

Let e(n) be the number of edges in the graph on {1, 2, ..., n} and d(n) be the number of divisors of n (strictly less than n).

We claim that the answer always exists if k ≤ e(n) (otherwise it's obviously NO). Let's enlighten it a bit.

Let's find the minimum possible m such that e(m) ≥ k and try to paraphrase the problem: we have to throw away some vertices from the graph on m vertices to leave exactly k edges. Note that the degree of vertex x is equal to : hence the most interesting numbers for us are primes strictly larger than  since their degree is equal to 1.

Now it's time to expose the most important fact of the day: we claim that . At the same time the number of primes greater than , is about . Quite intuitive that asymptotically it's almost enough to throw only them away (there are only 16 possible counters and they all appear with m ≤ 120 which could be solved manually). This observation is sufficient to get AC.

You could've chosen the parallel way and note that vertices greater than  — do not share edges, therefore they can be thrown away independently (adding the statement from the previous paragraph, greedy approach will do).

You could've even written recursive bruteforce :D Summarizing the aforementioned, it works well.

Time complexity: .

Note that the solutions might not fully match the editorial, though the ideas are still the same.

Code (GreenGrape): 35055945, 35055961Code (KAN): 35055995Code (xen): 35055977

Codeforces Round #460 (Div. 2) Editorial

By jinlifu1999, history, 5 years ago, In English919A - SupermarketWe can use greedy algorithm.

Obviously, if you can pay the least money for per kilo, you can pay the least money for m kilos. So you can find the minimum of ai/bi, we say it is x. Then m⋅x is the final answer.

Time complexity: O(n).

Code (C++ version)

919B - Perfect NumberLet's use brute force the find the answer.

You may find the answer is not too large (i.e. not bigger than 2⋅107), then you can find it in the given time limit.

You can check every possible answer from 1 (or from 19), until we find the k-th perfect integer.

That's all what we need to do. :P

Time complexity: O(answer). :P

Bonus1: Could you please come up with a faster brute force algorithm which doesn't need to check too many possible answers?

Bonus2: Can you solve the problem with a bigger k (i.e. k≤1018 or even bigger)?

Code (C++ version)

Code (Python version)

919C - Seat ArrangementsWe can find out how many consecutive empty positions in every row and column separately and add them together to form the final answer.

If the length of consecutive empty positions is no smaller than k, we assume that it is len. Then we can add len−k+1 to the final answer.

But, be careful. When k=1, the algorithm shown above is completely wrong. (Why?) So we need to deal with that situation separately. (I guess there will be lots of hacks :P)

Time complexity: O(nm).

Code (C++ version)

Code (Python version)

919D - SubstringIt is obvious that we can use dynamic programming algorithm to solve this stupid problem. :P

We can make an array f[i][j] to respect when you are at the point i, then how many letters j you can get. Note that i is ranging from 1 to n and j is from 1 to 26.

Then, you can do this dynamic programming algorithm by topological sorting. Specifically, you can use deg[i] to show how many edges that end at point i. First put all points i which satisfy deg[i]=0 into a queue. When the queue is not empty, do the following steps repeatedly.

Take one point from the front of the queue. We say it is i.Iterate all edges which begin at the point i. We say the endpoint of the edge is k. Then we update f[k][⋅] using f[i][⋅]. Finally we make deg[k] minus by 1. If deg[k]=0, then we add the point k into the queue.Make a variable cnt plus by 1.When there is no cycle in the graph, the queue will be empty with cnt=n. Then the answer is the maximum number among f[i][j]. If there are cycles in the graph, then cnt cannot be n. Thus the answer can be arbitrarily large. In that situation, we should output -1.

Time complexity: O(m⋅alpha), where alpha is the size of the alphabet (i.e. alpha=26).

Memory complexity: O(n⋅alpha).

Code (C++ version)

919E - Congruence EquationTrying all integers from 1 to x is too slow to solve this problem. So we need to find out some features of that given equation.

Because we have ap−1≡1(modp) when p is a prime, it is obvious that azmodp falls into a loop and the looping section is p−1. Also, zmodp has a looping section p. We can try to list a chart to show what n⋅an is with some specific i,j. (In the chart shown below, n is equal to i⋅(p−1)+j)



Proof for the chart shown above: For a certain i,j, we can see thatn⋅anmodp=((i⋅(p−1)+j)modp)⋅a(i⋅(p−1)+j)mod(p−1)=(j−i)⋅ajmodpAnd it's not hard for us to prove that n⋅anmodp has a looping section p(p−1). So we don't need to list i≥p.

Therefore, we can enumerate j from 1 to p−1 and calculate b⋅a−j. Let's say the result is y, then we have j−i≡y(modp) (You can refer to the chart shown above to see if it is). So for a certain j, the possible i can only be (j−y),p+(j−y),…,p⋅t+(j−y). Then we can calculate how many possible answers n in this situation (i.e. decide the minimum and maximum possible t using the given lower bound 1 and upper bound x). Finally we add them together and get the answer.

Time complexity: O(plogp) or O(p) depending on how you calculate y=b⋅a−j.

By the way, you can also try Chinese Reminder Theorem to solve this problem.

Code (C++ version)

919F - A Game With NumbersFirst we should notice that the useful number of states isn't something like (85)2, because the order of the numbers in each player's hand does not matter. Therefore, the useful states of each player is (5+8−18). Then the useful states is estimated as (5+8−18)2, which is 245025.

Then we can abstract those states as nodes, then link those nodes with directed edges which shows the transformation between two states (i.e. one can make one step to the other). Then we run BFS (or topological sort) on that graph. For a certain state, if all states it links out:

has a state that the current player will win. Then the current player will win.has a state that the will get into a deal. Then the current player will make it deal.are all lose states. Then the current player will lose.It is because the current player can choose the best way to go.

So we can do some initialization to get the "Win", "Lose" or "Deal" status for all possible states. Follow these steps shown below.

Give all states that is easily to identify a status "Win" or "Lose". Then push them into a queue. For other states, give "Deal" temporarily.Take a state from the front of the queue. Update all states that can reach this state in one step (i.e. has an edge between them) using the rule shown above.If the state can be defined as one status, push it into the queue and go to the second step. Or you can ignore it and go to the second step instantly.After this step (or we can say "Initialization"), we can answer those T queries easily.

Time complexity: O(k2⋅(m+k−1k)2+T), where k is the card number one player has, and m is the modulo. Here we have m=5 and k=8.

Bonus: Can you prove that the useful state of each player is (m+k−1k)?

Code (My stupid solution: C++ version)

Code (demon1999's fast solution: C++11 version)

UPD1: Note that the editorial of problem E is modified with some correction. Sorry for that inconvenience.

UPD2: The editorial is complete now. Hope you find it useful. :P

UPD3: It's seems that all bonus questions can be found in the comments. :) Don't hesitate to give them an upvote. :P

UPD4: The editorial is updated.

Codeforces Round #459 Editorial

By PrinceOfPersia, history, 5 years ago, In English918A - ElevenCalculate the first x Fibonacci sequence elements, where x is the greatest integer such that fx ≤ n. Let s be a string consisting of n lowercase 'o' letters. Then for each i ≤ x, perform sfi = 'O'. The answer is s.

Pseudo code:

s = ""for i = 0 to n-1    s[i] = 'o'x = y = 1while y <= n    s[y-1] = 'O'    tmp = y    y = y + x    x = tmpprint(s)Total time complexity: 

Writer: PrinceOfPersia

918B - Radio StationSave the names and ips of the servers. Then for each command find the server in  and print its name.

Total time complexity: 

Writer: PrinceOfPersia

917A - The MonsterFirst, let's denote s[l..r] as the substring slsl + 1... sr of string s. Also s.count(t) is the number of occurrences of t in s.

A string consisting of parentheses and question marks is pretty if and only if:

|s| is even.0 ≤ s[1..i].count('(') + s[1..i].count('?') - s[1..i].count(')') for each 1 ≤ i ≤ |s|.0 ≤ s[i..|s|].count(')') + s[i..|s|].count('?') - s[i..|s|].count('(') for each 1 ≤ i ≤ |s|.Proof: If s.count('?') = 0 then s is a correct bracket sequence. Otherwise, let q be an integer between 1 to |s| such that sq = '?'.

Lemma: We can replace sq by either '(' or ')' such that the three conditions above remain satisfied.

Proof: We'll use proof by contradiction. If we can replace sq by either '(' or ')' such that the conditions remain satisfied, the lemma is proven. Otherwise, the conditions will be violated if we replace sq by '(' or ')'.

Let's denote f(s) as s.count('(') + s.count('?') - s.count(')') and g(s) as s.count(')') + s.count('?') - s.count('('). Please note that f(s) =  - g(s) + 2 × s.count('?') and g(s) =  - f(s) + 2 × s.count('?').

By assumption, if we replace sq by '(' the conditions will be violated. By replacing sq the second condition can't be violated, thus the third condition will be violated. So, there's an integer i such that 1 ≤ i ≤ q and g(t[i..|t|]) < 0 (t is s after replacing sq by '('). Thus, g(s[i..|s|]) < 2. Similarly, there's an integer j such that q ≤ j ≤ |s| and f(s[1..j]) < 2.

Since all three conditions are satisfied for s (by assumption), then 0 ≤ g(s[i..|s|]), f(s[1..j]) ≤ 1.

Let's break s into three parts (they could be empty): a = s[1..(i - 1)], b = s[i..j] and c = s[(j + 1)..|s|].

g(s[i..|s|]) = g(b) + g(c) and f(s[1..j]) = f(a) + f(b). Since the three conditions are satisfied for s, then 0 ≤ g(c), f(a).

f(a) + f(b) ≤ 1 so f(a) - 1 ≤  - f(b). Thus f(a) - 1 ≤ g(b) - 2 × b.count('?'), so f(a) - 1 + 2 × b.count('?') ≤ g(b).

So f(a) - 1 + 2 × b.count('?') + g(c) ≤ g(b) + g(c) ≤ 1. So f(a) - 1 + 2 × b.count('?') + g(c) ≤ 1. Since i ≤ q ≤ j, then 2 ≤ 2 × b.count('?').

Also, 0 ≤ g(c), f(a). So, 1 ≤ f(a) - 1 + 2 × b.count('?') + g(c) ≤ 1. So f(a) - 1 + 2 × b.count('?') + g(c) = 1. This requires that f(a) = g(c) = 0 and b.count('?') = 1.

Since f(a) and g(c) are even, then |a| and |c| are even, and since |s| is even (first condition), then |b| is also even (because |s| = |a| + |b| + |c|).

f(a) = g(c) = 0 and 0 ≤ f(a) + f(b) and 0 ≤ g(b) + g(c), thus 0 ≤ f(b), g(b). Also, f(a) + f(b), g(b) + g(c) ≤ 1, thus 0 ≤ f(b), g(b) ≤ 1, since |b| is even, f(b) and g(b) are also even, thus, f(b) = g(b) = 0. g(b) =  - f(b) + 2 × b.count('?') and since 1 ≤ b.count('?') then g(b) ≠ 0.

Thus, we have 0 ≠ 0, which is false. So the lemma is true.

Using the lemma above, each time we can replace a question mark by parentheses and at the end we get a correct bracket sequence.

After proof: Knowing this fact, we can find all such substrings by checking the three conditions. Pseudo code:

f[n][n] = {}g[n][n] = {}for l = 1 to n    cur = 0    ok = true    for r = l to n        if s[r] == ')'            cur = cur - 1        else            cur = cur + 1        if cur < 0:            ok = false        f[l][r] = ok

for r = 1 to n    cur = 0    ok = true    for l = r to 1        if s[l] == '('            cur = cur - 1        else            cur = cur + 1        if cur < 0:            ok = false        g[l][r] = ok

ans = 0for l = 1 to n    for r = l to n        if f[l][r] and g[l][r] and (r-l+1) % 2 == 0            ans = ans + 1print(ans)Total time complexity:  where n = |s|

Writer: PrinceOfPersia

917B - MADMAXDenote dp(v, u, c) as the winner of the game (the person that starts it or the other one?, a boolean, true if first person wins) if the first person's marble is initially at vertex v and the second one's initially at u and our set of letters is {ichar(c), ichar(c + 1), ..., 'z'} if ichar(i) = char('a' + i) (c is an integer).

Denote  and ch(x, y) as the character written on edge from x to y.

Now if there's some x in adj(v) such that c < int(ch(v, x) - 'a') and dp(u, x, ch(v, x)) = false, then the first person can move his/her marble to vertex x and win the game, thus dp(v, u, c) = true, otherwise it's false.

Because the graph is a DAG there's no loop in this dp, thus we can use memoization. The answer for i, j is dp(i, j, 0).

Total time complexity: 

Writer: PrinceOfPersia

917C - PollywogWhat would we do if n was small? Notice that at any given time if i is the position of the leftmost pollywog and j is the position of the rightmost pollywog, then j - i < k. Thus, at any given time there's an i such that all pollywogs are on stones i, i + 1, ... i + k - 1, in other words, k consecutive stones.

x pollywogs are on k consecutive stones, thus, there are  different ways to sit these pollywogs on k stones, that's about 70 at most. Denote dp[i][state] as the minimum amount of energy the pollywogs need to end up on stones i, i + 1, ... i + k - 1, and their positions are contained in state (there are  states in total). We assume init is the initial state (pollywogs on the x first stones) and final is the final state (pollywogs on the x last stones).

Thus, we could easily update dp in  (where would the first pollywog jump?) using dynamic programming and this would work in  since the answer is dp[n - k + 1][final].

But n is large, so what we could do is using matrix multiplication (similar to matrix multiplication, but when multiplying two matrices, we use minimum instead of sum and sum instead of multiplication, that means if C = A × B then C[i][j] = min(A[i][k] + B[k][j]) for all k) to update the dp, in case q = 0 to solve the problem in .

For q > 0, we combine the dynamic programming without matrix and with matrix. Note that the special stones only matter in updating the dp when there's a special stone among i, i + 1, ... i + k - 1, that means at most for k × q such i, for the rest we could use matrices for updating.

Total time complexity: 

Writer: PrinceOfPersia

917D - Stranger TreesSolution #1:

First, for every K such that 0 ≤ K ≤ N - 1 we are going to find for every K edges in the original tree we are going to find the number of labeled trees having these K edges, then we will add them all to res[K].

But Mr. Author aren't we going to count some tree that has exactly E (where E > K) common edges with the original tree in res[K]? Yes, that's true. But we only count it  times! So, after computing the res array we are going to iterate from N - 1 to 0 assuming that the res is correct for all J > I (our current iteration), and then reduce  (the fixed res) from res[I]. Then we'll have the correct value for res[I].

But Mr. Author, how are we going to find res[K] in the first place? Let's first find out for a fixed K edges forest, in how ways we connect the remaining vertices to get a tree. Let's look at the components in the forest. Only their sizes are relevant because we can't connect anything inside them. Let the sizes be sz[0]... sz[N - 1]. (if you assume that the sizes are all 1, the number of resulting trees are NN - 2 (Kayley's theorem)).

To solve this subproblem, let's go to another subproblem. Let's assume that for every additional edge, we know which components it is going to go connect. Then, the number of resulting trees is  where d[i] is the degree of component i (edges between this component and other components). The reason is that we have sz[v] vertices inside component v to give to every edge that has one endpoint in v.

Ok going back to the parent subproblem. d[i] huh? I've heard that vertex v appears in the Prufer code of a tree d[v] - 1 times. so we've gotta multiply the answer by sz[v] every time it appears in Prufer code. It's also multiplied by  because we haven't multiplied it one time (d[v] - 1 not d[v]). But how to make it get multiplied by sz[v] every time component v is chosen? Look at this product. (sz[0] + sz[1] + ... + sz[N - 1])N - 2. If in the i-th parenthesis sz[v] is chosen, then let the i-th place on the Prufer code of the tree connecting the components be the component v. The good thing about this product is that if component v has come in the Prufer code K times, then the multiplication of the parenthesis has sz[v]K in it. So it counts exactly what we want to count.  is the answer for some fixed K edges.  corresponds to N in the original problem and N - 2 corresponds to Number_of_components - 2. so we want to count 

Okay Mr. Author so how do we count this for every K fixed edges in the original tree. Lets count dp[top_vertex v][size_of_component_containing_top_vertex s][the_number_of_edges_we_have_fixed e] which contains  of every component inside v's subtree which doesn't include v's component and Nthe_number_of_components_not_including_v's. We can update this from v's children. Let's add v's children one by one to the dp by assuming that the children we didn't go over don't exist in v's subtree.

let's go over old_dp[v][vs][ve] and dp[u][us][ue], we either fix the edge between u and v then it'll add dp[u][us][ue] × dp[v][vs][ve] to next_dp[v][us + vs][ve + ue + 1] and otherwise it'll add dp[u][us][ue] × dp[v][vs][ve] × N × us to dp[v][vs][ve + ue]. We can also divide it by N2 at the end with modulo inverses. We can find res[K] with the sum of dp[root][s][K] × s × N. (with s = N as a corner case).

The solution may look that it's N5 because it's inside 5 fors. But it's actually N4 if the us and vs fors go until sz[u] and sz[v] (actually only the subtree of v that we've iterated on). So the cost is sz[u] × sz[v] × N2. Let's look at it like every vertex from u's subtree is handshaking with every vertex of v's subtree and the cost of their handshaking is N2. We know that two vertices handshake only once. That's why it'll be  which is of .

Solution #2:

Let's define F(X) as the number of spanning trees of the graph KN plus X - 1 copies of T (the original tree). If we look at F(X) we'll see that it is actually  because it has Xi ways to choose which of the X multiple edges it should choose for the common edges. So the problem is to find F's coefficients. We can do that by polynomial interpolation if we have N sample answers of F. Let's just get N instances of F for X = 1 till X = N. We can find that using Kirchhoff's matrix tree theorem to find the number of spanning trees of a graph. So the complexity is . So we have an  complexity. This is how to do it in N2 -> (I don't know it yet, I'll update it when I have it ready)

Writer: Reyna

917E - Upside DownAssume ti is reverse of si. Use centroid-decomposition. When solving the problem for subtree S, assume its centroid is c. For a fixed query, assume v and u are both in S and path from v to u goes through the centroid c (this happens exactly one time for each v and u). Assume x is string of path from c to v and y is string of path from c to u. We should find the number of occurrences of sk in reverse(x) + y. If number of occurrences of s in t is f(s, t) then f(sk, reverse(x) + y) = f(tk, x) + f(sk, y) + A. First two variables can be calculated using aho-corasick and segment tree.

A is the number of occurrences of sk in the path such that some part of it belongs to reverse(x) and some to y.

So, so far the the time complexity is .

Now for counting A, first calculate the suffix tree for each string (for each sk and tk). A suffix tree is a trie, so let sf(v, s) be the vertex we reach when we ask the string of path from c (root) to v one by in the suffix tree of string s. We can calculate this fast for every v and s if we merge this suffix trees into one trie (we do this before we start the centroid-decomposition algorithm in per-process).

We associate a value val to each vertex of the trie, initially zero for every vertex. Now we traverse this trie like DFS. When we reach a vertex x, we iterate over all suffixes (there are 2(|s1| + ... + |sn|) suffixes) that end in x (the suffixes that equal the string of path from root of the trie to vertex x), and for each suffix (s, k) (suffix of string s with length k), we add 1 to the val of each vertex in the subtree of the vertex where the suffix (reverese(s), |s| - k) ends and we subtract this number when we're exiting vertex x (in DFS).

Now back to the centroid-decomposition, A equals val of vertex in trie where the suffix (tk, b) when in DFS we're at vertex in trie where (sk, a) ends where a is the size of the longest suffix of sk that is a prefix of the string of the path from c (root) to u and similarly, b is the size of the longest suffix of tk that is a prefix of the string of the path from c (root) to v. For achieving this goal, we can use persistent segment tree on the starting time-finishing time range of vertices in the trie (or without using persistent segment tree, we could calculate every A after the centroid-decomposition is finished, kind of offline).

Total time complexity:  where N = n + q + |s1| + |s2| + ... + |sn|.

Writer: PrinceOfPersia

CodeCraft-18 and Codeforces Round #458 (Div. 1 + Div. 2, combined) Editorial

By Superty, history, 5 years ago, In English914A - Perfect SquaresFor each number, check whether the number is a square or not (by checking factors smaller than the square root of the number or using sqrt function).

The answer is the largest number which isn't a square. (negative numbers can't be squares)

Make sure you initialize your max variable to  - 106 instead of 0.

Author: crvineeth97Testers: deepanshugarg, nir123

Author's code914B - Conan and Agasa play a Card GameLet A = max (a1, a2, ..., an). Observe that if A occurs an odd number of times, Conan can simply begin by removing one instance of A. If there are any cards left, they all have the same number A on them. Now each player can only remove one card in their turn, and they take turns doing so. Since there were an odd number of cards having A on them initially, this keeps continuing until finally, in one of Agasa's turns, there are no cards left.

However, if A occurs an even number of times, Conan cannot choose a card having A on it because it will leave Agasa with an odd number of cards having A. This will result in both players picking cards one by one, ending with Agasa picking the last card, and thus winning. In such a case, Conan can consider picking the next distinct largest number in the array, say B. If B occurs an odd number of times, then after Conan's turn there will be an even number of cards having B and an even number of cards having A. If Agasa takes a card having A then it becomes the same as the previous case and Conan wins. Otherwise, they take turns choosing a card having B until finally, on one of Agasa's turns, there are no cards having B and Agasa is forced to pick a card having A. Now it is Conan's turn and there are an odd number of cards having A, so it is again the same as the first case and Conan wins.

By a similar argument, we can show that if Conan plays optimally, he starts by picking a card having the greatest number that occurs an odd number of times. Conan loses if and only if there is no such number, i.e., Conan loses if and only if every number occurs an even number of times.

Author: RohanRTiwariTester: Superty

Author's code914C - Travelling Salesman and Special NumbersLet us denote the minimum number of steps it takes to reduce a number to 1 as the order of that number.

Since the number of set bits in numbers smaller than 21000 is less than 1000, any number smaller than 21000 would reduce to a number less than 1000 in one step. We can precompute the order of the first 1000 numbers.

For each x (x < 1000) such that x has order k - 1, we need to compute the number of numbers less than or equal to n that have k set bits.

Let k be the number of digits in the binary representation of n. Every number x < n satisfies the property that, for some i (1 ≤ i < k), the first i - 1 digits of x are the same as that of n, the ith digit of n is 1, and the i-th digit of x is 0. We can iterate through all possible i and compute the answer using binomial coefficients, that can be computed in O(l) where l is the length of binary representation of n.

Time Complexity: O(l) where l is the length of binary representation of n.

Author: aman_shahi2Tester: mprocks

Author's code914D - Bash and a Tough Math PuzzleBuild a segment tree on the array to answer range gcd queries. We can handle single element updates in the segment tree. Let us see how to answer an (l, r, x) query.

The segment tree decomposes the query range into O(logn) nodes that cover the range. If the gcds of all of these nodes are multiples of x, then the answer is YES. If the gcd of two or more of these nodes is not a multiple of x, then the answer is NO.

If the gcd of exactly one node is not a multiple of x, then we need to know how many elements in this node are not multiples of x. We can find this by traversing the descendents of that node.

If at a point only one child is not a multiple of x, recurse into it. If at any point, there are two children whose gcds are not multiples of x, then the answer is NO. Otherwise, if we reach a node that doesn't have any children, then the answer is YES.

Author: RohanRTiwariTesters: codelegend, Superty

Author's code914E - Palindromes in a TreeThe problem can be solved by centroid decomposition.

A path will be palindromic at most one letter appears odd number of times in the path. We maintain a bitmask for each node, where i-th bit is 1 if the i-th character occurs odd number of times, otherwise 0. The path from u to v is valid if mask[u] ^ mask[v] has at most one bit set to 1.

Consider a part as the subtree of the immediate children of the root of the the centroid tree. For a node, we need to consider the paths that go from its subtree to any other part. We add the contribution of nodes in the subtree of a node using a simple dfs and propagating the values above and add the corresponding contribution to the answer of the node currently in consideration(dfs). Complexity is n*log(n)*20

Author: born2ruleTesters: devanshg27, FundamentalEq

Author's code914F - Substrings in a StringLet N = |s|. Divide the given string into blocks of size  and use any suffix structure for each block. Complexity: O(|s|).

To update a character in the string, rebuild a suffix structure for that block. This takes O(K) per update.

We answer queries as follows. Remember that it’s given that the total length of all the query strings is at most 105.

If the size of the query string is greater than K, then the number of such strings will be at most y / K and hence we can directly use KMP in the string for the given range for all such strings. Overall Complexity: O(N * y / K)

If the size of the query string is less than K, we proceed as follows. For the occurrences of query string within a block, we can calculate them using the suffix structures for each block. This can be done in O(|y|) for each block, O(|y| * (N / k)) for the given range. For the occurrences that lie across two (adjacent) blocks, we only need to consider a string of 2 * |y|, we can simply use KMP for finding such occurrences. We need to choose the string carefully to avoid over counting (for more details, see the author’s solution). Its complexity will be O(N / k * 2 * |y|). For left and right blocks of the query range, we can again use KMP. The complexity would be O(2 * k). The overall complexity for the small query strings is therefore O(N / k * |y|). Hence, complexity over all such string would be O(y * N / k). Hence, the overall complexity is O(N * k + y * N / k). So choose any optimal K. Any K from 150 to 400 will fit in the time limit. Expected Complexity: O(N * sqrt(N))

There was an unexpected solution that involved bitset that runs in complexity O(N2 / 32). Have a look at Syloviaely 's code: 34364964

Author: RohanRTiwariTesters: born2rule, devanshg27, additya1998, virus_1010, nir123

Author's code914G - Sum the FibonacciApologies, we didn't expect an O(317) solution. The expected solution was as follows.

Let A[i] be the number of pairs (x, y) in the array such that their bitwise OR is i and x&y = 0, multiplied by Fib[i]. This can be done using subset convolution. Let B[i] be the count of each element in array, multiplied by Fib[i]. Let C[i] be the number of pairs (x, y) such that their bitwise xor is i, multiplied by Fib[i]. This can be done using Xor convolution.

Let D be the And Convolution of A, B, and C. Then the answer is given by the expression .

Complexity: O(217 * (173))

Author: FundamentalEqTester: born2rule

Author's code914H - Ember and Storm's Tree GameEmber wins if the path chosen by Storm is monotonic or bitonic. In this case, there can be two (i, op) pairs.

Let S be the set of trees having n vertices in which all paths are bitonic or monotonic. We need to find 2n(n - 1)|S|.

For every tree in S, there exists at least one vertex such that every path starting or ending at that vertex is monotonically increasing or decreasing.

First, let's count the number of rooted trees such that all paths starting at the root are increasing. Later we'll combine this with trees having decreasing paths.

Let tree[i][deg] be the number of trees having i vertices and maximum degree d such that all paths starting at vertex 1 are monotonically increasing and the degree of the vertex 1 is deg. We can find this quantity by a kind of knapsack DP in , as follows.

We can construct a tree of k + i·j vertices and degree of root deg + j by taking a tree of k vertices having root degree deg and attaching j trees of i vertices each to its root. Let the set of vertices be V = {1, ... k + i·j}. Initially we remove k vertices from V and use these vertices to construct the tree of k vertices. Let W be the set of remaining vertices. We partition W into j subsets of i vertices each. Sort these subsets by their minimum element. Now we make j trees of i vertices each, and use the l-th set of vertices to construct the l-th tree. Therefore, the number of ways to do this is:

where tree[i][any] is the number of trees of i vertices with any root degree from 1 to d - 1.

Note that there is a bijection from trees in which all paths from root are increasing and trees in which all paths from root are decreasing. ()

Note that tree[i + 1][j]·tree[n - i][k] is the number of trees such that all paths starting at the root are monotonic, and there are i vertices lying on the increasing paths and there are n - i - 1 vertices lying on the decreasing paths, and the degree of the root is j + k Therefore the quantity

is the number of rooted trees of n vertices such that all paths starting at the root are monotonically increasing or decreasing. However, we want to count unrooted trees.

Note that if a tree in S has k possible roots, then these roots form a chain of consecutive numbers with an increasing tree of size i on the larger end of the chain and a decreasing tree of size n - k - i on the smaller end of the chain. Such a tree gets counted k times in a. But for all of these roots except one, there is exactly one child of the root smaller than it. Therefore the total number of unrooted trees is

Time Complexity: 

Author: SupertyTester: codelegend

Author's code

Codeforces Round #457 (Div. 2) Editorial

By STommydx, history, 5 years ago, In EnglishI would like to take this opportunity to express my deepest apology to all of you who take your own precious time to participate in this unrated round. Also, apologies to vintage_Vlad_Makeev who really helped a lot in preparing the round and MikeMirzayanov who helped to host the round, I did not do a good job in managing the round. As the main author of this round, I'm undoubtedly responsible for the mistake that not writing a brute force solution to test the correctness of the intended solution. It is my responsibility to make sure everything is right before the round starts. I am really sorry that the round must be unrated to ensure fairness to all contestants.

I hope all of you can learn something from the contest. Do not claim a greedy solution absolutely correct (like me :C) unless you have proved it. On the bright side, I'm really glad that some of you found problem D and E interesting as said in some comments in the announcement blog post. I admit that problem D may seem to be a quite standard data structure problem but we think it would be fun for less experienced contestants to think how to put the concepts learnt together.

Just a little unimportant fact: The original div2B problem was a harder data structure problem which involves a slightly complicate mathematical proof (which the current one doesn't have :C). We replaced it because it is too difficult for div2B as the coordinator suggested.

916A - Jamie and Alarm Snoozeidea: STommydx, preparation: southball

Let's use brute force the find the answer. We first set the alarm time as hh: mm and initialize the answer as 0. While the time is not lucky, set the alarm time to x minute before and add 1 to the answer.

Why does this solution run in time? As x ≤ 60, hh decrease at most 1 for every iteration. Also, after at most 60 iterations, hh must decrease at least once. All time representation that hh = 07 (07:XX) is lucky so at most 24 times decrement of hh will lead to a lucky time. Therefore, the max. number of iteration possible is 24 * 60 = 1440 which is very small for 1 sec TL.

In fact, the largest possible answer is 390 where x = 2, hh = 06 and mm = 58.

My implementation: 34342125

916B - Jamie and Binary Sequence (changed after round)idea: southball, preparation: STommydx

The main idea of the solution is 2x = 2·2x - 1, that means you can replace 1 x element with 2 (x - 1) elements. To start with, express n in binary — powers of two. As we can only increase the number of elements, there is no solution if there exists more than k elements.

Let's fix the y value first. Observe that we can decrease the y value only if all y can be changed to y - 1. So we scan from the largest power and try to break it down if doing so does not produce more than k elements. After y is fixed, we can greedily decrease the smallest element while the number of elements is less than k.

My implementation: 34342011

916C - Jamie and Interesting Graphidea: STommydx, preparation: STommydx

First, observe that only n - 1 edges are required to fulfil the requirement, so we will make the other m - n + 1 edges with a very large number so they would not contribute to the shortest path or the MST. Now, the problem is reduced to building a tree with prime weight sum and two nodes in the tree have prime distance.

Recall that a path graph is also a tree! If we join (i, i + 1) for all 1 ≤ i < n, the shortest path will lie on the whole tree. We are left with a problem finding n - 1 numbers that sum to a prime. Let's make 1 edge with weight p - n + 2 and others with weight 1. Choosing a prime slightly larger than n (e.g. 100003) will fulfil the requirement for all cases.

My implementation: 34342305

916D - Jamie and To-do Listidea: STommydx, preparation: STommydx

Let's solve a version that does not consist of undo operation first. The task can be divided to two parts: finding the priority of a string and finding the rank of a priority. Both parts can be solved using trie trees. The first part is basic string trie with get and set operation so I will not describe it here in details. The second part is finding a rank of the number which can be supported by a binary trie.

To support the undo operation, observe that each operation only add at most 31 nodes to the trie trees. Therefore, we can make use the idea of persistent data structure and store all versions by reusing old versions of the data structure with pointers. Remember to flush the output after each query operation.

As pointed out by some of you, there exists alternative solutions using persistent dynamic segment trees.

My implementation: 34342389 (sorry for a bit messy)

916E - Jamie and Treeidea: longhuenchan, preparation: longhuenchan

Let's solve the problem without operation 1 first. That means the subtree of a vertex does not change.

For operation 2, the subtree of smallest size that contains u and v means the lowest common ancestor (lca) of u and v, and we update the subtree of lca. For operation 3, we query the sum of the subtree rooted at the given vertex. To do this, we can flatten a tree into an one dimensional array by considering the DFS order of the vertices starting from vertex 1. If a vertex has DFS order x and its subtree has size y, then the update/query range is [x..x + y - 1]. This can be done by standard data structures, such as binary indexed tree with range update function, or segment tree with lazy propagation.

Things get more complicated when the root of the tree r changes. One should notice that in order to reduce time complexity, we should not recalculate everything when r changes. We just need to keep a variable storing the current root. Now let's discuss the two main problems we face (In the following context, subtree of a vertex is defined according to vertex 1 unless otherwise stated):

How to find the LCA of u and v using the precomputed LCA table that assumes the root is vertex 1? Let's separate the situation into several cases. If both u and v are in the subtree of r, then query the LCA directly is fine. If exactly one of u and v is in the subtree of r, the LCA must be r. If none of u and v is in the subtree of r, we can first find the lowest nodes p and q such that p is an ancestor of both u and r, and q is an ancestor of both v and r. If p and q are different, we choose the deeper one. If they are the same, then we query the LCA directly. Combining the above cases, one may find the LCA is the lowest vertex among lca(u, v), lca(u, r), lca(v, r).

After we have found the origin w of update (for query, it is given), how to identify the subtree of a vertex and carry out updates/queries on it? Again, separate the situation into several cases. If w = r, update/query the whole tree. If w is in the subtree of r, or w isn't an ancestor of r, update/query the subtree of w. Otherwise, update/query the whole tree, then undo update/exclude the results of the subtree of w', such that w' is a child of w and the subtree of w' contains r.

The above ideas can be verified by working with small trees on paper.

longhuenchan's implementation: 34352491

We are glad to see some more elegant implementations by the contestants.

Feel free to discuss the problems below. I am happy to listen to feedback and answer questions from you guys. :)

Codeforces Round #456 (Div. 2) Editorial

By rek, history, 5 years ago, In EnglishWe, the round authors, are eternally grateful to all the brave who took part in this round. Sadly there were some issues to encounter, but we hope it only made the contest more interesting :)

912A - Tricky AlchemyNote that the crystals of each color are bought independently.

One needs 2·x + y yellow and 3·z + y blue crystals. The answer therefore is max(0, 2·x + y - A) + max(0, 3·z + y - B).

Author — GreenGrapeCode: 33946912

912B - New Year's EveIf k = 1, the answer is n.

Otherwise, let's take a look at the most significant bit of answer and denote it by p (with the 0-th bit being the least possible). It must be the same as the most significant bit of n. This means the answer cannot exceed 2p + 1 - 1.

Consider the numbers 2p and 2p - 1. Obviously, they both do not exceed n. At the same time, their xor is 2p + 1 - 1. Hence, the maximum answer can always be obtained if k > 1.

Author — GreenGrapeCode: 33946939

912C - Perun, Ult!The statement almost directly states the formula for the answer — it is calculated as , where f(t) is amount of enemies we can kill at t-th second. Thus, we need to learn how to calculate f(t) and find such values of t that are potential candidates for the point the maximum is achieved at.

First, let's consider the case we have no enemies with maximum health exceeding . Additionally, let .

So, how we can calculate f(t)? Let's model the process. There are three kinds of events that affect its value:

Some enemy has his health updated, it is now less than or equal to , thus we can kill the enemy;Some enemy has his health updated, it is now greater than , thus we can't kill the enemy;The enemy has regenerated enough health to become invincible again.One can observe that the optimal answer is reached at the second exactly preceeding the events of the second and the third kind. Indeed, otherwise we can move on to the next second: the bounty is increased and f(t) doesn't decrease, thus providing us with a better answer.

What remains for us is to calculate the time when the aforementioned events occur to run scanline. The first two kinds correspond directly to the updates (and initial values — we can treat them as updates occuring at zeroth second). Let's calculate when the events of third kind would occur. Let the second t be the moment when one of the enemies' health became equal to h. Let r be the regeneration rate of the enemy. At the second  he will regenerate enough health to become invincible again. One also needs take care of the case when r = 0: if there are no health updates after the enemy became killable, one can kill him at any moment and earn infinitely large amount of money. Note that one should need when did the last event of the first kind happen as updates cancel the potentially planned events of the third kind.

Now, consider the case when some enemy has maximum health less than or equal to . In that case, there is always an enemy to kill, and, since the bounty increases over time, the answer can be infinitely large.

Finally, if , the bounty stays constant and we cannot obtain the infinitely large answer. Since the bounty is constant, we are to find the maximum value of f(t) and multiply it by bounty. This is a simple task and is left as an excersise :)

Time complexity — .

Author — rekCode (rek): 33953146Code (xen): 33946949Code (GreenGrape): 33947166

912D - FishesLet's solve a simplified problem first. Assume we know all fishes' positions (xi, yi) (1-indexed). Denote as g(x, y) the amount of fish that is inside a scoop with lower-left angle located at (x, y). Then the expected value is equal to:

It's quite obvious that straightforward computation will result into O(n·m) time. However, we can invert the problem and calculate for each fish f(xi, yi) — how many scoops it is covered by. f is given by the following formula:

Let's get back to  and transform it into:

In other words, in order to maximize the expected value we have to choose k best values among n·m possibilities.

From now on there are several approaches.

Solution I.Imagine we're considering f(x0, y), i.e. with a fixed coordinate x0. Note that in this case f is y-convex, i.e. it's non-decreasing until some point, and after — non-increasing. Moreover, it always reaches its maximum at . Denote the points to the left of this one D, and to the right (inclusive) — I.

The rest of the solution looks as follows: initially we put 2·n points into the set, two per each x-coordinate, one for D and one for I. On each step we take the point with maximum value of f and replace it with its left or right neighbour (depending on which part it was from: D means that the substitute will be to the left, I — to the right).

Complexity: .

Solution II.Let's enhance the contemplations from the previous paragraph. Notice that f is convex by both values. Then we can take ) as the starting point and launch a breadth-first search with a priority queue, erasing the most significant point according to f from the queue and checking all of its yet unvisited neighbours in a 4-connected area.

Complexity:  with a greater constant compared with solution one.

Author — GreenGrapeCode (xen): 33946962Code (GreenGrape, solution 1): 33946974Code (GreenGrape, solution 2): 33946993

912E - Prime GiftThe initial idea that emerges in such kind of problems is to use binary search to determine the k-th element. Still we have to somehow answer the following query: "how many elements no greater than x satisfy the conditions?"

It's easy to see that all such numbers can be represented as p1a1·...·pnan. Denote D(G) as a set of numbers not exceeding 1018 such that all their prime divisors lie inside G.

Let N be our initial set. Sadly we cannot just generate D(N) since its size might be of the order of 8·108. Actually, the goal is to invent a way to obtain information about all elements without having to generate them explicitly.

Imagine we split N into two such sets A and B that  and . According to the fact that each element of D(N) can be represented as product of some element of D(A) and some element of D(B), we can explicitly generate D(A) and D(B), then sort them and find out how many pairwise products do not exceed x in O(|D(A)| + |D(B)|) using two pointers approach. This gives  in total.

The main part is to find the optimal partition. The first thought is to send the first  elements to A and the rest to B. However, this is not enough; in this case the approximate size of D(A) might reach 7·106 which is way too much to pass. To speed it up we can, for example, comprise A of elements with even indexes (i.e p0, p2, ...) so that sizes of both D(A) and D(B) do not exceed 106 and the solution runs swiftly.

Author — GreenGrapeCode (xen): 33947002Code (GreenGrape): 33946911

Codeforces Round #455 (Div. 2) Editorial

By Nickolas, 5 years ago, translation, In English909A - Generate LoginThe most straightforward solution is to generate all possible logins (by trying all non-empty prefixes of first and last names and combining them) and find the alphabetically earliest of them.

To get a faster solution, several observations are required. First, in the alphabetically earliest login the prefix of the last name is always one letter long; whatever login is generated using two or more letter of the last name, can be shortened further by removing extra letter to get an alphabetically earlier login.

Second, the prefix of the first name should not contain any letter greater than or equal to the first letter of the last name, other than the first letter.

Thus, a better solution is: iterate over letter of the first name, starting with the second one. Once a letter which is greater than or equal to the first letter of the last name is found, stop, and return all letter until this one plus the first letter of the last name. If such a letter is not found, return the whole first name plus the first letter of the last name.

909B - SegmentsConsider a segment [i, i + 1] of length 1. Clearly, all segments that cover this segment must belong to different layers. To cover it, the left end of the segment must be at one of the points 0, 1, ..., i (i + 1 options), and the right end — at one of the points i + 1, i + 2, ..., N (N - i options). So the number of segments covering [i, i + 1] is equal to Mi = (i + 1)(N - i). The maximum of Mi over all i = 0, ..., N - 1 gives us a lower bound on the number of layers.

Because the problem doesn't require explicit construction, we can make a guess that this bound is exact. max Mi can be found in O(N); alternatively, it can be seen that the maximum is reached for  (for a central segment for odd N or for one of two central segments for even N).

The answer is .

We can also prove this by an explicit construction. Sort all segments in non-decreasing order of their left ends and then in increasing order of their right ends. Try to find a place for each next segment greedily: if i is the left end of current segment, and segment [i, i + 1] is free in some layer, add the current segment to that layer; otherwise, start a new layer with the current segment.

and yes, this is our O(1) problem! :-)

909C - Python IndentationThis problem can be solved using dynamic programming.

Let's consider all possible programs which end with a certain statement at a certain indent. Dynamic programming state will be an array dp[i][j] which stores the number of such programs ending with statement i at indent j.

The starting state is a one-dimensional array for i = 0: there is exactly one program which consists of the first statement only, and its last statement has indent 0.

The recurrent formula can be figured out from the description of the statements. When we add command i + 1, its possible indents depend on the possible indents of command i and on the type of command i. If command i is a for loop, command i + 1 must have indent one greater than the indent of command i, so dp[i + 1][0] = 0 and dp[i + 1][j] = dp[i][j - 1] for j > 0. If command i is a simple statement, command i + 1 can belong to the body of any loop before it, and have any indent from 0 to the indent of command i. If we denote the indent of command i (simple statement) as k, the indent of command i + 1 as j, we need to sum over all cases where k ≥ j: .

The answer to the task is the total number of programs which end with the last command at any indent: .

The complexity of this solution is O(N2).

909D - Colorful PointsWe can simulate the process described in the problem step by step, but this is too slow — a straightforward simulation (iterate over all points when deciding which ones to delete) has an O(N2) complexity and takes too long. A solution with better complexity is required.

Let's consider continuous groups of points of same color. Any points inside a group are safe during the operation; only points at the border of a group are deleted (except for the leftmost point of the leftmost group and the rightmost point of the rightmost group, if these groups have more than one point). So, if current group sizes are, from left to right, N1, N2, ..., NG - 1, NG, group sizes after performing the first operation are N1 - 1, N2 - 2, ..., NG - 1 - 2, NG - 1, after the second operation — N1 - 2, N2 - 4, ..., NG - 1 - 4, NG - 2 and so on. This process continues until at least one of the groups disappears completely, at which point its adjacent groups may get merged if they are of the same color.

This way, multiple operations can be simulated at once:

Find the number of operations that are required for at least one group to disappear.

Update group sizes after this number of operations.

Remove empty groups.

Merge adjacent groups of the same color.

One update done this way requires O(G) time. During such an update at least one point from each group is deleted, so at least O(G) points are removed. If N is the initial number of points, we can remove at most N points in total. Therefore, running time of the algorithm is O(N).

909E - CoprocessorWe want to minimize the number of communications between main processor and the coprocessor. Thus, we need to always act greedily: while there are tasks that can be executed on the main processor right away, execute them; then switch to the coprocessor and execute all tasks that can be executed there; then switch back to the main processor and so on. This can be done using breadth-first search. To run reasonably fast, this solution has to be implemented carefully: instead of searching for available tasks at each step, we want to maintain two queues of available tasks (for main processor and coprocessor) and add a task to a corresponding queue once all tasks it depends on has been executed.

Alternatively, we can define Ti as the lowest number of coprocessor calls required to execute i-th task, and derive a recurrent formula for Ti. If u is a task and v1, ..., vk are its dependencies, then clearly for each i Tu ≥ Tvi because u must be executed after vi. Moreover, if vi is executed on the main processor and u — on the coprocessor, then executing u will require an additional coprocessor call. Therefore, Tu = maxi(Tvi + si), where si = 1 if u is executed on the coprocessor and vi — on the main processor; otherwise, si = 0. Now all Ti can be calculated by recursive traversal of the dependency graph (or traversing the tasks in topological order). The answer to the problem is max Ti.

909F - AND-permutationsPermutation p (pi & i = 0)If N is odd, the answer is NO. Indeed, any number in odd-numbered position i pi must be even, otherwise the last bit of pi&i is 1. For odd N there are less even numbers than odd-numbered positions, so at least one of the positions will hold an odd number, thus it's impossible to construct a required permutation.

If N is even, the required permutation exists. To build it, first observe that (2k - i)&(2k + i - 1) = 0. For example, for k = 5:

100000 = 25

011111 = 25 - 1

100001 = 25 + 1

011110 = 25 - 2

and so on.

We can use this fact to always match 2k - i and 2k + i - 1 with each other, that is, set p2k - i = 2k + i - 1 and p2k + i - 1 = 2k - i.

The full procedure for constructing the required permutation is as follows. For a given even N, find the maximum power of two that is less than or equal to N 2k. Match pairs of numbers 2k - i and 2k + i - 1 for each i = 1..N - 2k + 1. If we are not done yet, numbers from 1 to 2k - (N - 2k + 1) - 1 = 2k + 1 - N - 2 are still unmatched. Repeat the process for N' = 2k + 1 - N - 2.

For example, for N = 18 on the first step we set 2k = 16 and match numbers 15-16, 14-17 and 13-18. On the second step unmatched numbers are from 1 to 12, so we set 2k = 8 and match numbers 7-8, 6-9, 5-10, 4-11 and 3-12. On the third and the last step the remaining unmatched numbers are 1 and 2, so we set 2k = 2 and match numbers 1 and 2 with each other. After this no unmatched numbers are left, and we are done.

Permutation q (qi & i ≠ 0)We can do a simple case analysis for N = 1..7 manually, noticing that the answer is NO for N = 1..5, a possible answer for N = 6 is \textbf{3 6 2 5 1 4} as given in problem statement, and a possible answer for N = 7 is \textbf{7 3 6 5 1 2 4}.

If N is a power of two, then it is represented in binary as 10..0. We must have qN ≠ N, therefore qN < N, so the binary representation of qN is shorter than that of N. It follows that qN&N = 0, so the answer is NO in this case.

Finally, if N > 7 and N is not a power of two, the required permutation always exists, and can be built in the following way. Split all numbers from 1 to N into the following groups (k is the largest power of two which is still less than N):

1..7

8..15

16..31

\ldots

2k - 1..2k - 1

2k..N

For the first group use the permutation that we found manually. For each of the remaining groups, use any permutation of numbers in this group (for example, a cyclic permutation). The numbers in each group have leading non-zero bit at the same position (which corresponds to the power of two at the beginning of the group), so it is guaranteed that qi&i contains a non-zero bit at least in that position.

Editorial Codeforces Round 454 (and Technocup 2018 — Elimination Round 4)

By veschii_nevstrui, 5 years ago, translation, In EnglishEditorials of the first five problems in English will appear later.907A - Masha and BearsSizes of cars should satisfy the following constraints:

in i-th car, Masha and corresponding bear are able to get into, so size of the car should not be less than max(Vi, Vm);each bear likes its car, so size of i-th car is no more than 2·Vi;Masha doesn't like first two cars, then their sizes are more than 2·Vm;Masha likes last car, so it's size is not more than 2·Vm;Sizes of cars are strictly ordered. It means that size of father's car is strictly more than size of mother's one, and size of mother's car is strictly more than son's car.Sizes of bears don't exceed 100; then, sizes of cars does not exceed 200, and there are only 2003 possible variants of sizes of cars. In given constraints, one can just go through all possible triples of sizes and check if each of them satisfies the constrains above or not.

907B - Tic-Tac-ToeLet us describe each cell of the field by four numbers (xb, yb, xs, ys), 0 ≤ xb, yb, xs, ys ≤ 2), where (xb, yb) are coordinates of small field containing the cell, and (xs, ys) are coordinates of the cell in it's small field. It can be seen that for cell with "usual" coordinates (x, y), 1 ≤ x, y ≤ 9 and our new (xb, yb, xs, ys), there are following equalities which give us a key to go between coordinate systems:

xb = ⌊((x - 1) / 3)⌋, yb = ⌊((y - 1) / 3)⌋;xs = (x - 1) mod 3, yb = (y - 1) mod 3;x = 3 * xb + xs + 1, y = 3 * yb + ys + 1.In terms of new coordinates, if last move was in cell (xb, yb, xs, ys), then next move should be in arbitrary free cell with coordinates (xs, ys, x', y') for some  if it's possible; otherwise, next move can be done in arbitrary free cell. To solve the problem, one can go through all such pairs (x', y') and write "!" in each empty cell (xs, ys, x', y'); if there are not such empty cells, write "!" in all empty cells of the field.

906A - ShockersFrom last action, selected letter can be found; let it be c (without loss of generality). For each of other 25 letters, answers on some actions are contradicting with assumption that this letter was selected; moreover, for each letter d not equal to c, we can find the earlest such action with number Ad (for each action, we can easily check if assumption "d is selected" is contradicting with the action or not on linear time). Then, the answer is a number of electric shocks after action with number which is maximal among all such Ad-s.

906B - Seating of StudentsThe problem has many solutions, including random ones. Consider one of deterministic solutions. Without loss of generality, assume that n ≤ m.

There are a couple of corner cases:

n = 1, m = 1. In this case, good seating exists.n = 1, m = 2. In this case, seating does not exist (obviously).n = 1, m = 3. In any seating, one of neighbours of student 2 will be one of his former neighbours, so correct seating does not exist.n = 2, m = 2. Only student 4 can be a neighbour of student 1, but there should be 2 neighbours for student 1; then, correct seating does not exist.n = 2, m = 3. Both students 5 and 2 have 3 neighbours in the initial seating; then, in new seating, these students should be in non-neighbouring corner cells. Moreover, these corner cells can not be in one row because in this case it's impossible to find a student for cell between 2 and 5. So, without loss of generality, let 5 be in lower left corner, and 2 — in upper right corner. Then, only students 1 and 3 can seat on lower middle cell; but if sduent 1 seats in the cell, then student 4 is impossible to seat at any of the remaining cells, so do student 6 in case of student 3 seating at the cell. So, correct seating does not exist in this case too.n = 1, m = 4. In this case, one of correct seatings is 2 4 1 3.n = 1;5 ≤ m. In this case, let students with odd numbers in increasing order will be in first half of the row, and others in increasing order - in second half. For example, for m = 7 the seating will be 1 3 5 7 2 4 6.n = m = 3. One of possible correct seatings is:6 1 8

7 5 3

2 9 4;

If 2 ≤ n;4 ≤ m, then shift each even row cyclically on two symbols in the right, and then shift each even column cyclically on one symbol upwards. If students are vertical neighbours in the initial seating, then in new seating, they will be in different columns on the distance 2 (possibly through the edge of the table); but if students are horizontal neighbours in the initial seating, then in new seating they will be in neighbouring rows and neighbouring columns (possibly thorugh the edges again). So, for case 2 ≤ n, 4 ≤ m, we build a correct seating.906C - PartyLet’s formulate and prove several facts.

1. If we change an call order, the result doesn’t change. Let’s consider two vertices which are called consecutively. If they are not connected by edge, then regardless of the order, we get that at the end, neighbours of each vertex form a clique.

If they are connected, then independently on the order, we get clique from 2 vertices and all neighbours of them.

2. If graph is a tree, it’s sufficient to take as an answer all its vertices except leaves. Indeed, if we consider any 2 tree vertices, we get that all vertices on the way between them are in the answer. Each vertex reduces on 1 the distance between those 2, it means that the distance between them is 1.

3. Let’s select from source graph spanning tree, that has the largest number of leaves. One can say that we can use all vertices except leaves as an answer.

Obviously from point 2, that after all our operations with such set graph will become complete. Let’s show that it is minimal number of vertices.

Let we selected some set of vertices, that is the answer. Then subgraph of given graph, built on the selected set of vertices, should be connected (otherwise between connected component can’t appear the edge and graph can’t be complete. Also, each of vertices, that isn’t in an answer should have at least one of neighbours selected (otherwise it is impossible to add new edge to it). Now let’s select a spanning tree in selected set (it’s possible because our set is connected) and add non-selected vertices into the tree as leafs. Then we see that our selected can be represented as spanning tree in the initial graph, in which all selected vertices are all non-leaf vertices and possibly, some leafs; but leafs can be obviously removed from the selected set by proved above. So, one of optimal answers can be described as set of non-leaf vertices of spanning tree with minimal possible number of non-leaves and, as a consequence, with maximal possible number of leaves, QED.

4. Implementation. It is necessary to implement an algorithm that should work for 2n·n or faster or with worse asymptotic but with non-asymptotical optimization. One of possible solutions is following. Let contain any subset of vertices as a n-bit mask; for example, mask of a subset containing vertices {v1, v2, ..., vk} will be equal to 2v1 + 2v2 + ... + 2vk. Then, for subset with mask m, vertex v is in set iff m & 2v is not equal to 0; here & is a bitwise AND.

Let for each vertex v, neighbours[v] be a mask of subset of vertices containing vertex v and it's neighbours. Array neighbours[v] can be calculated easily. Then, let bool isConnected[m] be 1 for some mask m iff subset coded by m is connected. Array isConnected can be calculated in O(2n * n) by the following algorithm:

for all vertices  (let vertices be enumerated in 0-indexation), isCalculated[2v] is assigned to 1; for all other masks, isCalculated should be equal to 0;then, go through all masks in increasing order by a simple cycle; let m be current mask in the cycle;if isConnected[m] = 0, then go to the next iteration of cycle;otherwise, let v1, v2, ..., vk be vertices of subset coded by m. Then, mask m':  = maskNeighbours[m]:  = neighbours[v1]|neighbours[v2]|... |neighbours[vk] for | as bitwise OR is a mask coding a subset of vertices containing vertices of mask m and their neighbours. Then, for each vertex w in subset of mask m' we assign isConnected[m|2w] to be 1.The described algorithm works in O(2n * n); it can be proved by induction that at the end, isConnected[m] = 1 for mask m iff m is a code of connected subset of vertices.

But how to find an answer? Notice that mask m = 2v1 + 2v2 + ... + 2vk is a code of good (for our purposes) subset iff isConnected[m] = 1 and maskNeighbours[m] = 2n - 1 = 20 + 21 + ... + 2n - 1. For each mask m, we can check if it's good in O(n) time having an array isConnected calculated; the answer is a good mask with minimal possible number of elements in the corresponding set.

906D - Power TowerLet's learn to calculate . Assume that we want to find  where n and m non necessary co-prime, and x is some big number which we can calculate only modulo some value.

We can solve this problem for co-prime n and m via Euler's theorem. Let's reduce general case to that one. Note that . Indeed if n = d·m + r, |r| < m, then an = d·am + ar, |ar| < |am|. Let p1, ..., pt to be common prime divisors of n and m, a = p1k1... ptkt to be such number that it divisible by such divisors to the power they occur in m, and k to be least number such that . Then we have a chain

Here n and m / a are co-prime so we can calculate power value module . Moreover, , thus case x < k can be considered in .

This is already enough to solve the problem, but continuing one can prove that for  it holds

Where φ(m) is Euler totient function of m. Finally, to solve the problem one shoud note that  so it will take only  steps before m turns into 1.

906E - ReversesAfter inverses we have transform A1B1A2B2... AkBkAk + 1 → A1B1rA2B2r... AkBkrAk + 1. Consider operator mix(A, B) = a1b1a2b2... anbn for strings of equal lengths. Under such operator string will turn into X1Y1X2Y2... XkYkXk + 1 where Xk is string which has all characters doubled and Yk is arbitrary palindrome of even length.

Let's move through letters from left to right and keep minimum number on which we can split current prefix. Last letter will either be in some palindrome or is doubled. For doubled letters we consider ansi = min(ansi, ansi - 2). As for palindromes of even length, one can fit standard algorithm of splitting string into the minimum number of palindromes in such way that it will consider only splittings on even palindromes. For example, one can consider only such spits that every palindrome in the split end up in even index.

Codeforces Round #453 (Div. 1 & Div. 2) Editorial

By 300iq, history, 5 years ago, In English902A - Visiting a FriendNote that if we can get to some point x, then we can get to all points <= x. So we can support the rightmost point where we can get to. Then if this point can use the teleport (if this point is to the right of the teleport), we'll try to move it (If the limit of the teleport is to the right of the current point, then move it there). Then in the end we need to check that the rightmost point where we can get is equal to M.

902B - Coloring a TreeConsider the process from the end, we will "delete" any subtree from the tree, whose color of the ancestor of the highest vertex differs from the color of the highest vertex and the colors of all vertices in the subtree are the same. Thus, we can show that the answer is the number of edges whose ends have different colors + 1.

901A - Хешируем деревьяThere are many ways to solve the problem. First of all you should build any single tree. To do this, you first build the longest path from the root and then attach remained vertices on proper heights. Thus each vertex is either on the longest path or has parent on this path. To build the second tree you should use different vertices from previous levels during construction to make it different from first tree. This is always possible if there are two consecutive ai > 1. Otherwise the tree is determined uniquely by ai sequence.

901B - НОД многочленовAs for integers it is well known that worst case are consequent Fibonacci's numbers Fn + 1 = Fn + Fn - 1. Solutions to this problem are based on the same idea. There were two main intended solutions. First of all you should note that sequence

p0 = 1, p1 = x, pn + 1 = x·pn ± pn - 1Gives us the family of solutions, we just have to output pn and pn - 1. It can be directly checked for given constraints that you can always choose  +  or  -  to satisfy coefficients constraints.

The other solution is the same sequence but you use  +  instead of  ±  and take coefficients modulo 2. That's true because if remainders sequence has k steps while you consider numbers by some modulo it will have at least k steps in rational numbers. So the second intended solution is

p0 = 1, p1 = x, 

901C - Bipartite SegmentsIf two cycles of odd length intersect, then they can be bypassed so as to obtain an edge-simple cycle of even length.

It follows that the given graph is a vertex cactus, with cycles of odd length, then the vertex segment is good - if there is no loop, that the vertex with the minimum number from this cycle is present on this segment and the vertex with the maximum number from this cycle is present on this segment. Then we can select all the cycles, and now we work with the segments.

Let us find for each vertex a maximal right boundary such that the interval [i..mxi] is a bipartite graph.

Then mxi is equal to the minimal right boundary of the segment, which was opened later i.

This can be considered a minimum on the suffix, initially setting for all cycles mx[minimum on the cycle] = maximum on the cycle

To answer the query, we need to take the sum over mxi - i + 1 for those who have mxi ≥ r and the sum over r - i + 1 for those who have mxi ≥ r

then we note that mxi increases and we simply need to find the first moment when mxi becomes  ≥ r (we can do it with binary search)

And take two prefix sums - sum of (mxi - i + 1) and sum of i.

901D - Weighting a TreeLet's solve two cases.

First case is when graph is the bipartite graph

Then the sum of weights of the left part should be equal to the sum of weights of the right part (because each edge will bring an equal contribution to the sums of both part).

We will leave any spanning tree of this graph, then for it the solution is unique (take the edges entering the leafs, their weights are uniquely determined, subtract weights from weights of the second ends of this edges, delete the leafs, recursively) this solution can be found with dfs, then in the end, the root will has weight 0 (because sum of weights of the left part equal to the sum of weights of the right part) Thus, the answer exists when the sum of the weights of the left part is equal to the sum of the weights of the right part.

Second case when graph has the odd cycle.

We find an odd cycle, root the tree for any of its vertices, solve the tree. Then, we add to the weights of the edges of the cycle adjacent to the root minus its weight divided by 2 (it is even, because it is the sum of the weights of all vertices (with different signs) equal to the sum of the degrees of vertices by modulo 2). , and for all others we alternate the signs with which we add this value, then for all vertices except the root the sum does not change, but for the root we get the required value.

Example code: https://pastebin.com/b2bGp4Bh

901E - Циклический шифр(a - b)2 = a2 + b2 - 2ab, hence, . Let a'i = ai - ai - 1, . Then . This corresponds to cyclic convolution of polynomials  and . These polynomials uniquely determined by values in roots of unity of degree n. Thus we can divide values of C by values of B in this points and return to polynomials from values in roots of unity. To do this one should compute discrete Fourier Transform in arbitrary length polynomial which can be done by Bluestein's algorithm. Note that you can't use complex fft here because real values can be very close to zero leading to great precision issues. Thus you should find some mod having root of unity of degree 2n and compute discrete transform over it. Thus we will find dk = ak - a0 for each k, which will allow us to recover a0, because .

It can be proven that values of polynomial in roots of unity are eigenvalues of matrix of linear system thus cyclic shifts are linearly independent iff there is such mod which has root of unity of degree n and values of polynomial in all such roots doesn't equal zero. If it's true for polynomial in field of real numbers there will be only finite number of mods in which this may not be true (it only true if  of polynomial and xn - 1 isn't equal 1 in such mod).

Codeforces Round #452 (Div.2) Editorial

By fcspartakm, history, 5 years ago, In English899A - Splitting in Teamsit is profitably to the coach to unite groups from two students with groups from one student and after that unite in teams three groups from one student. Let's calculate two values: cnt1 — the number of groups from one student, and cnt2 — the number of groups from two students.

Then if cnt1 > cnt2 — the answer is cnt2 + (cnt1 - cnt2) / 3. In the other case, the answer is cnt1.

899B - Months and YearsNote, that n ≤ 24, so we should consider the following cycle: not leap-year — leap-year — not leap-year — not leap-year. This cycle repeats every 4 years, except in some cases. We should generate an array describing the duration of the months in the described cycle. After that we should check that the given sequence can be found in the generated array. For example, we can brute the beginning of the sequence in the array and check the correspondence of the elements of the given sequence to the corresponding elements of the generated array.

899C - Dividing the numbersTo solve this problem we should consider 4 cases.

If n divided by 4 without remnant than the sum of all numbers from 1 to n is even. Then we can divide numbers on two groups in such a way that absolute difference between sum of numbers in each part is 0. To make it we should take in one group all numbers which give a remainder 0 or 1 when dividing by 4.

If n gives a remainder 2 when dividing by 4 than the sum of all numbers from 1 to n is odd. Then we can divide numbers on two groups in such a way that absolute difference between sum of numbers in each part is 1 (because the sum of all numbers is odd, then we can not improve the answer). To make this, we need to take the same numbers in the same group as in the previous case.

If n gives a remainder 3 when dividing by 4 than the sum of all numbers from 1 to n is even. Then we can divide numbers on two groups in such a way that absolute difference between sum of numbers in each part is 0. To make this, we need to take in one group all numbers from 1 to n / 4, inclusively, and all last (n / 4 + 1) numbers (i.e. numbers from (n - n / 4) to n, inclusively).

If n gives a remainder 1 when dividing by 4 than the sum of all numbers from 1 to n is odd. Then we can divide numbers on two groups in such a way that absolute difference between sum of numbers in each part is 1 (because the sum of all numbers is odd, then we can not improve the answer). To make this, we need to take in one group all numbers from 1 to (n / 4 + 1), inclusively, and all last n / 4 numbers (i.e. numbers from (n - n / 4 + 1) to n, inclusively).

899D - Shovel SaleAt first let's check that the sum sum = n + (n - 1) consisting of only digits nine. If it is true then the answer is 1.

In the other case, we should calculate the number of digits in the number sum. Let this value if len. We should construct the number cur which consisting of (len - 1) digits nine. After that we should try to write each digit from 0 to 8 to the beginning of cur.

Let we wrote next digit c and cur became equal to p (i.e. the first digit is c and other digits are nines). So we need to add to the answer the number of ways to take two different digits from 1 to n in such a way that their sum equals to p.

If p ≤ (n + 1), we should add to the answer p / 2. If p > n + (n - 1) we should to add to the answer nothing. Else we should add to the answer the value (n + (n - 1) - sum) / 2.

899E - Segments RemovalWe will use to set of pairs. In the first set (call it len) we will store all segments consisting of the same numbers in a format — the length of the segment multiplied on  - 1 and the position of the beginning of the segment. In the second set (call it segments) we will store all segments consisting of the same numbers in a format — the position of the beginning of the segment and the length of the segment.

Initially we will put in the sets all segments from the given array consisting of the same numbers.

After that we will repeat the following algorithm until in sets there are non-deleted segments:

increase answer on 1;take from lens the longest and the leftmost segment (it will be in the beginning of the lens, because we store here all length multiplied on  - 1) and remove it from lens. Let this segment beginning in the position st and has length len;with help of lowerbound we can find in segments the left and the right segments relatively the segment from the previous article. After that we should remove from the segments the segment (st, len);if both left and right relatively of the current longest segment there are non-deleted segments and they consisting of the same numbers, we should to unite them in one segment. To do this, we should remove the left and right segments from lens and segments and put the new merged segment in lens and segments in the described format.899F - Letters RemovingFor each character c we should use set, where we will store positions of all non-deleted characters c.

Let the next query equals to l, r, c. Then at first we should transform the given positions l and r to the positions of the initial string, taking into account already deleted characters. We can do it with help of segments tree or sqrt-decomposition.

After we transformed l and r we should find the first position in set for character c (with help of lower_bound) which is in range [l, r] and remove positions from the corresponding set until they are in range [l, r]. Also we need to update information in data structure which we use to transform the given in the query l and r to the positions in the initial string.

This algorithm will fit into the time limit, because we will delete each position no more than once.

After we process all queries we should iterate through all sets, find all non-deleted positions and print characters, which are in that positions in the initial string (do not forget before that to sort all non-deleted positions in increasing order).

Codeforces Round #451 (Div.2) Editorial

By fcspartakm, history, 5 years ago, translation, In English898A - RoundingAt first let's round down the given number n to the nearest integer which ends with 0 and store this value in a variable a: a = (n / 10) * 10. So, the round up n (call it b) is b = a + 10.

If n - a > b - n then the answer is b. In the other case, the answer is a.

898B - Proper NutritionTo solve this problem we need to brute how many bottles of Ber-Cola Vasya will buy. Let this number equals to x. Then, if n - a·x is non-negative and divided by b we found the answer — Vasya should by x bottles of Ber-Cola and (n - a·x) / b Bars bars.

In case that (n - a·x) became negative there is no answer and we should print "NO".

898C - Phone NumbersLet's use map from string to vector of strings to simplify implementation. The map keys is friend names, and the values — list of phone numbers.

At first let's put all input data in map, but if vector for a current friend already contains a current number we should not put this number in the vector (for example, we can check it with help of set).

After that we need only to remove for each friend the numbers which are the suffixes of other number of that friend. The time limit allows to make it in time equals to square of phone number count for a current friend.

Now we need to iterate through map key set (it will be names of all Vasya's friends) and print all remaining phone numbers for each friend.

898D - Alarm ClockAt first we need to sort all alarms in increasing order of their times. Also we will use set, where we will store alarm times.

We will iterate through the alarms beginning from the first. Let current alarm time equals to x. Until set does not empty and the first set element less than x - m + 1 we should remove the first set element. After that only alarm with times not before m - 1 minutes relatively x will be in set. If after that the set size less than k - 1 we should insert x in the set (we will not turn off this alarm). In the other case, we should turn off this alarm, so we increase the answer on one and do not insert x in the set.

898E - Squares and not squaresAt first we need to implement a function to check integer a if it is a square of an integer. Let x is a round down square root of x. If x·x =  = a then a is a square of an integer.

Let's calculate two values: cnt1 — how many given numbers are integer squares and cnt2 — how many given numbers are not integer squares.

If cnt1 =  = cnt2, then we should not to change anything and the answer is 0.

If cnt1 > cnt2, then we should to make (cnt1 - cnt2) / 2 numbers-squares not to be squares. To make it we need to take (cnt1 - cnt2) / 2 numbers-squares, which do not equal to 0 and increase them by 1. If such numbers do not enough we should take needed number of 0 and increase them by 2.

If cnt1 < cnt2, then we should to make (cnt2 - cnt1) / 2 numbers, which do not squares, to be squares. Let's calculate for each such number the number of operations to make this number square-number and put this value in separate vector. After than we should sort vector in increasing order and print the sum of first (cnt2 - cnt1) / 2 vector elements.

898F - Restoring the ExpressionAt first we should calculate "hash" by big prime module from the given string, and the base must be equal to 10 because we work with numbers. We can use prime module about 1015, if we will use multiple of long longs by module with help of long doubles.

After that we will brute the length of the result of summation, let this value is len3. Because when two numbers are added the result may have the same length as the larger term, or may have a length one greater than the length of the larger term it is enough to check the following cases (len1 — the length of the first term, len2 — the length of the second term):

len1 = len3, len2 = n - len1 - len3len1 = len3 - 1, len2 = n - len1 - len3len2 = len3, len1 = n - len2 - len3len2 = len3 - 1, len1 = n - len2 - len3For each case the check algorithm is the same. At first we should check that all parts have positive length, that the length len3 satisfies the conditions described at the beginning of the tutorial and that it part has no trailing spaces.

Now we should divide each part on 10 in the needed power, to bring the value of the calculated "hash" to the desired degree. To make it we can multiply each part on element, which is reverse to 10 by the used module, in the desired power. To find r which is reverse to 10 be the prime module MOD we should raising 10 to the power (MOD - 2) with help of binary power raising.

If after the described operations the sum of first to parts by used module equals to the value of third part, we found the answer and we should print corresponding parts.

You could also perform calculations on several smaller modules.

Codeforces Round #450(Div. 2). Editorial.

By Snezhok, history, 5 years ago, translation, In English900A - Find Extra OneCount number of points located on left and right side of the OY axis. Answer will be "Yes" if number of points of one of the sets is smaller than two, "No" — otherwise.

Time complexity O(n).

900B - Position in FractionIn this task you should complete long division and stop, when one period passed. Period can't be more than b by pigeonhole principle. So you need to complete b iterations and if c digit hasn't been met, print  - 1.

Time complexity O(b).

900C - Remove Extra OneIn this problem you have to find an element after which removal the number of records is maximum possible.

Let ri be an array consisting of 0 and 1 depending on whether the i-th element was a record initially or not. We can compute it easily in O(N).

Let xi be the difference between the number of records after removal the i-th element and initial number of records.

Let's think of how does removal of ai influence the array ri. First of all, ri becomes 0. rj (j < i) do not change in this case. Some of rj (j > i), change from 0 to 1. These elements are not records initially, but become records after the removal. These elements are elements which have only one greater element in front of them — ai.

Here follows an O(n2) solution. Let's fix ai — the element we are going to remove. Let xi =  - ri  +  the number of such j that j > i, ai > aj, and for all k (k ≠ i, k < j) ak < aj. We can compute this just looping through all j and keeping the maximum over all elements but the i-th.

Now note that it's not required to fix ai. rj can become 1 from 0 only when a certain element from the left is removed. Let's loop through all aj and determine if there is an element to the left such that it is greater than aj, but all other elements are less than aj. We can check this using ordered set. If there is such a ai, then increase xi by 1. After the loop the array xi is fully computed, so we can just find the element which brings the maximum number of records, and minimum among such.

900D - Unusual SequencesIt's obvious that if y is not divisible by x, then the answer is 0. Let f(t) be the number of sequences such that their sum is t, and gcd is 1. Then the answer for the problem is .

How to compute f(t)?. Let's denote the number of sequences such that their sum is t as g(t). Then g(t) is 2(t - 1): represent all integers in the sequence in unary system with zeros, and split them with t - 1 ones. Note that , where {ti} are divisors of t. Then .

What's the complexity?. We know that the number of divisors of t is not greater than . We can also note than every divisor of divisor of t is a divisor of t. Thus we need for compute only f(ti) for every ti|t. Thus computing f(ti) takes  steps when all f(tj), tj < ti are already computed. The total complexity is , but on practice it works much faster than one can expect.

Also, we can use Möbius function to solve this problem. This solution has a better complexity, but we will leave this solution as an exercise for readers.

900E - Maximum QuestionsLet's find all positions i in string s such that occurrence t can start at position i after making some replacements.

How to find them? As t has a form "abab..." letters si, si + 2, si + 4, ..., s(i + m - 1|i + m - 2) should be equal to '?' or 'a' and si + 1, si + 3..., s(i + m - 1|i + m - 2) should be equal to '?' or 'b'. Let's calculate f[i][с] — how many consecutive letters si, si + 2, ..., s(f[i][c] - 1)·2 are equal to '?' or c.

Than it is left to verify for position i or f[i][a] ≥ cell(n / 2) and f[i][b] ≥ floor(n / 2). We found all positions where occurrence of t can start.

Remaining task can be solved using dynamic programming. Let dp[i][j] — the minimum number of replacements should be done that the number of occurrences in prefix i is exactly maximum possible minus j.

How to calculate this dp? If from position i + 1 can be started occurrence than dp[i + m][MaxOccuri + m - (MaxOccuri - j)] = best(dp[i + m][MaxOccuri + m - (MaxOccuri - j)], dp[i][j] + CountQuestionsi + 1, i + m). Where CountQuestionsi, j means the number of letter '?' in substring from position i to j and MaxOccuri means the maximum number of occurrences in prefix from position 1 to i, that can be calculated greedily.

Actually considering j > 1 is redundant. Really, if we consider such set of occurrences that exists prefix for which the number of occurrences at least two less than maximum possible than we always can find the larger set of occurrences taking the maximum possible in this prefix and maybe deleting one that intersects with the prefix.

The answer is dp[n][0].

Time complexity O(n).

Codeforces Round #449 Editorial

By ODT, history, 5 years ago, In English897A — Scarborough Fair By webmaster

For every i in range [l, r], if ci is c1 then change it into c2...

Because n, m are all very small, O(nm) can easily pass it.

PS. You can use binary search tree to solve it in  time.

897B — Chtholly's request By webmaster

The k-th smallest zcy number is conn(str(k), rev(str(k))), where str denotes the decimal representation of a positive integer as a string, conn denotes the concatenation two strings, and rev denotes the reverse of a string.

Then go over the smallest k such numbers and sum them up to obtain the answer.

896A — Nephren gives a riddle By webmaster

f(n) = str1 + f(n - 1) + str2 + f(n - 1) + str3.

First we can compute the length of f(n) for all possible n.

For a pair of (n, k), we can easily determine which part the k-th character is in.

If it's in f(n - 1), we can solve the problem recursively.

The complexity of this algorithm is O(n), which is sufficient to pass all tests.

Obviously, length(f(n)) ≥ length(f(n - 1))·2, so length(f(60)) ≥ kmax.

It means that for all n > 60, the k-th character of f(n) can only be in str1 or the first f(n - 1).

Then we can answer a query in  time.

896B — Ithea Plays With Chtholly By dogther

As the initial sheet "has already" in a non-decreasing order (although it has no numbers), what we should do is just "maintain" this order.

We use a simple method to do so: find the first sheet whose number is strictly greater than the given number (or it's an empty sheet) and replace it with the new number.

For each round, we either replace an existing number with a strictly smaller one, or fill in an empty sheet. The first case will happen at most c - 1 times for each sheet, and the second case will happen only once for each sheet. Thus in total, we will modify a sheet for at most c times. Thus, the total rounds won't be more than n × c.

To pass all the tests, we only need to maintain 2 similar sequences, one non-decreasing from the first and one non-increasing from the last, which makes a total round of , precisely, and use binary search or brute force to complete the "finding" process.

896C — Willem, Chtholly and Seniorious By ODT

This is an interesting algorithm which can easily deal with many data structure problems------if the data is random...

I initially named it as "Old Driver Tree" ( Which is my codeforces ID ).

(But now I call it Chtholly Tree~).

We can find that there is an operation that makes a range of number the same.

We can use an interval tree (std::set is enough) to maintain every interval that consists of the same number.

And for operation 2, we destory all the intervals in range [l, r] , and put in a new interval [l, r] into the interval tree.

For operations 1, 3, 4, we can brute-forcely walk on the tree, find every interval in range [l, r], and do the required operation on it.

Proof of time complexity:

We suppose that we have a randomly selected range [l, r] now, and we randomly choose which operation it is, suppose that there are x intervals in this range.

1/4 possibility we use O(x) time to erase O(x) nodes.

2/4 possibility we use O(x) time to erase nothing.

1/4 possibility we use O(x) time to erase nothing and add 2 new nodes into the tree.

So we are expected to use O(x) time to erase O(x) nodes.

By using interval tree to maintain, the time complexity of this problem is .

If operation 3 and 4 are changed into output the sum of ai for every i range [l, r], it seems that the time complexity may change into  , but I do not know how to prove it...

Solution using map

896D — Nephren Runs a Cinema By dogther

First let's consider a simpler problem that there are no customers with VIP cards and there are no 50-yuan notes left. For convinence, we suppose that n is an even number. The situation that n is an odd number will be similar.

By defining points (number of customers currently, number of 50-yuan note left) on a 2d-plane, the answer to our second question is the ways of drawing lines from (0,0) to (n,0), such that two adjacent points' y-axis have a difference of 1, and that all the points are above the x-axis.

The total routes will be Cnn / 2, but some of them are invalid. Consider another route starting from (0,-2).

For each invalid way in the previous route, consider the first point (x,y) that y<0 (y=-1).

By creating a symmetry route with y=-1 for the route before this point, this route will become exactly one route starting from (0,-2), and every route starting from (0,-2) will become an invalid route in a similar way.

So the number of invalid routes is Cnn / 2 - 1 (that is the number of routes from (0,-2) to (n,0)). Thus the answer will be Cnn / 2 - Cnn / 2 - 1.

Similarly if there are [l,r] 50-yuan notes left, the answer will be Cnn / 2 - r / 2 - Cnn / 2 - l / 2 - 1.

Now let's enumerate how many customers are there with VIP cards. If there are i of them, the answer will time a factor Cni.

One last question is about the modulo number. First separate it into forms like (p1a1) * (p2a2)... where p1... are primes. We can calculate how many factor pi are there in (j!), and the modulo value of the remaining ones.

Each time we take out a facter pi in (j!), and it becomes some product of numbers that are not divisble by pi as well as a remaining part (j / pi)!. For example, we want to calculate the number of factor 3 in (16!), and the product of numbers that are not divisble by 3 in (16!) mod (3^2). Then we have:

16! = (1 * 2 * 4 * 5 * 7 * 8 * 10 * 11 * 13 * 14 * 16) * (1 * 2 * 3 * 4 * 5) * (3^5)

The first part are not divisble by 3, so we can calculate their value (mod 3^2) in advance, the second part is a smaller problem (5!), so we can solve it recursively. For the number of factor 3, just add 5 in this case and solve it recursively.

After calculating how many factor pi in (j!) and the modulo value of the remaining ones, we can calculate the combnation numbers correctly. Finally use Chinese Remainder Algorithm to combine them.

896E — Welcome home, Chtholly By ODT

I'm really sorry for letting the brute force algorithm pass the tests...

My code uses about 600ms, in order to let some algorithms with large constant or larger time complexity ( like  ) pass, I set the time limit to 3000ms.

The most naive brute forces uses about 8000ms to 9000ms, I added some tricks and the fastest can pass the tests in 5600ms.

In all the contests I've attended, pragma GCC was not allowed to be used...

But on codeforces, this can optimize brute force algorithm from 5600ms to about 2500ms...



Thanks to MrDindows and Shik for teaching me this lesson...

My solution to this problem:

Split the array into  blocks, each containing  numbers.

In each block, for example block x, use f[x][v] to represent the number of v in block x.

For each number i, belong[i] is the the block that i is in.

We need to maintain each number in the block.

This can be maintained by using DSU or linked list.

By maintaining this, we can get the value of every number in a block in  time.

Notice that this two operations are the same:

1.For every number that is bigger than x, decrease it by x

2.Decrease every number by x, and for every number that is less than 1, increase it by x

For operation 1:

We get the value of each number in block belong[l] and belong[r] using the DSU or linked list, then for every number that should change, we change them.

Then we build block belong[l] and belong[r] up again.

For blocks numbered from belong[l] + 1 to belong[r] - 1:

If x × 2  ≤  max value in block p We merge all the numbers in range [1, x] to [x + 1, x × 2], and add x to tag[p] , tag[p] means that all the numbers in block p has decreased by tag[p].

If x × 2  max value in block p We merge all the numbers in range [x + 1, maxvalue] to [1, maxvalue - x].

For operation 2:

We get the value of each number in block belong[l] and belong[r] using the DSU or linked list.

We only need to traverse all the numbers in blocks belong[l] and belong[r], and traverse all the blocks between belong[l] and belong[r].

For block i in range [l, r], f[i][x + tag[i]] is the number of x in block i, so we just need to add this into the answer

Proof of time complexity:

There are  blocks.

The difference between the max number and the min number in each block is initially n. So the sum of this in every block is .

For each operation 1, we use O(x) time or O(max - x) time to make the difference of max and min element O(x) or O(max - x) smaller.

For each operation 2, we traverse  numbers and  blocks.

So the total time complexity if 

There seems to be another algorithm with the same time complexity, and has a smaller constant, but I couldn't prove its complexity so I used this algorithm instead.

My solution



(The missing picture on Div. 1E)

If you don't like it, just skip it please.

Codeforces Round #448(Div.2) Editorial

By NBAH, history, 5 years ago, translation, In English895A - Pizza SeparationWe can notice that if one of the sectors is continuous then all the remaining pieces also form a continuous sector.If angle of the first sector is equal to x then difference between angles of first and second sectors is |x - (360 - x)| = |2 * x - 360| = 2 * |x - 180|. So for each possible continuous sector we can count it's angle and update answer.

Time complexity O(n2) or O(n).

Solution

895B - XK SegmentsFirst, we need to understand how to find the number of integers in [l, r] segment which are divisible by x. It is r / x–(l - 1) / x. After that we should sort array in ascending order. For each left boundary of the segment l = a[i] we need to find minimal and maximal index of good right boundaries. All right boundaries r = a[j] should satisfy the following condition a[j] / x–(a[i] - 1) / x = k. We already know (a[i] - 1) / x, a[j] / x is increasing while a[j] increases. So we can do binary search on sorted array to find minimal/maximal index of good right boundaries and that mean we can find the number of good right boundaries.

Time complexity O(n * log(n)).

Solution

895C - Square SubsetsWe can notice that x is a perfect square of some integer if and only if each prime number enters decomposition of x into prime factors even times. There are only 19 prime numbers less than 70. Now we should find the bitmask for each integer in [1, 70] by the following way: There is 1 in bit representation of mask in k-th place if k-th prime number enters decomposition of that number odd times. Else there is 0. For each integer between 1 and 70 we need to find the number of ways we can take odd and even amount of it from a. Let f1[i], f0[i] be that number of ways relatively. Let dp[i][j] be the number of ways to choose some elements which are <= i from a, and their product has only those prime numbers in odd degree on whose index number j has 1 in binary representation. Initially dp[0][0] = 1.



dp[i + 1][j] +  = dp[i][j] * f0[i + 1]

The answer is dp[70][0].

Time complexity is O(max*2^cnt(max)), where max is maximal integer a[i], and cnt(max) is the number of prime numbers less than max.

Solution

895D - String MarkSuppose that we can calculate the function f(s) equal to the number of permutations of the string a strictly less than s. Then the answer is f(b) - f(a) - 1. Now we need to understand how to find f(s). First we should count the number of occurrences of each letter in the string a, cnt[26].Than we can iterate through the position of the first different symbol in the permutation a and the string s and update the number of remaining symbols cnt[26]. For each such position, we need to iterate through the symbol in the permutation of a which will stand in this position. It must be less than the character at this position in the s string. For each such situation we can calculate and add to the answer the number of different permutations that can be obtained using symbols not currently involved. Their number is stored in cnt[26]. In its simplest form, this solution works in O(n * k2), where k is the size of the alphabet. Such a solution can't pass the tests, but it can be optimized to O(n * k), and that is enough to solve the problem.

Time complexity O(n * k), where k is the size of alphabet.

Solution

Arpa's solution

895E - Eyes ClosedFor each position we need to maintain mathematical expectation of the value on it. Initially, for position i, it is a[i]. Let's process the query of the first type. Each number from the interval [l1, r1] remains on its place with probability (r1 - l1) / (r1 - l1 + 1). The probability that it will be replaced by a number from [l2, r2] is 1 / (r1 - l1 + 1). The mathematical expectation of the number to which it will be replaced is the arithmetic mean of sum of the mathematical expectation of numbers in [l2, r2], let it be x. Then, to update the expectation of a number from [l1, r1], we need to multiply it by (r1 - l1) / (r1 - l1 + 1) and add x / (r1 - l1 + 1) to it. That is, the query of the first type is reduced to the query multiplying all the numbers in a segment and adding to them a number. To process the second type query, you must find the sum of the numbers in the segment. All these queries can be processed with the help of segment tree.

Time complexity O(x + q * log(n))

Solution

Arpa's solution

Codeforces Round #447 (Div.2 Only) Editorial

By whfym, history, 5 years ago, In English894A - QAQSince n ≤ 100, we can iterate on the place of first 'Q','A' and second 'Q'. The brute force solution will work in O(n3) time which can surely pass. If we only iterate on the place of 'A', we can get the number of 'Q' before and after it using prefix sums, and it leads to O(n) solution.

Solution By: Bingheng Jiang (NOIRP)

PS: The characters in problem 894A is Diamond and Bort from Land of the Lustrous.

894B - Ralph And His Magic FieldFirst, it's obvious that the numbers put can be only 1 or -1. If k equals to -1 and the parity of n and m differ, the answer is obviously 0.

Otherwise, for the first (n - 1) lines and the first (m - 1) columns, we can put either 1 or -1 in it, and there're pow(2, [(n - 1) * (m - 1)]) ways in total. Then it's obvious that the remaining numbers are uniquely determined because the product of each row and each column is known already. So in this case the answer is pow(2, [(n - 1) * (m - 1)]) .

Solution By: ZeRui Cheng (Marco_L_T)

894C - Marco and GCD SequenceIf the minimum element isn't the gcd of the given set, the answer is -1. Otherwise, we can insert the minimum element between two consecutive elements of the set. And the length of the sequence is 2n - 1 which satisfies the constraints.

Solution By: Bingheng Jiang (NOIRP)

894D - Ralph And His Tour in Binary CountryBefore answering each query, pre-process on the tree. On each vertice, we can get a sorted array of all the vertices in its subtree sorted by distance to this vertex. And it costs O(nlog(n)) time using merge sort or O(n(log(n))2) time using std::sort. If you use std::sort, you should implement it carefully or it won't be able to fit in the time limit. Because the tree is an almost complete binary tree, one vertex will appear at most [log(n)] times in all n sorted arrays,so the memory complexity is O(nlog(n)).

To answer each query, we can iterate on the highest vertex on the tour and do binary search on the sorted array to get the answer. We'll do at most [log(n)] times of iteration and the binary search is O(log(n)) per iteration, so we can answer each query in O((log(n))2) time.

Overall, the time complexity is O(nlog(n) + m(log(n))2) and the memory complexity is O(nlog(n)). If you use std::sort, the time complexity will be O((n + m)(log(n))2) and the memory complexity is the same.

Solution By: Bingheng Jiang (NOIRP)

894E - Ralph and MushroomsFor collecting the most mushrooms, when in a strongly-connected component we can pass all the edges in the component until the mushrooms on the edges are all 0. So we can run Tarjan's algorithm to find all the SCCs in O(n + m) time and calculate the sum of mushrooms picked in each component by binary search or maths knowledge in O(m) time.

Then we can regard each SCC as a new vertex and get a DAG, and the remaining work is just to find the longest path on the DAG from a given vertex, where the length of an edge is the number of mushrooms in it initially, since we can only pass through it once. We can use topological sort and apply dynamic programming on the DAG in O(n + m) time. Overall, the time complexity is O(n + m).

Solution By: Yiming Feng (whfym)

Hope you had fun in this contest and got high rating!

See you next time!

Codeforces Round #446 Editorial

By Mahdi_Jfri, 5 years ago, In English892A - Greedwe sort the capacities in nonincreasing order and let s = capacity1 + capacity2 if

the answer is no and otherwise the answer is yes892B - WrathThe i'th person will be alive if min(j - Lj) > i over all j > i.

Consider you know the jth person is alive or not if j > i and you have x = min(j - Lj) over all j > i. If x > i then the ith person will be alive.

And you can update x easily.

892C - PrideConsider cnt1 as number of 1s in the a.

If 0 < cnt1 then the answer is n - cnt1.

otherwise We should find a segment with its gcd equal to 1 and minimum length.

consider a segment as (L, R) which L ≤ R and it's gcd as D(L, R)

We fix L and then iterate through all R in order. Consider we know that D(L, R) = G then D(L, R + 1) = gcd(G, A(R + 1)).

If D(L, R) = 1 then you can make all the elements in (R - L + 1) + (n - 1).

Answer is minimum possible D(L, R) over all possible segments.

891B - GluttonySort the array and shift it by one. This array will be an answer.

Proof:

When we shift the sorted array all of the elements become greater except the first one, consider f = {1, 2, ..., n} and t = {x1, x2, ..., xk} if 1 wasn't in t we would have

otherwise consider q = {y1, y2, ..., yn - k} = f - t then 1 can't be in q and we have

so

and we are done!891C - EnvyIt can be proven that there's a MST containing these edges if and only if there are MSTs that contain edges with same weight. So for each query we need to check if the edges with weight X have a MST. For checking this, if we remove all edges with weight greater than or equal to X, and consider each connected component of this graph as a vertex, the edges given in query with weight X should form a cycle in this new graph.

We can check this for all queries offline by sorting edges from minimum weight and do simple dfs for each weight in each query.

891D - SlothIf graph had odd number of vertices the answer is 0. Otherwise let's call edges that by removing them the remaining graph would have two even components good, and all the other edges are bad.

If you remove a good edge and put another edge somewhere such that the final graph is a tree, then it would have prefect matching if and only if the input tree had prefect matching.

If no two bad edges share a vertex, after removing a bad edge (lets call it X) we should chose the end points of the edge we want to add (lets call them v,u) such that the path between v and u in the input tree has alternately bad and good edges, the first and the last edges in the path are bad and X is in this path too. So for any path in the tree that has alternately bad and good edges and the first and final edges in it are bad we should add the  to the answer. This can be done using dp.

If there are bad edges that share vertices, we know that each vertex has odd number of bad edges to its neighbors, and if this number is greater than 3 then the answer is 0. So each vertex has 1 or 3 odd edges to its neighbors. The path between end points of added edge should contain all the vertices with 3 bad edges and also two of their bad edges should be in the path. So if the vertices with 3 bad edges aren't in a path with this condition then the answer is 0 and otherwise we can calculate the answer by checking some conditions in their path and counting the number of paths with some condition at the end points of their path.

also there's another solution using dp by KAN : 32407269

891E - LustLemma : expected value of res is equal to multiply of ais minus expected value of multiply of ais at the end of process. Prove : Imagine that at the end of process, ai turns to bi (bi ≤ ai). For this case, it is easy to prove that res is equal to multiply of ais minus multiply of bis (can be proved by induction). So we can see truth of lemma.

Define dpmask, k as expected value of multiply of mask's subset after k'th repeat. Now we want to calculate this dp. Fix index of k'th chosen number. If mask's subset contains that fixed number, then expected value of multiply of mask's subset decreases by expected value of dpmask2, k - 1 (mask2 is equal to subset of mask minus chosen fixed number). If mask's subset doesn't contains fixed index, then expected value of multiply of mask's subset doesn't change. More formally , for all indices i from 1 to n :

. (If mask contains i'th element).

 (If mask dosent contains i'th element)

So we can write :

dpmask, k +  = dpmask, k - 1

 (If mask contains i'th element)

After calculating this dp, we can find expected value of res, using lemma and dp2n - 1, k. This algorithm runs in O(2n * k * n). Now we want to optimize this solution. First of all, we can calculate this dp , using matrix exponential; because dpmask, k updates by a coefficient from dpmask2, k - 1. so if we write coefficient of update dpmask, k from dpmask2, k - 1 in matrixmask, mask2 , and write multiply of mask subset if emask, then 2n - 1'th element of matrixk * e, equals to expected value of ais after k'th repeat process. After his optimization, algorithm runs in O(23n * lgk).

In our second solution, we learned that expected value of multiply of ai's after k'th operation (name it as s) equals to 2n - 1'th element of matrixk * e. this element equals to . Now we want to calculate coefficients of matrixk2n - 1. by this coefficients, we can calculate value s. if we take a look at update of dpmask, k, we can define another meaning for this dp. imagine directed hypercube Qn and add a self loop for every vertex. now dpmask, k, can be this : for every walk that ends in mask in k moves, add  to dpmask, k. So it's easy to see that all masks that have equal number of elements, have equal dpmask, k. (regardless of base of dp) So matrixk2n - 1, mask is equals to this value for walks from mask to 2n - 1. Now, by fixing non self loop edges, we can see that matrixk2n - 1, mask is equal to :



So this value is equal for all masks with equal ones. name this value by Znumberofonesinmask. By our equation :

matrixk2n - 1, mask * emask (for 0 ≤ mask < 2n)

Znumberofonesinmask * emask (for 0 ≤ mask < 2n)

(for 0 ≤ w ≤ n)

So Zw’s can be easily calculated in O(n). Now we want to calculate  (for all masks with w ones). (for 0 ≤ w ≤ n). This value can be calculated by dpi, j (sigma of j_tuples multiplies in first i elements) in O(n2). So, finally, this algorithm runs if O(n2 + lg(k))

Editorial Codeforces Round 445 (and Technocup 2018 — Elimination Round 3)

By komendart, history, 5 years ago, In English886A - ACM ICPCIn this problem it's enough to iterate through all the triples checking whether its sum equals to the sum of remaining triple or not. Answer is "YES" if equality is possible and "NO" — otherwise.

886B - Vlad and CafesThere are two steps to solve this problem:

1. Put in array last the last time when Petya visited each cafe.

2. Now you need to find the position of minimum in this array and print it.

886C - Petya and CatacombsFirst, we notice that if journal contains two equal notes ti = tj, i < j, then at least one of them was made in newly visited room, because otherwise tj would be at least i. Thus there could be at most one note corresponding to previously visited room among equal notes.

Let's denote by cnti number of occurrences of i in the journal. From the previous statement we deduce that minimum possible number of rooms is at least . Also, it's easy to see that this value can be achieved: we say that first occurrence of each value corresponds to revisiting the previous room and all other correspond to visiting new rooms.

So the problem can be solved by calculating values cnti for each i between 0 and n and calculating the above sum.

Overall complexity – O(n).

886D - Restoration of stringIf some string is the most frequent then all its substrings are the most frequent too.If string ab or similar is the most frequent then letter a is always followed by letter b and b always follow a.Let's consider directed graph on letters where edge a → b exists only if ab is the most frequent. If there is cycle in such graph then good string doesn't exist.So such graph can be represented as several non-intersecting paths. All strings which correspond to paths must occur in non-empty good string. So if we print them in lexicographical order then we will get the answer.886E - Maximum ElementYou asked to find the number of permutations p of length n such that exists index i, such that pi ≠ n, pi is greater than any pj for j in [1, i - 1] and greater then any pj for j in [i + 1, i + k]. We will call such permutations good.

Define D(n) as number of good permutations that have pn = n. Notice that if k ≥ n, then D(n) = 0. Let w be a permutations such that wn = n. If index of element n - 1 is lesser than n - k, then w is good. Otherwise if n - 1 index is j, j ≥ n - k, then because there are less then k elements between n - 1 and n, w could be good only if i from the definition would be lesser than j. In that case permutation w1, ..., wj would form a good permutation of length j of some numbers with wj being the maximum.

Therefore the following equation is correct:

Which can be computed in O(n2), or in O(n) rewritten in the form

and using prefix sums for values .The answer is than calculated as follows:

Complexity: O(n).

886F - Symmetric ProjectionsLet us note that projection of set of points to line move center of mass of initial set to center of mass of initial set to center of mass of projections multiset. So if the line is good then the center of mass of initial set move to center of symmetry. Also If there is two points, which are symmetric with respect to center of mass then they will be symmetric under the projection on arbitrary line. So we can throw away these points.

Fix arbitrary point from remaining set. Let us take point from set, which will be symmetric to the fixed point. There is only one line, which has property, that two projections of chosen points are symmetric: the line, which is perpendicular to line passing through the center of mass of initial set and center of segment connecting two chosen points. So we have no more then n candidates which can be a good line. It is possible to check, that line is good, in O(nlogn) time.

Time: 

889E - Mod Mod ModHint 1: let . Can you define some interesting segments of value xi?

Hint 2: think of some dp.

Hint 3: once you get the dp in O(n2), to speed it up, note the following fact: if , then either c = a or .

Explanation of hint 1: let's call ansi = f(x, 1) - f(xi, i + 1), in other words, it's the part of answer we gain from summands from 1 to i. For i = 1 the following is true: x1 can be any number from 0 to a1 - 1, and ansi = xi.

Suppose for some i we have the following option: xi can be any number from 0 to r, and in this case ansi = xi * i + k. We can describe this situation by triple (i, r, k). We will show that this triple will produce at most two such triples for i + 1. Indeed, we can have many triples (i + 1, ai + 1 - 1, kj) with different kj and one triple . However, we can note that among triplets of the first type we can leave only one with maximum kj, because we're interested in maximum answer. This kj will equal . Thus, we have two transitions from each triple, that leads us to O(2n) bruteforce solution.

Explanation of hint 2: when we have a bruteforce, we (almost) always can think of a dp. Indeed, we have triples, among those with equal i and r let's keep only one with the largest k. There are at most i such triples on step i: on each step half of the generated triples have r = ai + 1 - 1, so we can merge them. This leads us to dp in O(n2).

Explanation of hint 3: Okay, what does the third hint say? It basically says that a number can only be taken by modulo  times until it becomes zero, where C is the bound of its initial value. What do we get from this? We can note that if r < ai + 1, we can just leave a triple (i, r, k) untouched except changing i to i + 1. Let's then keep pairs (r, k), assuming triples (i, r, k), where i changes in a cycle. On each step we should change all pairs such that r ≥ ai + 1, possibly adding one more pair with r = ai + 1 - 1. But when we change a pair, r is get by modulo, so this won't happen with a pair more than O(log(C)) times! Overall, the total number of times we touch a pair is bounded by . Adding  for map in which we keeps the pairs, we obtain the final complexity . Also, map can be replaced with binary search, but the complexity remains the same.

Codeforces Round #444 (Div. 2) Editorial

By Denisson, history, 5 years ago, translation, In EnglishOnce again we apologize for making mistakes during preparation.

887A - Div. 64Author: .tx.

If the string contains no ones then the answer is "NO" as the remainig number must be positive. Otherwise we can find the leftmost one and check if it is followed by at least six zeroes.

Solution.

887B - Cubes for MashaAuthor: .tx.

The answer is always less or equal to 98. We can go through numbers from 1 to 99 and find the first one which we cannot make using cubes.

Solution.

887C - Solution for CubeAuthor: .tx.

The amount of variants of input data for which the answer is "YES" is not more than 12 without considering rearrangement of colours. They all could be written in an array.

The alternative solution is writing a function of rotating a specific edge of the cube and checking if it is solved.

Solution. Denisson

Solution. .tx

887D - Ratings and Reality ShowsAuthor: .tx.

We can create two arrays of prefix sums of events given in input. The first one on values (a, b) and the second one on values (c, d). The answer is either 0 or the moment of time right after an event occured. Let's use the method of two pointers. One pointer will indicate an event V after which we want to participate in the talk show and the other one at the moment of time right after its influence ends. Then we can participate in the talk show if the minimum of prefix sums on values (c, d) from elements between pointers is not less than the difference of prefix sums on values (a, b) and (c, d) from element V. Also we must check that Izabella's rating doesn't become negative before participating in the talk show or during its peroid of influence.

Solution. Denisson

Solution. .tx

887E - Little BrotherAuthors: .tx, Denisson.

The center of required circle is on a perpendicular to the middle of the segment AB where A and B are two points from the input. If a circle with the center on the segment AB and the radius equal to half of its length satisfies the conditions then it is the answer. Otherwise we can find on which side relative to AB the center of the circle is. Every drawn circle blocks a continious interval of allowed values for the requierd circle. The limits of this interval can be found by using binary search. Now we have to find the least allowed value for the radius. It can be done, for example, by using method of scanning line.

Solution. Denisson

Solution. .tx

Solution. cdkrot

887F - Row of ModelsAuthor: Denisson.

For every element of an array ai we can check x elements on its right. If there are no elements less than ai we will mark it as "-1" and call it "bad". If there is exactly one element then make an edge from ai to this element. Otherwise swapping elements of the array will never make ai "bad". If there are no "bad" elements in the array then the answer is "YES". Otherwise we should find the leftmost "bad" element in the array bad. X elements after it are not less than itself. All elements before it are also not less than itself because otherwise an element less than bad would be "bad" too. Swapping bad with an element in suffix also makes no sense because its place will be taken by lesser element and the position will remain "bad". Thus, swapping bad with other element of the array makes no sense. The only way to satisfy the conditions is to swap one of x elements after bad with other element in the remaining suffix without considering a segment with length x after bad. Let's try to do it obviously. Then the following conditions must be satisfied. Consider choosing an element y in the remaining suffix. Then the swap can be the answer if y < bad. Also suffix after y and the segment between y and the segment with length x after bad must not contain "bad" elements. An element, which we swap y with, from the segment with length x after bad must be less than any adress on y. Also we need to check that after the swap on the right side of y we can find an element less than itself no further than x.

Time: O(n) or O(nlogn).

Solution. Denisson

Solution. Denisson

Codeforces Round #443. Editorial

By khadaev, 5 years ago, translation, In EnglishDiv 2 A879A - Borya's DiagnosisNote that Borya can use a greedy algorithm. He will visit each doctor as soon as possible. We only need to find the earliest day when he can do it. Constraints are pretty low, so we can use almost any reasonable way.

For example, we can just go through all the days, starting from the current one, and check if the doctor is working on that day. At the step i we need to go through at most max(si, di) days.

There is a more efficient way. We can find the smallest x that is greater than the current day, such that , in O(1). If x ≥ si, Borya will visit a doctor on day x, otherwise on day si. This solution is O(n).

Div 2 B879B - Table TennisIt's not very difficult to solve this problem in O(k + n). The statement hints us that we can use the data structure queue. We need to maintain the queue of players, the current winner and the number of wins he has. Each game is processed in O(1). It can be shown that number of games is less than n + k.

Of course, this solution is too slow. Let's think what happens if k is large. More precisely, assume that k ≥ n - 1. The winner need to win at least n - 1 games in a row, that is, he need to win against all the other players. Hence, the winner is just the strongest player.

So, if k ≥ n - 1, we can solve the problem in O(1). Otherwise simulation works in O(n).

Div 2 C = Div 1 A878A - Short ProgramLet's see what happens with a single bit. All operations work with each bit separately, so each bit of output depends only on the corresponding bit of input.

There are only four options: bit doesn't change, bit always changes, bit is set to 0, bit is set to 1. For each bit it's easy to find which of these options happens to it.

Now let's write a program of three lines:

Use XOR with a number that has ones in bits that must be reversed.Use OR with a number that has ones in bits which must be set to 1.Use AND with a number that has zeroes in bits that must be set to 0.It's easy to see that this program is equivalent to Petya's program.Depending on the implementation, it may works in O(n) or .

BONUS: solve a problem using at most two commands.

Div 2 D = Div 1 B878B - Teams FormationFirst, let's see what happens inside one bus. We can use a stack containing pairs (city, number of participants from it). When the number of participants reaches k, we erase the pair.

Suppose we build this stack. r is its size, (ci, di) are pairs in it. Now consider the interaction of two such buses. At the border, a team is formed, if c1 = cr and d1 + dr ≥ k. If the inequality becomes an equality, then another team can be formed from the second and penultimate groups, etc. Let's find the greatest p such that for each i = 1... p we have ci = cr + 1 - i and di + dr + 1 - i = k. Since the condition on i is symmetric with respect to , if p ≥ ⌈ r / 2⌉, then p = r.

Consider the case p = r separately. This means that the two buses are completely divided into teams. If m is even, answer is zero, otherwise answer is the sum of di.

Also, consider the case when r is odd and p = ⌊ r / 2⌋. In this case, after removing all teams at the borders of the buses, the queue looks like: left part of the first bus — mdp + 1 people from the cp + 1 city — right part of the last bus. If the number of people in the middle is divisible by k, then they will be divided into the commands, and the first half will unite with the last, and the answer is zero. If it doesn't, then some teams will be formed in the middle, and the process will end there.

Finally, if r is even smaller, it can be seen that after the formation of teams at the borders of buses the process will end.

Div 2 E = Div 1 C878C - TournamentImagine a directed graph, in which the vertices are participants, and the edge means that one participant can win the other in some kind of sports. A participant can win a tournament if there is a directed tree in this graph that contains all vertices, and this player is a root.

Consider the condensation of this graph. Since for any two vertices there is an edge at least in one direction, condensation is a path. It is clear that the required tree exists if and only if the root lies in the first strongly connected component.

We will maintain these strongly connected components. For each of them we will store its size, the greatest power and the smallest power in each kind of sports.

What happens when the new sportsman is added? He can defeat the component if in some kind of sports he is stronger than the minimum in this component. Similarly, he can lose to a component if in some kind of sports he is weaker than the maximum in this component. We need to find the weakest of those components that he can lose, and the strongest of those components that he can defeat. If the first component is stronger than the second, the new sportsman forms a new component. Otherwise, all the components between the first and the second merge into one, and the new sportsman joins it.

How to do it effectively? We will store the components in a some search tree and use the comparison by minimum in the first kind of sports as a comparator. It's easy to see that if you take any other sport or replace a minimum with a maximum, any two components will be compared in the same way. All we need is binsearch by one of the mentioned comparators: minimum or maximum for one of the kinds of sports.

At each step the number of operations with the tree is O(k) + k· number of components merged into one. At each step at most one component can be added, so the amortized time of one step is .

Overall time complexity is .

Div 1 D878D - Magic BreedingLet's consider a special case of the problem: all aij are 0 or 1. In this case there are at most 2k different characteristics. So we can use trivial solution, it works in O(q2k). Also we can sped up it using bitset.

Now we reduce the problem to this special case. We have a characteristic with values x1 ≤ x2 ≤ ... ≤ xk. Let's make k characteristics from it. i-th of them is one if and only if the original characteristic is at least xi, and zero otherwise. New characteristics behave correctly during our operations, and we can efficiently get old characteristics from them.

Number of characteristics has increased, but is doesn't matter for our solution for the special case. This solution works in O(q2k).

Div 1 E878E - Numbers on the blackboardLet's find a strategy for Sasha. His result can be represented in the form , where k1 = 0, 1 ≤ ki ≤ ki - 1 + 1 for i > 1.

For all ki satisfying these conditions he can obtain such result. We prove this by induction. For n = 1 is't obvious. Let n > 1. Find the greatest i such that ki = 1. It always exists cause k2 = 1. By the induction hypothesis we can get k1, k2... ki - 1 and ki - 1, ki + 1 - 1... kn - 1. Do this and merge them with the last move.

Now we describe the strategy. Let the last number be negative. Then Sasha wants to minimize kn. He always can use kn = 1. If tha last number is non-negative, he can use kn = kn - 1 + 1. In this case, Sasha first merges the last two numbers. Thus, the sequence ki consists of several blocks, in each of which ki + 1 = ki + 1, and each of the blocks except the first begins with 1.

Now we need to answer queries. We will do it offline. On the step i add the number ai and and answer all queries with r = i. We will support the blocks for the query [1, i].

What happens when we add a number? If it's negative, it simply forms a separate block. Otherwise it becomes the end of some block. It is easy to see that the new block is the union of several old blocks.

How to answer queries? [l, r] is the union of some blocks and a suffix of another block. We can see that this is the partition into blocks for our query.

How to do it fast? We will store the boundaries of blocks to do binary search on them and find the block in which the l lies. We need to store the results for each block and prefix sums of these results. Also we need to find sums  to find out results for suffixes.

Each step is processed in  except for merging blocks. But we create at most one block on each step, so amortized time of each step is .

Also in this problem we need to be careful with overflows. Although we need to find the result modulo some prime, in some places the sign is important. We can use that if |y| is more than maximum ai, then x + 2y is also big and have the same sign.

BONUS: solve this problem online.

БОНУС: solve it in O(nα(n)).

Codeforces Round #442 (Div. 2). Editorial.

By Livace, history, 5 years ago, translation, In EnglishMassive thank you to all who partisipated. It's really important for me. If you still have questions after reading editorial, feel free to write me using codeforces/vk/gmail.

877A - Alex and broken contest

tutorial877A - Alex and broken contestYou need just implement what is written in the statements. Count the total number of entries of the names and check if it's equal to 1.

877B - Nikita and string

tutorial877B - Nikita and stringLet prefa[i] be the count of letter "a" in prefix of length i and prefb[i] be the count of letter "b" in prefix of length i.

Let's fix two positions i and j, 1 ≤ i ≤ j ≤ n, so we remove all "b" from prefix, which ends in i, and suffix, which starts in j, and all "a" between positions i and j. Then length of string is (prefa[n] - prefa[j]) + (prefb[j] - prefb[i]) + (prefa[i]).

Using two for loops we find optimal i and j and calculate answer.

877C - Slava and tanks

tutorial877C - Slava and tanksLet's call the tanks, which are initially in even positions even, and the tansk, which are initially in odd positions odd.

Let's throw bombs in all even positions. Now all tanks are in odd positons. Now let's throw bombs in all odd positions. Now all even tanks are exterminated and all odd tanks are in even positions. Throw bombs in all even positions again. Now all tanks are extemintated.

It's not hard to prove that this strategy is optimal.

877D - Olya and Energy Drinks

tutorial877D - Olya and Energy DrinksNote, that bfs can find right answer, but works in O(n·m·k). It's too slow.

We'll store all not visited cells in set. For each row and column we'll make own set. Now it's easy to find all not visited cell which is reachable from vertex in O(cnt·log(n)), where cnt is number of this cells. Then summary it works in O(n·m·log(n)).

877E - Danil and a Part-time Job

tutorial877E - Danil and a Part-time JobLet's construct Euler tour tree. We'll put vertex in vector when first time visit it. For each vertext subtree is segment in this vector, borders of which we can calculate while constructing.

Now we need to make inversion on segment and get sum of segment. Segment tree is good for it.

877F - Ann and Books

tutorial877F - Ann and BooksIf i-th book is on economics, a[i] =  - a[i]. Now problem is to calculate count of segments of sum k.

Calculate prefix sums: . Then .

Now we can solve it in O(n·q·log(n)). We'll go along the segment and calculate cnt[i] — number of occurences of i in segment. Then we'll add cnt[p[i] - k] to answer. p[i] can be big enought, so we should use something like map. This is where the logarithm comes from.

Note, that we can easily move both borders to the left and to the right. Then we can solve it using Mo's algorhitm in O(q·sqrt(n)·log(n)). Unfortunatelly, it's still too slow.

Let's use coordinate compression. For each prefsum calculate v[i] — compressed value of p[i], l[i] — compressed value p[i] - k and r[i] — compressed value p[i] + k. It allows us to get rid of logarithm.

Codeforces Round #441. Editorial.

By vintage_Vlad_Makeev, history, 5 years ago, translation, In English876A - Trip For MealIf minimum of numbers a, b, c equals a or b, or n = 1. Then answer equals min(a, b)·(n - 1). Otherwise answer equals min(a, b) + c·(n - 2).

Also there is solution that uses dynamic programming.

(Idea — Jury of the Olympiad, developing — Andreikkaa)

876B - Divisiblity of DifferencesIf x - y is divisible by m, then x and y have same reminder when divided by m. Let's divide number to groups by reminder by modulo m, and if there is a group with size at least k print k numbers from it.

(Idea and developing — Kniaz)

875A - Classroom WatchFor numbers that doesn't exceed 109 sum of digits doesn't exceed 100, so we can just iterate over all possible sums of digits x and check if sum of digits of n - x equals x.

(Idea and developing — Sender)

875B - Sorting the CoinsWe denote, for 0, a coin that has left circulation and for one coin in circulation.

We solve the problem for a fixed array. If it consists of only 1, then the answer is 0, since the array is already sorted. Otherwise, consider the most right zero. If there is not a single 1 to the left of this zero, then the array is already sorted and the answer is 1.

Let 1 appears k times to the left of the rightmost zero. For one iteration the nearest 1 on the left will move to the position of this zero, and zero will move one position to the left. After this iteration, k - 1 ones will remain to the left of the rightmost zero. Hence the answer is k + 1.

Let us return to the original problem. We will keep the pointer to the rightmost zero. Since as a result of queries the zeros only disappear, the pointer moves only to the left. If the rightmost zero has disappeared, move the pointer to the left by a cycle, until we find the next zero.

Consider pointer is at the position x (numeration from zero), and there are only p ones in the array. On the right of x all the symbols are ones so on the right there are only n–x–1 ones. So on the left are p–(n–x–1) ones.

This solution works in за O(n + q).

(Idea — glebushka98, developing — ch_egor)

875C - National PropertyLet the strings si and si + 1 are not prefixes of each other. Then it is necessary that si, k < si + 1, k, where k is the first position, where si and si + 1 differ.

Consider strings si and si + 1. Let k be the first position in which they differ. Then there are two cases:

If si, k > si + 1, k, you capitalize si, k and not capitalize si, k + 1.

If si, k < si + 1, k, both these letters should be capitalized or not capitalizes simultaneously.

Let's make a graph in which letters will be vertexes. If si, k > si + 1, k, then mark si, k as capitalized, otherwise make a directed edge between si + 1, k and si, k. It means that if we capitalize si + 1, k, you also should capitalize si, k.

Note that our graph is acyclic because the edges are directed from big letters to small letters. Using dfs we capitalize all the letters, that are reachable from the capitalized letters and check the answer. If the answer is wrong, there is no answer.

(Idea — GlebsHP, developing — Flyrise)

875D - High CryFirst we find for each element the nearest element on the left and on the right more than it. It can be done by many ways, for example using stack.

Then you find for each element x the nearest on the left and on the right element y so that x|y > x. For this note that in y must be some bit set, which is not set in x. So you can just pass from left to the right (and then from right to the left) along the array, calculating goi — the nearest on the left (on the right) element in which the bit i equals 1.

We fix the mountain which will be the highest on the segment from the answer (if the heights are equal — the most left, for example). Then the segment must be completely nested in the segment on which the given mountain is the highest and must cross at least one element, OR with which our element is greater than the element itself.

This solution works in O(n) + O(nlogc) + O(n) = O(nlogc).

(Idea and developing — mingaleg)

875E - Delivery ClubWe will learn to check that the answer is no more p. If we learn to do this, we can make a binary search for the answer and get the answer.

To check we calculate dpi — is it possible to process the first i orders so that the last order of one courier is i, and the second order is i + 1. In this case, the transition can be done immediately by several steps forward.

Transition from i to j means that the first courier will execute the orders i + 1, i + 2, ... j - 1, and the second — the order with the number j.

The transition can be made if |xj - x{j - 1}| ≤ p and |xk - x{i - 1}| ≤ p for all k from i to j - 1.

It may be rewritten as xi - 1 - p ≤ xk ≤ xi - 1 + p, and so the maximum j for given i can be found using segment tree or analogical structure.

After that you only set dpj = 1 to all possible j on the segment. It can be done for example going along the massive and knowing maximum segment of possible j.

The solution works in O(nlognlogANS).

(Idea — Endagorion, developing — kraskevich)

875F - Royal QuestionsConsider bipartite graph in which princesses are in the left part and princes in the right part.

Because of the propriety of transversal matroid you can choose princesses greedily: let's sort princesses according to decrease in size of dowry and in this order try to add to matching. It can be done at O(nm) every time finding alternating chain. But this solution can be speed up.

Let's try to attribute to each (not isolated) vertex of right part the most expensive vertex of left part. If resulting set of edges is a matching it will be the solution. The set of edges can not form matching only if in the left part there are some vertexes for which both edges are taken. Let's name these vertexes "popular". Suppose that we didn't take any popular vertex in the optimal answer. Then you can take any its neighbor from right part and improve the answer. That' why weight of popular vertex can be added to the answer and remove it from the graph uniting its neighbors to one vertex. This vertex will describe the prince who has not got popular princess.

As in the previous case we'll consider vertexes of left part in descending order and the vertexes of right part we will keep is disjoint set union. If the current vertex of right part has two neighbors in right part, we add its weight to the answer and unite its neighbors in DSU. In the vertex has one neighbor in right part, we add the weight of vertex to the answer and remove the vertex of right part. Otherwise we don't add the weight of vertex to the answer.

Solution works in O(nlogn).

(Idea and developing — wilwell)

Editorial Codeforces Round 440 Div.1+Div.2 (and Technocup 2018 — Elimination Round 2)

By komendart, history, 5 years ago, translation, In English870A - Search for Pretty Integers Idea, preparation, editorial komendart

870B - Maximum of Maximums of Minimums Idea DPR-pavlin, preparation, editorial mHuman

870C - Maximum splitting Idea, preparation, editorial komendart

870D - Something with XOR Queries Idea, preparation, editorial mHuman

870E - Points, Lines and Ready-made Titles Idea, preparation, editorial komendart

870F - Paths Idea, preparation, editorial komendart

871E - Restore the Tree Idea MikeMirzayanov, preparation fcspartakm, editorial mHuman

Also many thanks to coordinator KAN, testers ifsmirnov, vintage_Vlad_Makeev, AlexFetisov and any other people who participates in preparation of contest.

870A - Search for Pretty IntegersNote that the length of the answer does not exceed two because we can take one number from the first list and one number from the second lists and make up of them a pretty number. So we need to check two cases:

1) Iterate through the digits from the first list and check if digit belongs to the second list too. Make up the number of this digit.

2) Iterate through the numbers from the first list and from the second list. Make up the number of this two digits. There are two ways: digit from the first list, then from the second list and vice versa.

Then you should choose the minimal number.

Code (C++) 31365874

Code (Python) 31365844

870B - Maximum of Maximums of MinimumsTo solve the problem, we need to consider three cases:

k ≥ 3:  then let pos_max be the position of the element with the maximum value, then it is always possible to divide the array into subsegments so that one subsegment contains only this number, so the answer to the problem is apos_max.

k = 2:  then all possible partitions are some prefix of nonzero length and coresponding suffix of nonzero length. You can iterate through all positions of the prefix end, and сalculate the answer for this fixed partition, that equals to maximum of minima on the prefix and on the suffix. Minimum value for all suffixes and prefixes can be counted in advance. The answer is the maximum of the answers for all possible partitions.

*Also it can be proved that for k = 2 the answer is the maximum of the first and last element.

k = 1:  then the only possible partition is one segment equal to the whole array. So the answer is the minimum value on the whole array.

Code 31366254

870C - Maximum splittingNote that minimal composite number is equal to 4. So it is quite logical that there will be a lot of 4 in splitting of big numbers. Let's write for small numbers (1 ≤ M ≤ n) dpn  – number of composite summands in splitting of n.

If our query n is small number let's print dpn. Else let's find minimal number k such that n - 4·k is small number. Then print k + dpn - 4·k.

We can find dpn in O(M2) or any other reasonable complexity. We even can find all dpn by hands if we set M to 15 or something like that (it will be proved later that 15 is enough).

So now we have right solution but it is not obvious why this solution works.

Proof (not very beautiful but such thoughts can lead to correct solution):

Let's find answer for all numbers from 1 to 15. Several observations:

1) Only 4, 6, 9 occurs in optimal splittings.

2) It is not beneficial to use 6 or 9 more than once because 6 + 6 = 4 + 4 + 4, 9 + 9 = 6 + 6 + 6.

3) 12, 13, 14, 15 have valid splittings.

Let's prove that all numbers that are greater than 15 will have 4 in optimal splitting. Let's guess that it is incorrect. If minimal number in splitting is neither 4 nor 6 nor 9 than this number will have some non-trivial splitting by induction.

If this number either 6 or 9 and we will decrease query by this number then we will sooner or later get some small number (which is less or equal than 15). There is no splitting of small numbers or it contains 4 in splitting (and it contradicts with minimality of the first number) or it contains 6 and 9. So we have contradiction in all cases.

We can subtract 4 from any big query and our solution is correct.

Code 31365909

870D - Something with XOR QueriesThe statement: those and only those permutations whose answers to the queries (0, i) and (i, 0) for all i coincide with the answers given to the program, are suitable for all possible queries.

The proof: , which means that with the answers to the queries (0, i) and (i, 0) you can restore the answers to all other queries.

If we fix the value b0, then we can restore the whole permutation, since we know the answers to the queries (i, 0), and .

You can iterate through the value b0, restore the whole permutation, and if there were no contradictions in it (that is, every number from 0 to n - 1 occurs 1 time) and for all i values  and  coincide with the answers given to the program, then this permutation is indistinguishable from the hidden permutation.

The answer is the number of such permutations, and one of such permutations.

Code 31366223

870E - Points, Lines and Ready-made TitlesLet's build graph on points. Add edge from point to left, right, top and bottom neighbours (if such neigbour exist). Note that we can solve problem independently for each connected component and then print product of answer for components. So we can consider only connected graphs without loss of generality.

Let's define X as number of different x-coords, Y as number of different y-coords.

What if graph contains some cycle? Let's consider this cycle without immediate vertices (vertices that lie on the same line with previous and next vertices of cycle). Draw a line from each such vertex to the next vertex of cycle (and from last to the first). We got all lines that are corresponding to x-coords and y-coords of vertices of cycle. Let's prove by induction that we can got all such lines from the whole graph

Run depth-first search from vertices of cycle. Let we enter in some vertex that is not from cycle. It mush have at least one visited neighbour. By induction for graph consisting of visited vertices we can get all lines. So there is line from visited neighbour. Draw line in another direction and continue depth-first search. Sooner or later we will get all lines for the whole graph. Please note that intermediate vertices of cycle will be processed correctly too.

If we can get all lines the we can get all subsets of lines. Answer for cyclic graph is 2X + Y.

Now look at another case  — acyclic graph or tree. We can prove that we can get any incomplete subset of lines.

Let's fix subset and some line not from this subset. Just draw this line without restriction. By similar induction as in cyclic graph case we can prove that we can get all lines (but fixed line doesn't exist really).

Now let's prove that it is impossible to take all lines. For graph consisting of only one vertex it is obvious. Else fix some leaf. We must draw a line which are not directed to any neigbour because it is the only way to draw this line. But now we have tree with less number of vertices. So our statement is correct by induction.

Answer for tree is 2X + Y - 1.

So the problem now is just about building graph on points and checking each component on having cycles.

Code 31365959

870F - PathsInteger 1 ≤ x ≤ n is bad is x = 1 or x is prime and x > n / 2. Otherwise integer is good.

primex for 1 < x ≤ n is minimal prime divisor of x.

Path between two vertices doesn't exist if at least one of them is bad.

Distance equals to zero if this two vertices are the same.

Distance equals to one if their numbers have common divisor.

Distance between vertices u and v equals to two if primeu·primev ≤ n.

Otherwise distance is three because path  always exists.

It is easy to find number of pairs of vertices between which there is no path.

Number of pairs with distance 1 equals to sum over all good x of expressions x - 1 - φ(x).

Number of pairs with distance 3 can be found if we subtract number of pairs without path and number of pairs with distances 0 and 1 from number of all pairs.

So it only remains to find number of pairs with distance 2. Let's divide such pairs on three types

1) Pairs of coprime composite numbers.

2) Good prime p and good number x such as primep·primex ≤ n and x is not divided by p.

3) Two different good prime numbers, product of which is less or equal than n.

Number of pairs with distance 2 equals to number of pairs of the first and the second types minus number of pairs of the third type.

Number of pairs of the first type equals to sum over all composite 1 ≤ x ≤ n of expressions φ(x) - ((number of noncomposite numbers which are less than x) - number of unique prime divisors of x).

For the second type we should sum up over all prime p number of good numbers x such that primep·primex ≤ n and subtract number of such numbers divided by p. The first we can calculate with some additional precalculations, for the second we can just check all numbers divided by p.

Number of the pairs of the third type can be found trivially.

For other details please see the author's code.

Code 31366002

871E - Restore the TreeIn the beginning, it should be noted that it is possible to find out numbers of vertices from which distances are given, the number of the ith specified vertex is idi, such that di, idi = 0. If there is no such a vertex, or more than one, then there is no answer.

Fix the root equal to some vertex from which distances are given in the input data. Assume root = id1. For any vertex idi, we can find vertices lying in the path from root to this vertex, since for such and only for such vertices d1, v + di, v = d1, idi. And accordingly, the vertex v suitable for this condition will be at a distance d1, v from root. So, we have learned to build a part of a tree that consists of vertices that lie on the path from root to some vertex idi. If we couldn't build the path in such a way, then there is no answer. Time complexity of this phase is O(nk).

Now consider the remaining vertices, in order of increasing depth (distance to the root). Let's consider a fixed vertex v, look at the path from it to root, this path can be divided into 2 parts - (root, u), (u, v) where u is the vertex from the already constructed tree, let's find the deepest of such u, this can be done with O(k) operations by using the fact that u is the deepest vertex among all lca(v, idi), which equals the vertex on the path from root to idi at a depth of d1, idi + d1, v - di, v. Then the ancestor v is the vertex that was added in the same way to the subtree u but with a depth of 1 less, or the vertex u (if the depth u is 1 less than the depth of the vertex v). If no such vertices have been added yet, then there is no answer, since we considered the vertices in order of increasing depth. Time complexity of adding each vertex is O(k).

The resulting tree is also the desired tree. Time complexity of the whole algorithm is O(nk).

Code 31368704

Codeforces Round #439 (Div. 2) Editorial

By Tommyr7, history, 5 years ago, In EnglishHi, all!

This is not Tommyr7, but the impostor behind the round (guess who I am? :P). The statements are written by me. The characters in the round feature, again, the Monogatari anime series, and to be more specific, Nisemonogatari: Fake Tale. The statements involve stories with fake things and oddities, but as per tradition, contain no spoilers. Thank you, everyone, and hope you've all enjoyed the round!

On a side note, special kudos to the best impostors of the round (except me, lol)!

Any feedback on problems and tutorials are welcome -- we look forward to doing even better in the future!

Here are hints for all problems and detailed tutorials!

HintsProblem AFirst approach: Optimize the straightforward solution.

... or even...Problem BMultiply instead of divide. What happens to the last digit when multiplying?

Problem CConsider islands of two colours and the bridges between them.

Problem DIterate over all possible combination, order and direction of extra edges.

Problem EFirst approach: 2D segment tree (or quadtree) with a set or vector on each node, representing the set of barriers that cover this node.

... or may as well...Second approach: Assign a random value to each barrier. Then utilise 2D Fenwick trees.

Tutorials869A - The Artful ExpedientAuthor Tommyr7, cyand1317 / Preparation Tommyr7, cyand1317 / Tutorial cyand1317

Tutorial869A - The Artful ExpedientFirst approach: Optimize the straightforward solution.

The O(n3) solution is to iterate through (i, j) pairs, then iterate over k and check whether xi xor yj equals either xk or yk. But it doesn't fit into the time limit.

We try to get rid of the k loop and make the check faster. Here's the insight: we create an array a, and let a[i] denote "whether value i appears in the given 2n integers". In this way we can make the check comsume O(1) time (with O(n) preprocessing for a), resulting in an O(n2) overall time complexity. Please see the model solution for an implementation.

A detail worth mentioning is that xi xor yj may exceed 2·106 and become as large as 2097152 = 221. Thus the array should be of size 2097152 instead of 2·106 and if not, invalid memory access may take place.

Second approach: Believe in magic.

Let's forget about all loops and algorithmic stuff and start fresh. What's the parity of the answer?

Looking at the samples again, do note that Karen scores two consecutive wins. The fact is that, Karen always wins.

Proof. For any pair (i, j), if an index k exists such that xi xor yj  = xk, then this k is unique since all 2n integers are distinct. Then, pair (k, j) also fulfills the requirement, since xk xor yj  = xi. The similar goes for cases where xi xor yj  = yk. Therefore, each valid pair satisfying the requirement can be mapped to exactly another valid pair, and the mapping is unique and involutory (that is, f(f(u)) = u). Thus, the number of such pairs is always even.

So, Karen still claims her constant win. Maybe it's Koyomi's obscure reconciliation ;)

Solution 1 (Tommyr7)Solution 2 (cyand1317)869B - The Eternal ImmortalityAuthor Tommyr7 / Preparation Tommyr7 / Tutorial cyand1317

Tutorial869B - The Eternal ImmortalityMultiply instead of divide. What happens to the last digit when multiplying?

 equals (a + 1)·(a + 2)·...·(b - 1)·b. Consider the multiplicands one by one, and when the last digit of the product becomes 0, it stays unchanged from then on.

Hence we can multiply the integers one by one, only preserving the last digit (take it modulo 10 whenever possible), and stop when it becomes 0. It's obvious that at most 10 multiplications are needed before stopping, and it's not hard to prove a tighter upper bound of 5.

Take care, integer overflow can emerge everywhere!

Model solution (Tommyr7)869C - The Intriguing ObsessionAuthor Tommyr7 / Preparation Tommyr7 / Tutorial Tommyr7

Tutorial869C - The Intriguing ObsessionFirst step: Consider what does at least 3 mean?

'The shortest distance between them is at least 3' means it can't be 1 or 2. The distance can't be 1 means that no two islands with the same colour can be straightly connected. The distance can't be 2 means that for each island, no two islands with the same colour can both be straightly connected with it.

Second step: Make the graph into 3 parts.

The bridges between red and blue islands have no effection with those between red and purple ones. Therefore, we can make the graph into 3 parts: one between red and blue, one between blue and purple, and the last one between red and purple.

Suppose there are A red islands and B blue islands, and there are k bridges between them. Then, the answer will be . So, the answer of bridges between red and blue ones should be 

Therefore, the final answer should be ans1 * ans2 * ans3.

You can calculate it with an O(n2) brute force. Also, you can make it into O(n).

Model solution (Tommyr7)869D - The Overdosing UbiquityAuthor quailty / Preparation quailty / Tutorial quailty

Tutorial869D - The Overdosing UbiquityIterate over all possible combination, order and direction of extra edges.

There are no more than O(m!2m) ways to go through these extra edges, each of which will bring us at most O(n2) more simple paths. If we count all these simple paths using simple depth-first search, the time complexity will be O(n2m!2m), which is the same as the order of the answer.

However, we can reduce the original graph to a pretty small one, for example, by keeping all the nodes on some cycle and compressing the others. Noticing that the longest simple path on a complete binary tree is just , the compressed graph will contain at most  nodes. Running simple depth-first search on such a small graph will lead to an  solution, which fits in with the small constraint of m and works really fast in practice.

Model solution (quailty)869E - The Untended AntiquityAuthor Tommyr7 / Preparation Tommyr7, cyand1317, visitWorld / Tutorial cyand1317

Tutorial869E - The Untended AntiquityThe barriers share no common points. Therefore two cells are connected iff the set of barriers containing each of them are the same. The reason is that no barrier can divide a barrier of larger area into two separate regions that are not reachable from each other.

The inner barrier can't be any larger in either side (otherwise there will be common points), and thus cannot divide the outer one.

First approach: 2D segment tree or quadtree.

In a 2D segment tree or quadtree, each node u represents a rectangular area. On each node we use an array list (std::vector) to keep track of all barriers fully containing u's represented rectangle. Each newly-added barrier will cause  insertions and each removal will result in  deletions.

For queries, iterate over the list in all involved nodes (there are  of them).

It can be proved that a node of size w × h with a corner (r, c) can be contained in most min{r - 1, c - 1, n - (r + h), m - (c + w)} barriers. Hence it can be shown that in the worst cases, a single query involves at most  elements in all lists. The total space complexity is , and time complexity is , both with a small constant multiplier (less than 1 / 4 for space and much less than 1 / 2 for time), efficient enough to pass all tests. Tester's implementation works in under 800 ms in worst cases, so we decided to let such solutions pass. Also, a little randomization in partitioning may help avoid constructed worst cases and further reduce maximum running time on tests.

Second approach: Randomization.

We need to quickly check whether two sets are identical. Assign a random hash value to each barrier and use their sum or xor sum as the hash of the set.

In this way, the creation/deletion of a barrier is equivalent to adding/subtracting/xoring a value to all cells in a rectangular region, and a query is equivalent to finding the values of two cells. The cells are reachable from each other iff their values are the same. This can be done efficiently with a 2D segment tree or 2D Fenwick tree, in  time.

With randomized values being 64-bit unsigned integers, the probability of a collision is 2 - 64. The probability to give 105 correct answers is (1 - 2 - 64)100 000 ≈ 1 - 2 - 47. And the probability to give correct answers on all tests is approximately 1 - 2 - 40.

If you're still afraid of collisions, you can: either (1) use a pair of 64-bit integers as the hash value, or (2) use the problemsetter's birthday, 20001206, as the seed (kidding, lol).

We are aware that a few implementations with sub-optimal time complexities passed all the tests, though we spared no effort in the preparation process to come up with various cases. We really look forward to doing better to eliminate all such possibilities in the future. Cheers!

Solution 1 (visitWorld)Solution 2 (Tommyr7)Tommyr7: I do hope you all enjoyed yourselves during the contest. See you next time!

Codeforces Round #438 Analysis

By Endagorion, history, 5 years ago, In English868A - Bark to UnlockIf the answer is 'yes', then the password is either one of the given strings, or can be formed by taking the last letter and the first letter of some of the given strings (these strings can be the same). This can be checked straightforwardly in O(n2) time.

868B - Race Against TimeThere are 12 × 60 × 60 positions on the clock face that can be occupied by hands and start/finish positions. After marking the positions occupied by hands, we can straightforwardly try both directions of moving and check if we arrive to the finish without encountering any of the hands. Of course, there are many solutions that are more efficient.

868C - Qualification RoundsLet us show that if a solution exists, then there is always a solution that uses at most two problems. First, if there is a problem not known to any of the teams, that we can just take this only problem in the set. Next, suppose that there is a problem known only to one of the teams. If there is a problem this team doesn't know, then these two problems make a good set. Otherwise, the team knows all the problems, hence we cannot find a good set.

In the rest case, each problem is known to at least two of the teams. Now, if there is a good set of problems, then each of the problems in the set must be known to exactly two of the teams. Indeed, let pi be the number of teams that knows the problem. If a good set contains k problems, then we must have , since otherwise we would have a team that knows more than half of the problems by pigeonhole principle. We also have pi ≥ 2, hence , and only the case pi = 2 is possible.

At this point, if we can find a pair of problems with pi = 2 and non-intersecting set of teams, then we are done. Otherwise, we can show that a good set does not exist by case analysis.

To avoid O(n2) solution, we can leave at most 24 problems with unique types (sets of teams) and do pairwise checking on them. This solution has O(n) complexity.

868D - Huge StringsThe key insight is that despite the strings can get very long, the answer for each string at most 9. Indeed, let us keep track of the number of distinct substrings of length 10 across all strings. Obviously, this number is at most 100 for the initial strings. Once we obtain a new string as a concatenation of two old ones, the only new substrings can arise on the border of these two strings, and there can be at most 9 of these substrings. Since 100 + 100·9 < 210, it is impossible to construct a string with answer 10.

Now, the solution is for each new string store the set of all distinct substrings of length at most 9. In order to construct this set for subsequent strings, we will have to store the first and the last 9 characters of each string (probably less if the string is shorter than 9). The number of operations is roughly 100·210 if we store the distinct substrings in arrays, but can be made smaller if we use bitsets.

868E - Policeman and a TreeSuppose that the policeman is moving from v to u via the tree edge. The criminals can now assume any positions in two halves of the tree (but cannot travel from one half to another). Let dpe, k, a be the resulting time to catch the criminals if the policeman have just started to travel along a (directed) edge e, there are k criminals in total, and a of them are in the half tree "in front" of the policeman.

If the edge e leads into a leaf of the tree, then the policeman catches everyone in this leaf, and his next step is to go back using the same edge. Otherwise, the criminals must have distributed optimally in the subtrees starting with edges e1, ..., ej. The policeman cannot win within time T if there is a distribution a1, ..., aj with  such that dpei, k, ai > T for every i. The optimal value of T can be found with binary search: for a particular T find the smallest ai such that dpei, k, ai > T, and check if . If this is the case, the criminals can distribute so that it will take  > T time to catch them.

The total complexity of this solution is , since we have O(nm2) DP states, with each state having O(n) transitions, and the last factor corresponding to binary search on the answer (assuming the answer is at most A).

868F - Yet Another Minimization ProblemFirst, let us solve the problem in O(kn2) time with a simple DP. Let dpi, j be the smallest cost of a partition of first j elements into i parts. Clearly, dpi, j = minj' < jdpi - 1, j' + cost(j', j). We can optimize the cost computation by moving j' from right to left and maintaining frequency for each element, since by introducing an element x into the segment, we increase the cost by fx – the number of occurences of x.

To optimize this further, let us note that p(j) – the (leftmost) optimal value of j' for a particular j is monotonous in j on any step i. Indeed, suppose that j1 < j2, and dpi - 1, x + cost(x, j2) < dpi - 1, p(j1) + cost(p(j1), j2) for x < p(j1). But cost(x, j2) - cost(p(j1), j2) ≥ cost(x, j1) - cost(p(j1), j1), since introducing an element into a segment [l, j2] is at least as costly as introducing it into a segment [l, j1]. Finally, dpi - 1, p(j1) - dpi - 1, x > cost(x, j2) - cost(p(j1), j2) ≥ cost(x, j1) - cost(p(j1), j1), and dpi - 1, p(j1) + cost(p(j1), j1) > dpi - 1, x + cost(x, j1), which contradicts the optimality of p(j1).

We can now apply the "divide-and-conquer" DP optimization: suppose that for a segment [l, r] we know that  for each . Choose m as the midpoint of [l, r] and find p(m) by explicitly trying all values in [L, R]. We now proceed recursively into segments [l, m - 1] with , and [m + 1, r] with . Assuming unit cost for cost(l, r) computation, one can show that the computation of all values of dpi, j for a particular i takes  time.

The final detail is that the time needed to compute cost(l, r) can be made amortized constant (that is,  in total per layer) if we store the value cost(p(m), m) from the parent segment, and add/remove segment elements one by one to obtain all subsequent values. The total complexity is now .

868G - El Toll CavesLet ai, j be the number of times we have checked spot j after i days. Assuming that the spot j contains the treasure, we can see that the expected number of days to find the treasure is . Hence the unconditional expectation of the answer is . This formula implies that the optimal strategy is to keep the visiting frequencies for all spots as close as possible, since the sum  is minimized under  when ai, j is the smoothest partition of ik. One implementation of this strategy is to visit spots  on day i. Note further that this strategy always visits spots in batches of size , hence we can divide both n and k by their GCD.

Let us now consider an example of n = 8, k = 3. Let Ei be the expected number of days to find the treasure in spot i according to the optimal strategy above. We can see that E3 = E0 + 1, E4 = E1 + 1, ..., E7 = E4 + 1, because a cell j + k is visited on day i iff the cell j was visited on day i - 1. We also have E0 = E5 / 2 + 1 for the same reason except for that the cell 0 was visited on the first day. This argument allows to express, say, E0 as a linear expression of itself, and find the answer in O(n) time. Another approach is to substitute the expressions until we cross the end of the sequence once: E0 = E3 - 1 = E6 - 2 = 2E1 - 4, also E1 = 2E2 - 4, but E2 = E5 - 1 = 2E0 - 3. We have obtained a similar set of linear relations of three spots with difference 2. To reduce to n = 3, k = 2 let us group Ej by : E0 + E3 + E6 = 3E0 + 3, E1 + E4 + E7 = 3E1 + 3, E2 + E5 = 2E2 + 1. We can see that the total contribution of all Ej for  is a linear function in Ex, with coefficients depending on whether . The main idea is that we continue this process with a different set of linear equations, effectively obtaining Euclid's algorithm that stores some additional data.

Let us now describe the general solution. Assume that we have a set of variables X0, ..., Xn - 1 satisfying Xi + k = A(Xi) for i + k < n, and Xi + k - n = B(Xi) for i + k ≥ n. Assume further that the answer . Let . For j < k', by applying relations A and B successively we obtain , hence  for j + k' ≥ k. Similarly,  for j + k' < k. Also, , where , . It follows that the transformation n → k, k → k', , , S1 → S'1, S2 → S'2 produces the same answer E.

In the end of this process we have n = 1, k = 0, hence we have a linear equation X0 = A(X0). After finding X0, the answer is S2(X0). The number of reductions of the above type is , with each transformation possible to do in  time, (S1 → S'1 and S2 → S'2 require fast matrix exponentation). The total number of operations is  per test.

MemSQL Start[c]UP 3.0 Round 2 Editorial

By cerealguy, 5 years ago, In English867A - Between the OfficesThe answer is "YES" if the first character of the given string is 'S' and the last character is 'F', otherwise it's "NO".

865A - Save the problem!The simplest solution is to make the denominations always {1, 2}, and set N = 2·A - 1. This provides exactly A ways to make change, because you can choose any number of 2 cent pieces from 0 to A - 1, then the rest must be 1 cent pieces.

865B - Ordering PizzaTo simplify things, let's first add a dummy contestant who will eat all the "leftover" pizza but gain no happiness. Then let's sort the contestants by bi - ai. Now we can describe the optimal way to feed the contestants once the pizzas are already bought: we should line up the contestants in order, and line up the pizzas in order with the type 1 pizzas at the front and type 2 pizzas at the back. Then the first contestant should take the first s1 slices, then the second contestant should take the next s2 slices, and so on.

Observe that there can be at most 1 pizza whose slices are taken by some contestants prefer type 1 and others prefer type 2. The remainder of pizzas will have only one type of preference (or possibly no preference), so those pizzas can be made of whichever type is preferred. For the final pizza we can check both possibilities and order the one that provides more happiness.

865C - Gotta Go FastLet's change the game by adding a deterministic variant, which takes exactly K seconds to complete. Initially, you play the original (random) game, but between levels (including before the first level), you're allowed to switch to the deterministic game (instead of restarting). You finish when you either complete the original game in at most R seconds, or complete the deterministic game.

This modified version is easier to analyze because there are no loops in the state graph. We can compute the optimal strategy by starting from the end and working backwards. For each level, and each amount of time it could have taken to reach this level, we can compute the expected time to completion for each of the 2 actions we can take, then perform whichever action is lower. Eventually we'll work our way back to the beginning of the game. If the optimal strategy is to immediately switch to the deterministic game, then the answer is greater than K. Otherwise it's less than K. This allows us to binary search the answer.

865D - Buy Low Sell HighLet's introduce the idea of options to the problem. Instead of having to buy stock when it is at a given price, each day you gain the option to buy a share at that days price, which you can exercise at any time in the future. This way we only need to exercise an option in order to sell it, and we never need to "hold" any stock.

Each day, 2 things happen. First, we get one more option. Second, if there is some option whose price is lower than today's price, we can be sure that we're going to exercise that option. What we don't know is when it's best to sell that option. However, we don't need to know when the best time is to sell - we can just sell it now, but give ourselves the option to buy it back at the price we just sold it for.

Options can be stored in a heap since we only ever care about the cheapest one. Running time .

865E - Hex DyslexiaFirst, observe that for a solution to exist, the sum of the digits in the input must be divisible by 15. This is because of the Casting out Nines rule, but applied in base 16. Furthermore, the sum of digits, when divided by 15, tells us how many carries must be performed when adding the answer to the input. We can try every possible set of positions for the carries, of which there are at most  ways. Once the carries are fixed, for each position we know the exact difference between the original digit in that position and the permuted digit in that position.

Now let's consider the permutation itself. Any permutation can be decomposed into cycles. Because we're looking for the minimum solution, it must be the case that every cycle in the permutation contains a zero. If there were a cycle without a zero, we could reduce every number in the cycle by the minimum value and produce a smaller solution. Furthermore, because every cycle contains a common element, that means the permutation can be written as a single cycle, since two cycles with a common element can be merged into one cycle using that element.

To build such a cycle, we can start at a zero, and when we add a digit to the path we know based on its position what the difference must be between it and the previous digit. For each of the 2|S| subsets of positions we can compute the minimum value that corresponds to a path through those positions. This step is O(|S|·2|S|).

Side note: the answer, if it exists, always begins with 0. There are 2 cases to consider. If S begins with an 'f', then the only possible solutions begin with a 0. Otherwise, the value given by  is a valid solution, and starts with 0.

865F - Egg RouletteWe can permute any prefix of an ordering containing at most R - 1 'A's or R - 1 'B's without changing the unfairness. This is because within that prefix one of the players cannot lose the game. This means that every ordering there is a unique ordering with the same unfairness that begins with exactly R - 1 'A's followed by R - 1 'B's and can be obtained by permuting such a prefix. Let's call this the canonical form of an ordering.

To search for canonical forms, we need to consider the remaining 2 * (C + 1) turns. The constraints set this to at most 42, so we can split it into two halves, compute every possible ordering for the left C + 1 turns and right C + 1 turns, then use a meet-in-the-middle algorithm to find those that minimize unfairness.

For each ordering in each half, we also need to compute how many corresponding orderings match the given string S. For the right half this is easy - every ordering either matches once or not at all. For the left half we have to consider non-canonical orderings. To compute this, we first need to find the longest prefix of the ordering that can be permuted. This is the longest prefix where every turn is the same as the first turn. Then we need to count how many 'A' and 'B' characters are in the ordering within that prefix, and how many 'A' and 'B' characters are in S within that prefix. If there are more 'A' or 'B' characters in S than the ordering, there are zero matches, otherwise the number of matches is given by a binomial coefficient.

The total runtime is O(C * 2C).

865G - Flowers and ChocolateLet's first consider how to compute the number of ways to make a bouquet with exactly K petals. Define a polynomial . Then if we compute P(x)N, the coefficient of xK gives the number of ways to make a bouquet with exactly K petals. This is because each possible bouquet produces a term with an exponent equal to its number of petals.

Now lets consider how to compute the number of ways to make a basket with exactly K chocolates. Define a polynomial . Then if we compute , the coefficient of x0 gives the number of ways to make a basket with exactly K chocolates. This can be derived from a Generating Function, but we will provide an alternate derivation.

Consider the following algorithm for computing the number of ways to make a basket with K chocolates:

ways = [1]repeat K times:    for i from 1 to B:        ways[c_i] += ways[0]    ways[0] = 0    ways.pop_front()return ways[0]Now let's define a polynomial . Initially, W(x) = 1. Lines 3 through 5 add a multiple of Q(x) to W(x), and line 6 divides W(x) by x. It follows that the resulting polynomial is congruent to x - K modulo Q(x).The final answer is the sum, over all values of K, of the number of bouquets with K petals times the number of baskets with K chocolates. The number of bouquets is given by the xK coefficient of P(x)N, or equivalently, the x - K coefficient of P(x - 1)N, and the number of baskets is given by the coefficient of x0 of . It follows that the answer is simply the coefficient of x0 of . This can be computed using  polynomial multiplications, each of which takes O(max(ci)2) time, using naive multiplication, for a total runtime of .

Codeforces Round #436 (Div.2) Editorial

By fcspartakm, history, 5 years ago, translation, In English864A - Fair GameThis problem has many different solutions. Let's consider one of them.

At first sort all numbers in non-descending order. Then the first n / 2 numbers must be equal to each other, the following n / 2 numbers must be equal to each other, and the number from the first half must be different from the number from the second half. So, if all conditions:

a[1] = a[n / 2]a[n / 2 + 1] = a[n]a[1] ≠ a[n]are met after sorting, the answer is «YES». Vasya must choose before the game number a[1] and Petya — a[n] (or vice versa). If at least one from the described conditions is failed, the answer is «NO».

864B - Polycarp and LettersLet's solve the given problem in the following way. We will iterate through the letters in the string in order from left to right.

If we are in position pos and the next letter is uppercase we skip it. In the other case, we need to create set and put letter spos in it. After that we iterate through string to the right until we do not met uppercase letter or until the string does not ended. We put in set each new lowercase letter. After we met uppercase letter (let position of this letter is p), or string is ended, we update the answer with the number of elements in set, and repeat described algorithm starting from position p.

864C - BusIf the bus can not reach the first gas station (i.e. b < f) print -1.

In the other case, the bus will reach the first gas station with b - f liters in the gasoline tank. Then we need to iterate through journeys from 1 to k and calculate a value need — how many liters of the gasoline needed to bus reach the next gas station. If need more than b — print -1, because it means that the bus can not reach the next gas station even with full gasoline tank. If need more than current level of gasoline in the tank the bus needs to refuel. In the other case, refuel is not necessary. After described operations we need to move to the point of next gas station and recalculate the fuel level in the tank.

864D - Make a Permutation!We will use an array cnt where we will store how many times the numbers from 1 to n met in the given array a. Put all numbers that never occur in the array a in a vector need — we must add this numbers in the array a to make a permutation.

We will add numbers from need in ascending order because we want to get lexicographically minimal permutation. Let pos is a pointer on the current number needpos which we need to add on the current move. Initially, pos = 0.

We will iterate through the array a. Let the current number equals to ai. If cntai = 1, we move to the next number in the array. If we added not all numbers from need, and ai > needpos or there already was ai on the prefix of the array (to check it we can use, for example, boolean array), then we put needpos in the current position, decrease cntai on one, increase pos and answer on one. If we do not change anything on that step we mark that ai already was on the prefix of the array. After that we move to the next number in array a.

864E - FireIf Polycarp will save two items, it is more profitable to first save the one whose d parameter is less. So, you can sort items by the parameter d.

Let dpi, j be the maximum total value of items Polycarp can save by checking first i - 1 items in j seconds. Here are two types of transitions. Polycarp can either save current item or skip it:

dpi + 1, j + ti = max(dpi + 1, j + ti, dpi, j + pi), if j + ti < didpi + 1, j = max(dpi + 1, j, dpi, j)To restore the sequence of items Polycarp can save you can remember for each pair (i, j) whether you took a thing with the number i - 1 when updating the value dpi, j.

Overall complexity: O(n·max1 ≤ i ≤ ndi).

864F - Cities ExcursionsThere is a direct graph. For each query, you need to find the kj-th vertex in the lexicographically minimal path from sj to tj.

First group the queries on the vertex tj and find all vertices from which the vertex tj is achievable. For this you can invert all the arcs and run dfs from the vertex tj.

Now consider the query (sj, tj). For this query, you need to find the lexicographically minimal path from sj to tj. If the vertex tj is not achievable from sj, then the answer is '-1'. Otherwise, in the lexicographically minimal path p from sj to tj the vertex pi (i > 1) is the minimal vertex from vertices u such that there exists an arc (pi - 1, u) and tj is achievable from u.

Thus, we can build a new graph consisting of arcs satisfying the previous condition. Let us invert the arcs in this graph. Consider the vertices achievable from tj in this graph. They form an outgoing tree. Only for these vertices there is a lexicographically minimal path to tj. The lexicographically minimal path from the vertex sj to the vertex tj is equal to the inverted path from tj to sj in this tree.

So, we can use binary climb to get the k-th vertex on this path.

Codeforces round #435 editorial

By mohammedehab2002, history, 5 years ago, In English862A - Mahmoud and Ehab and the MEX

One can see that in the final set all the elements less than x should exist, x shouldn't exist and any element greater than x doesn't matter, so we will count the number of elements less than x that don't exist in the initial set and add this to the answer, If x exists we'll add 1 to the answer because x should be removed .

Time complexity : O(n + x) .

Solution link (me) : https://pastebin.com/ALfcu8Ab .

Solution link (mahmoudbadawy) : https://pastebin.com/yXLkmA5F .

862B - Mahmoud and Ehab and the bipartiteness

The tree itself is bipartite so we can run a dfs to partition the tree into the 2 sets (called bicoloring), We can't add an edge between any 2 nodes in the same set and we can add an edge between every 2 nodes in different sets, so let the number of nodes in the left set be l and the number of nodes in the right set be r, The maximum number of edges that can exist is l * r, but n - 1 edges already exist so the maximum number of edges to be added is l * r - (n - 1).

Time complexity : O(n) .

Solution link (me) : https://pastebin.com/w3bF7gKS .

Solution link (mahmoudbadawy) : https://pastebin.com/PMpte7nC .

862C - Mahmoud and Ehab and the xor

n = 2, x = 0 is the only case with answer "NO" .

Let pw = 217 .

First print 1, 2, ..., n - 3 (The first n - 3 positive integers), Let their bitwise-xor sum be y, If x = y You can add pw, pw * 2 and , Otherwise you can add 0, pw and , We handled the case x = y in a different way because if we add 0, pw and  in this case, Then it's like adding 0, pw and pw, pw appears twice so we'll get wrong answer.

Handle n = 1 (print x) and n = 2 (print 0 and x) .

Solution link (mahmoudbadawy) : https://pastebin.com/w67KUY5u .

862D - Mahmoud and Ehab and the binary string

In the editorial we suppose that the answer of some query is the number of correct guessed positions which is equal to n minus hamming distance, The solutions in this editorial consider the answer of a query as n minus real answer, For convenience.

Common things : Let zero(l, r) be a function that returns the number of zeros in the interval [l;r] minus the number of ones in it, We can find it in one query after a preprocessing query, The preprocessing query is 1111..., Let its answer be stored in all, If we made a query with a string full of ones except for the interval [l;r] which will be full of zeros, If this query's answer is cur, zero(l, r) = cur - all, That's because all is the number of ones in the interval [l;r] plus some trash and cur is the number of zeros in the interval plus the same trash .

First solution by mahmoudbadawyLet's have a searching interval, initially this interval is [1;n] (The whole string), Let's repeat this until we reach our goal, Let mid = (l + r) / 2 Let's query to get zero(l, mid), If it's equal to r - l + 1, This interval is full of zeros so we can print any index in it as the index with value 0 and continue searching for an index with the value 1 in the interval [mid + 1;r], But if its value is equal to l - r - 1, This interval is full of ones so we can print any index in it as the index with value 1 and continue searching for a 0 in the interval [mid + 1;r], Otherwise the interval contains both values so we can continue searching for both in the interval [l;mid], Every time the searching interval length must be divided by 2 in any case so we perform O(log(n)) queries .

Second solution by meLet's send 1111... and let the answer be ans1, Let's send 0111... and let the answer be ans0, We now know the value in the first index (1 if ans1 > ans0, 0 otherwise), We can binary search for the first index where the non-found value exists, which is to binary search on the first value x where zero(2, x) * sign(non - found bit value) ≠ x - 1 where sign(y) is 1 if y = 0,  - 1 otherwise .

Solution link (me) : https://pastebin.com/Bc6q7TKv .

Solution link (mahmoudbadawy) : https://pastebin.com/RMyLDMxw .

862E - Mahmoud and Ehab and the function

Let's write f(j) in another way:-





Now we have 2 sums, The first one is constant (doesn't depend on j), For the second sum we can calculate all its possible values using sliding window technique, Now we want a data-structure that takes the value of the first sum and chooses the best second sum from all the choices .

observation: We don't have to try all the possible values of f(j) to minimize the expression, If the first sum is c, We can try only the least value greater than  - c and the greatest value less than  - c ( - c not c because we are minimizing c + second not c - second) because the absolute value means the distance between the two values on the number line, Any other value will be further than at least one of the chosen values, To do this we can keep all the values of f(j) sorted and try the elements numbered lower_bound(-c) and lower_bound(-c)-1 and choose the better (In short we're trying the values close to  - c only).

Now we have a data-structure that can get us the minimum value of the expression once given the value of the first sum in O(log(n)), Now we want to keep track of the value of the first sum .

Let the initial value be c, In each update, If the length of the updated interval is even, The sum won't change because x will be added as many times as it's subtracted, Otherwise x will be added to c or subtracted from c depending of the parity of l (the left-bound of the interval) .

Time complexity : O(n + (m + q)log(m)) .

Solution link (me) : https://pastebin.com/u828DjcS .

Solution link (mahmoudbadawy) : https://pastebin.com/dA3K8nfK .

862F - Mahmoud and Ehab and the final stage

First, Let's get rid of the LCP part .

observation: , That could make us transform the LCP part into a minimization part by making an array lcp where lcpi = LCP(si, si + 1), You could calculate it naively, And when an update happens at index a, You should update lcpa (If exists) and lcpa - 1 (If exists) naively .

Now the problem reduces to finding a ≤ l ≤ r ≤ b that maximizes the value:-

, If we have a histogram where the ith column has height lcpi, The the size of the largest rectangle that fits in the columns from l to r - 1 is , That's close to our formula not the same but it's not a problem (You'll see how to fix it later), so to get rid of finding the l and r part, We can make that histogram and the answer for a query will be the largest rectangle in the subhistogram that contains the columns from a to b - 1, One of the ways to solve it is to try some heights h and see the maximum width we can achieve if h was the height, call it w, and maximize with h * w, To solve the slight difference in formulas problem we'll just maximize with h * (w + 1)!!

Let BU be a value the we'll choose later, We have 2 cases for our largest rectangle's height h, It could be either h ≤ BU or h > BU, We will solve both problems separately.

For h ≤ BU we can maintain BU segment trees, Segment tree number i has 1 at index x if lcpx ≥ i and 0 otherwise, When we query, It should get us the longest subsegment of ones in the query range, Let's see what we need for our merging operation, If we want the answer for the longest subsegment of ones in a range [l;r], Let mid = (l + r) / 2, Then the answer is the maximum between the answer of [l;mid], The answer of [mid + 1;r], And the maximum suffix of ones in the range [l;mid] added to the maximum prefix of ones in the range [mid + 1;r] . So we need to keep all these information in our node and also the length of the interval, As it's a well-known problem I won't get into more detail. Back to our problem, We can loop over all h ≤ BU, Let the answer for the query on range [a;b - 1] in segment tree number h be w, The maximum width of a rectangle of height h in this range is w and we'll maximize our answer with h * (w + 1) .

For h > BU, Let's call a column of height greater than BU big, The heights we'll try are the heights of the big columns in the range, We don't have to try all the heights greater the BU, There are at most  big columns (Where tot is the total length of strings in input), Let's keep them in a set, When an update happens, You should add the column to the set or remove it depending on its new height, The set's size can't exceed  now, Let's see how to answer a query, Let's loop over the big columns in range [a;b - 1] only, If 2 of them aren't consecutive then the column after the first can't be big and the column before the second either, That's because if it were big, It would be in our set, So we can use this observation by making a new histogram with the big columns in the range only, And put a column with height 0 between any non-consecutive two, And get the largest rectangle in this histogram by the stack way for example in , The stack way will get us the maximum width w we can achieve for a rectangle containing column number i, We'll maximize with lcpi * (w + 1).

Also the answer for our main formula can be an interval of length one, All what I mentioned doesn't cover this, You should maintain another segment tree that gets the maximum length of a string in a range for this .

Maximize all what we got, You have the answer, Now it's time to choose BU, It's optimal in time to choose BU near  (Reason in tfg's comment below) .

Optimization: The longest subsegment of ones problem is solved by BU segment trees and each one has 4 integers in each node, You can make them 2 integers (max prefix and suffix of ones) and make another only one segment tree that has the rest of the integers, That would divide the memory by 2 .

Time complexity : 

Thanks to vintage_Vlad_Makeev for making it harder and more interesting .

Solution link (vintage_Vlad_Makeev) : https://pastebin.com/vQ4RJqh0 .

Solution link (mahmoudbadawy) : https://pastebin.com/t3Vetzwf .

Codeforces Round 434 Div.1+Div.2 (and Technocup 2018 — Elimination Round 1) Editorial

By vovuh, history, 5 years ago, translation, In English858A - k-roundingNotice that the number x ends with k or more zeros if the maximal power of 2 that is a divisor of x is at least k and the maximal power of 5 that is a divisor of x is at least k. Let's calculate the maximal powers of 2 and 5 that are divisors of n. If any of the powers is less than k then multiply the number by appropriate number of 2 and 5.

The answer is also LCM(n, 10k).

858B - Which floor?We will store our current answer in some variable ans. Initially it is -1.

Let's iterate over the quantity of the flats on each floor (it will be from 1 to 100 inclusive). Let it be cf. Then we have to check that this quantity coincides with given input. If  for any  then this quantity is incorrect.

Now if  then we can't determine on which floor flat n is situated. Print -1. In the other case set .

858C - Did you mean...We will solve the problem greedily. Let's find the leftmost typo. It will be three consecutive characters si - 1, si and si + 1 such that all of them are consonants and there are at least two diffirent letters. It is clear that we can cut this string after position i, because prefix will be correct and we will leave only one letter in the remaining part of the string. So each time we find the leftmost typo and cut out the prefix. Remember that after cutting the prefix you have to continue checking from index i + 2, not i + 1.

858D - Polycarp's phone bookFind the shortest substring of each string such that it doesn't appear in any other string as a substring. For each substring let's store the index of the string which contains this substring or  - 1 if there are more than one such string. Iterate over all substrings which have values that are not  - 1 and update the answer for the corresponding string.

858E - Tests RenumerationFirstly we will get rid of all tests that are already named correctly. After this, let's call samples "tests of 1 type", and system tests "tests of 2 type".

Let's denote "free positions" such indices  such that there is currently no test with the name i. If there are no any free positions, then we can't rename each test using only one operation move because firstly we have to make its index a free position.

Let's show that one free position is always enough. If there is one, then let's put some test of the corresponding type which has wrong name (a name that doesn't coincide with its type) into this position. It is clear that there will be at least one such test — otherwise all tests of corresponding type are at their positions, and there is no free position of this type. Then there are two cases — either we free a correct position (then we will have another free position) or we move a test which had illegal name (so we don't create any free positions).

It's better to move a test which occupies some position so we will have a new free position after it. It is clear that when there are no tests such that their names are correct numbers, but they are in position of different type, then we can't keep the quantity of free positions as it is, and after moving any test this quantity will decrease.

This approach is optimal because we will have to perform either cnt (cnt is the number of tests that aren't correctly named initially) or cnt + 1 operations. cnt + 1 will be the answer only if we have to make an operation that will create a free position (if there are no free positions initially).

This number of operations is optimal because if we have cnt incorrectly named tests, then we can't rename them in less than cnt operations; and this is possible only if we have at least one free position initially; otherwise we have to free some position.

858F - Wizard's TourObviously the task can be solved independently for each component.

Here is the algorithm that allows you to reach exactly  tours, where m is the number of edges in the component. Let's take arbitrary tree built by depth-first search. While exiting vertex v, we can process all the edges to the vertices with greater height and the edge connecting vertex v to its parent in the tree (if v isn't a root). If the number of edges to the lower vertices is even then we can split then into pairs. Otherwise let's add the edge from the parent to this splitting and not handle it for the parent itself.

This algorithm will find the pair to every edge for all the vertices but the root. There will be at most one edge without the pair so the answer is maximal.

860E - Arkady and a Nobody-menFirst of all, ans[v] = ans[parent[v]] + depth[v] + ans'[v], where ans'[v] is the sum of (number of descendants of the rank depth[v]) for all predecessors of v. All we need is to compute ans'[v] now.Let's make a dfs in the graph. Let the dfs(v) return a vector ret[v] such that ret[v][d] is the following tuple: (number of vertices on depth d in subtree of v, some vertex x with depth d in the subtree of v, the ans'[x] if we consider only predecessors in the subtree of v). Also let's build some structure so that we can easily restore answers in this subtree if we know the final value of ans'[x]. We will see what is this structure later.To compute ret[v] we need to be able to merge two rets of its sons. Let's say we merge tuple (cnta, a, ans'[a]) with (cntb, b, ans'[b]). Then all we need to do is:ans'[b] +  = depth[v] * cnta,ans'[a] +  = depth[v] * cntb,return (cnta + cntb, a, ans'[a]) as the result.However, we must also be able to restore ans'[b] after the dfs is complete (remind the unknown structure). So after performing ans'[b] +  = depth[v] * cnta let's add an edge a → b to a new graph with weight ans'[a] - ans'[b]. Note that the difference between these values will be the same all the time after the tuples are merged, so using this edge we will be able to restore the answer ans'[b].After the dfs is done, run another dfs on the new graph to restore the values ans'[v] and then ans[v].To perform the second step fast, we need to note that we can always merge smaller rets into larger, and move them in O(1) into parents. Since each tuple is merged into a larger vector only once, this solution works in total in O(n).

Codeforces Round #433 Editorial

By vintage_Vlad_Makeev, history, 5 years ago, In English(Idea — Sender , developing — timgaripov)

854A - ДробьIt's possible to look over all possible values of the numerator . For the current value of a we have to compute denominator as b = n - a, check that there are no common divisors (except 1) of a and b (it also could be done by a linear search of possible common divisors 2 ≤ d ≤ a). The answer is the maximal fraction that was considered during the iteration over all possible values of the numerator and passed the irreducibility test.

Pseudocode of the described solution is presented below:This solution have  time complexity.

However, we can find answer to the problem analytically in the following way:

(Idea — Chmel_Tolstiy, developing — mingaleg)

854B - Максим покупает квартируMinimum number of good apartments is almost always 1, since rooms with indices from 1 to k could be inhabited. Exceptions are cases in which k = 0 and k = n, in these cases both minimum and maximum number of good rooms is 0 since there is no inhabitant or vacant apartments.

Maximum number of good apartments could be reached, for example, as follows. Assume apartments with indices 2, 5, 8 and so on are occupied as much as possible. Each of these apartments produces 2 good rooms except from, if it exists, the one with index n (that apartment produces 1 good apartment). If number of inhabitant apartments is less than k occupy any of rest rooms to reach that number, every such occupation will decrease number of good apartments by one). Simulate this process, than count the number of good rooms to find maximum possible number. Expected complexity: O(n2) or O(n).

Instead of simulating the above process calculate number of apartments with indices 2, 5, 8 and so on excluding the one with index n if it exists. Number of that apartments is equal to , and if k ≤ x you can occupy some of these apartments to reach maximum number of good rooms equal to 2·k. Otherwise, if k > x, assume that apartments with indices 2, 5, 8 and so on are occupied, so any room has at least one inhabited room adjacent to it. Therefore number of good apartments is equal to number of vacant apartments and is equal to n - k. Implementation of these formulas with keeping in mind cases in which k = 0 and k = n will be scored as full solution of problem. Expected complexity: O(1).

(Idea — Zlobober, developing — halin.george)

853A - Вопросы планированияWe will show that following greedy is correct: let's for each moment of time use a plane, which can depart in this moment of time (and didn't depart earlier, of course) with minimal cost of delay.

Proof is quite simple: it's required to minimize . You can notice that  is constant, so we just need to minimize . Consider the optimal solution when plane i departs at moment bi and solution by greedy algorithm in which plane i departs at moment ai. Let x be plane with minimal cx, such ax ≠ bx. At any moment greedy algorithm takes avaliable plane with lowest cx, so ax < bx. Let y be a plane, such that by = ax. But cy >  = by, so bx·cx + by·cy >  = bx·cy + by·cx and it's possible to swap bx and by in optimal solution without loosing of optimality. By performing this operation many times it's possible to make bi = ai for each i and it means that greedy solution is optimal.

To make this solution work fast you need to use some data structures to find optimal plane faster for each moment. This data structure should be able to add number into set, give value of minimal element in set and erase minimal number from set. For this purpose you can use heap (or someting like std::set or std::priority_queue in C++).

(Idea — GlebsHP, developing — mingaleg)

853B - Встреча жюриObviously, each member of the jury needs to buy exactly two tickets — to the capital and back.

Sort all flights by the day of departure. Now go through flights to the capital (forward flights) and one by one assume it is the last forward flight in answer (let's say it is scheduled on day d). Thus you are assuming that all forward flights are contained in some fixed prefix of flights. Make sure that there is at least one forward flight for every jury member in this prefix and find the cheapest forward flight among them for every person. All return flights we are interested in are contained in the suffix of flights list such that every flight's departure date is at least d + k + 1. Take similar steps: make sure that there is at least one return flight for every jury member in this suffix and find the cheapest return flight among them for every person as well. Select minimal cost among these variants or find out that the problem has no solution. Expected complexity: O(nm2) or O(m2 + n).

Just as the boundary of considered prefix moves right, the boundary of considered suffix moves right as well. This suggests that the problem could be solved by the two pointers method. Assume you are storing minimum forward flight's cost on current prefix (infinity if no flight exists) for every person, and you are storing multiset (ordered by cost) of all return flights on current suffix for each person as well. To proceed next prefix and conforming suffix do the following:

Move prefix boundary to the next forward flight. If its cost ci is less than minimum forward flight's cost fwdfi from that city, then you could improve total cost: decrease it by ci - fwdfi and set fwdfi to ci since it's new minimal cost.Move suffix boundary to the next backward flight until there is such flight exists and it departure date difference with prefix boundary departure date is under k + 1.While moving suffix boundary, keep return flights multisets consistent: remove boundary flight right before moving that boundary to the next flight. Also check out if you are removing cheapest flight from multiset. If it is so, minimal flight cost for that city changed as well as total cost: it increases by difference between old minimal cost and new minimal cost. Keep in mind that if you are removing last flight from multiset, then there is no more appropriate return flight for this city and you should terminate the process.Proceed these steps moving boundaries to the right until the process terminates. In this way you've reviewed the same prefixes and corresponding suffixes as in slower solution described above. Expected complexity: .

(Idea — glebushka98, developing — vintage_Vlad_Makeev)

853C - BoredomWe can't iterate over all interesting rectangles. Let's count number of rectangles that are not intersecting our rectangle. To do it let's calculate number of rectangles to the left, right, up and down of rectangle in query. It can be easily done in O(1) time: suppose we have rectangle with corners (i;pi) and (j;pj). We have min(i, j) - 1 points to the left of rectangle, n - max(i, j) to the right, min(pi, pj) - 1 to the down, etc. If we have x points in some area, there are  rectangles in that area. But now we calculated twice rectangles that are simultaneously to the left and up of our rectangle, left and down, etc. To find number of such rectangles we can iterate over all points and find points which are in these areas and find number of rectangles in area using formula . The complexity is O(q·n).

To solve the problem we need to find number of points in some areas faster. It's quite easy to notice that we just have many queries of finding number of points in some subrectangle. It's classical problem that can be solved with some 2d tree in O(q·log2) solution. But it can be too slow and can not fit into time limit in case of inaccurate implementation. However, you can notice that all queries are offline and find number of points in subrectangle in O(q·logn) time. It's fast enough to pass all tests.

(Idea — Elena Andreeva, developing — vintage_Vlad_Makeev)

853D - Миша и зарядные станцииBefore solving problem one observation is required: suppose at day i we have xi bonuses. Then exists optimal solution, which spends 0 or min(ai, xi) bonuses every day.

It's quite easy to proof: suppose we have some optimal solution and i is a first day, when neither 0 nor min(ai, xi) bonuses were spent. If i is a last day on which non-zero amount of bonuses was spent, we can notice that solution spending min(ai, xi) bonuses that day is more optimal, so first solution was optimal. So let's consider next day after i, when non-zero amount of bonuses was spent, say j, and amount of bonuses spent at day j is sj (Also, amount of bonuses spent on day i is si). Let's look at solution that spends si + min(si - min(ai, xi), sj) bonuses at day i and sj - min(si - min(ai, xi), sj). That solution is still correct and still optimal, but it spends min(ai, xi) at day i or 0 at day j. Anyway this operation increases first day i when neither i nor min(ai, xi) bonuses were spent or first day j after it, when non-zero amount of burles were spent. But we can't increase i or j infinitely, so, after some iterations of such transformation, solution, spending 0 or min(ai, xi) bonuses in each day.

To make an O(n2) solution it's possible to consider dynamic programming approach: let dpi, j be minimum amount of money that is possible to spend at first i days to pay for all chargings and have 100·j bonuses on card. At first, dp0, 0 = 0 and dpi, j = ∞. Then we can easy calculate all states going through all states with something like this code:

for (int i = 0; i < n; i++) {    for (int j = 0; j <= 2 * n; j++) {         dp[i + 1][j + a[i] / 1000] = min(dp[i + 1][j + a[i] / 1000], dp[i][j] + a[i]);         dp[i + 1][j - min(j, a[i] / 100)] = min(dp[i + 1][j - min(j, a[i] / 100)],                                                  dp[i][j] + a[i] - 100 * min(j, a[i] / 100));     } }Of course, j can be up to 2·n, because at each day it's possible to earn at most 2 bonuses.

To make this solution faster let's consider the following observation: there exists an optimal solution, which never has more 3000 bonuses on bonus card. To proof it let's first proof following lemma:

Lemma 1: There exists an optimal solution which spends only 0 or ai bonuses at day i if there are at least 3000 bonuses at card at the beginning of day i.

Lemma 1 proof: Let's introduce some designations. Let xi be amount of bonuses at the beginning of day i and si be amount of bonuses spent at day i. Also let's call day i "fractional" if si ≠ 0 and si ≠ ai, and call day i "interesting" if si ≠ 0. Let's proof lemma2 and lemma3 at first:

Lemma 2: Assume xi ≥ 3000 and j — next after i interesting day and k — next after j interesting day. Then there exists an optimal solution in which k is not a fractional day or j is not a fractional day.

Lemma2 proof: Suppose is some optimal solution j and k are fractional days. Let's consider a solution spending sj + min(sk, aj - s{j}) bonuses at day j and sk - min(sk, aj - s{j}) at day k. This solution is still correct, because xi ≥ 3000, so for days j and k there is enough bonuses and still optimal. Lemma2 is proved.

Lemma 3: Assume xi ≥ 3000 and j — next after i interesting day. Then there exists an optimal solution is which j is not a fractional day.

Lemma 3 proof: Consider some optimal solution with fractional day j. At first let's proof that j is not last interesting day. Suppose, j is last interesting day in solution. But we can make a solution that spends ai bonuses at day i (because ai ≤ 3000) and it will be more optimal. Contradiction. So there exists next after j interesting day. Let's call it k. Let's consider 2 cases:

Case 1 (aj = 1000): Let's spend consider solution spending 1000 bonuses at day j and ak - (1000 - sj)) at day k. It's still correct and optimal but j is not a fractional day.

Case 2 (aj = 2000): There are two subcases:

Case 2.1 (ak = 2000): Let's spend consider solution spending 2000 bonuses at day j and ak - (2000 - sj)) at day k. It's still correct and optimal but j is not a fractional day.

Case 2.2 (ak = 1000): Let's proof, k is not last interesting day. Assume k is last interesting day. Consider a solution spending 2000 bonuses at day j and 1000 bonuses at day k. It's correct but more optimal that initial solution. Conrtadiction. Now let p be next after k interesting day (k is not a fractional day by lemma2). If 2000 - aj ≤ 1000 we can consider solution which spends 2000 bonuses at day j, 1000 - (2000 - ak) bonuses at day k and sp bonuses at day p. If 2000 - sj > 1000 let's consider a solution which spends sj + 1000 bonuses at day j, 0 bonuses at day k and sp at day p. But by lemma2 sp = ap, so we can consider solution that spends 2000 bonuses at day j 0 bonuses at day k and ap - (2000 - sj - ak) at day k. All of these solutions are correct and optimal.

Lemma 1 proof (end): At first, of course there is at least one interesting day after i (Otherwise, it's more optimal to charge at day i using bounses, but in initial solution si = 0 because xi - 1 ≤ 3000 and xi > 3000). Let's call that day j and by lemma3 j is not fractional day. Let's consider 4 cases now:

Case 1: (ai = 1000, aj = 1000). Let's consider a solution with si = 1000 and sj = 0. It's correct and still optimal, but xi ≤ 3000.

Case 2: (ai = 2000, aj = 2000). Same as case1.

Case 3: (ai = 2000, aj = 1000). Let's consider 2 subcases:

Case 3.1: j is not last interesting day. Let k be next interesting day. It ak = 1000 consider a solution spending 2000 bonuses at day i, 0 bonuses at days j and k. It's still correct and optimal, but xi ≤ 3000. If ak = 2000 consider a solution a spending 2000 bonuses at day i, 1000 bonuses at day j and 0 bonuses at day k. It's correct and optimal too, and xi ≤ 3000 too.

Case 3.2: j is last interesting day. Let's construct solution this way. At first let's set si = 1000 and sj = 0. Then let's iterate over all ineteresting days after j, say k, in order in increasing time and set si = si + min(2000 - si, sk), sk = sk - min(2000 - si, sk). If after this process we still have some bonus left just add it to si. At the end, si will be equal 2000 because we spent all bonuses, solution will still be correct and optimal, but xi ≤ 3000.

Case 4: (ai = 1000, aj = 2000). Let p be last day before i with sp ≠ 0. If ap = 1000 consider a solution with sp = 0, si = 0, sj = 2000. It's correct, optimal and xt ≤ 3000 for each t ≤ i. If ap = 2000, consider a solution with sp = 2000, si = 0, sj = 0. It's correct, optimal and xt ≤ 3000 for each t ≤ i, too.

So for all cases we can make correct and optimal solution such there is no xi ≤ 3000 for all i, or number of first day with xi > 3000 increases, but it can't increase forever, so after some amount of opereations solution with xi ≤ 3000 for all i will be constructed.

Because of this fact we can consider dynamic programming approach described before but notice, that we should consider only states with j ≤ 30. It will have O(n) complexity. Moreover, looking at states with j = 30 is required. It's possible to make a test on which solution, that looks at states with j ≤ 29 will be incorrect.

(Idea — Zlobober, developing — malcolm)

853E - Лада МалинаIn the original contest there were subtasks for this problem and it's more convinient to understand the editorial going through these subtasks, so we will leave them here.

The key part of a solution is to understand what are the locations that may be accessed from the origin in T seconds. First observation is that we should investigate it only in case when T = 1 because T is simply a scale factor. Let’s denote this set for T = 1 as P.

Group #1. For the first group it’s easy to see that P is a square with vertices in points ( ± 2, 0), (0,  ± 2). So, the first group may be solved with a straightforward O(qn) approach: we iterate through all the factories and check if it's possible to get for cars from i-th factories to the car exposition. We can rotate the plane by 45 degrees (this may be done by the transformation x' = x + y, y' = x - y), after this each query region looks like a square. Therefore, it's necessary to check if point lies inside a square:

Group #2. In the second group propeller velocities are two arbitrary vectors. It can be shown that P will always be a parallelogram centered in the origin, built on vectors 2v1 and 2v2 as sides. Thus, this group is a matter of the same O(qn) approach with a bit more complicated predicate: one should be able to check that an integer point belongs to an integer parallelogram. The key observation is that we may find an appropriate transformation of a plane that transforms this set into a rectangle. Indeed, there always exists an affine transformation performing what we want. As an additional requirement, we want to transform coordinates in such way that they are still integral and not much larger than the original coordinates. The transformation looks like following:

The first expression is a signed distance to the line parallel to the vector v1, and the second one is the signed distance from the line parallel to the vector v2. Easy to see that belonging to some query parallelogram can be formulated in terms of x' and y' independendly belonging to some ranges.

Group #3. Second group should be a hint for the third group. One can find that the set P = {w1v1 + ... + wkvk||wi| ≤ 1} is always a central-symmetric polygon with the center in the origin. Actually, this Polygon is a Minkowski sum of k segments [ - vi, vi]. Minkowski sum of sets A1, A2, ..., Ak is by definition the following set: . It can be built in  time, although in this problem k is very small, so one may use any inefficient approach that comes into his head, like building a convex hull of all points { ± v1 ± v2... ± vk}.

After we found out a form of P, it’s possible to solve the third group of tests in O(qnk) by checking if each possible factory location belongs into a query polygon in O(k) time.

Following groups are exactly the same, but the constraints are higher, they require using some geometric data structure to deal with range queries.

Groups #4 and #5. Fourth group and fifth group are very similar to first and second group correspondingly, but we need to process the requests faster. After the transformation of the plane, the request can be reformulated as "find sum of all factories inside a square", so any 2d data structure may be applied, like a segment tree of segment trees. Another approach is to use a sweeping line algorithm with a segment tree or an appropriate binary search tree, achieving a time complexity  or .

Group #6. To solve the sixth group we need to use a trapezoidal polygon area calculation algorithm applied to our problem. Calculate the sum of points in each of 2k trapezoid areas below each of the sides of a polygon, and then take them with appropriate signs to achieve a result. Such trapezoid area can be seen as a set of points satisfying the inequalities l ≤ x ≤ r and y ≤ kx + b. Under transformation x' = x, y' = y - kx, this area becomes a rectangle, leading us to an  time solution.

Codeforces Round #432 editorial

By Arpa, history, 5 years ago, In EnglishHi!

Thanks to all of you participates, who made this contest possible. And thanks to Lewin and Arterm, also to the great coordinator, Nikolay KAN Kalinin, zemen, WHITE2302, and for sure MikeMirzayanov.

Test data and code solutions. It's the original packages from polygon, you can find pretests, tests, generators, validators, etc in it.

HintsDiv.2 A: Take a look at notes section.

Div.2 B: Create a circle with these points.

Div.1 B: Fix the gcd.

Div.1 C: Tag: Grundy number.

DetailsDiv.1 C

I want to thank my grand teacher Mojtaba moji FayazBakhsh here. Who was my teacher not only for coding but also a teacher for my life. Thanks Mojtaba! Thanks to you and all of other good teachers in the world.

Solutions851A - Arpa and a research in Mexican waveIf t ≤ k, answer is t.If k ≤ t ≤ n, answer is k.If n ≤ t < n + k, answer is n + k - t.Another solution: just print min(t, k, n + k - t).

Author: Arpa

851B - Arpa and an exam about geometryIf a, b, c are on the same line or dis(a, b) ≠ dis(b, c), the problem has not any solution.

Author: Arpa

850A - Five Dimensional PointsIt's easier to visualize this in 2D first. Fix a point p. If all other points form angles that are 90 degrees or greater, they must all be in different quadrants, so there can be at most 4 such points. In k dimension, this generalizes to 2*k such points, so for five dimensions, there can only be at most 10 other points. Thus, we can run the naive solution for small n and print 0 otherwise.

Author: Lewin

Thanks to Lewin, the writer of this tutorial.

850B - Arpa and a list of numbersLet's define cost(g) the cost if we want gcd of the array becomes g. The answer is min cost(g) for g > 1. Now, let's see how to calculate cost(g). For each number like c, we can delete it with cost x or we can add it till g divides it. So, we must pay . Let's iterate on possible values for .

Before entering the main part of the solution, let's define two helper functions:

– cnt(l, r): this function returns the number of i's such that l ≤ ai ≤ r.

– sum(l, r): this function returns . To implement this function, define an array ps, such that psi keeps the sum of values less than or equal to i. Then sum(l, r) = psr - psl - 1.

Now for each multiple of g like k, let's find the cost of numbers in the range (k - g, k], and sum up these values. We must find the best f and divide the range into two segments (k - g, f] and (f, k] and delete the numbers in the first range and add the numbers in second range till they become k. Now to find the best value for f, .

So, the total cost for this range is cnt(k - g + 1, k - ⌊ f⌋) × x + (cnt(k - ⌊ f⌋ + 1, k) × k - sum(k - ⌊ f⌋ + 1, k)) × y.

Time complexity: .

Author: Arpa

850C - Arpa and a game with MojtabaThe problem is separate for each prime, so we will calculate Grundy number for each prime and xor these number to find the answer.

Now let's solve the problem for some prime like p. Let's show the game with a mask, i-th bit of mask is true if and only if there is a number in the list such that it is divisible by pi and it isn't divisible by pk + 1.

When some player chooses p and some k in his turn, in fact, he converts mask to (mask»k)|(mask&((1«k) - 1)). So, for each k, there is an edge between state (mask»k)|(mask&((1«k) - 1)) and mask. We can caluclate the grundy numbers by this way.

Author: Arpa

850D - Tournament ConstructionLet n be the number of players participating in the tournament. First of all, note that n ≤ 61, since the total number of wins must be , and there can be no more than 30 × n, therefore , hence n ≤ 61. Next, we find an appropriate n, based on the criterion of the condition. We will go through all possible n from 1 to 61 and use the dynamic programming method to determine whether there can be a given number of participants, the parameters will be:

the current element in the sorted list aposhow many participants are already aware of their number of victoriesthe total number of wins for the already known participantsFrom these parameters, we store whether it is possible for the remaining participants to assign any apos, apos + 1... am so that there is a tournament for these participants. Also, do not forget that each of ai should be taken at least once. Further, if we did not find n, then we print  - 1. Otherwise, you can recover from the dynamics how many times we took each ai, it remains to build a correct tournament on these values.

To do this, each time we take the player with the smallest number of wins, let this number be x, and we make him win x other players with the least number of wins, and loose to the remaining players. Next, delete this player, recompute for each remaining player how many times they have to win, and continue this process until all of the players are processed. The proof that a correct tournament is always built by this algorithm follows from the criterion.

Thus, the first part works in  the second part works in .

Author: Arterm

Thanks to WHITE2302, the writer of this tutorial. I translated this tutorial to English.

850E - Random Electionsbk(x) denotes i-th bit of x.  denotes number of bits in x.

Count number of ways where Alice wins. Suppose Alice wins in first round with mask x and in third round with mask y (so, bi(x) = 1 or bi(y) = 1 if i voter preferred Alice in corresponding round). Necessary condition is f(x) = f(y) = 1.

Assume we fixed x and y. In how many ways we can choose orders for voters? If bi(x) = bi(y), we can chose two valid permutations for i-th voter. If , only one permutation. So, total number of permutation is .

So, answer to the problem is

Denote S = {x|f(x) = 1}. Lets solve more general problem, for each z, how many pairs (x, y) are there such that  and ? This is well-known problem. There are multiple O(2nn) solutions. Probably first usage of this problem in competitive programming can be found here https://apps.topcoder.com/wiki/display/tc/SRM+518.

If you interesting in understanding this approach more deeply from math perspective, you can start investigate from here https://en.wikipedia.org/wiki/Fourier_transform_on_finite_groups.

Sorry for late editorial.

Btw, in task D there are always an answer (for any set S), that's called Reid's conjectue and was proven by T.X. Yao in 1988 (and have very difficult proof that I didn't manage to find in English; if somebody succeed in search, please direct it to me).

Author: Arterm

Thanks to Arterm, the writer of this tutorial.

850F - Rainbow BallsFirst, let's fix the final color of the balls.

After fixing the final color, we can see the other colors don't matter.

Define an "interesting" draw as one where we choose a ball of the final color and one of a different color.

Once we do an interesting draw, we can see there is an equal probability of increasing or decreasing the number of balls of our final color.

So, we can view this as a random walk, with equal probability of going in either direction. Let Xt be the number of balls of the final color at time t. Let T be the first time we hit 0 or S balls.

Now, we can write the expected value of time as follows: Let t(r) = E(T|X0 = r, XT = S) (i.e. in words, expected value of time, given we are at r, only counting the events that reach XT = S first).

Let p(r) be the probability of an interesting draw, so p(r) = r × (S - r) × 2 / (S × (S - 1)). Then, we can write t(r) = p / 2 × t(r - 1) + p / 2 × t(r + 1) + r / S. Rearranging gives us 2 × t(r) = t(r - 1) + t(r + 1) + (S - 1) / (S - r).

So, in particular, t(r) - t(r - 1) = t(r + 1) - t(r) + (S - 1) / (S - r) So, letting g(r) = t(r) - t(r - 1), we get g(r + 1) = g(r) - (S - 1) / (S - r). Doing some more manipulation can get us .

So, we just need to print the sum of t(ai).

Author: Lewin

Thanks to Lewin, the writer of this tutorial.

I’d like to finish the editorial with the below poem by Hatef Esfahani:

چه کند کوه کن دلشده با غیرت عشق    گر نه بر فرق زند تیشه ز رشک خسروTranslation: What can lover (Farhad) do with the power of love? He has no choice but to hurt himself by ax because he feels jealousy to Khosrow. More information about Khosrow and Shirin story.

Good luck and see you soon ;)

Codeforces Round #431 Editorial

By cyand1317, history, 5 years ago, In EnglishHi, dear contestants!

With the end of Codeforces Round #431 (Div. 1 and Div. 2), some might be complaining behind the screen that problems are too tricky or hard, or have been struggling with some supposedly solvable problem... Yes, this time problems seem hard, but anyways, I hope they provided you with something, say rating, fun, ideas, or experience. I don't want to see anyone losing confidence because of failure (bad luck) in a single contest — please, don't do so.

Here are the hints, tutorials and codes for the problems. Feel free to discuss about problems in the comments, and point out if something is incorrect or unclear. Thank you!

849A - Odds and Endsby cyand1317

HintTutorial849A - Odds and EndsWhat will the whole array satisfy if the answer is Yes?

An odd number of segments, each having an odd length. Thus the whole array needs to have an odd length.All segments starts and ends with odd numbers, so the array begins and ends with odd numbers as well.Is that a sufficient condition?

Yes, because for an array of odd length, and begins & ends with odd numbers, it's a single subsegment that satisfy the requirements itself.

Thus the answer is Yes if and only if n is odd, a1 is odd, and an is odd.

Model solution849B - Tell Your Worldby cyand1317

HintTutorial849B - Tell Your WorldFirst way: consider the first three points. What cases are there?

Denote them as P1(1, y1), P2(2, y2) and P3(3, y3).

A possible Yes solution falls into one of these three cases: one of the lines pass through P1 and P2; passes through P1 and P3; or passes through P2 and P3. With each case, find out all the points that will be covered if the line is extended infinitely, and if there are still remaining points and all of them are collinear, then the answer is Yes. Time complexity is O(n).

Second way: consider the first point.

A possible Yes solution falls into one of these two cases: P1 lies alone on a line; or some i exists such that one of the lines passes through P1 and Pi. For the second case, iterate over this i, and do it similarly as above to check whether a possible solution exists; for the first case, either check it specially, or reverse the array and apply the check for second case again. Time complexity is O(n2).

Note that in this problem, there is no need to worry about floating point errors, since all possible slopes are either integers, or 0.5, which can be precisely stored with IEEE doubles.

Tommyr7's solution (first idea)Model solution (second idea)848A - From Y to Yby cyand1317

HintTutorial848A - From Y to YFor a given string, how to calculate the cost?

With several experiments, you may have found that the "minimum cost" doesn't make sense — the cost is always the same no matter how the characters are concatenated. Precisely, the cost of the process for a multiset of c1 a's, c2 b's, ... and c26 z's, is . It's in this form because every pair of same characters will contribute 1 to the total cost.

Therefore we need to find such c1, c2, ..., c26 so that . This can be done greedily and iteratively. Every time we subtract the maximum possible  from k, and add c same new letters to the set, until k becomes 0. This c can be solved by any reasonable way, say quadratic formula, binary search or brute force. Time complexity veries from  to  or any acceptable complexity, depending on the choice of the method for finding c.

Of course, if a knapsack algorithm is used, it will use the minimum possible number of different letters, and works in .

Kalinin's solutionModel solution with knapsack (!)848B - Rooter's Songby cyand1317

HintTutorial848B - Rooter's SongHow to deal with "waiting time"?

Move every dancer ti units backwards in the first place, that is to (xi - ti, 0) for the vertical-moving group, and (0, yi - ti) for the horizontal-moving group. Then start the time, making everyone start moving immediately.

When do dancers collide? What changes and what keeps the same?

Notice that if two dancers collide before any other collision happens, then they have the same x + y values for their initial positions. Furthermore, after a collision, the two dancers keep having the same x + y, and also with the same relative orders of x and y. Also, after a collision, the union of all dancers' tracks will be the same as if they "went through" each other and no collision happened at all (see the figure for sample 1 to get a general idea on this).

Therefore, divide dancers into groups by pi - ti, and collisions will happen within groups only. Dancers in the same group will move on the same x + y line (a line of slope  - 1), and however collisions take place, they will keep current relative order of x and y. It's proved before that in each group, dancers' exiting positions is the same as if no collision happened at all (namely, (xi, h) for initially-vertical dancers, and (w, yi) for initially-horizontal ones). For each group, find out all such positions. Sort all dancers according to their initial x values, and sort these positions in the direction of (0, h) to (w, h) then (w, 0). Match the sorted dancers to these sorted positions and obtain the answers for all dancers. This solution works in .

Model solution848C - Goodbye Souvenirby adedalic

HintTutorial848C - Goodbye SouvenirLet's look at segment [l, r]. Let's p1x < p2x < ... < pkx — positions of all occurences of shape x at segment [l, r]. Then memory of shape x at segment [l, r] is pkx - p1x = (pkx - pk - 1x) + (pk - 1x - pk - 2x) + ... + (p2x - p1x).

Then we can build array of pairs b: bi = (prev(i), i - prev(i)), where prev(i) — previous occurence of shape ai . A query transforms to: , which is variation of counting numbers of greater on segment.

Queries of change in position can be proccessed by recounting values prev(p) for ap and next occurence of that shape before and after changing shape.

Processing of all queries can be done by building segment tree, which every node contains Fenwick tree by types of shape. For reducing memory usage we can, for every node, save only shapes, which appeared in any query for this node. Then Fenwick tree can be build only on this shapes by coordinate compressing.

Result complexity — O(n·log2(n)).

Model solution848D - Shake It!by cyand1317

HintTutorial848D - Shake It!Use DP.

Let's try to find "subproblems" in this. A graph can be expressed as: an edge, in parallel with an unordered multiset of zero or more ordered pair of two graphs. That is, "graph = edge [// (graph + graph) [// (graph + graph) [...]]]".

A graph can be represented by two parameters: number of operations needed to build it, and its minimum cut. Let f[i][j] keep the number of graphs with i operations and a minimum cut of j. The figure below shows one of the ways in which f[8][5] can be built from other f's.

How to iterate over all such possible splitting into pairs, while keeping them unordered? One way is to iterate through pairs — instead of determining f's one by one, we find all pairs of graph parameters and add them to graphs already formed with pairs considered before. (This is like how we do it in knapsack problems.)

Iterate through the parameters of two graphs in a pair, (a, b, c, d), and use a push-style transition to add each f[i][j] into the corresponding state if the pair is added a number of times to a graph in f[i][j]. That is, for each t, add  to f[i + t·(a + c + 1)][j + t·min(b, d)] — this means a pair of graphs with parameters [a][b] and [c][d] is added t times to a graph with parameters [i][j]. With O(n4) such parameters we need to spend O(n2) time updating all values, therefore time complexity is O(n6) which is not sufficient to pass.

Note: MultiCombination(n, r) means number of ways to select an unordered multiset of r elements out of n distinct elements, where one element can be selected more than once. This equals to .

Let's see the pair as a whole. Let g[i][j] keep the number of ordered graph pairs with i operations and a minimum cut of j. At each step, in stead of iterating over four parameters of a pair, we iterate over two parameters and use values of g to perform the update.

It can be seen that f[i][j] and g[i][j] only depend on such f[p][q] and g[p][q] that p ≤ i - 1. Therefore, we can determine f and g values in order of increasing i. This solution works with O(n2) states, each of which can be calculated in O(n3) time with another O(n) factor for MultiCombination, but since a harmonic series exists in the iteration of t, this is actually . Author's implementation takes a bit lower than 800 milliseconds to find an answer.

If MultiCombination is calculated along with the iteration of t (see the model solution), this works in  which is much faster.

Bonus. Come up with a DP on dual graphs.

Model solution848E - Days of Floral Coloursby cyand1317

HintTutorial848E - Days of Floral Colourstl;dr Just look at recurrences of g, f0, f1 and f2 and the part after f2's recurrence.

Break the circle down into semicircles.

We're basically pairing flowers under the restrictions. It's hard to deal with the whole circle, let's consider something simpler. Consider an arc of length i (segment of i flowers) and their opposite counterparts, surrounded by another two pairs of opposite flowers of the same colour. We will calculate their contribution to the total beauty, f0(i) — in other words, the total beauty if only this segment is required to be coloured (we will not pair them with flowers out of this segment).

A such segment with i = 7. For clarity's sake, a flower's opposite counterpart is drawn directly below it.

We come up with a function g(i), denoting the number of ways to colour a segment of length i with pairs of opposite 1 and 2 only. The recurrence is g(0) = 1, g(1) = 0, g(i) = g(i - 2) + g(i - 4).

First case: there are no opposite pairs within this segment. There are g(i) ways to do this, giving a total beauty of g(i)·i2.

Second case: there is at least one opposite pair within this segment. Fix the position of the first opposite pair, j (in the range of 0 and i - 1 inclusive). Another two cases diverge.

(a) No pair of distance 2 crosses the flowers at position j. In this case, a subproblem of length i - j - 1 emerge, generating a total beauty of g(j)·j2 × f0(i - j - 1).

(b) A pair of distance 2 crosses the flowers at position j. In this case, new subproblems appear — an arc of length i - j - 2 and their opposite counterparts, surrounded by an opposite same-colour pair on one side, and an already-paired flower and an opposite same-colour pair on the other. Denote this subproblem as f1, this case generates a total beauty of g(j - 1)·j2 × f1(i - j - 3).

Summing up and simplifying a bit, we get the recurrence for f0:

Doing almost the same (fix the opposite pair nearest to the side of an already-paired flower), we get the recurrence for f1:

Now we've solved the subproblem for a subsegment. Hooray!

For the whole circle, let's fix a pair of opposite flowers. Let it be flowers 1 and n. This can be rotated to generate other arrangements.

But we don't know how many times it can be rotated without duplication. So we fix the second opposite pair, letting it be the first one starting from flower number 2 and going clockwise. Let its position be i, then there shouldn't be any opposite pairs within [2, i - 1], and all arrangements can be rotated in j - 1 different ways to generate all different arrangements.

Example with n = 9 and i = 5.

There may be or may be not pairs of distance 2 crossing over flowers 1 and i. Consider all four cases, we run into another subproblem with déjà vu.

We introduce a new function, f2(i), denoting the total beauty of a segment of length i, with an already-paired flower and an opposite same-colour pair on both sides.

A subproblem of length 5.

Following the method above, we get

Then the answer can be calculated in linear time, with g, f0, f1 and f2 all calculated beforehand. Overall complexity is O(n2). Refer to the square-time solution below for an implementation.

Then, note that recurrences of f0, f1 and f2 are in the form of convolutions, so we'd like to optimize it with FFT. However, they include convolutions of the previous parts of the function itself, with another function like g(i)·i2, g(i)·(i + 1)2 or g(i)·(i + 2)2.

Under this situation, apply FFT in a divide-and-conquer subroutine. solve(L, R) assumes that f(1;L - 1) are already calculated, and all the terms that contribute to f(L;R) and involve f(1;L - 1) are already accumulated in their corresponding array positions. It finishes calculation of f(L;R). First, it calls solve(L, M), then add all terms that contribute to f(M + 1;R) involving f(L;M) by convolving f(L;M) with the other function (say g(i) × i2), then call solve(M+1, R). Over complexity is .

The model solution solves f0 and f1 in one pass, and f2 in another. They can also be merged into a single pass. Big thanks to you for patiently reading till this point, and if you just want to enjoy the problem rather than implementation, feel free just to write a O(n2) solution :)

O(n^2) solutionModel solutionBehind the scene and random things (read if tired of problemsolving)ExpandThank you for reading. Next round? Perhaps something more traditional, who knows? Believe me, I'll try harder if this happens.

Cheers! \(^ ^)/

UPD Packages for problems are uploaded. They are in Polygon format and contain everything including statements, tests & generators, validators & checkers, and solutions. You can download them from Google Drive or Baidu Drive.

Tutorial Codeforces Round #430 (Div. 2)

By Glebodin, 6 years ago, translation, In English842A - Kirill And The Game)

Let's denote the potion's amount of experience as exp and its cost as cost. We want to know if there is a potion such that exp and cost meet the following condition: . To do this, we can iterate on cost from x to y and check that exp = k·cost is not less than l and not greater than r.

https://ideone.com/a8syda

842B - Gleb And Pizza)

To understand whether some piece of sausage intersects with pizza, we can check if their borders intersect. And to check this, since their borders are circles, we are interested in their radii and the distance between their centers.

To check if a piece of sausage is inside the crust, we firstly check that it is inside the pizza ), and secondly check that it is completely outside the central part of the pizza ).

https://ideone.com/Jd66XL

842C - Ilya And The Tree)

It's easy to see that if the number written on some vertex i is not equal to 0, then its beauty will be some divisor of ai. Also if the number written on the root is 0 then the beauty of each vertex can be easily calculated. Otherwise beauty of each vertex will be a divisor of the number in the root.

Let's calculate the beauty of each vertex if the number in the root is 0. This can be done by traversing the tree, and the beauty of i is gcd(ai, ans[pari]).

If the number in the root is not 0, then possible values of beauty for each vertex are among divisors of this number. For each of these divisors we can maintain how many numbers on the path from the root to current vertex are divisible by that divisor. When we enter or leave some vertex, we need to update this information by iterating on divisors of the number in the root. If we maintain it and current depth d, then we can calculate the possible beauty of current vertex. It is equal to greatest divisor such that there are at least d - 1 numbers on the path that are divisible by this divisor.

https://ideone.com/uQNFX3

842D - Vitya and Strange Lesson)

If the last query was xi and then we receive a query xi + 1, then we can leave the original array unchanged and use the number  as the second query. So we will maintain current xor of queries instead of changing the array.

It's easy to see that if the array contains all numbers from zero to 2k - 1 and the number in the query is less than 2k, then the array will still contain all those numbers.

Let's store all numbers from the array in binary trie and maintain the number of leaves in each subtree.

To answer each query, we will descend the trie. We need to get the lowest possible answer, so if current bit of the number in the query equals i (i = 0 or i = 1), so we firstly check the subtree that corresponds to bit i. We will descend into the vertex only if the subtree is not a complete binary tree (so there exists a number that would belong to this subtree but is not included in the array). When we try to descend into an empty subtree, then we set all remaining bits in the answer to zero.

https://ideone.com/gVE1kC

842E - Nikita and game)

The vertices in the answer are the endpoints of some diameter of the tree.

Let's consider diameter (a, b), where a and b are its endpoints, and we add a new vertex с. Then the length of diameter either remains the same or increases by one (then new endpoints are vertices (a, c) or (b, c)).

We have to maintain current centers of the tree (there are not more than two centers). If the length of diameter increases, then the number of centers changes (but there will always exist a vertex that was the center before the query and remains the center after the query).

Let's build a segment tree on the eulerian tour of the tree. The vertex that maintains the segment [l, r] will store current maximal distance to the center and the number of vertices that have this distance. Then the answer for the query will be stored in the root of the segment tree.

When we add a new vertex, we need to check whether the length of diameter increases; this can be done with LCA. If the diameter increases, we update centers and distances to them.

https://ideone.com/5tXC92

Codeforces Round #429 [Editorial]

By totsamyzed, 6 years ago, translation, In EnglishGenerous Kefa — Adiv2(Authors: Mediocrity, totsamyzed)

Consider each balloon color separately. For some color c, we can only assign all balloons of this color to Kefa's friends if c ≤ k. Because otherwise, by pigeonhole principle, at least one of the friends will end up with at least two balloons of the same color.This leads us to a fairly simple solution: calculate number of occurrences for each color, like, cntc.Then just check that cntc ≤ k for each possible c.Complexity: O(N + K)

Godsend — Bdiv2(Author: Mediocrity)

First player wins if there is at least one odd number in the array. Let's prove this.Let's denote total count of odd numbers at T.There are two cases to consider:1) T is odd. First player takes whole array and wins.2) T is even. Suppose that position of the rightmost odd number is pos. Then the strategy for the first player is as follows: in his first move, pick subarray [1;pos - 1]. The remaining suffix of the array will have exactly one odd number that second player won't be able to include in his subarray. So, regardless of his move, first player will take the remaining numbers and win.Complexity: O(N)

Leha and function — Adiv1(Author: Mediocrity)

First of all, let's understand what is the value of F(N, K).For any subset of size K, say, a1, a2...aK, we can represent it as a sequence of numbers d1, d2...dK + 1, so that d1 = a1, d1 + d2 = a2, ..., .We're interested in E[d1], expected value of d1. Knowing some basic facts about expected values, we can derive the following:E[d1 + ... + dK + 1] = N + 1E[d1] + ... + E[dK + 1] = (K + 1)·E[d1]And we immediately get that .We could also get the formula by using the Hockey Stick Identity, as Benq stated in his comment.Now, according to rearrangement inequality,  is maximized when A is increasing and B is decreasing.Complexity: O(NlogN)

Leha and another game about graph — Bdiv1(Authors: 244mhq, totsamyzed)

Model solution uses the fact that the graph is connected.We'll prove that "good" subset exists iff  - 1 values among di can be changed to 0 / 1 so that  is even. If the sum can only be odd, there is no solution obviously (every single valid graph has even sum of degrees). Now we'll show how to build the answer for any case with even sum.First of all, change all  - 1 values so that the sum becomes even.Then let's find any spanning tree and denote any vertex as the root. The problem is actually much easier now.Let's process vertices one by one, by depth: from leaves to root. Let's denote current vertex as cur.There are two cases:1) dcur = 0In this case we ignore the edge from cur to parentcur and forget about cur. Sum remains even.2) dcur = 1In this case we add the edge from cur to parentcur to the answer, change dparentcur to the opposite value and forget about cur. As you can see, sum changed its parity when we changed dparentcur, but then it changed back when we discarded cur. So, again, sum remains even.Using this simple manipulations we come up with final answer.Complexity: O(N + M)

On the bench — Cdiv1(Authors: Mediocrity, totsamyzed)

Let's divide all numbers into groups. Scan all numbers from left to right. Suppose that current position is i. If groupi is not calculated yet, i forms a new group. Assign unique number to groupi. Then for all j such that j > i and a[j]·a[i] is a perfect square, make groupj equal to groupi. Now we can use dynamic programming to calculate the answer.F(i, j) will denote the number of ways to place first i groups having j "bad" pairs of neighbors.Suppose we want to make a transition from F(i, j). Let's denote size of group i as size, and total count of numbers placed before as total.We will iterate S from 1 to min(size, total + 1) and D from 0 to min(j, S).S is the number of subsegments we will break the next group in, and D is the number of currently existing "bad" pairs we will eliminate.This transition will add T to F(i + 1, j - D + size - S) (D "pairs" eliminated, size - S new pairs appeared after placing new group).T is the number of ways to place the new group according to S and D values.Actually it's . Why? Because there are  ways to break group of size size into S subsegments. ways to select those D "bad" pairs out of existing j we will eliminate.And  ways to choose placements for S - D subsegment (other D are breaking some pairs so their positions are predefined).After all calculations, the answer is F(g, 0), where g is the total number of groups.Complexity: O(N^3)

Destiny — Ddiv1(Authors: Mediocrity, totsamyzed)

We will use classical divide and conquer approach to answer each query.Suppose current query is at subsegment [L;R]. Divide the original array into two parts: [1;mid] and [mid + 1;N], where . If our whole query belongs to the first or the second part only, discard the other part and repeat the process of division. Otherwise, L ≤ mid ≤ R. We claim that if we form a set of K most frequent values on [L;mid] and K most frequent values on [mid + 1;R], one of the values from this set will be the answer, or there is no suitable value.

K most frequent values thing can be precalculated. Run recursive function build(node, L, R). First, like in a segment tree, we'll run this function from left and right son of node.Then we need K most frequent values to be precalculated for all subsegments [L1;R1], such that L ≤ L1 ≤ R1 ≤ R and at least one of L1 and R1 is equal to .

We will consider segments such that their left border is mid in the following order: [mid;mid], [mid;mid + 1], ...[mid;R]. If we already have K most frequent values and their counts for [mid, i], it's rather easy to calculate them for [mid, i + 1]. We update the count of ai + 1 and see if anything should be updated for the new list of most frequent values.

Exactly the same process happens to the left side of mid: we are working with the subsegments in order [mid;mid], [mid - 1;mid], ..., [L;mid].

Now, having all this data precalculated, we can easily run divide and conquer and get the candidates for being the solution at any [L;R] segment. Checking a candidate is not a problem as well: we can save all occurrences in the array for each number and then, using binary search, easily answer the following questions: "How many times x appears from L to R?".

Complexity: O(KNlogN)

In a trap — Ediv1(Author: Mediocrity)

The path from u to v can be divided into blocks of 256 nodes and (possibly) a single block with less than 256 nodes. We can consider this last block separately, by iterating all of its nodes.Now we need to deal with the blocks with length exactly 256. They are determined by two numbers: x — last node in the block, and d — 8 highest bits. We can precalculate this values and then use them to answer the queries.Let's now talk about precalculating answer(x, d). Let's fix x and 255 nodes after x. It's easy to notice that lowest 8 bits will always be as following: 0, 1, ..., 255. We can xor this values: 0 with ax, 1 with anextx and so on, and store the results in a trie. Now we can iterate all possible values of d (from 0 to 255) and the only thing left is to find a number stored in a trie, say q, such that q xor 255·d is maximized.

Complexity: O(NsqrtNlogN)

Codeforces Round #428 editorial

By Arpa, history, 6 years ago, In EnglishHi!

HintsA: Tag: Greedy!

B: Tag: Greedy!

C: For each vertex like v find exv, the expected length of their journey if they start from v.

D: Tag: Inclusion exclusion.

E: Find the maximum clique.

Solutions839A - Arya and BranLet t be number of her candies. At i-th day , we increase t by ai ,then we give Bran min(8, t) . So we decrease k from this value. We will print the answer once k becomes smaller or equal to 0 . Or we will print  - 1 if it does’n happen after n days.

Arpa's solution: 29412123.

839B - Game of the RowsUse greedy solution. Consider a group with x ≥ 4 members, put 4 of them in seats [3, 6] of some row, and throw the row. Now we have x - 4 members in this group now. Continue till all of the seats in the range [3, 6] become full, continue with [1, 2] and [7, 8]. Now handle groups with size  ≤ 3.

For groups with size  = 3, allocate 4 seats in range [3, 6] or 4 seats in range [1, 2] or [7, 8].

For groups with size  = 2, allocate 2 seats in range [1, 2] or [7, 8] or 3 seats in range [3, 6]. If no seat found, divide this group and make it two groups with size 1.

Fill the other parts with groups with groups with size  = 1.

If in any part we ran out of seat, the answer is NO, YES otherwise.

Arpa's solution: 29412154.

839C - JourneyLet the cities be vertices and roads be edges of a tree and vertex 1 be the root of the tree.

Let ans[i] be the answer for the i-th vertex (the expected value if they start their journey from that vertex and the horse doesn't go to it's parent). Now we can calculate ans[i] by knowing the answer for it’s children. Let v1, v2, …., vk be the children of i-th vertex , then  . Because when we are at i-th vertex , we have k choices with equal probabilities and  + 1 for going to one of them (length of the edge between i-th vertex and it’s children).

So if we know the answer of some vertex’s children, we can calculate its expected value and we can do it by a simple DFS (note that the answer for a leave is 0).

Arpa's solution: 29412220.

839D - Winter is here1st method:

Let cnt[i] be the number of such js that aj is divisible by i. Also let p[i] be i-th prime number.

Let f(m) be  for an arbitrary set with m members(something like the sum of strengths of all possible subsets, but replace 1 with the gcd of the sequence)

Finally let ans[i] be the sum of strengths of clans which gcd(strengths - of - clan’s - soldiers) = i.

Now we can calculate ans[i] by “Inclusion–exclusion principle” :



Because i·f(i) includes all possible clans that their members are all multiples of i, not the ones with gcd equal to i .Now, we can do the above calculation by a “foor-loop” through the multiples of i.

So all we have to do , is to calculate f(x) very fast. Actually f(x) = x·2x - 1 because :



2nd method:

Let cnt[i] be the number of such js that aj is divisible by i. Than cnt[i] is count of soliders with strength of i, 2i, 3i, ....

Let ans[i] be count of people in clans with gcd = i. To find ans[i] let's understand, how to find count of people in clans, in which every number is divided by i. If cnt[i] = c, it's



Let's calculate ans[i] from the end. Then ans[i] = cnt[i]·2cnt[i] - 1 - ans[2i] - ans[3i] - ....

Answer for problem's question is .

Asymptotics of solution is , where k is maximal value of ai.

NikaraBika's solution: 29458745.

839E - Mother of DragonsLemma : Let G be a simple graph. To every vertex of G we assign a nonnegative real number such that the sum of the numbers assigned to all vertices is 1. For any two connected vertices (by an edge), compute the product of the numbers associated to these vertices. The maximal value of the sum of these products is when assign equal numbers to a maximal clique (a subgraph that all of its vertices are connected to each other) and 0 to the rest of the graph.

Proof : If the graph is complete of order n then the problem reduces to finding the maximum of  knowing that x1 + x2 + … + xn = 1. This is easy, since . The last inequality is just the Cauchy-Schwarz inequality and we have equality when all variables are .

Unfortunately, the problem is much more difficult in other cases, but at least we have an idea of a possible answer: indeed, it is easy now to find a lower bound for the maximum: if H is the complete subgraph with maximal number of vertices k, then by assigning these vertices  and to all other vertices 0, we find that the desired maximum is at least . We still have to solve the difficult part: showing that the desired maximum is at most .

Let us proceed by induction on the number n of vertices of G. If n = 1 everything is clear, so assume the result true for all graphs with at most n−1 vertices and take a graph G with n vertices, numbered 1, 2, ... , n. Let A be the set of vectors with nonnegative coordinates and whose components add up to 1 and E the set of edges of G. Because the function  is continuous on the compact set A , it attains its maximum in a point (x1, x2, ... , xn). If at least one of the xi is zero, then f(G) = f(G1) where G1 is the graph obtained by erasing vertex i and all edges that are incident to this vertex. It suffices to apply the induction hypothesis to G1 (clearly, the maximal complete subgraph of G1 has at most as many vertices as the maximal complete subgraph of G). So, suppose that all xi are positive. We may assume that G is not complete, since this case has already been discussed. So, let us assume for example that vertices 1 and 2 are not connected. Choose any number 0 < a ≤ x1 and assign to vertices 1, 2, ... , n of G the numbers x1−a, x2 + a, x3, ... , xn. By maximality of f(G), we must have  , where C1 is the set of vertices that are adjacent to vertex 2 and not adjacent to vertex 1 (the definition of C2 being clear). By symmetry, we deduce that we must actually have  , which shows that f(x1, x2, ... , xn) = f(0, x1 + x2, x3, ... , xn). Hence we can apply the previous case and the Lemma is solved.

Now by the Lemma , we have to find the maximal clique and get the answer.(Let the maximal clique have m vertices, then the answer is ).

We can find the maximal clique by the "meet in the middle" approach. Divide the vertices of the graph into 2 sets with equal number of vertices in each set(if n is odd, one set will have a vertex more than the other). We can save the maximal clique for each subset of the first set in dp[mask]. Now ,for each clique C in the second set, let v1, ... , vt be vertices in the first set that are connected to all of the vertices of C. Then m = max(m, dp[mask(v1, ... , vt)] + sizeof(C)) (m is size of maximum clique). Note : finding the maximal clique is also possible by a wise brute forces.

Arpa's solution: 29412249.

P.S. Please notify me if there is any problem.

Codeforces Round #427 Editorial

By qoo2p5, history, 6 years ago, translation, In EnglishProblem A. Key races835A - Key racesInformation on the success of the first participant will come in 2·t1 + v1·s milliseconds, of the second participant — in 2·t2 + v2·s milliseconds. We need to compare these numbers and print the answer depending on the comparison result.

C++ code: 29077019

Python code: 29077039

Problem B. The number on the board835B - The number on the boardLet's rephrase the problem a little. Suppose that we initially have a number n and we need to make a number from it with the sum of digits at least k, changing as fewer digits as possible.

Obviously, it is optimal to replace the digit with 9. When we replace digit d with 9, we increase the sum by 9 - d. It means it's optimal to replace the minimal digit.

Let cnti be the number of occurrences of the digit i in n. While the sum is less than k we will repeat this

Find minimal i that cnti > 0.Decrease cnti by 1.Increase the answer by 1.Increase the sum by 9 - iIt's not hard to prove, that algorithm makes as less replaces as possible.

Alogithm works in  time and O(1) additional memory.

C++ code: 29077095

Python code: 29077110

Problem C. Star sky835C - Star skyThe brightness of the i-th star in moment t is , where  is modulo operator.

Let's precalc for each p = 0...С, x = 1...100, y = 1...100 cnt[p][x][y] — the number of stars with the initial brightness p in the rectangle (1; 1)-(x; y). It is calculated like calcuating of partial sums: cnt[p][x][y] = cnt[p][x - 1][y] + cnt[p][x][y - 1] - cnt[p][x - 1][y - 1] + (the number of stars in the point (x;y) with the initial brightness p).

Then the total brightness of stars at the i-th view is , where  is the number of stars with the initial brightness p in the given rectangle. This number can be calculated using array , using the inclusion-exclusion principle: amount(p, x1, y1, x2, y2) = cnt[p][x2][y2] - cnt[p][x1 - 1][y2] - cnt[p][x2][y1 - 1] + cnt[p][x1 - 1][y1 - 1].

Let X is the maximum coordinate. Time complexity: O(n + qc + cX2). Memory complexity: O(cX2).

C++ code: 29077145

Java code: 29077165

Problem D. Palindromic characteristics835D - Palindromic characteristicsObservation I.

If the string is k-palindrome, then it is (k - 1)-palindrome.

Observation II.

The string is k-palindrome if and only if the both following conditions are true:

It is a palindrome.It's left half is non-empty (k - 1)-palindrome.Solution.

Let's calculate the following dp.

dp[l][r] is the maximum k such that the substring built from characters from l to r is k-palindrome.The dynamics is calculated in the order of non-decreasing of substring lengths.The values for l = r and l = r - 1 are computed trivially.Let r - l > 1. Then, if s[l] ≠ s[r] or dp[l + 1][r - 1] = 0, dp[l][r] = 0. Otherwise dp[l][r] = dp[l][m] + 1, where .When we have dp values, we can calculate cnt[k] — the number of substrings, which dp value is k. Then the number of substrings that are k-palindromes is .

The solution works in O(|s|2) time and uses O(|s|2) memory.

Also, you could notice that the string can be no more than -palindrome, and solve the problem in  time, reducing the memory usage to O(|s|).

C++ code: 29077222

Java code: 29077251

Python code: 29077276

Problem E. The penguin's game835E - The penguin's gameThe solution can be separated into several parts.

I. Finding the parity of the number of special icicles in the given subset using 1 question.

Consider the following cases:

Subset's size is even, the number of special icicles in it is even. Then the answer to such question is 0.Subset's size is even, the number of special icicles in it is odd. Then the answer to such question is .Subset's size is odd, the number of special icicles in it is even. Then the answer to such question is x.Subset's size is odd, the number of special icicles in it is odd. Then the answer to such question is y.x, y ≥ 1 and x ≠ y, so the numbers 0, x, y,  are pairwise distinct. Therefore, we can find the parity of the number of special icicles on the given subset using 1 question.

II. The solution for the problem for the only one special icicle.

Suppose we have n icicles, and one of them is special. Then you can find it using  questions.

The algorithm is to use binary search over the minimum prefix that contains the special icicle.

III. The solution of our problem.

Each integer n ≤ 1000 can be written using no more than  bits. Iterate over the bits from 0 to . Ask a question about the icicles that have 1 in their numbers in the fixed bit. After that, we can determine if the numbers of the special icicles differ in this bit. Really, the bits differ if this subset's size is odd, and don't differ otherwise.

Obviously, we will find at least one bit, where their numbers differ. Let A is the subset of the icicles that have 1 in this bit, and B is the complement set. Let m is the size of the smallest from these subsets. Then . Let's solve the problem for the only one special icicle for the smallest of these subsets.

Then it's easy to get the number of the other icicle: we know the number of the first icicle and we know in which bits the numbers differ and in which don't.

This solution uses 19 question. It can be proven that in the given constraints you can't solve this problem in less than 19 questions.

C++ code: 29077366

Problem F. Roads in the Kingdom835F - Roads in the KingdomObservation I.

The given graph is a cycle with hanged trees. So, we can remove the edge only from the cycle, the resulting graph will be a tree.

Observation II.

We can minimize the distances only between the pairs of vertexes such that path between them goes through the cycle's edges. Let's say that these pairs are interesting.

Solution.

Let's find the cycle using dfs. Let its length be k. Let's number the vertices in it from 1 to k in round order. We will try to remove edges between 1 and 2, 2 and 3, ..., 1 and k and calculate the maximum distance between the interesting pairs.

We need to pre-compute the following:

di — the maximum depth of the tree hanged to the i-th vertex of the cycle.wi — the length of the edge between the i-th vertex of the cycle and the next in the round order.pref_diami — the maximum distance between the interesting pairs such that their vertexes are in the trees hanged to the vertexes 1, 2, ..., i of the cycle.suff_diami — the maximum distance between the interesting pairs such that their vertexes are in the trees hanged to the vertexes i, i + 1, ..., k of the cycle.pref_fari — the maximum distance from the first vertex of the cycle to the vertexes that are in the trees hanged to the vertexes 1, 2, ..., i of the cycle.suff_fari — the maximum distance from the first vertex of the cycle to the vertexes that are in the trees hanged to the vertexes i, i + 1, ..., k of the cycle.Also suff_diamk + 1 = suff_fark + 1 =  - ∞.

These pre-computations can be done in linear time.

If we delete the edge between the i-th vertex of the cycle and the next in the round order, then the maximum distance between the interesting pairs is max(pref_far[i] + suff_far[i + 1], pref_diam[i], suff_diam[i + 1]).

After we found the optimal edge to remove, we remove it and find the diameter of the resulting tree. It can be done with 2 dfs'es. Let vertex v be the farest from 1. Let vertex u be the farest from v. It's easy to prove that the path between u and v is the diameter.

Time complexity: O(n). Memory complexity: O(n).

C++ code: 29077386

Codeforces Round #426 Editorial

By GreenGrape, 6 years ago, translation, In EnglishWe, the round authors, are eternally grateful to all the brave who took part in this round. Sadly there were some issues to encounter, but we hope it only made the contest more interesting :)

834A - The Useless ToyPrequisites: none.

The sole fact that the spinner has four positions, which are repeated periodically, leads us to the following observations that are easily verifiable:

first thing is that no matter what the direction was, when k is even we're going to get the same ending position;secondly, if we replace n by , the resulting problem would have the same answer (basically we have removed full rotations of the spinner from consideration).Thus, if , the answer is "undefined". Otherwise, we have to find the aforementioned remainder and find the direction of the spin, which is pretty straightforward.

Time complexity: O(1).

Code: 29027824

834B - The Festive EveningPrerequisites: none.

This problem is solved with two linear sweeps. In the first one, we determine the last position for each letter. In the second one, we just model the process: we mark the letter as active when we stumble upon it for the first time, and as inactive when we reach the last position for this letter. If there are more than k letters active at some specific point of time, we output "YES". Otherwise, we output "NO".

Time complexity: O(n).

Code: 29027867

834C - The Meaningless GamePrequisites: none (maybe binary search).

Let S denote the product of the set of numbers said by Slastyona, and P denote the product of the set of numbers barked by Pushok (in case one of the sets is empty the corresponding product is assumed to be equal to one).

Then, we can reformulate the problem in a following way: we need to find such S and P that the following holds:

We can already see a slow way to solve the problem. It is based on assumption that if a ≤ b, then S ≤ P and S3 ≤ 109, so we can just enumerate all possible values of S.

Unfortunately, we have as much as 350000 games. So we need to find a more efficient solution.

Note that ab = S3·P3, and  (let us denote the cubic root as X). We can then easily find the required values:

We only need to check whether ab is a perfect cube and  divides a and b.

Time complexity: O(1) (or O(log(ab)) if binary search was used to find the cubic root).

Code: 29027782

833B - The BakeryPrerequisites: dp + segment trees

All authors' solutions are based on the following dp idea: let's calculate dp(k, n) — the maximum cost we can obtain if we assign the first n cakes to k boxes.

For k = 1 the answer is equal to the number of distinct values on a prefix.

For k > 1 the answer can be deduced as follows (here c(i, n) denotes the number of distinct elements in range (i, n)):

dp(k, n) = max1 ≤ i < ndp(k - 1, i - 1) + c(i, n)There are two possible approaches.

Solution I:

Imagine we're trying to compute the k-th dp layer and our currect position is i, maintaining a max segment tree with the sum dp(k - 1, j) + c(j + 1, i) in j-th cell where 0 ≤ j < i. The answer for dp(k, n) is just a prefix query.

How do we move i the right? Let's denote i-th cake type as y. Notice that the i  →  i + 1 transition increases the segment tree values for all cells j such that there's no y in range [j + 1, i] by one (since we've added a new distinct element).

More formal, we increase all j's between the previous position of y plus one (or the beginning of the array if we haven't marked y before) to i. Hence we got a lazy update segment tree and a simple prev[i] precalc. There's a single  for both updating and computing a single dp(k, n) and a total complexity of .

Solution II:

Many tried this approach and failed. Albeit we didn't focus on cutting this solution much, it still required several optimizations to pass.

Let's denote the leftmost i such that dp(k - 1, i) gives the optimal answer for dp(n, k) as opt(k, n). We claim that opt(k, n) ≤ opt(k, n + 1)) (this one is a left as an exercise to the reader).

With with assumption it is the right time for applying divide & conquer dp optimization (here persistent segment tree is used for counting the number of distinct cakes in a range, which is a well-known application of it; the divide and conquer technique is described here, for example: codeforces.com/blog/entry/8219).

There are  relaxes in a single dp layer, each of those is processed in . With a total of k layers we get the overall complexity of .

Code (divide & conquer, GreenGrape) 29027705

Code (divide & conquer, xen) 29027883

Code (lazy propagation) 29027667

833C - Ever-Hungry KrakozyabraPrerequisites: Combinatorics or strong faith :)

At first we might assume (without loss of generality) that both left and right bounds are strictly less than 1018 (otherwise we just append 1 to the list of unedible tails) and hence consider only numbers with no more than 18 decimal digits.

Notice that there are not than many numbers without leading zeros: they are no more than  (the number of solutions to c1 + c2 + ... + cn ≤ 18, where ci — the number of i-s in a number). To be precise, there are only 4686824 such numbers in range 1  →  1018. Thus we might simply brute all such numbers and for a fixed candidate (let's denote it as A), whether it is possible (using some additional zeros if neccessary) to form the number A' from the range [L, R].

How do we check it rapidly? Let's represent L and R as vectors of length n (we might add some leading zeros to L if neccessary), and A — as an array num (with possible additional zeros).

We will brute it in the following way: go(pos, lflag, rflag), which keeps out current position and indicates whether the currently obtained number is equal to the corresponding prefix of L / R. Several cases to consider:

If (pos = n), we return true.If (lflag = 1) и (rflag = 1), we strictly follow the prefixes of L and R. There are two deeper cases:If L(pos) = R(pos), the only way out is to place L(pos), decrease the number of corresponding digits in num and proceed to go(pos + 1, 1, 1).Else if L(pos) < R(pos), we have to check if there's an element in [L(pos) + 1, R(pos) - 1]. It's obvious that the answer is true in this case (since after we get right between L and R we can assign the suffix whichever way we want). Otherwise we first consider the possibility of placing L(pos) and proceeding to go(pos + 1, 1, 0) or placing R(pos) and proceeding to go(pos + 1, 0, 1). If nothing returns true, the answer is false;If only left flag is active (lflag = 1), we need a random digit from the suffix [L(pos) + 1, 9]. If we find it — the answer is true. If no — we try L(pos) and go(pos + 1, 1, 0) or return false.A lone right flag is processed in a simular way with the only difference that we try the [0, R(pos) - 1] prefix or R(pos) and go(pos + 1, 0, 1).At a first glance it seems that out bruteforce will end up being O(2n). But an easy observation shows that there can be no more that two separate branches here. The total bruteforce complexity is O(10·n).

Complexity: , where K stands for the maximum number length.

Code: 29027757

833D - Red-Black CobwebPrequisites: centroid decomposition, segment tree / BIT / treap, modulo division

Analogically to the vast variety of problems where we are to find some information about all the paths of the tree at once, we can use centroid decomposition as a basis.

Let us fix some centroid and some path consisting of r red and b black vertices (let us denote it as a pair (r, b)). For this path, we need to somehow obtain (and do it fast!) information about all augmenting paths — such pairs (r', b') that 2·min(r + r', b + b') ≥ max(r + r', b + b').

Let us simplify a problem for a little while: let's assume we are only interested in finding such paths (r', b') that 2·(r + r') ≥ (b + b'). If we rewrite the inequality as (2·r - b) ≥ (b' - 2·r'), we can clearly see that the paths we are interested in comprise the suffix of some tree with nodes having indices 2·x - y.

Unfortunately, this bound is not enough. We need to discard all the paths that satisfy not only this condition, but also have a red part which is too long, i.e. those having 2·(b + b') < (r + r').

With the same trick we the inequality turns into 2·b - r < r' - 2·b', describing some prefix of a x - 2·y tree.

We should maintain size and product of clamminesses for all subtrees. Then the problem of calculating the contribution of a fixed path reduces to quering these two trees.

More precisely, for a (r, b) path with clamminess x looks as follows. Denote suffix(2·r - b) as (size, product) for the first tree, and prefix(2·b - r) as the corresponding pair for the second one. Then the first pair gives us the positive contribution of (product·xsize) whereas the second pair gives the same amount of negative contribution (in terms of the second tree this time). The only thing left is to divide them modulo 1e9 + 7.

We might get a little bit more tricky and use modulo givision only when we process all paths from this centroid; this will give us the total complexity of , where M = 1e9 + 7.

Code: 29027729833E - Caramel CloudsPrequisites: scanline.

The key idea is that only minutes which are covered by no more than two clouds can contribute to the answer.

Let us demonstrate how to solve the problem for a fixed k using scanline. Let's create 2·n events: for the start and the end of each cloud. We will then go through all the events in ascending order of their coordinates, maintaining the following values:

the set of active clouds open;the count of sunny (from the beginning!) minutes free;the array single(i), which denotes the number of minutes covered solely by cloud i;the variable top – the largest number of sunny minutes we can obtain on a given prefix by deleting no more than two clouds;the sparse table cross, whose element (a, b) holds the number of minutes of sunny minutes covered solely by a and b;and finally, the array opt(i) – the optimal number of sunny minutes we can obtain if we dispel i-th cloud as one of the selected ones.We will also construct a treap (or BIT/segment tree if we want to), where each leaf has the index in form of the pair cost(i), i, keeping best index relative to single(i) in the subtree in each node.

So, let us assume we are now considering some event with the coordinate x, which is going to add some segment with length len.

If open is empty, it's enough to just increase free by len.If open contains exactly two elements (let's denote them as a and b), we need to increase cross[a, b] by len and try to update opt(a) via using b and opt(b) via using a if it's possible (i.e. if the sum of costs does not exceed the budget).The case when open only one element is the most interesting. We have to try to increase both single(a) and opt(a) by len consequently. What clouds may optima have also updated for? Obviously, for every cloud which cost allows us to dispel it together the cloud a. But it's only necessary to update opt only for cloud with maximal single(x) (don't forget to delete a from the tree) on range [0..C - cost(a)]. Why? We leave this as an excercise for the reader.After that, we will either need to remove the start of the cloud from open if we are dealing with a closing event, or to put it into open otherwise.

Along with aforementioned operations we can also update the variable top. It's not that hard to observe that if free + top ≥ k, the answer would be some point of the last segment: we can find it as x - (free + top) - k.

It's also worth noting that if we are to order all the queries in the non-descending order, the answers would be ordered the same way. We can then process them in one go.

Time complexity: .

Code: 29027876

Codeforces Round #425 (Div.2) Editorial

By Loud_Scream, history, 6 years ago, In Russian832A - Sasha and SticksNote, that it's not important from which side sticks are being crossing out. Players will make summary  turns. If this number is odd, Sasha made 1 more turn than Lena and won. Otherwise, Sasha and Lena made same number of turns and Sasha didn't win.

Solution Arpa: 28852813

832B - Petya and ExamIf pattern doesn't contain "*", to match pattern, it's neccesary that string's size is equal to pattern size , all letters in pattern match with the letters in string, and in the positions on which pattern contains "?", the string contains good characters.

If pattern contains "*", split it into two strings: p1 contains all characters before "*" and p2 after it. Note, that string doesn't match pattern, if it's size is less than |p1| + |p2|. Split the string into three: s1 is prefix of size |p1|, s2 is suffix of size |p2|, and s3 is the remaining substring. The string mathes pattern, if s1 matches p1, s2 matches p2 and s3 contains only bad characters.

Obviously, that we can make all checks in time of O(|s|). Final asymptotics is .

Solution Arpa: 28852764832C - Strange RadiationWe'll use binary search by answer. Obviously, that answer is always less than 106 and more than 0. We denote the answer for t at current iteration.

For each person, running left, we have to find positions of bomb, at which he will have time to reach the point 0 in time t. Let d be the distance between the person and point 0 and d1 be the distance, which passed the person before he caught up with the ray.

If , we can place bomb in every point.

Otherwise, we can place bomb in point x, 

Before the meeting with the ray, person ran a distance of d1 at a speed of vi, after the meeting he ran a distance of d - d1 at a speed of vi + s. We require the total time be no more than t.We need the person to be caught by rays, so bomb have to have coordinate more than person's initial coordinate.We know that rays and person met at the point of d - d1 at the moment of . Rays moves at the speed of s. It means they started moving at the point of .Note that solutions of this system form a segment on the coordinate line.

For persons, running right, the reasoning is similar.

We find all the segments for persons, runnig left, and persons, running right. If some point with the whole coordinate belongs to segment for person, running left and person, running right, we move right border of binary search and left border otherwise.

To find this point we can use scanline or prefix sums. Let the binary search make it iterations. Than final asymptotics is O(n · log n · it), if we use scanline, or O((n + maxx) · it) if we use prefix sums.

Solution KAN: 28853440832D - Misha, Grisha and UndergroundLet vertex 1 be the root of the tree. For each vertex i we calculate value hi  — distance to the root.

Now we can represent way v1  v2 as two ways v1  lca(v1, v2) and lca(v1, v2)  v2.

Note that number of edges in the interseption of two such ways v1  v2 и u1  u2, hv1 ≤ hv2, hu1 ≤ hu2 is max(0, hlca(u2, v2) - max(hv1, hu1)). We can calculate lca in O(log n), using binary lifting, or in O(1), using .

Using the formula we can easy calculate answer for fixed s, f and t. To answer the query, we consider all possible permutations of a, b and c, there are only 3!.

Final asymptotics is O(n · log n + q · log n) or O(n + q), depending on the lca search algorithm.

Solution Arpa: 28853297832E - Vasya and ShiftsThe first thing to notice is that the problem can be reduced to a matrix form. To do this quite easily, we note that if we denote xi as the number of times we apply the i-th row, then we will get the matrix, we will have exactly n columns (xi) and m rows. That is, Aij will match the i-th symbol in the j-th row. Now we get the usual system of linear equations. Note that we have a restriction on xi, , that is, we are interested in the number of SLE solutions, modulo 5. Then for each query it would be possible to find the number of solutions using the Gauss algorithm (0 or 5n - rk(A)), but this solution will take O(n3·q) time, which does not fit under restrictions. One of the optimizations for improving the algorithm is to bring the matrix A to a triangular matrix form (find the rank) and memorize the transformations. Then for each query string we could apply these transformations, then the algorithm will work O(n3 + q·n2), which is already past Time Limit.

Solution Loud_Scream: 28853611

Codeforces Round #424 Editorial

By KAN, 6 years ago, translation, In English831A - Unimodal ArrayLet use two variables pos1 и pos2. Initially pos1 = 0 and pos2 = n - 1.

After that we need to iterate through the given array from the left to the right and increase pos1 until the next element is strictly more than previous. After that we need to iterate through the given array from the right to the left and decrease pos2 until a[pos2 - 1] > a[pos2].

Now it is left only to check that all elements between positions pos1 and pos2 are equal to each other. If it is true the answer is "YES", otherwise, the answer is "NO".

831B - Keyboard LayoutsAt first we need to support the correspondence of letters on keyboards. For example, it can be done with help of map < char, char > . Let's call it conformity.

Let the first layout equals to s1 and the second — s2. Now we need to iterate through the first string and make conformity[s1[i]] = s2[i]. Also we need to make conformity[toupper(s1[i])] = toupper(s2[i]), where function toupper(c) gives the lowercase letter c to the corresponding uppercase letter.

After that simply iterate through the given text. Let the current symbol is c. If c is a digit we need to print it. Otherwise, c is a letter, so we need to print conformity[c].

831C - Jury MarksAt first let's calculate an array sum where sum[i] equals to sum of the first i jury points.

Now consider the value b1. Let the initial score equals to x. Here we need to iterate by m from 1 to k — how many members of jury rated the participant until Polycarp remembered b1. Then x = b1 - sum[m]. Insert each initial scores in set.

So, we got all possible initial participant scores. After that it is left only to check correctness of each initial score.

Let the another candidate on initial score equals to d. We need to put in set points all values d + sum[i] for all i from 1 to k. After that we need to check that all elements of array b can be find in points. If it is true the participant could has initial score d points, so we need to increase the answer on one.

830A - Office KeysTo solve this problem you need to understand the fact that all keys which people will take is continuous sequence of length n in sorted array of keys.

At first let's sort all keys in increasing order of their positions. Then brute which of the keys will take a leftmost person. Let it will be i-th key. Then the second person from the left will take the key i + 1, third — (i + 2) and etc. So, we can determine the time after which all people can reach the office with keys if the sequence of keys beginning from i-th key. Now we need to update the answer with this value and move to the next position i + 1.

830B - Cards SortingFirst note that operation "put a card under the deck" is the same as "stark viewing from the beginning when you reach the end", and do not move cards anywhere.

Then, let's proceed all cards with equal numbers on them at once. It's obvious that Vasily puts them away one after another. Let's denote the position where he was when he put the last card less than x be position p in the deck. Two cases are possible.

If all cards equal to x are after position p, then he looks all the cards until he takes the last card with x, and puts away all cards equal to x;Otherwise there is a card with x that is before p. In this case Valisy looks at all cards from p to the end, and after that — at all cards from the beginning of the deck to the last card with x that is before p.It's easy to process both cases if we keep for each x positions of all cards with x from the top to the bottom of the deck. Aside of this we need any data structure that is capable of computing sum on a segment and changing a single value (we can store 1 for a position with a card in the deck, and 0 is the card is already put away). We can use segment tree or Fenwick tree for example.

830C - Bamboo PartitionFirst fact: The problem is asking to maximize d such that: .

. Let , then .

Second fact: Number of possible values for  is .

For x, let  these values are 1... A and .

So there is at most  segments for d such that  will not change.

Now generate all possible values and sort them, and for each segment check if there is a d in that segment satisfying the condition and update the answer.

My solution.

Thanks Arpa for this editorial!

830D - Singer HouseHint: Compute dp[k][c] "what is the number of sets of c non-intersecting paths in k-house?" Yes, it works. The answer is dp[k][1].

dp1, 0 = dp1, 1 = 1.

For updating dpi from dpi - 1 for each L, R(1 ≤ L, R ≤ 2i - 1) Let X = dpi - 1, L·dpi - 1, R:

Take the root, and make itself a new path  dpi, L + R + 1 +  = X.

Don't take the root  dpi, L + R +  = X.

Take the root, and connect it to a path in the left child  dpi, L + R +  = X·L·2.

Take the root, and connect it to a path in the right child  dpi, L + R +  = X·R·2.

Take the root, and it combines two paths  dpi, L + R - 1 +  = X·C(L + R, 2)·2.

Now the important fact is because we need dpk, 1 we only need first k values of dpi. So the complexity is .

Thanks Arpa for this editorial!

830E - Perpetual Motion MachineBy default, all vertices contain 0. We will solve problem in few steps, getting answer for our question in different cases.

Graph contains cycle. In this case, solution exists, all vertices of cycle contain 1, sum would be 0.Graph contains vertex with degree more than 3. Solution exists, this vertex has 2 and its neighbours 1. Sum will be 22 + deg(v) - 2 * deg(v) ≤ 0 when deg(v) ≥ 4.Graph contains more than one vertex of degree 3. In this case we can reduce to previous case: we put 2 in the between these vertices and ones in other neighboors. Doing this, we "contract" path between vertices to one with the number 2 and obtain vertex of degree 4.Graph contains just one vertex of degree 3. It is the most complicated point in our solution. We just state this and prove it later.Statement: There is only one vertex with degree 3, with 'tails' of sizes p - 1, q - 1 и r - 1 (length of the tail = how many vertices lay on it). In this case expression can take only non-positive values if .

All graph's vertices have degree less than 3. This case can be easily reduced to previous one, having p = 1.We are going to prove this by two ways.

First way: Let's look on tail, sized k, having form of the bamboo. Numbers in vertices are ai and have sum A. We are going to minimize A. As one can see,

2A = 2a12 - 2a1a2 + 2a22 - 2a2a3 + ... - 2ak - 1ak + 2ak2 = a12 + (a2 - a1)2 + (a3 - a2)2 + ... + (ak - ak - 12) + ak2Let ak = S, d1 = a1, d2 = a2 - a1, d3 = a3 - a2, ..., dk = ak - ak - 1. Тогда

2A = d12 + d22 + ... + dk2 + S2While

So we have S and we want to choose k numbers with sum S so that sum of their squares is as small as possible. One can prove, that best choice is , while having sum . In this case .We will use induction for proof. Base (n = 1) is evident. Step n → n + 1:  – optimal sum of squares if one of n + 1 numbers is x. We shall minmize this function. This is nearly equal to derivative being zero. , what we wanted to prove.

Now we get back to construction where are three tails of sizes p, q и r are connected to 3-degree vertex. Number in 3-degree vertex is S, value of the whole graph is D, and values of tails are A, B и C. (2A - S2) + (2B - S2) + (2C - S2) = 2D + S2. If we fix S, when, as it was shown before optimal values of tails are i, , . We have . It means that D ≤ 0 can be only if .

Second way:

Let the tail of size p have numbers in vertices x1, x2, ... xp - 1 counting from the leaf, size q - y1, y2, ... yq - 1, size r - z1, z2, ... zr - 1. Root we will define as v = xp = yq = zr.

Let

Ax = x12 + x22 + ... + xp - 12 - x1x2 - ... - xp - 2xp - 1 - xp - 1v, Ay = y12 + y22 + ... + yq - 12 - y1y2 - ... - yq - 2yq - 1 - yq - 1v, Az = z12 + z22 + ... + zr - 12 - z1z2 - ... - zr - 2zr - 1 - zr - 1v.We want to compute S = v2 + Ax + Ay + Az.

One can see that



Actually, if we calculate this expression, we will have



Each term with xi2 features once on both adjacent terms and gives the sum 

When,



Because all F ≥ 0, we should have other expression not greater than zero. However, v ≠ 0, because in this case for having all squares zero all numbers would be zero. Because of this, .

Conclusion:

Necessity of this criterion is proved. Sufficiency can be seen from definition F in the second proof - we should put arithmetic progressions on all tails.

In case of graph having form of bamboo, we have , equal to  while q, r ≥ 1, what is obviously impossible. So answer is always «NO».

All mentioned above is made with few depth-first searches, so complexity of this solution is O(V + E).

Codeforces Round #423 Analysis

By KAN, 6 years ago, translation, In EnglishThe analysis is being updated.

828A - Restaurant TablesWe need to store three values: a — the number of free tables for one person, b — the number of free tables for two persons and c — the number of tables for two persons occupied by single person.

If the next group consisting of 2 persons and there are no free tables for two persons (i. e. b =  = 0) the restaurant denies service to this group and we need to add 2 to the answer. In the other case, we need subtract one from b and move to the next group.

If the next group consisting of 1 person and there is free table for one person (i. e. a > 0) we need to subtract one from a and move to the next group. In the other case, if there is free table for two persons you need to put person for this table, subtract one from b and add one to c. If there are no free tables but c > 0 we need to subtract one form c. If no one from the described conditions did not met the restaurant denies service to this group consisting of one person and we need to add one to the answer and move to the next group.

828B - Black SquareIf there are no black cells on the field it is enough to paint any one cell.

In the other case, we need to calculate 4 values:

minX — the index of upper row with black cell;maxX — the index of bottom row with black cell;minY — the index of leftmost column with black cell;maxY — the index of rightmost column with black cell.After that we can get the length of square side which should be obtained after repainting. Let this side equals to len and len = max(maxX - minX + 1, maxY - minY + 1). If len more than n or len more than m there is no solution. Else, the answer is equals to len·len - cnt, where len·len is the number of cells in the resulting square and cnt is the number of black cells on the initial field. The value cnt can be calculated in one iteration through the given field.

827A - String ReconstructionAt first let's sort all given string by their positions and also determine the length of the answer string.

After that fill the answer string with letters "a" because the answer string must be lexicographically minimal.

Let's use variable prev — the minimal index of letter in the answer string which did not already processed. After that we need to iterate through the sorted strings. If the next string ends before prev we skip it. In the other case, we need to impose this string to the answer string beginning from necessary position and write down all letters beginning from prev or from the beginning of impose (depending on which of these values is greater). If the imposing of string ends in position endPos we need to make prev = endPos + 1 and move to the next string.

827B - High LoadHint: one of the optimal solutions is a star-like tree: one "center" node with k paths with lengths difference at most one.

Proof: let the optimal answer be something different from the structure described. If it is a star with k paths, but the lengths differ by more than one, we can shorten the longest one and lengthen the shortest one, and the answer won't become greater. So, doing this operation once or more, we eventually get the described structure, that means that our answer is optimal.

If the optimal answer is not a star, let's hang it on one of its centers, and let the diameter be d. Then the depths of all leaves are not greater than . Suppose there is some edge e from the root that has more than one leaf in its subtree. Let v be some leaf in this subtree, and its depth be y. Let's take the path from leaf v all the way up to some vertex with degree more than 2, and rehang this path to the root. The tree is now more star-like, and we are going to prove that the answer didn't become larger. Obviously, we're only interested in distances between v and other leaves. Moreover, we can see that the current depth of v is smaller than y, and the distance between v and other leaves doesn't exceed . It is proved now.

827C - DNA EvolutionNote that there are only 4 different characters and queries' lengths are only up to 10. How does this help? Let's make 4 arrays of length |s| for each of the possible letters, putting 1 where the letter in s is that letter, and 0 otherwise. We can update these arrays easily with update queries.

Consider a letter in a query string e. It appears equidistantly in the string we write down under the string s. Thus, we should count the number of ones (in one of our four arrays) at positions which indices form an arithmetic progression, and bounded by some segment (the query segment [l, r]). This sounds hard, but we can note that the difference between the indices (i.e. the common difference of the arithmetic progression) is not larger than 10. Thus, we can store 10 copies of each of four arrays we created above. For the x-th copy of some letter, we reorder the elements so that first we put all positions p for which , then all positions p for which , and so on. This will make possible to change each query on an arithmetic progression to a sum query on a segment. Thus, we can just sum up answers for each letter in string e.

827D - Best Edge WeightHint 1: Find some MST in the initial graph and name it M. Now there are edges of two types: in the tree, and not in the tree. Process them in a different way.

Hint 2: For edges not in the MST, the answer is the maximum weight of MST edges on the path between the edge's ends, minus one.

Proof: Consider the edge E such that it doesn't appear in our MST and its weight is W and consider the maximum weight of MST edges on the path between the edge's ends is MX.

It's obvious that if W ≥ MX there is an MST such that E will not appear in that (at least it will not appear in M).

Now let's prove that if W = MX - 1 it will appear in any MST. Consider an MST like OM that E does not appear in that, let's prove M was not an MST and it's a contradiction. Let ends of E be v, u. Look, consider the path between v, u in M, there is an edge with weight MX in this path but there isn't any edge in OM with weight greater than or equal to MX. So M is not an MST because when we build an MST we sort edges by their weight and add them greedily (Kruskal's algorithm).

Hint 3: For an edge E in the MST, let non-MST edges such that MST path between their ends go through E be bad edges, the answer is the minimum weight of bad edges, minus one.

Proof: Let the minimum weight of bad edges be CW and weight of E be W. It is obvious that if W ≥ CW there is an MST such that E will not appear in that. Now if W < CW so we will check E before bad edges and we will add it.

The remaining part is easy: for non-MST edges, one can just query the maximum on a tree path with binary lifts or whatever other structure on a tree. For MST edges, we can do the same, but in the other direction, like range queries, or even easier with centroid decomposition, HLD or using sets and the smaller-to-larger optimization.

Thanks Arpa for the proofs!

827E - Rusty StringLet si is symbol number i from the given string.

Statement: k can be period of string s when if and only if there are no two indices i and j for which .

Evidence:

Necessity: Let it is not true. Then for any letter fill of omissions such paint i and j will left that si ≠ sj, si ≠ ?, sj ≠ ? and this contradicts the definition of the period.

Adequacy: Let fill omissions with constructive algorithm in a way that string after that is having a period k. Let's look on some remainder of division on k. There are two options. In the first option there are no such i that i gives needed remainder by divide on k and si ≠ ?. Then let fill all positions with such remainder with symbol "V". In the second option there are i such that i gives this remainder by division on k and si ≠ ?. Let fill all positions with this remainder symbol si. Now in all positions with equal remainder by division on k in string stand equal symbols and it means that string has period k.

Let's call a pair indices i and j contradictory, if si ≠ sj, si ≠ ? and sj ≠ ?, then the string has period k if and only if there are no contradictory pair i and j for which |i - j| is divisible by k. This is a direct consequence of the statement proved above.

Let's learn how to search for all such numbers x that there is contradictory pair i and j that i - j = x. Let A — the set of positions, where stand "V", and B — the set of such positions i that sn - i = K. So our task reduced to finding such all possible numbers that it is representable as the sum of a number from A and a number from B.

Let's look on polynomials P(x) = a1x1 + a2x2 + ..., Q(x) = b1x1 + b2x2 + ..., where ai equals to 1, if i can be found in A or 0, otherwise. Similarly for set B and bi. Let's look on P(x) * Q(x). Coefficient at xi is equal to 1 if and only if when i сan be represented in sum of a number from A and a number from B. It is correct because coefficient at xi equals to . But ajbi - j ≥ 0 and equals to 1 if and only if when aj = 1 и bi - j = 1, and it means that , but j + (i - j) = i. Polynomials can be multiplied with help of Fast Fourier transform, so this part of solution works in O(nlogn).

It is only left to learn how to check that k is a period of string. It can be done in , with check all numbers like ik ≤ n. Totally it works in . So, all solution works in O(nlogn).

827F - Dirty Arkady's KitchenLet's consider undirected edge(u;v) as two directed edges (u;v) and (v;u). Let Arkady came to the vertex u in moment of time t. Then he can come to v in moments of time t + 1, t + 3, ... until the edge is existing.

We will expand each directed edge: on one of them we can come in even moments of time and leave in odd; on the other edge we can come in odd moments of time and leave in even. So, each of the edges from initial graph has turned in 4 edges of the new graph.

Let's calculate for each edge dpi — the minimal moment of time when we can come on the edge i. Let's count this values with help of sorting of events like "edge appeared". For each vertex and parity we will remember the edge for which we can appear in this vertex in moments of time with such a parity which will disappear later than others.

When the event of appearing edge became we need to check if it is possible in this moment of time come to the beginning of this edge. If it is possible then dpi = li, where li — the minimal moment of time when it is possible to come to the beginning of the edge to go through this edge. Every time when some vertex became reachable with needed parity we say that value of dp is equals to this time for all edges which wait in this vertex this parity. Totally each edge will processed no more than two times, so totally solution works in O(nlogn).

Codeforces Round #422 (Div. 2) Editorial

By Melnik, 6 years ago, In Russian822A - I'm bored with lifeTutorial is not available

First accepted Div1: 00:00:58 kriii

First accepted Div2: 00:00:59 Baneling3

Author's solution822B - Crossword solvingLet's consider all the positions i (1 ≤ i ≤ m - n + 1) that denotes the begining of the occurrence of the string s in the string t. Then let's find out how many symbols we should replace if the begining of the occurrence is position i. After the considering of all m - n + 1 positions the optimal answer will be found.

Total complexity is O(nm).

First accepted Div1: 00:03:30 Egor.Lifar

First accepted Div2: 00:04:43 Baneling3

Author's solution822C - Hacker, pack your bags!Let's sort all the vouchers by their left border li. Let's consider the vouchers in this sorted order. Now we want to consider i-th one. The duration of the i-th voucher is ri - li + 1. Consequentally only the vouchers with the duration x - ri + li - 1 can make a couple with the i-th one. At the same time you shouldn't forget that the value of this expression may be negative. You should check it. Besides let's find a couple for the i-th voucher among all the vouchers k for which rk < li.

To implement this solution let's keep an array bestCost. bestCost[j] denotes the minimal cost of the voucher with the duration equal to exactly j on the considering prefix (i.e. we should consider only such vouchers k with rk < li in bestCost). Thus, it's enough to consider vouchers in order of increasing of their left borders and update the array bestCost.

Total complexity is .

First accepted Div1: 00:08:30 nuip

First accepted Div2: 00:10:19 ColdSu

Author's solution822D - My pretty girl NooraSuppose we have already calculated f(2), f(3), ..., f(r). Then calculating the value of the expression is easy.

Consider process of calculating f(x). Suppose we found optimal answer. Represent this answer as sequence of integers d1, d2, ..., dk — on the first stage we will divide girls into groups of d1 participants, on the second stage into groups of d2 participants and so on. Let us prove that all di should be prime.

Suppose some di is a composite number. Then it can be decomposed into two numbers di = a·b. In addition, let n girls are admitted to the i-th stage. Then on current i-th stage  comparisons will occur. But if we divide this stage into two new stages, then number of comparisons is . So, we proved that all di should be prime. Then it's easy to write DP which will be calculated by transition from the state to the states given by dividing current state by prime divisors. For solving this task we can use Eratosthenes sieve.

Total complexity is same as complexity of Eratosthenes sieve: .

In addition you can prove the fact that we should split the girls into groups by prime numbers in the order of their increasing. This optimization significantly accelerates the algorithm.

First accepted Div1: 00:15:47 BanRussiaAtIOI

First accepted Div2: 00:18:01 ColdSu

Author's solution822E - LiarFormally, you were given two strings s and t. Also number x was given. You need to determine whether condition f(s, t) ≤ x is satisfied. f(s, t) is equal to the minimal number of non-intersect substrings of string s which can be concatenated together to get t. Substrings should be concatenated in the same order they appear in s.

Note that for short strings we can use DP(prefS, prefT) = f(s[1... prefS], t[1... prefT]).

Note that we are not interested in such states in which value of DP is greater than x. Also note that we can swap DP value with one parameter to get new DP: G(prefS, cnt) = prefT, where cnt — value of old DP, prefT — maximal prefT for which condition is satisfied: DP(prefS, prefT) = cnt.

G have |s|·x states. But it's not clear how to make transitions to make total complexity smaller.

Note that there is only two transitions:



First transition is obviously, because we make prefix longer by one letter, i.e. s[1... prefS + 1] can be split into several parts to get prefix of string t, i.e. t[1... prefT].

Second transition is not so obviously, but if we take some part from string s to cover string t, it's easy to see that it's optimal to take the longest possible part. Length of such longest possible part is lcp = LongestCommonPrefix(s[prefS + 1... |s|], t[prefT + 1... |t|]).

We can find lcp using suffix array.

Total complexity is , where N = |s| + |t|. But solutions with complexity  also passed. Also lcp can be found by binary search with hashes. So the total complexity of such solution is .

First accepted Div1: 00:43:18 BayHarborButcher

First accepted Div2: 01:05:21 CountOlaf

Author's solution822F - MadnessFirstly let's notice the fact that in the optimal answer each of the paths consists of exactly one edge.

Let's choose one particular vertex. Let's the degree of this vertex is deg. The most optimal answer for this vertex is , because one point make a full loop of the edge in 2 seconds. Vetrex with the degree deg has exactly deg adjacent edges. Consequentally deg distinct points will visit this vertex. Therefore in the optimal answer we should select all the starting positions and directions in such way that they visit the vertex each  seconds.

Let us show that we are able to select starting positions and directions so that the answer for every vertex is the optimal one.

Let's put points at the moment of time between 0 and 2 instead of putting somewhere on the edge. The moment of time between 0 and 1 will correspond to the coordinates from 0 to 1 in the direction from the vertex and the moment of time between 1 and 2 will correspond to the coordinates from 1 to 0 in the direction to the vertex. Let's select a root among the tree vertices. Let's consider a case of the root. If there are deg adjacent edges we can put a point at 0.0 seconds on the first edge, at  seconds on the second edge, at  on the third edge, ..., at  on the edge number deg.

Run the Depth First Search from the root (or Breadth First Search). Let's consider a case of another vertices. All these vertices will have a particular moment of time for the point in the upper edge. upEdgeMoment denotes this moment. So if the vertex degree is deg then the moments on the lower edges should be equal to  (here if the value exceeds 2, we calculate it modulo 2, i.e. 1.2 + 1.3 = 0.5), where i is the number of lower edge. The lower edges are numbered from 1 to deg - 1.

All in all, we are able to put points on every edge so that the answers for each vertex are the optimal one.

Total complexity is O(n).

First accepted Div1: 00:16:33 webmaster

First accepted Div2: 01:12:52 Nisiyama_Suzune

Author's solution

Codeforces Round #421 Editorial

By adedalic, history, 6 years ago, In EnglishFirst, I apologize for problems with round and serious problem with Div1A/Div2C. It was very important round for me and, as always, something goes wrong. KAN have already wrote about this.

Anyway, there are problems, so editorial must exists. Due some circumstances, Editorial will be upload in parts. Also, most of tutorials will contain main ideas how to solve task, not ready algorithm.

820A - Mister B and Book ReadingAll that needed - is to accurately simulate process.

Create variable, which will contain count of read pages, subtract l, add v0, check, what you still have unread pages, make v0 = min(v1, v0 + a) and again.

Complexity is O(c).

code820B - Mister B and Angle in PolygonSince polygon is regular, all vertices of a regular polygon lie on a common circle (the circumscribed circle), so all possible angles are inscribed angles. And all inscribed angles subtending the same arc have same measure.

More over, minor and major arcs between vertices vi and vk equals to minor and major arcs between vertices vi + 1 and vk + 1.

And finally, length of arc can be calculated with formula as sum of minor arcs between consecutive vertices. Length of minor arcs between consecutive vertices equals to 360 / n.

Length of inscribed angle is half of arc it based on.

In other words  if v1 < v2 < v3 or  in other case.

In the end, this task can be solved by checking all different (v3 - v1) (v1 can be fixed as 1), or by formula, if we put in  formula above.

In result finding closest angle can be done in O(n) or even O(1) time.

code819A - Mister B and Boring GameTutorial is not available

code819B - Mister B and PR ShiftsLet's see, how pk (1 ≤ k ≤ n) affects different shifts.

Let's denote di is deviation of the i - th shift. At first all di = 0.

Then pk affects it in following way:

d0 +  = |pk - k|,d1 +  = |pk - (k + 1)|,...dn - k +  = |pk - n|,dn - k + 1 +  = |pk - 1|,...dn - 1 +  = |pk - (k - 1)|.Then there are 2 cases: pk ≥ k or not.

If pk ≥ k after removing modules we will get 3 query:

to add pk - (k + i) to di where 0 ≤ i ≤ pk - k,to add (k + i) - pk to di where pk - k < i ≤ n - k andto add pk - i to dn - k + i where 0 < i < k.Else if pk < k we need to perform next operation:

to add (k + i) - pk to di where 0 ≤ i ≤ n - k,to add pk - i to dn - k + i where 1 ≤ i ≤ pk andto add i - pk to dn - k + i where pk < i < k.But in both cases we must add 3 arithmetic progression to the segment of array d. Or make operation of adding k·(x - l) + b to segment [l, r]. Its known task, which can be done by adding/subtracting values in start and end of segment offline.

To make such operation we need to remember, how to add value b to segment [l, r] of array d offline. We can just do next operations: d[l] +  = b and d[r + 1] -  = b. Now value in position i .

So what is adding progression with coef k? it's only adding to array d value k to all positions in segment [l, r]. That's why we need other array, for example df and making df[l] +  = k and df[r + 1] -  = k. In result, .

So algorithm to add k·(x - l) + b to segment [l, r] is next:

d[l] +  = b,d[r + 1] -  = k·(r - l + 1),df[l] +  = k,df[r + 1] -  = k.After all queries we need recover array d with formula . And after that get answer with formula .

So complexity is O(n).

code819C - Mister B and Beacons on FieldThere 2 stages in this task: moving of first beacon and moving of second.

But at first we need factorization of n and s. Since n and s are product of integers  ≤ 106, it can be done in O(log(n) + log(s)) time by "Sieve of Eratosthenes".

Start from second stage, when second beacon is moving:

Position of beacons will look like pair of points: (0, 0), (0, k), where 0 ≤ k ≤ n.

We need to check existing of point (x, y) such, that area of triangle (0, 0), (0, k), (x, y) equals to s. Using cross product |((0, k) - (0, 0))·((x, y) - (0, 0))| = 2·s. After simplifying we get |k·x| = 2·s where 0 ≤ k ≤ n.

So we can iterate all divisors of 2·s, using factorization of s and recursive algorithm.

Complexity of second stage is O(σ (s)), where σ (s) — number of divisors of s and for s ≤ 1018 σ (s) ≤  ≈ 105.

In the first stage we have such points: (k, 0), (0, n), where 1 ≤ k ≤ m.

We need to check existing of point (x, y) such, that area of triangle (k, 0), (0, n), (x, y) equals to s. Using cross product |((k, 0) - (0, n))·((x, y) - (0, n))| = 2·s we can get next equation: |k·(y - n) + n·x| = 2·s. Then solution exists iff gcd(k, n) | 2·s (2s % gcd(k, n) = 0).

And we need to calculate how many 1 ≤ k ≤ m such, that gcd(k, n) | 2·s.

We will solve it in next way: let's n = p1n1p2n2... plnl and 2s = p1s1p2s2... plsl (ni, si ≥ 0).

Look at all pi, that ni > si. It's obvious, that if pisi + 1 is divisor of k, then 2s doesn't divide at gcd(k, n).

In result, we have some constrains on k, like k doesn't divide at aj = pijsij + 1.

Finally, we have next task: calculate number of k (1 ≤ k ≤ n) such, that k doesn't divide any of ai. It can be done with inclusion-exclusion principle, where number of k which divides ai1, ai2 ... aib is .

Complexity of first stage is O(2z(n)), where z(x) — number of prime divisors of x, z ≤ 15 for integers up to 1018.

Result complexity is O(σ (s) + 2z(n)) per test.

code819D - Mister B and AstronomersLet's construct slow but clear solution and then, speed it up.

Let's denote . We can see, that, at first, all operation with time are modulo T and the i - th astronomer checks moments sti, (sti + s)%T, (sti + 2s)%T ..., where . More over, every astronomer, who checks moment t will check moment (t + S)%T by next time.

So we now constructed functional graph with T vertices. But this graph has very special type, since it can be divided on some cycles. More specifically, This graph consists of gcd(T, s) oriented cycles and each cycle has length exactly . Even more, vertices u and v belong to same cycle iff u ≡ v (mod gcd(T, s)).

So we can work with cycles independently.

Let's look closely on one cycle. It's obviously, that all astronomers will walk on their cycles from their starting positions sti % T. But what the answer for them.

Answer for the i - th astronomer is number of vertices, including starting vertex, to the nearest starting vertex of any other astronomer if count along the orientation of cycle, because if two astronomers came to same vertex, lucky is one, who came first. Other astronomer has this vertex as start, his time is stj, i - th time is sti + k·s, k ≥ 1 and sti + k·s > stj. If sti ≡  stj (mod T) and sti < stj then answer for the j - th astronomer is always 0.

So we must effectively calculate distance between two positions on cycle.

For that, let's numerate vertices along the orientation of cycle using vertex with minimal label as 0. If we will know position of sti% T for every astronomer calculation of distance between consecutive is trivial (sort, or set or other).

For the i - th astronomer let's denote vertex with label 0 in his cycle as zi. zi = sti % gcd(T, s). But cycles very specific, because vertex with label 0 is zi, vertex with label 1 is (zi + s) % T, vertex with label 2 is (zi + 2s) % T. In other words, vertex with label k is (zi + k·s) % T.

If we want to know position k of sti, we need to find v such, that v ≡  (v% gcd(T, s)) + k·s(mod T) which is diofant equation and can be calculated in O(log(T)) time.

Result complexity is O(n·log(T)).

code819E - Mister B and Flight to the MoonThere are different constructive solutions in this problem. Here is one of them.

Consider odd and even n separately. Let n be even. Let's build for each even n  ≥  4 a solution such that there are triangles 1-2-x, 3-4-y, 5-6-z and so on. For n  =  4 it's easy to construct such a solution. Then let's add two vertices at a time: a  =  n  -  1 and b  =  n. Instead of triangle 1-2-x let's add triangle 1-a-2-x, square 1-a-2-b and square 1-2-b. The same with 3-4-y, 5-6-z and so on. Only one edge a-b is remaining, we should add it twice. To do this let's replace the square 1-a-2-b with triangles a-b-1 and a-b-2. Easy to see that the condition on triangles is satisfied, so we can proceed to adding two more vertices and so on.

To deal with odd n let's keep triangles 2-3-x, 4-5-y and so on. To add two more vertices replace each of these triangles with two squares and one triangle in the same way as for even n, and also add two triangles 1-a-b.

code

Codeforces Round #420 (Div. 2) Editorial

By send_nodes, history, 6 years ago, In EnglishFirst, I really need to apologize for the round. There was a serious problem in D that was even covered in the sample test, that the main solution did not handle correctly. I should have been much more careful with this problem and looked for these kind of cases. Unfortunately, it was a big enough issue that caused the round to be unrated. I know this upset a lot of people, but it's tricky to find a solution to this kind of problem after the problem has happened.

I still hope the problems were good quality. If you learned something new from the round, or from this editorial, then the round was worth it. I would advise to solve the problems you couldn't solve during the contest, so you can take away something from the round.

If you want any further clarification on a problem, please ask in comments!

821A — Okabe and Future Gadget Laboratory

We can simulate exactly what's described in the statement: loop over all cells not equal to 1 and check if it doesn't break the city property. To check if a cell breaks the property, just loop over an element in the same row, and an element in the same column, and see if they can add to give the cell's number. The complexity is O(n4).

Sidenote: The definition of lab here was actually inspired from a USAMTS problem in 2016.

Code821B — Okabe and Banana Trees

The critical observation to make is that the optimal rectangle should always have a lower-left vertex at the origin. This is due to the fact that the line has positive y-intercept and negative slope: any rectangle which doesn't have a vertex at the origin could easily be extended to have a vertex at the origin and even more bananas.

Then, we just need to try every x-coordinate for the upper-right corner of the box and pick the maximum y-coordinate without going over the line. We can compute the sum of any rectangle in O(1) using arithmetic series sums, so this becomes O(bm) because the x-intercept can be up to bm. You can make it faster by trying every y-coordinate; this makes the complexity O(b), but this was unnecessary to solve the problem.

 Can you solve the problem with better complexity?

O(b) Code821C — Okabe and Boxes

It looks like Daru should only reorder the boxes when he has to (i.e. he gets a remove operation on a number which isn't at the top of the stack). The proof is simple: reordering when Daru has more boxes is always not worse than reordering when he has less boxes, because Daru can sort more boxes into the optimal arrangement. Therefore, our greedy algorithm is as follows: simulate all the steps until we need to reorder, and then we resort the stack in ascending order from top to bottom.

This has complexity O(n2 log n). However, we can speed this up if we note that whenever we reorder boxes, any box currently on the stack can be put in an optimal position and we can pretty much forget about it. So whenever we reorder, we can just clear the stack as well and continue. This gives us O(n) complexity because every element is added and removed exactly once.

Code821D — Okabe and City

First, let's make this problem into one on a graph. The important piece of information is the row and column we're on, so we'll create a node like this for every lit cell in the grid. Edges in the graph are 0 between 2 nodes if we can reach the other immediately, or 1 if we can light a row/column to get to it. Now it's a shortest path problem: we need to start from a given node, and with minimum distance, reach another node.

Only problem is, number of edges can be large, causing the algorithm to time out. There are a lot of options here to reduce number of transitions. The most elegant one I found is Benq's solution, which I'll describe here. From a given cell, you can visit any adjacent lit cells. In addition, you can visit any lit cell with difference in rows at most 2, and any lit cell with difference in columns at most 2. So from the cell (r,c), you can just loop over all those cells.

The only tricky part is asking whether the current lit row/column should be a part of our BFS state. Since we fill the entire row/col and can then visit anything on that row/col, it doesn't matter where we came from. This means that you can temporarily light each row/column at most once during the entire BFS search.

So complexity is O(n + m + k), with a log factor somewhere for map or priority queue. Interestingly enough, you can remove the priority queue log factor because the BFS is with weights 0 and 1 only, but it performs slower in practice.

You can see the code implementing this approach below.

Benq's code:Another approach to this problem was using "virtual nodes". Virtual nodes are an easy way to put transitions between related states while keeping number of edges low. In this problem, we can travel to any lit cell if its row differs by <=2, or its column differs by at most 2, but naively adding edges would cause O(k^2) edges.

Instead, for every row, lets make a virtual node. For every lit cell in this row, put an edge between the lit cell and this virtual node with cost 1. We can do something similar for every column.

Now, it's easy to see that the shortest path in this graph suffices. A minor detail is that we should divide the answer by 2 since every skipping of a row or column ends up costing 2 units of cost.

821E — Okabe and El Psy Kongroo

You can get a naive DP solution by computing f(x, y), the number of ways to reach the point (x, y). It's just f(x - 1, y + 1) + f(x - 1, y) + f(x - 1, y - 1), being careful about staying above x axis and under or on any segments.

To speed it up, note that the transitions are independent of x. This is screaming matrix multiplication! First, if you don't know the matrix exponentiation technique for speeding up DP, you should learn it from here.

Now, let's think of the matrix representation. Since the x dimension is the long one and the y dimension is small, lets store a vector of values dp where dpi is the number of ways to get to a y value of i at the current x value. This will be the initial vector for matrix multiplication.

Now, what about the transition matrix? Since our initial vector has length y and we need a matrix to multiply it with to map it to another vector with length y, we need a y by y matrix. Now, if you think about how matrix multiplication works, you come up with an idea like this: put a 1 in the entry (i,j) if from a y value of i we can reach a y value of j (i.e. |i - j| ≤ 1). Don't believe me, multiply some vector times a matrix of this form to see how and why the transition works.

You can then build this matrix quickly and then matrix exponentiate for under every segment and multiply by the initial vector, then make the result as the new initial vector for the next segment. You should make sure to remove values from the vector if the next segment is lower, or add values to the vector if the next segment is higher. This gives complexity O(nh3 log w) where h = 16 and w = k.

Code

Codeforces Round #419 Editorial

By robinyu, 6 years ago, In English816A - Karen and MorningThis is a rather straightforward implementation problem.

The only observation here is that there are only 1440 different possible times. It is enough to iterate through all of them until we encounter a palindromic time, and count the number of times we had to check before we reached a palindromic time.

How do we iterate through them? The most straightforward way is to simply convert the given string into two integers h and m. We can do this manually or maybe use some functions specific to your favorite language. It is good to be familiar with how your language deals with strings. It is also possible, though inadvisable, to try to work with the string directly.

To go to the next time, we simply increment m. If m becomes 60, then make it 0 and increment h. If h becomes 24, then make it 0.

To check whether a given time is palindromic, we simply need to check if the tens digit of h is the same as the ones digit of m, and if the ones digit of h is the same as the tens digit of m. This can be done like so: check if  and .

Another way is to simply cross-check against a list of palindromic times. Just be careful not to miss any of them, and not to add any extraneous values. There are 16 palindromic times, namely: 00: 00, 01: 10, 02: 20, 03: 30, 04: 40, 05: 50, 10: 01, 11: 11, 12: 21, 13: 31, 14: 41, 15: 51, 20: 02, 21: 12, 22: 22 and 23: 32.

816B - Karen and CoffeeThere are two separate tasks here:

Efficiently generate an array c where ci is the number of recipes that recommend temperature i.Efficiently answer queries "how many numbers ca, ca + 1, ca + 2, ..., cb" are at least k?" where k is fixed across all queries.There are some solutions to this task using advanced data structures or algorithms. For example, a conceptually straightforward idea is the following: create a segment tree c. We can treat all recipes as range update queries which we can do efficiently in  (where m is the largest ai or bi) time using lazy propagation.

After all recipes, we replace all ci by 1 if it's at least k, and 0 otherwise. Afterwards, each of the next q queries is a basic range sum query, which can be done simply in  time.

Other solutions exist, too: Fenwick trees with range updates, event sorting, sqrt-decomposition with binary search, Mo's algorithm, and so on. These solutions all pass, but they are all overkill for this task.

A very simple solution is as follows. Initialize c with all zeroes. For recipe that recommends temperatures between li and ri, we should increment cli and decrement cri + 1.

Cumulate all values. That is, set ci to c1 + c2 + c3 + ... + ci. This can be done with one pass through the array.

Now, magically, ci is now the number of recipes that recommend temperature i. If ci is at least k, set it to 1, otherwise, set it to 0.

Cumulate all values again.

Now, every query that asks for the number of admissible temperatures between a and b can be answered simply as cb - ca - 1.

This runs in O(n + q + m), which is really fast.

Note that if your solution does this and still runs quite slow, chances are your solution is using slower input methods. We raised the time limit to 2.5 seconds in this problem in order to avoid failing slow input solutions.

815A - Карен и играFix the number of times we choose the first row. Say we choose the first row k times. This actually uniquely determines the rest of the solution; consider the cells on the first row. There is no other way to increase these cells, except by choosing the columns they are on, and so we need to choose the j-th column g1, j - k times.

Now, once we know the number of times we have to choose each column, we will also know how many times to choose the remaining rows. At this point, for any given row i, the remaining number of times we have to choose it is gi, j - (g1, j - k), this should be the same for all j in a given row (otherwise there is no solution).

We can simply try all k, see if they can form a valid solution, and if so, calculate how many moves it will take. Find the smallest required number of moves, and then recover the solution.

Implemented properly, it should run in O(n) time, which should be fast enough. Note that there are O(max gi, j) possible choices for k, and testing a certain k can be done in O(nm) time. A solution will have at most O(max(n, m)·max gi, j) moves, so printing them will take that much time.

Overall, this solution hence runs in O(nm·max gi, j) time, which is acceptable.

There is a faster solution to this, both in terms of runtime and implementation time, which we will describe below.

Notice that, when there is a 0 on the grid, all the moves are already fixed. If the 0 is at gi, j, then we need to choose row i' exactly gi', j times, and column j' exactly gi, j' times.

What if there is no 0 on the grid? Well, we intuitively want to reduce numbers as much as possible, and in fact the greedy algorithm works here. If there are not more rows (n ≤ m), we should keep choosing rows, and if there are fewer columns (n > m), we should keep choosing columns, until there is a 0. It doesn't even matter which particular rows or columns we choose; for example, if n ≤ m, we could just keep choosing row 1 until a 0 appears, or we could choose all rows 1, 2, 3, ..., n in order and just keep cycling through them. The end result will be the same.

We can just check that the grid is correct at the end and print  - 1 otherwise.

Implemented properly, this runs in O(nm + max(n, m)·max gi, j), which is asymptotically optimal; it takes at least O(nm) time to read the input, and O(max(n, m)·max gi, j) to print the output.

815B - Karen and TestThere are a couple of ways to solve this problem.

The easiest way is to calculate the coefficients, or "contributions", of each number to the final sequence. In fact, the contribution of any number is determined by its position as well as the n.

To do this, using brute force, we can compute the contribution of each element by just running a brute-force on 0, 0, 0, ..., 1, ..., 0, 0, 0 for all positions 1 and then trying to observe patterns. In any case, one should eventually realize that the pattern depends on :

When , the pattern is: 

When , the pattern is: 

When , the pattern is: 

When , the pattern is: 

This is perhaps what most contestants did in the contest. We will not prove that this is correct; instead, a more elegant solution will be suggested.

First, simplify the problem so that only addition ever happens. In fact, this version is much easier: the contribution of the  element when there are n elements is precisely .

Now, let's go back to the original task. We will repeatedly perform the operation until the number of elements n is even, and the first operation is addition, to reduce the number of cases we have to handle. It can be observed that, regardless of our starting n, this will happen somewhere within the first two rows. We can therefore just brute force it.

Observe the following picture:

Consider the blue elements only. Am I the only one whose mind is on the verge of exploding? Notice that they are doing precisely the simpler version of the task! In other words, if we consider only a1, a3, a5, ..., we are basically solving the simple version of the task!

In fact, the same can be said of a2, a4, a6, ....

Why is this true? Well, look at the picture. Notice that, if we have an even number of elements with the first element being addition, then, after 4 rows, it will again be even and the first element will also be addition, so the pattern simply continues!

We can hence compute the final two values on the second to last row, and then add or subtract them, depending on what the final operation should be. In fact, this also explains the patterns we observed for  and !

To compute  quickly, we can use the formula . We can just preprocess all relevant factorials in O(n), and also their modular multiplicative inverses modulo 109 + 7 in order to perform the division. This runs in  or just O(n) if you are willing to consider the  a constant.

815C - Karen and SupermarketInstead of asking for the maximum number of items we can buy with b dollars, let's ask instead for the minimum cost to buy j items for all j. Afterwards, we can simply brute force all j to find the largest j that still fits within her budget b.

Note this problem is actually on a rooted tree, with root at node 1; the constraint xi < i guarantees there are no cycles in this problem. The coupon requirement essentially means that if we buy good i at the discounted price, we also need to buy good xi at the discounted price, and so on. If we don't buy at discounted price there are no constraints (except that Karen can afford it. Unfortunately, she isn't a criminal.)

There is a rather straightforward O(n3) dynamic programming solution to this problem, as follows:

Let fi, j be the minimum cost to buy j items in the subtree of i if we can still use coupons, and gi, j the minimum cost to buy j items in the subtree of i if we cannot use any more coupons.

We know that for all leaves, fi, j = ci - di and gi, j = ci.

We can compute gi, j for all nodes as well; this is simply the sum of the j smallest c's in the subtree of i. This can be done straightforwardly in O(n2) or .

To compute this fi, j for some non-leaf node i, we should initialize fi, 1 = ci - di.

Now, we can add each of the children of i one by one, and try each j. Suppose we take k elements from one of the children. Then we have fi, j = min(fi, j, fi, j - k + fi, k). We just have to make sure to implement it in a way that we don't inadvertently take elements multiple times, usually by making an auxiliary array.

Finally, we set fi, j = min(fi, j, gi, j) to consider not using the coupons. Note that we can't do this at the start, because otherwise it could cause conflicts.

This runs in O(n3), which is too slow. This is because there are n nodes, and to compute fi, j for all j in that node, it takes  where pi is the set of all of the children of i, and s(h) is the subtree size of node h. This sum turns out to be O(n2), and so the final runtime is O(n3).

How could we make it faster? Take the largest (in terms of nodes) child of subtree i. Can we avoid iterating through this?

Yes, we can! Suppose our tree was binary. Now, we can compute fi, j = min0 ≤ k < j(fa, j - k - 1 + fb, k + ci - di), where a and b are the subtrees of i, with s(a) ≥ s(b). This skips iterating through the larger subtree a.

We can extend this to non-binary trees, too; just do this to skip the largest subtree, and then add the rest like before.

The runtime of the transition is now , which turns out to be just O(n). The final runtime is hence O(n2) (or , depending on the algorithm used for the greedy portion.) This is sufficient to solve this problem.

815D - Karen and CardsLet's say we have one card, with a1 = 4, b1 = 2 and c1 = 3. For simplicity, we have p = q = r = 5.

Consider which cards will beat this one. Let's fix the c of our card, and see what happens at all various c:

Note that a green cell at (a, b) in grid c represents that the card (a, b, c) can beat the card (4, 2, 3). Hence, the total number of cards that can beat this card is simply the number of green cells across all c grids.

This representation is helpful, because we can easily account for more cards. For example, let's say we have another card a2 = 2, b2 = 3 and c2 = 4:

Now, what happens when we want to consider the cards that beat both of these cards? Well, we simply have to consider the intersection of both sets of grids!

Remember that we are simply trying to count the total number of green cells in all grids.

It turns out that trying to count the number of green cells directly is quite difficult. Instead, it is more feasible to count the number of not green cells, and then simply subtract it from the number of cells pqr.

How could we do this? We should exploit some properties of the grids.

First, for any particular card (ai, bi, ci), all the grids from 1 to ci are the same, and all the grids from ci + 1 to r are the same. This means that we can avoid a lot of redundancy, and only perform some sort of update when we reach the change.

Second, if some cell (a, b) is not green for some fixed c, then neither are the cells (a', b') for all a' ≤ a and b' ≤ b for the same c. This means that we can replace each grid with an array u1, u2, u3, ... where ua is the largest b for which (a, b) is not green. Additionally, u1 ≥ u2 ≥ u3 ≥ ... ≥ up.

Third, for any card, there are only at most two distinct values in u for any fixed c in one card.

Finally, for any card, no value ui in c is less than ui in c' if c < c'.

These properties are all pretty easy to observe and prove, but they will form the bread and butter of our solution.

Let's iterate cards from c = r to c = 1. Suppose we maintain an array s which will at first contain all 0. This will be the number of cells that are not green.

We will update it for all grids first. For each card, we are essentially setting, for all i, si to max(si, ui).

Of course, doing this for each grid will take O(np), which is too slow. To remedy this, initialize s as a segment tree instead. Now, we are basically just setting s1, s2, s3, ..., sai to max(sj, bi) for all cards i.

Because s is essentially a maximum of a bunch of u's, which are all nonincreasing by the second property, it follows that s is also nonincreasing at all times. Therefore, these updates are easy to do; we are essentially setting sk, sk + 1, sk + 2, ..., sai to bi for the smallest k where bi ≥ sk. We can find k using binary search. Binary searching the segment tree can be done in  time using an implicit binary search by going down the tree; an explicit  binary search might have trouble passing the time limit.

Using the aforementioned procedure, we are able to generate s corresponding to the layer c = r in  time. Using the segment tree, we should also be able to get the sum of all values in s at all times. This will allow us to count the number of not green cells.

Now, we will go backwards from c = r to c = 1. We should decrement c, and then see which grids changed. (Just sort the cards by ci and do a two-pointers approach.) All the newly-changed grids can then be updated in a similar manner as before. When a grid changes, thanks to the fourth property, there is no worry of any ui getting smaller than it was before; they can only get bigger. So, we have to update two ranges s1, s2, s3, ..., sai to r and sai + 1, sa2 + 1, sai + 3, ..., sp to max(sj, bi). The former is a simple range update, the latter can be done using binary search like before.

After we update all grids for a particular c, get the range sum, and decrement c again, and so on until we reach 1. We will have the found the total number of not green cells in all c, and from there we can recover all the green cells, and hence the final answer.

Sorting the cards by ci takes  time, constructing the segment tree s takes O(p) time, there are O(n) updates each taking  time, and iterating takes O(r) time. The final runtime is therefore  time, which is sufficient to solve this problem.

This solution can be modified to pass p, q, r ≤ 109, too; however, this was not done as it uses only standard ideas and just contains more tedious implementation. If you want, you can try to implement it.

815E - Karen and NeighborhoodSurprisingly, it is possible to solve this problem without knowledge of any sophisticated algorithms or data structures; this problem can be solved completely through observations, brutal case analysis and grunt work, which we will try to summarize here.

The first and most obvious observation: the first person always goes to house 1, and the second person always goes to house n. Consider these two guys as special cases; now, we're solving the problem on a segment of length n - 2.

Note how we define segments here; a segment of length l is a row of l unoccupied houses, with the two houses just before and after both endpoints occupied.

Notice that, for any segment, if a person moves into any house in this segment it will be the middle one; if there are two middles, it will be the left of the two middles. So, if we have a length 3 segment, the person will move into the 2-nd house in the segment. If we have a length 6 segment, the person will move into the 3-rd house in the segment, and so on.

When a person moves into a house in a given segment of length l, if l > 2, it will also create two new segments; the left segment will be length  and the right segment will be length .

Let's write down the segments in a binary tree, where the i-th layer contains all segments spawned by the (i - 1)-th layer, and the first layer contains precisely the segment of length n - 2.

For example, consider n = 46. The binary tree will look like this:

From this, we can make a number of observations.

We can see that there are at most 2 different segment lengths in any layer. Additionally, these values are always l and l + 1, where l is the smaller one.

Let the two lengths in a given layer be l and l + 1 (if there is only one, it's just l). Now, consider the following:

If l is odd, the segments of length l and l + 1 will be processed in order from left to right.If l is even, all segments of length l + 1 will be processed first, from left to right, then all segments of length l will be processed, also from left to right.This makes sense; the "minimum distance" is actually just the smaller of the two children, and you can observe that in the above first case, the smaller of the two children is equal, while in the second case, the smaller of the two children of l is smaller than the smaller of the two children of l + 1.

Additionally, all segments in any particular layer are always processed before the segments in the next layer (except in the case l = 2—we will discuss the special cases later.) We can therefore determine, rather straightforwardly, what layer the k-th segment is. Since all the layers above this layer are now irrelevant, we can just subtract all the taken layers from k. Now, the problem has been reduced to finding what house the k-th guy in a fixed layer moves into.

How will we find this? Well, note that there is exactly one house separating any two segments in a given layer. If we go to the k-th segment, the label of the house we actually went into is k (number of houses occupied on previous layers), plus the total length of segments 1, 2, 3, ..., k - 1 (unoccupied houses before this one), plus  (the middle house in the k-th segment).

It is easy to determine l and the number of length l and length l + 1 segments for any particular layer. What's harder to compute are two crucial details:

What's the relative position of the k-th processed segment in this layer?How many layers have length l + 1 before the segment at this relative position?If we can answer these two questions efficiently, we are basically done with the core of the solution, and just have to handle special cases.

Let's answer the first question. If l is odd, this is trivial; the k-th processed segment is precisely that at position k.

If l is even, things get a lot trickier. Luckily, we can perform more observations. Draw the tree with root segment 39 (n = 41), and observe the fourth row. Now, draw the trees with root segments 40, 41, 42, ..., 47.

Observe how the fourth row changes from root segment 39 to 47:

Root segment is 39: 4, 4, 4, 4, 4, 4, 4, 4Root segment is 40: 4, 4, 4, 4, 4, 4, 4, 5Root segment is 41: 4, 4, 4, 5, 4, 4, 4, 5Root segment is 42: 4, 4, 4, 5, 4, 5, 4, 5Root segment is 43: 4, 5, 4, 5, 4, 5, 4, 5Root segment is 44: 4, 5, 4, 5, 4, 5, 5, 5Root segment is 45: 4, 5, 5, 5, 4, 5, 5, 5Root segment is 46: 4, 5, 5, 5, 5, 5, 5, 5Root segment is 47: 5, 5, 5, 5, 5, 5, 5, 5In what order are the numbers increased? It's not immediately obvious, but we can try to write down the binary representations of the (zero-indexed) positions in the order they are increased:

7: 1113: 0115: 1011: 0016: 1102: 0104: 1000: 000Actually, this is just the reversed binary numbers in reverse order! Remember that our goal is to find the relative position of the k-th processed element. Without loss of generality, suppose that the k-th processed element is of length l + 1 (the analysis when it is length l is almost the same.)

This is equivalent to asking for the k-th smallest element among the first m numbers in that list (m is the number of l + 1 segments in the given layer, which is easy to compute).

Let's take root segment equal to 44, as in the illustration earlier. Let's say we want the position of the k = 4-th occurrence of 5. That's equivalent to finding the 4-th smallest element in this list (obviously we never get to generate this list explicitly):

7: 1113: 0115: 1011: 0016: 110Consider these binary numbers digit by digit starting from the largest. Notice that, at any point, the number of ones is always equal to or one more than the number of zeroes; above, there are 3 ones and 2 zeroes.

We want the 4-th smallest, and there are only 2 zeroes, so we know it has to start with 1. We throw out (again, not explicitly) all the numbers that start with zero, and we are now left with finding the 2-nd smallest in this list:

Our number so far: 1??

7: 115: 016: 10Now, there are 2 ones and 1 zero. We want the 2-nd smallest, and there is only 1 zero, so we know the next digit is 1. We throw out all the numbers that start with zero, and we are now left with finding the 1-st smallest in this list:

Our number so far: 11?

7: 16: 0Now, there is 1 one and 1 zero. We want the 1-st smallest, and there is 1 zero, which is enough. So, this is the next digit. The final number is 6, which means that the position of the 4-th 5 is at 6. (7 if one-indexed).

This process works for any arbitrary numbers in , and now we are able to answer the first required question in just  time.

Now, we need to answer the second question. How many layers have length l + 1 before the segment at this relative position?

Actually, this question can be solved using almost the exact same binary digit analysis! The problem is equivalent to asking for how many numbers, among the first m numbers in the earlier list, have a position less than k. We will omit the analysis here for brevity, but it uses virtually the same idea and also solves this question in .

Now, we have solved both questions, and have essentially finished the core of the problem. But we're not yet done! We still have to handle the corner cases.

There are actually only two corner cases: l = 1 and l = 2.

When l = 1, note that every segment of length 2 is basically treated as two segments of length 1.

When l = 2, segments of length 3 are handled first, each creating segments of length 1. Then, the segments of length 1 and 2 are treated like with l = 1, despite the segments of length 1 technically being on the next layer.

Both of these cases can be solved using the same binary digit analysis, with some grunt-work formulas that can be a bit hard to get precisely correct. These cases can also be solved in .

Overall, the runtime of the solution is just .

Codeforces Round #418 (Div. 2) Editorial

By cyand1317, history, 6 years ago, In EnglishGreetings!

Codeforces Round #418 (Div. 2) has just come to an end. This is my first round here, and hope you all enjoyed the contest! > <

Seems the statements still created a few issues :( Anyway hope you liked it, and the characters feature the Monogatari anime series. Let me state again that the statements has little to do with the actual plot — they're inspired by five theme songs actually — and I'm not spoiling anyone of the series! ^ ^

Sympathy for those failing system tests on B... This problem was intended to experience a lot of hacks but somehow there are not so many.

Here are the detailed solutions to the problems. Feel free to write in the comments if there's anything incorrect or unclear.

814A - An abandoned sentiment from pastThe statement laid emphasis on the constraint that the elements are pairwise distinct. How is this important?

In fact, this implies that if the resulting sequence is increasing, then swapping any two of its elements will result in another sequence which is not increasing.

And we're able to perform a swap on any resulting sequence if and only if k ≥ 2. Thus if k ≥ 2, the answer would always be "Yes". For cases where k = 1, we replace the only zero in sequence a with the only element in b, and check the whole sequence. Hackable solutions include those only checking the replaced element and its neighbours, and those missing the replaced element.

Bonus. Figure out why solution 2 is not hackable.

Solution 1Solution 2814B - An express train to reveriesPermutating directly no longer works here. Let's try to dig something out from the constraints.

Imagine that we take a permutation p1... n, and change one of its elements to a different integer in [1, n], resulting in the sequence p'1... n. There are exactly 2 positions i, j (i ≠ j) such that p'i = p'j, while the other n - 2 elements are kept untouched. This is actually what a and b satisfy.

Find out these two positions in a, and the two candidates for them — that is, the only two numbers not present in the remaining n - 2 elements. Iterate over their two possible orders, and check the validity against sequence b.

Of course you can solve this with casework if you like.

Solution 1Solution 2 - Casework814C - An impassioned circulation of affectionThe first thing to notice is that we are only changing other colours to Koyomi's favourite one. Furthermore, we won't create disconnected segments of that colour, for that's no better than painting just around the longest among them.

This leads us to a straightforward approach: when faced with a query (m, c), we check each segment [l, r] and determine whether it's possible to fill this segment with letter c, within at most m replacements. This can be done by finding the number of times c occurs in that segment (denote it by tc), and checking whether (r - l + 1) - t ≤ m. But this O(n2·q) solution would be too slow.

Since the number of different queries is 26n, we can calculate all answers beforehand. For each letter c and a segment [l, r], we'll be able to fill the whole segment with c within (r - l + 1) - tc moves. Use this information to update the answers, and employing a "prefix max" method gives us a time complexity of O(n2·|Σ| + q), where |Σ| equals 26. Refer to the code for a possible implementation.

Bonus. Find out the O(n2  +  n·|Σ|  +  q) solutions and the O(nq) solutions (some of them may get TLE — remember to check against maximum data next time!).

Solution814D - An overnight dance in discothequeCircles' borders do not intersect, that is, each circle is "directly" contained in another circle, or is among the outermost ones. Can you see a tree/forest structure out of this?

We create a node for each of the circles Ci, with weight equal to its area π ri2. Its parent is the circle which "directly" contains it, namely the one with smallest radius among those circles containing Ci. If a circle is an outermost one, then it's made a root. This tree structure can be found in O(n2) time.

Consider what happens if there's only one group: the spaciousness equals the sum of weights of all nodes whose depths are even, minus the sum of weights of all nodes whose depths are odd.

Now we are to split the original tree/forest into two disjoint groups. This inspires us to think of a DP approach — consider a vertex u, and the parity (oddness/evenness) of number of nodes in its ancestors from the first and the second group. Under this state, let f[u][0 / 1][0 / 1] be the largest achievable answer in u's subtree.

The recursion can be done from bottom to top in O(1), and the answer we need is the sum of f[u][0][0] for all u being roots. Time complexity is O(n2) for the tree part and O(n) for the DP part. See the code for the complete recursion.

Bonus. Build the tree in  time.

Bonus. Find different greedy solutions for this problem and try to prove their correctness.

Solution 1 - DP on treesSolution 2 - GreedyOne more thing — Staying up late is bad for health.

814E - An unavoidable detour for homeLet's make it intuitive: the graph looks like this.

Formally, if we find out the BFS levels of the graph, it will look like a tree with extra edges among vertices of the same level, and indices of vertices in the same level form a consecutive interval. Therefore we can add vertices from number 1 to number n to the graph, without missing or violating anything.

Consider the case when we want to add vertex u to a graph formed by the first u - 1 vertices. The state only depend on the current and the previous level (We can't start level l + 1 without finishing level l - 1, thus there are only two unfinished levels).

The whole thing is described by four parameters: the number of "1-plug" (having one outgoing edge that is not determined) and "2-plug" (similar definition) vertices in the previous and the current level. Let f[u][p1][p2][c1][c2] be the number of ways to build the graph with the first u vertices, with p1 "1-plug" vertices and p2 "2-plug" vertices in the previous level, and c1 and c2 in the current one respectively.

For vertex u, we must choose one vertex v in the previous layer and connect u to it. For the remaining degree(s) of u, we can choose either to connect them to vertices in the same layer, or simply leave them for future. Also, we may start a new level if p1 = p2 = 0. This gives us an O(1) recursion.

There are O(n5) states, giving us a time complexity of O(n5) and a space complexity of O(n4) if the first dimension is reused. The constant factor can be rather small (since p1 + p2 + c1 + c2 ≤ n). See solution 1 for detailed recursion.

Let's try to improve this a bit. Instead of adding one vertex at a time, we consider the layer as a whole. Let f[c0][c1][c2] be the number of ways to build a single level with c0 vertices (their "plugs" don't matter), and connect it to the previous layer which has c1 "1-plug" vertices and c2 "2-plug" ones. Recursion over f can be done in O(1). Then let g[l][r] be the number of ways to build the graph with vertices from l to n, while vertices from l to r form the first level — note that this level should be connected to another previous one. The recursion over g can be done in O(n). The final answer should be g[2][d1] since the capital must be directly connected to vertices from 2 to d1. The overall time complexity is O(n3). Huge thanks to Nikolay Kalinin (KAN) for this!

Bonus. Figure out the O(n4) solution :P

Solution 1 - O(n^5)Solution 2 - O(n^3) by KANThis is the round with the most solutions so far perhaps? There are at least 3 × 2 × 3 × 3 × 3 = 162 different ways to pass all problems in this round =D

Pla-tinum happy though I'm supposed to bePla-tinum sad is somehow how I get

Personally I'd like to express my gratitude to the community for creating this amazing first-time experience for me. Thank you, and see you next round. Probably it will be for Ha... Well, let's wait and see :)

Cheers \(^ ^)/

[Editorial] Codeforces Round #417 (Div. 2)

By Ahmad_Elsagheer, 6 years ago, In EnglishHello Codeforces, I hope you enjoyed the round!

Just some notes about the problems:

In problem A, the picture and example notes should complete your understanding for the problem if the statement itself is not clear.

Solutions that check the lights of each part separately should have failed on pretests. My bad.

Problem C was assigned as B at the beginning, but moved to C lest it is harder than B difficulty. However, I think problem B is still easier than problem C (check the solution below).

I thought problem D is easier than problem E. Once, conditions are well-understood and related to each other and the problem is modeled correctly, then its implementation is easy.

The points I have just described is my own opinion in the problems. Of course, you might have a different point of view. However, I would like you to keep in mind that I did my best to make statements clear and pretests strong.

Thanks for your understanding!

812A - Sagheer and CrossroadsFor pedestrian crossing i (1 ≤ i ≤ 4), lanes li, si, ri, si + 2, li + 1, ri - 1 are the only lanes that can cross it. So, we have to check that either pi = 0 or all mentioned lanes are 0.

Complexity: O(1)

Implementation

812B - Sagheer, the HausmeisterWhen Sagheer reaches a floor for the first time, he will be standing at either left or right stairs. If he is standing at the left stairs, then he will go to the rightmost room with lights on. If he is standing at the right stairs, then he will go to the leftmost room with lights on. Next, he will either take the left stairs or the right stairs to go to the next floor. We will brute force on the choice of the stairs at each floor. Note that Sagheer doesn’t have to go to the last floor, so he will go to the highest floor that has a room with lights on.

Complexity: O(n·2n)

Implementation

812C - Sagheer and Nubian MarketIf Sagheer can buy k items, then he can also buy less than k items because they will be within his budget. If he can’t buy k items, then can’t also buy more than k items because they will exceed his budget. So, we can apply binary search to find the best value for k. For each value k, we will compute the new prices, sort them and pick the minimum k prices to find the best minimum cost for k items.

Complexity: 

Implementation

812D - Sagheer and KindergartenLet’s go through scenario requests one by one. For request a b, if toy b is free, then child a can take it. Otherwise, child a will wait until the last child c who requested toy b finishes playing. Since, no child can wait for two toys at the same time, each child depends on at most one other child. So we can put an edge from the a to c. Thus, we can model the scenario as a forest (set of rooted trees) as each node has at most one outgoing edge (to its parent).

For query x y, if toy y is free, then child x can take it and no child will cry. Otherwise, toy y is held by another child. Lets denote z to be the last child who requested toy y. So x now depends on z. If z is in the subtree of x, then all children in the subtree of x will cry. Otherwise, no child will cry. We can check that a node is in the subtree of another node using euler walk (tin and tout) with preprocessing in O(n) and query time O(1)

Complexity: O(k + n + q)

Implementation

812E - Sagheer and Apple TreeIn the standard nim game, we xor the values of all piles, and if the xor value is 0, then the first player loses. Otherwise, he has a winning strategy. One variant of the nim game has an extra move that allows players to add positive number of stones to a single pile (given some conditions to make the game finite). The solution for this variant is similar to the standard nim game because this extra move will be used by the winning player, and whenever the losing player does it, the winning player can cancel it by throwing away these added stones.

This problem can be modeled as the mentioned variant. Lets color leaf nodes with blue. The parent of a blue node is red and the parent of a red node is blue (that’s why all paths from root to leaves must have the same parity). Blue nodes are our piles while red nodes allow discarding apples or increasing piles.

If the xor value of blue nodes s = 0, then Soliman loses on the initial tree. To keep this state after the swap, Sagheer can:

swap any two blue nodes or any two red nodes.

swap a blue node with a red node if they have the same number of apples.

If the xor value of blue nodes s ≠ 0, then Sagheer loses on the initial tree. To flip this state after the swap, Sagheer must swap a blue node u with a red node v such that 

Complexity: O(n + maxA) where maxA is the maximum value for apples in a single node.

Implementation

You can read more about games from this link

Codeforces Round #416 Editorial (with hints)

By hloya_ygrt, history, 6 years ago, translation, In English811A - Vladik and Courtesy

HintTutorial811A - Vladik and CourtesyLet's simulate process, described in problem statement. I.e subtract from a and b numbers 1, 2, 3, ..., until any of them is less than zero. The process would terminate less than in  iterations, because sum of arithmetical progression with n members is approximately equal to n2.

811B - Vladik and Complicated Book

HintTutorial811B - Vladik and Complicated BookObviously, that all the elements in range, which are less than px will go to the left of px after sort. So the new position will be l + cntless. Let's find cntless with simple iterating through all the elements in the segment.

O(n * m)

Challenge. Can you solve the problem with n, m ≤ 106?

811C - Vladik and Memorable Trip

Hint 1Hint 2Tutorial811C - Vladik and Memorable TripLet's precalc for each x it's frx and lsx — it's leftmost and rightmost occurrences in the array respectively. Now for each range [l, r] we can check, if it can be a separate train carriage, just checking for each ai (l ≤ i ≤ r), that frai and lsai are also in this range.

Now let's define dpi as the answer to the problem for i first people. To update dp we can make two transitions:

Assume, that there was such train carriage, that finished at position i. Then iterate it's start from right to left, also maintaining maximal ls, minimal fr and xor of distinct codes cur. If current range [j, i] is ok for forming the train carriage, update dpi with value dpj - 1 + cur.If there wasn't such train carriage, then last element didn't belong to any train carriage, so we can update dpi with value dpi - 1.O(n2)

Challenge. Can you solve the problem with n, a[i] ≤ 105? Try to use the fact, that .

811D - Vladik and Favorite Game

Hint 1Hint 2Tutorial811D - Vladik and Favorite GameIt's clear, that to reach finish without stepping into dangerous cells we have to know, whether our buttons are broken. Firstly, let's find any route to the finish using bfs / dfs. At the first moment of this route, when we have to go down, we would find out, if our button is broken, because we are still at the first row of the matrix and if the button is broken, we just won't move anywhere. Similarly for left and right pair of buttons. After that we found out, that button was broken, we can change in our route moves to opposite ones.

Challenge. Assume this problem: let's change all dangerous cells on walls, i.e such cells, in which it is just impossible to enter. Now you have to generate such string from moves 'L', 'R', 'U', 'D', that without dependance on possible button breakage of pairs 'L'/'R' and 'U'/'D', as in original problem, will visit finish cell. Of course, it is not necessary to stop at finish cell, you just have to visit it at least once.

811E - Vladik and Entertaining Flags

HintTutorial811E - Vladik and Entertaining FlagsLet's use interval tree, maintaining in each vertex two arrays of n numbers: left and right profile of the interval corresponding to the vertex. Each number in this arrays would be in range from 1 to 2 * n denoting component, in which cell is.

For merging such structures we would iterate on splice of two vertices and unite components, if two adjacent cells have same colors and than recalculate components of left and right profile of the new structure.

Codeforces Round #415 Editorial

By hloya_ygrt, history, 6 years ago, translation, In English810A - Straight <>It is obvious that add any marks less than k isn't optimal. Therefore, iterate on how many k marks we add to the registry and find minimal sufficient number.

Setter's codeFirst accepted Zhigan.

810B - Summer sell-offInitially, the number of sold products on i-th day is min(ki, li) and in sell-out day is min(2 * ki, li). Let's sort days in descending of min(2 * ki, li) - min(ki, li) and take first f days as sell-out days.

Setter's codeFirst accepted polygonia.

809A - Do you want a date?We know, that a lot of different solutions exists on this task, I will describe the easiest in my opinion.

Let's sort the coordinates in ascending order and iterate through the pairs of neighbours xi and xi + 1. They are adding to the answer xi + 1 - xi in all the subsets, in which there is at least one point a ≤ i and at least one point b ≥ i + 1. The number of such subsets is equal to (2i - 1) * (2n - i - 1).

Setter's codeFirst accepted div2: RaidenEi.

First accepted div1: Lewin.

809B - Glad to see you!Let's start with searching the first point. We can do it using this binary search: let's ask points mid and mid + 1 each time, when we calculated the center of search interval. So we always know in which of the halves [l, mid], [mid + 1, r] exists at least one point. Since in the initial interval there is at least one point and any point in the interval of search is closer, than any point out of the interval, we will never lose this point out of the search.

Now let's run two binsearches more, similarly for everything to the left and to the right of the first found point. Again, any point in the interval of search is closer, than any point out of the interval. Now it is not guaranteed that initially exist at least one point, so we have to check the found one using one query.

Setter's codeFirst accepted div2: polygonia.

First accepted div1: V--o_o--V.

809C - Find a carAt first, let's examine that numbers in the matrix are equal to binary xor of the row and column. Precisely, the number in cell i, j is equal to .

Now let's split the query into 4 queries to the matrix prefix, as we usually do it in matrix sum queries. In order to find the answer to the query, we have to maintain 2 dp-on-bits: cnt[prefix][flagX][flagY][flagK] and dp[prefix][flagX][flagY][flagK], where prefix — the number of placed bits, flagX, flagY  — flags of equality x, y in query and flagK  — flag of equality of row and column xor with k. Flag of equality is a boolean, equal to 0, if our number became less then prefix, and 1 if prefix is still equal. If you aren't familiar with such dp, please try to solve another task with dp on prefix with less number of flags.

cnt will maintain the number of cells that are suitable for the arguments and dp — accumulated sum.

Setter's codeFirst accepted div2: xsup.

First accepted div1: anta.

809D - Hitchhiking in the Baltic StatesLet dpi — minimal number that can be last in strictly increasing subsequence with length i. Iterate through prefixes of intervals and maintain this dp. Obviously this dp is strictly increasing.

What happens when we add new interval l, r:

In the rightmost position i, such that dp[i] < l, we can make a transion dp[i + 1] = min(dp[i + 1], l). Since i — the rightmost position, dp[i + 1] ≥ l, than this transition happens always, i.e dp[i + 1] = l.Let j — the rightmost position, such that dp[j] < r, the for each  we can make a transition dp[k + 1] = min(dp[k + 1], dp[k] + 1). But since dp[k] < dp[k + 1], than dp[k] + 1 <  = dp[k + 1], so this transition happens always.Thinking from the facts above, we can solve this task maintaining dp in cartesian tree (treap). Let's find and split interval from i + 1 to j. Add to every number in this tree 1. Delete j + 1-t node. And merge everything adding one more node with key l.

Setter's codeFirst accepted: ksun48.

809E - Surprise me!Here φ(x) denotes Euler's totient function of x, gcd(x, y) is the greatest common divisor of x and y and f(x) denotes the amount of divisors of x.

Small remark. We need to find the answer in the form of , where gcd(P, Q) = 1. Let A will be the sum of all pairwise values f(u, v) and B is the amount of such pairs i.e. n(n - 1) and let g = gcd(A, B). Then P = A·g - 1, Q = B·g - 1 and the answer for the problem is P·Q - 1 = A·g - 1·B - 1·g = A·B - 1 which means there is no need to know g.

As it often happens in the problems where you are required to calc anything over all paths of a tree it's a good idea to use so-called centroid decomposition of a tree. Shortly, decomposition chooses some node of a tree, processes each path going through it and then deletes this node and solves the problem in the remaining forest recursively. It's obvious there is no matter what node we choose the answer will be always calculated correctly but total run-time depends on choosing this node. It's claimed each tree contains such a vertex with the removal of which all the remaining trees will have a size at least twice less then a size of this tree. So if we always choose such a vertex, each node of a tree will exist no more than in  trees built by desomposition which is good enough.

Let's build centroid decomposition of the given tree. Let's root is the root of the current tree. Let's solve the problem for this tree (let's call it 'layer') and solve it for the sons of root recursively after that.

At first,  where g = gcd(a, b).

Also for the current layer dist(u, v) = du + dv where dx is the distance from root to x.

Let's fix some vertex v. How to calc the sum φ(av·av)·dist(u, v) inside our layer over all such u that the path  goes through root? Let's denote the set of such u as A(v). We want to add to the answer 

, where g = gcd(au, av).

Considering we need to sum up all such sums over each v from the layer, the sum current layer increases the total sum equals to .

So we need to be able to sum up , g = gcd(au, av) for each v. Let's understand how to calc sumg for each g which means the sum of Euler's totient functions of all such vertices u, that has gcd⁡(av, au) = g. Let's imagine we know sumphic which denotes the sum of φ(au) for such u that . Then the following statement is true:

.

We can calculate values of sumphi in  time: each divisor of each number in range from 1 to n (which is, as it known, ) will be counted in  layers of the centroid decomposition.

So we're already able to calc sum values in the time apparently proprtional to . More precisely, the number of operations we waste for calculating sum will be equal to  over all such i and x that (1 ≤ x, i ≤ n, , where f(x) is the amount of divisors of x. This sum is equivalent to . Coding this solution carefully can give you Accepted thanks to high TL we set to Java solution. I can prove only  complexity for this solution which is a very high upper bound. Can anyone give any better complexity for ?

However we can speed up this solution. Here we calculated  giving that sumg was equal to  leading to  complexity for each v in the layer.

Actually the sum  for each x can be showed as  using some coefficients cx[]. If we find them we'll be able to process each v of the layer in O(f(av)) time which leads to final  complexity.

Let's precalculate these coefficients in ascending order for each x. It's easy to see that c1[1] = 1 and for a prime p . Now let's x is a composite number and let's p is it's least prime divisor and α is such maximum number that x is divisible by pα, and . Then coefficients for any divisor z of x can be calculated in the following way:

If  then cx[z] = cq[z], otherwise.Total complexity: .

Setter's codeFirst accepted: radoslav11.

Tinkoff Challenge — Final Round Editorial

By zscoder, history, 6 years ago, In EnglishBank RobberyAuthor : zscoder

This is a simple implementation problem. We iterate through all banknotes one by one and check if Oleg can take each of them. If a banknote is at position x, then Oleg can take it if and only if b < x < c. This can be checked in O(1) time. Thus, the total complexity is O(n). Note that the information on the starting position of Oleg is useless here.

CodeCutting CarrotAuthor : zscoder

Let's find the value of xi explicitly. Suppose we make the i-th cut and distance xi from the apex. Then, the ratio of similitude of the isosceles triangle with apex equal to the apex of the carrot and the base equal to the i-th cut and the whole carrot is . Since the area of this smaller isosceles triangle is the sum of areas of the first i pieces, which is  of the whole carrot. Thus, , which is equivalent to . Thus,  and we can find each xi in O(1) time. The total complexity is O(n).

CodeNaming CompanyAuthor : zscoder

First, it is clear that Oleg will place  letters and Igor will place  letters. Next, it is clear that Oleg and Igor will both choose their smallest and biggest letters respectively to place in the final string. Thus, we now consider that Oleg places his smallest  letters and Igor places his largest  letters.

Consider the following greedy strategy. When it's Oleg's turn, he will replace the frontmost question mark with his smallest letter. When it's Igor's turn, he will replace the frontmost question mark with his largest letter. At first glance, you might think that this works. However, there's another case that we haven't considered.

Suppose Oleg has the letters {x, y, z} and Igor has the letters {a, b, c}. According to our previous strategy, Oleg will place x as the first letter. However, that's not optimal. He can place his letters at the back and force Igor to place the first letter. The reason is because the largest letter of Igor is not larger than the smallest letter of Oleg. Thus, it is beneficial for Oleg to place his letters at the back and force Igor to place his letters in front.

So, what exactly will the final string look like? We'll look at the moves one by one. If at some point Oleg's smallest letter is still strictly smaller than Igor's largest letter, then both player must put their smallest (largest if it's Igor) letter as the frontmost letter. Why? Suppose not, then on the next turn the other player will occupy that spot with their best (smallest if Oleg, largest if Igor) letter, and the resulting string will be worse for the current player. This proves that greedy is correct in this case.

Now, what if Oleg's smallest letter is not smaller than Igor's largest letter. In this case, both players will want to force the other player to place their own letter at the beginning of the string. It can be proven that in this case, each person will place their current worst (largest if Oleg, smallest if Igor) letter at the back of the string in the optimal strategy. Thus, we can calculate the final string starting from this point and after that reverse this part and combine it with the first part of the string where both players greedily place their best letters in the beginning.

Time Complexity : O(n)

Many people failed on pretest 6 initially because they didn't consider the second case.

CodeLabelling CitiesAuthor : AnonymousBunny

Add each vertex to its own adjacency list. Now, we claim that if it is possible to label the cities to satisfy the problem conditions, then it is possible to do so so that for every two cities with the same adjacency list, they're labelled with the same number.

Indeed, if they have the same adjacency list, they must be neighbours. Thus, the difference between their labels is at most 1. Suppose we label the first vertex u with number i and the second vertex v with the number i + 1. Note that since their adjacency lists are equal, a vertex x is a neighbour of u iff it's a neighbour of v. Thus, u and v can't have neighbours with labels i - 1 or i + 2, or else it will contradict the condition. Thus, all neighbours of u and v have labels i or i + 1. Thus, we can safely change the label of the second vertex v to i and the conditions will still hold.

Thus, we can sort the set of adjacency lists of each vertex, and then group the vertices with the same adjacency list together. Suppose there are k such groups. For simplicity, we can create a new graph where each group represent a vertex of the new graph. Connect two groups i and j if and only if there exist some vertex in group i that connects to a vertex in group j. Note that the graph will have at most O(m) edges. Now, if a vertex has degree  ≥ 3, we can't assign a number to that vertex properly, as one of its neighbours will not have a label which have a difference  ≤ 1 from it. Thus, all vertices in the new graph must have degree  ≤ 2. Since it's connected, it must be either a cycle or a path. However, it can be easily seen that there is no labelling if it's a cycle. Thus, it must be a path. Now, we can just assign the labels to the graph from one end of the path to the other end by the numbers 1 to k. Finally, the label of a vertex is simply the label of its group.

This solution can be implemented in  time.

CodeChoosing CarrotAuthor : zscoder

First, we solve the problem when no one has any extra turns.

Suppose we're binary searching the answer. Let all the numbers  ≥ x be equal to 1 and all the numbers  < x be equal to 0. Both players can remove one number from one end of the row. The goal of the first player is to let the remaining number be 1 and the goal of the second player is to leave 0 in the end. If the first player can win, this means that the answer is at least x. Thus, we first try to solve this simpler problem.

We claim that the first player wins if and only if :

n is even and one of the two middle numbers is 1.

n is odd, the middle digit is 1 and at least one of the digits beside the middle digit is 1 (unless n = 1, for which first players wins when the only carrot is labelled 1)

Indeed, once we deduce this, we can easily prove this by induction on n. The proof is just doing casework and considering all possible moves.

Once we have this fact, we realize we don't actually have to binary search the answer. If n is even, the answer is  while if n ≥ 3 is odd, the answer is . (If n = 1 then the answer is obviously a1.)

Now, we have to take extra moves into account. Fortunately, it's not very difficult. Having k extra moves just means that Player 1 can choose to start the game in any subsegment of length n - k. Thus, we just have to compute the maximum answer for all subsegments of length n - k for all 0 ≤ k ≤ n - 1. With the formula above, you can find all the answers in O(n) time or even  time if you use sparse table for range maximum query.

CodeLeha and security systemAuthor : hloya_ygrt

We use a segment tree to solve this problem. For each node, it is sufficient to store two arrays : sum[i], denoting the total contribution of the digit i in the current segment (if a digit is in the tens digit then it contributes 10 to the sum and etc...), and also nxt[i], what all the digits i in the current segment are changed to.

Maintaining these arrays is quite straightforward with lazy propogation. When we push an update down a node, we need to update the nxt array of the children. First, we change st[id].nxt[u] to v, where the current update is to change all digits u to v. Then, we change st[id * 2].nxt[i] to st[id].nxt[st[id * 2].nxt[i]], where st[id] is the current node and st[id * 2] is one of the children nodes. (Do the same for the right children). You can see the code if you need more details. Finally, update the sum array of the current segment.

The total complexity of the code is , which is fast enough.

CodeReplace AllAuthor : zscoder

First, we solve the problem when there're no question marks, i.e. we find a way to calculate the number of good pairs of strings fast for a constant pair of strings A and B.

Call a pair of strings (S, T) where |S| ≤ |T| coprime if S = T or S is a prefix of T, and if T = S + X, then (X, S) is also coprime. (S, T) where |S| > |T| is coprime iff (T, S) is coprime.

If A = B, then all possible strings work. Thus, we assume A ≠ B from now on. We remove the longest common prefix of A and B. Thus, we can assume A[0] ≠ B[0]. Thus, either S is a prefix of T or T is a prefix of S. WLOG, S is a prefix of T. Let T = S + X. Now, A and B consists of only S and X. Using this, we can prove by induction on |S| + |T| that S and T must be coprime.

One important property of coprime strings is that S + T = T + S holds. (again induction works here)

Now, since the strings S and T needs to be coprime, we have S + T = T + S. This allows us to swap any neighbouring Ss and Ts (or 'A's and 'B's) in A and B, as the resulting strings will still be equal. Thus, swapping repeatedly allows us to sort the strings A and B. (the 'A's appear in front and 'B's appear at the back) Let xA, xB, yA, yB denote the number of As and Bs in the first string and second string respectively. If (xA, xB) > (yA, yB), then the answer is 0. We'll handle the case (xA, xB) = (yA, yB) later. Now, assume xA > yA, xB < yB. Thus, we have to solve the equation (xA - yA) copies of S = (yB - xB) copies of T.

Now, let x = xA - yA, y = yB - xB. If x = y, then the solution is S = T. Otherwise, assume x > y. Then, |S| < |T|. So, by comparing, we again have T = S + X, for some nonempty binary string X. Note that S and X must be coprime too, so we can sort the second string as well. We cancel off the Ss on both sides to get (x - y)S = yX. Thus, this means that if (S, T) is a solution for (x, y), then (S, X) is a solution for (x - y, y). Note that repeating this process will eventually lead us to (1, 1). (this process is similar to Euclidean Algorithm)

The answer for (1, 1) is the number of solutions to S = T. Let's denote the solution here as X. Doing some backtracking, we realize that the answer for (x, y) is equal to (X....X (y times), X...X (x times)). Note that we still have the condition |S|, |T| ≤ N, so we can translate this to an appropriate condition on the length of X and the answer is simply the number of binary strings of length not exceeding the maximum possible length of X.

The only case that remains is that (xA, xB) = (yA, yB). In this case, any pair of coprime strings S and T will work. Thus, our task reduces to calculating the number of coprime pair of strings with length not exceeding N.

We claim that the number of coprime pair of strings (S, T) with |S| = p, |T| = q is .

If p = q the claim is obviously true. Otherwise, we can induct on p + q agin. If q > p, we can write T = S + X and then the number of coprime pairs of (S, T) is equal to the number of coprime pairs of (S, X), which by induction is equal to . This proves the claim.

Thus, we just need to compute the sum of  for all 1 ≤ p, q ≤ N.

Indeed, since N ≤ 3·105, it is enough to count the number of pairs (p, q) with gcd = g for all g.

However, this is quite easy. Let cnt[i] denote the number of pairs (p, q) such that p and q are both divisible by i. Let ans[i] denote the number of pairs (p, q) with gcd = i. Then, . Thus, this can be computed in .

Now, we need to find out how to calculate the sum of all these values on two strings X and Y with question marks. Handle the case when the two strings become equal separately.

Let's first make a summary of the number of good pairs of strings for constant strings A and B. In fact, note that the formulaes above only depends on (dA, dB), the difference between the number of As in A and B, and the difference between the number of Bs in A and B (note that dA, dB can be negative)

If dA = dB = 0, then the answer is the sum of  for all 1 ≤ p, q ≤ N, which as we have just saw can be precomputed in time.

Otherwise, if dA, dB ≥ 0 or dA, dB ≤ 0, then there are no good pair of strings.

Finally, in other cases, let p = |dA|, q = |dB|. Then, the answer is .

This also means that we can compute the answer if we know dA and dB very fast. (worst case is )

Now, suppose in the strings X and Y, we have a and b question marks respectively. Additionally, suppose the current difference between the number of As and Bs of these strings is (p, q).

If we choose x and y of the question marks from X and Y to be replaced with As, then the difference between As and Bs in the strings become (p + x - y, q + (a - b) - (x - y)). Let's denote q as q + a - b for simplicity. Thus, the difference is now written as (p + (x - y), q - (x - y)). The values of x and y can be any integer in the range [0, a] and [0, b] respectively. Suppose for all  - b ≤ d ≤ a, we know how many ways to assign the question marks have x - y = d. Then, we can iterate through all the ds one by one and compute the answer fast for each d.

Thus, the final hurdle is to calculate the number of ways to obtain x - y = d for all possible d so that 0 ≤ x ≤ a, 0 ≤ y ≤ b. This is just the sum of  for all 0 ≤ x ≤ a. However, this is equal to , as the number of ways to choose b + d objects from a + b objects is the same as the sum of the product of the number of ways to choose x objects from the first a objects and the number of ways to choose b + d - x objects from the first b objects for all 0 ≤ a ≤ x. Thus, this value can be computed in O(1) with precomputed factorials and inverse factorials (or you can maintain this value when we iterate through all d).

Finally, don't forget to take care of the cases where it is possible for both strings to be equal.

The time complexity of the solution is .

Code

Playrix Codescapes Cup Problems Analysis

By KAN, 6 years ago, translation, In EnglishA: Carrot Cakes799A - Carrot CakesOne of possible solutions — to simply simulate described process. To make it we need two variables — t1 and t2. In them we will store the time when each of the ovens will become free. In the beginning t1 equals to 0 and t2 equals to d.

After simulating the process we will get a time for which possible to make n cakes with 2 ovens (this time equals to maximum from t1 and t2). It is only left to compare this time with value (n + k - 1) / k·t — a time for which possible to make n cakes using only one oven.

B: T-shirt buying799B - T-shirt buyingLet's store in three arrays t-shirts which have appropriate color. About each t-shirt is enough to store its index, but we will additionally store its cost. It is possible that one t-shirt will be in two arrays (if this t-shirt colorful).

Then we need to sort t-shirts in each array in increasing order of cost. After that we will process buyers. Also for each array we will store the pointer to leftmost t-shirt which was not purchased yet.

For a new buyer we need to look on array with t-shirts which appropriate to his favorite color. Using appropriate pointer let's iterate to the right until there are t-shirts or until we not found unsold t-shirt (to this we can store one more array used with type bool — did we sell or no appropriate t-shirt). If there are no t-shirt with needed color — print -1. In the other case, print the cost of founded t-shirt and tag in array used that we sold this t-shirt.

C: Fountains799C - FountainsThere are three ways — Arkady builds one fountain for coins and other for diamonds, Arkady builds both fountains for coins and Arkady builds both fountains for diamonds. In the end we need to choose a way with maximum total beauty.

The first way is simple — we need to choose one fountain of each type with maximum beauty on which is enough coins and diamonds which Arkady has. To make it we can easily iterate though all given fountains.

The other two ways are treated similarly to each other. Consider the way when Arkady builds both fountains for coins.

Let's write out all the fountains for a coins in a separate array. We will store them as pairs — cost and beauty. Then sort the array in ascending order of cost. Let Arkady will build fountains with cost p1 and p2 coins and p1 ≤ p2 and p1 + p2 ≤ c. Additionally we need an array maxB, where maxBi equals to maximum fountain beauty on the prefix of sorted fountains for coins which ends in position i.

The option when p1 equals to p2 should be considered separately. It can be done in one iteration through the fountains — from fountains with same cost we need to choose two with maximum beauty and update the answer with the resulting value.

It is only left case when p1 < p2. Let's brute the fountain with cost equals to p2. After that, Arcady will have c - p2 coins. After that with help of binary search we need to find the fountains prefix which Arkay can build for the remaining coins. With help of array maxB we can determine the maximum beauty of fountain which Arkady can build.

Similarly, the third way is solved when both fountains will be built for diamonds.

D: Field expansion799D - Field expansionAt first let's check if rectangle can be placed on given field — if it is possible print 0.

In the other case we need to expand the field. Let's sort all extensions in descending order and take only 34 from them — it is always enough based on given constraints.

After that we need to calculate linear dynamic where di equals to maximum width which we got for the length i. Let's iterate through extensions in sorted order and recalculate d. For each length i we need to expand itself or to expand the width di. To avoid overflow we will not store the width and length which more than 105. On each recalculate value of d we need to check if rectangle can be places on current field. If it is possible – we found the answer and we need to print the number of extensions which we already used.

E: Aquarium decoration799E - Aquarium decorationLet's divide the decorations in four groups: that aren't liked by anybody (group 0), that are liked only by Masha (group 1), that are liked only by Arkady (group 2), that are liked by both (group 3). Sort each group by the cost. Then, it's obvious that in optimal solution we should take several (or 0) first elements in each group. Take a look at the group 3. It's easy to see that if we take x decorations from it, then we should take first k - x decorations from each of the groups 1 and 2. Let's call these decorations (x from the group 3 and k - x from each of the groups 1 and 2) obligatory, and let's call the other decorations free. If the number of obligatory decorations is less than m, we need to take several cheapest free decorations. It's easy to construct an O(n2) solution then: for each x we can construct the answer described in linear time and then choose minimum among these answers.

To speed up the algorithm, let's try all x from the minimum possible (it's easy to get it from integers k, m and groups 1 and 2 sizes), making transfers from x to x + 1. We should maintain the set of costs of free decorations, and let's also keep integer y, which is the number of free decorations that we should add to the current answer, and also the sum of the y cheapest free decorations. When we increase x by 1, in groups 1 and 2 the most expensive obligatory decoration becomes free (because the value k - x decreases by one 1). These decorations (if any) we should add to our free set. We should also add one obligatory decoration from the group 3, so, the number of free decorations could change by one. So, we need at most 2 operations of adding an integer to a set, and an operation that changes y with the corresponding change of the sum. We can perform these operations in O(log(n)), for example, using two std::set objects in С++ (or its analogues in other languages) one set for the smallest y integers and one for the others. The overall complexity to change x to x + 1 is now O(log(n)), so the overall complexity is O(n * log(n)).

F: Beautiful fountains rows799F - Beautiful fountains rowsLet's describe an O((n + m)2) solution first. Let's try all possible pairs (a, b) and check if they suit us. Let's try all values of a from 1 to m.

Let garden (x, y) denote a garden with fountains from x to y, and let's say that a garden bans a position x for a fixed a if there is non-zero even number of fountains on the segment [a, x], i.e. the pair (a, x) doesn't suit Ostin due to this garden.

Now there are two types of gardens we want consider: gardens of the first type start have form (x, y) where x < a, y ≥ a, and gardens of the second type have form (x, y) where a ≤ x ≤ y.

The gardens of the second type ban such positions equal to x + 1, x + 3, ..., and maybe y, y + 1, y + 2, ..., m if (y - x + 1) is even. These positions do not depend on a, we can keep an array that tells us how many gardens ban each position of b. Initially, we add 1 to all such positions for each garden, and we remove that 1 when the a passes beyond the left bound of that garden.

Let R be the set of right ends of all gardens of the first type. These gardens ban positions a + 1, a + 3, ..., x, where x is bounded by the maximum element in R. Also, if there is a value t in R such that (t - a + 1) is even, then all positions t, t + 1, t + 2, ..., m are banned as well. We're interested in the minimum value of t such that (t - a + 1) is even, so, we can keep two separate sets Reven and Rodd for even and odd values, and look for the minimum in one of them.

So, it's easy now to determine if a pair (a, b) is suitable or not. We can try all b, check is there is at least one fountain on [a, b] and add (b - a + 1) to the answer if the pair is suitable.

Let's improve the solution to . We can note that each operation that changes banned positions for the second type gardens is a range query over odd or even numbers. So we can handle it with segment tree with range queries. Similarly, the gardens of the first type reduce non-banned positions of each parity to some segment, so we can do a range query to count the number of non-banned positions in the two trees described. The overall complexity is .

G: Cut the pie799G - Cut the pieLet's first prove that solution always exists. Define f(α) as the difference between the area of the polygon part contained in the halfplane with polar angles in range [α, α + π] and the area of the polygon part contained in the halfplane with polar angles in range [α + π, α + 2π]. Note that f(0) =  - f(π), and since f is a continuous function, it reaches zero somewhere on [0, π].

The proof leads us to the concept of a solution. If we can compute f(α) fast, we can do a binary search over α to find the root. Computing f(α) consists of two parts. First, we should find the intersection points of the line with the polygon, it is a known problem which can be solved in . Second, we should compute the area, and there we can use prefix sums for oriented triangle (the origin and a polygon edge) areas that we use to compute the area of the whole polygon. The only thing we have to add is the oriented area of three new segments, that is easy to compute. The overall complexity is , where ε is the required precision. Note that the angle precision should be more accurate than the required area precision.

VK Cup 2017 Round 3 + Codeforces Round #412 -- Tutorial

By tourist, history, 6 years ago, translation, In EnglishHere is the tutorial of VK Cup 2017 Round 3 and Codeforces Round #412. Enjoy!

Is it rated?807A - Is it rated?To solve this problem, you just had to read the problem statement carefully. Looking through the explanations for the example cases was pretty useful.

How do we check if the round is rated for sure?

The round is rated for sure if anyone's rating has changed, that is, if ai ≠ bi for some i.

How do we check if the round is unrated for sure?

Given that all ai = bi, the round is unrated for sure if for some i < j we have ai < aj. This can be checked using two nested for-loops over i and j.

Exercise: can you check the same using one for-loop?

How do we find that it's impossible to determine if the round is rated or not?

If none of the conditions from steps 1 and 2 is satisfied, the answer is "maybe".

CodeT-Shirt Hunt807B - T-Shirt HuntThis problem was inspired by this comment: http://codeforces.com/blog/entry/49663#comment-337281. The hacks don't necessarily have to be stupid, though :)

Initially, we have x points. To win the current round, we need to score any number of points s such that s ≥ y.

If we know our final score s, we can check if we get the T-shirt using the given pseudocode. Moreover, since hacks change our score only by multiples of 50, the difference s - x has to be divisible by 50.

Naturally, out of all s satisfying the conditions above, we need to aim at the smallest possible s, since it's easy to decrease our score, but difficult to increase.

How many successful hacks do we need to make our score equal to s?

If s ≤ x, we need 0 successful hacks, since we can just make (x - s) / 50 unsuccessful hacks.

If s > x and s - x is divisible by 100, we need exactly (s - x) / 100 successful hacks.

If s > x and s - x is not divisible by 100, we need (s - x + 50) / 100 successful hacks and one unsuccessful hack.

All these cases can be described by a single formula for the number of successful hacks: (max(0, s - x) + 50) / 100 (here " / " denotes integer division).

The constraints were low enough, and the number of required hacks was also low enough. A less effective but easier solution can be achieved if we just iterate over both the number of successful and unsuccessful hacks we make. Once we know these two numbers, we know our final score s and we can explicitly check if this score gives us both the victory and the T-shirt.

More efficient codeLess efficient codeSuccess Rate806A - Success RateThis problem can be solved using binary search without any special cases. You can also solve it using a formula, handling a couple of special cases separately.

If our success rate is p / q, it means we have pt successful submissions out of qt for some t. Since p / q is already irreducible, t has to be a positive integer.

Let's reformulate things a bit. Initially we have x successful submissions and y - x unsuccessful ones. Suppose we fix t, and in the end we want to have pt successful submissions and qt - pt unsuccessful ones. It's clear we can achieve that if pt ≥ x and qt - pt ≥ y - x, since we can only increase both the number of successful and unsuccessful submissions.

Note that both inequalities have constant right hand side, and their left hand side doesn't decrease as t increases. Therefore, if the inequalities are satisfied for some t, they will definitely be satisfied for larger t as well.

It means we can apply binary search to find the lowest value of t satisfying the inequality. Then, the answer to the problem is qt - y. If even for very large t the inequalities are not satisfied, the answer is -1.

It can be proved that one "very large" value of t is t = y — that is, if the inequalities are not satisfied for t = y, then they cannot be satisfied for any value of t. Alternatively, picking t = 109 works too, since y ≤ 109.

Actually, inequalities pt ≥ x and qt - pt ≥ y - x are easy to solve by hand. From pt ≥ x it follows that . From qt - pt ≥ y - x it follows that . In order to satisfy both inequalities, t has to satisfy .

Don't forget that t has to be integer, so the division results have to be rounded up to the nearest integer. In general, if we want to find  rounded up where both a and b are positive integers, the usual way to do that is to calculate (a + b - 1) / b, where " / " is the standard integer division (rounded down).

In this solution, cases when p / q = 0 / 1 or p / q = 1 / 1 have to be handled separately.

Binary search solution codeFormula solution codeDynamic Problem Scoring806B - Dynamic Problem ScoringDynamic problem scoring used to be used more often in Codeforces rounds, including some tournament rounds like VK Cup 2015 Finals.

Once you read the problem statement carefully, the problem itself isn't overly difficult.

Consider new accounts Vasya puts into play. Correct solutions to which problems does he submit from these new accounts?

If Vasya hasn't solved a problem, he can't submit correct solutions to it.If Vasya has solved a problem which Petya hasn't solved, then clearly Vasya wants the maximum point value of this problem to be as high as possible, thus it doesn't make sense to submit its solution from the new accounts.Suppose Vasya solved the problem at minute v, Petya solved it at minute p and the problem's maximum point value is m, then Vasya's and Petya's scores for this problem are m·(1 - v / 250) and m·(1 - p / 250), respectively. Let's denote the difference between these values by d = m·(p - v) / 250. Vasya wants to maximize this value.If p - v is positive (that is, Vasya solved the problem faster than Petya), then d is maximized when m is maximized. To maximize m, Vasya shouldn't submit correct solutions to this problem from the new accounts.On the other hand, if p - v is negative (that is, Petya solved the problem faster than Vasya), then d is maximized when m is minimized. To minimize m, Vasya should submit correct solutions to this problem from the new accounts.Finally, if p - v is zero (that is, Petya and Vasya solved the problem at the same moment), then d = 0 for any value of m, so it doesn't matter if Vasya submits correct solutions to this problem or not.It follows from the above that Vasya should always do the same for all new accounts he puts into play.

Let's iterate over x — the number of new accounts Vasya puts into play, starting from 0. Then we can determine what solutions Vasya should submit from these accounts using the reasoning above. Then we can calculate the maximum point values of the problems, and then the number of points Vasya and Petya will score. If Vasya's score is higher than Petya's score, then the answer is x, otherwise we increase x by one and continue.

When do we stop? If Vasya submits solutions to a problem from the new accounts, then after putting at least n accounts into play the maximum point value of this problem will reach 500 and won't change anymore. If Vasya doesn't, then after putting at least 31n accounts into play the maximum point value of this problem will reach 3000 and won't change anymore. Therefore, if x exceeds 31n, we can stop and output -1.

Note that we can't find the value of x using binary search due to the fact that Vasya can't submit solutions to the problems he hasn't solved. That is, more accounts do not mean more profit. For example, consider the following test case:

30 -1 -1 -1 -1-1 0 -1 -1 -1-1 0 -1 -1 -1If Vasya doesn't use any new accounts, his score will be 1000, while Petya's score will be 500. If Vasya uses at least 61 accounts, both his and Petya's score will be 3000.

CodePrairie Partition806C - Prairie PartitionThis kind of partition sometimes shows up in solutions to knapsack problems with multiple items of the same type.

Let's say we want to check if the answer can be m. That means we have to construct m chains of powers of 2 like 1, 2, 4, ..., 2k - 1 (possibly with different values of k), and then assign at most one of the remaining elements to each chain so that the element doesn't exceed double the largest power of 2 in its assigned chain. If we can assign all the elements successfully, m is one possible answer.

It can be proved that the chains can be constructed greedily one by one, with each chain as long as possible. Let's denote the number of occurrences of integer x in the input by c(x). Then, the number of chains where integer 2k can be used is restricted by bound(2k) = min(c(20), c(21), ..., c(2k)). If we construct the chains greedily, then it's easy to see that the first bound(2k) chains will use 2k. And if we use as many occurrences of powers of 2 as possible, that's better both because we are left with less elements to be assigned to the chains and because the largest powers of 2 in the chains are higher, thus more elements can be assigned to the chains.

Having m chains constructed, how do we quickly check if we can assign the remaining elements to these chains? This can also be done greedily. If we can't assign the largest of the remaining elements to the longest chain, then we can't assign this element to any chain, so there's no possible assignment. Otherwise, remove the largest element and the longest chain from consideration, and repeat the process until we either assign all the elements or run into a failure situation described above. Why is greedy correct? Consider a valid assignment where the largest element E is assigned to some chain c, and some element e is assigned to the longest chain C. If E ≠ e and C ≠ c, it can be seen that we can as well reassign E to C and e to c to get another valid assignment. Thus, if there exists a valid assignment, there also exists one with E assigned to C.

Implemented straightforwardly, this solution works in O(n2). In fact, both factors of n can be optimized.

First, it can be seen that if m is one possible answer but there is at least element equal to 1 not yet involved in any chains, then m + 1 is another possible answer, since when we construct the m + 1-th chain we only make the situation better — we won't have to assigned the elements of this chain to other chains, and we'll have another chain which can be used for assignment too. Therefore, we can perform a binary search on the smallest possible value of m, thus having to do  assignments instead of O(n).

Second, let a be the largest of the input integers. All elements of the input sequence can be distributed into  groups: powers of 2, and integers between consecutive powers of 2. The integers in the groups are effectively indistinguishable from our point of view, which allows us to do the assignment part in .

Applying any of these two optimizations was enough to solve the problem.

Code with the second optimizationCode with both optimizationsPerishable Roads806D - Perishable RoadsThis is my favorite problem in this contest. Several clever observations make its solution really simple.

First important observation helps understand the optimal structure of the signpost directions. Suppose there are two cities A and B with the signposts directed to the same city C. Without loss of generality, suppose that the road A-C has smaller or equal perishability than the road B-C. Then, if the signpost in city B is redirected to city A instead, perishability of the route from B (as well as from other cities with routes passing through B) to the museum city won't increase. It follows that there exists an optimal solution with at most one signpost directing to each city, so the directions of the signposts form a path ending in the museum city.

Second important observation is that there exists a road with the smallest perishability p. Let's subtract p from all road perishabilities, and increase the answer by p·(n - 1) in the end. Now, all roads have non-negative perishabilities, and there exists a road with perishability 0. Once our path contains such a road, perishabilities of all routes from cities after this road up the path is equal to 0.

More formally, let's denote perishabilities of the roads in the path starting from the museum city as w1, w2, ..., wn - 1. The sought sum is then equal to . It's easy to prove that there exists some k such that wk = 0. Indeed, as we go up the path from the museum city, then once we visit an endpoint of any 0-perishability road it's good to follow this 0-perishability road so that route perishabilities of all the remaining cities become 0.

Consider an optimal solution, and let k be the smallest index with wk = 0. Let's prove that for all i ≤ k - 3 we have wi > wi + 1. Indeed, assume that for some i ≤ k - 3 we have wi ≤ wi + 1. Then, since the graph is complete, we can replace the i + 1-th edge with an edge directing to an endpoint of any 0-perishability road, and the i + 2-th edge with this 0-perishability road. In this case, the minimized sum will become smaller, which is a contradiction to our solution being optimal.

Then, we have two options: either wk - 2 > wk - 1 or wk - 2 ≤ wk - 1. If some path of the first type is optimal, then it always coincides with the minimum weight path from the museum city to some city adjacent to a 0-perishability road, and the weight of this path will be the answer. If some path of the second type is optimal, then in this path we first move to some city X, and then use two roads to move to a city adjacent to a 0-perishability road, and we increase the answer by double the weight of the first of these roads as the result of this movement — therefore, first we find the minimum weight path from the museum city to each city X, increase the weight of this path by double the smallest perishability of the roads adjacent to X, and find the answer as the smallest of these values.

This gives us an O(n3) solution if we run Dijkstra's algorithm from every vertex of the graph to find the answer for it.

It can be optimized to O(n2) if instead of running Dijkstra's algorithm from every vertex, we run just one instance of Dijkstra's algorithm, initializing the answer for each vertex with double the smallest perishability of an adjacent edge.

CodeBlog Post Rating806E - Blog Post RatingThere are several different solutions to this problem, I'll describe one of them.

First, we have to determine the optimal rating order for a set of users. Using an exchange argument, it can be shown that to maximize the final community rating the users should rate the blog post in non-decreasing order of their estimated ratings. Indeed, consider an optimal rating order, consider two users with estimated ratings x and y next to each other in this order, and assume that x > y. Let's denote the community rating before these two users rate the blog post by a. Then here is what happens if these two users rate this blog post in the current and the reverse order:

We can see that the x, y order is never better than y, x. That means we can swap these two users in the order and the result won't become worse. We can continue swapping all such pairs of users until we obtain a non-decreasing order.

Now, suppose users with estimated ratings b1 ≤ b2 ≤ ... ≤ bm rate a newly created blog post. For some x, the first x users will rate it with -1. It can be seen that the following property will hold for the rest of the users — their estimated ratings will not be lower than the community rating of the blog post at the moment of viewing the page. Thus, all remaining users will rate the blog post with +1 or 0.

Let's sort all users according to their estimated rating, and maintain a segment tree which contains, for each user in this order, the difference between his estimated rating and the community rating after his view. Initially, all users are inactive and it looks like they rate the blog post with 0. Then, we'll make users active one by one in order of input. We'll also maintain three sets of active users — those who rate the blog post with +1, 0 and -1, respectively.

To make a user active, first we find how he rates the blog post. Then, there are three cases:

If he rates the blog post for 0, there is no need to do anything else.If he rates the blog post for -1, the rightmost -1 might change to 0. If it does, we are done. Otherwise, the community rating before users in the "+1 and 0" group has decreased by 1. Thus, the leftmost 0 (if it exists) changes to +1, and we're done.If he rates the blog post for +1, then either there's a user to the right of him whose value in the segment tree becomes negative, in which case the leftmost of these users now rates the blog post for 0 instead of +1, or there's no such user, in which case nothing else changes.All operations above can be performed using queries to our sets of users and segment tree. For example, when a user appears who rated the blog post with +1, we have to insert him into the +1 set and make a query to the segment tree to decrease the value by 1 in the range from this user to the last user. The answer — that is, the maximum possible community rating after the first k users — is the size of the +1 set minus the size of the -1 set.

CodeTest Data Generation806F - Test Data GenerationThis problem was inspired by division 1 problem A from Codeforces Round #201, which I tested: http://codeforces.com/contest/346/problem/A. Several hours before the round, I noticed that all test cases except for the examples were generated randomly. Moreover, there were three cases with maxn = 10 and maxa = 100, twenty cases with maxn = 100 and maxa = 109, and that's all. Not surprisingly, all test cases had even n and greatest common divisor equal to 1.

The problem statement tells us that interesting test cases have odd n, even an, and odd an / g. Suppose that g is divisible by 2k and not divisible by 2k + 1 for some k ≥ 1. Let's focus on interesting test cases with some fixed value of k.

We choose integers a1 < a2 < ... < an from 1 to maxa, all divisible by 2k, with an not divisible by 2k + 1. This is equivalent to choosing integers a1 < a2 < ... < an from 1 to  with an being odd.

Thus, for fixed k, the problem asks us to calculate the number of ways to choose at most maxn, but an odd number, of integers from 1 to b so that the largest chosen number is odd.

Let f(b, n, p) be the number of ways to choose exactly n integers from 1 to b so that the largest chosen number has parity p (we define f(b, 0, 0) = 1 and f(b, 0, 1) = 0). Suppose that for fixed b we have calculated the values of f(b, n, p) for all n ≤ maxn and . Can we calculate all the values of f(2b, n, p) quickly? Yes, we can!

Here is a formula which allows us to do that:

The first summand corresponds to the case when out of integers from 1 to 2b, we only choose those from 1 to b. In the other case, we iterate over i — the number of integers chosen from 1 to b. It follows that we don't care about the parity of the largest of these i integers, but we have n - i integers chosen from b + 1 to 2b, and we know the number of ways to choose those with the largest integer of the required parity (which might change if b is odd).

This formula allows us to calculate all the values of f(2b, n, p) in O(maxn2), but we can still do better. Let xi = f(b, i, 0) + f(b, i, 1) and . Then,

The right hand side is nothing else but the convolution of sequences x and y, so all these values can be calculated in  using Fast Fourier Transform. The modulo q given in the input was set to a low enough value so that doing FFT in doubles and rounding the result to the nearest integer gave enough precision. Discrete Fourier Transform with two different modulos can also be used, though it's several times slower.

It's also important that, given all the values of f(b, n, p), it's easy to calculate all the values of f(b + 1, n, p) in O(maxn) time. This means we can calculate the values of f(b, n, p) for any b in  using an idea similar to exponentiation by squaring.

Finally, recall that we need to find the values of f(b, n, p) for all , that is, for  different values of b. Doing calculations separately for all b gives a solution which works in .

We can do better if we notice that while doing calculations for , we also do the calculations for all  naturally. Thus, we only need  convolutions. The final complexity of the solution is .

Code

Codeforces Round #411 Editorial

By saliii, history, 6 years ago, In EnglishWe were waiting several weeks to setting this contest and hope the problem was good enough.

EventsThere was a difficulty with 805E - Ice cream coloring/804C - Ice cream coloring. A little bug in the checker fortunately yields accepting an incorrect solution of only one person during the contest. I should apologize all of you because of this.

For this sentence, Vertices which have the i-th (1 ≤ i ≤ m) type of ice cream form a connected subgraph. You can find the meaning of "connected subgraph" with connected and subgraph, thus it can be empty as it is more logical. How ever, I should apologize all of the participants because of weak sample tests in the statement.

I will write the full editorial in the few next days, now some hints and short solutions exist here.

Hints805A - Fake NP

hint1805B - 3-palindrome

hint1805C - Find Amir / 804A - Find Amir

hint1hint2805D - Minimum number of steps / 804B - Minimum number of steps

hint1hint2hint3hint4805E - Ice cream coloring / 804C - Ice cream coloring

hint1hint2hint3805F - Expected diameter of a tree / 804D - Expected diameter of a tree

hint1hint2804E - The same permutation

hint1hint2hint3804F - Fake bullions

hint1hint2hint3hint4hint5hint6Solutions805A - Не NPIf l ≤ r the answer is 2, other wise l.

To prove this phrase, assume the answer is x (2 < x), consider all of multiples of x from l to r as z1, z2, ..., zk. If k =  = 1, 2 is also a correct answer, otherwise numbers from l to z2 - 1 make at least 3 even number, and for each multiple from z2 to zk - 1 as Z, Z or Z + 1 is even, so 2 is also a correct answer.

Bounce: Find the maximum number, occurs maximum number of times in the segment.

From: saliii, Writer: saliii

Time Complexity: 

Memory complexity: 

python3C++805B - 3-палиндромThe answer is constructive as follows:

"aabbaabbaabb..."It is obvious there is no 3-palindrome as substring and the number of 'c' characters is minimum possible equal to zero.From: saliii, Writer: saliii

Time Complexity: 

Time Complexity: 

Memory complexity: 

python3C++805C - Найти АмираConsider pairs of schools cost of their traverse is 0:

.

Connect this pairs with traversing from the second of each pair to the first of the next pair.

So if n = 2·k the answer is k - 1 and if n = 2·k + 1 the answer is k.

The minimum number of direct paths should be n - 1, so because of using all of 0s and make the other direct paths with 1s the path is minimum possible spanning tree.

From: saliii, Writer: saliii

Time Complexity: 

Time Complexity: 

Memory complexity: 

python3C++805D - Минимальное число шаговThe final state will be some character 'a' after 'b':

"bbb...baaa...a"It's obvious to prove all 'b's are distinctive to each other(i.e. Each 'b' in the initial state, will add some number of 'b's to the final state disjoint from other 'b's). For a character 'b' from the initial state it will double after seeing a character 'a'. For each i-th character 'b', consider ti the number of a before it. So the final number of 'b's can be defined as .

From: MohammadJA, Writer: MohammadJA

Time Complexity: 

Time Complexity: 

Memory complexity: 

python3C++805E - Раскраска мороженогоLet's guess as obvious as possible. We can get the answer is at least .We'll just use a dfs to paint the graph with this answer.

Run dfs and in each step, when we are in vertex v with parent par, for each ice cream, if it is in the set of par, then its color is given in the par's set. If not, we'll paint it with a color that isn't used in this set. To prove the algorithm works, assume the first step we paint an ice cream by (answer + 1)-th color, you know the number of ice creams is at last equal to answer, some of these ice creams was painted in the par's set and obviously we don't need to more than szv color to paint them.

From: saliii, Writer: saliii

Time Complexity: 

Memory complexity: 

C++Time Complexity: 

Memory complexity: 

C++805F - Матожидание диаметра дереваLet's solve the problem for two trees.

Define dt as diameter of t-th tree and fti as the maximum path starting from i-th vertex of t-th tree, for all valid i and j, assume that the edge is between them and find the diameter with max(f1i + f2j + 1, max(d1, d2)).

The answer will be:

.Let's improve the  solution to .

Let's sort the arrays f1 and f2 decreasingly and make two partial sums of them, p1 and p2, such that . Iterate on ft, in step i, we will check all of the valid edges which i-th vertex is an endpoint of that: Consider the first element in f1 - t as j such that fti + f(1 - t)j > max(d1, d2), by binary search, according to the previous solution for i-th step, we should add it to the answer:

p(1 - t)j + n - j - 1·max(d1, d2)Let's prove if in each query, we choose t, the smaller tree, the solution will be accepted.

There is two simple modes we should consider:

1- If : The time complexity will be  per query.

2- If : Number of trees with  is at last . If we don't calculate the answer for two same pairs of vertices by memoization, at last  time we need to these bigger trees, so it yields .

From: MohammadJA, Writer: MohammadJA

Time Complexity: 

Memory complexity: 

C++804E - Та же перестановкаIf  then it is simply provable the answer is "NO".

So we just need to check n = 4·k,  4·k + 1. There is a constructive solution to do that. Assume that n = 4·k. Partition numbers to k classes, each class contains a 4 consecutive numbers.

We can solve each class itself by these swaps to reach the same permutation:

(3, 4) (1, 3) (2, 4) (2, 3) (1, 4) (1, 2)

We can do swaps between two different classes as follows to reach the same permutation, assume that the first element of the first class is i and for the second class is j:

(i + 3, j + 2) (i + 2, j + 2) (i + 3, j + 1) (i, j + 1) (i + 1, j + 3) (i + 2, j + 3) (i + 1, j + 2) (i + 1, j + 1) (i + 3, j) (i + 3, j + 3) (i, j + 2) (i, j + 3) (i + 2, j) (i + 2, j + 1) (i + 1, j) (i, j)

Now assume that n = 4·k + 1. Do the swaps above with first 4·k numbers with these changes in place of swaps in the classes itself to satisfy the last number:

(3, n) (3, 4) (4, n) (1, 3) (2, 4) (2, 3) (1, 4) (1, n) (1, 2) (2, n)

From: saliii, Writer: saliii

Time Complexity: 

Memory complexity: 

C++804F - Фальшивые слиткиAs the hints said this problem have two part:

First we want to solve the first part that is evaluating the mni and mxi for gangs. Obviously mni will be the number of thieves have a gold in i-th gang.

lemma1:Consider there is just a single edge from v to u; as hints said if one thief in v with index i has a gold it copied its gold to every j in u if and only if  .

Now we call f(v, g) that g|szv as a gang with size g that thief number i has a gold in this gang if and only if one of the thiefs with index j in v-th gang has a gold such that .

lemma2: Consider two edge like  and . as thing said in hints and above we can consider that v affect in w like this edge:

.

lemma3: Consider a directed walk like w1, w2, , ..., wn. from two last lemmas we can consider the affect of w1 on wn as:

.lemma4: Consider a closed directed walk from v like v,  w1,  w2,  ...,  wn,  v from three last lemmas we can consider  in which u is f(v, gcd(v, w1, w2, ..., wn)).

So now decompose graph of gangs to maximal strongly connected components from lemma4 for every component like a1, a2, ..., an, we can consider in place of all of them gang v with size equal to g = gcd(a1, a2, ..., an) such that i-th thief has a gold in v if and only if there is a j such that i-th thief in f(aj, g) has a gold.

So we decreased the problem to a dag tournament, Let's sort the vertices with topological sort. We'll find a Hamiltonian path of vertices such that for every different i and j there is directed edge from i-th vertex of the path to j-th vertex of the path if and only if i < j. By the lemma 2 it's sufficient to solve the problem for the path itself. So we decreased the problem to a only path. For the path, just do greedily, for each i from 1 to n affect the i-th vertex on the i + 1-th vertex, it can be done with complexity . So mxi is equal to the number of ones after doing all of the things.

For every vertex we'll consider a mxi and mni.We sort this scores in an array T. |T| = 2·n.

Starting from biggest to smallest one. When we reach maximum of i-th vertex and, we fix this vertex and count number of sets he is in which and it has the minimum score of the set:

There is two kinds of vertices, q element of array mn are more than or equal to mni, and of the others, p elements of array mx are more than mxi(means if j-th vertex is in the second kind then mni ≤ mxi < mxj.

So we have to fix number of second kind of vertices as j(1 ≤ j ≤ min(b - 1, p)) and for all j do this: 

It is clear when we fix maximum of j-th and i-th vertex as the minimum score of the set, we didn’t count one such sets twice and when fixing i-th vertex the fact holds. Also it is clear we count all of the situations. The complexity of this part is .

From: saliii, Writer: amsen

Time Complexity: 

Memory complexity: 

Java8C++C++As my good friend, Arpa, did, let me share with you a perfect poem of one of our best poet you might know, Molavi:

.......................................................................................بند بگسل، باش آزاد ای پسر ** چند باشی بند سیم و بند زر

O son,  burst thy chains and be free! How long wilt thou be a bondsman to silver and gold?

.......................................................................................گر بریزی بحر را در کوزه‌‌ای ** چند گنجد قسمت یک روزه‌‌ای‌‌

If thou pour the sea into a pitcher,  how much will it hold? One day's store.

..................................................................................... کوزه‌‌ی چشم حریصان پر نشد ** تا صدف قانع نشد پر در نشد

The pitcher,  the eye of the covetous,  never becomes full:  the oyster - shell is not filled with pearls until it is contented.

.............................................................................. هر که را جامه ز عشقی چاک شد ** او ز حرص و عیب کلی پاک شد

He (alone) whose garment is rent by a (mighty) love is purged entirely of covetousnes

Codeforces Round #410 (Div. 2) Editorial

By I_Love_Tina, history, 6 years ago, In English798A - Майк и палиндромLet cnt be the number of  such that si ≠ sn - i + 1.

If cnt ≥ 2 then the answer is NO since we must change more than 1 character.

If cnt = 1 then the answer is YES.

If cnt = 0 and n is odd answer is YES since we can change the character in the middle, otherwise if n is even the answer is NO because we must change at least one character.

Complexity is O(|s|).

Solution: Link

798B - Майк и строкиFirst of all, you must notice that the operation of removing the first character and appending it to the left is equivalent to cyclically shifting the string one position to the left.

Let's denote by dpi, j the smallest number of operations for making the first i strings equal to string si moved j times.

Let f(i, j) be the the string si moved j times,then .

The answer is min(dpn, 0, dpn, 1, ..., dpn, |sn| - 1).

The complexity is O(|S|3 × n).

Solution: Link

798C - Майк и GCDFirst of all, the answer is always YES.

If  then the answer is 0.

Now suppose that the gcd of the sequence is 1. After we perform one operation on ai and ai + 1, the new gcd d must satisfy d|ai - ai + 1 and d|ai + ai + 1  d|2ai and d|2ai + 1. Similarly, because d is the gcd of the new sequence, it must satisfy d|aj, j ≠ i, i + 1.

Using the above observations we can conclude that , so the gcd of the sequence can become at most 2 times bigger after an operation. This means that in order to make the gcd of the sequence bigger than 1 we need to make all numbers even. Now the problem is reduced to the following problem:

Given a sequence v1, v2, ... , vn of zero or one,in one move we can change numbers vi, vi + 1 with 2 numbers equal to . Find the minimal number of moves to make the whole sequence equal to 0.

It can be proved that it is optimal to solve the task for consecutive ones independently so we divide the array into the minimal number of subarrays full of ones, if their lengths are s1, s2, ... , st,the answer is .

Complexity is .

Solution: Link

798D - Майк и распределениеIn the beginning, it's quite easy to notice that the condition " 2·(ap1 + ... + apk) is greater than the sum of all elements in A " is equivalent to " ap1 + ... + apk is greater than the sum of the remaining elements in A ".

Now, let's store an array of indices C with Ci = i and then sort it in decreasing order according to array A, that is we must have ACi ≥ ACi + 1.

Our answer will always have size . First suppose that N is odd. Add the first index to our set, that is make p1 = C1. Now, for the remaining elements, we will consider them consecutively in pairs. Suppose we are at the moment inspecting AC2k and AC2k + 1. If BC2k ≥ BC2k + 1 we make pk + 1 = C2k, else we make pk + 1 = C2k + 1.

Why does this subset work? Well, it satisfies the condition for B because each time for consecutive non-intersecting pairs of elements we select the bigger one, and we also add BC1 to the set, so in the end the sum of the selected elements will be bigger than the sum of the remaining ones.

It also satisfies the condition for A, because Ap1 is equal or greater than the complement element of p2 (that is — the index which we could've selected instead of p2 from the above procedure — if we selected C2k then it would be C2k + 1 and vice-versa). Similarly Ap2 is greater than the complement of p3 and so on. In the end we also add the last element from the last pair and this makes the sum of the chosen subset strictly bigger than the sum of the remaining elements.

The case when N is even can be done exactly the same as when N is odd, we just pick the last remaining index in the end.

The complexity is .

Solution: Link

798E - Майк и код перестановкиLet's consider ai = n + 1 instead of ai =  - 1. Let's also define the sequence b, where bi = j such that aj = i or bi = n + 1 if there is no such j. Lets make a directed graph with vertices be the indices of the permutation p with edges of type (a, b) representing that pa > pb. If we topologically sort this graph then we can come up with a possible permutation: if S is the topologically sorted graph then we can assign to pSi number i.

In this problem we will use this implementation of topological sort.

But how we can find the edges? First of all there are edges of the form (i, bi) if bi ≠ n + 1 .For a vertex i he visited all the unmarked vertices j (1 ≤ j < ai, j ≠ i) and you know for sure that for all these j, pj < pi. But how we can check if j was already marked? The vertex j will become marked after turn of vertex bj or will never become unmarked if bj = n + 1. So there is a direct edge from i to j if j = bi or 1 ≤ j < ai, j ≠ i and bj > i.

Suppose we already visited a set of vertices and for every visited vertex node we assigned to bnode value 0 (for simplicity just to forget about all visited vertices) and now we want to find quickly for a fixed vertex i an unvisited vertex j with condition that there is edge (i, j) or say it there isn't such j, if we can do that in subquadratic time then the task is solved. As stated above the first condition is j = bi if 1 ≤ bi ≤ n, this condition is easy to check. The second condition is 1 ≤ j < ai and bj > i, now consider vertices with indices from interval 1..ai - 1 and take j with maximal bj. If bj > i we found edge (i, j) otherwise there are no remaining edges. We can find such vertex j using segment tree and updating values while we visit a new vertex. In total we will visit n vertices and query the segment tree at most 2 × (n - 1) times (n - 1 for every new vertex and n - 1 for finding that there aren't remaining edges).

Complexity and memory are  and O(N).

Solution: Link

VK Cup Round 2 + Codeforces Round #409 Tutorial

Автор Lewin, история, 6 лет назад, По-английскиViscious Keyboard801A - Vicious KeyboardWe can count the number of times the string "VK" appears as a substring. Then, we can try to replace each character with "V" or "K", do the count, and return the maximum such count.

Alternatively, we can notice if there are currently X occurrences of "VK" in the string, then we can either have X or X + 1 after modifying at most one character. Try to see if you can find a necessary and sufficient condition for it being X + 1 (or see the second solution.

example code 1example code 2Valued Keys801B - Valued KeysFirst, let's check for impossible cases. If there exists a position i such that the i-th character of x is less than the i-th character of y, then it is impossible.

Now, let's assume it's always possible and construct an answer. We can notice that each position is independent, so let's simplify the problem to given two characters a and b with a >  = b, find a character c such that min(a, c) = b. Here, we can choose c = b. So, for the original problem, if the answer is possible, we can print y.

example codeVoltage Keepsake772A - Вечная КопилкаFirst, let's deal with the infinite case. If the supply of power is at least as big as the sum of demands, we can keep all devices alive indefinitely.

Otherwise, let's binary search for the result. We can do binary search since if we can keep all devices alive for E seconds, we can keep it alive for any time less than E seconds.

Since all usage/charging is continuous, we can think about it as "splitting" up the charge amount.

For each device and a fixed time T, we can compute the rate that we need to charge it so that the device always has positive power. Well, it uses ai power per second, so it uses a total of T * ai power. It currently has bi power, so we need Xi = max(0, T * ai - bi) units of power. This means we need Xi / T units of power per second to this device.

So, we just need to check that . If so, then it is possible to keep the devices alive for T seconds, and we can use this to continue our binary search.

Since we are binary searching on doubles, it is useful to just do it for a fixed number of steps. We can approximate the max answer is somewhere around 1014 and we need a precision of 10 - 4, so we need approximately  iterations.

example code (c++)Volatile Kite772B - Выпуклый КорабльFirst, let's restate the problem as the minimum distance D needed to make the polygon nonconvex. We can notice we can achieve this by by changing one angle of the polygon nonconvex. So, that involves moving at most 3 points. Let's take a look at the following picture:



Here, A,B,C denote consecutive vertices on our polygon. The circle represents the area that each point can be moved to (once we fix our distance), and we want to choose red points that lie in or on the circle such that they form an obtuse angle.

We can see that this is possible as long as the radius exceeds half the distance between segment AC and point B. Thus, we just need to compute the minimum such distance for all such consecutive three points on our polygon.

To compute the distance between a segment and a point, consider this link: https://en.wikipedia.org/wiki/Distance_from_a_point_to_a_line#Line_defined_by_two_points In particular, it is the cross product between (B-A) and (C-A) divided by the length of segment AC.

example code (c++)example code (java)Vulnerable Kerbals772C - Возмутительный КонтрастLet's consider a directed graph with m nodes, labeled from 1 to m, where there is an edge between nodes i and node j if there exists a number x such that .

Now, we can notice there is an edge between node i and node j if and only if gcd(n, i) divides gcd(n, j).

So, there are two directed edges between two nodes i and j if and only if gcd(n, i) = gcd(n, j). So, these form some directed cliques in our graphs.

We can also notice that this happens to form the SCC decomposition of our graph (i.e. condensation). So this problem reduces to finding the heaviest path in a DAG with weights on nodes. The nodes in this dag correspond to divisors of n, and the weight corresponds to the number of allowed numbers with that gcd.

example code (c++)example code (java)Varying Kibibits772D - Властные КонтактыThere are two approaches. One is inclusion exclusion. The other is a modification of the fast walsh hadamard transform.

Inclusion Exclusion: Let's change definition of G(x) so that f(S) >= x rather than f(S) = x. Here "y >= x" means that if y and x are considered as strings, then each digit in a particular position in y is greater than its corresponding digit in x. This is then easy to compute, since the numbers we can use must satisfy the constraint that each digit is larger than the corresponding position in x. So, we can go from 999, 999 to 0 and do inclusion/exclusion to change the >= condition to =, by fixing which digits are fixed and which ones are strictly greater, so it takes 26 time per value of x to compute.

Fast Walsh Hadamard transform: Let's consider the simplified problem where we just want to know the number of subsets that evaluate to x for all values of x.

Let f(freq) taken in a frequency array of length 10^k, and returns a list of length 10^k, where the i-th element represents the result. When k = 0, this is easy to compute, it is just 2freq[0].

Let's fix the value of the topmost digit. We can split our frequency array into 10 parts, representing which one is the top digt. Let's label these freq_0, freq_1, ..., freq_9 (these have length 10^(k-1)).

Then, we can compute g_9 = f(freq_9) g_8 = f(freq_9+freq_8) g_7 = f(freq_9+freq_8+freq_7) ... g_0 = f(freq_9+freq_8+...+freq_0) (The plus signs here are element by element addition, so [0,3] + [5,4] = [5,7] for example).

Then, we can combine these to get the answer to our original problem. Namely, our final answer will be (g_0 - g_1), (g_1 - g_2), ... , g_9 (i.e. concatenate the element by element subtraction of g_1 from g_0 to g_1-g_2 and so on).

Of course, we don't need to do this recursively, we can do it in a loop (see my java code for example).

Back to the original problem, we need to keep track of three values when doing the first pass of our algorithm, the number of elements, sum of elements, and sum of squares of elements. Then, in our base case, we can use these three numbers to compute the desired sum.

The runtime of this is T(n) = 10 * T(n/10) + O(n) = O(n log_10(n)).

example code (c++, inclusion/exclusion approach)example code (java, FWHT approach)Verifying Kingdom772E - Верифицируем КоролевствоConsider building the tree leaf by leaf.

The base case of two leaves is trivial.

Now, suppose want to add another leaf wi.

We can define the "centroid" as a tree such that after removing the centroid, all remaining connected components has at most half the number of leaves (note this is different from the standard definition of centroid).

Notice, each internal node can be represented as a pair of leaves (x,y), where x comes from the left child, and y comes from the right child.

Ask the judge (x,y,w_i).

Depending on the response, we can remove the centroid, and know which subtree that w_i lies in (i.e. either the left child, right child, or upper child). So, we can recurse on that tree.

So, inserting a node takes log_2 i questions and O(i) time, so overall we ask n log n questions and take n^2 time.

example code (c++)example code (java)

Codeforces Round #408 (Div. 2) [Editorial]

Автор zoomswk, 6 лет назад, По-английски796A - Buying A HouseThis is a simple implementation problem.

Let the ans be infinity initially.

Iterate through the houses. Suppose we are considering house i, update the ans if and only if

1) ai ≠ 0,

2) ai ≤ k, and

3) |i - m| < ans.

The answer is 10 * ans.

This solution runs in O(n).

Official Implementation: http://ideone.com/jsXSst

===

796B - Find The BoneThis is another implementation problem.

Let’s create an array a of length n (with initial values set to 0), and set ai = 1 only for the positions x = i where there is a hole.

If there is a hole at x  =  1, obviously, the answer is 1, because the ball must fall onto the ground before any operation is applied.

Otherwise, consider each swapping operation chronologically (from the first to the last).

While doing so, we will also maintain a variable pos, the position where the ball is.

Let the involving cup positions be u and v. There are three cases to consider:

1) If pos is equal to u, set pos  =  v.

2) If pos is equal to v, set pos  =  u.

3) Otherwise, skip the operation.

Make sure to stop considering any more operations if apos equals 1.

After this procedure, pos will be the final answer.

This solution runs in O(k).

Official Implementation: http://ideone.com/YD7s4S

NOTE: If you get TLE, use faster input methods. For example, use scanf instead of cin.

===

796C - Bank HackingFirst, note that the input graph is a tree.

Let m be the greatest value of ai (that is, max(a1, a2, ..., an)). Observe that the answer can be m, m + 1, or m + 2 only.

Why? It is because each bank’s strength can be increased at most twice, once by a neighboring bank, and once by a semi-neighboring bank. So the strength required to hack bank i is at most ai + 2, regardless of the sequence of banks you choose to hack.

Now, suppose u is the first bank we would hack first. We would need a computer with strength at least au to hack it. Let the neighboring banks of u be v1, v2, ..., vk. We would need a computer with strength at least avi + 1 to hack those banks. And for each bank x not yet hacked, we can hack them with a computer with strength at least ax + 2.

For simplicity, add 2 to all the banks’ strengths. Let’s maintain a map data structure to keep track of number of times some value of strength occurs. Again, suppose we would start by hacking bank u. Now, we would need a computer with strength at least au - 2 to hack it. For the neighboring banks v, it would be av - 1. For other banks x, it would be ax.

For a fixed bank u, you can iterate through its neighboring banks, and update the map data structure accordingly. Keep track of the maximum value that occurs, and update the answer.

We can simply iterate through banks u to start with, and get the final answer.

But wait. Won’t it work in  or something like that?

No. Let’s analyze the runtime carefully. (You can skip this if you know why. This is for beginners.)

Suppose we choose bank u to start with. We have to iterate through its neighboring banks. The number of the banks neighboring to u is equal to the degree of bank u. We would need O(1 + du) operations for bank u.

By iterating through all possible u from 1 to n, we will perform O(n + d1 + d2 + ... + dn) operations. You can see that if there are m edges in a graph, the degrees of all nodes sum to 2m. Trees have n - 1 edges, so d1 + d2 + ... + dn  =  2(n - 1)  =  2n - 2  =  O(n). Therefore, we need to perform only O(n) operations. However, each operation involves the map data structure, so the overall runtime is . Be aware that the use of hash map could bring the runtime to O(n2).

Looking more closely, we can also keep track of the occurrences of only m + 1 and m + 2, and no other values. So, although not required to get AC, we can get rid of the map data structure, and therefore eliminate the logarithmic factor.

The official solution provided here runs in O(n).

Official Implementation: http://ideone.com/B9pjyi

NOTE: If you get TLE, use faster input methods. For example, use scanf instead of cin.

===

796D - Police StationsA greedy solution shutting down either every d roads or when a police station is encountered, although seems pretty nice, turns out to be incorrect.

Consider performing a breadth first search (BFS) with “cities with a police station” as starting vertices, and shutting down the road when it leads to a visited vertex (city). This will leave every bad city connected (either directly or indirectly) with one of its nearest police stations, and thus will not break the law.

With this method, you can see that exactly k’ - 1 roads will be shut down (where k’ is the number of cities that have a police station in them). Suppose this is not optimal, and k’ + c (c ≥ 0) roads can be shut down. The tree will break into k’ + c + 1 components, while there are only k’ cities with a police station, so this is a contradiction, since there will be at least one component without any police station. Hence, shutting down k’ - 1 roads is optimal.

Official Implementation: http://ideone.com/nlPVW0

===

796E - Exam CheatingThis problem can be solved using dynamic programming.

First, observe that it is never suboptimal to look as many consecutive questions as possible. That is, just look k consecutive questions whenever you decide to glance, unless it exceeds the corner (question n).

Let dp[i][j][a][b] denote the number of questions you can get correct by considering questions 1 to i by glancing exactly j times with a and b being the number of remaining questions that can be looked at as a benefit of the previous glances. As stated before, it is optimal to look as many consecutive questions as possible, so when we decide to look, we share this benefit (of looking) to the next questions too, and it are stored in a and b, which denote how many of the next consecutive questions can be looked without paying one more glance. The answer can be calculated in O(npk2). (You can see in the code as to how.)

However, npk2 can be up to (1000) * (1000) * (50) * (50)  =  2, 500, 000, 000, so the solution will not fit in the time limit of 2 seconds.

This can be improved. Observe that if p > 2 * ceil(n / k), you can look at all questions on both geniuses’ answer sheets, so the answer can be found in O(n) (or you can just set p to 2 * ceil(n / k) and run the dynamic programming). By eliminating this case, the running time for dynamic programming will become O(npk2) = O(n(n / k)k2) = O(n2k). This, indeed, will fit in time, as n2k is only (1000) * (1000) * (50)  =  50, 000, 000.

Problem with memory limit might still persist, so you will need to optimize the use of memory. For example, since you need only dp[i - 1][..][..][..] and dp[i][..][..][..] when calculating dp[i][..][..][..], you could remember only the two last rows. The memory use will be much smaller. The use of short data type (instead of int) may also help.

Please see the commented code for more details.

Official Implementation: http://ideone.com/cwP55b

===

796F - Sequence RecoveryFirst, let’s find the maximum value each integer can be. Chronologically considering the operations, you can see that once an integer is involved in type 2 operation, future type 1 operations can tell nothing about its initial value. You can find naively find the maximum value each integer can be in O(nm), but that’s obviously way too slow.

This can be solved using segment trees. You might be familiar with point updates and range queries, but now you have to consider point queries and range updates. No—lazy propagation is not needed. This process can be solved in .

After that, let each integer has its maximum possible value as its value. Go through the operations once again one by one (both type 1 and type 2), and check with another segment tree whether this sequence gives correct results for type 1 operations. If it is not, you can be sure that there is no valid sequence. Why? Let’s consider two cases. If the result is smaller than what the input says, this integer can’t really be bigger than it is (other type 1 operations needed it to be this small, or maybe type 2 operation forced it to become this value). If the result is bigger than what the input says, this happens only when there is a contradiction between type 1 and type 2 operations, and nothing can be done (because type 2 operations say so).

Let’s complete the final step — make the bitwise OR maximal. You should consider 2 cases.

1) There is more than one free integer. (Free integer is the one such that no type 1 operation limits it maximum value.)

The optimal bitwise OR is simply 230 - 1. Just make one of the free integers 229 - 1 and the others 109 (any value no less than 229 but also no more than 109 will work). You can be sure that this is optimal. Other integers can simply remain untouched.

2) Otherwise

For case 2, for each value appearing in more than one integer of the sequence (do not consider the one without maximum value yet), you can lower one of them. Lowering more than one of them will not give a better result if you lower it in this way: sacrifice the most significant bit for ALL other less significant bits. It’s obvious that the operations remain satisfied. As for the free integer, if any, you can greedily assign some bit to it, starting from the most significant bit, but make sure that it doesn’t exceed 109 in value.

Official Implementation: http://ideone.com/FfnJyp

===

Feel free to ask any questions below. It's hard to write an editorial that satisfies the need of everyone. I hope you'll enjoy solving the problems :)

Codeforces Round #407(Div.1 + Div.2) Editorial

By giraffeh, history, 6 years ago, In English789A - Anastasia and pebblesFor every pebble type we can count the minimal number of pockets Anastasia need to collect all pebbles of this type. That's easy to notice that this number equals . So the answer for the problem is . Solution complexity is O(N).

789B - Masha and geometric depressionWe need to handle following cases in the solution:

|b1| > l — answer is 0.b1 = 0 — if 0 is present in array a than answer is 0, else inf.q = 1 — if b1 is present in array a than answer is 0, else inf.q =  - 1 — if both b1 and  - b1 are present in array a than answer is 0, otherwise inf.q = 0 — if 0 isn't present in array a than answer is inf, else if b1 is present in a than answer is 0, else answer is 1.In all other cases we can simply iterate over all terms of progression b while their absolute value doesn't exceed l. For every term that is not present in a we simply increasing answer by 1. Obviously, the absolute value of every next element is bigger in at least 2 times than the absolute value of previous. That's why we'll need to check at most log l progression terms.Solution complexity is O(M·logL) or O(M·logM + logL·logM).

788A - Functions againWe can solve the problem for segments with odd and even l separately. Let's build arrays b (bi = |ai + 1 - ai|·( - 1)i) and c (ci = |ai + 1 - ai|·( - 1)i + 1). Obviously, that segment with the greatest sum in array b starts in some even index. In every segment starting in odd index we can move l one position right and make answer not-worse, because every element of odd index in b is non-positive. Also, sum of segment starting in even index of b equals to value of f on the same segment. Analogically for array c and odd starting indexes. So the answer equals to maximal of maximal sums of arrays b and c.

The segment with the greatest sum can be found with the two pointers method or using prefix sums. Such solution works with O(N) complexity.

788B - Weird journeyWe can consider the system of towns and roads as a graph, where edges correspond to roads and vertexes to cities.

Now, let's fix two edges, that will be visited once. All other edges we can split into two. Then, the good way in the old graph equivalents to any Euler path in the computed one. Widely known that Euler path exists in graph when and only when there are 0 or 2 vertexes with odd degree. Consider following cases of mutual placement of edges that will be visited once:

Regular(not loops) edges that are not adjacent — graph has four vertexes with odd degree, so Euler path doesn't exist.Regular edges that are adjacent — graph has exactly two vertexes with odd degree, so Euler path exists. So, any pair of adjacent regular edges satisfies Igor.One of the edges is a loop — graph hasn't any vertex with the odd degree(if another chosen edge is a loop too) or has two of them(if another chosen edge is regular). So, any pair in which at least one edge is a loop satisfies Igor.So, we have to calculate the number of pairs of adjacent regular edges and add the answer for loops. For every vertex i we can calculate cnti — the number of regular edges incoming in it. General number of adjacent regular edges is . Also, we need to add the number of pairs with loops. Let's count loop — general number of loops in the graph. So we can add loop·(m - 1) to the answer. Now, we included pairs with two loops twice. That's why we need to subtract Cloop2 — the number of pairs with two loops.

Also, we need to check the graph to be connected by edges. If the graph is not connected then the answer is 0. We can do it using algorithms of DFS or BFS.

Complexity of the given solution if O(N + M).

788C - The Great MixingLet  — needed concentration and s1, s2, ..., sm — concentration of types we'll use.









Then, we can decrease every si by n. So, we reduced the problem to finding a set of numbers with zero sum.

Now we can build a graph, where vertexes are our sum.

There will be m edges from each vertex, where m — the number of different concentrations. Obviously, we'll have at most 1001 different concentrations, so there are at most 1001 edges from each vertex. Now, we need to find a cycle of smallest length. We can do this using BFS starting from vertex 0. With BFS we can find the first vertex with the existing edge to vertex 0.

We need at most 1000 vertexes to each side (from -1000 to 1000), so the solution complexity is O(2001·min(k, 1001)).

788D - Finding linesFirst we solve another problem. Let we have points not straight lines, but points on one axis. Let MAX = 108, that is, the maximum coordinate. First, we find the left and right points. The left is ( - MAX + get( - MAX)), and the right one (MAX - get(MAX)). Then we solve the problem recursively. There will be a function f(l, r) that finds all points on the segment (l, r) if l and r — are points. We have already found the extreme points, so we can call this function.

The function f(l, r) makes a query at the center point between l and r, that is, . If the answer is equal to the distance to the extreme points, then there are no more points between l and r. If the distance is less, then for one more query we can find out the point on the left or right. Let this point x, then we start f(l, x) and f(x, r).

We introduce a function that checks if there is a vertical line x. We can select a random point in the range [ - MAX, MAX] and make a query, if the answer 0 — is a straight line. If MAX = 108, and the maximum n = 104, then the error probability is 10 - 4, if you querys twice, then 10 - 8.

Now we will solve the main task. We make a query at the point ( - MAX,  - MAX), we can find out whether the minimum distance to the vertical or horizontal line. We introduce the function G(x, y), which will find the nearest straight line whose coordinates are greater than x or y, and get(x, y) = 0. How is this solved? If there are no more lines, then for non-negative t, get(x + t, y + t) = t. Then we can find a minimal power such that get(x + t, y + t) ≠ t. Then we know that this applies to either the vertical line (x + t + get(x + t, y + t)), or the horizontal (y + t + get(x + t, y + t)) . We can find out which one. If, for example, to the vertical one, then we solve the problem for G(x + t + get(x + t, y + t), y).

Then we find either all horizontal lines, or all vertical lines. To find out which straight lines we found, we need to look at the last function G(x, y), namely our "ray". If it rests on the vertical straight MAX, then we find all the vertical ones. And vice versa.

Now how to find other lines. Let's say we found all the vertical ones. Then we will find the maximum distance between the neighbors, between the first line and ( - MAX), between the last line and (MAX), this distance will be at least .

That is, we search in what position the maximum will be reached, if there are no horizontal lines, let it be val. Let this be the coordinate x, we will make queries on the line x, starting with —  - MAX, ending with MAX, with the step . We find all the points whose answer is not equal to val. Then we can divide all these points into "segments", that is, a set of points that go successively. For each "segment", the minimum distance will only apply to horizontal lines, that is, vertical ones will not affect in any way. Therefore, each "segment" can be solved independently, by the method already known to us (assume that there are no vertical lines).

788E - New taskTo begin with, we apply scaling to all numbers and replace each element of the array with its position in the sorted array.

Count the answer for the original array. For each i, calculate smaller_prefi as the quantity of such j that j < i, aj ≤ ai and smaller_sufi — the number of such j that j > i, aj ≤ ai. This can be done with a segment tree or a Fenwick tree. If we consider each element as k from the command [i, j, k, l, p], then the answer for fives with this k is smaller_prefj, aj = ak)·smaller_sufj, aj = ak). The common answer is the sum of the answers for each possible k. Now after each request we will update the answer. We will support for each type of number for the prefix and suffix for 2 segment tree. Since when, an element turns on/off it is important to know only information about elements with the same value, then you can update the answer using only it. Consider array b as a number vector of occurrences of the form au.

In the first "suffix tree" in the sheet we store smaller_sufbi, if the element with the number bi is included, otherwise 0, and in the remaining vertices the sum in the sons. In the second suffix tree we store in the sheet smaller_sufbi·((the number j, such that aj = abi,  < b[i], element with the number j — is included) + 1), if the element with the number bi is included, otherwise 0, and in the remaining vertices the sum in the sons.

For the prefix, you need to do exactly the same thing.

Let cntau be the number of numbers of the form au.

Now when the request for turning off/on the element with number u came, we need to subtract/add to the answer the number of such pentads [i, j, k, l, p] where u = k, u = j, u = l. Further cu =  ((the quantity j, j < u, aj = au) + 1). In other words, cu — is the number in the occurrence vector of numbers of the form au). First, consider the number of fives where u = k. Them is (the sum on the interval [1;cu-1] in the first prefix tree) · (the sum on the segment [cu+1;cntau] in the first "suffix tree").

The number of fives where u = j is ((the sum on the segment [cu+2;cntau] in the second "suffix tree" segments) - ((the number of elements j, j ≤ u, aj = au, the element with the number j is included) +1)· (the sum on the segment [cu+2;cntau] in the first "suffix tree" segments ))·smaller_prefu. The number of fives where u = l must be calculated in the same way as for u = j, only in the other direction.

Updating the values ​​of the suffix tree elements:

When the item is turned off, you need:Take the sum on the segment [cu+1;cntau] in the second segment tree in the same segment in the first tree.Assign the element with the number cu to the element in the second segments tree 0.Assign the element with the number cu in the first tree 0.When you enable an item, you need:Add on the segment [cu+1;cntau] in the second segment tree the sum on the same line in the first tree.Assign the element with the number cu in the second tree (the number of such j, j ≤ u, aj = au, the element j is included) + 1)·smaller_suffu.Assign the element with the number cu in the first tree smaller_sufu.The update in the tree with the prefix is the same.

Adding on the segment will be done by a kind of lazy pushing — in the second segment tree you need to have access to the corresponding vertex of the first tree, when changing the vertex, add/subtract the sum at the top of the first segment tree.

The complexity of the solution is O(N·logN + M·logN)) by time, O(N) by memory.

Codeforces Round #406 Editorial

By PrinceOfPersia, 6 years ago, In EnglishHere's the git repository containing source codes for problems of this contest.

 

787A - The MonsterYou need to find out if there are non-negative integers like i and j such ai + b = cj + d and i or j (or both) is minimized. It's easy to show that if a, b, c, d ≤ N, and such i and j exist, then i, j ≤ N, so you can iterate over i and check if such j exists.

Time complexity: 

 

787B - Not AfraidThe problem says given a CNF formula, check if we can set value of literals such that the formula isn't satisfied. Answer is yes if and only if you can set values so that at least one clause isn't satisfied.

It's easy to show that answer is yes if and only if there's at least one clause that for that clause there's no i such that xi and  are both in it. This can be easily implemented.

Time complexity: 

 

786A - BerzerkFor each state of monster (2n possible states, the position and whose turn it is) we will determine if it will be won, lost, or stuck in loop (the player whose turn it is, will win, lose, or the game will never end if this state happens).

For this purpose, first each state with monster on 1 is lost. Then if we consider a graph that its vertices are our 2n states, we will recursively determine the answer for each vertex. If a state has an edge to a lost state, it's won, and if all its edges are to won states, it's lost. The vertices that are neither lost or won at the end have answer "loop".

You can implement this using a simple memoize.

Time complexity: 

 

786B - LegacyConsider a weighted directed graph (initially it has n vertices and no edges). We will construct a segment tree to handle queries of second type (and one for the third type but with similar approach).

Build a segment tree on number 1, ..., n. For each node of segment tree consider a vertex in the graph. For each leaf in this tree (like one with interval [l, l + 1)), add an edge with weight equal to 0 from vertex corresponding to this node to vertex l in the original graph. And for each non-leaf node, add an edge with weight equal to 0 from vertex corresponding to this node to the vertex corresponding to node of each of its children.

So we're adding about 4n vertices and edges to the graph. For each query of second type, we will add an edge from v to each maximal node of segment tree that [l, r) contains (lg(n) nodes for each query) with weight equal to w.

And construct a segment tree in the same way for queries of third type. Finally run Dijkstra's algorithm on this graph.

Time complexity: 

 

786C - Till I CollapseYour task is to find the minimum number of parts needed to partition this such that each part contains no more than k different numbers.

For a fixed k, we can greedily find the answer. First, fix a maximal partition with at most k different numbers in it, then a maximal after that and so on. If answer for k is ans(k), we can find this number in . The only thing we want is to find maximum r for a fixed l so that [l, r] has at most k distinct numbers.

This can be done with binary search + segment tree, but it's too slow. We can do this using a persistent segment tree in : for a fixed l, we define fl(i) to be 1 if l ≤ i and there's no such j that l ≤ j < i and ai = aj otherwise 0. So, if we have a segment tree on every fl, we can use this segment tree to find the first r for an arbitrary k (it's like finding k - th one in this array).

So we find the answer in , so the total complexity is , and because , , so:

Total time complexity: .

 

786D - Rap GodUse centroid-decomposition. In each decomposition:

Assume c is centroid of current subtree. Then for each vertex v in current subtree, we want to find some part of answer for each query with x = v. More precisely, for each query (x, y) that x is in the current subtree (in the decomposition), we want to find the number of vertices like z such that z is also in the subtree, if we remove the centroid from the tree z and x will be disconnected (centroid itself satisfies this condition) and str(x, z) < str(x, y).

str(x, z) = str(x, c) + str(c, z). So for each query first compare str(x, y) with str(x, c). Comparing two paths (str(x, y) and str(v, u)) can be done using hash (for each v and k, keep hash of str(v, 2i - th parent of v) and its reverse) and using binary search for finding LCP of two strings. Based on result of comparison:

If str(x, y) < str(x, c), then there's no such z in current subtree.If str(x, y) > str(x, c) and str(x, c) is not a prefix of str(x, y), then all vertices like z that satisfy the first two conditions (from the three conditions above) are counted.Otherwise there's a vertex e on path from x to y such that str(x, w) = str(x, c). Because str(x, z) = str(x, c) + str(c, z) and str(x, y) = str(x, w) + str(w, y) = str(x, c) + str(w, y), then you have to count such z that satisfy the first two conditions and str(c, z) < str(w, y).For the third case, you need to count vertices like z that str(c, z) < str(w, y). For this purpose, using a single DFS construct trie of all str(c, z) and then for each query find the position of str(w, y) in the trie (using hashes and binary search). More precisely, you need to find LCP of str(w, y) and strings in the trie to determine how many strings in the trie are less than str(w, y).

All of this can be done in  And there's an additional log for centroid-decomposition, so:

Total time complexity: 

 

786E - ALTIf n and m were smaller: We construct a bipartite graph. For each citizen we consider a vertex in the first part, and for each guardian in the tree we consider a vertex in the second part. We put an edge between vertex i from first part and j from second part if and only if path xi to yi contains edge j. Answer to the problem is vertex cover of this graph. Time complexity: 

But now that n and m are great, we can't use this approach.

We will instead build a DAG. Like above, For each citizen we consider a vertex in the first part, and for each guardian in the tree we consider a vertex in the second part. Consider the data structure that is used to find LCA of two vertices in the tree (keeping 2i-th ancestor of each vertex for each i). We will use that to build the graph.

For each vertex v in the tree and i (0 ≤ i ≤ lg(n)), we consider a vertex in the tree, this vertex is pr(v, i). We'll build a flow network. For each v, we put an edge from pr(v, 0) to the vertex corresponding to edge (guardian) connecting v and its parent (with capacity = ∞). For each i > 0, we put an edge from pr(v, i) to pr(v, i - 1) with capacity = ∞ and one to pr(2i - 1 - th parent of v, i - 1) with capacity = ∞. Then for each citizen, like the algorithm we used to find the LCA of xi and yi, when we're going up from a vertex v to its i-th parent, we put an edge from vertex corresponding to citizen i to pr(v, i) with capacity = 1.

Finally we consider a vertex S as source and T and sink. For each citizen i, we put an edge from S to vertex corresponding to him/her with capacity = 1. And for each guardian put an edge from vertex corresponding to this edge to T with capacity = 1.

It can be shown that the answer to the original problem is maximum flow of this network. Also certificate can be found using a DFS (it's exactly like finding a certificate(vertex cover) in maximum-matching approach).

Since the network contains levels(cuts) from S to T with all edges with capacity equal to 1, the total time complexity is  where E is the number of edges in the network which is , so:

Time complexity: 

 

Don't hesitate to ask if you have any question/suggestion.

UPD: Git repo was not completely public, it is now. You can clone it or you can browse codes in "Repository" section.

VK Cup 2017 Round 1 and CF Round 405 — Editorial

By Errichto, 6 years ago, In English791A - Bear and Big BrotherThis problem is simple: just multiply a by 3 and b by 2 until a > b. Output the number of operations. You will not need more than 6 iterations.

Code: 25627790

771A - Bear and Friendship ConditionThe main observation is that you should print "YES" if the graph is a set of disjoint cliques (in each connected non-clique there is a triple of vertices X,Y,Z that X-Y and Y-Z but not X-Z). To check if each connected component is a clique, you can run dfs and count vertices and edges in the connected component — it's a clique if and only if .

Code: 25627860

771B - Bear and Different NamesFirst generate n different names. If the i-th given string is "NO", make names i and i + k - 1 equal. Note that it doesn't affect other groups of k consecutive names.

Code: 25627873.

771C - Bear and Tree JumpsIt's a known problem to count the sum of distances for all pairs of vertices. For each edge, we should add to the answer the number of times this edge appears in a path between some two vertices. If sv denotes the size of the subtree of the vertex v (we can first root the tree in 1), we should add sv·(n - sv) to the sum.

In this problem, the answer is around , where S is the answer for the known problem described above. But for each path with length L, we should add  to the answer, where f(L, k) says how much we must add to L to get a number divisible by k (f(10, 3) = 2, f(11, 3) = 1, f(12, 3) = 0). We know the sum of  because it's  in total. What remains is to compute the sum of f(L, k). To achieve that, for each remainder modulo k, we want to know the number of paths with length that has this remainder. For example, if k = 3 and there are 200 paths with remainder 1, they all have f(L, k) = 2, so we should add 200·2 to the answer.

Let's root the tree in any vertex and do bottom-up dp. For each subtree we compute the k values: for each remainder modulo k how many paths (starting from the root of this subtree) have this remainder. We can merge two subtrees in O(k2), so the total complexity is O(n·k2). See my code for details.

Code: 25627885.

771D - Bear and CompanyLetters different than 'V' and 'K' are indistinguishable, so we can treat all of them as the same letter 'X'.

We will try to build the final string from left to right Let dp[v][k][x] denote the number of moves needed to move first v letters 'V', first k letters 'K' and first x letters 'X' to the beginning of the string (those letters should become first v + k + x letters of the string). We should also remember the last used letter (to ensure that there is no 'K' just after 'V') so let's extend the state to dp[v][k][x][lastLetter] (or it can be dp[v][k][x][is_the_last_letter_V]).

To move from a state, we should consider taking the next 'K' (i.e. the k + 1-th letter 'K' in the initial string), the next 'V' or the next 'X'. Of course, we can't take 'K' if the last used letter was 'V'.

The last step is to see how we should add to the score when we add a new letter. It turns out that it isn't enough to just add the difference between indices (where the letter was and where it will be) and the third sample test ("VVKEVKK") showed that. Instead, we should notice that we know which letters are already moved to the beginning (first k letters 'K' and so on) so we know how exactly the string looks like currently.

For example, let's consider the string "VVKXXVKVV" and moving from the state v = 4, k = 1, x = 1 by taking a new letter 'K'. We know that first 4 letters 'V', 1 letter 'K' and 1 letter 'X' are already moved to the beginning. To move the next letter 'K' (underlined in blue on the drawing below) to the left, we must swap it with all not-used letters that were initially on the left from this 'K'. Counting them in linear time gives the total complexity O(n4) but you can also think a bit and get O(n3) - it's quite easy but it wasn't required to get AC. On the drawing below, used letters are crossed out. There is only 1 not-crossed-out letter on the left from 'K' so we should increase the score by 1 (because we need 1 swap to move this 'K' to the x + k + v + 1-th position).

Code: 25627898.

771E - Bear and Rectangle StripsThere are three types of rectangles: in the top row, in the bottom row, and in both rows (with height 2). For each type, and for each starting index i we can quite easily find the first possible ending index - it's the first index on the right with the same prefix sum of numbers (it means that the difference of prefix sums is 0). We can iterate from right to left for each of three types, use store prefix sums in the set and for each type and each starting index we can remember the first possible ending index (or we will know that there is no such index). The complexity of this part is .

Now, the naive square solution would be to create an array dp[n][n] and compute dp[i][j] as the maximum possible score, if we are allowed to use only first i cells in the first row and first j cells in the second row. Thanks to the precomputing above, we can move from a state in O(1), considering the following options:

increase i by 1 (without taking any rectangle)increase j by 1take the first possible rectangle in the first row (check what is the first possible ending index of a rectangle in the first row, starting at index i + 1)take the first possible rectangle in the second rowif i = j, also consider taking first possible rectangle of height 2 (in both rows)Now let's improve this part to O(n). Let Ci denote the best score if we were allowed to use only first i cells in each row (Ci = dp[i][i]). It turns out that the following values for each i are enough to solve the problem:

CiIf we were allowed to use only first i cells in the first row, how far we must go in the second row, in order to get the score Ci + 1. In other words, what is the smallest j such that dp[i][j] = Ci + 1Similarly, the smallest j such that dp[j][i] = Ci + 1Take a look at the drawings below. The value Ci is the maximum possible score for light-blue cells on the left drawing. The right drawing shows the third of situation listed above - we want to know what prefix of cells in the first row is needed, if we want to get the score Ci + 1.

To see that it works, we must prove that we don't have to care how far we must go in one row to get the score Ci + 2 or higher. The crucial observation that getting score at least Ci + 2 means that we took at least two rectangles that are at least partially on the right from index i (i.e. each of them contains at least one cell with index greater than i) - see the drawing below. So, instead of considering this situation now, we can first take some rectangle in the second row (or skip a few cells) because we can take that last rectangle in the first row later. In other words, when we are in the state dp[i][j] where i < j, it's enough to consider taking a rectangle in the first row or just increasing i without taking anything.

Code: 25627911.

771F - Bear and Isomorphic PointsIf p1 is collinear with some two other points, we should print 0. Now let's assume that no two points are collinear with p1.

The naive solution is to iterate over O(n2) pairs of points. For each pair of points there is a line going through them both, and we know that the new placement of p1 should be on the same side (e.g. on the left) from the line - otherwise the sign of the cross product will change. In other words, the new placement must belong to some halfplane. What we're looking for is the intersection of those O(n2) halfplanes, what can be found in . We should also remember that the new placement must be inside the big square, what can be achieved by adding four halfplanes (each for one side of the square).

It turns out that it's quite easy to improve the complexity of the naive solution. Let's first sort other n - 1 points by angle. One way to approach the problem is to think "we are interested in those new placements that don't affect the sorting of those n - 1 points" - this is almost enough to get the intended solution. If sorted (in the clockwise order) points are p2, p3, ..., pn, taking into account a halfplane that goes through points pi and pi + 1 ensures that pi + 1 is further in the clockwise order than pi (i.e. it is more "on the right" if we look from p1). Usually, pi + 2 is also more "on the right" than pi, and so on, till some point pj that is no longer "on the left" from pi (if we look from p1). For each i, let's find the first j that pj is "on the left" from pi (move indices i and j with two pointers) and then consider a halfplane that goes through pi and pj. To sum up, we consider n halfplanes determined by pairs (pi, pi + 1) and n halfplanes determined by pairs (pi, pj) where pi and pj are almost opposite to each other, with respect to p1. It turns out that this is already a working solution - no other halfplanes are needed. The answer is the intersection of found O(n) halfplanes. Let's prove the correctness.

Let's assume that one of halfplanes (going through some pa and pb) wasn't considered, while it should be because it would affect the answer. And let's say that pb is more "on the right" than pa, and a < b. If |a - b| = 1, we surely considered that halfplane. Otherwise, if there is some other point with index  such that it is on the proper side of the line (pa, pb), i.e. on the same side as p1, halfplanes determined by pairs (a, m) and (m, b) completely cover that (a, b) halfplane. Here we must use induction: if each halfplane determined by a pair (a, b) for smaller value of b - a is either taken or covered by some other taken halfplanes, then also halfplanes with greater differences b - a will be considered (remember that we assumed that there is some other points with index  such that ...).

The case analysed above is shown on the drawing below. Let R denote the red point. If halfplanes (pa, R) and (R, pb) are considered (or from induction they are covered by something else), we don't need considering (pa, pb).

What remains is the case when a + 1 ≠ b and each point with index in [a + 1, b - 1] is on the line (pa, pb) or on the wrong side (not the same as p1). It quite easily implies that our line is already covered everywhere except for the segment (pa, pb), see the drawing:

Now we should take a look at points pb + 1, pb + 2, .... If one of them pk is on the wrong side of the line (pa, pb) (i.e. on the side different than p1), the halfplane (pk - 1, pk) covers our segment (pa, pb) and we are done. Otherwise, all those points are on the proper side (the same as p1). Eventually one of them will be the last one that is "on the right" from pa and let's remember that we consider halfplanes determined by such pairs (earlier denoted as pi and pj). Since that point is on the proper side of the line (pa, pb), the segment is covered:

Code: 25627924.

Codeforces Round #404. Editorial.

By gepardo, history, 6 years ago, translation, In EnglishThis is an editorial for the problems of the today's contest. I tried my best to describe the solutions for the problems as detailed as possible, but if something is not understandable for you, you can write in comments! :)

785A - Anton and Polyhedrons

HintTutorial785A - Anton and PolyhedronsI think there's nothing to explain in this problem. Just check the polyhedron type, determine its number of faces and sum these numbers.

Time complexity is .

C++ codeJava codePython code785B - Anton and Classes

HintTutorial785B - Anton and ClassesAt first, let's determine what classes Anton will attend first — chess classes or programming classes.

Consider the case when Anton attends chess classes first and then attends programming classes. It's not hard to observe that in this case it's better to take the chess classes variant in which the right range is as more to the left as possible. Also, we take the programming classes variant in which the left range is as more to the right as possible. Because chess classes must be earlier than programming classes, the distance between them can be calculated as the distance between these two points (the right range of chess classes and the left range of programming classes). But if the right chess classes point will be later than the left programming classes point, it means that our condition (chess is earlier than programming) is false or the periods intersect. So in this case we take 0 instead of the distance.

The second case is considered in the same way. It's obvious that the answer will be the maximum of these two cases.

Time complexity is .

C++ codeJava codePython code785C - Anton and Fairy Tale

This problem had weak pretests. It was made intentionally to cause more hacks. And I have warned you about it in the announcement :)

HintTutorial785C - Anton and Fairy TaleAt first, let's make the following assumption: if a sparrow cannot eat a grain because the barn is empty, the number of grains in the barn becomes negative. It's easy to see that the answer doesn't change because of this.

Now, let's observe the number of grains before sparrows come. At first, the barn remains full for m + 1 days (because sparrows eat less grains than it's added to the barn). Then the number of grains is decreased by one, by two and so on. So, on the m + 1 + i-th day there are  grains in the barn before sparrows come (remember that for any positive integer x the equality  is always true).

How can we determine if the barn is empty? It's reasonable that if there are q grains on the k-th day after grain is brought, then at the end of the k - 1-th day there are q - m grains in the barn. So, if on the k - 1-th day the barn becomes empty (q - m ≤ 0), then there must be q ≤ m grains on the k-th day after grain is brought.

So, we must find such minimal day m + 1 + k, in which there are m or less grains after grain is brought. That is, using the formula above, we must find such minimal k that



It can be easily done using binary search. It's not hard to observe that the answer in this case is m + k (if in the m + 1 + k-th day before sparrows come there are less or equal than m grains, then in the m + 1 + k - 1 = m + k-th day the barn is empty).

The corner case in this problem is m ≥ n. In this case the barn becomes full every day and it becomes empty only in the n-th day when sparrows eat all the grain.

Also notice that k can be found using a formula, but such solutions could fail by accuracy, because the formula is using the square root function.

Time complexity is .

C++ codeJava codePython code785D - Anton and School - 2

HintTutorial785D - Anton and School - 2At first, let's simplify the problem: let our string consists of x + y characters, begins with x characters "(" and ends with y characters ")". How to find the number of RSBS in such string?

Let's prove that this number is equal to . It's easy to observe that this formula also means the number of ways to match the string with the sequence of zeros and ones of the same length, which contains exactly x ones. Now prove that for every such sequence of zeros and ones we can find an RSBS subsequence. How can we do it? Let's consider it on the example of the following string:

Let's include to our subsequence all the opening brackets that match zeros and all the closing brackets that match ones. In our example, we include brackets number 1, 3, 5 and 6, so we get the subsequence "(())", which is an RSBS.

Why every sequence we got in this way is an RSBS? Let the number of ones that match closing brackets is equal to z. So x - z ones match opening brackets (because we have x ones, as we remember) and, therefore, z zeros match opening brackets. So the number of opening brackets is equal to the number of closing brackets in our subsequence. Also opening brackets appear earlier than closing brackers. So such subsequence is always an RSBS, and the statement above is proved.

Now we must understand how to solve the entire problem. Let's iterate over an opening bracket that is the last opening bracket in our subsequence. Now observe that only opening brackets may come before this bracket, and only closing brackets may come after this bracket. The rest of the brackets will definitely not appear in the subsequence. Let's count the number of opening brackets before the iterated one, incluing the iterated one (let this number is equal to x), and also the number of closing brackets after the iterated one (let this number is equal to y). To calculate these numbers, we can precalc them for all the positions in  using prefix sums.

Now, we have reduced our problem to the already solved, because we have x opening brackets and then y closing brackets. But we also have an additional condition: we must necessarily take the last opening bracket. So the answer is equal to , not , because on the position with the last opening bracket we must put a zero. So we must put x ones on x + y - 1 positions instead of x + y positions.

Time complexity is  (logarithm is to divide by modulo, that is necessary to calculate the number of combinations).

C++ codeJava code785E - Anton and Permutation

I'm sorry that this problem was not original. I will try my best to prevent this from happening again.

If you have TL or ML in this problem, don't think that the time/memory limits are too strict. The model solution works in 1.2 seconds and consumes 9 MB memory.

HintTutorial785E - Anton and PermutationAt first observe that there is 0 inversions in the initial permutation.

Let's divide our queries in  blocks. Now learn how to answer all the queries in one block in .

At first, let's divide our positions in the permutation in fixed and mobile positions. Mobile positions are all the positions that are changed in the current block. Fixed positions are the rest of the positions. Observe that the number of mobile positions is not more than .

Now all the inversions are divided into three types:

Inversions only between fixed positions;Inversions only between mobile positions;Inversions between fixed and mobile positions.To keep inversions of the first type is the easiest of all: their number doesn't change. So we can precalcualte them in the beginning of the block. How can we do it? Let's remember the answer for the query that was directly before the beginning of the block (if the block starts with the first query, this number is equal to 0). This number is equal to the total number of inversions in the beginning of the block. To get the number of fixed inversions, we can just subtract from this number the number of inversions of the second and the third types.

It's also easy to calculate the number of inversions of the second type. In the beginning their number can be counted even using a naive algorithm in . How to keep this number? We can recalculate each time not all the inversions but only these ones that contain changed elements. Totally we can count them in  for a block.

It's a little bit harder to keep inversions of the third type. To count them we'll use the similar approach as with inversions of the second type. We'll also recount the number of inversions only for changed elements. So, we must learn how to count the number of inversions between fixed elements and some mobile element on the position x. What fixed elements make an inversion with it? It's obvious that these are the elements which are earlier than the x-th and wherein bigger than it (denote this query countLower(x, px)) or elements which are later than the x-th and wherein smaller than it (denote this query countUpper(x, px)). Here px denotes the x-th element of permutation. Observe that there are  such queries.

How can we calculate the answers for these queries quickly? At first note that we can count them offline, because fixed elements doesn't change and mobile elements are not counted in these queries. Consider how we can count answers for countLower(x, y) (for countUpper(x, y) we can use the same approach). Let's sort all the countLower queries by non-decreasing x. Now if we have some structure that can add a value to an element and count a sum on a segment, we can easily do it. Let we added the fixed elements that stay earlier than x (it can be easily done because all the queries are sorted by non-decreasing x). So the answer is the sum on the segment (y + 1, n).

What data structure can we use? We can use sqrt-decomposition, because it takes  for adding and  for sum query. Totally all the  countLower and countUpper queries in a block are processed in .

Time complexity is .

There also exists an  solution. You can find it by yourself as an exercise. Such solution should be written carefully, otherwise it doesn't fit to the time limit or memory limit.

C++ codeJava codeAlternative solution from Vladik:

C++ codeAlternative solution from netman:

Java code

Technocup 2017 Finals and Codeforces Round #403 Editorial

By Endagorion, history, 6 years ago, translation, In English782A - Andryusha and SocksThis is a simple implementation problem. Store an array for whether a sock of each type is currently on the table, along with the total number of socks, and the largest number encountered. It is now easy to process socks one by one and maintain everything.

Complexity: O(n) time and memory.

782B - The Meeting Place Cannot Be ChangedWe will apply binary search to solve this problem. Inside the binary search we have to check if it is possible to meet within t seconds. In this time, i-th friend can get anywhere within the segment [xi - tvi, xi + tvi]. For the meeting to be possible, there must be a point common to all these segments, that is, their intersection must be non-empty.

An easy way to intersect a number of segments [l1, r1], ..., [ln, rn] is to compute L = max li and R = min ri. If L ≤ R, then [L, R] is the intersection, otherwise, the intersection is empty.

Complexity:  time and O(n) memory. Here ε is the required relative precision.

781A - Andryusha and Colored BalloonsIf v is a vertex of degree d, then the answer is at least d + 1. Indeed, any two neighbours of v can be connected by a path of length three via vertex v. Also, v lies on a common three-vertex path with any of its neighbours (possibly using a non-neighbour vertex). It follows that v and all of its neighbours must have pairwise distinct colors.

Let us show that the strongest of these estimates is best possible, that is, construct a coloring with D + 1 colors, where D is the maximal degree. Root the tree at arbitrary vertex, and color the root with color 1, also color its children with subsequent colors. All the rest vertices will be colored as follows: if a vertex v is colored x, and its parent is colored y, then for the children of v we will use numbers starting from 1 skipping x and y. One can check that no color with number larger than D + 1 shall be used. Implementation-wise, this is a simple DFS procedure.

Complexity: O(n) time and memory.

781B - Innokenty and a Football LeagueLet us write ai and bi for first and second options for i-th club name.

If all ai are distinct, we can assign all of them to be club names without conflict. Otherwise, suppose that for clubs i, j we have ai = aj, hence we can't use them simultaneously. Note that, say, choosing ai and bj is also forbidden by the statement. It follows that we must use bi and bj as i-th and j-th club names respectively.

If for some other club k we now have ak = bi, then we are forced to use bk as its name as well. We can process this kind of chain conflicts with a BFS-like procedure. If at any point we are forced to use the same name for two different clubs, then the answer is NO. Otherwise, resolving all conflicts will yield a correct assignment.

Complexity: O(n) memory and time if implemented carefully (not necessary though).

781C - Underground LabLet's start a DFS at any vertex of the graph, and produce an Euler tour — the order of vertices visited by a DFS, where each vertex v is written down every time DFS visits it (in particular, when a recursive call made from v terminates). Note that the Euler tour has exactly 2n - 1 entries in it, hence it would be a correct answer for k = 1. For a general k, cut the Euler tour into k consecutive pieces of size at most ⌈ 2n / k⌉, and yield it as an answer. Note that each path of the answer has to contain at least one vertex.

Complexity: O(n + m) time and memory.

781D - Axel and Marston in BitlandLet us write Ai for the binary string obtained after i inverse-append steps, for example, A0 = 0, A1 = 01, and so on. Let us also write . By definition we must have , and .

Let us store matrices Pk and Qk, with entries Pk / Qk(v, u) equal to 1 for pairs of vertices v, u such that there is a Ak/Bk-path from v to u. Note that P0 and Q0 are exactly the adjacency matrices with 0- and 1-arcs respectively.

Next, note that Pk + 1(v, u) = 1 if and only if there is a vertex w such that Pk(v, w) = Qk(w, u) = 1, and a similar condition can be written for Qk + 1(v, u). It follows that Pk + 1 and Qk + 1 can be computed using Pk and Qk in O(n3) time (the method is basically boolean matrix multiplication: , ).

To use the matrices Pk and Qk to find the answer, let us store L — the largest answer found, and S — the set of vertices reachable from the vertex 1 in exactly L steps. Let's process k by decreasing from a certain value k0, and see if L can be increased by 2k. The next 2k characters after L-th position will form the string Ak or Bk depending on the popcount parity of L. Let's denote S' the set of vertices reachable from S following Ak / Bk. If S' is non-empty, we can increase L by 2k, and assign S = S', otherwise, we don't change anything. In the end, L will be the maximal path length as long as it at less than 2k0.

Note that we can take k0 = 60 since we don't care about exact value of answer if it is greater than 260. This results in an O(k0n3) solution, which is too slow. However, optimizing boolean multiplication with bitsets cuts the working time  times, and the solution is now fast enough.

Complexity:  time, and  memory. Here , and w = 64 is the word length in bits.

781E - Andryusha and Nervous BarriersSolution 1: Let us move a sweep-line from the bottom to the top, and say that i-th barrier is active if the current y-coordinate satisfies ui ≤ y ≤ ui + si. If we want to find the result of dropping a ball in column x at a certain moment, we have to find the highest active barrier that covers x at the moment.

Let us store a segment tree, with a set of active segments in each tree node. When introducing a new active segment, we represent it as a union of  tree nodes, and add this segment in each of these nodes' set; when a segment becomes non-active, we delete these entries. If at any point we are interested in finding the highest active barrier for a column x, we consider all  tree nodes covering x and look at their highest entries only. Also, for each segment we store the number of resulting balls after hitting this segment; this number can be found by making two queries to the tree (for the two balls resulting from the collision) at the same time we activate the barrier.

To find the final answer, for each column drop a ball in it from height h + 1 and sum the results. Thus, the answer can be found in  time (with the second logarithm for std::set working time).

Solution 2: Let us go from the top to the bottom instead, and maintain positions of all balls to be dropped. If any of these balls occupy the same position, we group them together and store the size of the group. Each column will have a separate stack of groups, with lower groups on top of the stack.

Let's see how a new barrier [l, r] changes our configuration. For each column [l, r] we want to drop several lowest groups on the barrier, which will result in creating at most two new groups next to the barrier. Let us store a segment tree of size w, with x-th entry equal to the height of the lowest group in column x. While [l, r] range minimum in the segment tree is low enough, we pop the lowest group from the corresponding stack (and update the segment tree accordingly). Finally, we create the new groups, and push them to their respective stacks. After processing all barriers, the rest groups will fall straight to the bottom.

A standard amortized estimate shows that O(n + w) operations will be performed, for  time complexity.

781F - Intranet of BusesLet us do a binary search on the answer. Inside it, we have to check if at any time moment bus pairs 1 and 2, 2 and 3, ..., n and 1 are within distance x of each other simultaneously.

Let p(t) be the location of the bus 1 (that departed at time 0) at time t. Let us call a time moment t good, if we have ||p(t + T / m) - p(t)|| ≤ x, with ||a - b|| equal to the distance between points a and b. If there is a moment t such that t, t + T / m, ..., t + (m - 1)T / m are all good, then the answer is at least x.

We can build the two-dimensional graph (as in "function graph", not "graph with vertices and edges") of p(t + T / m) - p(t) over time by keeping track of segments where points p(t) and p(t + T / m) are. When the points are bounded to a pair of sides, the vector p(t + T / m) - p(t) changes linearly in time. There are O(n) time moments when either point switches from side to side, hence the difference graph can be constructed in O(n) time with the two pointers approach.

Now, for a certain x let's find the set of good moments t. We will do this separately for each segment of the difference graph, and then paste the answers. We have the condition ||q|| ≤ x, where q ranges over a segment. This is the segment-circle intersection problem, which is a standard geometrical primitive, with various approaches from solving quadratic equations to rotating a certain vector by an angle. In any case, the result will be a time range or an empty set. Note that q may stay still for a certain time range of the graph, which should be treated separately.

To ensure that p(t), p(t + T / m), and so on are all good for certain t, let us "cut" the segment [0, T] into m equal parts and superimpose them, with "good" segments possibly being cut into parts, now overlapping each other. A suitable moment t is now a point that is covered m times. Finding such point is a simple scan-line application.

Complexity: , where ε is the required relative precision.

Codeforces Round #402, Editorial

By niyaznigmatul, 6 years ago, translation, In English779A - Pupils RedistributionProblem setter: MikeMirzayanov

To solve this problem let's use array cnt[]. We need to iterate through first array with academic performances and for current performance x let's increase cnt[x] on one. In the same way we need to iterate through the second array and decrease cnt[x] on one.

If after that at least one element of array cnt[] is odd the answer is  - 1 (it means that there are odd number of student with such performance and it is impossible to divide them in two. If all elements are even the answer is the sum of absolute values of array cnt divided by 2. In the end we need to divide the answer on 2 because each change will be counted twice with this way of finding the answer.

779B - Weird RoundingProblem setter: MikeMirzayanov

To solve this problem we need to make k zeroes in the end of number n. Let's look on the given number as on the string and iterate through it beginning from the end (i.e. from the low order digit). Let cnt equals to the number of digits which we reviewed. If the current digit does not equal to zero we need to increase the answer on one. If cnt became equal to k and we reviewed not all digits we need to print the answer.

In the other case we need to remove from the string all digits except one, which equals to zero (if there are more than one such digit we left only one of them). Such digit always exists because the problem statement guaranteed that the answer exists.

779C - Dishonest SellersProblem setters: MikeMirzayanov and fcspartakm

To solve this problem we need at first to sort all items in increasing order of values ai - bi. Then let's iterate through sorted array. If for the current item x we did not buy k items now and if after discounts it will cost not more than now, we need to buy it now and pay ax, in the other case we need to buy item x after discounts and pay bx.

778A - String GameProblem setter: FireZi

In this problem we have to find the last moment of time, when t has p as a subsequence.

If at some moment of time p is a subsequence of t then at any moment before, p is also its subsequence. That's why the solution is binary search for the number of moves, Nastya makes. For binary search for a moment of time m we need to check, if p is a subsequence of t. We remove a1, a2, ... am and check if p is a subsequence greedily.

778B - Bitwise FormulaProblem setter: burakov28

Note that changing i-th bit of chosen number doesn't change any bits of any of the variables other than i-th one. Also note that the total number of values is greater, as more variables have 1 at i-th position.

Let's solve for every bit independently: learn, what is the value of i-th bit of chosen number. We can try both values and simulate the given program. Choose one of the values that makes more variables to have 1 at i-th position. If both 0 and 1 give equal number of variables to have 1 at i-th position, choose 0.

778C - Peterson PolyglotProblem setters: niyaznigmatul and YakutovDmitriy

While erasing letters on position p, trie changes like the following: all the edges from one fixed vertex of depth p are merging into one. You can see it on the picture in the sample explanation. After merging of the subtrees we have the only tree — union of subtrees as the result.

Consider the following algorithm. For every vertex v iterate over all the subtrees of v's children except for the children having largest subtree. There is an interesting fact: this algorithm works in  in total.

Denote as sx the size of the subtree rooted at vertex x. Let hv be the v's child with the largest subtree, i.e. su ≤ shv for every u — children of v. If u is a child of v and u ≠ hv then . Let's prove that.

Let . Then  and .Otherwise, if , then we know that su + shv < sv. Therefore, .Consider vertex w and look at the moments of time when we have iterated over it. Let's go up through the ancestors of w. Every time we iterate over w the size of the current subtree becomes twice greater. Therefore we could't iterate over w more than  times in total. It proves that time complexity of this algorithm is .

Solution:

Iterate over all integers p up to the depth of the trieFor every vertex v of depth pUnite all the subtrees of v with running over all of them except for the largest one.How to unite subtrees? First method. Find the largest subtree: it has been already built. Try to add another subtree in the following way. Let's run over smaller subtree's vertices and add new vertices into respective places of larger subtree. As the result we will have the union of the subtrees of v's children. All we need from this union is it's size. After that we need to roll it back. Let's remember all the memory cells, which were changed while merging trees, and their old values. After merging we can restore it's old values in reverse order.

Is it possible to implement merging without rolling back? Second method. Let's take all the subtrees except for the largest one and build their union using new memory. After that we should have two subtrees: the largest one and the union of the rest. We can find size of their union without any changes. Everything we need is to run over one of these trees examining another tree for the existence of respective vertices. After this we can reuse the memory we have used for building new tree.

778D - Parquet Re-layingProblem setter: pashka

Let's assume that the width of the rectangle is even (if not, flip the rectangle). Convert both start and final configurations into the configuration where all tiles lie horizontally. After that, since all the moves are reversible, simply reverse the sequence of moves for the final configuration.

 

How to obtain a configuration in which all tiles lie horizontally. Let's go from top to bottom, left to right, and put all the tiles in the correct position. If the tile lie vertically, then try to turn it into the correct position. If it cannot be rotated, because the neighboring tile is oriented differently, proceed recursively to it. Thus, you get a "ladder", which can not go further than n tiles down. At the end of the ladder there will be two tiles, oriented the same way. Making operations from the bottom up, we'll put the top tile in a horizontal position.

 

778E - Selling NumbersProblem setters: niyaznigmatul and VArtem

Because the target value for this problem is calculated independently for all digits, we'll use the dynamic programming approach. Define dpk, C as the maximum possible cost of digits after we processed k least significant digits in A and C is the set of numbers having the carry in current digit. This information is sufficient to choose the digit in the current position in A and recalculate the C set and DP value for the next digit.

The key observation is that there are only n + 1 possible sets instead of 2n. Consider last k digits of A and Bi. Sort all the length-k suffixes of Bi in descending lexicographical order. Because all these suffixes will be increased by the same value, the property of having the carry is monotone. That means that all possible sets C are the prefixes of length m (0 ≤ m ≤ n) of this sorted list of suffixes. This fact allows us to reduce the number of DP states to O(n·|A|). Sorting all suffixes of Bi can be accomplished using the radix sort, appending the digits to the left and recalculating the order.

The only thing that's left is to make all DP transitions in O(1) time. To do that, maintain the total cost of all digits and the amount of numbers that have the carry. After adding one more number with carry in current digit, these two values can be easily recalculated. After processing all digits in A, we have to handle the remaining digits in Bi (if there are any) and take the best answer. Total running time is .

Problem analysis of Codeforces Round #401 (Div. 2)

By GlebsHP, history, 6 years ago, In English777A - Shell GameFix the initial numeration of shells. Consider function p(i, j) to be the index of the shell located at position j after i moves.

p(0) = {0, 1, 2}p(1) = {1, 0, 2}p(2) = {1, 2, 0}p(3) = {2, 1, 0}p(4) = {2, 0, 1}p(5) = {0, 2, 1}p(6) = {0, 1, 2}Thus, after 6 movements all shells will get back to initial positions. To solve the problem we need to take n modulo 6 and simulate that number of moves.

777B - Game of Credit CardsFirst we want to consider a strategy that minimizes the amount of flicks Moriarty will receive from Sherlock. This is similar to loosing as few rounds as possible. He can use digit 0 can be used to not loose against digit 0, digit 1 to not loose against digits 0 and 1 and so on. Thus, Moriarty should try all digits from 0 to 9 and greedily apply them to Sherlock's digits they can beat. If the maximum number of rounds Moriarty can not loose is a the answer for the first question is n - a.

For the second question we need to count the maximum number of rounds Moriarty can win. Now digit 0 is useless, digit 1 wins against digit 0, digit 2 wins against digits 0 and 1, and so on. Thus, Moriarty should consider his digits from 0 to 9 and greedily use them to digits they can beat.

777C - Alyona and SpreadsheetFor each cell (i, j) compute value up(i, j) equal to maximum r, such that table is non-decreasing in row j if we keep only rows from i to r inclusive. This values can be computed in O(nm) time using the following formulas:

up(i, j) = up(i + 1, j) + 1, if i < n and ai, j < ai + 1, j;up(i, j) = 1 otherwise.To process the query (li, ri) we have to check whether there exists k such that up(li, k) ≥ ri. We will answer this questions using by precomputing maximum values in each row .

777D - Cloud of HashtagsIt is possible to solve this problem in many ways. One of them was to iterate over all strings in reversed order and to try to leave the longest possible prefix of each string greedily without breaking the statement.

Let's prove this solution formally. Note that the set of possible lengths of some string si in a correct answer forms a segment between 1 and some critical length li. Indeed, if there exists a correct answer with i-string having a length of x ≥ 2, then there also exists an answer with i-th string having a length of x - 1, since it is possible to leave only the first symbol of all previous strings and make the answer correct.

Let's express li through li + 1. Reduce the length of (i + 1)-st string to li + 1 and consider two options. First, si may be lexicographically not greater than si + 1, and in this case we may obviously let li be equal to |si|. Otherwise, li can't be larger than lcp(si, si + 1) where lcp deontes the length of the longest common prefix of two strings (if we keep si longer, it will be larger than any possible prefix of si + 1). At the same time, if we reduce si up to lcp(si, si + 1), it will be correct. So, we may let li be equal to lcp(si, si + 1).

Note that due to the way we defined li, if we just reduce any string up to its maximum possible length, it will also be a correct answer. So, it is also a correct answer to the original problem.

777E - Hanoi FactoryTo start with make the following observation: if two rings i and j have equal outer radiuses bi = bj they can be merged in one ring of the same outer radius, inner radius equal to min(ai, aj) and height equal to hi + hj.

Using the observation we transform our problem to the one with distinct outer radiuses. Sort ring by this radius in descending order. From this point we consider bi < bj for all i > j. For each ring we want to compute value ans(i) — maximum height of the tower that ends with the ring i. This dynamic programming can be computed in O(n2) time using the following formula: .

There are two different ways to speed up the calculation of this dp:

Keep rings sorted by inner radius in a separate array. For each ring j < i store its value of ans(j) there and 0 for others. To get max ans(j) we have to query maximum on some suffix of this array: from the one hand only rings with original index j < i will be non-zero, from the other hand this will suffice the condition bi > aj. This can be done using segment tree or binary indexed tree.Note that if i < j < k and it's possible to place ring k on ring j and ring k on ring i, then it's possible to place ring j on ring i. Indeed, from ai < bk and bk < bj follows ai < bj. That means we only need to compute for each i maximum value j such that aj < bi. This can be done using data structures listed above or just with a single pass over array with a stack. Go from left to right and keep indexes of all valid positions in increasing order. Pop elements while they do not suffice condition aj < ai and then put i on the top. For clarifications, check the following code:

stack <int> opt;for (int i = 0; i < n; i++) {     while (!opt.empty() && r[opt.back()].inner >= r[i].outer)         opt.pop();     if (!opt.empty())         ans[i] = ans[opt.back()];     ans[i] += r[i].height;     opt.push(i);}




Codeforces Round #200 Tutorial

By gen, 9 years ago, translation, In English344A - MagnetsBy the definition each block consists of a number of consequent and equally oriented dominoes. That means that in places where adjacent dominoes are not oriented equally, one block ends and another block starts. So, if there are x such places, the answer is equal to x + 1.

Solution complexity: O(n). Problem author: gen.

Bonus: The problem was created a day before the contest and filled in the last part of a physically flavoured DivII complect. :]

344B - Simple MoleculesFirst solution. First, the sum a + b + c should be even, since each bond adds 2 to the sum. Now let x, y, z be the number of bonds between 1st and 2nd, 2nd and 3rd, 3rd and 1st atoms, accordingly. So we have to solve the system x + z = a, y + x = b, z + y = c. Now observe that the solution to the system is the length of the tangents on the triangle with sides of length a, b, c to its inscribed circle, and are equal to , , . If the problem asked only the possibility of building such a molecule, we could just check if there exists (possibly degenerate) triangle with sides a, b, c.

 

Second solution. Bruteforce all x values. For a fixed x values of y and z are defined uniquely: y = b - x, z = a - x.

Solution complexity: O(1) / O(n). Problem authors: gen, andreyv.

Bonus: Can you solve the problem for any vertex number n? When and how can such a graph be built?

343A - Rational ResistanceIf a fraction  can be obtained with k resistors, then it is simple to calculate that we can obtain fractions  and  with k + 1 resistors. So adding one resistor means performing one operation backwards in Euclidean algorithm. That means that the answer is equal to the number of steps in standard Euclidean algorithm.

Solution complexity: . Problem authors: gen, andreyv.

Бонус: At first we thought about the major problem (any two elements can be joined), but had a moment of eureka and got that the given problem unexpectedly naturally can be reduced to GCD. By the way, the result tree — http://en.wikipedia.org/wiki/Calkin%E2%80%93Wilf_tree.

343B - Alternating CurrentLet us solve the following problem first: we are given a string of symbols A and B. If the i-th symbol is A, then at the i-th step the upper wire (see figure) is being put over the lower wire. If the i-th symbol is B, the lower wire is being put over the upper wire at i-th step. Observe that if some two symbols A and B are adjacent, we can untangle this place, throw the symbols out and obtain the string of length two symbols less. So the wires can be untangled iff the number of A's and B's in the string is the same. The given problem can be reduced to the described in a following fashion: in each odd position we change – to B and + to A. In each even position we change — to A and + to B. The reduction is correct, since on each even position the order of — and + are always swapped, and in each odd position their order is the same as in the beginning.

Solution complexity: O(n). Problem authors: gen, andreyv.

Bonus: If you are interested by this problem, you can learn about the braid theory http://en.wikipedia.org/wiki/Braid_theory :] Fun fact: a harder version of this problem was planned already for Round #142, but the error in solution idea was found, and the problem was left to lay for almost a year.

343C - Read TimeLet's search the answer t with the binary search. Fix some value of t. Look at the first head from the left h[i] that can read track p[0]. If p[0] > h[i], then h[i] goes to the right t seconds and reads all tracks on its way. Otherwise if p[0] ≤ h[i], then the head has two choices:

go to the right  seconds, then  to the left and h[i] - p[0] again to the left;go to the left h[i] - p[0] seconds, then h[i] - p[0] to the right and t - 2·(h[i] - p[0]) again to the right.Obviously, for h[i] it is more advantageous to visit the track positioned as much as possible to the right. So we choose by . Then we move the pointer onto the first unread track, and repeat the algorithm for h[i + 1], and so on with each head.

Solution complexity: . Problem authors: gen, gorbunov.

Bonus: The problem is completely real, if the disk has only a single head, if we know, what tracks should be read; then the optimal algorithm chooses between the two choices described above. I and gorbunov were listening this on a lecture, and created the given problem out of boredom ;]

343D - Water TreeLet's learn how to color a whole subtree. For that enumerate all vertices in post-order DFS. Then each subtree covers a single continious vertex number segment. For each vertex we store the bounds of such segment for a subtree with a root in this vertex. Then to color a subtree means to color a segment in a segment tree.

Then create a segment tree that has a following property: if a vertex v was emptied, and is still empty, then this vertex is colored in the segment tree. In the beginning "empty" all the vertices. That is, color all the vertices in the segment tree. With this tree we can efficiently process the queries:

Fill a vertex v. Clean the interval for the subtree of v. If before that some vertex of a subtree was empty, color the parent of v.

Empty a vertex v. Color the vertex v in the segment tree.

Reply whether a vertex v is filled. If in the segment tree at least one vertex is colored, then there is such a descendant of v that is empty now, so the vertex v is not filled.

Shtrix noted that essentially the same solution can be implemented with only a single set.

Solution complexity: . Problem author: gen.

Bonus: Some participants could see the similarities with a problem Ball Machine from BOI 2013, but the solutions to the both problems are quite different.

343E - Pumping StationsIn this problem we are asked to find such graph vertex permutation that maximizes the sum of the maximum flows sent between each two consequtive vertices in the permutation.

The problem can be solved with Gomory-Hu tree data structure. For a given weighted graph the tree has the following properties:

The vertex set of the tree and the graph is the same.The maximum flow between vertices u and v in the tree is equal to the maximum flow in the graph.Surprisingly, such a tree exists for any weighted graph, and can be built in O(n·maxFlow). It appears that the answer to the problem is equal to the sum of the edge weights in this tree.

We prove this statement by induction on the number of the tree vertices. Pick the edge (u, v) with the smallest weight in the tree. Consider that in an optimal permutation more than one path between two adjacent verteces in the permutation passes through this edge. Erase all these paths, then each of the u and v subtrees holds a set of disjoint remaining paths from the permutation. For each set, join all the paths in one chain, obtaining two chains. These chains we join by a path s that goes trough the edge (u, v). Thus we have built a permutation that is not worse than the considered one. For a path s the edge (u, v) is the smallest, so the flow along this path is equal to the weight of this edge. It follows from the induction that in subtrees u and v the answer is equal to the sum of edges. By adding the weight of edge (u, v), we get the desired result.

From the last paragraph it is clear how to build such a permutation: take the smallest edge, obtain two chains from the vertex subtrees recursively, and add them together to form a one chain. Since there are not many vertices, we can do this part in O(n2).

Solution complexity: O(n·maxFlow). Problem authors: gen, Gerald.

Bonus: Shortly before the contest we decided to make the constraints more loyal, so some solution that find Gomory-Hu tree by finding flow O(n2) times also passed. We hope that nobody is particularly saddened by this fact. (;

Codeforces Round #199 (Div. 2) Editorial

By HolkinPV, 9 years ago, translation, In English342A - Xenia and Divisors

In this problem you should guess that exists only three valid groups of three

1) 1, 2, 4

2) 1, 2, 6

3) 1, 3, 6

(You can see that integers 5 and 7 are bad).

So, we will greedy take these groups of three. If some integers will be not used, the answer is -1. In other case, print found answer.

342B - Xenia and Spies

The problem is solved by greedy algorithm. We will pass the note only in correct direction. Also, if we can pass the note at the current moment of time, we do it. In other case, we will hold it and don't give it to neighbors (we can make this action at any moment of time). Obviously this algorithm is correct. You should only implement it carefully.

342C - Cupboard and Balloons

In the problem you should carefully get formula. The optimal solution put marbles by two in a row. And then put one marble upon others if it possible. The most difficulties were to deal with this last phase.

In comments to the post were given formulas how to put the last marble (exactly in the middle). And there was a good beautiful illustration, which describes the situation.

342D - Xenia and Dominoes

In the problem you can count number of correct puzzles or substract number of incorrect puzzles from number of all puzzles. In any case you should count DP, where the state is (j, mask) — j — number of the last full column, mask — mask of the last column. This problem is equivalent to the well known problem about domino tiling or the problem about parquet.

To get the solution of the whole problem I did the following. I try to attach one domino to each of 4 directions, then paint all three cells in black and count the number of correct puzzles. But in this case you will count some solutions several number of times. So you need to use inclusion exclusion formula for these 4 directions.

342E - Xenia and Tree

The problem can be solved in different ways. The most easy idea is sqrt-optimization. Split all queries into sqrt(m) blocks. Each block we will process separately. Before processing each block, we should calculate minimum distances from every node to the closest red node using bfs. To answer the query we should update this value by shortest distances to red nodes in current block.

The solution becomes simple. Every sqrt(m) queries we make simple bfs and for every node v WE calculate value d[v] — the shortest distance to some red node from node v. Then to answer the query of type 2 you should calculate min(d[v], dist(v, u)), where u — every red node, which becomes red in current block of length sqrt(m).

Distance between two nodes dist(u, v) can be got using preprocessing for lca.

Codeforces Round #198 — Editorial

By fchirica, 10 years ago, In English340A - СтенаYou are given a range [A, B]. You're asked to compute fast how many numbers in the range are divisible by both x and y. I'll present here an O(log(max(x, y)) solution. We made tests low so other not optimal solutions to pass as well. The solution refers to the original problem, where x, y ≤ 109.

Firstly, we can simplify the problem. Suppose we can calculate how many numbers are divisible in range [1, X] by both x and y. Can this solve our task? The answer is yes. All numbers in range [1, B] divisible by both numbers should be counted, except the numbers lower than A (1, 2, ..., A — 1). But, as you can see, numbers lower than A divisible by both numbers are actually numbers from range [1, A — 1]. So the answer of our task is f(B) — f(A — 1), where f(X) is how many numbers from 1, 2, ..., X are divisible by both x and y.

For calculate in O(log(max(x, y)) the f(X) we need some math. If you don't know about it, please read firstly about least common multiple. Now, what will be the lowest number divisible by both x and y. The answer is least common multiple of x and y. Let's note it by M. The sequence of the numbers divisible by both x and y is M, 2 * M, 3 * M and so on. As a proof, suppose a number z is divisible by both x and y, but it is not in the above sequence. If a number is divisible by both x and y, it will be divisible by M also. If a number is divisible by M, it will be in the above sequence. Hence, the only way a number to be divisible by both x and y is to be in sequence M, 2 * M, 3 * M, ...

The f(X) calculation reduces to finding the number of numbers from sequence M, 2 * M, 3 * M, ... lower or equal than X. It's obvious that if a number h * M is greater than X, so will be (h + 1) * M, (h + 2) * M and so on. We actually need to find the greatest integer number h such as h * M ≤ X. The numbers we're looking for will be 1 * M, 2 * M, ..., h * M (so their count will be h). The number h is actually [X / M], where [number] denotes the integer part of [number]. Take some examples on paper, you'll see why it's true.

The only thing not discussed is how to calculate the number M given 2 number x and y. You can use this formula M = x * y / gcd(x, y). For calculate gcd(x, y) you can use Euclid's algorithm. Its complexity is O(log(max(x, y)), so this is the running time for the entire algorithm.

Official solution: 4383403

340B - Четырехугольник с максимальной площадьюI want to apologize for not estimating the real difficulty of this task. It turns out that it was more complicated than we thought it might be. Let's start explanation.

Before reading this, you need to know what is signed area of a triangle (also called cross product or ccw function). Without it, this explanation will make no sense.

The first thing we note is that a quadrilateral self intersecting won't have maximum area. I'll show you this by an image made by my "talents" in Paint :) As you can see, if a quadrilateral self intersects, it can be transformed into one with greater area.

 

Each quadrilateral has 2 diagonals: connecting 1st and 3rd point and connecting 2nd and 4th point. A diagonal divides a plane into 2 subplanes. Suppose diagonal is AB. A point X can be in one of those two subplanes: that making cross product positive and that making cross product negative. A point is in "positive" subplane if ccw(X, A, B) > 0 and in "negative" subplane ccw(X, A, B) < 0. Note that according to the constraints of the task, ccw(X, A, B) will never be 0.

Let's make now the key observation of the task. We have a quadrilateral. Suppose AB is one of diagonals and C and D the other points from quadrilateral different by A and B. If the current quadrilateral could have maximal area, then one of points from C and D needs to be in "positive subplane" of AB and the other one in "negative subplane". What would happen if C and D will be in the same subplane of AB? The quadrilateral will self intersect. If it will self intersect, it won't have maximal area. "A picture is worth a thousand words" — this couldn't fit better in this case :) Note that the quadrilateral from the below image is A-C-B-D-A.

 

Out task reduces to fix a diagonal (this taking O(N ^ 2) time) and then choose one point from the positive and the negative subplane of the diagonal. I'll say here how to choose the point from the positive subplane. That from negative subplane can be chosen identically. The diagonal and 3rd point chosen form a triangle. As we want quadrilateral to have maximal area, we need to choose 3rd point such as triangle makes the maximal area. As the positive and negative subplanes are disjoint, the choosing 3rd point from each of them can be made independently. Hence we get O(N ^ 3) complexity. A tricky case is when you choose a diagonal but one of the subplanes is empty. In this case you have to disregard the diagonal and move to the next one.

Official solution: 4383413

340C - Про туристаDespite this is a math task, the only math formula we'll use is that number of permutations with n elements is n!. From this one, we can deduce the whole task.

The average formula is sum_of_all_routes / number_of_routes. As each route is a permutation with n elements, number_of_routes is n!. Next suppose you have a permutation of a: p1, p2, …, pn. The sum for it will be p1 + |p2 – p1| + … + |pn – pn-1|. The sum of routes will be the sum for each possible permutation.

We can calculate sum_of_all routes in two steps: first time we calculate sums like “p1” and then we calculate sums like “|p2 – p1| + … + |pn – pn-1|” for every existing permutation.

First step Each element of a1, a2, …, an can appear on the first position on the routes and needs to be added as much as it appears. Suppose I fixed an element X for the first position. I can fill positions 2, 3, .., n – 1 in (n – 1)! ways. Why? It is equivalent to permuting n – 1 elements (all elements except X). So sum_of_all = a1 * (n – 1)! + a2 * (n – 1)! + … * an * (n – 1)! = (n – 1)! * (a1 + a2 + … + an).

Second step For each permutation, for each position j between 1 and n – 1 we need to compute |pj — p(j + 1)|. Similarly to first step, we observe that only elements from a can appear on consecutive positions. We fix 2 indices i and j. We’re interested in how many permutations do ai appear before aj. We fix k such as on a permutation p, ai appears on position k and aj appears on a position k + 1. In how many ways can we fix this? n – 1 ways (1, 2, …, n – 1). What’s left? A sequence of (n – 2) elements which can be permuted independently. So the sum of second step is |ai - aj| * (n – 1) * (n – 2)!, for each i != j. If I note (a1 + a2 + … + an) by S1 and |ai - aj| for each i != j by S2, the answer is (N – 1)! * S1 + (N – 1)! * S2 / N!. By a simplification, the answer is (S1 + S2) / N.

The only problem remained is how to calculate S2. Simple iteration won’t enter in time limit. Let’s think different. For each element, I need to make sum of differences between it and all smaller elements in the array a. As well, I need to make sum of all different between bigger elements than it and it. I’ll focus on the first part. I sort increasing array a. Suppose I’m at position i. I know that (i – 1) elements are smaller than ai. The difference is simply (i — 1) * ai — sum_of_elements_before_position_i. Sum of elements before position i can be computed when iterating i. Let’s call the obtained sum Sleft. I need to calculate now sum of all differences between an element and bigger elements than it. This sum is equal to Sleft. As a proof, for an element ai, calculating the difference aj — ai when aj > ai is equivalent to calculating differences between aj and a smaller element of it (in this case ai). That’s why Sleft = Sright.

As a conclusion, the answer is (S1 + 2 * Sleft) / N. For make fraction irreducible, you can use Euclid's algorithm. The complexity of the presented algorithm is O(N * logN), necessary due of sorting. Sorting can be implemented by count sort as well, having a complexity of O(maximalValue), but this is not necessary.

Official solution: 4383420

340D - Граф сортировки пузырькомA good way to approach this problem is to notice that you can't build the graph. In worst case, the graph will be built in O(N2) complexity, which will time out. Also, notice that "maximal independent set" is a NP-Hard task, so even if you can build the graph you can't continue from there. So, the correct route to start is to think of graph's properties instead of building it. After sketching a little on the paper, you should find this property:

Lemma 1 Suppose we choose 2 indices i and j, such as i < j. We'll have an edge on the graph between vertices ai and aj if and only if ai > aj. We'll call that i and j form an inversion in the permutation.

Proof We assume we know the proof that bubble sort does sort correctly an array. To proof lemma 1, we need to show two things.

Every inversion will be swapped by bubble sort.For each i < j when ai < aj, bubble sort will NOT swap this elements.To proof 1, if bubble sort wouldn't swap an inversion, the sequence wouldn't be sorted. But we know that bubble sort always sorts a sequence, so all inversions will be swapped. Proofing 2 is trivial, just by looking at the code.

So far we've got how the graph G is constructed. Let's apply it in maximal independent set problem.

Lemma 2 A maximal independent set of graph G is a longest increasing sequence for permutation a.

Proof: Suppose we have a set of indices i1 < i2 < ... ik such as ai1, ai2, ..., aik form an independent set. Then, anyhow we'd choose d and e, there won't exist an edge between aid and aie. According to proof 1, this only happens when aid < aie. Hence, an independent set will be equivalent to an increasing sequence of permutation a. The maximal independent set is simply the maximal increasing sequence of permutation a.

The task reduces to find longest increasing sequence for permutation a. This is a classical problem which can be solved in O(N * logN). Here is an interesting discussion about how to do it.

340E - Яхуб и перестановкиIn this task, author's intended solution is an O(N ^ 2) dp. However, during testing Gerald fount a solution using principle of inclusion and exclusion. We've thought to keep both solutions. We're sorry if you say the problem was well-known, but for both me and the author of the task, it was first time we saw it.

Dynamic programming solution

After reading the sequence, we can find which elements are deleted. Suppose we have in a set D all deleted elements. I'll define from now on a "free position" a position which has -1 value, so it needs to be completed with a deleted element.

We observe that some elements from D can appear on all free positions of permutation without creating a fixed point. The other elements from D can appear in all free positions except one, that will create the fixed point. It's intuitive that those two "classes" don't influence in the same way the result, so they need to be treated separated.

So from here we can get the dp state. Let dp(n, k) = in how many ways can I fill (n + k) free positions, such as n elements from D can be placed anywhere in the free position and the other k elements can be placed in all free positions except one, which will create the fixed point. As we'll prove by the recurrences, we are not interested of the values from elements of D. Instead, we'll interested in their property: if they can(not) appear in all free positions.

If k = 0, the problem becomes straight-forward. The answer for dp(n, 0) will be n!, as each permutation of (n + 0) = n numbers is valid, because all numbers can appear on all free positions. We can also calculate dp(n, 1). This means we are not allowed to place an element in a position out of (n + 1) free positions. However, we can place it in the other n positions. From now we get n elements which can be placed anywhere in the n free positions left. Hence, dp(n, 1) = n! * n.

We want to calculate dp(n, k) now, k > 1. Our goal is to reduce the number k, until find something we know how to calculate. That is, when k becomes 0 or 1 problem is solved. Otherwise, we want to reduce the problem to a problem when k becomes 0 or 1. I have two cases. In a first case, I take a number from numbers which can be placed anywhere in order to reduce the numbers which can form fixed points. In the second case, I take a number from those which can form fixed points in order to make the same goal as in the first case. Let's analyze them.

Case 1. Suppose X is the first free position, such as in the set of k numbers there exist one which cannot be placed there (because it will make a fixed point). Obviously, this position exist, otherwise k = 0. Also obviously, this position will need to be completed with a term when having a solution. In this case, I complete position X with one of n numbers. This will make number equal to X from the k numbers set to become a number which can be placed anywhere. So I "loose" one number which can be placed anywhere, but I also "gain" one. As well, I loose one number which can form a fixed point.

Hence dp(n, k) += n * dp(n, k — 1).

Case 2. In this case position X will be completed with one number from the k numbers set. All numbers which can form fixed points can appear there, except number having value equal to X. So there are k — 1 of them. I choose an arbitrary number Y from those k — 1 to place on the position X. This time I "loose" two numbers which could form fixed points: X and Y. As well, I "gain" one number which can be placed anywhere: X.

Hence dp(n, k) += (k — 1) * dp(n + 1, k — 2).

TL;DR

dp[N][0]=N!

dp[N][1]=N*dp[N][0]

dp[N][K]=N*dp[N][K-1]+(K-1)*dp[N+1][K-2] for K>=2

This recurrences can be computed by classical dp or by memoization. I'll present DamianS's source, which used memoization. As you can see, it's very short and easy to implement. Link

Inclusion and exclusion principle

I'll present here an alternative to the dynamic programming solution. Let's calculate in tot the number of deleted numbers. Also, let's calculate in fixed the maximal number of fixed points a permutation can have. For calculate fixed, let's iterate with an index i each permutation position. We can have a fixed point on position i if element from position i was deleted (ai = -1) and element i does not exist in sequence a. With other words, element i was deleted and now I want to add it back on position i to obtain maximal number of fixed points.

We iterate now an index i from fixed to 0. Let sol[i] = the number of possible permutations having exactly i fixed points. Obviously, sol[0] is the answer to our problem. Let's introduce a combination  representing in how many ways I can choose k objects out of n. I have list of positions which can be transformed into fix points (they are fixed positions). I need to choose i of them. According to the above definition, I get sol[i] =  . Next, I have to fill tot - i positions with remained elements. We'll consider for this moment valid each permutation of not used values. So, sol[i] =  . Where is the problem to this formula?

The problem is that it's possible, when permuting (tot — i) remained elements to be added, one (or more) elements to form more (new) fixed points. But if somehow I can exclude (subtract) the wrong choices from sol[i], sol[i] will be calculated correctly. I iterate another index j from i + 1 to fixed. For each j, I'll calculate how many permutations I considered in sol[i] having i fixed points but actually they have j. I'll subtract from sol[i] this value calculated for each j. If I do this, obviously sol[i] will be calculated correctly.

Suppose we fixed a j. We know that exactly sol[j] permutations have j fixed points (as j > i, this value is calculated correctly). Suppose now I fix a permutation having j fixed points. For get the full result, I need to calculate for all sol[j] permutations. Happily, I can multiply result obtained for a single permutation with sol[j] and obtain the result for all permutations having j fixed points. So you have a permutation having j fixed points. The problem reduces to choosing i objects from a total of j. Why? Those i objects chosen are actually the positions considered in sol[i] to be ones having exactly i fixed points. But permutation has j fixed points. Quoting for above, "For each j, I'll calculate how many permutations I considered in sol[i] having i fixed points but actually they have j" . This is exactly what algorithm does.

To sum up in a "LaTeX" way, 

We can compute binomial coefficients using Pascal's triangle. Using inclusion and exclusion principle, we get O(N2). Please note that there exist an O(N) solution for this task, using inclusion and exclusion principle, but it's not necessary to get AC. I'll upload Gerald's source here.

341D - Яхуб и Xor'ыThe motivation of the problem is that x ^ x = 0. x ^ x ^ x… ^ x (even times) = 0

Update per range, query per element

When dealing with complicated problems, it's sometimes a good idea to try solving easier versions of them. Suppose you can query only one element each time (x0 = x1, y0 = y1).

To update a submatrix (x0, y0, x1, y1), I’ll do following operations. A[x0][y0] ^= val. A[x0][y1 + 1] ^= val. A[x1 + 1][y0] ^= val. A[x1 + 1][y1 + 1] ^= val.

To query about an element (X, Y), that element’s value will be the xor sum of submatrix A(1, 1, X, Y). Let’s take an example. I have a 6x6 matrix and I want to xor all elements from submatrix (2, 2, 3, 4) with a value. The below image should be explanatory how the method works:

 

Next, by (1, 1, X, Y) I’ll denote xor sum for this submatrix.

“White” cells are not influenced by (2, 2, 3, 4) matrix, as matrix (1, 1, X, Y) with (X, Y) a white cell will never intersect it. “Red” cells are from the submatrix, the ones that need to be xor-ed. Note that for a red cell, (1, 1, X, Y) will contain the value we need to xor (as it will contain (2, 2)). Next, “blue” cells. For this ones (1, 1, X, Y) will contain the value we xor with, despite they shouldn’t have it. This is why both (2, 5) and (4, 2) will be xor-ed again by that value, to cancel the xor of (2, 2). Now it’s okay, every “blue” cell do not contain the xor value in their (1, 1, X, Y). Finally, the “green” cells. These ones are intersection between the 2 blue rectangles. This means, in their (1, 1, X, Y) the value we xor with appears 3 times (this means it is contained 1 time). For cancel this, we xor (4, 5) with the value. Now for every green cell (1, 1, X, Y) contains 4 equal values, which cancel each other.

You need a data structure do to the following 2 operations:

Update an element (X, Y) (xor it with a value).Query about xor sum of (1, 1, X, Y).Both operations can be supported by a Fenwick tree 2D. If you don't know this data structure, learn it and come back to this problem after you do this.

Coming back to our problem

Now, instead of finding an element, I want xor sum of a submatrix. You can note that xor sum of (x0, y0, x1, y1) is (1, 1, x1, y1) ^ (1, 1, x0 – 1, y1) ^ (1, 1, x1, y0 – 1) ^ (1, 1, x0 – 1, y0 – 1). This is a classical problem, the answer is (1, 1, x1, y1) from which I exclude what is not in the matrix: (1, 1, x0 – 1, y1) and (1, 1, x1, y0 – 1). Right now I excluded (1, 1, x0 – 1, y0 – 1) 2 times, so I need to add it one more time.

How to get the xor sum of submatrix (1, 1, X, Y)? In brute force approach, I’d take all elements (x, y) with 1 <= x <= X and 1 <= y <= Y and xor their values. Recall the definition of the previous problem, each element (x, y) is the xor sum of A(1, 1, x, y). So the answer is xor sum of all xor sums of A(1, 1, x, y), with 1 <= x <= X and 1 <= y <= Y.

We can rewrite that long xor sum. A number A[x][y] appears in exactly (X – x + 1) * (Y – y + 1) terms of xor sum. If (X – x + 1) * (Y – y + 1) is odd, then the value A[x][y] should be xor-ed to the final result exactly once. If (X — x + 1) * (Y — y + 1) is even, it should be ignored.

Below, you'll find 4 pictures. They are matrixes with X lines and Y columns. Each picture represents a case: (X odd, Y odd) (X even, Y even) (X even Y odd) (X odd Y even). Can you observe a nice pattern? Elements colored represent those for which (X – x + 1) * (Y – y + 1) is odd.

       

Yep, that's right! There are 4 cases, diving the matrix into 4 disjoint areas. When having a query of form (1, 1, X, Y) you only need specific elements sharing same parity with X and Y. This method works in O(4 * logN * logN) for each operation and is the indented solution. We keep 4 Fenwick trees 2D. We made tests such as solutions having complexity greater than O(4 * logN * logN) per operation to fail.

Here is our official solution: 4383473

341E - Игра с конфетамиKey observation Suppose you have 3 boxes containing A, B, C candies (A, B, C all greater than 0). Then, there will be always possible to empty one of boxes using some moves.

Proof We can suppose that A <= B <= C. We need some moves such as the minimum from A, B, C will be zero. If we always keep the numbers in order A <= B <= C, it’s enough some moves such as A = 0. I’ll call this notation (A, B, C).

How can we prove that always exist such moves? We can use reductio ad absurdum to prove it. Let’s suppose, starting from (A, B, C) we can go to a state (A2, B2, C2). We suppose A2 (A2 > 0) is minimal from every state we can obtain. Since A2 is minimal number of coins that can be obtained and A2 is not zero, the statement is equivalent with we can’t empty one chest from configuration (A, B, C). Then, we can prove that from (A2, B2, C2) we can go to a state (A3, B3, C3), where A3 < A2. Obviously, this contradicts our assumption that A2 is minimal of every possible states. If A2 would be minimal, then there won’t be any series of moves to empty one chest. But A2 isn’t minimal, hence there always exist some moves to empty one chest.

Our algorithm so far:

void emptyOneBox(int A, int B, int C) {

if A is 0, then exit function.

Make some moves such as to find another state (A2, B2, C2) with A2 < A.

emptyOneBox (A2, B2, C2);

}

The only problem which needs to be proven now is: given a configuration (A, B, C) with A > 0, can we find another one (A2, B2, C2) such as A2 < A? The answer is always yes, below I’ll prove why.

Firstly, let’s imagine we want to constantly move candies into a box. It doesn't matter yet from where come the candies, what matters is candies arrive into the box. The box has initially X candies. After 1 move, it will have 2 * X candies. After 2 moves, it will have 2 * (2 * X) candies = 4 * X candies. Generally, after K moves, the box will contain 2^K * X candies.

We have A < B < C (if 2 numbers are equal, we can make a move and empty 1 box). If we divide B by A, we get from math that B = A * q + r. (obviously, always r < A). What if we can move exactly A * q candies from B to A? Then, our new state would be (r, B2, C2). We have now a number A2 = r, such as A2 < A.

How can we move exactly A * q coins? Let’s write q in base 2. Making that, q will be written as a sum of powers of 2. Suppose lim is the maximum number such as 2 ^ lim <= q. We get every number k from 0 to lim. For each k, I push into the first box (the box containing initially A candies) a certain number of candies. As proven before, I'll need to push (2 ^ k) * A candies. Let's take a look at the k-th bit from binary representation of q. If k-th bit is 1, B will be written as following: B = A * (2 ^ k + 2 ^ (other_power_1) + 2 ^ (other_power_2) + ...) + r. Hence, I'll be able to move A * (2 ^ k) candies from "B box" to "A box". Otherwise, I'll move from "C box" to "A box". It will be always possible to do this move, as C > B and I could do that move from B, too.

The proposed algorithm may look abstract, so let's take an example.

Suppose A = 3, B = 905 and C = 1024. Can we get less than 3 for this state?

B = 3 * 301 + 2. B = 3 * (100101101)2 + 2.

K = 0: we need to move (2^0) * 3 coins into A. 0th bit of q is 1, so we can move from B to A.

A = 6, B = 3 * (100101100)2 + 2 C = 1024

K = 1: we need to move (2 ^ 1) * 3 coins into A. Since 1th bit of q is already 0, we have to move from C.

A = 12, B = 3 * (100101100)2 + 2 C = 1018

K = 2: we need to move (2 ^ 2) * 3 coins into A. 2nd bit of q is 1, so we can move from B.

A = 24, B = 3 * (100101000)2 + 2 C = 1018

K = 3: we need to move (2 ^ 3) * 3 coins into A. 3nd bit of q is 1, so we can move from B.

A = 48, B = 3 * (100100000)2 + 2 C = 1018

K = 4. we need to move (2 ^ 4) * 3 coins into A. 4th bit of q is 0, we need to move from C.

A = 96, B = 3 * (100100000)2 + 2 C = 970

K = 5. we need to move (2 ^ 5) * 3 coins into A. 5th bit of q is 1, so we need to move from B.

A = 192, B = 3 * (100000000)2 + 2 C = 970

K = 6 we need to move (2 ^ 6) * 3 coins into A. We mve them from C.

A = 384 B = 3 * (100000000)2 + 2 C = 778

K = 7 we need to move (2 ^ 7) * 3 coins into A. We move them from C

A = 768 B = 3 * (100000000)2 + 2 C = 394

K=8 Finally, we can move our last 1 bit from B to A.

A = 1536 B = 3 * (000000000)2 + 2 C = 394

A = 1536 B = (3 * 0 + 2) C = 394

In the example, from (3, 905, 1024) we can arrive to (2, 394, 1536). Then, with same logic, we can go from (2, 394, 1536) to (0, X, Y), because 394 = 2 * 197 + 0.

This is how you could write emptyOneBox() procedure. The remained problem is straight-forward: if initially there are zero or one boxes having candies, the answer is "-1". Otherwise, until there are more than 2 boxes having candies, pick 3 boxes arbitrary and apply emptyOneBox().

Here is a source implementing the algorithm. 4383485

BONUSInstead of a conclusion, I'll post here related problems to the ones used in the round. :) Please note that some of them might be more easier / complicated than level of difficulty used in the round. Feel free to think of them / ask help / discuss them in the comment section :)

Div2 A Suppose x, y, A, B ≤ 109. Instead of being asked how many bricks are colored with both red and pink in range [A, B], you're asked how many bricks are colored with at least one color. After you solve this one, solve the same problem, but instead of having 2 persons painting, you have k persons (k ≤ 20). Solution by Enchom

Div2 B Given a very long list of special points, can you find quickly a convex special quadrilateral? Can you find very very quickly? :) Also, can you find maximal area of a special convex quadrilateral in time better than O(N4)? Solutions for first problem and second problem provided by Xellos and Enchom

Div2 D / Div1 B Suppose the reverse problem. You are given a bubble sort graph having N vertices and M edges. Find its independent maximal set. Can you achieve O(N2) to do this? Does a solution in O((N + M) + N * logN) exist? Solution by CountZero

Div2 E / Div1 C Find a solution running in liniar time. Solution (dynamic programming) by ivan100sic . Solution (inclusion exclusion principle) by eduardische

Div1 D Suppose the 3D version of this problem. You have a 3D matrix and you perform same QUERY/UPDATE operations, but using 6 parameters (a submatrix is defined now all elements a[i][j][k] for which x0 <= i <= x1, y0 <= j <= y1, z0 <= k <= z1). Can you get a solution using O(log3 * N) per query, having constant 8? But for d dimensions, does an O(2d * (logd)n) algorithm per query exist? :) Solution by Dwylkz.

Div1 E In our algorithm, we pick arbitrary 3 boxes. Can you find some heuristics of picking 3 boxes to reduce number of moves?

Codeforces Round #197 — Tutorial

By Fefer_Ivan, 10 years ago, translation, In English339A - Helpful Maths

Tutorial by Fefer_Ivan

To solve this problem we can count the number of digits 1, 2 and 3 in the input. If there are c1 digits 1, c2 digits 2 and c3 digits 3. Then we must print the sequence of c1 digits 1, c2 digits 2 and c3 digits 3. Digits must be separated by + sign.

339B - Xenia and Ringroad

Tutorial by Fefer_Ivan

To solve this problem we must learn how to calculate fast enought the time, needed to travel between houses a and b. Let's consider the case when a ≤ b. Than Xenia needs b - a seconds to get from a to b. Otherwise a > b, Xenia will have to go thought house number 1. So she will need n - a + b seconds.

339C - Xenia and Weights

Tutorial by Fefer_Ivan

Let's consider the definition of balance. Balance is the difference between sum of all weights on the left pan and sum of all weights on the right pan. At the beginning balance is equal to 0. Att each step Xenia puts one weight on the pan. It means she adds to or substracts from balance integer from 1 to 10. In each odd step, the integer is added and in each even step the integer is subtracted. From the statement we know, that after each step, balance must change it sign and must not be equal to 0. So if after some step the absolute value of balance is greater than 10, Xenia can not continue. Also, it is said in the statement that we can not use two equal weigths in a row. To solve the problem, let's consider a graph, where vertices are tuples of three numbers (i, j, k), where i is a current balance, j is a weight, used in the previous step, and k is the number of the current step. Arcs of the graph must correspond to Xenias actions, described in the statement. The solution of the problme is a path from vertex (0, 0, 1) to some vertex (x, y, m), where x, y are any numbers, and m is the requared number of steps.

339D - Xenia and Bit Operations

Tutorial by Gerald

The problem could be solved by using a typical data structure (segment tree).

The leafs of the segment tree will store the values of ai. At the vertices, the distance from which to the leafs is 1, we will store OR of the numbers from the leafs, which are the sons of this node in the segment tree. Similarly, vertices, the distance from which to the leafs is 2, we will store Xor of the numbers stored in their immediate sons. And so on. Then, the root of the tree will contain the required value v.

There is no need to rebuild all the tree to perform an update operation. To do update, we should find a path from the root to the corresponding leaf and recalculate the values only at the tree vertices that are lying on that path. If everything is done correctly, then each update query will be executed in O(n) time. Also we need O(2n) memory.

339E - Three Swaps

Tutorial by Gerald

We will call the command l, r a reverse, also we will call the row of horses an array. Suddenly, right?

The problem can be solved with clever bruteforcing all possible ways to reverse an array. To begin with, assume that the reverse with l = r is ok. Our solution can find an answer with such kind of reverses. It is clear that this thing doesn't affect the solution. Because such reverses can simply be erased from the answer.

The key idea: reverses split an array into no more than seven segments of the original array. In other words, imagine that the array elements was originally glued together, and each reverse cuts a segment from the array. Then the array would be cut into not more than 7 pieces.

Now you can come up with the wrong solution to the problem, and then come up with optimization that turns it into right. So, bruteforce all ways to cut array into 7 or less pieces. Then bruteforce reverse operations, but each reverse operation should contain only whole pieces. It is clear that this solution is correct, One thing it does not fit the TL.

How to improve it? Note that the previous solution requires the exact partition of the array only at the very end of the bruteforce. It needed to check whether it is possible to get the given array a. So, let's assume that the array was originally somehow divided into 7 parts (we don't know the exact partition), the parts can be empty. Now try to bruteforce reverses as in naive solution. One thing, in the very end of bruteforce try to find such a partition of the array to get (with fixed reverses) the given array a.

The search for such a partition can be done greedily (the reader has an opportunity to come up with it himself). Author's solution does this in time proportional to the number of parts, that is, 7 operations. However, this can be done for O(n) — this should fit in TL, if you write bruteforce carefully.

Codeforces Round #196 — Problems Analysis

By gojira, 10 years ago, translation, In English337A - PuzzlesFirst, let's sort the numbers f[i] in ascending order. Now assume that the smallest jigsaw puzzle which the teacher purchases consists of f[k] pieces. Obviously, she should buy the smallest n puzzles which are of size f[k] or greater to minimize the difference. These are the puzzles f[k], f[k+1], ..., f[k+n-1] (this is not correct when f[i] are not distinct and f[k]=f[k-1], but such cases can be skipped). The difference between the greatest and the least size of the puzzles in such set is f[k+n-1]-f[k].

To choose the optimal f[k], we can test every k between 1 and m-n and pick the one producing the least difference. The full algorithm is as follows:

read(n, m, f[1..m])sort(f[1..m])best = INFINITYfor k = 1 to m-n  best = min(best, f[k+n-1] - f[k])print best337B - Routine ProblemSuppose that the width and height of the screen are W and H correspondingly. Since W:H = a:b, we have H=W*b/a. Similarly, the width and height of the film frame w and h are related as h=w*d/c. Imagine that Manao stretches/constricts the frame until it fits the screen horizontally or vertically, whichever happens first. There are three cases to consider: the horizontal to vertical ratio of the screen is less, equal or more than the corresponding ratio of the frame.

In the first case (a/b < c/d) the stretching process ends when the frame reaches the same width as the screen. That is, the frame will enlarge in W/w times and its new width will be W. Thus, its new height is h*W/w = w*c/d * W/w = W*d/c. We are interested in the ratio of unoccupied portion of the screen to its full size, which is (screen height - frame height) / (screen height) = (W*b/a - W*d/c) / (W*b/a) = (bc-ad)/bc.

In the second case (a/b > c/d) the process ends when the frame reaches the same height as the screen. Its height will become H and its width will become w*H/h = w * W*b/a / (w*d/c) = W*b/a * c/d. The unoccupied portion of the screen's horizontal is (W - W*b/a * c/d)/W = (ad-bc)/ad.

In the third case, the frame fills the screen entirely and the answer will be 0.

All that's left is to print the answer as an irreducible fraction. We need to find the greatest common divisor of its nominator and denominator for this. It can be done using Euclidean algorithm or just through trial division by every number from 1 to q. Since q is no more than a product of two numbers from the input and these numbers are constrained by 1000, we need to try at most million numbers in the worst case.

337C - QuizAssume that Manao has doubled his score (i.e. gave k consecutive correct answers) exactly X times. Then the least possible score is obtained when this doublings happen in the beginning of the game, i.e., when he answers the first X*k questions and never manages to answer k consecutive questions after that. The correctness of this statement follows from the following: for any other scenario with X doublings, all of these doublings can be moved into the beginning and the total score will not increase. Hence, for X=1 Manao's minimum score is k*2+m-k: he answers k consecutive questions, the score doubles, then he answers m-k questions. For X=2 the minimum possible score is (k*2+k)*2+m-2*k, for X=3 — ((k*2+k)*2+k)*2+m-3*k. For the general case, a formula (2^1+2^2+...+2^X)*k + m-X*k = (2^(X+1)-2)*k + m-X*k is derived.

The abovementioned observation shows that the minimum score grows monotonically when X is increased, so all we need is to find the minimum feasible X. It should satisfy the inequalities X*k <= n and X + (n - n mod k) / k * (k-1) + n mod k >= m. More on the second inequality: Manao answered the first X*k questions, thus there are n-X*k left. Now he can answer at most k-1 question from each k questions. If k divides n-X*k (which is the same as k divides n), the inequality becomes X*k + (n-X*k) / k * (k-1) >= m, but the remainder complicates it a bit: X*k + (n - X*k - (n - X*k) mod k) / k * (k-1) + (n - X*k) mod k >= m. This formula can be simplified to the one written earlier. So, the minimum X is equal to max(0, m - (n - n mod k) / k * (k-1) - n mod k). You'll need exponentiation by squaring to compute the score corresponding to this value of X. Thus, the overall complexity of this solution is O(log(n)).

337D - Book of EvilObviously, in graph theory language our problem is: given a tree with n vertices, m of which are marked, find the number of vertices which are at most distance d apart from each of the marked vertices.

Let us hang the tree by some vertex r, that is, assume that it is a rooted tree with root in vertex r. Let us also rephrase the condition imposed on sought vertices: we need to count such vertices v that the maximum distance from v to a marked vertex is at most d.

For any inner vertex v, the marked vertex which is the farthest from it is either in the subtree of v or outside it — in the latter case the path from v to the farthest marked vertex traverses the parent of v. Using this observation, we can recompute the distances to the farthest marked vertices when transiting from a vertex to its child.

First, we will compute the distance from every vertex v to the farthest marked vertex within the subtree of v. Let us call this distance distDown[v]. The values of distDown[] can be computed in a single depth-first search: for each leaf of the tree this distance is either 0 (when the leaf is marked) or nominal negative infinity (when the leaf is not marked), and for each inner vertex v distDown[v]=max(distDown[child1], distDown[child2], ..., distDown[childK])+1, where childi are the children of v.

Now we will compute the distances from each vertex to the farthest marked vertex outside its subtree. Let's denote this distance with distUp[v]. We will use DFS again to compute values of distUp[]. For the root, distUp[r] is equal to nominal negative infinity, and for any other vertex v there are two cases: either the farthest marked vertex is located in the subtree of v-s parent p, or it is even "farther", i.e., the path to it traverses vertex p-s parent. In the first case, the distance from v to such vertex is equal to max(distDown[sibling1], ..., distDown[siblingK])+2, where siblingi are the brothers (other children of the parent) of vertex v. In the second case, it is equal to distUp[p]+1. Thus, distUp[v] is equal to the maximum of these two values. Note that you need to be clever to perform the computations in the first case in overall linear time. For this, you can find the maximum max1 and second maximum max2 of values distDown[sibling1], ..., distDown[siblingK]. After that, when distDown[v] < max1, we have max(distDown[sibling1], ..., distDown[siblingK])=max1, otherwise we have distDown[v] = max1 and max(distDown[sibling1], ..., distDown[siblingK])=max2.

After computing distDown[] и distUp[], it is easy to derive the answers: it is the count of such vertices v that distDown[v] <= d && distUp[v] <= d.

You can check 4302127 for an implementation of the described approach.

337E - Divisor TreeLet us first show that in an optimal divisor tree only the root or a leaf can hold a value other than one of a[i]. Suppose that we have an inner vertex different from the root which holds a number X not equal to any of a[i]. Then we can exclude this vertex from the tree and tie its children to its parent without violating any of the tree's properties.

Hence, our tree consists of the root, vertices with numbers a[i] tied to each other or to the root, and leaves, which are tied to vertices with numbers a[i] and contain these numbers' prime factorizations. The exception is the case when one of a[i] is written in root itself, and the case when some a[i]-s are prime themselves. Also note that in general case it's easy to count how many leaves the tree will have. This count is equal to the sum of exponents of primes in prime factorizations of those a[i]-s which are the children of the root.

Since N <= 8, we can build all divisor trees which satisfy the observations we made. Let's sort numbers a[i] in descending order and recursively choose a parent for each of them from the vertices already present in the tree. Of course, tying a number X to some vertex v is only possible if the product of X and the numbers in children of v divides the number in v itself. For a[1], we have a choice — we can make it the root of the tree or a child of the root (in this case the root will hold a nominal infinity which is divisible by any number). For every next a[i], the choice is whether to tie it to the root or a vertex containing one of the previous numbers. Therefore, we only consider O(N!) trees in total.

You can check 4302171 for an implementation of this idea.

338D - GCD TableObservation 1. If the sequence a occurs in table G, then it should occur in row i = LCM(a[1], ..., a[k]). The proof follows. It is clear that theoretically it may only occur in rows with numbers which are multiple to i, since the row number should divide by each of a[index]. Consider some a row with number i*x, where x>1. The rows i and i*x differ only in such elements j that i*x and j both divide by some p^q (where p is prime) which does not divide i (hence, G(i*x, j) is divisible by p^q). But none of the a[index] may divide by such p^q, since then i would be also divisible by it. Therefore, if a occurs in row i*x, then it does not intersect with index j. Since it can only reside on indices where i and i*x coincide, checking only the i-th row is enough. It also clear that if i > n, the answer is NO.

Observation 2. The sought index j should satisfy the following modular linear equations system:

j = 0 (mod a[1])j + 1 = 0 (mod a[2])...j + l = 0 (mod a[l + 1])...j + k - 1 = 0 (mod a[k])

<=>

{j = -l (mod a[l + 1])}In other words, j + l must divide by a[l+1] for each l=0..k-1.

According to Chinese Remainder Theorem, such a system has a solution iff for each pair of indices x, y (0 <= x, y <= k-1) we have -x = -y (mod GCD(a[x+1], a[y+1])). Let's denote L = LCM(a[1], ..., a[k]). If the system has a solution, then it is singular on interval [0, L) and all the other solutions are congruent to it modulo L. Suppose that we have found the minimum non-negative j which satisfies the given system. Then, if a occurs in G, it will start from the j-th element of the i-th row. Theoretically, it may begin at any index of form j+x*L, x>=0, but since i = L, we have G(i, j+X*L) = GCD(i, j+X*i) = GCD(i, j). So it is sufficient to check whether the k consecutive elements which begin at index j in row i coincide with sequence a. It is also clear that when j > m-k+1, the answer is NO.

Finally, let's consider how to solve a system of modular linear equations. We can use an auxiliary method which, given r1, m1, r2, m2, finds minimum X such that X = r1 (mod m1) and X = r2 (mod m2), or determines that such number does not exist. Let X = m1*x + r1, then we have m1*x + r1 = r2 (mod m2). This can be represented as a Diophantine equation m1*x + m2*y = r2-r1 and solved using Extended Euclidean Algorithm. The least non-negative x, if it exists, yields the sought X = m1*x + r1. Now this method can be used to find the minimum X1 which satisfies the first two equations. After that, we can say that we have a system with k-1 equation, where the first two old equations are replaced with a new j = X1 (mod LCM(a[1], a[2])), and repeat the same procedure again. After using this method k-1 times, we obtain the solution to the whole system.

Also note that the proposed solution does not require long arithmetics: — The computation of LCM(a[1], ..., a[k]) can be implemented with a check before each multiplication: if the result will become larger than n, the answer is NO; — When it comes to solving the system of equations, we already know that L <= n <= 10^12, thus all the intermediate moduli will also obide to this constraint; — The Extended Euclidean Algorithm can find a solution in the same bounds as its inputs, so it will also use numbers up to 10^12.

The overall complexity of the algorithm is O(k logn).

338E - Optimize!Decyphering Manao's pseudocode, we unearth the following problem: you are given arrays a[1..n] and b[1..len] and a number h. Consider each subarray of a of length L. Let us call it s. Count how many of them have the property that the elements of b can be shuffled in such a way that each sum s[i]+b[i] (1<=i<=L) is at least h.

First, let's solve a problem for one subarray. That is, we need to determine whether the elements of two arrays s and b can be matched in such a way that each sum is h or more. We can do the following: for each element of s, find the least element of b such that the two's sum is at least h, and erase the corresponding element from b. If we managed to pair each of the elements from s, then the arrays hold the property. Note that the elements of s can be processed in any order. If both s and b are sorted, then the idea described can be implemented in linear time.

We can not achieve better complexity when considering each subarray separately, so we will try to solve the problem for several subarrays at the same time. Suppose that b is already sorted. We choose some X < len and consider a subarray a[i..i+X-1]. Let's process all the numbers from this subarray, i.e., for each of them find the least b[j] which pairs up with this number and erase it from b. The whole processing can be done in time O(n) if we have a sorted version of a and the corresponding indices computed beforehand.

Now we can find the answer for every subarray s of length len which begins in segment [i-Y, i] using O(YlogY) operations, where Y=len-X. For this, we just take the Y elements which are in s but not in a[i..i+X-1] and process them against the numbers left in b. If each of them has been paired, then subarray s holds the required property, otherwise it does not. Moreover, since the subarrays we consider are overlapping, we can optimize even further and obtain amortized O(Y) complexity per subarray. To understand this, note that for processing a subarray in O(Y) time we only need to obtain its sorted version (to be more specific, the sorted version of the portion which does not overlap with a[i..i+X-1]). For the leftmost subarray we consider, we can sort its elements in usual way. For every next subarray (which differs from its predecessor in exactly two elements) we only need O(Y) operations to obtain its sorted version by updating the information from the previous subarray. Thus we have complexity O(YlogY + Y^2) of processing Y segments in total, which gives O(Y) per segment on average.

Now let us take a look at the full picture. To process all subarrays of length len, we need to use the method given above for each of the segments a[Y..Y+len-1], a[2Y+1..2Y+len], a[3Y+2..3Y+len+1], .... Therefore, we have O(N/Y) iterations of algorithm with comlexity O(N+Y^2). We need to find a value of Y that minimizes N*N/Y + N*Y, which is Y=~sqrt(N). The overall complexity is O(Nsqrt(N)). However, we need to consider the case len < sqrt(N) separately, since then Y = len - X < len. In this case, the problem can be solved in time O(N*len) with ideas similar to those described above.

You can check the implementation of this idea in 4302344.

P.S. The statement of the "problem" that Manao is solving actually contains a Georgian fairy tale. You can copy almost the same text from here and try to guess what he tale is about :)

Tutorial Codeforces Round #195 (Div. 2)

By gridnevvvit, 10 years ago, translation, In English336A - Vasily the Bear and Triangleval = |x| + |y|. Then first point is (val * sign(x), 0), second — (0, val * sign(y)). Swap points if needed according to statement.

Let's see why this is the answer. Conditions x ≠ 0 and y ≠ 0 give us that one point is on X-axis, and the other on Y-axis. Let's see how it works for x > 0 and y > 0. Other cases can be proved in similar way. We need to show, that (x, y) belongs to our triangle(including it's borders). In fact (x, y) belongs to segment, connecting (x + y, 0) with (0, x + y). Line through (x + y, 0) and (0, x + y) is Y =  - X + x + y. Using coordinates (x, y) in this equation proves the statement.

Author's solution

336B - Vasily the Bear and FlyAlso you could iterate circles, adding distance for each of them and dividing by m2 in the end. Let's see how the i-th iteration works 1 ≤ i ≤ m. Distance to m + i-th circle is 2R. Distance to m + j-th circle, where |j - i| = 1, is . For other circles it's quite simple to calculate sum of distances. There are i - 2 circles which located to the left of current circle. So, sum of distances for these circles is . In the same manner we can calculate answer for cirlcles which are located to the right of the current circle

Рисунок для теста с 3-мя окружностями

Author's solution

336C - Vasily the Bear and SequenceLet's check max beauty from 29 to 0. For every possible beauty i our aim is to find largest subset with such beauty. We will include in this subset all numbers, that have 1 at i-th bit. After that we do bitwise and as in statement, and if the resulting value is divisible by 2i, then there is the answer. Solution works in O(n).

Author's solution

336D - Vasily the Bear and Beautiful Stringsany — random binary string, s + g — concatenation of strings, MOD = 1000000007.

String 1 + any always transforms into 0, string 1 — into 1. String 01 + any always transforms into 1, string 01 — into 0. String 001 + any transforms into 0, string 001 — into 1, and so on. Using these facts let's consider following solution.

Cases like strings without ones or zeroes are easy. For every i (in zero-based numbering) let's assume that it is position of the first occurence of 1 in our string. Using already known facts we can understand what is the final result of transformations for such string. If the result equals to g, we add C(cnt[0] + cnt[1] - i - 1, cnt[1] - 1) to the answer. Calculation of binomial coefficients is following: fact[i] = i!%MOD, , C(n, k) = fact[n]inv(fact[n - i]fact[i]), where inv(a) — inverse element modulo MOD. inv(a) = aMOD - 2, because MOD is prime number.

Author's solution

336E - Vasily the Bear and Painting SquarePretty tough problem. Consider following DP dp[lvl][op][cur][type] — number of ways to take op triangles, if we have 2lvl + 1 squares. cur, type — auxiliary values. Answer will be dp[n][k][0][2]k!. type means type of transitions we make. cur — amount of used quarters (cur = 4 — 2 quarters, cur < 4 — cur quarters). It is important to distinguish cur = 2 from cur = 4, because amount of consecutive pairs of unused quarters is different.

Значения cur для различных ситуаций

About transitions. type = 2. Iterate amount of pairs (considering cur) of consecutive quarters that we will take. It is important for them to have no common quarters. We can get two pairs only in case cur = 0. Let's also take some quarters that are not in pairs. Calculate number of ways to select corresponding triangles and add to the current DP-state value dp[lvl][op - choosen][newcur][1] * cntwaystochoose. For better understanding of type = 2 check my solution (calc(n, k, cur, type) — isfordp[n][k][cur][type]).

type = 1. Now we take triangles at the borders (number of squares is 2*lvl + 1). "at the borders" means marked X, see the picture.



Iterate amount of pairs (considering cur) of consecutive triangles we take. It is important for pairs to have no common triangles. Let's also take some triangles that are not in pairs. Calculate number of ways to select corresponding triangles and add to the current DP-state value dp[lvl][op - choosen][cur][0] * cntwaystochoose.

type = 0. We take triangles at the borders (number of squares is 2*lvl). "at the borders" means marked X, see the picture.



Take some triangles, not in pairs. Calculate number of ways to select corresponding triangles and add to current DP-state value dp[lvl - 1][op - choosen][cur][2] * cntwaystochoose. Starting values: dp[0][0][cur][1] = 1, dp[0][cnt][cur][1] = 0, cnt > 0.

Author's solution

Codeforces Round 194 — Editoral

By Sammarize, 10 years ago, translation, In English334A - Candy Bags

In this problem one must divide all natural numbers from 1 to n2 to groups size of n with the same sums.

Lets divide all this numbers to pairs . We can to do it since n is even and therefore n2 is even too. Then we can just make n groups consists of  of these pairs.

334B - Eight Point Sets

In this problem you must to do only what's written — you must to define does this set of points sutisfies to decribed conditions.

There are many ways to define it. For instance:

Check if there are exactly 3 discinct x's and y's. One can put all x's to set and then get it size to find amount of distinct x's (as well as y's). Then print ``ugly'' if this amount isn't equals to 3.Finally we have x1, x2 и x3 as well as y1, y2 и y3. Now lets check if for every pair (xi, yj) (except (x2, y2)) such point exist in given set of points.But I think that to read editoral of this problem is not good idea. It is better to just look at the implementation.

334C - Secrets / 333A - Secrets

Actually we are looking for longest sequence of natural number a1, a2, ..., ak, so that every number in it sequence is the power of three, sum of all numbers is more then n and if we remove any number sum will be less then n. To be precise we are looking for length of this sequence.

Consider minimal number ai = A in the sequence. All this numbers are divides to A since them all are powers of 3. And then, sum S of all this number is divides to A too. Suppose that n is divide to A too. Then, since S > n, then S - A ≥ n. And then if we remove A from sequence, sum of other number not less then n — contradist with second condition.

Well, we now that n is not divide to none element in sequence. Now lets find minimal k so that , and answer is .

334D - Chips / 333B - Chips

At first lets make two remarks:

On every (vertical of horizontal) line we can put only one chip.If there is at least one forbidden cell on the line then we can't put chip on this line.Follow last remark we will avoid hits chip on forbidden cells. Lets avoid ``collisions'' of chips.

Lets consider these four line: vertical lines number i and n + 1 - i and horizontal lines with the same numbers. Chips on these lines can collides together, but con't collides to another chip. Therefore we can solve the problem for these four line independently. And finally lets observe that we can put the chip on each of these lines without cillisions as well as on the picture.

 

So, we can iterate all possible fours and put chip on every possible line. And don't fogot about case of two middle line in case of n is odd.

334E - Lucky Tickets / 333C - Lucky Tickets

In this problem we can find the right amount of lucky tickets.

Lets consider amount of different numbers we can get from one four-digit ticket number. It is easy to iterate all this tickets, since it amount only 104. It happened that we can get almost 60 numbers from ticket on the average.

Suppose we can get number x from ticket n. It is clearly that either x - k ≥ 0 or k - x ≥ 0. If k - x ≥ 0 we can write eight-digit ticket number who will have k - x in the first four digits and n in the last four digits. It is clearly that such ticket is k-lucky. This method allows us to get almost 600 000 lucky tickets and it is enough.

333D - Characteristics of Rectangles

In this problem we must to find maximal value of minimum of values on four intersections of two rows and two columns of table.

In another words, we are looking for maximum value of min(ai1, j1, ai1, j2, ai2, j1, ai2, j2) for all i1, i2, j1, j2 such that 1 ≤ i1, i2 ≤ n, 1 ≤ j1, j2 ≤ m, i1 ≠ i2, j1 ≠ j2. Lets us binary search of the answer. For us it we must can define is there two rows and two colums with ones on all four its intersections; in other words, integers i1, i2, j1, j2 so that ai1, j1 = ai1, j2 = ai2, j1 = ai2, j2 = 1.

Lets consider all pair of natural numbers (i1, i2) so that there exist nutural number j so that ai1, j = ai2, j = 1. Existence of two equals such pairs is equals to existence of above four numbers. But it is can be only  such pairs. Therefore we can make the array where we will mark pair who were meets. Lets iterate all pairs in any order until we meet repeated pair or pairs are ends. So we have solution of time .

333E - Summer Earnings

In this problem it is need to draw three circle equals together with maximum possible radius with centers in given points. In another words it is need to find triangle wich minimum side is maximal.

Unfortunately solution with bit optimize is not expected for us.

Lets call to memory two simple geometric facts. Firstly, sum of alnges of trianle is equals to . Secondly, minimal angle is opposit to minimal side of triangle.

Since, at leats one side of angles of triangle not less then  and this anlge is not least one. And side opposite to it is not least side. Therefore, if in   then min(|AB|, |BC|, |CA|) = min(|AB|, |BC|).

And then lets do the follows. Lets iterate apex B and for each B lets find triangle with maximal minimum of sides when B is the apex of triangle and . For it lets sort all other points by the angle relative to B, and for each point A lets find point C most distant to B among such points that . We have to use segment tree for maximum and two pointers or binary searsh to now left and right bound of possible points C during iterating A.

Finally, we have solution of time .

Codeforces Round #193 (Div. 2) — Tutorial

By Serega, 10 years ago, translation, In EnglishAny suggestions, remarks and information about mistakes are welcomed. If you can improve the quality of this tutorial, please write me a private message :)

332A - Down the Hatch!

Since n ≥ 4, one Vasya’s turn does not affect his other turns. Consequently, you should find just the number of positions (0-indexed) in the given string, which indexes are multiples of n and before which there are at least three same symbols.

Asymptotics of the solution — O(|s|)

Code

332B - Maximum Absurdity

Let’s build the array of partial sums, which will permit to find the sum in any segment of the array in O(1). Let's iterate through the number a (the left edge of the leftmost segment) in descending order. Now we need to find among segments of length k, starting from position which index is greater than or equal to a + k, a segment with the maximum sum. Since we search a in descending order, we can maintain this segment during the transition from a to a - 1.

Asymptotics of the solution — O(n).

Code

332C - Students' Revenge

Let’s sort orders ascending bi, and by equality of bi — descending ai. One can assume that in an optimal solution all the orders obeyed by the chairperson go in the sorted list after orders that she hasn’t obeyed (it may be wrong if there are several same orders, but it doesn’t affect parameters of an answer). Let’s iterate through i — the position of the first order in the sorted list, which the chairperson will obey. To the left of this order we should choose p - k orders which the chairperson won’t obey. As we should choose orders with the maximum sum of bi, we can just choose p - k orders that immediately precede the i-th order. To the right of the i-th order we should choose k - 1 orders which the chairperson will obey. These orders should have the maximum sum of ai. If we iterate i by descending, we can keep these k - 1 orders in some data structure that can perform basic operations with sets in logarithmic time (for example, multiset in C++).

Asymptotics of the solution — O(nlogn)

Code

332D - Theft of Blueprints

In the problem is given the weighted undirected graph without loops and multiple edges satisfying the following property: for every set S containing k vertices there is exactly one vertex adjacent to all vertices from this set (*) (this vertex is called “adjacent with S”). For any k-element set of vertices we can calculate the special characteristic: the sum of the weights of edges that connect vertices from S with vertex, adjacent with S. It is required to find the mathematical average of the characteristics of all k-element sets of vertices.

One can solve this problem using the following fact (the proof is now available only in the Russian version of this post): if k ≥ 3, only complete graph containing k + 1 vertices satisfies the problem statement. For complete graphs answer is equal to doubled sum of weights of all edges, divided by n. The same way one can calculate answer if k = 1. Now let’s consider the case k = 2. Let’s iterate through the vertex i which is adjacent with our two-element set. Let’s write in ascending order all such numbers j that ci, j ≠  - 1. Any two different vertices of this list form the set for which vertex i is adjacent, and there are no other such sets of vertices. Looking over all pairs of vertices in this list, we can add characteristics of all these sets to the answer. Since it’s guaranteed that the graph satisfies the property (*), each pair of vertices will be analyzed only once. A similar approach is used in the validator for this problem.

Asymptotics of the solution — O(n2).

Code

332E - Binary Key

Let’s iterate through the number of ones in the key (cnt). One can note that cnt can’t be large than min(|s|, k), as the keys containing more than |s| ones can’t be lexicographically minimal.

Let’s consider the solution of this problem with the fixed cnt. Any complete pass on the key corresponds to the extracting cnt of k scanned symbols of the container, i. e. container is divided into blocks of length k, and the message is divided into blocks of length cnt (last blocks may be shorter). We’ll number the characters in each block of the message from 0 to cnt - 1. We’ll call (q, j)-suffix suffix of q-th block of the message that starts from a position j in this block. Let’s solve the problem with dynamic programming: di, j is true if there exists a key, the first i characters of which are zeros and which corresponds to the extracting from container the string that is the result of concatenation of all (q, j)-suffixes of the message. The transitions are based on the filling of i-th position of the key with zero or one (we need to choose the minimum acceptable character). To restore the key you can keep chosen characters for each subtask.

Asymptotics of the solution — O(k·|s|2 + |p|).

Code

Codeforces Round #192 Editorial

By fushar, 10 years ago, In EnglishSo! We hope you enjoyed the round. Internally, we called this round Trollforces, because as you knew, most solutions should be unexpected :)

Some fun fact: there are ~ 30 pictures in this round, totaling ~ 144 KB.

Here is the editorial, written with mixed point of views of all writers (hence "I" may refer to any of us).

330A - Cakeminator by dolphinigle

Long solution:

Once an evil strawberry, always an evil strawberry (since they can’t be eaten).Thus, if a row cannot be eaten before any eat is performed, it can never be eaten.Same with column.Thus, you can know which columns and which rows you can eat.Just try to eat them all and calculate how many cells you actually eat.Short solution:

A row or a column cannot be eaten if it has at least one strawberry.A cell cannot be eaten if both its row and its column cannot be eaten -- otherwise you can eat the row/column and eat it!If there are r' rows that cannot be eaten, and c' columns that cannot be eaten, then there are r' * c' cells that cannot be eaten -- a cell such that both its row and columns cannot be eaten.

Since all other cells can be eaten, answer is R * C — r' * c'.

330B - Road Construction by jonathanirvings

Since m < n/2, there exists at least one node that is not incident to any edge.The constraints can be satisfied if and only if the graph is a star graph: http://en.wikipedia.org/wiki/Star_(graph_theory). We can just create a star graph centered with the node and connect it to all other nodes.330C - Purification / 329A - Purification by dolphinigle

Obviously the minimum possible answer is n (why?). But is it always possible to purify all the cells with n spells?If there exist a row consisting of entirely "E" cells and a column consisting of entirely "E" cells, then the answer is -1. This is since the cell with that row and that column cannot be purifed.Otherwise, without loss of generality let's suppose there is no row consisting entirely of "E". Then, for each row, find any "." cell. Purify it. The case with no column consisting entirely of "E" is similar.330D - Biridian Forest / 329B - Biridian Forest by dolphinigle

The only non ad hoc problem in the round! ...sort of. Despite the very long problem statement, the solution is really simple.

We should take any shortest path from S to E (yes, any!). We will see why this is optimal at the end.If a breeder can reach E faster than or equal to us, then he will battle us. This is since he can simply walk to E and waits for us there.Otherwise, they can never battle us by contradiction. Assume they battled us, but they cannot reach cell E from their location faster or equal to us. If the battle us in cell X, then cell X is part of the shortest path from S to E that you are travelling. Since he is able to battle us there, he must be able to arrive at cell X <= us. But then, that means he can walk from X to E and reach E before or equal to us! Contradiction.This is optimal, since any breeder that we battle in this solution must also be battled in any other solution (the other breeders should immediately go to E and wait).You can use Breadth-First Search once from exit cell to obtain the shortest paths from each breeder to it.Thoughts

I tried to make this clearer by separating the paragraphs by topic. Did it work well?

Btw, mikemon is pronounced "mi-ke-mon", not "mike"-mon -- similar to how Pokemon is pronounced "po-ke-mon" not "poke"-mon >:).

330E - Graph Reconstruction / 329C - Graph Reconstruction by fushar

First, I would like to apologize the missing node 3 in the picture of the first example. It was a mistake :(

Intended, deterministic solution:

If n <= 7, brute force all possible subsets of the edges (at most 2^(7 * (7 — 1) / 2)), and check if they satisfy the constraint.Otherwise, a solution always exists. Here is how to construct one.Partition the nodes into connected components. Note that each component will be either a cycle or a chain. List the nodes of each component in order of the cycle/chain. For example, for the first example, the partition would be { <1, 2, 3>, <4, 5, 6, 8, 7> }. For each component, we do not care whether it is a cycle or a chain.For each component, reorder the nodes such that all nodes in the odd positions are in the front. For example, component ABCDEFGHI is reordered into ACEGIBDFH. (Each letter represent a node.)Pick any component with the largest number of nodes. If the number of nodes in it is even, swap the first two nodes. For example, ABCDEFGH -> ACEGBDFH -> CAEGBDFH.For each other component, insert the nodes alternately between the largest component. For example, if the other components are acebd and 1324, insert them as follows: CAEGBDFH -> C a A c E e G b B d DFH -> C 1 a 3 A 2 c 4 EeGbBdDFH.Connect adjacent nodes so that the number of edges is m, connecting the last with the first nodes if necessary.The deterministic solution is very tricky. Therefore, I made the pretest quite strong. Some tricky cases:

4-cycle and 1-chain (covered in the example)3-cycle and 3-cycle4-cycle and 3-cycle (very tricky! many submissions failed on this case)Actually, we can do brute force when n <= 6, but this requires a special handling: when the largest component has 4 nodes, we should swap the first node with the third node (not the second). This is to handle the 4-cycle-and-3-cycle case.

Troll solution, nondeterministic:

Do the following many times:

x = [1, 2, 3, ..., n]random_shuffle(x)for i = 1 to m:    if the edge (x[i], x[(i+1)%n]) is in input:        // fail this iteration, repeat the entire procedure

if didn’t fail:    // we obtain a solution!    for i = 1 to m:        print x[i], x[(i+1)%n]

If didn’t obtain solution:    print -1So, the question is, for large n what is the probability that a permutation is not "bad"? This can be computed (or at least approximated) similar to computing derangement probability -- I obtained a result above 0.1, which means in 100 iterations it should succeed if there was a solution. ...There is a solution if n > 7, so it should work.

329D - The Evil Temple and the Moving Rocks by dolphinigle

Post your solution in the comment! Here's mine for the last case! (approximately 120,000 sounds). You can get the number of sounds your solution produces when submitting it to the server.

1 copy ofv<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v>v^

24 copies ofv.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v.v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^

24 copies ofv^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^.^

1 copy of>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^>^....................................................................................................

1 1I wonder if there’s a solution with ~150,000 sounds or more... the (theoretical) upper bound is 100^3 / something, so it may be feasible...?

329E - Evil by dolphinigle

The solution to this problem is actually quite simple: 4122927

This problem asks us to prove something very long (the proof below is of 80+ lines).

Assume that the number of cities is at least 4. The case where it's less than 4 is trivial.

First, we will assume that no two cities will have same X or Y coordinates. To get this assumption, we can juxtapose every city very slightly that it will not change the answer.

The keys are : A) "Manhattan Distance", B) the tour starts and ends at the same city. Suppose we know a tour. The total distance traveled will be |X1 — X2| + |Y1 — Y2| + |X3 — X2| + |Y3 — Y2| ...

Let's separate the X and Y coordinates for simplicity. Note that each city will contribute twice to this value, for example X2 was in |X1 — X2| and |X3 — X2| in the example above. Manhattan distance implies that each of these values will either be multiplied by +1 or -1, depending on the other coordinate being compared in the absolute term. Furthermore, the number of values that are multiplied by +1 must equal the number of values that are multiplied by -1 (since in each absolute term, one is multiplied by +1 and the other by -1). This directly implies an upper bound on the maximum length of the tour.

If we list all the X coordinates of the cities, and we put each of them twice in this list, and sort them, the maximum will be gained if we multiply the last half by +1 and the first half by -1, and finally summing them up. Note that all of these reasoning applies to the Y coordinate, and summing both maximum of X and Y, we receive an upper bound on the length of the tour.

If we can find a tour with this length, our job is done. In some case, it's possible. Let's investigate!

First, if we have the medians of the X and the Ys as in the list above, we can separated the field like below :

 A  | B    |---------    | C  | DThe lines corresponds to the median for both X and Y.

At most one city will lie on each of the median lines (recall our assumption that X and Ys are distinct).

Let's call each A B C and D as boxes. Below, we will refer box A as simply A (applies to B, C, and D too)

To obtain the value above, from a city in B we must go to a city in C. Same reasoning yields : B->C, C->B, A->D, D->A. Here, pairs of cities become apparrent, A and D are paired as well as B and C.

First, if either A+D is empty or B+C is empty, then we can obtain the upper bound above. We simply alternates between the two remaining pair. So let's assume that A+D is not empty and B+C is not empty.

First, let's investigate the relationship between B and C (A and B will also exhibits this relationship).

Theorem 1:

|B — C| <= 1.

Why:

First, if there are no cities in the medians or there is a single city in the center of the median :

A median divides the region into two areas with the same number of cities, so we have:

a) A+B = C+Db) A+C = B+Dsubstituting A from a to b yields :

(C+D-B)+C = B+D2C = 2BB = CAnd the theorem follows.

Next, suppose there are two cities in the median, one for each median line :

Let's suppose the median is one above and one on the right. All other cases will be similar. By definition of median...

a) (A + B + 1) = (C + D)b) (A + C) = (B + D + 1)Substituing a into b yields

(C + D - B - 1 + C) = (B + D + 1)2C = 2B + 2C = B + 1which also implies A = D

Applying the same technique to other cases will give:

C = B and A = D+1C = B-1 and A = DC = B and A = D-1And the theorem follows.

Note also that the one with the extra 1 city will be the one that is not adjacent to any median city (adjacent being the city lies in the boundary of the box)

OK, so in the following observations, we will assume the upper bound (that is, the sorted list of both X and Ys have their first half multiplied by -1 while the rest by +1), and trying to find a solution that's as close as possible to this upper bound.

The following will be another case analysis.

Theorem 2:

If there are two cities in the medians (that is, one in each median line), then the upper bound can be achieved.

Why:

We use pair of boxes to denote either A and D or B and C. From the second part of the proof for theorem 1, there will be a pair of boxes that contain different number of cities. Let's pick this pair, and start at the one with the most boxes. We keep alternating with its pair until we end up back in our starting box. Then, we simply move to either of the median city. From there we move to the other pair of box, the farthest one of the two. Alternate between the two, go to the other median city, and return to the starting city. It's easy to see that this will be optimal and have the upper bound as its value.

Now, let's see if there are no cities in the medians. First of all, this implies that the number of cities is even. Second, this implies that our upper bound which has the X and Y lists as -1 -1 -1 ... -1 1 ... 1 1 1 will not work (since this implies we have to continuously alternate between the two pairs of boxes, however, we can't switch between the pair of boxes). So, at least a modification would be required. The smallest possible modification is obtained by swapping the medians, that is, it becomes : -1 -1 -1 ... -1 -1 1 -1 1 1 ... 1 1 1. This is sufficient. Why? So, there are two cities that changes since the number of cities is even. Furthermore, these two cities will be the closest to the median line (let's assume these coordinates are X, that is, they're the closest to the vertical median line) and lies at two different boxes. Then, we proceed as follows. We start at one of these two cities. Alternate and end at the other side. If the other city is at that box, we make it so that we end at that city, and in this case, we can move to a city in the other box pair while respecting the list of X coordinates (we can do so since this city is the closest to the median line). Otherwise, the city will be in the other pair of boxes. We simply move there and it can be shown that we still respect the list of X coordinates. Alternate and at the end, go back to the starting city. All of these can be shown to still respect the list above.

This is optimal since this is the next largest possible upper bound if upper bound cannot be achieved.

Now, if there is a single city in the center of both medians, then the upper bound cannot be achieved. To see this, the upper bound can only be achieved if from a city in a box we move to another city in its box pair or to the center city. However, since both pair of boxes contains a city, we will need to move at least twice between them. Since there's only one center city, this is not possible.

Observe that this case implies an odd number of cities. Hence, we can't simply swap the median since it swaps the x coordinates of the same median city. Instead, we do this :

-1 -1 ... -1 -1 1 1 -1 1 ... 1 1

or

-1 -1 ... -1 1 -1 -1 1 1 ... 1 1

That is, we swap to either one of the neighboring city. With the same reasoning as above, we can show that we respect this list of X coordinates.

To achieve O(N) expected performance, note that the only operations we need are : grouping elements into boxes and median finding. Both can be done in expected O(N) time (expected since although there is a worst-case O(N) selection algorithm, it's ugly).

Thoughts:

Actually I intended to reword this into a three-paragraph weird story, but that seems a little too evil >:), so it was left out.

Codeforces Round #191 — Tutorial

By fchirica, 10 years ago, In English327A - Игра с переворачиванием

I’ll present here the O(N ^ 3) algorithm, which is enough to solve this task. Then, for those interested, I’ll show a method to achieve O(N) complexity.

O(N ^ 3) method: The first thing to observe is that constrains are slow enough to allow a brute force algorithm. Using brute force, I can calculate for each possible single move the number of 1s resulting after applying it and take maximum. For consider each move, I can just generate with 2 FOR loops all indices i, j such as i <= j. So far we have O(N ^ 2) complexity. Suppose I have now 2 fixed vaIues i and j. I need to calculate variable cnt (initially 0) representing the number of ones if I do the move. For do this, I choose another indice k to go in a[] array (taking O(N) time, making the total of O(N ^ 3) complexity). We have two cases: either k is in range [i, j] (this means i <= k AND k <= j) or not (if that condition is not met). If it’s in range, then it gets flipped, so we add to count variable 1 – a[k] (observe that it makes 0 to 1 and 1 to 0). If it’s not in range, we simply add to cnt variable a[k]. The answer is maximum of all cnt obtained.

O(N) method: For achieve this complexity, we need to make an observation. Suppose I flip an interval (it does not matter what interval, it can be any interval). Also suppose that S is the number of ones before flipiing it. What happens? Every time I flip a 0 value, S increases by 1 (I get a new 1 value). Every time I flip a 1 value, S decreases by 1 (I loose a 1 value). What would be the “gain” from a flip? I consider winning “+1” when I get a 0 value and “-1” when I get a 1 value. The “gain” would be simply a sum of +1 and -1. This gives us idea to make another vector b[]. B[i] is 1 if A[i] is 0 and B[i] is -1 if A[i] is 1. We want to maximize S + gain_after_one_move sum. As S is constant, I want to maximize gain_after_one_move. In other words, I want to find a subsequence in b[] which gives the maximal sum. If I flip it, I get maximal number of 1s too. This can be founded trivially in O(N ^ 2). How to get O(N)? A relative experienced programmer in dynamic programming will immediately recognize it as a classical problem “subsequence of maximal sum”. If you never heard about it, come back to this approach after you learn it.

327B - Голодная последовательность

We’ll present two different solutions for this task.

Solution 1. What if we solve a more general task? What if each hungry number from the solution isn’t allowed to be divided by any number smaller than it (except 1, which is divides every natural number). If this more general condition would be met, then the “hungry” condition would be met, too (as a[i] won’t be divided by a number smaller than it (except 1), it won’t be divided by a[j], too, with j < i, assuming that a[j] is different from 1). Now how to find numbers for this more general condition? We can rephrase it as: each number from more general condition has 2 divisors: 1 and itself. So if we print N numbers with 2 divisors in increasing order, that would be a good solution. As you probably know, numbers with 2 divisors are called “prime numbers”. The task reduces to finding first N prime numbers. This can be done via brute force, or via Sieve of Eratosthenes (however, not necessarily to get an AC solution).

Solution 2. Suppose we are given the number N. We can observe that for big enough consecutive numbers, the array is always hungry. For example, we can print 3 * N + 0, 3 * N + 1, 3 * N + 2, …, 3 * N + (N – 1). Magic, isn’t it? Why does it work now? Pick an arbitrary a[i]. The solution would be bad if one of numbers 2 * a[i], 3 * a[i], 4 * a[i] and so on would be in a[] array. However, it will never happen. The smallest multiple from that ones will be 2 * 3 * N = 6 * N. There is not possible to obtain a smallest multiple than that one. On the other hand, the biggest number from a[] array would be 3 * N + N – 1 = 4 * N — 1. Since smallest multiple is bigger than biggest term of the array, it (and of course other multiples bigger than it) will never exist in a[] array. So the above solution is correct also.

327C - Волшебная пятерка

Property: A number is divisible by 5 if and only if its last digit is either 0 or 5.

A first solution: Suppose you’re given a plate S, not so big, so we can iterate all its elements. Can we get the answer? I build a new array sol[]. In explanation, both S and sol will be 1-based. Denote N = size of S. Also, denote sol[i] = the number of ways to delete digits from plate S such as we obtain a magic number which has the last digit on position i. The answer is sol[1] + sol[2] + … + sol[N]. Let’s focus now on calculating sol[i]. If S[i] (digit of the plate corresponding to ith position) is different than 0 or 5, then sol[i] is 0 (see “property”). Otherwise we have to ask ourself: in how many ways I can delete digits in “left” and in “right” of position i. In the “right”, we have only one way: delete all digits (if one digit from right still stands, then the number isn’t ending at position i). Now in the “left”: there are digits on positions 1, 2, …, i – 1. We can either delete a digit or keep it – anyhow he’d do we still get a magic number. So on position 1 I have 2 ways (delete or keep it), on position 2 I have also 2 ways, …, on position i – 1 I have also 2 ways. Next, we apply what mathematics call “rule of product” and we get 2 * 2 * 2 … * 2 (i – 1 times) = 2 ^ (i – 1). Applying “rule of product” on both “left” and “right” I get 2 ^ (i – 1) * 1 = 2 ^ (i – 1). To sum it up: If S[i] is 0 or 5 we add to the answer 2 ^ (i – 1). Otherwise, we add nothing. The only problem remained for this simple version is how we calculate A ^ B modulo one number. This is a well known problem as well, called “Exponentiation by squaring”.

Coming back to our problem: So what’s different in our problem? It’s the fact that we can’t iterate all elements of plate. However, we can use “concatenation” property. We know that if an element is a position i in the first copy, it will also be on positions i + n, i + 2 * n, i + 3 * n, …, i + (k – 1) * n (we don’t call here about trivial case when k = 1). What if iterate only one copy and calculate for all K copies. If in the first copy, at the position i is either 0 or 5, we have to calculate the sum 2 ^ i + 2 ^ (i + n) + 2 ^ (i + 2 * n) + … + 2 ^ (i + (k – 1) * n). By now on, in calculus I'll denote i as i — 1 (it's a simple mathematical substitution). A first idea would be just to iterate each term and calculate it with exponentiation by squaring. However, it takes in the worst case the same complexity as iterating all plate. We need to find something smarter.

2 ^ i + 2 ^ (i + n) + 2 ^ (i + 2 * n) + … + 2 ^ (i + (k – 1) * n) =

= 2 ^ i * 1 + 2 ^ i * 2 ^ n + 2 ^ i * 2 ^ (2 * n) + … + 2 ^ i * 2 ^ ((k – 1) * N) =

= 2 ^ i * (2 ^ 0 + 2 ^ n + 2 ^ (2 * n) + … + 2 ^ ((k – 1) * n)

We reduced the problem to calculate sum S = 2 ^ 0 + 2 ^ n + 2 ^ (2 * n) + … + 2 ^ (X * n).

What’s the value of 2 ^ n * S ? It is 2 ^ n + 2 ^ (2 * n) + 2 ^ (3 * n) + … + 2 ^ ((X + 1) * n). And what you get by making 2 ^ n * S – S ?

2 ^ n * S – S = 2 ^ ((X + 1) * n) – 1

S * (2 ^ n – 1) = 2 ^ ((X + 1) * n) – 1

S = (2 ^ ((X + 1) * n) – 1) / (2 ^ n – 1).

We can calculate both 2 ^ i and S with exponentiation by squaring and the problem is done. For "/" operator, we can use multiplicative inverse (you can read about that and about Fermat Little's theorem, taking care that 10^9 + 7 is a prime number). The time complexity is O(N * logK). Note: that kind of reduction of powers is called “power series” in math.

Alternative solution: For this alternative solution, we don't need to use any special properties of 5. In fact, we can replace 5 by any integer p and still have the same solution. So for now, I shall write p in place of 5.

This suggests a dynamic programming solution: denote dp(x,y) be the number of ways of deleting some digits in the first x digits to form a number that has remainder y (modulo p). For simplicity, we accept “empty” plate be a number that is divisible by p. Writing the DP formula is not difficult. We start with dp(0,0) = 1, and suppose we already have the value dp(x,y). We shall use dp(x,y) to update for dp(x + 1,*), which has two possible cases: either keeping the (x + 1)-th digit or by deleting it. I won't go into much detail here. The answer is therefore dp(N,0).

Clearly, applying this DP directly would time out. For a better algorithm, we resort on the periodicity of the actual plate. The key idea is that, we imagine each digit in the plate as a linear transformation from (x0, x1, .., x(p – 1)) to (y0, y1, y(p-1)). Obviously, (x0, x1, .., x(p — 1)) corresponds to some dp(i, 0), dp(i, 1) .. dp(i, p — 1) and (y0, y1, y(p-1)) corresponds to some (dp(i + 1, 0)), dp((i + 1), 1), ..., dp(i + 1, p — 1) .So we can write X * M(d) = Y, where X and Y are vectors of length p, and M(d) is the matrix of size p * p representing digit d (note that M(d) is independent from X and Y). By multiplying all |a|.K such matrices together, we obtain a transformation from (1, 0, 0, .., 0) to (T0, T1, .., T(p – 1)) where T0 is actually our answer (including the empty plate).

What's the difference? We can group the matrices in groups of length |a|, and lift to the exponent K. That leads to an algorithm with time complexity O(p^3(|a| + log K)), which could be risky. To improve, we should go back to our original DP function and observe that it is actually a linear transformation from (1, 0, 0, .., 0) to (R0, R1, …, R(p – 1)), if we restrict ourselves in the first fragment of length |a|. So instead of multiplying |a| matrices together, we can run DP p times with initial conditions (0, 0, .., 0, 1, 0, .., 0) to obtain the matrix transformation. The overall time complexity becomes O(|a| * p^2 + p^3 log K) .

327D - Башни из кирпичей

In case you want to try some examples on your own, you may play this game, which is the origin of this problem: http://en.wikipedia.org/wiki/Tower_Bloxx

Now back to the analysis :)

The restriction given in the problem poses you to think of building as many Red Towers as possible, and fill the rest with Blue Towers (since there is no profit of letting cells empty, such cells can be filled by Blue Towers). Also, it's quite obvious to see that each connected component (containing empty cells only) is independent from each other, so we shall iterate the component one by one. Denote the current component be S.

Lemma 1 is impossible to build S so that it contains all Red Towers only.

Proof Suppose there exists such a way. Look up the last cell that is built (denote by x). Clearly x is a Red Tower, so at the moment it is built, x must be adjacent to a cell than contains a Blue Tower. However, it's obvious that there's no such cell (if there is, it must belong to S, which is impossible).

As it's impossible to have all Red Towers, it's natural to look up at the next best solution: the one with exactly one Blue Tower, and among them, we need to find the least lexicographic solution. Fortunately, we can prove that such a configuration is always possible. Such proof is quite tricky, indeed:

Lemma 2 Pick any cell b in S. It is possible to build a configuration that has all but b be Red Towers, and b is a Blue Tower.

Proof Construct a graph whose vertices correspond to the cells of S, and the edges correspond to cells that are adjacent. Since S is connected, it is possible to build a tree that spans to all vertices of S. Pick b as the root and do the following:

Build all cells of S blueMove from the leaf to the root. At each cell (except the root), destroy the Blue Tower and rebuild with the Red Tower. To be precise, u can be destroyed (and rebuilt) if all vertices in the subtree rooted at u have already been rebuilt.How can it be the valid solution? Take any vertex u which is about to be rebuilt. Clearly u is not b, and u has its parent to be blue, so the condition for rebuilding can be met. When the building is completed, only b remains intact, while others have been transformed into Red Towers.

So we get the following algorithm: do a BFS / DFS search to find connected components. Then, apply Lemma 2 to build a valid configuration.

327E - Идем по оси

Usually when dealing with complicated problems, a good idea is to solve them for small cases. Let’s try this here.

First case: K = 0. The answer is obviously N! (each permutation of p1, p2, …, pn would be good).

Next case: K = 1. The answer of this one is N! – |L1|. By L1 I denote all routes for which a prefix sum is equal to first lucky number. Obviously, if from all routes I exclude the wrong ones, I get my answer. If we can find an algorithm to provide |L1| in good time, then problem is solved for K = 1.

We can just try all N! permutations. Despite this method is simple, it has complexity O(N!), too much for the constraints.

Suppose we’ve founded a set of positions p1, p2, .., pk such as a[p1] + a[p2] + ..+ a[pk] = U1 (first unlucky number). How many permutations can we make? The first k positions need to be p1, p2, .., pk, but in any order. Hence we get k! . The not used positions can also appeared in any order, starting from k + 1 position. As they are n – k, we can permute them in (n – k)! ways. Hence, the answer is k! * (n – k)! Instead of permuting {1, 2, .., n}, now we need to find subsets of it. Hence, the running time becomes O(2^n). This is still too much.

Meet in the middle. We make all subsets for first half of positions (from 1 to N / 2) and them for second half (from N / 2 + 1 to N). For each subset we keep 2 information: (sum, cnt) representing that there is a subset of sum “sum” containing “cnt” elements. For each (X, Y) from left we iterate in the right. After choosing one element from the left and one from the right we just “split” them. To split 2 states (A, B) and (C, D), the new state becomes (A + C, B + D). But we know that A + C = U1. This comes us to the idea: for each (X, Y) in the left, I check (U1 – X, 1), (U1 – X, 2), … , (U1 – X, K) from the right. For each of them, the answer would be (Y + K)! * (N – Y – K)! . I can store (using any data structure that allows this operations, I suggest a hash) how(C, D) = how many times does state (C, D) appear in the right. So, for a state (A, B) the answer becomes a sum of how(U1 — A, K) * (B + K)! * (N — B — K)!. Doing the sum for all states (A, B), we get our answer. The complexity of this method is O(2 ^ (N / 2) * N).

Final Case: K = 2 The whole "meet in the middle" explanation worthed. We will do something very similar to solve this case. Suppose U1 and U2 are the unlucky numbers. Without loosing the generality, let's assume U1 <= U2.

Following "Principle of inclusion and exclusion" paradigm (google about it if you never heard before) we can write our solution as N! — |L1| — |L2| + |intersection between L1 and L2|. Again, by L1,2 I denote the number of routes which have a prefix sum equal to number U1,2. The |X| is again the cardinal of this set. Basically we can calculate |X| as for K = 1. The only problem remained is calculating |intersection between L1 and L2|.

The |intersection between L1 and L2| is the number of permutations which have a prefix sum equal to U1 and a prefix sum equal to U2. Since U1 <= U2, we can split a permutation from this set in 3 parts:

1/ p1, p2, ...pk such as a[p1] + a[p2] + ... + a[pk] = U1.

2/ pk+1, pk+2, ..., pm such as a[pk+1], a[pk+2], ..., a[pm] = U2 — U1. Note that a[p1] + a[p2] + ... + a[pm] = U2.

3/ The rest of elements until position n.

By a perfectly identical logic from K = 1 case, the number of permutations given those p[] would be k! * (m — k)! * (n — m)!.

So the problem reduces to: find all indices set p1, p2, ... and q1, q2, .. such as a[p1] + a[p2] + ... + a[pn1] = U1 and a[q1] + a[q2] + ... + a[qn2] = U2 — U1. Then, we can apply formula using n1 and n2 described above.

The first idea would be O(3 ^ N) — for each position from {1, 2, .., n} atribute all combinations of {0, 1, 2}. 0 means that position i is 1/, 1 means that position i is in 2/ and 2 means that position i is in 3/ . This would time out.

Happily, we can improve it with meet in the middle principle. The solution is very similar with K = 1 case. I won't fully explain it here, if you understood principle from K = 1 this shouldn't be a problem. The base idea is to keep (S1, S2, cnt1, cnt2) for both "left" and "right". (S1, S2, cnt1, cnt2) represents a subset which has sum of elements from 1/ equal to S1, sum of elements from 2/ equal to S2, in 1/ we have cnt1 element and in 2/ we get cnt2 elements. For a (S1, S2, cnt1, cnt2) state from "left" we are looking in the right for something like (U1 — S1, U2 — U1 — S2, i, j). We get O(3 ^ (N / 2) * N ^ 2) complexity.

Unexpected solution During the round, we saw a lot of O(2 ^ N * N) solutions passing. This was totally out of expectations. I believe if would make tests stronger, this solution won't pass and round would be more challenging. That's it, nothing is perfect. As requested, I'll explain that solution here.

Before explaining the solution, I assume you have some experience with "bitmask dp" technique. If you don't, please read before:

http://community.topcoder.com/tc?module=Static&d1=tutorials&d2=bitManipulation

http://codeforces.com/blog/entry/337

In this problem we'll assume that a is 0-based. For a mask, consider bits from right to left, noting them bit 0, bit 1 and so on. Bit i is 1 if and only if a[i] is in the subset which is in a bijective replation with the mask. For example, for mask 100011101 the subset is {a0, a2, a3, a4, a8}. I'll call from now on the subset "subset of mask". Also, the sum of all elements in a subset will be called "sum of mask" (i.e. a0 + a2 + a3 + a4 + a8). We'll explain the solution based by watashi's submission. 4017915

First step of the algorithm is to calculate sum of each mask. Let dp[i] the sum of mask i. Remove exactly one element from the subset of mask. Suppose the new mask obtained is k and removed element is j. Then, dp[i] = dp[k] + a[j]. dp[k] is always calculated before dp[i] (to proof, write both k and i in base 10. k is always smaller than i). Having j an element from subset of mask i, we can compute mask k by doing i ^ (1 << j). Bit j is 1, and by xor-ing it with another 1 bit, it becomes 0. Other bits are unchanged by being xor-ed by 0. This method works very fast to compute sum of each mask.

From now on, let's denote a new array dp2[i] = how many good routes can I obtain with elements from subset of mask i. Watashi uses same dp[] array, but for making it clear, in editorial I'll use 2 separate arrays. Suppose that CNT(i) is number of elements from subset of mask i. We are interested in how many ways we can fill positions {1, 2, ..., CNT(i)} with elements from subset of mask i such as each prefix sum is different by each unlucky number.

Next step of the algorithm is to see which sum of masks are equal to one of unlucky numbers. We mark them as "-1" in dp2[]. Suppose we founded a subset {a1, a2, ..., ax} for which a1 + a2 + ... + ax = one of unlucky numbers. Then, none permutation of {a1, a2, ..., ax} is allowed to appear on first x positions. When we arrive to a "-1" state, we know that the number of good routes for its subset of mask is 0.

Now, finally the main dp recurrence. If for the current mask i, dp2[i] = -1, then dp2[i] = 0 and continue (we discard the state as explained above). Otherwise, we know that there could exist at least one way to complete positions {1, 2, ... CNT(i)} with elements of subset of mask i. But how to calculate it? We fix the last element (the element from the position CNT(I)) with some j from subset of mask i. The problem reduces now with how many good routes can I fill in positions {1, 2, ..., CNT(i) — 1} with elements from subset of mask i, from which we erased element j. With same explanation of sum of mask calculations, this is already calculated in dp2[i ^ (1 << j)].

The result is dp2[(1 << N) — 1] (number of good routes containing all positions).

Editorial has been made by me and ll931110.

The authors of the problems:

Div.2 A & Div.2 B — me

Div.2 C & Div.2 D & Div.2 E — ll931110

Codeforces Round #190 — Editorial

By cgy4ever, 10 years ago, In EnglishUpdate 1 Added links to my code.

Update 2 The links to my code seems not work, so I push my codes on github, and you find all of them here: https://github.com/cgy4ever/cf190

Update 3 Fixed my solution of Div1-C (Div2-E). In this problem, we must find centroid of tree instead of center of tree. Thanks RomaWhite for pointing this out and provide test case. And it seems that many solutions can pass the system test will fail on his test case (including my model solution). I feel apologetic for the weak test cases and wrong solution.

Update 4 Reformat the passage, I hope it would looks better.

322A - Ciel and Dancing

Let's define remainNew = # of people haven't danced before. So at beginning remainNew = n+m, and we have:

During the 1st song, remainNew must decreased by at least 2. (Because the boy and girl must haven't danced before.)During the k-th (k>1) song, remainNew must decreased by at least 1. (Because one of the boy or girl must haven't danced before.) So the answer must be no more than n+m-1.And it's not hard to construct one schedule get this maximal possible answer:

1 11 2...1 m2 13 1...n 1322B - Ciel and Flowers

If there are no "mixing bouquet" then the answer will be r/3 + g/3 + b/3. One important observation is that: There always exist an optimal solution with less than 3 mixing bouquet.

The proof is here: Once we get 3 mixing bouquet, we can change it to (1 red bouquet + 1 green bouquet + 1 blue bouquet)

So we can try 0, 1, 2 mixing bouquet and make the remain 3 kind of bouquets use above greedy method. Output one with largest outcome.

322C - Ciel and Robot 321A - Ciel and Robot

Note that after Ciel execute string s, it will moves (dx, dy). And for each repeat, it will alway moves (dx, dy). So the total movement will be k * (dx, dy) + (dx[p], dy[p]) which (dx[p], dy[p]) denotes the movement after execute first p characters. We can enumerate p since (0 <= p < |s| <= 100), and check if there are such k exists.

Note that there are some tricks:

We can divide dx or dy directly because they both can become zero.Another trick is that k must be non-negative.Many people failed on this test case (which no included in the pretest):

-1 -1UR322D - Ciel and Duel 321B - Ciel and Duel

We have 3 solutions to this problem:

= 1. greedy =

There are 2 cases: we killed all Jiro's cards, or not.

If we are not killed all of Jiro's cards, then:

We never attack his DEF cards, it's meaningless.Suppose we make k attacks, then it must be: use Ciel's k cards with highest strength to attack Jiro's k cards with lowest strength, and we can sort the both k cards by strength to make attack one by one. (If there are an invalid attack, then we can't have k attack)If we kill all Jiro's card: Then for all DEF cards, we consider it from lower strength to higher: if its strength is L, then we find a card of Ciel with strength more than L (If there are many, we choose one with lowest strength). Then we can know if we can kill all DEF cards. And then we choose |x| cards with highest strength of Ciel, try to kill Jiro's remain card.

Note that if we could kill all ATK cards, the order doesn't matter: the total damage will be (sum of strength of Ciel's remain card) — (sum of strength of Jiro's remain card).

= 2. DP =

Above solution looks complicated, can we solve it with few observation? Yes we can. The only observation is that:

There always exist an optimal solution that: If Ciel's two card X's strength > Y's strength, and X, Y attacks on A and B with the same position, then A's strength > B's strength. We already use this observation in above solution.

Then what can we do? Yes, we can sort all Ciel's card, all ATK card of Jiro, all DEF card of Jiro.

Let's DP[pCiel][pATK][pJiro][killAll] be the state that next unconsidered card of Ciel, Jiro's ATk, Jiro's DEF are pCiel, pATK, pJiro, and killAll=1 if and only if we assume at the end we can kill all Jiro's card.

Then we have 4 choice:

Skip, this card don't attack.Attack on the next ATK card.Attack on the next DEF card.Assume Jiro has no cards and make a direct attack.= 3. MinCostMaxFlow =

Well, what if we want to solve this problem with no observation?

Ok, if you are good at construct flow algorithm, it's an easy thing to solve this by flow.

Please see my solution for details. It just considered the matching relationship.

322E - Ciel the Commander 321C - Ciel the Commander

This is a problem with construction on trees. And for these kind of problems, we usually use two method: up-down or down-up. So we have 1 solution for each method:

= 1. up-down construction =

Suppose we assign an officer with rank A at node x. Then for two distinct subtree rooted by x, says T1 and T2: There can't be any invalid path cross T1 and T2, because it is blocked by node x. (It's clear that we can't make 2 rank A officer.)

So we can solve these subtree independently: the only different is that we can't use rank A anymore.

Then the question is: which node should x be? It could be good if any subtree will has a small size. And if you have the knowledge of "centroid of tree", then you can quickly find that if x be the centroid of this tree, the subtree's size will be no more than half of the original tree. So we only needs about log2(n) nodes and 26 is enough.

= 2. down-up construction =

The above solution involves the concept of "centroid of tree" but you might not heard about that, don't worry, we have another solution can solve this problem without knowing that, and it's easier to implement.

Suppose we choose 1 as the root and consider it as a directed tree, and on some day we have the following problem:

We have some subtree rooted at T1, T2, ..., Tk, and they are already assigned an officer, we need to assign an officer to node x and link them to this node. Well, a normal idea is: we choose one with lowest possible rank.

The rank of x should satisfy:

If there are a node with rank t exposes at Ti and a node with t exposes at Tj (i!=j), then rank of x must be higher than t. (Otherwise the path between them will be invalid.)If there are a node with rank t exposes at Ti, then the rank of x can't be t.So we can use this rule to choose the lowest possible rank. But can it passes? Yes, it can, but the proof is not such easy, I'll introduce the main idea here:

We assign each node a potential: p(x) = {2^('Z' — w) | w is exposed}. For example, if 'Y' and 'Z' are exposed, then p(x) = 1 + 2 = 3.We can proof p(x) <= |# of nodes of the subtree rooted by x| by proof this lemma: When we synthesis x with T1, T2, ..., Tk, p(x) <= 1 + p(T1) + ... + p(Tk). It's not hard to proof, but might have some cases to deal with.321D - Ciel and Flipboard

For this problem we need a big "observation": what setup of "flips" are valid? What means set up of "flips", well, for example, after the 1st step operation of example 1, we get:

1 1 01 1 00 0 0It means the left top 2x2 cells are negatived.

Given a 0-1 matrix of a set up of "flips", how can you determine if we can get it by some N x N (I use N instead of x here, it don't make sense to write something like x x x.) flips.

To solve this problem, we need the following observation:

For any i, any j<=x: setUp[i][j]^setUp[i][x]^setUp[i][j+x] will be 0.For any i, any j<=x: setUp[j][i]^setUp[x][i]^setUp[j+x][i] will be 0.It's quite easy to proof than find that: after each operation, there always be 0 or 2 cells lay in {setUp[i][j], setUp[i][x], setUp[i][j+x]} or {setUp[j][i], setUp[x][i], setUp[j+x][i]}.

So what? Well, then there must be no more than 2^(N*N) solutions, since if we determine the left top N x N cells, we can determine others by above equations.

And then? Magically we can proof if one set up meets all above equations, we can get it. And the proof only needs one line: think the operation as addition of vectors in GF2, then we have N*N independent vector, so there must be 2^(N*N) different setups we can get. (Yes, I admit it need some knowledge, or feeling in linear algebra)

Then the things are easy: we enumerate {setUp[1][N], setUp[2][N], ..., setUp[N][N]}, and determine others by greedy. (More detailed, by columns.)

You can find details in my code.

321E - Ciel and Gondolas

This problem may jog your memory of OI times (if you have been an OIer and now grows up, like me). Maybe some Chinese contestants might think this problem doesn't worth 2500, but DP optimization is an advanced topic in programming contest for many regions. It's quite easy to find an O(N^2 K) DP:

dp[i][j] = max{ k | dp[i-1][k] + cost(k+1...j)}(dp[i][j] means the minimal cost if we divide 1...j foxes into i groups)

There are many ways to optimize this kind of dp equation, but a large part of them based one the property of cost function. So we need to find some property independent of cost function.

Let opt[i][j] = the smallest k such that dp[i][j] = dp[i][k] + cost(k+1...j) Then intuitively we have opt[i][1] <= opt[i][2] <= ... <= opt[i][n]. (I admit some people don't think it's intuitively correct, but it can proof by some high school algebra)

Then how to use this stuff?

Let n = 200 and suppose we already get dp[i][j] for i<=3 and now we have to compute dp[4][j]: If we first compute dp[4][100], then we can have opt[4][100] at the same time.

And when we compute dp[4][1] ... dp[4][99], we know that the k must lay in 1...opt[4][100]. When we compute dp[4][101] ... dp[4][200], we know that k must lay in opt[4][100]...n.

Let's formalize this thing: We use compute(d, L, R, optL, optR) to denote we are computing dp[d][L...R], and we know the k must be in range optL...optR.

Then we have:

compute(d, L, R, optL, optR) = 

	1. special case: L==R.

	2. let M = (L+R) / 2, we solve dp[d][M] as well as opt[d][M]. Uses about (optR-optL+1) operations.

	3. compute(d, L, M-1, optL, opt[d][M])

	4. compute(d, M+1, R, opt[d][M], optR)One can show that this solution will run in O(NlogN * K). Note that we don't need opt[d][M] at the center of interval optL...optR. We can proof at each recursive depth, the total cost by line 2 will be no more than 2n. And there are at most O(log(n)) depths.

Codeforces Round #189 — Editorial

By havaliza, 10 years ago, In English320A - Magic NumbersAlthough the input number is very small, solving the problem for arbitrary length numbers using strings is easier. It's easy to prove that a number meeting the following conditions is magical:

The number should only consist of digits 1 and 4.The number should begin with digit 1.The number should not contain three consecutive fours (i.e. 444).Here is a sample implementation in C++:

#include <iostream>#include <string>

using namespace std;

bool is_magical(string number) {	for (int i = 0; i < (int)number.size(); i++)		if (number[i] != '1' && number[i] != '4')			return false;

	if (number[0] == '4')		return false;

	if (number.find("444") != number.npos)		return false;

	return true;}

int main() {	string number;	cin >> number;

	if (is_magical(number))		cout << "YES" << endl;	else		cout << "NO" << endl;

	return 0;}320B - Ping-Pong (Easy Version)Imagine the intervals as nodes of a graph and draw directed edges between them as defined in the statement. Now answering the second query would be trivial if you are familiar with graph traversal algorithms like DFS or BFS or even Floyd-Warshall!

Here's an implementation using DFS: 3951145

And here's an implementation using BFS: 3947426

Finally an implementation using Floyd-Warshall: 3945330

319A - Malek Dance ClubSolving this problem was easy when you modeled the assignment with two sets of points numbered from 0 to 2n - 1 (inclusive) paired with 2n line segments. Each line segment corresponds to a dance pair. And each pair of intersecting lines increase the complexity by one.

Imagine you now the solution for binary string x. Now we want to calculate the answer for 1x and 0x easily. Look at the figure below:

 

The figure shows what happens in a simple case. Whenever you append 0 before x the same structure appears twice in the result. But whenever you append 1 before x the same structure appears twice but the first half of points in right column are swapped with the second half. This increases the number of intersections by size of first half times size of the second half.

So if x has length n and f(x) is the complexity of the assignment then we have:

f(0x) = 2f(x)f(1x) = 2f(x) + 22nAn interesting fact is that f(x) is equal to x2n - 1.

319B - Psychos in a LineWill be fixed :)

Let's find the murderer! Well, if you look close you see that each psycho is murdered by the nearest psycho on his left which has a greater id.

Now let ti be the number of the step which i-th psycho in the line is murdered (not the psycho with id equal to i). Assume j-th psycho in the line be the nearest psycho with a larger id than i-th psycho in the line in his left. As we know j-th psycho kills the i-th psycho. We also now that this happens when all psychos between j and i have been killed. So ti = max(tj + 1, ..., ti - 1) + 1.

Now we have a simple O(n2) solution using the above observations. To make things run faster you should be familiar with a classic problem. This problem asks to find the nearest greater element to the left of each element in a array. This problem has a O(n) solution. You can solve it yourself or read about it here.

After knowing about all these things it wouldn't be hard to figure out a way to solve this problem efficiently. Here is a cute implementation of what is described above: 3945963

319C - Kalila and Dimna in the Logging IndustryThis problem is equal to finding the minimum cost to cut the last tree completely. Because any cutting operation can be done with no cost afterward. Let dpi be the minimum cost to cut the i-th tree completely. It's easy to figure out that we can calculate dpi if we know the index of the last tree which has been cut completely (j-th tree). Knowing this dpi would be equal to dpj + bjai. So dpi = minj = 1..i - 1(dpj + bjai).

Using the above information the problem has an easy dynamic programming solution in O(n2). There's a known method which can be used to improve recursive relations with similar form. It's called Convex Hull Trick. You can read about it here.

319D - Have You Ever Heard About the Word?TODO

319E - Ping-PongTODO

Codeforces Round #188 (analysis)

By Rei, 10 years ago, translation, In EnglishProblem analysis v 0.9.

318A - Even Odds

In this problem we need to understand how exactly numbers from 1 to n rearrange when we write firstly all odd numbers and after them all even numbers. To find out which number stands at position k one needs to find the position where even numbers start and output either the position of the odd number from the first half of the sequence or for the even number from the second half of the sequence.

318B - Strings of Power

In the heavy metal problem one needs to find the number of the substrings in the string S with a given prefix A and given suffix B. If we mark black all the starting positions of the entries of the string A in S, and white all the starting positions of the entries of the string B, then we come to the following problem: count the number of pairs <black position, white position> (in this order). To solve this it is enough to iterate from left to right counting the number of the passed black positions. Meeting black position we increment this number by one, meeting white position we add to the answer the number of pairs with this white position, which is exactly our memorized number of the already passed black positions.

317A - Perfect Pair

318C - Perfect Pair

This problem were more about accuracy then about ideas or coding. It is important to not forget any cases here.

On each step we replace one of the numbers x, y by their sum x + y until the pair becomes m-perfect (id est one of them becomes not lesser than m). It is clear that one sould replace lesser number from the pair x, y. Indeed lets say the pair x1 ≤ y1 dominates the pair x2 ≤ y2, if y1 ≥ y2 and x1 ≥ y2. In this case if one can get m-perfect pair from x2, y2 by certain sequence of actions, then one can get m-perfect pair from x1, y1 by the same or shorter sequence of actions. If x ≤ y, then the pair x + y, y dominates the pair x + y, x. Hence path from x + y, y to m-perfect is not longer than from x + y, x, and we may assume that we choose exactly this pair.

Consider following cases:

x ≤ 0, y ≤ 0 In this case our numbers do not increase in the process. Hence either the pair is alredy m-perfect or it will never be.

x > 0 and y > 0 In this case for each m pair will after several steps become m-perfect. To count precise number of those steps one needs to launch emulation. If x > 0 and y > 0, then pair "grows exponentionaly>> (more formally: easy to show that starting from secnd step sum x + y grows in at least 3 / 2 times each step) and emulation works pretty fast. However in the case x < 0 and y > 0 (or vice versa) pair might change very slowly. Most bright example is x =  - 1018, y = 1. Thus one needs to count number of steps until both numbers becomes positive before launching emulationt. For x < 0 and y > 0 number of those steps is exactly .

317B - Ants

318D - Ants

One may reformulate the problem ass follows. Non-negative integers A(x, y) are placed in the vertices of two-dimensional lattice  We may imagine this construction as a function . On each step for each vertex P = (x, y) with A(x, y) ≥ 4 we perform operation φP, which substracts 4 from A(x, y) and adds 1 to A(x, y - 1), A(x, y + 1), A(x - 1, y), A(x + 1, y). We may think that operation φP applies to the whole function A. We need to find values of A after the iterations stops.

Key idea is that operactions φP and φQ for all points P and Q commutes, that is φP(φQ(A)) = φQ(φP(A)). This means that the order of operations is unimportant. In particular, we may assume that from each given vertex run all possible four-groups of ants and not only one. After this observation one may run full emulation of the process. As an exercise contestants may check that ants will never leave square 200 × 200 with center in the origin 0 with given constraints.

317C - Balance

318E - Balance

In this problem we need to find 2n2 transfusions from initial configuration to the desired one. First of all we propose the following: if in each connected component overall volume of the water in initial configuration is the same as in desired one, then answer exist. We call the vessel ready, if current volume of its water equals desired one. Let us describe solution which is probably easier to code. We will make vessels ready one by one. Consider the pair of non-ready vessels s and t (there is more water in s than desired, and less water in t than desired), such that they are connected by the path P, and if one transfuses d litres from s to t then one of the vessels becomes ready. Now we need to find a way to transfuse d litres by path P from s to t. One may write recursive function pour(s, t, d) for this aim. Let t' stand before t in this path, then function works as follows: transfuses from t' to t as many water as possible (not more than d of course), then calls pour(s, t', d) and on the final step transfuses from t' to t all that left. It is easy to check that all such transfusions are correct. This algorithm makes 2len transfusions on the path of length len, so total number of transfusions is not greater than 2n2.

317D - Game with Powers

For each numner x denote sequence of its powers within [1..n] as Pow(x): 

Game proceeds as follows: on each step one player takes still available number x from 1 to n and prohibits whole set Pow(x). Who can't make his turn loses.

This game may be decomposed in the sum of lesser games. Indeed, lets call number x simple (and corresponding sequence Pow(x) simple), if it is not a power of any number y < x. Then: 1. for each  there is simple x, such that ; 2. for each simple distinct x and y sets Pow(x) and P(y) do not intersect. Indeed, for a given k there is exactly one simple x such that k is power of x. This may be showed from fundamental theorem of arithmetic: if  and d = gcd(α1, α2, ..., αn), then .

Hence set [1..n] decomposes into primitive sets Pow(x), on each of those Pow(x) game proceeds independetly. Now one may use Sprague–Grundy theory to see that mexx of our game is just xor of all mexx of games on simple Pow(x). For fixed x, if Pow(x) = {x, x2, ..., xs}, then mexx of the game on Pow(x) depends only on s, but not on x. In our case s runs from 1 to 29, mexx for all such s may be directly precalculated. Now it is enough to find numbers q(s) of simple x with a given size of Pow(x) equal to s (actually we are interested in parity of q(s) not in q(s) itself).

Our constraints allows to do it directly: run x from 2 to , if it is not crossed out, determine the size Pow(x) [increment corresponding q(s)], and cross out all numbers from Pow(x).

This cycle finds all simple sequences of length at least 2. Quantity of non-crossed numbers is the number of all simple sequences of length 1. Now it is enough to look at parities of q(s) and xor coressponding mexx.

However one may find all q(s) for . Indeed lets look at the number  and sequence {x, x2, x3, x4, ..., xs}. This sequence is not simple iff it is containd in some larger simple sequence. But number of subsequenes of size s in a given sequence of size t > s is easy to find: it is just [t / s]. Recalling that simple sequences do not intersect one gets the reccurent formula:

.

Now it is easy to find all q(s) from q(29) to q(1).

Remark: while coding it is important to remeber simple number x = 1.

317E - Princess and Her Shadow

In this problem princess Vlada should simply catch the Shadow. Here is the idea of a solution. If there is only one tree, then using it as a barrier to the shadow it is not hard to catch the shadow. Similar technique works if Vlada and Shadow are far from the square where all the trees grow. But what can she do in the dark depths of the forest? If there is no path at all between Vlada and Shadow, then there is no way to catch it. Otherwise consider a shortest path from Vlada to the Shadow and make Vlada follow it. This path gives Vlada a queue of the steps that she should perform. Additionaly if shadow moves, then we add her move to the queue (simply speaking Vlada follows the shadow). This is where the algorithmic part ends. Now we state that either Vlada catches the shadow in the desired number of steps, or steps out of the "forest square". To proof this we note that the length of the path between Vlada and Shadow may only decrease. And if it does not decrease long enough, then once in k steps (k is the length of the path) Vlada and Shadow shifts at the same vector over and over, and at some moment leaves the "forest square". Note that if the trees allow our heroes to step out of the "forest square" at the beginning, then we may just get them out from the start. But taking this approach we still need to catch the Shadow in a "labyrinth forest".

Apologies for the delay. There are probably misprints and mistakes here (thousands of them!), please feel free to point them out.

Codeforces Round #187 tutorial

By Sereja, 10 years ago, translation, In English315A - Sereja and BottlesJust check for each bottle, can I open it with another. In this task can pass absolutely any solutions.

315B - Sereja and ArrayWe will support all of the elements in the array, but also we will supprt additionally variable add: how much to add to all the elements. Then to add some value to every element we simply increase the add. In the derivation we deduce the value of the array element + add. When you update the item we put to a value, value that you need to put minus the current value of add.

314A - Sereja and ContestNote that if we remove some of the participants, we never remove the participants with lower numbers as theirs amount will only increase. So just consider the sequence of all the participants, and if the participant does not fit we delete him.

314B - Sereja and PeriodsIt is clear that we can use greedy algorithm to look for the number of occurrences of the 2nd string in the first string, but it works too slow. To speed up the process, you can look at the first line of the string that specifies the second period. And the answer is divided into how many string you need to set the second string. Next, we consider our greedy algorithm. We are going by the first string, till we find the first character of the second string, then the second, third and so on until the last, then again find the first, second, and so the cycle. It is clear that if we stand in the same twice in a state in which the positions in the first string corresponds to one character string that determines the period and the position of the second string are the same, then we obtain the period. When we find this period, we can just repeat it as many times as possible.

To better understand, I advise you to read any accepted solution.

314C - Sereja and SubsequencesIt is clear that we need to calculate the sum of the products of elements of all the different non-decreasing subsequences of given sequence. Let's go through the sequence from left to right and maintain the array q[i]: what means the sum of all relevant sub-sequences, such that their last element is equal to i. Clearly, if the next number is x, then you need to put q[x] = sum (q[1] + q[2] + ... + q[x]) * x + x. The answer to the problem is the sum of q[i]. To find all the amounts you can use Fenwick tree.

314D - Sereja and Straight LinesRoll all at 45 degrees using the transformation: (x, y) -> (x ', y'): x '= x + y, y' = x-y. Next you need to place two lines parallel to the coordinate axes. Sort the points by the first coordinate. Next, we use a binary search for the answer. May we have fixed a number, you now need to check whether it is enough or not. Note that now we need to put two strips of width 2 * fixed amount that they would have to cover all the points. Suppose that some point should be close to the left side of the vertical strip, then for all points that do not belong to the strip we find the minimum and maximum second coordinate. If the difference between the found coordinates no more then 2 * fixed quantity, the strip can be placed, otherwise — no.

soon...

Analysis of Codeforces Round #186 (Div. 2)

By Furko, 10 years ago, translation, In English313A - Ilya and Bank Account

This problem is the easiest one. You need to use only div and mod functions. If n>0, then answer is n, else you need to delete one of two digits.

For better understanding you can look at solution.

313B - Ilya and Queries

Precalculate some array Ai, that Ai = 1, if si = si + 1, else Ai = 0. Now for any query (l, r), you need to find sum of Ai, that (l ≤ i < r). It is standart problem. For solving this problem you can precalcutate some another array Sum, where Sumi = A1 + A2 + ... + Ai. Then sum of interval (l, r) is Sum_r — Sum_{l-1}.

For better understanding you can look at solution.

313C - Ilya and Matrix

At the start sort array. Let Ci — number of times of entering the number in Aі optimal placement. Answer is sum of Ai * Ci for all i (1 ≤ i ≤ 4n). If we look at the array C, we can see that for maximal element C = n + 1 (for array with size 4n), then for second, third and fourth maximum elements C = n. On this basis we can see, that for array with non-increasing order answer calculate like Sum(1, 1) + Sum(1, 4) + Sum(1, 16) + ... + Sum(1, 4n). So, for solve this problem you have to know only sort.

For better understanding you can look at solution

313D - Ilya and Roads

To solve this problem you need to use dynamic programming. Let Fulli, j — minimal cost of covering interval (i, j). Fix left border and move right. You can solve this subtask with complexity O(nm) or O(nmlogn). Now we need to solve the standart problem of dynamic programming. Cover K points with intervals that have not intersect. This problem with square dynamic. dpi, j — minimal cost of covering j-points, if you look some prefix length i. Answer for all problem is minimal integer from dpi, j, (k ≤ j ≤ n).To solve second part:

1) dpi + 1, j = min(dpi + 1, j, dpi, j) — skip point with number i + 1

2) dpk, j + len = min(dpk, j + len, dpi, j + Cost); Cost — cost of interval with length len, that ending at point k. We precalculate Cost at first part of solution.

For better understanding you can look at solution

313E - Ilya and Two Numbers

Author solution is harder than that which is offered by MrDindows. It is solution of MrDindows.

1) Get the number of our sequences in sorted by frequencies. Thus from the first sequence (hereinafter — the first type) — in a direct order from the second — to the contrary.

2) These numbers are put on the stack, where if, recording onto the stack of the second type, we find the number at the top of the first type, then this pair of extract and add to the answer.

3) At the end, obviously the stack we can find a number of properties of the second type and the first bottom — on. Then their grouping in response pairs with the start and end.

For better understanding you can look at solution.

Sorry for waiting.

Codeforces Round #185 Editorial

By lydrainbowcat, 10 years ago, In English311A - The Closest Pairhttp://codeforces.com/blog/entry/7787

311B - Cats TransportP.S. I feel very sorry that I thought it was a traditional DP problem with only 800B code and didn't realize some participants were not familiar with such kind of problems, so I said it was easy.

Let a[i] be the distance from hill 1 to hill i, s[i]=a[1]+a[2]+…+a[i].

Firstly, we sort the cats by (Ti-a[i]). Then we can divide the cats into P consecutive parts, and plan a feeder for each part. Dynamic Programming can solve this problem.

Let f[i,j] indicates the minimum sum of waiting time with i feeders and j cats.

f[i,j] = f[i-1,k]+a[j]*(j-k)-s[j]+s[k] = a[j]*j-s[j] + f[i-1,k]+s[k]-a[j]*k

That’s O(PM^2). It’ll get TLE.

Let p>q, if p is "better" than q, then:

f[i-1,p]+s[p]-a[j]*p>f[i-1,q]+s[q]-a[j]*q

(f[i-1,p]+s[p])-(f[i-1,q]+s[q])>a[j]*(p-q)

g[p]-g[q]>a[j]*(p-q)

So we can use Convex hull trick with a queue. Then we get O(MP), which can pass the problem.

311C - Fetch the TreasureFirstly, we solve such a problem: if we can go exactly k,k1,k2……or kp cells forward each step, what cells can we reach?

We divide the H cells into k groups: Group 0,1……k-1. The i-th cell should be in Group (i mod k).

If we reach Cell x in Group (x mod k), we can also reach Cell (x+kj , 1<=j<=p) in Group ((x+kj)mod k).If we reach Cell x in Group (x mod k), we can also reach Cell (x+k) in the same group.Let D[i] be the minimum cell we can reach in Group i. Then we can reach all the cells which number are bigger then D[i] in Group i.

Regard the groups as points. Regard k,k1,k2……kp as edges. And use a Shortest-Path Algorithm to calculate all D[i].

Notice that there are at most 20 operations of type 1, we are able to run such an algorithm after each of these operations. The total time complexity is O(20*k*20*log(k)) with Dijkstra.

Secondly, we build a binary-heap to solve operations of type 2 and 3.

Type1 – If a D[i] becomes smaller, we put the new cells we can reach into the heap.Type2 – Decrease a value of a node in the heap, or a cell in the “Treasure Cell” array.Type3 – Ask the biggest node in the heap and delete it.These are basic operations of binary-heap. The time complexity is O(NlogN). In C++, you can also use priority_queue from STL and lazy-tags. So we can solve the whole problem in O(400klogk+NlogN).

311D - Interval Cubinghttp://codeforces.com/blog/entry/7787

311E - Biologisthttp://codeforces.com/blog/entry/7847

312A - Whose sentence is it?We only need to find out if “miao.” is a prefix of the sentence, and if “lala.” is a suffix of the sentence. Pay attention to the situation when both conditions are satisfied.

312B - Archerhttp://codeforces.com/blog/entry/7847

Editorial Codeforces Round #184 (Div.2)

By gridnevvvit, 10 years ago, translation, In English305A - Strange AdditionAll you have to do is implement following algorithm:

If we have numbers 0 or 100, we take them to needed subset.If we got number greater than 0 and less than 10, we take it.If we got number  divisible by 10 we take it.In case we have no numbers of second and third type, we take a number  that is not divisible by 10Solution

305B - Continued FractionsThere are at most two ways to represent rational fraction as continued. Using Euclid algorithm you can do that for  and then check equality of corresponding ai.

Solution

305C - Ivan and Powers of TwoFirst of all, let's carry over all powers of two in the following way: if we have ai = aj, i ≠ j, carry 1 to ai + 1. Now as all of ai are distinct, the answer is max(ai) — cnt(ai) + 1, where max(ai) — maximal value of ai,cnt(ai) — size of a

Solution

305D - Olya and GraphFirst of all let's consider a graph on a number line. It's neccesary to have edges i -  > i + 1(first type). Also you can edges like i -  > i + k + 1 (second type). Other edges are forbidden. This allows us to understand whether the answer is 0 or not. Also answer is 0 when all edges of second type doesn't intersect, considering them to be segments of number line, except when k ≥ n - 1 — in this case answer is 1. Now we know that answer != 0. Frow all edges we have let's use only second type edges. If there aren't any of this edges we can add 1 to the answer, because of possibility of adding 0 edges to graph. For every vertex i, that has possibility of adding second type edges, let's add to answer 2cnt, cnt — amount of vertexes on [i, min(i + k, n — k — 1)] without edges of second type out of them. Also it is necessary for all the second type edges to start in this segment.

Solution O(n + m) Solution O(m + log(n))

305E - Playing with StringLet's consider substring of s s[i... j], that all characters from i to j are palindrome centers, and i - 1, j + 1 are not. Every such substring can be treated independently from the others, and as we don't need to know it'sstructure let's consider only it length len. Let's calculate grundy[len] — Grundy function. If we want to cut character at position i 0 ≤ i < len then our game splits in to independent ones: first will have length i - 1, second — len - i - 2, as s[i - 1] and s[i + 1] are not centers of palindrome any more.

Solution

Codeforces Round #183 Editorial

By MinakoKojima, 10 years ago, In EnglishOverview ...。。。(; Д ;) 。

Tutorial ...Problem 2A. Pythagorean Theorem IIMath, implementation

This problem can be solve by brute-force, but it come up with a nicer solution if we involve some math.

Check the following article if you are interested.

http://en.wikipedia.org/wiki/Pythagorean_triple#Generating_a_triple

Problem 2B. CalenderMath, implementation

This problem can be solve by brute-force, but it come up with a nicer solution if we involve some math.

Check kabar's code if you are interested.

http://codeforces.com/contest/304/submission/3715756

Problem A. Lucky Permutation TripleMath, Constructive algorithms, Congruent

when n is odd, A[i] = B[i] = iwhen n is even, there is no solution. So why? Because:S = \Sum_{i=0}^{n-1} i = n/2 (mod n) but 2*S = 0 (mod n)

See also at:

http://codeforces.com/blog/entry/7499#comment-133446

Problem B. Rectangle Puzzle IIMath, Geometry

Give you n, m, x, y, a, b.

Find a maximum sub-rectangle within (0, 0) — (n, m), so that it contains the given point(x, y) and its length-width radio is exactly (a, b). If there are multiple solutions, find the rectangle which is closest to (x, y). If there are still multiple solutions, find the lexicographically minimum one.

Split the problem into x-axis and y-axis. Then you can solve the sub tasks in O(1).

d = gcd(a,b)a /= db /= dt = min(n/a, m/b)a *= tb *= tBe careful, when the length is outside the original rectangle.

Problem C. Minimum ModularMath, Graph theory, Brute-force, Congruent

It is hard to solve this problem at once, so at first, let us consider on k = 0, this easier case can be solved by enumerate on the ans. Let us define a bool array diff[], which diff[x] is weather there are two number, ai, aj, such that abs(ai - aj) = x.

So ans is legal <=> diff[ans], diff[2*ans] … are false.

The time-complexity O(n2 + mlogm). Here m is the maximum ai.

Consider on k > 0, we need to know how many pairs which has difference x. Store them invector<pair <int, int> > diff[x];

Then use a dsu to maintain the how many a_i are congruent when enumerate on the ans.

Problem D. Rotatable NumberMath, Number theory

(Coming Soon...)

http://codeforces.com/blog/entry/7499#comment-133342

Problem E. Random RankingMath, Probability

(Coming After D...)

http://codeforces.com/blog/entry/7499#comment-133488

Codeforces Round #182 tutorial

By Sereja, 10 years ago, translation, In English302A - Eugeny and ArrayIf the length of the given segment is even and count of 1 in input is not lower then half of the length of the segment and count of -1 in the input is not lower then half of the length of the segment so we have answer 1, otherwise 0.

302B - Eugeny and Play ListFor each song we will count moment of time, when it will be over (some sums on the prefixes, for example). Further, we will use binary search of two itaratos method to solve the problem.

301A - Yaroslav and SequenceUsing dfs we will find number of numbers that we can set as positive. Note that we can either set all of the numbers as positive or leave one number(any) as negative. If we can obtain all numbers as positive, we just return sum of modules of the numbers, but if we cannot we will count the same sum and will subtract minimal modular value multiple 2 from sum.

301B - Yaroslav and TimeWe will use binary search to find the answer. Further we will use Ford-Bellman algorithm. On each step we will have an array of maximum values on timer, when we stand in some point. On in transfer we will check: will our player stay alive after travelling beetwen points. If we can make transfer, we will update value of the final destination point. Becouse of a_i<=d and integer coordinates we haven't optimal cycles, and solution exists.

301C - Yaroslav and AlgorithmWe will use ? as iterator. In the begin we will set ? before the number. Then we will move it to the end of the string. Then we will change ? to ?? and we will move it to the begin, while we have 9 before ??. If we have another digit, we just increase it, and finish the algorithm. If we have ?? at the begin, we change it to 1, and end the algorithm.

Look for accepted solutions for better understanding.

301D - Yaroslav and DivisorsLets add all pair: (x,y) ((d[x]%d[y]==0) || (d[y]%d[x]==0)) to some lest. We can count such pairs using Eretosphen algorithm. Here will be O(n*log(n)) sych pairs using fact, that we have permutation. We will sort all this paairs using counting-sort. Also we will sort given in input intervals. For each given interval we should count number of pairs that countained in given them . Such problem we can solve using Fenvik tree. On each step we will add segments(that are sorted by right side). On each step we will update Fenfick-tree that count number of added pairs on some suffix. Using such tree if it easy to count the answer. So we have O(n*log^2(n)) solution.

301E - Yaroslav and ArrangementsWe will build the needed arrays sequentially adding numbers. Let's look at what states we need. First, it is obvious that you need to keep the number of ways to build an array of already added numbers, secondly you need to know the total amount of added numbers. Now let's look at what happens when we add a new number (that is greater than all of the previous in a certain amount). It is clear that the added numbers should stand between the numbers 1 to less. In this case, if we put two new numbers in a row, between them should stand more (since we already have placed less). It is obvious that you need to cover all the previous numbers (among which must stand newly added). Thus, we have another state: the number of integers between which we should put the new ones. Thus we have the dynamics of the four parameters: dp [all] [ways] [lastnumber] [counttoadd]. Transfer. It is clear that you need to add at least counttoadd numbers, but how will this affect the number of ways to arrange the numbers? It's simple. Suppose we added number x, then the number of ways to be multiplied by the value of Q (x-counttoadd, counttoadd), where Q (x, y) — the number of ways to assign the same x balls in y different boxes. Q (x, y) = C (x + y-1, y-1) where C (x, y) — binomial coefficient.

Editorial Codeforces Round #181 (Div.2)

By gridnevvvit, 10 years ago, translation, In English300A - ArrayIn this problem you just need to implement following algorithm. Split input data into 3 vectors: first will contain negative numbers, second positive numbers, third zeroes. If size of first vector is even move one number from it to the third vector. If second vector is empty, then move two numbers from first vector to the second vector. This solution works in O(n).

Аuthor's solution

300B - CoachInput data represents a graph. If there is a connected component with at least 4 vertexes, then answer is  - 1. Every connected component with 3 vertexes is a complete team. Other teams are made from 1 or 2-vertex components. If amount of 2-vertex components is greater than 1-vertex answer is  - 1. Otherwise match 2-vertex components with 1-vertex. If there are some 1-vertex components left then split them into groups of three. This algorithm works in O(n + m). Also you could implement O(n4) solution.

Аuthor's solution

300C - Beautiful NumbersLet's MOD = 1000000007. Let's precalc factorial values modulo MOD. fact[i] = i!%MOD, . Let i be an amount of digits equal to a in current excellent number. In this case we can find sum of digits in this number: sum = ai + b(n - i). If sum is good, then add C[n][i] to answer. In this problem it's impossible to calculate binomial coefficients using Pascal's triangle, because of large n. However it can be done this way C[n][i] = fact[n]inv(fact[n - i]fact[i]). inv(a) is multiplicative inverse element(modulo MOD). MOD is a prime number, so inv(a) = aMOD - 2. Calculating this values for each i from 0 to n will give correct answer in O(nlog(MOD)).

Аuthor's solution

300D - Painting SquareThis picture is helpful for understanding.

This picture is helpful for understanding.

Let's consider problem D in graph terms:

We have matrix n × n, which represents a graph:

It is tree.Every vertex, except leaves, has 4 children.There are 4k distinct vertexes, with distance k from root.We need to color k vertexes of this graph. By that we mean also to color all vertexes on path from i to 1(root).

Knowing height of tree we can build it in unique way. Let's find height of tree in this way:

int height = 0;while (n > 1 && n % 2 == 1) { n /= 2; height++;}Let's consider following DP: z[i][j] — number of ways to color graph height i in j steps.

Naive solution in O(k4log(n)):

z[0][0] = 1; z[0][i] = 0, i > 0; z[i][0] = 1, i > 0z[i][j] = 0;for(int k1 = 0; k1 <= j - 1; k1++)   for(int k2 = 0; k2 <= j - 1 - k1; k2++)    for(int k3 = 0; k3 <= j - 1 - k1 - k2; k3++)      {         int k4 = j - 1 - k1 - k2 - k3;  z[i][j] += z[i-1][k1] * z[i-1][k2] * z[i-1][k3] * z[i-1][k4];  z[i][j] %= mod;      }But it is not what we whant in time terms. Let's consider current DP as polynomial coefficients: z[i][j] — coefficient of power j of polynomial i. In that case z[i + 1][j + 1] — coefficient of power j of polynomial i to the 4-th power. This approach allows to solve problem in O(k2log(n)). However this solution is quite slow, because of modulo operations. As you see, this modulo is not so big ( ≤ 107), that allows us to reduce number of modulo operations, thus giving huge perfomance boost. Also it is possible to use FFT to solve in O(klog(k)log(n)).

Аuthor's solution. Uses FFT

Аuthor's solution. Without FFT

300E - Empire Strikes BackLet's . val is upper bound for answer. val! is divisible by , you can easily prove it using facts about prime powers in factorial and following inequality . By the way,  is called multinomial coefficient. So answer can't exceed 1013.

If n! divisible by den, then (n + 1)! is also divisible by den. That means that function of divisibility is monotonic and we can use binary search.

For every i, i = 2..., 107, let's precalc max prime in i using linear sieve of Eratosthenes. For i it will be lp[i]. After that let's create a vector, with all primes less then 107.

Now let's calculate following values cnt[i] — amount of numbers a, i <  = a.

Now me can factorize denominator like this:

for(int i = max; i>=2; i--) { if (lp[i] != i)   cnt[lp[i]] += cnt[i]; cnt[i / lp[i]] += cnt[i];}Finally we use binary search from lf = 1 to .

Аuthor's solution

Codeforces Round #180 Editorial

By SteamTurbine, 10 years ago, In English298A - Snow Footprints

The starting position can be anywhere with a footprint. The footprints can be categorized into 3 types.

only L sonly R sR s followed by L sIn case 1, we end in the left of all footprints. In case 2, we end in the right of all footprints. In case 3, we either end in the rightmost R or the leftmost L

298B - Sail

We can simply move by greedy method — only moves when it takes the boat closer to the destination.

297A - Parity Game

Obv 1: If a has odd parity, we can apply operation 1 to increase its number of 1s by 1.

Obv 2: If a has even parity, its number of 1s cannot increase anymore.

Claim: If the number of 1s in a is not fewer than those in b, we can always turn a to b

The idea is to make a copy of b at the right of a. Lets assume a starts with even parity. If we need a 0, simply apply operation 1. If we need a 1, keep remove from the head until we removed an 1. Notice that we never remove digits from 'new part' of a. Now the parity of a will be odd and we can apply operation 1. After that, the parity of a becomes even again, the number of 1 in the 'old part' of a decrease by 1 and we handle a 1 in b. Finally, remove the remaining old part of a and we get b.

Combine all those facts, we can conclude that we can turn a into b if and only if

countOnes(a) + parity(countOnes(a)) ≥ countOnes(b)297B - Fish Weight

First we sort a and b in non-increasing order. We claim that the answer is YES if and only if exists a is lexicographically larger than b.

 If a is not lexicographcally larger than b, that means for every i, ai ≤ bi. That implies for every fish Alice has, there is a corresponding fish Bob has and is as heavy as Alice's.

 Let i be the smallest index such that ai > bi. We can amplify the gap between wai and wbi as large as we want to make Alice wins.

297C - Splitting the Uniqueness

An equivalent definition for almost unique, is an array with at least ⌊ 2n / 3⌋ different elements. The idea is to split s into three parts: In the first part, we give uniqueness to a. In the second part, we give uniqueness to b. In the third part, we give uniqueness to both.

Lets assume s is sorted. Since s is an unique array, we know si ≥ i for all i (0-based). The image below will give some intuition on how we are going to split it. a is red, b is blue, the length of the bar represent the magnitude of the number. In the first and second part, we do not care about the array that we are not giving uniqueness to.

 

For exampmle, if n = 30:

i = 0... 9:  assign ai = i (do not care values of b)

i = 10... 19:  assign bi = i (do not care values of a)

i = 20... 29:  assign bi = 29 - i and set ai = si - bi. From i = 20, a will have strictly increasing values starting from at least 11.

297D - Color the Carpet

For k = 1 there is only one coloring so we just need to check the number of  =  constraints. When k ≥ 2, it turns out that using only 2 colors is always sufficient to satisfy at least 3 / 4 of the constraints.

Lets assume w ≥ h (rotate if not). We will call the constraints that involves cells in different row "vertical constraints", and similar for "horizontal constraints".

First we color the first row such that all horizontal constraints in row 1 are satisfied. We will color the remaining rows one by one.

To color row i, first we color it such that all horizontal constraints in row i are satisfied. Then consider the vertical constraints between row i and row i - 1. Count the number of satisfied and unsatisfied vertical constraints. If there are more unsatisfied constraints than satisfied constraints, flip the coloring of row i. Flipping a row means turning 2211212 → 1122121, for example.

If we flip the coloring of row i, all horizontal constraints in row i are still satisfied, but for the vertical constraints between row i and row i - 1, satisfied will turn to unsatisfied, unsatisfied will turn to satisfied. Therefore, we can always satisfy at least half the vertical constraints between row i and row i - 1.

The number of unsatisfied constraints is at most (h - 1) × ⌊ w / 2⌋, which is at most 1 / 4 of the total number of constraints (recall w ≥ h).

297E - Mystic Carvings

Problem and editorial written by AEtheReal. Link to editorial.

Codeforces Round #179 tutorial

By Sereja, 10 years ago, translation, In English296A - Yaroslav and PermutationsNote that after applying the operations of the exchange, we can get any permutation of numbers. Not difficult to understand that the answer is "YES", if you can place a single number that it would not stand in the neighboring cells. Thus, if a some number is meeted C times, it must fulfill the condition C <= (n+1) / 2.296B - Yaroslav and Two StringsБудем решать обратную задачу: посчитать количество способов сделать сравнимые пары.Для начала посчитаем количество способов сделать первую строку меньше равной второй.Это количество равно произведению количества способов сделать это для каждой позиции по отдельности,так как они все позиции независимы. Посчитаем такую же величину, но когда вторая строка меньше-равна первой. И аналогично посчитаем количество способов сделать две строки равными. Для каждого символа величины можно считать простым циклом.Теперь возьмем величину 10 в степени количества знаков вопроса во входном файле и отнимем полученный ответ на обратную задачу, это и будет ответом.295A - Greg and ArrayДля того, что бы прибавить значение d на отрезке [x,y] достаточно завести массив b и поставить значенияb[x] += db[y+1] -= dДальше за один проход по массиву легко восстанавливаются все числа.Применим данный метод дважды: сначала для запросов, а потом для операций(зная сколько раз мы ее выполним).295B - Greg and GraphДля решения задачи нужно хорошо понимать принцип работы алгоритма Флойда.Общий вид алгоритма Флойда:for (k=1;k<=n;k++)for (i=1;i<=n;i++)for (j=1;j<=n;j++)a[i][j] = min(a[i][j], a[i][k]+a[k][j]);То есть на каждом шаге мы пытаемся пропустить путь через вершину К.Будем не удалять вершины, а добавлять(идя с конца).На каждом шаге будем пробовать пропустить путь между всеми вершинами через новую.Таким образом мы получим решение, работающее за кубическое время.295C - Greg and FriendsЗаметим, что на каждом шаге нас интересует только положение лодки(номер берега) и количество людей веса 50 и 100 на каждом береге. При чем количество людей на одном береге полностью определяется через другой.Для поиска минимального количества переправ будем использовать волновой алгоритм, основанный на этом состоянии.Для нахождения количества способов просто добавим сумму всех переходов в состояние при переходе будем переносить все способы из одного состояния в другое умножая на количество способов выбрать людей, которые нужны для перехода из одного состояний в другое.295D - Greg and CavesБудем пользоваться динамическим программированием: dp[i][j] — сколько существует способов построить фигуру, что в строке i будет ровно j столбцов занятыми черными клетками и всем, что между ними. При этом фигура должная не убывать (иными словами мы берем только верхнюю часть фигуры).Как делать переход? Заметим, что dp[i][j] = 1+dp[i-1][2] * (j-2+1)+ ... +dp[i-1][l] * (j-l+1)+ ... +dp[i-1][j].Распишем это: dp[i][j] = 1+dp[i-1][2] * j+ ... +dp[i-1][l] * j+ ... +dp[i-1][j] * j — dp[i-1][2] * 1 — dp[i-1][3] * 2 — ... — dp[i-1][j] * (j-1).Понятно, что если завести частичные сумму, то данные величины считать становится очень просто.Как посчитать полный ответ: будем перебирать номер максимального подходящего t(обозначенного в условии).Теперь единственное отличие, это то что следующая строка должна содержать строго меньше столбцов. То есть имеем аналогичный переход, с -1 слагаемым.Так же заметим, что зафиксировав "основу" мы должны домножить количество способов на число способов разместить ее на плоскости, то есть основу шириной j мы можем поставить (m-j+1) способами.295E - Yaroslav and PointsНаучимся решать задачу: найти сумму расстояний между точками.Если расписать, что происходит при добавлении одной точки, то получим формулу: x_i*(2*i-n) Где x_i — отсортированные координаты, а n общее количество точек.Научимся зная ответы для двух отрезков точек знать ответ для их объединения.Понятно, что для подсчета такой информации нужно всего лишь сложить два ответа,и добавить сумму координат первого множества умноженное на некоторое число ии добавить сумму координат второго множества умноженное на некоторое, возможно другое, число.Таким образом зная ответы для некоторых отрезков общий ответ.Будем использовать корневую декомпозицию или декартово дерево для хранения таких отрезков.Не сложно понять, что вставка и удаление делается достаточно быстро для этих структур.Например для корневой декомпозиции можно каждый раз просто вырезать и вставлять точку в нужные отрезки, а если множество стало содержать длинные отрезки или много отрезков, то просто перестроим его заново. Асимптотика решения не меняется.

Codeforces Round #178 Editorial

By havaliza, 10 years ago, In English294A - Shaass and OskolsAlthough Oskol is not really name of a specie of birds, In Iran it's known as a kind of bird which is very forgetful and can't even remember his way back to home when he flies away! It's commonly used instead of the word "stupid" among the kids! :D

In this problem you just have to now how many birds are there on each wire after each shot. A good trick for the first and the last wire would be to define wires 0 and n + 1. In this way the birds that fly away sit on these wires and you don't need to worry about accessing some element outside the range of your array.

Here is a neat implementation in C++ from contestant rpslive: 3484601

294B - Shaass and BookshelfAs said in the statement, the thickness of each book is either 1 or 2. Think about when we want to arrange v1 books of thickness 1 and v2 books of thickness 2 vertically and arrange all other n - v1 - v2 books horizontally above them to achieve a configuration with total thickness of vertical books equal to v1 + 2v2. Is it possible to find such arrangement? Because the total thickness of vertical books is fixed it's good to calculate the minimum possible total width of horizontal books. As the width of a book doesn't matter in vertical arrangement it's good to use the books with shorter width horizontally and the ones with longer width vertically. So pick out v1 books with longest width among books of thickness 1 and do the same with books of thickness 2. The sum of width of n - v1 - v2 remaining books should be at most v1 + 2v2.

The solution would be to try the things we explained above for all possible values of v1 and v2. And print the best answer. :)

There exists other ways to solve this problem mostly using dynamic programming but this was the intended solution of the problem.

Here is a nice implementation in C++ from contestant bayram: 3485189 (You should also know that 'bir' means 'one' in Turkish and 'iki' means two!)

294C - Shaass and LightsI just want to solve the third sample of this problem for you and you can figure out the rest by yourself. :)

The third sample is ...#...#... where # is a switched on lamp and . is a switched off lamp. As you can see we have three different types of lights. The first three lights (Type A), the 5th to 8th lights (Type B) and the last three lights (Type C). We have to switch on the lights three times for each type of lights. Aside from the order of moves for each type there are  possible permutations of the string AAABBBCCC which tells us how to combine the steps of different types. Switching on the lights is done uniquely for types 1 and 3. But for type 2 each time we have to possible options until we're left with one off light. So there are 23 - 1 ways to do this. So the answer would be 1680*1*4*1 = 6720.

The general solution would be to find all groups off consecutive switched off lamps and calculate the number of ways to combine all these groups. Then for each group you should calculate in how many ways it can be solved.

The implementation needs some standard combinatorial computations which you can see here: 3485187

294D - Shaass and Painter RobotTODO

294E - Shaass the GreatTODO

I promise the editorial will be completed come soon soon soon! :)

Codeforces Round #177, editorial

By witua, 10 years ago, translation, In EnglishHi!

289A - Polo the Penguin and SegmentsSolution. First of all, we need to count, how many integers are inside given segments at the beginning. Since they don't intersect and even touch, no integer point can belong to more than one segment at the same time. This mans that starting value of segments is .

If k divides p, then answer is 0 — we don't need to do anything, it's already done. But if it's not true, we need to know the minimal number of turns to make k divisor of p. Since we can in single turn increase p by 1 (by decreasing the left point of the leftmost segment), this number is equal to .

Note. Note that just output  is not enough: you need to pay attention for case when , or just output .

289B - Polo the Penguin and MatrixSolution. First of all, we need to know when the answer is -1. For that you should notice that after any operation on number z, value  doesn't change. Indeed, . This means that there is not answer if there are two different points for which  is diffrent.

Now we can transform our problem a bit. We can just write down all integers from matrix n × m to one array b of size k = n × m and sort them all in non-decreasing order. It is not hard to notice that in some of the optimal solutions, all number are at the end equal to one of the number for starting array. But also, it is optimal to make all number equal to  (median element). Why to median? Suppose that we make all numbers equal to non-median element with index x. Then if |x - (k - x)| > 1 (i. e. from one side there are more elements than from another + 1). So, by moving out element more to median, we can make result better.

After we know, to which number we should bring all, the answer is just , divided by d.

Note. There is also full solution with complexity O(n2m2).

288A - Polo the Penguin and StringsSolution. To solve this problem we need to find out some contruction of resulting string. But first of all, we need find out when there is no result. Obviously, if k > n, there is not result — you cannot build string of length n with more than n characters. Another one case is when k = 1 and n > 1 — there is no answer in that case also.

Consider that k = 2. It's really easy to see that answer for such case is a string of form abababab.... To construct string for k > 2 you need to add some extra characters — c, d, e.... To make string lexicographically smallest, you need to add that characters as close to the end as we can. And the best bet here is abbabab...abacdefgh.... So, we need just to add characters c, d, e, f... (i. e. k - 2 characters from c) to the end of the string.

288B - Polo the Penguin and HousesSolution. Since k ≤ 8 you can solve this problem using brute force. This means that you can recursively construct all possible kk possibilities of first k assignments. (For k = 8 this is equal to 16 777 216.) For each of that assignments you need to check whether it is correct or not (by problem statement). Ths can be simply done using loops.

When you know the number of assignment for the first k tables (let it be f(k)), all you need to do is to count the number of assignment for the rest n - k plaques. Since there should bo no path to 1, there should be no path to any of first k houses, so at each plaque for houses from k + 1 to n there can be any number from k + 1 to n, inclusive. There are (n - k)n - k such possibilities. And hence the total answer is f(k)(n - k)n - k.

Note. There also exists solution with dynamic programming, and also there exists formula for f(x). You can read about it more here, here и here.

288C - Polo the Penguin and XOR operationSolution. Since we need to maximize the result, we need to find such permutation, for which the least number of bit disappear. (We consider bit disappeared if it was 1 both in i and pi, so in  it is 0). It turns out that for each n there is such permutation that no bit disappear. How to build it? We will be solving problem by iterations while n > 0. On each iteration, we need to find the biggest (the leftmost in binary representation) bit which is not 0 in binary representation of n and denote it position (bits are numbered from 0) by b. Now we need to find integer m — minimal integer from 0 to n, inclusive, such that b-th bit is also 1 in it. After that you can see (look image below), that at  no bit disappear, at  no bit disappear, ..., at  no bit disappear. So, it is good to assign exactly that integers to our permutation, i. e. pm = m - 1 and pm - 1 = m, pm + 1 = m - 2 and pm - 2 = m + 1 and so on. After that assign value m - (n - m + 1) - 1 to n and go to next iteration.

 

Now when we know how to build permutation and that no bit disappear, the value of the answer is equal to .

288D - Polo the Penguin and TreesSolution. As always in such problems, root our tree at some vertex, for example vertex with number 1. We need to find out, what will happen when we have already chosen one path. Obviously, after deleting all vertices and their edges from that path, tree will disintegrate in some set of trees. Denote their sizes by c1, c2, ..., ck, where k is the number of trees. Then the number of ways to choose the second path is equal to . This gives us O(n2) solution — just to brute force all pathes and count the number of second paths by this formula. We need to do it in O(n). To do so, dfs our graph and fix some vertex during dfs, we will consider this vertex as the last vertex in the first path. Now we need to find the sum of above formula for the rest of the vertex. Here you can separately solve this problem for all vertex inside subtree of current vertex and for the rest of the vertices. For subtree vertices, you can, after finding the answers for all vertices of subtree, find the answer for root of subtree. To do so, you need to iterate all edges from current vertex and sum up results for that vetices. Also you need to add the sum of values  multiplied by the number of vertices in subtree, where di are all sizes of subtrees of vertices from current vertex, not including from current edge). You can use some partial sums of something like that to make it linear. For the rest of the vertices (not in subtree) it is actually similar, but a bit harder. Here you need to keep current result as a parameter of dfs and when you entering some vertex you should add some additional counts to the current sum (similarly as in first case).

Note. Also, you can find the number of bad pairs of pathes and subtract it from the total number. Also some divide and coquer solution exists, you can think about it.

288E - Polo the Penguin and Lucky NumbersSolution. In this problem there are a lot of different formulas, most of them are for optimizing solution and making it lenear. Editorial shows just a general idea because it's pretty hard to explain all of them and good for you to derive it by yourself. If you have any questions — write them all in comments.

Denote by a1, a2, ..., an all lucky number from segment. First of all, we need to do reduce the problem a bit. Let we have some fixed digit (pos, d), i. e. position of this digit is pos (from 0 from right to left) and value is d (4 or 7). Then, for all ai (1 ≤ i < n) such that pos-th digit of ai is equal to d, we need to add ai + 1 × d × 10pos to the answer. Now we can see that problem can be reduced to the following. For each fixed digit (pos, d) find the sum of all ai such that ai + 1 on the pos-th position has digit d. Obviously, we can solve the problem for 1..l and 1..r separately and then subtract the first from the second — that will be the answer.

How to find such sum among all lucky numbers of some length but less than some lucky number x? We will describe the general idea. Any lucky number, less than x has some common prefix with x, then one digit is less than the corresponing in x (i. e. it is 7 in x and 4 in another integer) and the rest of the digits are arbitrary. So, by iterating all such positions where is the first digit less than in x, we can, using the fact that the rest of the digits are arbitrary and some formulas and precomputations, compute the results for each position and digit.

Codeforces Round #175 (Div. 2) Tutorial

By HolkinPV, 10 years ago, translation, In English285A - Slightly Decreasing Permutations

As the answer you can print such permutation: n, n - 1, ..., n - k + 1, 1, 2, ..., n - k. For example, if n = 5, k = 2, then the answer is: 5, 4, 1, 2, 3. If k = 0, you should print 1, 2, ..., n. Such solution can be written in two loops.

285B - Find Marble

It is known that a permutation can be considered as set of cycles. The integer i moves to p[i] for all i (1 ≤ i ≤ n). You can start moving from integer s along the cycle. If you find integer t, then print the length of the path. If you return to s, then print  - 1.

285C - Building Permutation

The solution of the problem is rather simple. Sort all integers a and then make from integer a[1] integer 1, from integer a[2] integer 2 and so on. So, integer a[i] adds to the answer the value |a[i] - i|. The answer should be count in 64-bit type. You can simply guess why such solution is correct.

285D - Permutation Sum

For a start, describe bruteforce solution. Firstly, we will always assume, that a is identity permutation, that is a[i] = i. In this case, the answer should be multiplied by n!. Or in other way your bruteforce will not be counted. Secondly, using our bruteforce we can see, that for even n the answer is 0.

What do you also need to get accepted? First case is to calculate answers for all n on your computer and write them in constant array. In other words you can make precalc. Second case is to make you solution faster. The soltuion using meet-in-the-middle idea works fast for n ≤ 15. If you remember that for even n answer is 0 then you can get accepted using such solution. But other simple bruteforces and dynamic programmings on maps work slower than 3 seconds.

285E - Positions in Permutations

Editorial for Codeforces #174

By abacadaea, 10 years ago, In EnglishHere is the editorial for Round #174. Thanks for participating. We hope you enjoyed the problems! :)

Div2 A

We didn’t expect this problem to be so hard :(. This problem can be solved by brute forcing. For any x,  you can compute  in O(p) time (iteratively multiply cur = (cur * i) % p, not use pow in math library!), so overall brute force will be O(p2) time.

Note: there is actually  algorithm.

The problem was written by abacadaea.

Div2 B

We first note that players who have folded do not affect our desired answer. Then, we can do casework on the number of players who are currently “IN”. If no cows are “IN”, then all the players who are “ALLIN” can show their hands. If exactly one cow is “IN”, she is the only one who can show, so the answer is 1. If two or more cows are “IN”, no one can show their hands. Then we simply count the number of cows of each type and check for each case. The total runtime is O(n).

The problem was written by scott_wu.

Div1 A / Div2 C Consider the problem with only queries 1 and 2. Then the problem is easy in O(n): keep track of the number of terms and the sum, and you can handle each query in O(1). But with query 3 we need to also be able to find the last term of the sequence at any given time. To do this, we keep track of the sequence di = ai + 1 - ai for i = 1, 2, ..., s - 1,  and as,  where s is the length of the sequence. Notice that query 2 only modifies one value of di,  and queries 1 and 3 are easily processed and able to update this information. This gives us an O(n) algorithm.

One can also use a fenwick or segment tree to compute the last element, but it’s not nearly as nice :).

The problem was written by abacadaea.

Div1 B / Div2 D

First, suppose we only have the sequence a2, a3, …an. We note that the current state is only determined by the location and the direction we are facing, so there are only 2·(n - 1) states total. Then, we can use DFS with memorization to find the distance traveled from each state, or  - 1 if a cycle is formed, in O(n) time. Now, when we add a1 into the sequence, we essentially only need to give the distance traveled starting from each state facing left. The only difference is that if we ever land on a1 again, there must be a cycle, as we started on a1. Using this, we can solve the problem in O(n) time total.

The problem was written by scott_wu.

Div1 C / Div2 E

Imagine the problem as a graph where coins are the nodes and Bessie’s statements are directed edges between coins. Because of the problem conditions, the graph must be a set of cycles and directed paths. If there are any cycles in the graph, the answer is clearly 0.

Then, suppose we have a path p1, p2, …pk in the graph, where it is known that we have more coins of type p1 than of type p2, more of type p2 than of type p3,  and so on. The key observation in this problem is that this is equivalent to having k independent coins of value {a(p1), a(p1) + a(p2), a(p1) + a(p2) + a(p3), …}. The first coin in our new list represents how many more coins of type p1 than of type p2 we have, the second coin in our new list represents how many more coins of type p2 than of type p3 we have, and so on. However, we must be careful to note that we need at least one of each of the new coins except for the last one, so we can subtract their values from T before doing the DP.

After creating our new set of values, we can run the DP the same way we would run a standard knapsack. This algorithm takes O(nt) time total.

The problem was written by scott_wu.

Div1 D

Let ν2(n) denote the exponent of the largest power of 2 that divides n. For example ν2(5) = 0, ν2(96) = 5. Let f(n) denote the largest odd factor of n.

We can show that for fixed ai, aj(i < j),  we can construct a cool sequence ai = bi, bi + 1, ... bj - 1, bj = aj if and only if  and either ν2(ai) + j - i = ν2(aj) or ν2(aj) ≤ j - i - 1. Proof here

With this observation, we can use dynamic programming where the kth state is the maximum number of ai (i ≤ k) we can keep so that it is possible to make a1, ... ak cool. The transition for this is O(n),  and the answer is just n - max (dp[1], dp[2], ..., dp[n]). This algorithm is O(n2).

The problem was written by scott_wu.

Div1 E

This will go over the basic outline for solution.

We can show that the answer is  where wi is the number of wins cow i appears to have. Proof here

Now sort the skill levels of the cows (the order of the si doesn’t actually matter). s1 is lowest skill. Now consider an n × n grid where the ith row and jth column of the grid is a 1 if the match between cow i and cow j is flipped. The grid is initially all zeros and Farmer John’s query simply flips a rectangle of the form [a, b] × [a, b].

We can process these queries and compute the number of wins for each cow using a vertical sweep line on the grid and updating with a seg tree on the interval [1,n]. The seg tree needs to handle queries of the form \begin{enumerate} \item Flip all numbers (0->1, 1->0) in a range [a, b]. \item Query number of 1’s in a range [a, b]. \end{enumerate} Note that given this seg tree we can compute the number of wins for each cow at every point in the sweep line as (Number of 1’s in range [1,i — 1]) + (Number of 0’s in range [i + 1, n]). There are O(m) queries so this solution takes  time.

The problem was written by abacadaea.

Round #173 — Editorial

By A.K.Goharshady, 10 years ago, In EnglishHi, Here's the editorial.

Please note that not all the codes presented below belong to me. (It's a combination of codes from our problemsetters and testers) -- And I borrowed AKGMA's account since I wasn't able to link to my own submissions somehow!

Note: It seems that the Codeforces mark-up is not functioning. To see a submission go to: http://www.codeforces.com/contest/282/submission/submission-number

A: Bit++Just use a simple loop. (Take a look at the Python code)

GNU C++: 3314442, 3314464

GNU C: 3314471

Python: 3314475

B: Painting EggsThis one can be solved by a greedy algorithm. Start from the 1st egg and each time give the egg to A if and only if giving it to A doesn't make the difference > 500, otherwise give it to G.

To prove the correctness, one can use induction. The base case is trivial. Suppose that we've assigned the first n - 1 eggs such that the total money given to A is Sa and total money given to G is Sg. We can assume Sa ≥ Sg. Now we must either add gn to Sg or add an to Sa. If we can't add gn to Sg, then Sg + gn > Sa + 500, so  - 500 > Sa - Sg - gn, adding 1000 to both sides gives us the inequality 500 > Sa + (1000 - gn) - Sg which is exactly what we need to make sure that we can add an = 1000 - gn to Sa.

GNU C++: 3314480, 3314484

GNU C: 3314488

Python: 3314492

C: XOR and ORFirst of all, check the length of the two strings to be equal. Then with a little try and guess, you can find out that the zero string (00...0) can't be converted to anything else and nothing else can be converted to zero. All other conversions are possible.

GNU C++: 3314503, 3314504, 3314509, 3314512, 3314514

D: Yet another Number GameFor n=1, everything is clear. If a1 = 0 then BitAryo wins, otherwise BitLGM is the winner.

For n=2: define win[i][j] = (Whether i,j is a Winning position). It's easy to calculate win[i][j] for all i and j, using a loop (Checking all possible moves). This leads us to an O(n3) solution.

For n=3: Everything is similar to NIM, With the same statement of proof as for NIM, i,j,k is a winning position if and only if (i xor j xor k)  ≠ 0.[Don't forget the parentheses in code :) ] Complexity: O(1)

One can also solve this case using DP. We define lose[i][j]= (Least k, such that i,j,k is a losing position) ,lose2[i][j]=(Least k, such that k,k+i,k+i+j is a losing position) and win[i][j][k] just as the case with n=2. As in the codes below, one can calculate all these values in O(n3).

Using the same DP strategy for n=2 and the O(1) algorithm for n=3 and n=1, leads us to a total complexity of O(n2) which was not necessary in this contest.

GNU C++: 3314578, 3314580, 3314585, 3314588

E: Sausage MaximizationCan be solved using a trie in O(n log (max{ai})).

Start with a prefix of size n, and decrease the size of prefix in each step. For each new prefix calculate the XOR of elements in that prefix and add the XOR of the newly available suffix (which does not coincide with the new prefix) to the trie, then query the trie for the best possible match for the XOR of the new prefix. (Try to get 1 as the first digit if possible, otherwise put 0, then do the same thing for the second digit and so on). Get a maximum over all answers you've found, and it's all done. [By digit, I mean binary digit]

GNU C++: 3314616, 3314619

We hope you enjoyed the tasks.

Codeforces Round #172 Editorial

By MinakoKojima, 10 years ago, In EnglishOverview ...In DIV 1, there are 3 normal tasks accompanied with 2 challenge tasks. About 40 competitors solve first three tasks during the contest and I believe there will be more if we extended the duration a little bit.

Task D is a standard data-structure problem hidden behind a classical maximum cost flow model. This kind of problem are usually trick-less, but hard to implement especially under the pressure. Because of this, it becomes tonight's draw-breaker.

Task E is a extended version on a classical DP && Math problem. There are many solutions to the original problem, one is giving a global view under the state transition, and using a data structure to handle it carefully. However, this one is even more harder, few people have ever tried it except Jacob. (Although is wrong.)

As a seasoned competitor, Petr took the C-B-A order which proved to be the best choice through out the night. And after quickly solved C and B, he has sunk into problem A, it takes him about 45 minutes to cut-the-knot and got 2 Successful Hacking Attempt as a reward.

On the other hand, peter50216 gave his response to Problem A straightly! It only took him about 15 minutes to write a code which is full of trigonometric function and if-else. And on top of this is another 15 minutes to solve the successors. After that, he gave 2 Successful Hacking Attempt on A and 1 Successful Hacking Attempt on B as the end.

While we were marvelling at peter50216 for his solid skill in geometry, al13n gave the first attempt to problem D among the game. Unfortunately his solution get TLE on the pretests.

This is a O(mk^2logn) algorithm, and we think it is hard to optimize it to pass the pretests even for our setter. And abandoned the O(mk^2logn) solution and totally reconstructed the O(mklogn) from the sketch now became more difficult and audacious.

While we were praying to al13n, Jacob gave the first solution and the only solution for Problem E among the whole game! It cost all of his time and led him no time to solve others. It sounds like a miracle ..

We were all sooooooo excited and opened his code and look carefully, but, actually I myself got quite confused by his solution, and didn't know why it can work at all.

While all we setter and tester were checking the solution carefully. UESTC_Nocturne (XHXJ) gave the first correct solution among the game for problem D. It is a huge code more than 12kb, and perform as same as our std solution. Although he haven't solve A && B, this break-through has already establish his winner position.

After the contest, I interview her to "how can you solve this problem so quick", and replied as “I have solved the simplified problem, and have thought about this method before.”

At the same time, we found that Jacob's solution was wrong, we generated a few maximal random data, and it return WA about one-quarter of them. After some discussion we decided to add one of them into the tests.

In both problem D and E, our pretests intended to be as strong as possible. How I wish to let Jacob know about his solution is wrong so he can quickly get out of the impasses and get Accepted in the end... .

al13n also pass from the pretests after UESTC_Nocturne, we are relieved to hear about it at first, but found it is a O(mk^2logn) solution with a wrong optimization soon, this solution will definitely fail in system test, but he may didn't aware of it at the time.

There are other three correct solutions for Problem D near the end of the game, among them FattyPenguin's solution is the fastest one, and he make it in ten minutes ago before the contest end and liouzhou_101's solution actually is a O(mk^2logn) one but with some dramatic optimizations. It is hard to block this kind of solution or it could cause some trouble for our Java Users.

Tutorial ...http://assets.codeforces.com/statements/280-281/Tutorial.pdf

Problem 2A. Word CapitalizationProblem 2B. Nearest FractionProblem A. Rectangle PuzzleProblem B. Maximum Xor SecondaryProblem C. Game on TreeProblem D. k-Maximum Subsequence SumProblem E. Sequence TransformationBackstage: The screencast of my screen during the contest, you can see what happened behind the scene if you are interested, just have fun ~.

CMHJT's tutorial: Another tutorial written by one of the setters for C, D, E.(Chinese!)roosephu's tutorial for D: Tester's tutorial for Problem D.Seter's tutorial for E: Tester's tutorial for Problem E.......: A brief overview release after the contest end.(Chinese!)Sidelights ...There are some disputes about the problem A, but personally I like it very much, this is a basic problem(surely it is evil), can be described in one picture, and all of us could solve it if they are careful. Some people say it is harder than A so it should be swap with Problem C, but I insist on put it at A, because, we all think Problem B && C needs some idea, but A needs only basic knowledge we learned in middle school. And it can be solved in a different style if you have a well-implemented Geometry Template. Some competitors are just good at this kind of problem while others are not. And after all, this is the only problem which has trick in this contest. :)In problem B, some people got confused in “bitwise excluding OR = XOR or OR?”, they are only familiar with "XOR" but get into confused with something like "bitwise excluding OR". Well, as a Non-English speaker, I can only expressed my understanding, we didn't intend to do that. In the original statement we write "XOR" but during the translate process it became "bitwise excluding OR", and I did not think it could cause such trouble. Here we can only recommend you read more English book, because such things will occur from now on and keep up.tourist lost his target (Rating above 3000) after the contest. But we all think he'll return soon.rng_58 didn't participate in the contest but took a virtual participation on the next day. He can't solve D && E and get Rank 5 along after Petr.tclsm2012 as a purple, also solve Problem D during the contest, but failed at A && C at the expense.Both the winner and the runner-up failed on problem A.UESTC_Nocturne's A solution was hacked by scottai1, the latter, also failed at the system test after a while.One of our setter ... came in the hospital after setting problems.We were adding tests against submitted solutions during the contest.Daniel Sleator (A professor at CMU who invented many data structures such as splay trees, link-cut trees, skew heap and discovered amortized analysis, see Wikipedia ...）participated in Div 2 and get promotion to Div 1 after the contest. And he checked our Div 1. E and write a miraculous DP solution1 2 in Ocaml which based on a conclusion.

Unofficial editorial for Codeforces Round #171 (Div. 2)

By Maksim1744, 17 months ago, In EnglishContinuing with the theme of absent editorials for old rounds, here is an editorial for Codeforces Round #171 (Div. 2). Even though there is an official editorial, it is only in russian and doesn't have solution for the last problem.

A

Editorial279A - Point on SpiralSince constraints are small, you can just simulate the whole process, but I'll explain an O(1) solution. Let's look at the path



Now it's easy to see that the plane can be divided into four parts



And then we can calculate answer for each part separately, just be careful with borders. For example, for the right part the answer is 4x−3.

CodeB

Editorial279B - BooksThe problem can be written in the following way: for each index i denote ri as the largest index such that ai+…+ari⩽t. The problem is to find max(ri−i+1).

One can see that ri are nondecreasing, so the problem can be solved with two pointers: iterate over i and keep a pointer to corresponding ri.

CodeC

Editorial279C - LadderLet's calculate two arrays before answering queries. tol[i] is the smallest index such that [btol[i],…,bi] is nonincreasing, and tor[i] is the largest index such that [bi,…,btor[i]] is nondecreasing. Then for each query we can take tor[l] and tol[r] and compare them. The answer is "Yes" iff tor[l]⩾tol[r]. In other words, we are checking if the largest nondecreasing segment from l and largest nonincreasing segment from r are intersecting.

To calculate tol[i], go over i from 1 to n and maintain largest nonincreasing suffix. For tor do the same in reverse.

CodeD

Editorial279D - The Minimum Number of VariablesYou can notice that when we want to perform some operation, we are only interested in a subset of current values of variables (including zeros). So let's create dp[i][mask]=bool, which is 1 if we can perform first i operations and end up with the values from mask. Here k-bit in the mask corresponds to the value vals[k], where array vals stores all numbers in a and a zero, and k-th bit is set iff the value of one of the variables is vals[k].

To make transition from dp[i][mask] to dp[i+1][new_mask], let's look at the operation. We have to find two values in the mask such that their sum is a[i+1]. Then to calculate new_mask we have to set k-th bit in the mask, where k is such that vals[k]=a[i+1]. Also, while writing new variable we can overwrite any existing variable, so we have an option to disable any bit in the mask.

Now it looks like we have O(2nn) states and n transitions from each state (disabling each bit). But actually if we only make transition from dp[i][mask]=1, the complexity will be O(2nn), because for each i there are at most 2i+1 masks that we can achieve, since there are only i distinct numbers on the current prefix plus an additional zero. And ∑ni=12i+1⋅n=O(2nn).

The only problem left is to check if we can build some number y from vals using numbers from mask. This can be precomputed in O(2nn): let's calculate array possible[mask]=x, where i-th bit in x is set iff we can get number vals[i] from mask on the next step. To calculate it, first for each mask with at most 2 bits just calculate all possible x with any straightforward approach, since there are only O(n2) such masks. For any other mask notice that we can get y iff sum of some two values equals to y. So we can iterate over all submasks such that they differ from mask in exactly one bit and update possible[mask] with possible[submask]. And since mask has at least 3 bits, if there is a pair which sums up to y, this pair will be included into at least one of the submasks. One can even notice that we only need any 3 such submasks to cover every pair of bits.

The answer is minimum number of bits over all masks such that dp[n][mask]=1.

CodeE

Editorial279E - Beautiful DecompositionFirst of all it's easy to notice that we will use each power of 2 at most once.

Let's look at the highest bit in the current number, suppose it's 2k. Since the sum of all powers of 2 below k is less than 2k, we will have to add at least one power of two 2x with x⩾k. One can see that adding 2k+2 is not optimal, since then we will have to subtract at least 2k+1 and 2k+2−2k+1 can be replaced with 2k+1. So the only choices are 2k or 2k+1. If we add 2k, we have to solve a problem for remaining number, which is a suffix or our current binary string. Otherwise, 2k+1 is larger than our current number, so we just need the answer for m=2k+1−n. Let's call such m a complement for a number n (notice that we don't need k in the definition because k is defined as largest bit in n)

Now let's look at m. To calculate it, we have to flip all bits in n and add 1 to the result. Now it's easy to see that if m is a complement for n, then for any suffix of n (in binary form), the corresponding suffix of m is a complement for it. Also, n is a complement for m.

So during our calculations we will only deal with n, m, suffixes of n and suffixes of m. And this leads to a following dp solution: let v[1]=n, v[2]=m. Then dp[ind][suf] is the smallest answer for a binary number represented by a suffix of number v[ind] starting from index suf. We can calculate this dp starting from dp[…][n] and the answer will be dp[1][1].

Code

Codeforces Round #170 Tutorial

By RAD, 10 years ago, translation, In English278B - New Problem

The total number of different strings of 2 letters is 262 = 676, but the total length of the input strings is no more than 600. It means that the length of answer is no more than 2. So just check all the strings of length 1 and 2.

277A - Learning Languages

Build bipartite graph with n nodes for employees and m nodes for languages. If an employee initially knows a language, than there will be an edge between corresponding nodes. Now the problem is simple: add the minimal number of edges in such a way, that all the n employees will be in the same connected component. Obviously, this number equals to the number of initially connected components, containing at least one employee, minus one. But there is one exception (pretest #4): if initially everyone knows no languages, we'll have to add n edges, because we can't add the edges between employees (remember that the graph is bipartite).

277B - Set of Points

For m = 3, n = 5 and m = 3, n = 6 there is no solution.

Let's learn how to construct the solution for n = 2m, where m ≥ 5 and is odd. Set up m points on a circle of sufficiently large radius. This will be the inner polygon. The outer polygon will be the inner polygon multiplied by 2. More precisely (1 ≤ i ≤ m):









If m is even, construct the solution for m + 1 and then delete one point from each polygon. If n < 2m, delete 2m - n points from the inner polygon.

Unfortunately, this solution doesn't work for m = 4, n = 7 and m = 4, n = 8.

Another approach is to set up m points on a convex function (for example, y = x2 + 107), and set up the rest n - m points on a concave function (for example, y =  - x2 - 107). Take a look at rng_58's solution — 3210150.

277C - Game

At first, notice that horizontal and vertical cuts are independent. Consider a single horizontal line. It contains m unit segments. And in any game state it's always possible to decrease the number of uncut units as the player wants. Imagine, that she starts growing a segment from a border, increasing it's length by 1 at a time. Each time the total uncut length decreases by either 0 or 1. In the end it obviously reaches 0.

The same holds for vertical lines as well. So if there are no initial cuts, the game is a nim with n - 1 piles of m stones and m - 1 piles of n stones. Could be solved with simple formula.

Initial k cuts should be just a technical difficulty. For any vertical/horizontal line, which contains at least one of the cuts, it's pile size should be decreased by the total length of all segments on this line.

How to make a first move in nim: let res is the result of state (grundy function), and ai is the size of the i-th pile. Then the result of the game without i-th pile is . We want to replace ai with some x, so that . Obviously, the only possible . The resulting solution: find a pile for which , and decrease it downto .

277D - Google Code Jam

Suppose we have fixed set of inputs that we have to solve. Let's learn how to determine the optimal order. Obviously, Small inputs (and Large inputs with probFail = 0) won't fail in any case. It means that our penalty time is no less than submission time of last such ``safe'' inputs. So we will solve such inputs before all the others. Inputs with probFail = 1 are just a waste of time, we won't solve such inputs. Now we have only inputs with 0 < probFail < 1. Let i and j be two problems that we are going to solve consecutively at some moment. Let's check, if it is optimal to solve them in order i, j, or in reversed order. We can discard all the other inputs, because they don't affect on the relative order of these two.

(timeLargei + timeLargej)(1 - probFailj) + timeLargei(1 - probFaili)probFailj < (timeLargei + timeLargej)(1 - probFaili) + timeLargej(1 - probFailj)probFaili

 - probFailj·timeLargej - timeLargei·probFailj·probFaili <  - probFaili·timeLargei - timeLargej·probFaili·probFailj

timeLargei·probFaili(1 - probFailj) < timeLargej·probFailj(1 - probFaili)

timeLargei·probFaili / (1 - probFaili) < timeLargej·probFailj / (1 - probFailj)

Now we've got a comparator for sort, which will give us the optimal order. Note, that inputs with probFail = 0, 1 will be sorted by the comparator correctly as well, so it's not a corner case.

Let's return to the initial problem. First of all, sort problems with the optimal comparator (it's clear that any other order won't be optimal by time, and the score doesn't depend on the order). Calculate the DP: z[i][j] = pair of maximal expected total score and minimal expected penalty time with this score, if we've already decided what to do with the first i problems, and we've spent j real minutes from the contest's start. There are 3 options for the i-the problem:

skip: update z[i + 1][j] with the same expected values

solve the Small input: update z[i + 1][j + timeSmalli], the expected total score increases by scoreSmalli, and the expected penalty time increases by timeSmalli (we assume that this input is solved in the very beggining of the contest)

solve both inputs: update z[i + 1][j + timeSmalli + timeLargei], the expected total score increases by scoreSmalli + (1 - probFaili)scoreLargei, and the expected penalty time becomes timeSmalli + (1 - probFaili)(j + timeLargei) + probFaili·penaltyTime(z[i][j]), where penaltyTime(z[i][j]) is the expected penalty time from DP

The resulting answer is the best of z[n][i], (0 ≤ i ≤ t).

The expected total score could be a number around 1012 with 6 digits after decimal point. So it can't be precisely stored in double. And any (even small) error in calculating score may lead to completely wrong expected time (pretest #7). For example, you can multiply all the probabilities by 106 and store the expected score as integer number to avoid this error.

277E - Binary Tree on Plane

If there is no "binary" restriction, the solution is simple greedy. Each node of the tree (except the root) must have exactly 1 parent, and each node could be parent for any number of nodes.

Let's assign for each node i (except the root) such a node pi as a parent, so that ypi > yi and distance between i and pi is minimal possible. Renumerate all the nodes in order of non-increasing of y. Now it's clear that pi < i (2 ≤ i ≤ n). So we've just built a directed tree with all the arcs going downwards. And it has minimal possible length.

Let's recall the "binary" restriction. And realize that it doesn't really change anything: greedy transforms to min-cost-max-flow on the same distance matrix as edge's costs, but each node must have no more than 2 incoming flow units.

Codeforces Round #169 Editorial

By Fcdkbear, 10 years ago, translation, In EnglishA. Lunch Rush

Let’s look at all restraunts, where Rabbits can have their lunch. Let’s calculate the answer for all restraunts and choose the maximulm value among of them. We need to use formula descrbed in problem statement to calculate the answer for some particular restraunt. Time complexity of this solution is O(N).

C++ code

Java code

B. Little Girl and Game

Let’s calculate the number of letters with odd number of occurrences in s. Let this value be equal to k.

If k = 0, then first player can win immediately: he can easily build palindrome, placing equal letters in different sides of resulting string (he always can do it, because total number of all letters is even).

If k = 1 then first player can win immediately again; at first he builds palindrome from letters with even number of occurrences in s; after that he inserts the rest of the letters in the middle of built in previous step string.

Let’s proof very useful statement. If k > 1 our problem has the following solution: if k is even, than second player is winner; otherwise, first player is winner.

Let k = 2. At the beginning of the game first player can make move of two types.

Using move of first type first player can decrease k to 1 by erasing one appearance of letter with odd number of occurrences. But this move leads him to defeat, because after this move second player can build palindrome.

Using move of second type first player can increase k to 3 by erasing one appearance of letter with even number of occurrences. In this case second player can make similar move — he will erase the same letter. Since the number of moves of this type is finite, sooner or later first player will have to make a move of first type. After this move he loses immediately.

So, if k = 2, than second player is a winner.

Let k = 3. First player can decrease k to 2 by erasing the letter with odd number of occurrences. If second player will try to increase k to 3 again by erasing the similar letter, first player can decrease k to 2 again (he erases the same letter again). It’s easy to see that the last move in this sequence of moves will be the move of first player. So, first player always can change the game in such a way that k = 2. This position is losing position for second player and winning position for first player.

Now we can easily proof our statement for any k using mathematical induction.

So, we have quite easy solution with time complexity О(|S|).

C++ code

Java code

C. Little Girl and Maximum Sum

Lets calculate for each cell of the initial array the number of queries that cover this cell. It’s claimed, that we should associate the cell with bigger value to the cell with bigger value in initial array. More formally: suppose b is an array, in i - th cell of which is written the number of queries that cover i - th cell. Suppose а is an initial array. Let’s sort those arrays. It’s claimed, that the answer in this case can be calculated with following formula: 

Let’s proof this statements. We will take a look at some indexes i < j, and at elements, corresponding to shis indexes a[i], a[j] , b[i], b[j] (a[i] ≤ a[j], b[i] ≤ b[j]). Those elements add to the answer the following value: a[i]·b[i] + a[j]·b[j]. Let’s swap a[i] and a[j]. Now those elements elements add to the answer the following value a[i]·b[j] + a[j]·b[i]. Let’s take a look at the following difference:

a[i]·b[j] + a[j]·b[i] - a[i]·b[i] - a[j]·b[j] = b[j]·(a[i] - a[j]) + b[i]·(a[j] - a[i]) = (b[j] - b[i])·(a[i] - a[j]) ≤ 0.

So, swapping of two elements leads us to nonincreasing of the total result. This means, that our arrangement is optimal.

Now we need to calculate array b fast enough.

For this purpose one can use different data structures, which support segment modifications (segment tree, Cartesian tree and so on). But there exists much easier method.

Let’s create some array d. When we have query li, ri, we should increase value d[li] by 1 and decrease value d[ri + 1] by 1. In such a tricky way we increase all elements in segment [li;ri] by 1 After processing all of the queries we need to make a loop, which visit every element of array d. In this loop we can easily calculate all elements of array b.

Now we are ready to get the final answer. The complexity of author’s solution is O(NlogN + Q)

C++ code

Java code

D. Little Girl and Maximum XOR

To be honest, I am surprised that problem D had so many accepted solution during the contest. The author’s solution uses dynamic programming. In this editorial I’ll explain this solution.

First of all we should convert L and R to the binary numeral system. Now we can solve our problem with dynamic programming, using the following state d[p][fl1][fr1][fl2][fr2], where p is current position in binary representation of our numbers a and b (this parameter is in range from 0 to number of bits in R), fl (0 or 1) is a variable, which shows if current value of а is strictly greater than L, fr1 (от 0 до 1) is a variable, which shows if current value of а is strictly less then R, fl2, fr2 are variables, which show the similar things for b.

Let’s use recursion with memorization for our solution.

Let’s define the base of recursion. If we have looked through all the bits, we should return 0.

Let’s define a recursive transition. We need to know, which bits we can place into binary representation of number а in p-th position. We can place 0 if the following condition is true: p-th bit of L is equal to 0, or p-th bit of L is equal to 1 and variable fl1 shows that current value of a is strictly greater then L. Similarly, we can place 1 if the following condition is true: p-th bit of R is equal to 1, or p-th bit of R is equal to 0 and variable fr1 shows that current value of a is strictly less then R. Similarly, we can obtain, which bits we can place into binary representation of number b in p-th position.

Let’s iterate through all possible bits’ values and check the result of xor operation. If it is equal to 1, we should add to the answer corresponding power of 2. We also need carefully recalculate values of variables fl1, fr1, fl2, fr2. We should choose maximum answer from all valid options.

Initial state for our recursion is (P,0,0,0,0), where P is number of bits in R.

I hope, my code will clarify all the obscure points.

I also want to say, that this approach is in some sense universal and can be applied to many similar problems, like this one

The complexity of algorithm is O(logR)

C++ code

Java code

In Russian thread I saw another really nice solution, so I decided to include this solution to the editorial.

First of all, if L = R, than the answer is 0.

Now let’s consider case with L ≠ R. Let Ri be the i-th bit of R, Li be the i-th bit of L. Let’s define p as largest number such as Rp ≠ Lp (we use 0-based indexation). Let’s take a look at all numbers in range [L;R]. It’s easy to see, that bits, that are higher than bit with index p are equal for all this numbers. Thus, those bits can not affect our answer, because their xor will always equal to 0.

Let’s build numbers a and b in the following way:

1) a: bits which are higher than bit with index p are equal to the corresponding bits of L, p-th bit is equal to 0, the rest of bits are equal to 1.

1) b: bits which are higher than bit with index p are equal to the corresponding bits of L, p-th bit is equal to 1, the rest of bits are equal to 0.

It’s easy to see, that a and b both lie in range [L;R]. It’s also easy to see, that xor of this numbers sets all bits, that are not higher than bit with index p to 1. So, our answer is maximum possible and is equal to 2p + 1 - 1

The complexity of algorithm is O(logR)

Java solution from AlexanderBolshakov

We can iterate through value of p using binary search. We can achieve time complexity O(log(logR)) in this way, but it wasn’t required during the contest.

E. Little Girl and Problem on Trees

One can see, that our tree is a set of chains, each of which starts in the root.

First of all we need to decompose our tree in chains using, for example, depth first search. For each vertex we should find out it’s depth and number of chain, which contain this vertex. For each chain we’ll use some data structure, which can fast enough change it’s elements and fast enough answer to the range sum query. For example, we canuse Binary Indexed Tree (BIT). We also need to create one BIT for root. This BIT is global: it’s information is actual for all the chains

Let’s remember problem С. In that problem we used array d for processing all the queries. We need to know values of elements of array b in that problem after processing all the queries. In this problem queries are online. That’s why we need to use BIT; it allows to change element and answer range sum query in O(logN) time.

Let’s learn, how to process queries, which require modification and queries, which require finding the element, using BIT.

BIT can make two types of operations:

add(x, y) — add value y to element with index x

find(x) – finds sum in range from 1 to x

Let’s consider, that we need to add value val to all elements in range from l to r . Than we should just make operations add(l, val) and add(r + 1,  - val).

Let’s consider, that we have query which require printing the value of element with index v. Then we should just make operation find(v).

Now let’s go back to the initial problem.

During the processing query of type 0 we should check, if it affects the root. If query affects the root, we should carefully process this query in our chain and make necessary changes in root’s BIT. Otherwise we just process query in our chain.

During the processing query of type 1 we should just find corresponding sums in root’s BIT and in BIT for our chain. We should print the sum of this values.

Time complexity of this solution is O(N + QlogN)

C++ code

Java code

That’s all. I’ll be very glad to answer to your question in comments.

Codeforces Round #168 Editorial

By havaliza, 10 years ago, In EnglishHi :)

Here's the editorial for round #168. This time I tried to do my best to prepare a good contest. In some parts I failed but I still learned many things which will surely help me to do better next times! ^.^ I hope you've liked the problems. :)

275A - Lights OutAuthor: havaliza

For each light you should count the number of times it’s been toggled. Consider a light is toggled k times. If k is even then the final state of the light is ‘on’ otherwise it’s ‘off’. The implementation would be easy. You may look at the accepted solutions as reference.

275B - Convex ShapeAuthor: havaliza

Consider a pair of black cells. There exist at most two different valid paths we can take between these two cells. The naïve solution would be to check the existence of at least one of these paths for each pair of black cells. There are O(n2m2) such pairs and each pair can be checked in O(n + m). So the time complexity will be O(n2m2(n + m)) which is enough to get accepted.

But there exists a O(nm) approach. It’s obvious that each row of the grid either doesn’t have any black cell or the black cells are a consecutive part of the row. The same holds for every column. For every non-empty row consider the interval of its black cells. The intersection of intervals of all non-empty rows should be non-empty. If the same holds for all columns then our grid is convex. The proof of this solution is not hard and is left for the reader.

274A - k-Multiple Free SetAuthor: havaliza

Consider an integer x which is divisible by k. At most one of the integers x and x / k can appear in the maximum k-multiple free subset. Also for any integer y at most one of the numbers y and yk appears in the answer. If you look like this you can see the input as chains of numbers so that for each chain no two adjacent elements can appear in the output. For example, If k = 2 then 6, 12, 24, 48, 96 forms a chain. It’s easy to see that from a chain of length l we can choose at most (l + 1) / 2 elements in the answer. So the solution would be to compute the lengths of the chains and pick as much numbers as we can from each chain. You can sort all the numbers and do binary search or similar things to find the length of chains. Here’s a cute greedy solution which picks numbers greedily from the chains:

First sort all the numbers. Also consider an empty set of integers S, which represents the output. For each integer x in the sequence, If it’s not divisible by k, just pick it and insert it into S. Otherwise if it’s divisible by k check if x / k is in S or not. If it’s not in S insert x into S otherwise skip x.

I’d also like to note that this problem comes from an old problem in UVa Online Judge, with the same the name.

274B - Zero TreeAuthor: havaliza

In the problem statement vertex 1 is not mentioned as root of the tree. But it seems if we make it the root of the tree we can figure out the solution easier. For the leaves of the tree we can see the least number of steps needed to make each of them equal to zero. Consider a vertex which all its children are leaves. The minimum number of times that we should increase this vertex is at least as the maximum times one of the children of this vertex is increased. Also the minimum number of times this vertex is decreased is at least as maximum times one of the children of this vertex is decreased. Now we know some necessary plus or minus steps that this vertex is included in them. So after all of the children of this vertex reached zero, this vertex itself has some new value. If the current value of the vertex is positive we should decrease this vertex certain times otherwise we should decrease it. So we can find the minimum number of times this vertex should be decreased and the minimum number of times this vertex should be increased. As we showed above if we know these pair of numbers for each child of a vertex then we can calculate these numbers for that vertex too.

This can be implemented using a simple DFS on the rooted tree. And the answer to the problem would be the sum of increments and decrements of vertex 1. The time complexity of the solution is O(n).

274C - The Last Hole!Author: haas

In the solution we will try to find the position of all points which are the last moments in holes. Here we claim that each minimal potential hole is one of these two forms:

For each three centers that form an acute triangle it’s obvious that they form a potential hole. The last point in this hole would be the in triangle’s circumcenter.

For each four centers which are sides of a square it’s also obvious there’s a potential hole with last point being the square’s center.

For each potential hole we should check if the last point is not covered with any other circle in the last moment. The solution would be the hole with maximum distance from the centers which won’t be covered by anything else.

Let’s remind some geometry facts. We know that circumcenter of a triangle is the point where the three perpendicular bisectors of the triangle meet. Also the circumcenter of the triangle lies inside the triangle if and only if the triangle is acute. Circumcenter is the point which has equal distance from each vertex of the triangle.

Using above information it’s easy to prove that three circles make a hole if and only if the triangle they form is acute. Now what remains is to prove that in the last moment which the hole is disappearing there are 3 triangles or four forming a square enclosing the hole. I’m not going into details but the proof would be like this. Consider the last point of a hole. There are some circles which form the border of the hole in the last moment. These centers have the same distance from the last point. We need to prove that only three of the centers or four of them which form a square do the same job. And all others can be ignored. Consider the circle which these centers lie on its perimeter. Here’s a way to pick at most four of these points which make that hole. As long as there are three consecutive points which form make a obtuse triangle delete the middle point (why?). It’s easy to see what will remain at the end is either a square or an acute triangle.

The implementation can be done in O(n4) with iterating through all triangles in O(n3) and checking them in O(n). Also there are at most O(n3) squares, because once you’ve picked three of its vertices the fourth will be unique.

We’ve seen other coders implementing this solution or other solutions in better time complexities. So please share your solutions in the comments. :)

274D - Lovely MatrixAuthor: havaliza

The naïve solution for this problem would be to make a graph were each vertex represents a column of the grid. Then for each two not erased integers x and y in the same row where x < y we can add an edge from the column of x to the column of y in our graph. Then topological sorting on the built graph would give us the sought order of the rows. But there can be as much as O(m^2) edges in our graph and thus a O(nm2) solution won’t pass the time limit.

But still the idea to solve this problem is to implement topological sort in a such way that the graph we make has less edges or to make less processing to find the topological sort. Here I present two solutions which use topological sorting. One implements topological sorting explicitly in a graph of columns as its vertices with some extra vertices but fewer edges. The other one does some kind of topological sorting without building the graph and by deciding which column can come as the first column of our ordering, and doing the same thing until all columns come in order.

The first solution relies on decreasing the number of edges we used in the graph of our naïve solution. Consider the numbers of a row sorted. We insert an extra vertex between each pair of adjacent different numbers. Then each column gets connected to the next extra vertex and each extra vertex gets connected to the columns before the next extra vertex. In this way the sorted order of this row would be preserved in topological sorting. We do the same thing for each row, so topological sort on the final graph would give us the sought ordering of columns. This can be implemented in O(nmlgm).

In the second solution for each row we color all the minimum not erased elements of that row. The first column in the output permutation should be a column where all of its non erased elements are colored. So we put this column as the first column. Now the rest of the columns can be ordered by the same way. If at some point we can’t find a suitable column then there’s no solution. This also can be implemented in O(nmlgm).

It seems the problem was easier than a usual D problem, but before the contest I didn’t think so. I myself found the idea to solve this problem after some time, so I thought it wouldn’t be suitable for a C. Any ideas on how to measure the hardness of a problem better for next times? Because it doesn’t feel so good not to see the problems solved according to the foreseen difficulty level! :D

274E - Mirror RoomAuthor: havaliza

The blocked cells can make lots of complicated patterns. So it’s obvious that the solution in includes simulating the path the laser beam goes. But the dimensions of the gird are large and the beam might travel a long path before entering a loop. So naïve simulation will surely time out (See note!).

It’s kind of obvious that the beam finally comes back to its initial position and direction. Here were going to prove that the maximum number of times the beam might reflect until it reaches its first state is O(n + m + k). Consider an empty grid, It has O(n + m) maximal empty diagonal segments. When we block a cell, the two diagonal segments which pass this cell split. So the number of maximal empty diagonal segments increases by two. There for there are O(n + m + k) of these segments. Also If you look at the behavior of the beam it passes some of the segments one after another. So if you simulate the beam, it reflects O(n + m + k) times. Instead of naïve simulation we can find the next position the beam reflects.

Now we’re going to prove that no cell will be visited twice. A cell gets visited twice in the cycle if we pass it in both NE-SW direction and NW-SE direction. Consider the grid colored in black and white like a chessboard. There are two types of diagonal segments the NE-SW ones and NW-SE ones (property 1). At each reflection we alternate between these two. Also there are two types of segments in another way, black segments and white segments (property 2). As you can see each time one of the properties changes the other one also changes. As a result we’ll never pass a black cell in both directions, and the same is for a white cell.

So this problem can be solved with simulation in O((n + m + k)lgk).

You'd like to read Petr's solution for a clean implementation of this approach. 3162462

Note: The random tests I had generated before the contest were weak and I didn’t notice that naïve simulation solutions would pass the test. Now the tests are more powerful. :)

Codeforces Round #167 tutorial

By Sereja, 10 years ago, In English272A - Dima and Friends

We will bruteforce number of fingers that will be show Dima, then if total sum of fingers = 1 modulo (n+1), Dima will clean the room. So we should increase answer if the remaining part after division by (n+1) is not 1.

272B - Dima and SequenceFirst of all — f(i) is number of ones in binary presentation of number. We will repair all numbers to functions of them. Now we have to find number of pairs of equal numbers. Lets Q[i] — number of numbers with i bits, the answer will be sum of values Q[i]*(Q[i]-1)/2 for all i.

273A - Dima and StaircaseLets L will be the answer after last block, last block was (w1, h1), next block is (w2, h2). Next answer will be max(L+h1, A[w2]), where A — given array. At the beggining we can suppose that L = 0, w1 = 0, h1 = 0.

273B - Dima and Two SequencesNot hard to understand that answer will be (number of numbers with first coordinate = 1)! * (number of numbers with first coordinate = 2)! * ... * (number of numbers with first coordinate = 10^9)!/(2^(number of such i = 1..n, that Ai=Bi)). The only problem was to divide number with non prime modulo, it can be easely done if we will count number of prime mulpiplies=2 in all factorials. Then we can simply substract number that we need and multiply answer for some power of 2.

273C - Dima and HorsesNot hard to understand that we have undirected graph. Lets color all vetexes in one color. Then we will find some vertex that is incorrect. We will change color of this vertex, and repeat our search, while it is possible. After every move number of bad edges will be decrease by 1 or 2, so our cycle will end in not more then M operations. So solutions always exists and we need to change some vertex not more then M times, so we will take queue of bad vertexes and simply make all operations of changes.

273D - Dima and FigureGood picture is connected figure that saticfy next condition: most left coordinates in every row of figure vere we have some cells will be almost-ternary, we have the same situation with right side, but here we have another sign. So it is not hard to write dp[i][j1][j2][m1][m2] numbr of figures printed of field size i*m, where last row contain all cells from j1 to j2, the most left coordinate will be m1, the most right coordinate will be m2. But it is not enough. We have to rewrite it in way that m1 will mean — was there some rows j and j+1 that most left coordinate if row j is bigger then most left coordinate in j+1. So now it is not hard to write solution with coplexity O(n*m*m*m*m). But we should optimize transfer to O(1), is can be done using precalculations of sums on some rectangels.

273E - Dima and Gamewill be added soon.

Codeforces Round #166 Tutorial

By RAD, 10 years ago, translation, In English271A - Beautiful Year

This is a very straight forward problem. Just add 1 to a year number while it still has equal digits.

271B - Prime Matrix

Precalculate the next prime for every integer from 1 to 105. You can do that in any way. The main thing is to test all the divisors up to square root when you are checking if a number is prime.

Now for each aij (element of the given matrix) we can easily calculate addij — how many do we have to add in order to make aij prime. After that all we need to do is to find row or column with minimal sum in this new matrix.

271C - Secret

If 3k > n there is no solution (because each of the k sets must have at least 3 elements). Otherwise we can divide first 3k words in the following way:

1 1 2 2 3 3 ... k k 1 2 3 ... k

For each of the k sets, the difference between the first and the second elements will be 1. And the difference between the second and the third elements is definitely not 1 (more precisely, it is 2k - i - 1 for the i-th set). So each set doesn't form an arithmetic progression for sure.

For this solution it doesn't matter how we divide the rest n - 3k words.

271D - Good Substrings

At first, build a trie containing all suffixes of given string (this structure is also called explicit suffix tree). Let's iterate over all substrings in order of indexes' increasing, i. e. first [1...1],  then [1...2], [1...3], ..., [1...n], [2...2], [2...3], ..., [2...n], ... Note, that moving from a substring to the next one is just adding a single character to the end. So we can easily maintain the number of bad characters, and also the "current" node in the trie. If the number of bad characters doesn't exceed k, then the substring is good. And we need to mark the corresponding node of trie, if we never did this before. The answer will be the number of marked nodes in the trie.

There is also an easier solution, where instead of trie we use Rabin-Karp rolling hash to count substrings that differ by content. Just sort the hashes of all good substrings and find the number of unique hashes (equal hashes will be on adjacent positions after sort). But these hashes are unreliable in general, so it's always better to use precise algorithm.

271E - Three Horses

It could be proved, that a card (x, y) (x < y) can be transformed to any card (1, 1 + k·d), where d is the maximal odd divisor of y - x, and k is just any positive integer. So every (ai - 1) must be divisible by d, i. e. d is a divisor of gcd(a1 - 1, ..., an - 1), and we can just iterate over all possible divisors. Let's take a look at all the initial cards (x, y), which have have d as their maximal odd divisor: these are cards with y - x equal to d, or 2d, or 4d, 8d, 16d, ... Don't forget that the numbers x and y must not exceed m. It means that the total number of cards with some fixed difference t = y - x is exactly m - t.

The resulting solution: sum up (m - 2ld), where d is any odd divisor of gcd(a1 - 1, ..., an - 1), and l is such, that 2ld ≤ m.

Codeforces Round #165 Tutorial

By gen, 10 years ago, translation, In EnglishDiv II A — Fancy FenceProblemThe problem is to tell whether there exists a regular polygon with angle equal to a.

SolutionConsider all supplementary angles of the regular n-polygon with angle a, which are equal to . Their sum is equal to , because the polygon is convex. Then the following equality holds: n·(180 - a) = 360, which means that there is an answer if and only if .

 

Time: O(t).

Memory: O(1).

Implementation: C++, Java

CommentsThe problem can be also solved by rotating vector (1, 0) by angle  until it returns in this position (but at most 360 times), and checking that only one full turn has been made (implementation example: C++).

It is also a rare problem on Codeforces that contains just 1 sample test, 1 pretest and 1 full test.

Div II B — MultithreadingProblemIn this problem we are asked to find the number of n-permutation elements that definitely have been moved after performing any sequence of move-to-front element operations. Equally, we should find the maximum possible number of elements that could have not been moved.

SolutionIf some ai is greater than ai + 1, it is clear that ai definitely contains a new message because the order of these two elements has changed. Let the last such element be ak. Then all of the elements ak + 1, ak + 2, ..., an can contain no new messages, since their order has not changed. The answer to the problem is n - k. If there is no such ak the order hasn’t changed at all and there may be no new messages.

Time: O(n).

Memory: O(n) / O(1).

Implementation: C++, Java

CommentsThe problem was born while staring at the Codeforces main page and trying to think up an easy Div II problem. =)

Div II C / Div I A — Magical BoxesProblemWe are given ai squares with side length 2ki. It is allowed to insert squares only inside larger ones, and no two squares should overlap. We must determine the minimum p so we can place all the given squares inside a square with side length 2p.

SolutionSuppose we can put all the squares inside a square with side length 2p. Then we can insert each ki type squares independently along the grid as shown in the picture. No two squares will overlap, since 2x divides 2y, if x < y. That means that we can find the smallest square that can hold all the given squares with side length 2ki for each ki separately. The answer will be the side length of the largest such square.

 

To be able to put ai squares with side length 2ki inside a square with side length 2s, the following should hold:

(2s)2 ≥ (2ki)2·ai4s ≥ 4ki·ai4s - ki ≥ aiWe can then find the minimum s:



In a special case, if we obtain s = ki, s should be increased by 1.

Time: .

Memory: O(1).

Implementation: C++, Java

CommentsThe problem can be also solved using binary search on p. However, we can see that each square with side length 2k + 15 holds any number of squares with side length less than 2k, since . So it is enough to find the first square that fits from range 2max{k} + 1 to 2max{k} + 15.

Div II D / Div I B — Greenhouse EffectProblemThere are n points on the line, each of type from 1 to m. We can freely divide the line into m - 1 intervals and replace some points so each point with type i is inside the i-th interval numbered 1 to m from left to right. We must find the minimum number of points to replace.

SolutionFirst, observe that the coordinates don’t matter: only the order of the points is important. Let there be some number of points we can replace to achieve the good arrangement. Then all the other points remain in their positions, so their values must be in increasing order from left to right. Then we must find the maximum number of points that can remain in their positions, which is the longest non-decreasing subsequence of types in the input. If it is of length l, the answer is n - l.

In this problem it was enough to implement a quadratic solution. We count dp[i][j] — the length of the longest non-decreasing subsequence on prefix [1;i], with element of type j being the last in subsequence. The transition is as follows:

For easy implementation, we can maintain only array dp[j], and skip the second case.

Time: O(n2) / .

Memory: O(n2) / O(n).

Implementation: C++

CommentsWe had to solve this problem during the work on our project, the origin lies in arranging some rectangular table borders. Our original project dp implementation actually runs in O(nm).

Div II E / Div I C — Flawed FlowProblemIn this problem we are given an undirected graph and its flow, and we must reconstruct the edge directions of this flow.

SolutionThe key element to solving the task is the following observation: if we know all the incoming edges of a vertex, all the remaining edges must be outgoing. The source has no incoming edges, so we already know that all its edges are outgoing. For all other vertices except the sink the amount of incoming and outcoming flow is the same, and is equal to half of the sum of the flow along its incident edges. The algorithm then is to repeatedly direct all the flow from the vertices for which all the incoming edges are known. This can be done with a single BFS:

for all v from 2 to n-1    f[v] := sum(flow(v,u))/2;put source in queuewhile queue is not empty    v := pop(queue)    for all edges (v, u)        if (v, u) is not directed yet            direct v -> u            f[u] = f[u] - flow(v,u)            if u not sink and f[u] = 0                push(queue, u)As the flow contains no cycles, we can sort the vertices topologically. Then we can be sure that, until all edge directions are known, we can put at least the first vertex with unknown edges in the queue, as all of its incoming edges will be from vertices with lower indices, but we took the first vertex with unknown edges.

Time: O(n + m)

Memory: O(n + m)

Implementation: C++, Java

CommentsThe obvious "easy" solution is to run some maxflow algorithm and get the answer. However, such implementations failed on anti-maxflow pretest #6.

Div I D — Maximum WaterfallProblemWe are given n horizontal segments on a plane, and 2 extra topmost and bottommost segments. These two segments are the source and the sink of the flow. A flow can pass from one segment to a lower segment, if their horizontal projections overlap and there is no other segment between them so their projections overlap. The value of the flow on such segment edge is equal to the length of the horizontal projection overlap. We must find the maximum possible value of the flow along a single segment path.

SolutionWe will use a sweepline algorithm to solve this task. This horizontal sweepline runs from bottom to top, and holds the parts of the segments that are visible from the line this sweepline is currently at. Each part also holds the reference to its original segment. The sweepline itself is implemented with a binary search tree.

The events of the sweep are the segments. When a new segment is found, we want to find all the lower segments that we can direct the flow onto from this segment. These can be only the original segments of the parts currently in the sweepline whose projections overlap with this segment. Then we iterate over all such parts p (finding the first such part is an  operation). How do we know that we can direct the flow onto p? Observe that if there is some segment that prevents this, there should be also a part q in the sweepline that also can be seen from the current segment. And since the projections of all three segments overlap, this part can only be directly to the left or to the right of p in the binary search tree. So we just check whether the original segments of the two parts next to p prevent the flow from the current segment to the original segment of p.

Afterwards, we remove all such parts from the sweepline, and insert a new part corresponding to the new segment. If the new segment only partially covered an existing part, we reinsert the remaining portion of that part. There are at most two such portions — one on each side of the segment. Thus each segment inserts at most 3 new parts and the size of the sweepline is O(n). Each part is handled just once before removal, so the total time of such operations is .

Once we know we can direct the flow through  we can immediately update the maximum downwards flow of a:

fa = max(fa, min(fb, min(ra, rb) - max(la, lb)))When we reach the top, ftop will be the answer.

 

Time: 

Memory: O(n)

Implementation: C++, Java

CommentsAnother problem from our project. You can also first build a graph from the segments using the same sweepline and then find the path with the maximum flow in that graph. In the original problem you have to find this graph and there are no top and bottom segments.

Div I E — String TheoryProblemIn this problem we have an n × m rectange. Each unit midpoint is connected with a segment to some other midpoint not on the same side of the rectangle. We can change the order of the columns and rows, but the segments must remain attached to their midpoints. We should find such a rearrangement that no two segments intersect, or tell that there is no solution.

SolutionThere are overall 6 types of segments that connect the sides:

left-top;top-right;right-bottom;bottom-left;left-right;top-bottom;If there are both left-right and top-bottom segments, there is no solution. Otherwise there remain only 5 types of segments. Without loss of generality suppose there are no left-right segments. Let’s take a closer look at what should the end picture of the rectangle be:

 

All left-top segments should be at the left top corner connecting positions (L,i) and (T,i), otherwise they surely would cross some other segment. Similarly must be positioned top-right, right-bottom, bottom-left segments. Finally, all top-bottom segments should be parallel. We also observe that the number of left-top segments must be equal to the number of right-bottom segments and the number of top-right segments should be equal to the number of bottom-right segments. Thus the important observation: the picture of the end arrangement is unique and can be determined from the input simply by counting the number of segments of each type.

Next we define a cycle to be the sequence of segments, where the second midpoint of some segment in the cycle is equal to the first midpoint in the next segment in the cycle. In the given example there are two such cycles (but the direction of each cycle actually matters):

 

Then we observe that the set of the cycles does not change with any permutation by the definition of the cycle. We can make a sketch of the solution: we should find the cycle sets in the given arrangement and in the end arrangement, and compare them for equality.

At this point we actually find all the cycles in both arrangements. There are only two types of cycles:

(left-top)  (top-right)  (right-bottom)  (bottom-left);other cycles.We can easily check whether the sets of first type cycles match, since the length of such cycles is 4. If they match, we rearrange the columns and rows involved to match the end arrangement.

How to compare the remaining cycles. Consider a following example:

 

Let the difference in the number of left-top and left-bottom segments be i, and this number plus the number of top-bottom segments s. If we enumerate the midpoints as in the figure, we can see that each top midpoint k is connected to the bottom midpoint  (top-right segments continue as corresponding left-bottom segments). Thus we can describe it as a permutation

Our cycles correspond to the cycles in this permutation, with top-right segment continuation to left-bottom segment corresponding to the case where permutation cycle element decreases. It is known that the number of such permutations is  and their length is . So all these cycles have the same length. Denote the remaining segment types as some letters (in picture A, B, C). Then not only the length, but the strings describing the cycles are also the same, but can be shifted cyclically (here the direction of the cycles also is important). Besides, we know this string from the correct arrangement cycle. Thus we need to compare all the remaining given arrangement cycle strings to this string, considering cyclic shifts as invariant transformations. For each string this can be done in linear time, for example, using the Knuth-Morris-Pratt algorithm. When we find a cyclical shift for each cycle, we can position its relevant columns and rows according to the end arrangement.

Time: O(n + m).

Memory: O(n + m).

Implementation: C++, Java

CommentsThis is a total killer task for coding. It took both of us around 5 hours to code the implementation. Congratulations again to kelvin, at the time of writing still the only one to solve the problem (and of course to anyone who will get this difficult problem accepted =) ).

Codeforces Round #164 (Div. 2) — Problems Analysis

By gojira, 10 years ago, translation, In English268A - GamesWith only 30 teams, the simplest solution is simulating all the matches:

for i = 1 to N  for j = 1 to N    if i != j and h[i] = a[j] then      ++ansAn O(N + M) solution is also possible, where M is the length of colors' range (i.e. 100 under the given constraints). First, you need to count for each color i the number of teams cntH[i] which have the home uniform of color i and the number of teams cntA[i] which have the away uniform of color i. The answer is the sum of products of these quantities for each color, i.e. sum of cntH[i] * cntA[i] over all i.

268B - ButtonsLet us first detect the worst case scenario. It is more or less apparent that when Manao tries to guess the i-th (1 <= i <= n) button in order, he will make n-i mistakes in the worst case. After that the correct button is evident.

Now let's count the total number of presses Manao might need before he guesses the whole sequence. When he is guessing the first button he makes n-1 mistakes, but the "mistake cost", i.e. the number of presses before the mistake is made, is equal to 1. When Manao goes for the second button, the mistake cost becomes 2, because each time Manao needs to press the first (already guessed) button. Continuing like this, we obtain that when Manao tries to guess the i-th button in order, he will perform (n-i) * i button presses.

After Manao guessed the correct sequence, he needs to enter it once, which is another n presses.

So we already have an O(n) algorithm: sum up (n-i)*i for i=1, ..., n-1 and add n to the sum obtained.

When n is anything that fits in 32-bit integer type, the task is solvable in O(1)*. The sum (n-i)*i is two separate sums: the sum of n*i and the sum of i*i. The first sum is n*(1+...+n-1), which can be computed with the sum of arithmetic progression. The second sum is the sum of squares from 1 to n-1, which can be evaluated with a polynom of degree 3: http://pirate.shu.edu/~wachsmut/ira/infinity/answers/sm_sq_cb.html

*The only problem is that the answer for large n-s does not fit even in 64-bit integer type, but at least we can compute its remainder from division by anything.

268C - Beautiful Sets of PointsObviously, if a set contains a point (x', y'), it can not contain any other point with x=x' or y=y', because these two points would be an integer distance apart. There are only n+1 distinct x-coordinates and m+1 distinct y-coordinates. Therefore, the size of the set sought can not exceed min(n, m) + 1.

If the constraint x+y>0 was not present, the set of points (i, i) (0 <= i <= min(n, m)) would do nicely. The distance between two points (i, i) and (j, j) is equal to |i-j|*sqrt(2) and can only be integer when i=j. On the other hand, there are min(n, m) + 1 points and we already know that we can't take more than that.

Since point (0, 0) is restricted, we can take the other "diagonal", i.e. use points (i, min(n, m) - i).

268D - Wall BarsThose who are well experienced at dynamic programming can scroll down to "Overall solution" right away. Those who have some experience in DPs can read my attempt to explain how you can come up with that solution. Those with no experience probably shouldn't read this at all :)

Imagine a solution which considers all possible designs, adding the bar-steps one by one. Consider any sequence, like 2123412413. There are 4 ways to continue this sequence by appending '1', '2', '3' or '4' to it. For each of the 4^n wall bars / strings we need to check that for at least one of {'1', '2', '3', '4'} character the following is true: its first entry in the string is at position no more than h, each next one differs from the previous by no more than h and the last one is beyond position n-h.

Surely, such a solution won't work for large n-s in any reasonable time, but we can start from it in the search of a better approach. First, let's note that we can check the feasibility of the string after each character addition: if somewhere in the middle of string we noticed that for each of the characters the necessary conditions are broken, there is no reason to complete the string. Also, note that we don't need the whole prefix to check the validity of the conditions after each character addition. All we need to know is when each of the '1', '2', '3' and '4' characters occured last, and whether the conditions for each of the characters have been fulfilled up to this point. It turns out that two prefixes in which [each of the characters last occured at the same position] and [the validity of the conditions for each character are equal], are absolutely equivalent for the brute force algorithm's further operation. That is, for example for h=4 these two prefixes can be completed (up to length n) in the same number of ways:

4412342413212424224132The last time each of the characters have occured at the same positions, characters '1' and '3' are already "lost" (the conditions are already broken for them), characters '2' and '4' can still turn the string into a valid one.

With the help of the observations made, we can already build a polynomial-time algorithm based on dynamic programming principle. Let ways[curN][i][j][k][l][ii][jj][kk][ll] be the number of designs of height curN, where the last step in direction 1 was at height i, the last step in direction 2 — at height j and so on; ii, jj, kk, ll are boolean parameters which indicate whether the conditions are valid in the corresponding direction. When we choose the direction for the step at height curN+1, we obtain a design with curN+1 steps, the last step in the direction we chose is now at height curN+1 and rest stay where they were. Conditions validity can also be reassessed. Since curN is always one of {i, j, k, l}, we can obtain a O(n^4) algorithm. However, this is still too slow.

Another observation: if we are looking at a bar at height curN and the last step in this direction was earlier than curN-h steps ago, we don't really care which height was it exactly at, since this direction is not valid any more. Therefore, the number of states in our algorithm can be only O(n*h^3). Moreover, those ii,jj,kk,ll parameters correlate with the heights of the latest steps in the corresponding directions, so we can (almost) get rid of them, thus reducing the number of states in a number of times.

On the base of these observations we can probably build different solutions. I will tell mine.

Overall solutionWe will keep a 5-dimensional DP :) Let ways[curN][alive][last1][last2][last3] be the number of designs where:

There are exactly curN steps.

If the direction of the latest step if still "alive", then alive = 1, otherwise it's equal to 0. A direction is alive if its first step was not higher than h and each subsequent one was higher than the previous by at most distance h.

last1, last2 and last3 keep the information about the other directions in any order. lasti can be zero in two cases: if there were no steps in the corresponding direction, or if the latest one was earlier than h steps before. Otherwise, lasti is the number of steps between the current step and the latest step in the corresponding direction.

We can optimize by keeping last1<=last2<=last3, which reduces the number of states in roughly 6 times. However, this complicates the code and doesn't have a significant effect (since the transitions processing becomes costly). Thus I will not consider it at all.

What transitions can be made from state [curN][alive][last1][last2][last3]? We shall process the states in order from curN=1 to curN=N-1. ways[1][1][0][0][0] (i.e. a single step) is equal to 4 as a base case. So we have:

If we add a step in the same direction as the latest (i.e. the one at height curN), then we obtain state [curN+1][alive][last1+1][last2+1][last3+1] (roughly): curN has increased by 1; the "livingness" of the direction of the last step could not change; all the lasti-s have increased by 1. However, note that for lasti=0 it should not be incremented (the corresponding step either does not exist at all, or is way below). Also, for lasti=h-1 it turns to zero (the last step is now too low).

If we put the step in the same direction as the one which was at height last1, we obtain state [curN+1][last1 > 0 || curN < h][alive][last2+1][last3+1]. This decyphers in the following way: if last1>0, then this condition is alive. last1 could also be 0, but the number of already built steps less than h — in which case this is the first step and the direction becomes alive by putting it. The direction denoted by last1 has been replaced (in the state parameters) by the one in which the curN-th step was sticked out. Therefore, it was 1 step ago and we should write [1] there. On the other hand, that direction could already be dead and we would need to write [0]. It turns out that the value coincides with value of alive. last2 and last3 change in the same way as in the previous case.

Directions last2 and last3 are treated in the same way as last1.

When we process a transition, the number of designs corresponding to the new state increments by ways[curN][alive][last1][last2][last3]. So the overall answer is sum of all [n][1][a][b][c], where 0<=a,b,c<h plus sum of all [n][0][a][b][c], where at least one of a, b, c is non-zero. So we have an algorithm of O(n*h^3) complexity which needs asymptotically the same amount of memory. Its implementation could catch ML (especially on Java). This can be handled through the following observation: since we only need values [i-1][][][][] to compute [i][][][][]-s, only O(h^3) states need to be kept at any given moment.

Well, before writing this analysis I didn't realize it was so huge :)

You can check SteamTurbine's solution at 3027309 for a very compact implementation of a similar idea.

268E - PlaylistLet us first find the answer for a fixed sequence of songs. Consider any two songs which are at positions i and j (i < j) in the playlist. If Manao liked song i and disliked song j, then song i will be listened to again. Therefore, with probability p[i]*(1-p[j]) the process length will increase by L[i]. The sum of L[i]*p[i]*(1-p[j]) over all pairs (plus the length of all songs since Manao listens to them at least once) is the expected length for the fixed sequence.

So we have that if there are two songs (l1, p1) and (l2, p2), the first one should be placed earlier in the playlist if l1*p1*(1-p2)>l2*p2*(1-p1) and later otherwise. This is obviously true if there are only two songs. But suppose that we have more and you ask, why can't there be another song (l3, p3) such that the above inequality rules out that the first song should be after this one and the second song should be before it? Then it's unclear which of the orders results in the maximum expected value. Consider this case in details:

l1*p1*(1-p2)>l2*p2*(1-p1)l1*p1*(1-p3)<l3*p3*(1-p1)l2*p2*(1-p3)>l3*p3*(1-p2)<=>l1*p1/(1-p1)>l2*p2/(1-p2)l1*p1/(1-p1)<l3*p3/(1-p3)l2*p2/(1-p2)>l3*p3/(1-p3)(this is not quite true if any pi is equal to 0 or 1, but that's not important here)

We have a contradicting system of inequations, so such a case is impossible.

Next, let's consider some order of songs (l[1], p[1]), ..., (l[n], p[n]), in which there is a pair of neighbouring songs i and i+1, for which the condition l[i] * p[i] * (1 - p[i + 1]) >= l[i + 1] * p[i + 1] * (1 - p[i]) does not hold, and assume that this order is optimal. Evidently, if we interchange songs i and i+1, the answer will only change by the value contributed by this pair (i.e. l[i] * p[i] * (1 - p[i + 1])). The rest of the songs keep their order towards song i and song i+1. But l[i] * p[i] * (1 - p[i + 1]) < l[i + 1] * p[i + 1] * (1 - p[i]), therefore if we put song i+1 before song i, we obtain a larger value. So we have a contradiction — the order chosen is not optimal.

So it turns out that the permutation with maximum possible expected value is obtained when sorting the songs in decreasing order of l[i]*p[i]/(1-p[i]). But we still have a problem of computing the answer for a fixed permutation: we only learned how to do this in O(n^2), which is too slow with n=50000. We can use an idea which is probably a yet another dynamic programming example. Suppose we have fixed j and are counting the contribution of song j towards the answer if Manao dislikes it. This value is (l1*p1 + l2*p2 + ... + l[j-1]*p[j-1]). For j+1, the corresponding value will be (l1*p1+...+l[j-1]*p[j-1]+l[j]*p[j]). It turns out that these values differ in only a single summand, so we can compute each of them in O(1) if we consider j-th one by one in increasing order. This idea can be expressed as follows:

lovedLenExp = 0.answerExp = 0.for j = 1 to N  answerExp += l[j]  answerExp += lovedLenExp * (1 - p[j])  lovedLenExp += l[j] * p[j]That's all :)

Codeforces Round #163 (Div. 2) Tutorial

By HolkinPV, 10 years ago, translation, In English266A - Stones on the Table

In this problem you should count number of consecutive pairs of equal letters. It can be done using one cycle and O(N) time.

266B - Queue at the School

In this you should realize the given process. You should t times swap elements i and i + 1 if on the place i was a girl and on the place i + 1 was a boy. You should not push some girl to the left multiple times at once. The solution can be written using O(N·T) time.

266C - Below the Diagonal

This problem can be solved using constructive algorithm. We will use inductive approach. At first, we have matrix of size n and n - 1 ones in it. Therefore, there is a column with no ones in it. So, we put this column to n-th place. In this case, the lower right element will be 0. Then find any row with at least one integer one and put it to the n-th place.

After these operations the element in cell (n, n) equals to 0 and the last row has at least one integer one. Therefore, we can reduce the dimension of our problem, that is n:  = n - 1. In our new problem we have no more than n - 2 ones. So, we can solve this problem using the same algorithm. When n equals to 1 you should finish algorithm, because there is no ones left. This algorithm uses O(N) swap operations, no more than two for every n.

266D - BerDonalds

I'll tell a few ideas how to solve this problem. Firstly, describe the solution with time O(N4). Consider every edge (u, v) of length len where could be the answer point. Let this point lie at a distance x from vertex u. So, the distance from this point to vertex i would be min(x + d[u][i], len–x + d[v][i]), where d[x][y] — distance between vertices x and y. Equate these values and get the critical value x for vertex i, x = (len + d[v][i]–d[u][i]) / 2. It follows that the answer to the problem is half-integer. So, for every edge and every other vertex we get set of critical points. We should check them all include the vertices of the graph (ends of the segments). This solution may probably pass with some optimizations.

Another solution with complexity O(N3·log2). Multiply all weights by 2. Consider every edge where should be the answer and make binary search for the answer (in integers). To check some current value you should consider every vertex i and assume that the answer is achieved in this vertex. In this case, the answer point must lie on this edge <= some value l[i] or >= some value r[i]. This subproblem is solved using offline algorithm using sorting events and maintaining the balance.

Also, you can use ternary search on every edge of the graph. But you should divide every edge on several segments and find the answer on every segment, because the ternary search is incorrect in this problem.

The last two solutions can provide accepted, if you realize them carefully. Also note, that there is the solution with complexity O(N3) by the author RAD.

266E - More Queries to Array...

This problem can be solved using data structure. We would use segment tree, we will support k segment trees for every power. At every vertex we will calculate weighted sum of the appropriate power, also we will save some number that indicates the color of the whole segment, if any.

User Egor in comments to the post and user mexmans in comments to the tutorial tell their formula to get the answer. I try to describe how to get them by yourself. Firstly, you should write what value your segment tree gives. The tree can calculate the sum . You need to calculate the sum , you can write it also as . Then you should write the last sum for some first powers (at least three) (at piece of paper) and subtract the second sum (what you need) from the first sum (what your tree can calculate). You get an expression that describes what should be subtracted to get the answer from the value what you tree can calculate. This is just the Newton binomial without the highest power.

So, the answer for power j is expressed as the subtraction of the value of query to your segment tree and the Newton binomial, with all powers that are less than j (these values can also calculated using your segment tree). Partial sum of the powers and binomial coefficients can be precalced. The solution has the complexity O(N·K·log(N)).

Codeforces Round #162 Tutorial

By rng_58, 10 years ago, In EnglishDiv2 A Colorful Stones (Simplified Edition) (Author: rng_58)In this problem you just need to implement what is written in the statement. Make a variable that holds the position of Liss, and simulate the instructions one by one.

Div2 B Roadside Trees (Simplified Edition) (Author: snuke)The optimal path of Liss is as follows: First she starts from the root of tree 1. Walk up the tree to the top and eat a nut. Walk down to the height min(h1, h2). Jump to the tree 2. Walk up the tree to the top and eat a nut. Walk down to the height min(h2, h3), ... and so on.

Div1 A / Div2 C Escape from Stones (Author: DEGwer)In this problem, there are many simple algorithms which works in O(n). One of them (which I intended) is following:

You should prepare 2 vectors. If s[i] = 'l', you should push i to the first vector, and if s[i] = 'r', you should push i to the second vector. Finally, you should print the integers in the second vector by default order, after that, you should print the integers in the first vector in the reverse order.

This algorithm works because if Liss divides an interval into two intervals A and B and she enters A, she will never enter B.

Div1 B / Div2 D Good Sequences (Author: DEGwer)The main idea is DP. Let's define dp[x] as the maximal value of the length of the good sequence whose last element is x, and define d[i] as the (maximal value of dp[x] where x is divisible by i).

You should calculate dp[x] in the increasing order of x. The value of dp[x] is (maximal value of d[i] where i is a divisor of x) + 1. After you calculate dp[x], for each divisor i of x, you should update d[i] too.

This algorithm works in O(nlogn) because the sum of the number of the divisor from 1 to n is O(nlogn).

Note that there is a corner case. When the set is {1}, you should output 1.

Div1 C / Div2 E Choosing Balls (Author: hogloid)There are many O(Q * N * logN) solutions using segment trees or other data structures, but probably they will get time limit exceeded.

We can solve each query independently. First, let's consider the following DP algorithm.

dp[c] := the maximal value of a sequence whose last ball's color is c

For each ball i, we want to update the array. Let the i-th ball's color be col[i], the i-th ball's value be val[i], and the maximal value of dp array other than dp[col[i]] be otherMAX. We can update the value of dp[col[i]] to dp[col[i]] + val[i] × a or otherMAX + val[i] × b. Here, we only need to know dp[col[i]] and otherMAX. If we remember the biggest two values of dp array in that time and their indexes in the array, otherMAX can be calculated using the biggest two values, which always include maximal values of dp array other than any particular color.

Since the values of dp array don't decrease, we can update the biggest two values in O(1). Finally, the answer for the query is the maximal value of dp array.

The complexity of the described algorithm is O(QN).

Div1 D Colorful Stones (Author: rng_58)First, let's consider a simpler version of the problem: You are given a start state and a goal state. Check whether the goal state is reachable from the start state.

Define A, B, C, and D as in the picture below, and let I be the string of your instructions. A and B are substrings of s, and C and D are substrings of t.

 

It is possible to reach the goal state from the start state if there exists an instruction I such that:

1 A is a subsequence of I.2 B is not a subsequence of I.3 C is a subsequence of I.4 D is not a subsequence of I.So we want to check if such string I exists. (string s1 is called a subsequence of s2 if it is possible to get s2 by removing some characters of s1)

There are some obvious "NO" cases. When D is a subsequence of A, it is impossible to satisfy both conditions 1 and 4. Similarly, B must not be a subsequence of C. Are these sufficient conditions? Let's try to prove this hypothesis.

To simplify the description we will introduce some new variables. Let A', B', C', and D' be strings that can be obtained by removing the first characters of A, B, C, and D. Let c1 and c2 be the first characters of A and C.

 

Suppose that currently the conditions are satisfied (i.e. D is not a subsequence of A and B is not a subsequence of C).

If c1 = c2, you should perform the instruction c1 = c2. The new quatruplet will be (A', B', C', D') and this also satisies the conditions.If c1 ≠ c2 and B' is not a subsequnce of C, you should perform the instruction c1. The new quatruplet will be (A', B', C, D) and this also satisies the conditions.If c1 ≠ c2 and D' is not a subsequnce of A, you should perform the instruction c2. The new quatruplet will be (A, B, C', D') and this also satisies the conditions.What happens if all of the above three conditions don't hold? In this case A and C have the same length and A = c1c2c1c2..., B = c2c1c2c1. In particular the last two characters of A and B are swapped: there are different characters x and y and A = ...xy, B = ...yx. Now you found a new necessary condition! Generally, if A and B are of the form A = ...xy and B = ...yx, the goal state is unreachable. If the last instruction is x, Vasya must be in the goal before the last instruction, but then Vasya will go further after the last instruction. If the last instruction is y, we will also get a contradiction.

Finally we have a solution. The goal state is reachable from the start state if and only if D is not a subsequence of A, B is not a subsequnce of C, and A and C are not of the form A = ...xy, C = ...yx. The remaining part is relatively easy, so I'll leave it as an exercise for readers.

Div1 E Roadside Trees (Author: snuke)For this problem there are slides: Please check here.

UPD: Thank you for pointing out mistakes. They are fixed.

Codeforces Round #161 Tutorial

By RAD, 10 years ago, In English263A - Beautiful Matrix

If the single 1 is located on the intersection of the r-th row and the c-th column (1-based numeration), then the answer is |3 - r| + |3 - c|.

263B - Squares

If k > n, then the answer doesn't exist. Otherwise let's sort the squares by descending of their sizes. Now you can print any point that belongs to the k-th square and doesn't belong to the k + 1-th square. One of the possible answers is (ak, 0).

263C - Circle of Numbers

First of all, we have to check that each number occurs in the input exactly 4 times. If it's not true, then the answer definitely doesn't exist.

Otherwise, let's try to restore the circle. As cyclic shift of circle doesn't matter, let 1 to be the first number. As the second and the third number must be connected to each other and to 1, there are only few possibilities. So let's try them all. And when we know first three numbers, the rest of the circle could be easily and unambiguously restored in O(n). Just find a number, which is not included in the circle yet, and is connected to the last two numbers of the circle. Add this number to the resulting circle (as new last number), and repeat the procedure while possible. If we succeeded to add all the numbers to the circle, than the resulting circle is the answer.

263D - Cycle in Graph

Consider any simple path v1, v2, ..., vr which cannot be increased immediately (by adding a node to it's end, vr). In other words, all the neighbours of vr are already included in the path. Let's find the first node of the path (say, vl), which is connected to vr. It is clear that vl, vl + 1, ..., vr is a cycle and it contains all the neighbours of vr. But according to the problem's statement, each node has at least k neighbours. So length of the cycle is at least k + 1 ( + 1 is for node vr itself).

263E - Rhombus

Divide the rhombus of size k into 4 right-angled triangles as shown on a picture below. One of them has size k, two — size k - 1, and another one — size k - 2.

 

Let's solve the problem separately for each triangle. The most convenient way to do that is to rotate the input 4 times and run the same solving function 4 times. The result of this function will be a 2D array. Cell (x, y) indicates the answer we get if the right-angled vertex of triangle is located at cell (x, y). So it will be easy to combine 4 such arrays (just rotating and shifting properly) to get the actual answer for rhombus.

The main idea of the solution for triangle is the following. If we know the answer for a cell, we can easily move our triangle by one cell in any direction (right, down, left, or up) and recalculate the answer for that new cell in constant time. In fact, we need only 2 directions: right and down. And the values for top left corner should be calculated with straightforward cycles in O(k2) time.

 

More precisely, let's define 5 functions:

The sum on diagonal segment of k elements: 

The sum on vertical segment of k elements: 

The weighted sum on vertical segment of k elements: 

The sum on a triangle: 

The weighted sum on a triangle: 

Calculating the first 3 functions in O(nm) in total is quite obvious. Formulas for the others are following:

triangle(x, y + 1) = triangle(x, y) - diagonal(x, y - k + 1) + vertical(x, y + 1)

triangleWeighted(x, y + 1) = triangleWeighted(x, y) - triangle(x, y) + verticalWeighted(x, y + 1)

Formulas for moving in other directions are similar.

Codeforces Round #160 tutorial

By Sereja, 10 years ago, In English262A - Roma and Lucky Numbers

This problem just need to simulate everithing that was given in statment.

262B - Roma and Changing Signs

We will "reverse" numbers from the begining to the end while numebrers are negative and we did't spend all k operations.In the end there can leave some operetions, and we will "reverse" only one numeber, with minimal value k(that remains) times.

261A - Maxim and Discounts

Ofcourse the most optimal way is to use discount with minimal q_i. We will sort our numbers and will go from the end to begin of the array. We will by use our discount as soon as it will be possible. It's not hard to see that we will buy all the items with numbers I (zero-numeration from the end of the sorted array) such, that I%(q+2)<q.

261B - Maxim and RestaurantIf all people can come, we will return answer as n.If it is impossible, there will be finded some person that will be the last to come. We will brtueforce this value. Then we will detrminate dp[i,j,s] in how many ways j persons from the first i with total length s can be in the resturant. It is easy to calculate.Then we will add to the answer values dp[n][i][s]*i!*(n-1-i)! for all i,s such that s+p[h]>P. Where P — total length of the table, p[h] — length of the fixed person.

261C - Maxim and MatrixFor fixed m, the sum in the last row will be 2^(bit_count(m+1)-1). So now if T is not power of 2, answer is 0. Else we can find number of bits that we need. And know we have stndart problem. How many numbers form 2 to n+1 have exactly P bits in binary presentation of the number. It is well known problem can be done using binomial cooficients. We will count number of numebers smaller then out number with fixed prefix.

261D - Maxim and Increasing Subsequence

This problem can be done using dp[i,j] where we can end our increasing sequence with length i and last number j. Its not hard to understand that number of states will be n*b. To make a tranfer we need to know array first[j] — first position of the number j in the sequence b, next[i][j] — first position of the number j in the sequence b after position i.

Now its easy to calculate all values.

261E - Maxim and Calculator

I will add tutorial later. But I will give you a hint: number of numbers with maximal prime divisor<=100 is near 3000000 numbers.

Codeforces Round #159 (Div. 2) Разбор Задач

By NALP, 10 years ago, In Russian257A - РозеткиОчевидно, что выгоднее использовать сетевые фильтры с наибольшим количеством розеток на них. Поэтому сначала отсортируем их по убыванию этой величины. Теперь переберем ответ, то есть, сколько фильтров мы будем использовать, пусть это значение равно p, а фильтры имеют a1, a2, ..., ap розеток. Очевидно, что если соединить эти фильтры, то итого будет доступно k - p + a1 + a2 + ... + ap розеток. Это значение надо сравнить с m и выбрать минимальное подходящее p. Если ни одно значение p не подходит, то следует вывести  - 1.

257B - Игра в кубикиДля начала переберем цвет первого кубика, который поставит Петя. Вася следующим ходом захочет поставить кубик противоположного цвета, затем Петя захочет поставить кубик такого же цвета, как и поставленный Васей и т.д. Так мы можем проэмулировать всю последовательность ходов обоих мальчиков и найти их счет.

Единственное, что может изменить Петя в игре – это цвет первого кубика, и он его поставит так, чтобы его счет был как можно больше.

257C - Угол обзораСначала давайте избавимся от координат точек, а именно, заменим все точки лучами от (0, 0) до каждой из точек.

Тогда очевидно, что искомые стороны угла – это пара соседних лучей, причем из двух углов, образованных выбранными лучами, надо выбрать тот, который покрывает все остальные лучи. Получается, что выгоднее всего выбрать такую пару соседних лучей, между которыми наибольший угол, пусть он равен a, и вывести величину 360 - a (в градусах).

Отдельный случай — когда все точки лежат на одном луче, в этом случае ответ равен 0.

257D - СуммаУ нас есть последовательность переменных a1, a2, …, an. Возьмем две переменные с максимальными значениеми (допустим, i и i + 1), удалим их и вставим в последовательность новую переменную x = ai + 1 - ai так, чтобы сохранилось свойство неубывания последовательности. Так будем делать до тех пор, пока не останется единственное число s, которое и будет искомой суммой. Очевидно, что если мы будем разворачивать последовательность замен с учетом знаков, то в итоге узнаем, какой знак стоит у каждой из начальных переменных так, чтобы их сумма была равна s.

Теперь осталось понять, почему число s подходит под ограничения 0 ≤ s ≤ a1. Очевидно, что оно не может быть отрицательным, так как при всех заменах мы из большего числа вычитаем меньшее. Также несложно понять, что при всех заменах минимальное число в последовательности не может увеличиваться, значит, оно до последней замены будет максимум a1. Аналогично, второе число в последовательности также не может перед последним шагом быть больше a2 и так далее. Несложно понять, что при последней замене мы получим s ≤ a2 - a1 ≤ a1.

257E - Жадный ЛифтЭта задача решается классическим методом – событиями во времени. Событиями являются: «человек встал в очередь к лифту», «человек вошел в лифт», «человек вышел из лифта».

Будем поддерживать множество будущих событий, текущее время T и текущее положение лифта x.

В каждый момент времени будем выполнять следующие действия:

если есть люди, которые в текущее время T пришли к лифту, то поставим их в очередь на их стартовом этаже;если на текущем этаже есть люди, то посадим их в лифт, таким образом очередь на этом этаже опустеет;если в лифте есть люди, которые должны выйти на текущем этаже, то высадим их и запомним для них ответ – текущее время T;найдем количество людей, которые ждут выше этажа x или которые едут выше, а также найдем количество людей, которые ждут ниже этажа x или едут ниже, и согласно условию выберем направление движения.Однако если мы на каждой итерации будем увеличивать текущее время T лишь на единицу, то решение будет работать слишком долго. Надо научиться переходить сразу к следующему моменту времени, когда появится какое-либо новое событие, и лифт передвигать сразу на несколько этажей вверх или вниз. Очевидно, что между событиями направление движения лифта не меняется.

Понятно, что нам достаточно посмотреть на следующий момент времени, когда придет какой-либо человек и встанет в очередь на этаже, а кроме того найти следующий этаж по направлению движения, на котором кто-либо выйдет или зайдет.

Это можно сделать с помощью структуры «множество» с операциями «найти следующее число в множестве после данного» и «найти предыдущее число в множестве перед данным». Это умеет стандартные структуры set в С++ или TreeSet в Java.

Также для действия номер 4 нам понадобятся две структуры данных, которые умеют находить сумму чисел на определенном отрезке в массиве, для этого можно использовать, например, деревья отрезков или деревья Фенвика. Одна из структур хранит, сколько людей ждут лифта на каждом из этажей, а вторая – сколько людей в лифте хочет выйти на каждом из этажей. В принципе, эти две структуры можно объединить в одну.

Таким образом, для каждого из людей мы будем обрабатывать ровно по три события, и итоговое время решения будет равно O(n·log(n)).

Codeforces Round #158 (Div. 2) Tutorial

By HolkinPV, 10 years ago, translation, In English260A - Adding Digits

At first try to add to the right one digit from 0 to 9. If it is impossible write -1. In other case, the remaining n–1 digits can be 0 because divisibility doesn’t change.

260B - Ancient Prophesy

In this problem you have to consider every date from 2013 to 2015 year (there is no leap years in this interval), count occurrences of this date and find maximum. In one year there is 365 days, so the complexity of the solution (3·365·N).

260C - Balls and Boxes

Firstly describe simple solution. We will get by one ball from boxes (we begin from box x) from right to left (action back). At some moment there will be 0 balls in current box. This box is the first box in our initial problem (from which we took all balls and begun to put). In this box we put all balls, which we get from all boxes.

But we can’t solve the problem in such a way, because it is too long. Note, that before we meet the situation when in some box will be 0 balls, we will go through every element of array several times and subtract 1. So we can make our solution faster. We can subtract from every element of array minv - 1, where minv — minimum in array. After that you should do O(N) operations, that were mentioned above.

260D - Black and White Tree

The problem can be solved constructively maintaining the following invariant (rule) — the sum of the white vertices equals to the sum of the black vertices. The tree is a bipartite graph, so we build bipartite graph with no cycles, which will satisfy the conditions of the problem. Parts of graph will be black and white vertices.

On each step we will choose vertex v with minimum sum from white and black vertices. Then find any vertex of opposite color u and add edge (u, v) with weight s[v], and subtract from sum of u sum of v, that is s[u] = s[u]–s[v]. After each step one vertex is deleted. That’s why there will be no cycles in constructed graph. When we delete last vertex of one of colors, all other vertices can be joined in any correct way with edges of weight 0.

260E - Dividing Kingdom

Consider 9! variants of location of integers a[i] on 9 areas. When we consider some location (some grid), we can easily find amount of cities to the left of the left vertical line, to the right of the right vertical line, below the lower horizontal line and above the upper horizontal line. All these numbers is sum of three values a[i].

We assume that the lines of the answer are always in half-integer coordinates. Then, knowing the above 4 numbers, we can uniquely determine separately for x and y how to accommodate all the 4 lines. It remains only to check that in all areas there is desired number of points.

For each of four zones (to the left of the left vertical line, to the right of the right vertical line, below the lower horizontal line and above the upper horizontal line) separately check, that all three areas have correct number of cities. It can be done offline using scan-line and segment-tree, which can find sum on interval and change value in some point. You should put all queries in some array, sort them and process from left to right. Note, when you check 8 from 9 areas for every 9! variants of location, the last area (central) could not be checked, it will be correct automatically.

Codeforces Round #157 — Editorial

By witua, 10 years ago, translation, In English259A - Little Elephant and ChessObviously, the only correct rows are rows WBWBWBWB and BWBWBWBW. Only thing you need to do is to check whether each string is one of these. If yes then print YES, else print NO.

259B - Little Elephant and Magic SquareSince each number is less than or equal to 105, you can loop all possible a1, 1 values, the rest of cells can be calculated from this.

258A - Little Elephant and BitsIt's pretty easy to notice that you need to delete the first (from the left) 0-digit. The only catchy case is 111...111 — here you need to delete any of 1-digits.

258B - Little Elephant and ElectionsFirst of all, lets think about the problem of finding array ci — the number of integers from 1 to m such, that the number of lucky digits is equal to i. It's pretty standart dynamic programminc problem, which can be solved with state [position][less][count].

It can be solved directly using DP, but to simplify a bit you can use brute force (recursion) to brute all possible assignments of numbers of lucky digits in for all paries (up to 9 digits). Now you can divide all parties in several indepentent groups, each of which should contain the same number of lucky digits. Consider that the party of Litte Elephant is with number 1. Than assignment for the first position should have more digits than the sum of the rest (because of the statement). Since all groups are indepented (because there is no number that can have different number of lucky digits, obviously) you can find the number of resulting assignments for each group and find the final result by multiplying these all numbers and taking modulo 109 + 7.

Consider that you have group of size t, each number of which should contain l lucky digits. That it's pretty easy to understand that the number of assignment is equal to (cl) * (cl - 1) * (cl - 2) * ... * (cl - t + 1).

258C - Little Elephant and LCMThe complexity of the possible solution is O(n * sqrt(n) * log(n)). You can see that statement lcm(b1, b2, ..., bn) = max(b1, b2, ..., bn) is equal to statement "All the numbers b1, b2, ..., bn must divide max(b1, b2, ..., bn)". You can iterate that max(b1, b2, ..., bn), let it be equal to m. Find all divisors of m and sort them — p1, p2, ..., pk. For each i between 1 and k you can find (using simple DP) the number of numbers aj that pi ≤ aj < pi + 1 (if i = k than pi + 1 = max(a1, a2, ..., an) + 1), denote it as qi. Then the reuslt is equal to 1q1 * 2q2 * 3q3 * ... * pqp, because for each of the q1 numbers there is 1 way to assign, for each of q2 numbers there is 2 ways of assignments, and so on. But you should notice that if doing this problem in such way, you need to garantee that there is some i such bi = m. Hance you need from the last multiplier (pqp) subtract (p - 1)qp — all the ways that there is no number equal to m.

258D - Little Elephant and Broken Sorting258E - Little Elephant and TreeVery useful thing in this problem is ordering all vertices in DFS order (preorped). After that any subtree can be represented as a some sequence of continuous vertices. Consider that we have some fixed vertex v. Which vertices should be included in cv? Obviously, if in the path from the root to v is some non-empty vertex (i. e. such that has at least one integer in its list) than each vertex from substree v should be included in ci, but since we now working with preorder traversal of the tree, we consider that every vertex from some segment [lv, rv] must be included to ci. More generally, let for each vertex keep some set of segments (lk;rk). If on the i-th operation we have two vertices a and b, we add segment (lb;rb) to vertex a, and (la;ra) to vertex b. Also for each vertex i (i = 1..n) we add segment (li;ri), where (li;ri) is a segment in our preored traversal for subtree i. After that, you can see that, if we unite all segments from all vertices on the path from the root to some vertex v, we find the result for v, which will be the size of the resulting set.

So now we need some data structure that would support three operations: add(l, r), subtract(l, r), count(). The first one should add 1 to all positions from l to r, inclusive. The second should subtract 1 from all positions from l to r, inclusive. The last should count the number of non-zero element. This all can be done either with segment tree or sqrt-decomposition.

Codeforces Round #156 tutorial

By Sereja, 10 years ago, translation, In English255A - Greg's WorkoutIt is not hard problem. We must calculate sums of numbers for each group and print group with maximum count.

255B - Code ParsingNot hard to see that after few operations of first type string will become: x..xy..y. After fer operations of second type, there will be only letters of one type, count of this letters will be: |count(x) — count(y)|

256A - Almost Arithmetical ProgressionЗаметим, что ответ это длина последовательности: a, b, a, b, ... где a и b — некоторые целые числа. Зафиксируем одно число (допустим a), будем перебирать число b, и считать какой мы получим ответ, если это будет последнее число в последовательности. Заметим, что для фиксированных a, b — ответ считается жадно. Так же будем действовать и тут. Будем искать последнее вхождение числа b до зафиксированного, что между ними есть число a, и будем брать ответ как длина до найденного числа +2 (икасть будем с помощью метода двух указателей). Так же нужно рассмотреть случай, когда это будет 1е или 2е вхождение в последовательность.Так же существует решение с помощью динамического программирования.Асимптотика обоих решений O(n^2).Буду очень рад, если кто то напишет решение с лучшей асимптотикой.

256B - Mr. Bender and SquareSolution — binary search for answer. Next we have to calculate the area of a truncated square set at 45 degrees. This can be done as follows: Calculate its total area. Subtract area that cuts off the top line. Similarly, for the lower, left and right line. Add parts that are cutted by corners. You can write a function that finds the length of the truncation desired area, for that would not write a lot of code.

256C - Furlo and Rublo and GameNote that after the first move any pile turns into a pile no larger than 1000000. We assume Grundy function for numbers less than 1 million. Grundy function is very small, you can start on the partial sums for each type of function that would quickly tell what function is in the interval, and which are not present. Knowing the answer is not difficult to find small response for all piles.

256D - Liars and SergeIf person say number x, and at all x was said by x persons, then we cannot tell anything about fixed person.

Now we understand which sequence are good for us. We will calculate their count wuth dynamic programming dp[n][m][k], n — which persons answers we set to the sequence right now, m — how mant persons gived theis answers, k — how many persons from them are liers.Transfer:dp[n][m][k]*cnk[N-m][n] -> dp[n+1][m+n][k]dp[n][m][k]*cnk[N-m][p] -> dp[n+1][m+p][k+p] p = 1 .. N, p != n.We assume, that N — total number of the persons. This solution get TLE, becouse complexity if O(N^4). We need to use precalc. It will not be so big, as N is power of 2.

256E - Lucky ArraysSolution is — interval tree. We will save dynamic programming f[i,j] in each vertex, this dp means: in how many ways we can change all 0 to some numbers on interval, such that it will be valid and first element will be i and last will be j.

With normal implementation its easy to pass system tests.

Codeforces Round #155 (Div. 2) — tutorial

By Nerevar, 10 years ago, In English254A - Cards with Numbers

For each x from 1 to 5000 store a list L(x) of such indexes i that ai = x. Then just check that all lists have even size and output the elements of each list in pairs.

254B - Jury Size

One of the possible solutions is: for each Olympiad find the period of the preparation. This can be done by iterating the days back from the day of the Olympiad. For each day d of the preparation add pi to the number of distinct jury members that have to work on problems on day d. Then the answer is maximum calculated sum over all days. Be careful with the year 2012.

254C - Anagram

Lets denote the number of character x in s by Cs(x). Similarly Ct(x) is defined. Then the minimum number of changes required to get anagram of t from s is equal to . Now we need to obtain lexicographically minimum solution. Lets iterate through the positions in s from the left to the right. For a fixed position, look through all characters from 'a' to 'z' and for each character decide whether the optimal answer can contain this character in that position. If it can, put this character in that position and continue with the next position. To check if the given character is suitable quickly, we maintain the values Cs(x) and Ct(x) while iterating through positions.

254D - Rats

Choose arbitrary rat (for say, the leftmost of the upmost). It's cell should be cleared. Make a BFS that never goes further than d from this cell (we will call such a BFS by d-BFS). It will visit approximately 2d2 cells in the worst case. So, we have to blow the first grenade in one of the visited cells. Lets check every visited cell as a candidate. Make a d-BFS from the candidate cell. Some cells with the rats will not be visited. That means that they should be cleared by the second grenade. Choose arbitrary cell with a rat that was not cleared by the first grenade. Make a d-BFS from it. All cells visited by this BFS are candidates to blow the second grenade. Lets check every such cell. Checking a cell again means making a d-BFS from it. If this BFS visits all cells that were not cleared by the first grenade, that we have found a solution. As every d-BFS visits at most 2d2, the overall number of steps is approximately 8d6.

254E - Dormitory

The problem can be solved by dynamic programming: denote as D(n, r) the maximum rating that we can achieve in the first n days with the condition that we have r kilos of food remaining from the day n - 1. It is obvious that if we decide to feed k friends on some day, the better way is to feed k friends with the lowest fj (of course we consider only friends that live with Vasya on that day). So we need to sort all available students in the order of increasing fj and try to feed 0, 1, 2, \ldots first students in this order. We have 4002 states and 400 transitions from each state.

Codeforces Round #154 (Div. 2) — tutorial

By Nerevar, 10 years ago, translation, In EnglishSorry for the short tutorial: we are too busy preparing and conducting school competition.

253A - Boys and Girls

Lets assume that we have more boys than girls (the other case is solved similarly). Then we can construct one of the optimal solutions in the following way: we add pairs consisting of a boy and a girl (BG, in that order) to the end of the line until we don't have girls any more. Then add remaining boys to the end of the line. For instance, with 7 boys and 4 girls we will come to the solution BGBGBGBGBBB.

253B - Physics Practical

For each x from 1 to 5000 calculate count(x) — the number of measurements equal to x. The iterate over all possible minimal values m (from 1 to 5000). For a fixed m we can easily figure out which numbers we have to erase: we should erase every number k that k < m or k > 2·m. To find out the number of such values in the given sequence, we should sum up values count(k) for all such k.

253C - Text Editor

One of the solutions to the problem is breadth-first-search (BFS). Vertices of the graph correspond to all possible pairs (r, c), denoting the row and the position of the cursor. Each vertex has at most four arcs leaving it (these arcs correspond to pressing the buttons). So we need to find the shortest path from one vertex to the other. There are at most 107 vertices and at most 4·107 arcs. This problem can also be solved with some greedy observations.

253D - Table with Letters - 2

Lets iterate over all pairs of rows i, j (i < j), that bounds the sub-table from the top and from the bottom. Then for each character ch make a list of such column numbers k that T[i, k] = T[j, k] = ch. Consider such list for some fixed character ch. All we need to count is the number of pairs l, r (l < r) in this list such that the sub-table with corners at (i, l) and (j, r) contains not more than k characters "a". This can be done using two standard techniques: two-pointer method and calculating partial sums.

253E - Printer

First lets learn how to simulate the process with all priorities known. We will keep the priority queue of tasks. The task enters the queue when the printer receives this task, and leaves the queue when the printer finishes it. Then every change in the queue happens when one of the two possible events occurs: the printer receives some task or finishes printing some task. Between the consecutive events printer just prints pages from the tasks with the highest priority. So, if we maintain a set of events, the simulation can be done in O(NlogN).

To solve the problem, make an obvious observation: the higher priority the task has, the sooner the printer finishes it. Then the required missing priority can be found using binary search. Also we can search the missing priority among O(N) values. The overall complexity is O(Nlog2(N)).

This problem also has O(NlogN) solution, which will be described later.

Editorial of Codeforces Round #153

By KADR, 10 years ago, translation, In EnglishThis is a complete English version of the editorial of Codeforces Round #153. If you have any questions or suggestions, feel free to post them in the comments.

252A - Little Xor (A div 2)Let's iterate over all segments in our array. For each of them we'll find the xor of all its elements. Then we need to output the maximal xor we've seen.

252B - Unsorting Array (B div 2)If all elements in the array are equal then there's no pair of numbers we are looking for. Now we can assume that there exist at least 2 different numbers in the array. Let's iterate over all pairs of different numbers in the array and for each such pair we'll check if it can be the answer. If some pair indeed can be the answer, we'll output it and terminate the program. Otherwise, there is no pair of numbers we are looking for, so we need to output -1.

It may seem that the complexity of described algorithm is O(N3). Actually it's not true and the real complexity is O(N). One may notice that in every array of length greater than 3 there are at least 3 pairs of different numbers (remember we assumed that there exist at least one pair of different numbers in the array). Note that these 3 pairs lead to 3 different resulting arrays. On the other hand, there are only 2 possible sorted arrays. According to the pigeonhole principle one of these 3 resulting arrays is unsorted.

252C - Points on Line (C div 2)251A - Points on Line (A div 1)Let's select the rightmost point of our triplet. In order to do this we can iterate over all points in ascending order of their X-coordinate. At the same time we'll maintain a pointer to the leftmost point which lays on the distance not greater than d from the current rightmost point. We can easily find out the number of points in the segment between two pointers, excluding the rightmost point. Let's call this number k. Then there exist exactly k * (k - 1) / 2 triplets of points with the fixed rightmost point. The only thing left is to sum up these values for all rightmost points.

252D - Playing with Permutations (D div 2)251B - Playing with Permutations (B div 1)First, we need to theck whether permutation s is the identity permutation. If it is, then the answer is "NO".

Now we'll describe an algorithm which works in all cases except for one. We'll tell about this case later.

Let's apply our permutation q until either the current permutation becomes equal to s or we make exactly k steps. If the current permutation is equal to s and we've made t steps before this happened, then we need to look at the parity of k - t. If this number is even, then we can select any two consequent permutations in the sequence and apply (k - t) / 2 times the following two permutations in this order: q and inv(q), where inv(q) is the inversed permutation q. Actually, we don't need to build the sequence itself, it's enough to check only the parity of k - t. So, if it is even, then the answer is "YES".

Analogically, we can replace q with inv(q) and repeat described process again. If we still didn't print "YES", then the answer is "NO".

The algorithm we've just described works for all cases except for one: when the permutation q is equal to inv(q) and at the same time s is reachable within one step. In this case the answer is "YES" iff k = 1.

The complexity of described solution is O(N2).

252E - Number Transformation (E div 2)251C - Number Transformation (C div 1)Let L be the least common multiple of all numbers from 2 to k, inclusive. Note that if a is divisible by L, then we can't decrease it with applying an operation of the second type. It means that any optimal sequence of transformations will contain all numbers divisible by L which are located between b and a. Let's split our interval from b to a into several intervals between the numbers divisible by L. It may happen that the first and the last intervals will have length less than L. Now we can solve the problem for the first interval, the last interval and for any interval between them. After that we need to multiply the last result by the total number of intervals excluding the first and the last ones. The only thing left is to add up obtained 3 values.

In order to solve the problem for one interval one can simply use bfs.

Be careful in the cases when we have only 1 or 2 intervals.

The complexity of described solution is O(L).

251D - Two Sets (D div 1)Let X be the xor of all numbers in the input. Also let X1 be the xor of all numbers in the first collection and X2 be the xor of all numbers in the second collection. Note, if the i-th bit in X is equal to 1 then the same bit in numbers X1 and X2 is either equal 0 and 1 or 1 and 0, respectively. Analogically, if the i-th bit in X is equal to 0 then this bit in numbers X1 and X2 is either equal 0 and 0 or 1 and 1, respectively. As we can see, if the i-th bit in X is equal to 1 then it doesn't affect on the sum X1 + X2 in any way. For now, let's forget about the second condition in the statement which asks us to minimize X1 in case of tie.

In order to find the optimal value of X1 + X2 we need to make one more observation. Let's look at the most significant bit of number X which is equal to 0. If there exist such partitions of the initial collection in which this bit is equal to 1 in X1 then the optimal partition should be one of them. To prove this one should remember that the respective bit in number X2 is also equal to 1. Let this bit correspond to 2L. If the bit we are looking at is equal to 1 in both X1 and X2 then the smallest possible value of X1 + X2 is 2L + 1. On the other hand, if both X1 and X2 have zero in this bit, then the maximal possible value of X1 + X2 is 2L + 1 - 2 which is strictly smaller than 2L + 1.

We'll be solving the initial problem with a greedy algorithm. Let's iterate over all bits which are equal to 0 in number X from highest to lowest. We'll try to put 1 to the number X1 in this position and then check if there exists at least one partition which satisfies the current condition together with all conditions we've already set up. If such partition exists, then we can leave our newly added condition and move to lower bits. If there is no such condition, then we need to move to lower bits without adding any new conditions. At the end we'll find the maximal value of X1 + X2.

So, we have a set of conditions and we want to check if there exist at least one partition which satisfies all of them. For each condition for i-th bit we'll create an equation over the field Z2 with n variables, where the coefficient at the j-th variable is equal to the i-th bit of the j-th number. If some variable is equal to one then we take the corresponding number into the first set, otherwise -- into the second one. This system of equations can be solved with Gaussian elimination. Note that we don't need to solve the complete system from scratch every time we add a new equation. It's sufficient to recalculate the matrix from the previous state, which can be done in O(NK). Here K is the number of equations in the system.

Now we need to minimize X1 while keeping the value of X1 + X2 unchanged. It can be done in the similar way as finding the optimal value of X1 + X2. We'll iterate over all bits which are equal to 1 in number X starting from the highest one. For the current bit we'll try to put 0 in the corresponding position of X1. If after adding this condition our system of equations becomes incompatible, then we need to put 1 in this position of X1.

The complexity of this algorithm is O(NL2), where L -- is the length of binary notation of the largest number. For further optimization one can use bitset in Gaussian elimination, although it wasn't necessary for getting AC during the contest.

251E - Tree and Table (E div 1)If N = 1, then the answer is 2.

If there is a node with degree greater than 3 in the tree, then the answer is 0. That's because every cell of the table has at most 3 neighbors.

If there is no vertex of degree 3 in the tree, then the answer is 2n2 - 2n + 4. This formula can be derieved in natural way during the solution of other parts of the problem. Also, one could write a simple DP to calculate the answer in this case. Anyway, let's prove this formula.

At first, let's solve slightly different problem, which will be also used in the solution of main case of the initial problem. We want to find the number of ways to place a tree in which all nodes have degree smaller than 3 on the table so that one node of degree 1 is attached to the upper-left corner of the table (let it be node number 1). It can be shown that if the table has size 2xK, then the number of placements of the tree is equal to K. The last formula can be proven by mathematical induction. If K = 1 then the above statement is obviously true. Suppose K > 1 and let's assume that the table is oriented horizontally so that we have 2 rows and K columns. If we put a vertex adjacent to the first one to the right from upper-left corner then we have only 1 way to complete the placement of the tree. If we put this vertex to the bottom-left corner, than the next vertex should be put to (2, 2) and the problem is reduced to the same one with K smaller by one. We have a recurrent relation f(K) = f(K - 1) + 1 and we know that f(1) = 1. This means that f(K) = K.

Let's come back to the initial problem of counting the nymber of ways to put a tree without vertices of degree 3 on the table 2xN. Without loss of generality let's assume that the first vertex has degree 1. We'll consider only placements in which the first vertex is laying in the first row and at the end we'll multiply our answer by 2. If the first vertex is laying in the first or the last column then then there are N ways to complete the tree (see the previous paragraph). If the first vertex is laying in the i-th column than there are i - 1 ways of placing our tree in which a vertex adjacent to the first one (let it be vertex 2) is laying to the left of it. Also there are N - i ways in which the second vertex is laying to the right of vertex 1. Adding up these values for all columns and multiplying the answer by 2 we get the final formula: 2n2 - 2n + 4.

Now we have only one case left in which there exists a vertex of degree 3 in our tree. Let's declare this vertex to be a root. If there are several vertices of degree 3, any of them can be chosen to be a root. We'll assume that the root is laying in the first row and at the end we'll multiply our answer by 2. Obviously, the root should be put to a cell with 3 neighbors. Each descendant of the root should be put either to the left, to the right or to the bottom from the cell which contains the root. Let's fix this ordering (to do this we need to iterate over 6 permutations). Also if the "bottom" son of the root has degree greater than 1, then we'll also fix the ordering of its adjacent vertices (there are 2 ways to do this). Now the column which contains the root is fully occupied. The last statement means that regardless of the way we place the rest of vertices, the ones to the right from the root will stay there. The same for all vertices which lay to the left from the root. Moreover, we have the fixed number of vertices to the left from the root, which means that there's at most one way to place the root on our table. Note that if the number of vertices to the left from the root is odd, then we won't be able to complete the placement. In order to find the number of vertices to the left from the root we need to sum up sizes of subtrees of its left descendant and of the left descendant of its bottom son.

So, we have two separate subproblems (for vertices laying to the left from the root and to the right from the root) and for each of them we need to calculate the number of trees to place the rest of our tree in the table. There are only two possible situations:

1) We need to place a subtree with its root in vertex v on the rectangular table in such way that vertex v is laying in the corner (let it be upper-left corner).

2) We need to place subtrees with roots in v1 and v2 on the rectangular table in such way that vertex v1 is laying in the upper-left corner and vertex v2 is laying in bottom-left corner.

Obviously, each of these two problems has non-zero answer only if total size of subtrees is even.

Let's show how to reduce a problem of the second type to a problem of the first type. So, if either v1 or v2 has two descendants, then the answer is 0. If both of them have one descendant, then we can solve the same problem for their children which'll have the same answer. If both v1 and v2 have no children, then the answer is 1. At last, if one of these two vertices has 1 descendant and the other vertice doesn't have any descendants, we have a problem of the first type for this only child of vertices v1 and v2.

The only thing left is to solve a problem of the first type. Let f(v) be the number of ways to place a subtree having vertex v as its root on the rectangular table. The size of this table is determined uniquely by the size of subtree. Let's consider two cases:

a) Vertex v has degree 2.

b) Vertex v has degree 3.

In the case when vertex v has degree 2 and there are no vertices of degree 3 in its subtree, then f(v) = s(x) / 2, where s(v) is the size of subtree with its root in vertex v. We've already proven this formula above. Now let's suppose that there's at least one vertex of size 3 in the subtree with root v. If there are several vertices with degree 3, we'll chose the one that is closer to vertex v. Let it be vertex w. We have 2 possible cases for it:

a.1) Path from vertex v to vertex w will go in such way that the vertex which lays before vertex w in this path is located to the left from vertex w on the table.

а.2) Path from vertex v to vertex w will go in such way that the vertex which lays before vertex w in this path is located to the top from vertex w on the table.

Its easy to show that there's no third option.

In each of two cases a.1) and a.2) we'll fix directions of descendants of number w (one direction is taken by the parent of vertex w, so there are exactly 2 possible directions). In case if descendant of degree greater than 1 is located in the same column with w, we need to fix directions of its descendants, too. After this we have problem of type 1) or 2) to the right of vertex w. To the left from w we have a tree which either can't be put on the table or can be put in exactly 1 way. In order to check this we need to look on the length of path from v to w and the size of subtree of grandson of w, which is located to the right from w (of course, if it exists). Now we need to sup up answers for all possible variants.

So we know how to solve problem of type a), when vertex v has degree w. The only thing left is to solve problem b), when v has degree 3. To do this we need to fix directions of its descendants and after that we'll have either a problem of type 1) or a problem of type 2), which were formulated above.

The complexity of solution is O(N).

Разбор задач Codeforces Round #152

By pkhaustov, 10 years ago, In RussianЗадача A (div2) — Шкафы

Автор: max777alex

В этой задаче можно рассмотреть независимо все левые дверцы шкафов и, аналогично, все правые. Очевидно, чтобы привести все левые дверцы шкафов в одинаковое положение, нужно определить какое из двух состояний ("левая дверца открыта" или "левая дверца закрыта") встречается чаще. Все левые дверцы, которые находятся в другом состоянии требуется привести к этому. Аналогично надо поступить и с правыми дверцами. Если аккуратно посчитать в таком случае количество операций изменения состояния дверцы, то это оно и будет ответом.

Задача B (div2) — Котенок Гав

Авторы: max777alex, pkhaustov

В данной задаче требовалось найти минимальное положительное N-значное число, которое делится без остатка на 2, 3, 5 и 7. Очевидно, раз все эти четыре числа являются простыми, то число, которое делится на все эти четыре числа, должно делиться на их произведение 2·3·5·7 = 210. Для N < 3 такого числа не существует. Для N = 3, конечно же, ответ равен 210. Для N > 3 следуем следующему алгоритму.

Найдем остаток R от деления 10N - 1 на 210. Далее требуется добавить 210 - R к 10N - 1, чтобы получилось число, кратное 210. Учитывая, что 0 ≤ R < 210, получаем, что последние три разряда числа определяются значением R, а оставшиеся разряды — совпадают с соответствующими разрядами числа 10N - 1.

Можно также было заметить закономерность для последних трех разрядов с изменением N и заменить вычисления остатков аккуратным разбором случаев.

Задача A (Div1), C (div2) — Электроник-футболист

Авторы: am-real

Для начала временно избавимся от радиуса мяча — сдвинем верхнюю стену на радиус вниз. Мяч, в таком случае, можно считать материальной точкой. Штанги не трогаем. Отразим центр мяча относительно сдвинутой верхней стены. Соединим полученный отраженный центр мяча и точку (0, y1 + r).

Далее остается аккуратно определить, не касается ли мяч левой стены. Очевидно, что точкой стены, наиболее близко лежащей к траектории центра мяча, будет штанга (0, y2). Таким образом достаточно проверить расстояние от этой точки до траектории мяча. Если оно меньше радиуса, значит ответа нет, иначе — точка пересечения проведенной ранее линии и сдвинутой на радиус вниз стеной и будет ответом.

Если целиться выше точки (0, y1 + r), траектория центра мяча только приблизится к штанге (0, y2), поэтому целиться в другие точки смысла не имеет.

Задача B (Div1), D (div2) — Конфеты — каждому!

Автор: pkhaustov

В задаче предполагалось, что друзья из Простоквашино могут закончить свой путь на любом участке улицы. Давайте изначально предположим, что заканчивать свой маршрут друзьям можно только на последнем участке улицы. В таком случае решение более, чем очевидно.

С ростом количества изначально имеющихся с собой конфет, время, которое требуется для угощения всех жителей может либо не изменяться, либо уменьшаться. Следовательно, здесь применим бинарный поиск по количеству конфет. С помощью бинарного поиска закрепим количество конфет, которые мы изначально взяли с собой. Идем слева направо (от первого участка, до последнего). Если находимся на участке с магазином — обязательно покупаем конфеты (денег у нас бесконечно много, значит, нет смысла не покупать конфеты). Если мы находимся на участке с домом, то при наличии конфет — угощаем жителей этого дома. Если же конфет у нас нет, то пропускам этот дом. Несложно доказать, что возвращаться назад выгодно только тогда, когда у нас достаточно конфет, чтобы угостить жителей всех пропущенных домов. Пусть первый пропущенный дом оказался на участке L. На участке R мы купили конфеты, и теперь их достаточно, чтобы угостить жителей всех пропущенных домов. Тогда участок от L до R мы дополнительно пройдем еще на два раза. Если попытаться угостить жителей пропущенных домов раньше, чем мы достигнем участка R (на участке T), то участок от L до T нам так же придется преодолеть дополнительно на два раза. Однако, так как мы не можем угостить всех жителей на отрезке от L до T, это говорит о том, что придется преодолеть некоторую часть этого интервала еще два раза, для чего нам еще на два раза придется преодолеть отрезок от T + 1 до R. Очевидно, что преодолев на два раза отрезки (L, T) и (T + 1, R) мы, фактически, преодолели на два раза отрезок от L до R. Помимо этого, какую-то часть отрезка от L до T нам потребуется преодолеть еще два раза. Получается, что количество времени, которое нам потребуется, будет строго больше, чем в первом случае. Аккуратно моделируем процесс за O(N), чтобы определить минимальное количество времени, которое потребуется на выполнение прохода по улице.

Теперь предложим модификацию для случая, когда закончить свое путешествие друзья могут на любом участке. В таком случае некоторую часть P улицы вовсе не обязательно посещать. Такая часть улицы представляет собой несколько (возможно ноль) последних участков этой улицы и не содержит домов. Определить такую часть можно за O(N) для каждого имеющегося изначально количества конфет на руках у друзей. Назовем улицу за вычетом ее части P полезной частью. В какой-то момент времени может оказаться так, что выгоднее дойти до конца полезной части и пойти обратно до тех пор, пока жители всех пропущенных домов не получат свои конфеты, после чего раздача сладостей прекращается. Такую проверку можно осуществлять за O(1) на каждом шаге вышеописанного решения.

Результирующая асимптотика O(N·logN) (логарифм возникает из-за использования бинарного поиска).

Задача C (Div1), E (div2) — День рождения ослика Иа-Иа

Авторы: am-real, pkhaustov

Сформулируем ряд утверждений, которые помогут нам решить задачу. При любом действии Винни-Пуха количество нетронутых горшков на любой из полок не может быть увеличено. Таким образом, если на полке с номером i изначально находилось Ai горшков, то в любой момент времени нетронутых горшков на этой полке будет C, причем 0 ≤ C ≤ Ai. Несложно поддерживать вероятность P(i, C) того, что на полке с номером i находится C нетронутых горшков для всех возможных значений i и C. Это можно сделать с помощью динамического программирования.

Очевидно, ответом после каждой операции будет сумма P(i, 0) по всем возможным значениям i. Заметим, что после каждой операции число нетронутых горшков может измениться только на полке, с которой Винни-Пух берет горшки. Формулы для переходов между состояниями динамического программирования достаточно тривиальны. Какие-то трудности могут возникнуть при выводе формул для ki ≠ 1. Этих трудностей можно избежать, если разбивать запросы с ki ≠ 1 на ki запросов с ki = 1, ведь 1 ≤ ki ≤ 5, и, следовательно, время выполнения существенно увеличено не будет. Допустим и вариант, когда запросы не разбиваются. Для этого требуется аккуратно вывести несложные формулы переходов.

Несложно заметить, что перед первым запросом можно посчитать сумму P(i, 0) по всем значениям i. Далее, при выполнении каждого запроса ui, vi, ki, до его выполнения отнимать P(ui, 0) от ответа, а после его выполнения — добавлять новое значение P(ui, 0) к ответу.

Если обозначить наибольшее значение Ai по всем i, как MaxA, то асимптотика такого решения, очевидно, будет O(N·MaxA). Памяти такое решение так же требует O(N·MaxA).

Задача D (Div1) — Ежик и звезды

Авторы: am-real, pkhaustov

Для начала заметим, что задачу можно свести к более простому варианту аналогичной задачи. В первую очередь, можно избавиться от точек, которые не находятся между двумя заданными во входных данных лучами, выходящими из начала координат. После чего можно повернуть все точки относительно начала координат на такой угол, чтобы один из лучей совпал с одной из осей координат. Для определенности положим, что мы повернули все точки на угол α1 так, чтобы луч, который был пущен под этим углом совпал с осью OX.

Теперь задача существенно упрощается. Все точки лежат в первой координатной четверти (то есть все координаты строго положительны), и имеется прямая L0 под углом α2 - α1, которая проходит через начало координат и все точки лежат ниже нее. Добавим точку начала координат в наш набор, как фиктивную. Проведем через каждую из точек прямую Li параллельную прямой L0. Отсортируем точки в порядке убывания ординаты пересечения прямой Li с осью Oy. Пойдем с конца. Для каждой точки i будем считать длину наибольшей цепочки MaxL(i), которая начинается из этой точки (смотреть будем на те точки, которые уже рассмотрены в нашем обратном порядке обхода). Для каждой точки i мы будем рассматривать все точки j между заданными лучами и выбирать такую, что MaxL(j) максимально, после чего полагать MaxL(i) = MaxL(j) + 1.

Чтобы рассмотреть только те точки, которые находятся в области между лучами выходящими из точки i, требуется выбрать такие точки j, для которых Li пересекает ось Oy выше, чем Lj, и ордината Yj не меньше, чем ордината Yi. Заметим, что из-за порядка сортировки первое условие всегда выполняется, если аккуратно обработать точки с одинаковыми прямыми Li. Для соблюдения оставшегося ограничения достаточно воспользоваться стандартной идеей с деревом интервалов. Но гораздо лучше заметить, что эта задача эквивалентна задаче нахождения поиска наибольшей возрастающей последовательности. Ответом будет значение MaxL для фиктивной точки начала координат.

Как результат, имеем решение с асимптотикой O(N·logN) и O(N) затратами памяти.

Задача E (Div1) — Бесконечная матрица

Автор: pkhaustov

Несложно заметить ряд закономерностей. Для начала обратим внимание на первую строку матрицы. В i-ом столбце первой строки находится элемент со значением (i - 1)2 + 1. Несложно найти закономерность для первого столбца — там в чистом виде квадраты натуральных чисел. Диагональ тоже задается легкой закономерностью i2 - i + 1.

Дальше несложно заметить, что в любом столбце до элемента главной диагонали значения увеличиваются с шагом в единицу. После элемента главной диагонали элемент в i-ой строке равен i2 - i + 1. Как видим, можно и диагональный элемент отнести к этой же закономерности.

Для подматрицы, в которой нужно найти сумму, выполняем разбиение на участки над главной диагональю и под ней и производим вычисления согласно приведенным закономерностям. В авторском решении использовались суммы для квадратов первых N чисел, для суммы сумм квадратов первых N чисел и (выраженная через них) сумма кубов первых N чисел. Существуют и другие варианты формул.

Теперь стоит выполнить все вычисления по модулю 1010. Для того, чтобы отследить, имеет ли число более десяти знаков, будем хранить (помимо остатка) частное от деления на 1010 по модулю нескольких различных простых чисел порядка 109. На практике достаточно и одного простого числа, но для генерации тестов использовалось сразу четыре.

Для решения задачи также можно использовать и типы данных, связанные с длинной арифметикой. Много решений с такой реализацией проходили. Однако, стоит отметить, что нельзя погарантировать хорошее быстродействие такому решению.

Codeforces Round #151 (Div. 2) Tutorial

By HolkinPV, 10 years ago, translation, In English246A - Buggy Sorting

In this problem you should hack the sorting algorithm, of course it was incorrect. It was correct only for arrays with n <  = 2. In other cases you could print n, n–1, ..., 1 as a counter-example. To make the sorting right, the second cycle should be from 1 but not from i.

246B - Increase and Decrease

Note, that you can always get the answer n–1. To get this result you should make first n–1 equal using the last element as the second element in pair of given operation. But after it, the whole array could become equal. It could happen if the sum of array’s elements is divisible by n. So the answer is n–1 or n.

246C - Beauty Pageant

This problem was rather mathematical. The correct solution is: firstly take every element once, then take the maximum and any other, then two maximums and any other, then three maximums and any other and so on. In this case, you get as many sets as you need in this problem. It is easy to check, that all sums will be different.

246D - Colorful Graph

This problem could be solved in this way: create new graph where vertices are the colors of the given graph. The edge between vertices u and v belongs this new graph if there are two vertices a and b in the given graph such that c[a] = u and c[b] = v. So, the answer is such color k with minimum number, that the degree of the vertex k in the new graph is maximum (without multiple edges). Such solution could be written using O(M·log(N)) time.

246E - Blood Cousins Return

This problem had little in common with problem 208E - Blood Cousins. In comments to this problem there was given a solution using structure deque (array in which you can add or delete elements from both endings). Let’s describe solution using this structure.

Firstly all different names change with different integers and for every vertex v save all queries with this vertex. Then for every vertex, which is root of some tree make dfs, the parameters of dfs are vertex v and deque <set > z. This deque for every depth i of the subtree of v save set — all different names (integers) on depth i.

This deque could be calculated simply. Consider all sons of v and calculate such deque for them. Obviously, the size of our deque z will be maximum of sizes of descendants’ deques. Then consider every descendants’ deques and merge appropriate sets of integers. Of course, we will merge smaller set to a larger set. After that you should insert to the beginning of deque z the set of size 1 — color of vertex v.

After this, you can at once answer all queries of vertex v. Answer is 0 if v has no descendants on the depth k or the size of z[k]. It is known that such method has good asymptotic, the author’s solution works about one second. The asymptotic is O(N·log2(N)).

The solution should be realized carefully. You must not copy every element of your set or deque. You should do swap of smaller and greater set or deque without copying elements ant than merge smaller to greater.

Editorial for Codeforces Round #150

By Ripatti, 10 years ago, translation, In EnglishAdiv2. Consider an array A of integers in range from 1 to nk. Let's remove from A all numbers ai and all other numbers store into an array B. The array B will have (n - 1)k elements. Now for i-th kid you should output numbers ai, B[(n - 1) * (i - 1) + 1], B[(n - 1) * (i - 1) + 2], ... B[(n - 1) * (i - 1) + n - 1] (B is 1-based).

Author is Gerald .

Bvid2. Solution 1. You should write some bruteforce solution over all numbers with no more than 9 digits (number 109 should be considered separately). Bruteforce algo seems like this:

dfs( int num ) // run it as dfs(0)  if (num > 0 && num <= n) ans++  if (num >= 10^8) return  for a = 0..9 do    if num*10+a>0 then      if number num*10+a has no more than 2 different digits then        dfs( num*10+a )ans will store the answer. After that you wrote bruteforce, you can run it and see that it works fast (that is same time for any testcase).

Solution 2. Let's build all undoubdetly lucku numbers using bitmasks. You can iterate over length of number L, pair of digits x and y, and bitmask m of length L. If the i-th bit of m is 1, the i-th digit of number should be x; otherwise it should be y. So about 103 × 210 numbers will be generated (it is very rough estimate, count of numbers will be more than 10 times less).

In this solution you should accurately process the case of leading zeroes and the case when all digits of number are same.

Author is Gerald

Adiv1, Cdiv2 Let's see how function f changes for all suffixes of sequence a. Values of f will increase when you will increase length of suffix. For every increase all 1-bits will stay 1-bits, but some 0-bits will be changed by 1-bits. So, you can see that no more than k increasing will be, where k number of bits (in this problem k = 20). Among all suffixes will be no more that k + 1 values of function f.

Now you can run over sequence a trom left to right and support an array m (or a set) of values of f for all subsegments that end in the current position. Size of m always no more than k + 1. When you go from position i - 1 into position i, you should replace m = {m1, m2, ..., mt} by m' = {ai, m1|ai, m2|ai, ... mt|ai}. After that you should remove from m repeated values (if you use set, set will do this dirty work itself). Then you should mark all numbers from m in some global array (or put them into some global set). At the end you should calculate answer from the global array (or set).

Authors are Gerald , Ripatti

Bdiv1, Ddiv2 You should check for every edge: this one can be body of hydra or not. Let's fix some edge (u, v) (order of vertices is important, i.e. you should also check edge (v, u)). Now you should chose some set of h vertices connected with u and some set of t vertices connected with v. These sets should not contain vertices u and v. Also, these two sets should have no common vertices.

If  and , there is no any hydra here.

Orherwise, if  or , there is some hydra in any case. Even if all vertices connected with u and with v are common, number of them so big, that you always can split them into groups of size  ≥ h and size  ≥ t.

The last case is  and . Here you can find all common vertices in O(h + t), using array of flags. When you find the common subset, you can easy check existence of hydra.

UPD How to find common vertices in O(h + t) using array of flgs? You should initailize that array in the beginning of program. For every check you should do following actions. Firstly in  you should mark in the array all neighbours of u. After that you should iterate over all adjacent to v vertices and check value of flag in the array for every of them (in ). Vertices that have "thue" in the array will be common. Finally you should clear the array in : you should iterate over all adjacent to u vertices again and mark these vertices in the array as "false". Because  and , the total complexity will be O(h + t).

All edges can be checked in time O(m(h + t)). So you either find reqired edge or find that there is no required edge. Also in time O(m) you can build hydra with fixed body-edge.

This problem also has solution in  independent from values of h and t, but this solution is more complex.

Author is Ripatti

Cdiv1, Ediv2 Firstly tou should emulate all process in "idle mode". Let farmer was in points (x0 + 1 / 2, y0 + 1 / 2), (x1 + 1 / 2, y1 + 1 / 2), ... , (xn + 1 / 2, yn + 1 / 2). Coordinates x0, x0 + 1, x1, x1 + 1, ... xn, xn + 1 on axis x are interesting for us. Coordinates y0, y0 + 1, y1, y1 + 1, ... yn, yn + 1 on axis y are interesting too. You should store all of them into two arrays. Also you should add to these coordinates bounds of the field.

Then you should build "compressed" field: every cell of this field means rectangle of the starting field that placed between neighbour interesting coordinates. Size of the compressed field is O(n) × O(n). Let's initally all cells painted into the white color. Now you should emulate all process again and paint all visited cells in the compressed field by the black color. During every move you will paint O(n) cells, so all process will be done in O(n2).

Now you should emulate bugs' actions. You should run DFS (ot BFS) from some border cell of the compressed field and paint all reached cells be red color.

At the end you should iterate over all compressed field and find sum of areas of rectengles corresponding to black and white cells. So, you will receive the answer.

This solution works in O(n2).

Author is Ripatti

Ddiv1 You need for every column find the lowermost cube that you can see. You will see all cubes above this cube.

Consider the city from above. You will see drid of size n × n. Now you should draw the line through every node of the grid parallel to vector v. We need know only that happens in every strip between two neighbour lines. Every column cover segment of O(n) adjacent strips.

Now you should create an array a; every element of a corresponding to one strip. This array will store maximal height of considered columns.

Then you should sort all columns in order if increasing distance from observer. In that order you should do following queries of 2 types:

Minimum on segment. This query is needed when you want find the lowermost visible cube.

Replace ai → max(ai, h) on segment. You need this query for "drawing" column in the array.

That is all solution. You just need choose some data structure that can fast do queries. You can select from: block decomposition (length of every block should be ; because length of every query about O(n), total complexity of solution will be O(n5 / 2)), segment tree (), stupid array (it's O(n3), cache optimized implementaton fits in the time limit).

Author is Ripatti

Ediv1 We will build the matrix constructively. At any step we will have array of groups of columns. Order of groups is defined but order of columns inside every group is unknown.

During building we will change order of rows because it is doesn't affect the answer (we can build answer using order of columns only).

Consider the way of building of the matrix. Firstly you should find the row that has maximal number of ones. You should swap this row with the first row. Aftar that two groups of columns should be created. Into the first group you should put columns that have "1" in the firts row; all other columns should be stored into the second group. The second group is "special" — see about it below.

Now you should more times search the row that has "1" in at least two groups. For every of that rows you can determine positions of all ones no more than only way. If you determined no ways, you should output NO and finish execution. After that you determined positions of ones, you should split some groups of columns into two subgroups.

About "special" group. You should take into account case when you should drop some columns from this group and insert them before all groups. You will never face with situation when it is not clear which columns should be dropped and which should not, because in the beginning you chose the row with maximal number of ones.

After repeating process than described above sevaral times, "good" rows may end. I.e. for every row all ones will be placed in no more than one group. Now you should recursively do solution described above inside every of groups of columns.

The solution works in O(n3). It can be upgraded to , but it was not required.

UPD Also here some O(n2) solution exists based on PQ-trees, as said mugurelionut. More information here.

Author is Ripatti

Codeforces Round #149 (Div. 2) Tutorial

By NALP, 10 years ago, translation, In English242A - Heads or TailsThis problem was very easy, we should only use two cycles with i and with j (a ≤ i ≤ x, b ≤ j ≤ y), iterate all possible outcomes of the game and print such in that i > j. The time is O(x·y).

242B - Big SegmentAt first, we must note that the answer is always unique, because if segment i covers segment j, that segment j can't cover segment i. It possible if and only if there are coincide segments in the set, but it's not permissible by the statement. Let's pay attention the answer covers the most left point of all segments and the most right point of all points too. Now then we should found L = min(li) and R = max(ri) and print index of segment [L, R], or  - 1 if there is no such segment in the set. The time is O(n).

242C - King's PathThe most important thing for accepted solution is that it is guaranteed that the total length of all given segments doesn't exceed 105. We should use this feature, let's number allowed cells and found shortest path by BFS. It's easiest to use associative array such as map in C++ for numbering. The time is O(n·log(n)).

242D - DisputeDenote current value of counter number i as bi. Let's describe an algorithm. It takes any counter i such that bi = ai and presses its button. The algorithm finishes if there is no such i.

Let's proof correctness of the algorithm:

Why does Valera win the game? Because there is no such counter which has bi = ai else we must press the button.

Why doesn't algorithm press some button multiple times? Because it presses button number i only if bi = ai, and after this pressing the value bi is increased and the equation will be true never.

Why is the algorithm fast? Because of paragraph 2 it does no more n pressings which produces no more n + 2·m increases of the counters. We should use queue for fast seaching counters which has bi = ai like this: every time we change value of the counter numbered i we check equation bi = ai and if it's true then we push value i to the queue. It's easy to understand that all indexes i will be in queue no more one time.

Also these paragraphs proof that the answer always exists. You must print  - 1 never. The time is O(n + m).

242E - XOR on SegmentLet's write numbers a1, a2, ..., an as a table which has size n × 20, and bi, j is jth bit in ai. Then sum of numbers on segment [l, r] equals . The last notation helps us to process queries.

For fast implementation we should use 20 binary trees like cartesian trees or range trees. Every tree matchs one of bits (and matchs one of the columns of the table bi, j).

calculation of sum is equal to counting 1-s from l-th to r-th.

operation "xor" equals reversing all bits from l-th to r-th (i.e. 0 changes to 1, 1 changes to 0).

The first operation executes for all bit numbers, the second executes only for bits in which input number xi has ones.

These operations may be easy implemented with binary trees. The time is O(m·log(n)·20).

Editorial for Codeforces Round #148

By havaliza, 10 years ago, In EnglishHi :)

Here is the editorial for round #148. I just tried to explain the ideas rather than detailed implementation explanation. I'm sorry for my bad English, so please tell me if something is not clear in the descriptions.

Two Bags of PotatoesThe author of this problem is Gerald. The total number of potatoes is a multiple of k and constraint  there will be at most 105 multiples of k in range 1 to n. So you can iterate on multiples of k and print the ones that satisfy the problem.

Easy Tape ProgrammingIn this problem you just need to simulate every thing which is written in the statement step by step. You can see a simple implementation of this here: http://www.codeforces.com/contest/239/submission/2512422

Not Wool SequencesLet a1, ..., an be a not-wool-sequence. We define another sequence called b in which bi is xor of the first i elements of a,  and b0 = 0.

Now xor of elements of a consecutive subsequence like ai, ..., aj will be equal to . So we know that all elements of b should be different. Therefore b is a sequence of distinct integers of length n + 1 starting with 0 made of numbers 0 to 2m - 1. The number of such sequences is  and this is the answer to problem.

Boring PartitionComing soon...

World Eater BrothersConsider we only want to change direction of minimum number of roads so that all other countries are reachable from a specific country x. This problem can be solved in O(n) and it's exactly what 219D - Choosing Capital for Treeland asks for. If you don't know how to solve it you can read the editorial of that contest.

Consider two countries A and B which can be chosen by world eater brothers to achieve the minimum number of road direction changes. After changing the direction of roads, there exists a country on the undirected path between A and B which is reachable from both A and B using roads. We call such country a middle-country.

We want to iterate on middle-countries and find the best two countries for ruling for each middle-country. For each neighbor of the current middle-country calculate the minimum number of road changes in the subtree rooted at that neighbor so that all countries will be reachable from some country in that subtree. Then from two of these subtrees we need to pick A and B and all other subtrees will have edges pointing to the root of subtree. This can be computed in O(n) for each middle-city. So the overall complexity will be O(n2).

Tape ProgrammingThis problem was my favorite in the problemset. The primary point is that at any moment during the interpretation of a program only a prefix of the program is modified and used by IP.

Consider we want to calculate the output of subsequence sl, ..., sr. While running the original program s1, ..., sn if at any moment CP enters the interval [l, r] it should be pointing to position l and the direction of DP should be right. So it's like we have started interpreting sl, ..., sr independently. The termination of execution of sl, ..., sr is the first time CP points to somewhere outside interval [l, r].

Therefore what we need to solve the problem is to run the original program. And after each termination if the program is nonempty then run it again until program is empty. Then we should keep a log of positions we have visited and the time of each visit and the number of printed digits of each type until then. After this preprocessing the to calculate the answer of query (li, ri) its enough to find the first time CP visited sli and the first time CP visited sri + 1 or sli - 1 after that.

The described approach can be implemented in O(nlog(n) + qlog(n)).

Meeting herConsider a bus passing a shortest path from si to ti. There are some points that are necessary to pass in order to obtain a shortest path. Firstly we compute them. This can be done in O(n3) with Floyd-Warshall and some processing after that. Urpal is sure that a bus from i-th company always passes such vertices on his path from si to ti. So he can get on a bus from i-th company only at vertices the bus surely passes.

At any moment Urpal's status can be uniquely determined by his position on the map and the bus he's traveling with. So we have nk states (position, bus).

Our goal is to reach some (b, ...) state from a (a, v) state which bus v surely passes a (source states). So let's find all states that can reach a goal state. We call such states good states.

Consider Urpal is at junction x and he's traveling with a bus of type y. Let v1, v2, ..., vw be the list of junctions the bus might go on its shortest path from sy to ty. And let c1, c2, ..., cl be the list of companies that their bus surely passes junction x, excluding y-th company. For state (x, y) we know we can reach junction b (it's a good state) if one of the following is true:

x = b, the minimum cost of solving the problem will be 0.All states (v1, y), (v2, y), ... and (vw, y) are good states, the minimum cost of solving the problem will be the maximum of all these states.At least one of states (x, c1), (x, c2), ... or (x, cl) is a good state, the minimum cost of solving the problem will be the minimum the good ones plus one.At first the only good states we know are states with junction b, (b, ...). Now some new states might have become good states. So we add those states to the list of known good states. We do this until no state becomes good anymore.

At the end we print the minimum cost of source states which are good, and if they don't exist we print -1.

The process thing can be implemented in O(n4). :)

Codeforces Round #147 (Div. 2) Разбор Задач

By NALP, 10 years ago, In RussianПриветствую всех участников раунда!

237A - Free CashИз условия задачи легко понять, что если в некоторую минуту придут k человек, то Валере нужно иметь в кафе не менее k касс. Значит, требуется найти максимальное количество людей, которые придут в одну и ту же минуту, а это делается очень просто множеством способов, например, просто насчитав в массив cnt[h][m] количество людей, которые придут в час h и минуту m, а потом найдя в этом массиве максимум.

237B - Young TableРешение, которое опишем ниже, почти никак не использует хитрую форму таблицы (кстати, такая таблица называется диаграммой Юнга). Заполним таблицу числами от 1 до s следующим способом: будем идти по строкам таблицы начиная с первой слева направо, после конца текущей строки переходим на начало следующей, и в процессе каждой из клеточек присвоим число по порядку обхода от 1 до s. Очень просто показать, что такой порядок чисел удовлетворяет оба неравенства из условия.

Теперь опишем алгоритм приведения таблицы из того вида, как она нам дана во входных данных, в описанный выше вид.

Возьмем число 1 и посмотрим, где оно находится в этих двух таблицах. Если это число стоит не на своем месте, то поставим его на свое место, соответственно то число, которое там стояло, встанет на старое место единицы. Аналогично сделаем для 2, 3, ..., s. Очевидно, что этот алгоритм сделает не более s шагов и приведет таблицу в вид, описанный в первом абзаце.

237C - Primes on IntervalДля начала с помощью решета Эратосфена выделим все простые числа от 1 до b и пометим их единичками в массиве d, то есть если p — простое, то d[p] = 1, иначе d[p] = 0.

Заметим, что если l — корректное число, то l + 1 тоже корректно. В самом деле, для позиций x от a до b - l количество простых в отрезке с началом в x могло лишь увеличиться (мы же длину отрезка увеличили, а значит, количество простых в нем никак не могло уменьшиться). А кроме того исчез из рассмотрения один отрезок с началом в точке b - l + 1, так как при увеличении длины его правый конец стал больше, чем число b.

Таким образом, мы показали, что функция f(l), возвращающая TRUE или FALSE (корректно число или нет) монотонна, а значит, мы можем с помощью бинарного поиска найти наименьшее l, для которого f(l) = TRUE, или ответить, что такого не существует.

Функция f(l) считается очень просто — можно проитерироваться по всем числам от a до b - l + 1 и найти для каждого начала количество простых чисел в соответствующем отрезке длины l, это можно сделать с помощью частичных сумм, насчитанных по массиву d.

237D - T-decompositionВозьмем любое ребро начального графа, очевидно два его конца принадлежат некоторому множеству xi, значит, вес любой его Д-декомпозиции как минимум 2. Покажем, как постороить декомпозицию именно такого веса. Для этого каждое из ребер исходного графа превратим в отдельное множество xi, то есть все они будут состоять из двух элементов.

Очевидно, что первые два условия выполняются. Для выполнения третьего условия для начала соединим все множества по принципу: добавим ребро между двуми множествами, если их пересечение не пусто. Однако построенный таким образом граф не является деревом, покажем другой способ соединения вершин.

Для того, чтобы сделать из него дерево, достаточно для каждой вершины v начального дерева выделить все xi, в которых она содержится, и соединить их в цепочку в любом порядке, добавив нужное количество ребер.

Несложно понять, что такой граф не будет содержать циклов, будет связен, а значит является деревом. Постоенная Д-декомпозиция будет иметь вес 2, и количество вершин n - 1.

237E - Build StringЭта задача несложно решается алгоритмом поиска максимального потока минимальной стоимости на трехслойном графе:

первый слой состоит из n вершин, каждая из которых отвечает за свою строку из входных данных; в i-ую вершину этого слоя входит по одному ребру из истока с пропускной способностью ci и стоимостью i;

второй стой состоит за 26·n вершин, каждая из которых отвечает за количество определенных букв в каждой из строк из входных данных; в вершины этого слоя входят ребра только из первого слоя стоимостью 0 и пропускной способностью равной количеству соответствующих букв в соответствующей строке;

третий слой состоит из 26 вершин, каждая из которых отвечает за количество соответствующих букв в строке t; в вершины этого слоя входят ребра только из второго слоя стоимостью 0 и бесконечной пропускной способностью; кроме того, из вершин третьего слоя выходят ребра в сток стоимостью 0 и пропускной способностью, равной количеству соответствующих букв в строке t.

Если максимальный поток в этой сети меньше, чем |t|, то ответ равен  - 1, а иначе — минимальной стоимости максимального потока.

Codeforces Round #146 Tutorial

By YuukaKazami, 10 years ago, In English236A - Девушка или ЮношаIt is a very simple problem, just count how many distinct chars in the input and output the correct answer.

236B - Простая Задача с ЧисламиFirst of all, we can make a table of size a*b*c to store every number's d value. Then we can just brute force through every tripe to calculate the answer.

235A - Задача на НОКIt is a simple problem, but many competitors used some wrong guesses and failed. First of all, we should check if n is at most 3 and then we can simply output 1,2,6.

Now there are two cases: When n is odd, the answer is obviously n(n-1)(n-2). When n is even, we can still get at least (n-1)(n-2)(n-3), so these three numbers in the optimal answer would not be very small compared to n. So we can just iterate every 3 number triple in [n-50,n] and update the answer.

235B - Сыграем в Osu!Let us take a deep look at how this score is calculated. For an n long 'O' block, it contributes n2 to the answer.

Let us reformat this problem a bit and consider the following alternative definition of the score: (1) For each two 'O' pair which there is no 'X' between them, they add 2 to the score. (2) For each 'O', it adds 1 to the score.

We claim that this new definition of the score is equivalent to the definition in the problem statement.

Proof of the claim: For an n long 'O' block, there are Cn2 pairs of 'O' in it and n 'O' in it. Note that 2Cn2 + n = n2.

So now we work with the new definition of the score. For each event(i,j) (which means s[i] and s[j] are 'O', and there is no 'X' between them). If event(i,j) happens, it adds 2 to the score.

So we only need to sum up the probabilities of all events and multiply them by 2, and our task becomes how to calculate the sum of probabilities of all the event(i,j). Let P(i,j) be the probability of event(i,j).

We can see that P(i,j) can be computed by . Then we denote P(j) as the sum of all event(i,j) for i<j. We have dp(0)=0 and dp(j)=(dp(j-1)+pj - 1)*pj

235C - Циклическая ЗадачаThis problem can be solved by many suffix structures. Probably using suffix automaton is the best way to solve it since suffix automaton is simple and clear.

Let us build a suffix automaton of the input string S, and consider the query string x.

Let us also build a string t as x concatenated with x dropping the last char. One can see that every consecutive sub-string of t with length |x| is a rotation of x.

Let us read the string t with suffix automaton we have build, and every time take the first char out and add a new char, add the answer by the number of string equal to this current sub-string of t (which is a rotation of x).

And one more thing, we should consider the repetend of x as well, check my solution here:2403375.

Check here if you are not familiar with suffix automaton :e-maxx's blog

235D - Игра с ГрафомFirst of all, let us consider the simpler case of trees.

Let us use Event(A,B) to denote the following event "when we select A as the deleting point, B is connected to A".

Clearly, if Event(A,B) happens, it would add 1 to totolCost.

So we can just simply calculate the probability of every Event(A,B), and add them up.

Let us consider how to calculate the probability of Event(A,B).

Assume there are n vertices in the path between A and B, we claim that the probability is simply 1 / n.

Let us try to prove it using induction.

First let us assume there's a connected sub-graph of the tree containing both A and B, if the sub-graph only has n vertices, then the event happens only if we select vertex A, so the probability is 1 / n.

Otherwise, assume it has x vertices there is two cases: whether the selected vertex is on the path between A and B or not.

In the first case, the probability of Event(A,B) happen is 1 / x because if we don't select A, Event(A,B) will never happen.

In the second case, the sub-graph containing A,B has become smaller, so the probability is (x - n) / xn.

So add them up we can prove this statement.

Then we can solve the tree case by simply add up the inverse of every path's length in the tree.

And for the original case, there's at most 2 paths between A and B.

If there's only one path, then everything is the same with the tree case.

Otherwise, the path between A and B should pass the cycle in the graph.

Let us examine this case, you can see that there 2 types of vertex:

Vertex on the path of A to cycle or B to cycle, they should not be selected before A because once they're selected, A and B lost connectivity, let us call them X.

Vertex on the cycle, the two paths from A to B, each path contains a path in the cycle, let us call them Y and Z.

So there are two possibilities: X and Y are free when A is selected, X and Z are free when A is selected.

And we should subtract the case that X and Y, Z are all free when A is selected because it double-counts before.

So the probability is 1 / (X + Y + 1) + 1 / (X + Z + 1) - 1 / (X + Y + Z + 1).

Check Petr 's solution for the details: 2401228

And my C++ implementation: 2403938

235E - Задача с ЧисламиLet us consider each prime in one step, the upper limit for a, b, c is recorded.

So if we fixed the power of 2 in each i, j, k like 2x, 2y, 2z, then their upper limit becomes a / 2x, b / 2y, c / 2z, and the power of 2 in their multiplication is just x+y+z.

Let us denote dp(a, b, c, p) for the answer to the original problem that i, j, k 's upper limit is a, b, c. And their can only use the prime factors which are not less than p.

Let the next prime to be q, so we can try to fix the power of p in i, j, k and get the new upper limit.

So we can do transform like this: dp(a, b, c, p) = sum of dp(a / px, b / py, c / pz, q)·(x + y + z + 1)

Check my code here: 2404223

Also you can check rng_58 solution here: http://codeforces.ru/blog/entry/5600

If you have any problems, you can ask here :)

Editorial for Codeforces Round #144

By tunyash, 10 years ago, translation, In EnglishIt will be finised in few hours. If you don't understand something, ask your questions, please.

233A - Perfect Permutation

Idea: Gerald Implementation: tunyash Editorial: fdoer

Consider permutation p such that pi = i. Actually p is a sequence of numbers from 1 to n. Obviously ppi = i. Now the only trick is to change the permutation to satisfy the second equation: pi ≠ i. Let's swap every two consequtive elements. More formally, for each k: 2k ≤ n let's swap p2k - 1 and p2k. It's easy to see that the obtained permutation satisfies both equations for every n with the only exception: when n is odd, there is no answer and we should print  - 1.

233B - Non-square Equation

Idea: tunyash Implementation: tunyash, Gerald Editorial: fdoer

Firstly let's find the interval of possible values of s(x). Hence x2 ≤ n and n ≤ 1018, x ≤ 109. In other words, for every considerable solution x the decimal length of x does not extend 10 digits. So smax ≤ s(9999999999) = 10·9 = 90.

Let's bruteforce the value of s(x) (0 ≤ s(x) ≤ 90). Now we have an ordinary square equation. The deal is to solve it and to check that the current bruteforced value of s(x) is equal to sum of digits of the solution. If the solution exists and the equality holds, we should relax the answer.

It seems that the most error-generating part of this problem is solving the equation.

Knowing arrays is not neccessary to solve these two problems.

232A - Cycles

Idea: tunyash, fdoer Implementation: tunyash Editorial: tunyash

Let's add edge in order of increasing a and for equal b in order of increasing b (here a and b — the least and the greatest vertices of the edge). If the new edge adds too much 3-cycles, we won't add it. We can count the number of new 3-cycles in O(n) complexity (they all contain the new edge, so it's enough to check all variants of the third vertex). Obviously we will obtain some proper graph, because we can always add a vertex and two edges to make a new triangle. So, there is always an answer. The complexity of this solution is O(n3).

Let's proof that 100 vertices are always enough for the given restrictions on n.

For some p after first p iterations we will have a complete graph of p vertices.Now we have exactly C(p, 3) triangles. Consider p such that C(p, 3) ≤ k and C(p, 3) is maximal.For the given restrictions p ≤ 85.From this moment, if we add u from some vertex, we increase the total number of 3-cycles on C(u, 2).So we have to present a small number that is less than C(85, 3) as sum of C(i, 2).The first number we subtruct will differ C(85, 1) on some value not greater than C(85, 1) = 85, because C(n, k) - C(n - 1, k) = C(n - 1, k - 1).The second number we subtruct will differ the number we have on some value not greater than C(14, 1) = 14.and so on.For every k it's enough to use not more that 90 vertices.232B - Table

Idea: tunyash, Skird Implementation: tunyash Editorial: tunyash

Let si number of points in the column i. 

Two neighboring squares are drawn at this picture, A is the number of point it the left area (it is one column), B is the number of points in the middle area and C is the number of points in the right area (it is one column too). That's why by definition we have:

Therefore A = C.That's why Divide all columns by equivalence classes on the basis of . For all a and b from one class sa = sb.cnta is number of columns in class with .There are (Cnk)cnta ways to draw k points in the each of columns in the class a independendently of the other classes.dp[i][j] is number of ways to fill all columns in classes 1, ... i in such way that . cnti take only two values  and . Let's calc (Cna)cnti for all a and cnti and use it to calc our dp. We have O(n2·k) complexity.232C - Doe Graphs

Idea: Gerald,tunyash Implementation: tunyash, Gerald Editorial: tunyash

Let's reduce the problem to the same problem for graphs with less orders. Vertex |D(n - 1)| + 1 is cutpoint (except cases n ≤ 2 but equations below is true for these cases).

Without loss of generality a < b.

Let dist(a, b, n) — length of the shortest path in graph of order n.

The first case is a ≤ |D(n - 1)| and |D(n - 1)| + 1 ≤ b

dist(a, b, n) = min(dist(a, |D(n - 1)|, n - 1), dist(a, 1, n - 1)) + dist(b - |D(n - 1)|, 1, n - 2) + 1 

Edges is marked in red, paths is marked in blue. This formula means that we can go from the vertex a by the path 1 to the vertex 1. Then we can go to the |D(n - 1)| + 1 by the edge and go to the vertex b by the path 3. Or we can go to the vertex |D(n - 1)| by the path 2 and then go to the vertex |D(n - 1)| + 1 by the path 2 and then go to the vertex b by the path 3.

The second case is |D(n - 1)| + 1 ≤ a, b.

dist(a, b, n) = dist(a - |D(n - 1)|, b - |D(n - 1)|, n - 2)That's easy case.

The third case is a, b ≤ |D(n - 1)|

dist(a, b, n) = min(dist(a, b, n - 1), min(dist(1, a, n - 1), dist(|D(n - 1)|, a, n - 1)) + min(dist(1, b, n - 1), dist(|D(n - 1)|, b, n - 1) + 2) 

If shortest path contains cutpoint (|D(n - 1)| + 1) we can go to the vertex 1 or |D(n - 1)+1$ form the both of a and b. After that we can go to the cutpoint. Else we should consider path from a to b in D(n - 1).

Let's notice that for all of n will be no more than 4 distinct runnings of dist(i, j, n).

It can be prooved by the considering many cases of our actions.

In authors colution we cashed all dist(1, i, n) and dist(i, |D(n)|, n) for all achieveable i and n.

We have complexity  for one query. (it's log because |D(n)| grows like φn).

232D - Fence

Idea: Gerald, tunyash Implementation: fdoer Editorial: fdoer

Let d and d' be arrays such that di = hi - hi + 1, d'i =  - di for every 1 ≤ i ≤ (n - 1). With that notation the conditions of matching look somehow like these:

the pieces do not intersect, that is, there isn't a single plank, such that it occurs in both pieces of the fence;the pieces are of the same width;for all i i (0 ≤ i ≤ r1 - l1 - 1) the following condition holds: dl1 + i = d'l2 + i (that is true in case when l = r).The main idea of our solution is stated in the next sentence. For each query l...r the answer is number of pairs (a, b) such that (a > r or b < l), 1 ≤ a ≤ b ≤ n - 1, b - a = r - l and dl...r - 1 exactly matches d'a...b - 1. Let's build a suffix array sa from the concatenation of arrays d and d' with a fictive number between them for separation. Let position of suffix i in sa be posi. For each query all pieces of the fence that satisfy both second and third conditions of matching will be placed in sa on some segment boundleft...boundright such that boundleft ≤ posl ≤ boundright and lcp(boundleft...boundright) ≥ (r - l). So, it's possible to use binary search to find bound's. Depending on complexity of lcp finding algorithm, we could get them in O(logn) or O(log2n) complexity.

But there is still a problem to count the number of suffixes from saboundleft...boundright that satisfy the first condition too. Actually it is equal to count the number of i (boundleft ≤ i ≤ boundright) such that (n + 1 ≤ sai ≤ n + l - (r - l) - 1 or sai ≥ n + r) (in the concatenation d' starts from n + 1). It is a classic problem to count numbers from the given interval in the given subarray. For each query it could be solved in O(logn) complexity.

For instance, we could solve it offline using sweep line method and any data structure that support queries of sum on an interval and increment of an element. Or we could use some 2D/persistent structure.

So, the summary of the algorithm looks like this:

build d and d'. Build a suffix array on their concatenation.For each query:

find the interval (boundleft...boundright) with two consecutive binary searches using lcp function.query the count of suffixes from that interval that do not intersect with the given piece of the fence.The best author's solution complexity is O(nlogn + qlogn), but careful written solutions in O(nlog2n) comply with the lime limit too.

232E - Quick Tortoise

Idea: tunyash Implementation: tunyash, KAN Editorial: tunyash

Let's choose central column of the area and for all cells to the left from column calc masks of achieveable cells in the central column and for all cells to the right from column calc masks of cells of which this is achievable. It's easy dp with bitsets.  for the right part of board.  ( — logical or, here it's bitwise or for masks) for the left part. dp calcs mask of achieveable points in the central column.

 

For query x1, y1, x2, y2 (if y1 ≤ mid ≤ y2, where mid is chosen central column) answer is yes if  ( is bitwise and) is not empty.

Run this algo for left and right part of board we will get answers for all queries. Complexity is .

Codeforces Round #143 (Div. 2) Editorial

By Igor_Kudryashov, 10 years ago, translation, In English231A - Team

It is needed just to implement actions described in statement. You had to read data and to calculate number of members of team, which were sure about the solution, for every task. If this number is greater than one, the answer must be increased by one.

231B - Magic, Wizardry and Wonders

Let's see, what will be the last number of array after i iterations. After the first iteration it will be an - 1–an (and total number of elements will be decreased by one). After the second iteration the last number will be an - 2–an - 1 + an. It is not hard to see, that after n - 1 iterations remain a1–a2 + a3–a4 + ... + ( - 1)n + 1·an. In a such way, our task is to put numbers from 1 to l in array so, that sum of numbers in odd positions minus sum of numbers in even positions will equal to given d. This means sum of numbers in odd positions must be equal . But the minimal sum can be , and the maximal — .

Because of this we should choose a2·k so, that s fits the boundaries. Constrains allow to do it in a such manner. Firstly, put ones on the even positions. If s > maxv after that, the answer is  - 1. Otherwise, let's increase each a2·k by one until s = minv. If we put l in all even positions and s < minv, than answer is  - 1 too. After we put numbers on even positions, let's write 1 in all odd positions, and while sum of this elements is less than s increase each one by fitting value.

231C - To Add or Not to Add

One of the main observations, needed to solve this problem, is that the second number in answer always coincides with someone aj. Let's see why it is true. Suppose, the second number of the answer is aj + d for someone j and aj + d ≠ ai for all i. This means, we increased some numbers, which is less than aj, so that they became equal to aj, and then all this numbers and some numbers, which is equal to aj, we increased to aj + d. But if we didn't increase all this numbers to aj + d and remain they equal to aj, we'd perform less operations and the answer would be better.

Due to this fact we can solve problem in a such manner. Sort array in non-decreasing order. Iterate over ai and calculate, what is the maximal number of ai we can obtain. For maximizing first number of answer, we must increase some lesser numbers to ai and perform not greater than k operations. It is obvious that firstly we should increase such aj that ai–aj is minimal. So, if we can solve problem in O(n2), we would iterate j from i to 0 and increase aj to ai, while we could. But the solution must be faster, and we will use binary search. We will brute the number of numbers, which we must do equal to ai. Suppose we fix cnt this value. Now we have to check if we can do cnt numbers equal to ai by not greater than k operations. For doing this, let’s calculate . If this value not greater than k, we can do it. For calculating sum quickly, we can save prefix sums and than si - cnt + 1, i = si–si–cnt. Finally we solved this problem in O(n·logn).

231D - Magic Box

The main subtask of this problem is to check whether we can observe the center of face of parallelepiped from point p = (x, y, z). Let’s see the case, when the face belongs to plane z = z1. For performing all calculations in integer numbers, multiply all coordinates x, y, z, x1, y1, z1 by 2. Take the point  and normal to plane, containing the fixed face, which is directed out of interior of parallelepiped, that is . Also take vector . If undirected angle between this vectors is less than 90 degrees, we can observe a from p. For checking this we can use scalar product. If scalar product of  and  is strictly greater than zero, than that angle is fitting.

231E - Cactus

In this problem you should find the number of simple paths between some pair of vertices in vertex cactus. If you learn the structure of these graphs, it is not hard to see, that if we’ll squeeze each cycle in one vertex, we get a tree. So let’s squeeze all cycles in source graph and get this tree. Also every vertex of this tree we’ll mark, if it is squeezed cycle (let’s call this vertices 1-vertices) or single vertex in source graph (this vertices we’ll call 0-vertices).

Then, we’ll do the following to find the number of paths between vertices a and b in source graph. Suppose c is a vertex, corresponding to a in obtained tree (it can be a single vertex or a vertex, corresponding to a squeezed cycle with a), and d is a vertex, corresponding to b. Let’s denote deg is the number of 1-vertices in path from c to d in tree. Than it is easy to understand, that the answer for query is , because every cycle (1-vertex) increase the number of possible ways twice (you can go from one vertex to other by two ways in cycle).

It means that we need to count the number of 1-vertex on the path from one vertex to other in tree quickly to answer a query. We can do it in a following way. Hang our tree for one vertex, which we’ll call a root. Denote for every vertex cntv is the number of 1-vertex on the way to the root (including root and vertex itself). Suppose we want to find the number of 1-vertex on the path from a to b. Denote c is the least common ancestor of vertices a and b. Than number of 1-vertex on the way from a to b is equal to cnta + cntb–2·cntc, if c is 0-vertex and cnta + cntb–2·cntc + 1, if c is 1-vertex. The least common ancestor can be found by standard method — binary method recovery. Finally we have O(m + k·logn) solution.

Educational Codeforces Round 142 Editorial

By awoo, history, 6 weeks ago, translation, In English1792A - GamingForces

Idea: BledDest

Tutorial1792A - GamingForcesThe first spell looks pretty weak compared to the second spell. Feels like you almost always replace one with another. Let's show that you can totally avoid casting the spell of the first type twice or more on one monster.

Let the two first spell casts be (i,j) and (i,k) for some monsters i,j and k. You can replace them by a cast of the second spell on i and a cast of the first spell on (j,k). That would deal even more damage to i and the same amount to j and k. The number of casts doesn't change.

Thus, it only makes sense to use the first spell on monsters with 1 health. Calculate the number of them, kill the full pairs of them with the first spell, and use the second spell on the remaining monsters.

Overall complexity: O(n) per testcase.

Solution (Neon)1792B - Stand-up Comedian

Idea: BledDest

Tutorial1792B - Stand-up ComedianFirst, let Eve tell the jokes of the first type — they will never do any harm. At the same time, let her tell the jokes of the fourth time at the very end — they will not do any good.

Types two and three are kind of opposites of each other. If you tell jokes of each of them one after another, then the moods of both spectators don't change. Let's use that to our advantage. Tell the jokes of these types in pairs until one of them runs out. There's a little corner case here, though. If there were no jokes of the first type, then you can't use a single pair because of the spectators leaves after one joke.

Finally, try to tell the remaining jokes of the same type before the fourth type. So the construction looks like 1,1,…,1,2,3,2,3,…,2,3,2,2,2,…,2,4,4,4,…,4 with 2 and 3 possibly swapped with each other.

Let's recover the answer from that construction. After the first type, both moods are a1. After the alternating jokes, the moods are still the same. After that, one of the spectators will have his/her mood only decreasing until the end. Once it reaches −1, the show ends.

Thus, Eve can tell a1+min(a2,a3)⋅2+min(a1+1,abs(a2−a3)+a4) jokes if a1≠0. Otherwise, it's always 1.

Overall complexity: O(1).

Solution (awoo)1792C - Min Max Sort

Idea: BledDest

Tutorial1792C - Min Max SortIf the array is already sorted, then the answer is 0. Otherwise, there is a last operation, after which the permutation takes the form 1,2,…,n. Which means that the elements 1 and n are selected as the last operation (because they are at the first and last positions after the operation). Now we know that the last operation is (1,n) and it doesn't matter where exactly these numbers are in the permutation, i. e. we can assume that the answer has increased by 1, and consider only the numbers 2,3,…,n−2,n−1. Similarly, for the "remaining" permutation, there are two options, either it is sorted, and then the answer is 1, or there is a last operation and the numbers 2 and n−1 are used in it. And so on until the "remaining" permutation is sorted or empty.

It remains to find out how to quickly check whether the numbers in the segment [k,n−k+1] are sorted (they go in the correct order in the initial permutation). Note that this segment corresponds to values of elements, not to positions in the permutation. If this segment is sorted for some k, then the answer does not exceed k−1.

There are several ways to check, let's consider one of them. Note that if the segment [k,n−k+1] is sorted for some value k, then it will be sorted for large values as well. So we can start with the maximum value of k (which is equal to ⌊n+12⌋) and decrease it until the segment remains sorted. Now for each k we need only two checks that posk < posk+1 and posn−k+1 > posn−(k+1)+1, where posi is the position of the element i in the permutation.

Thus, we got the solution in linear time.

Another way is to run binary search on k since if the numbers in [k,n−k+1] appear in the permutation in sorted order, the same holds for k+1. This approach yields a solution in O(nlogn).

Solution (Neon)1792D - Fixed Prefix Permutations

Idea: BledDest

Tutorial1792D - Fixed Prefix PermutationsLet's try to solve for one of the given permutations. Let it be some p. How to make the answer for it at least 1? Well, we have to find another permutation q such that p⋅q=(1,r2,r3,…,rm). How about at least k? Well, the same: p⋅q=(12…,k,rk+1,…,rm).

Push q to the right side of the equation. p=(12…,k,rk+1,…,rm)⋅q−1. Now think. What does it actually mean for some permutation to be multiplied by (1,2,…,k)? It stays the same. So the first k elements of p will be equal to the first k elements of q−1.

Thus, you have to find a permumtation such that its inverse has the longest common prefix with p. This can be done in multiple ways. For example, you can store all inverses in a trie and traverse it with p until you reach a dead end. Or simply push all prefixes of each inverse into a set and iterate over k. Alternatively, you can just sort inverses and do lower_bound for p in this list — the permutation with longest common prefix will be either the result or the one before it.

Overall complexity: O(nm)/O(nmlogn)/O(nm2logn) per testcase.

Solution (awoo)1792E - Divisors and Table

Idea: adedalic

Tutorial1792E - Divisors and TableFirstly, let's factorize m. Since m=m1⋅m2 we can factorize m1 and m2 separately and then "unite" divisors. For example, use can get canonical representations of m1=pf11pf22…pfkk and m2=pg11pg22…pgkk to get canonical representation of m=pf1+g11pf2+g22…pfk+gkk and then use it to generate all divisors of m.

Let's estimate the number of divisors divs(m). It's convenient for our purposes to estimate it as O(m13). More precisely, there are at most 105000 divisors for m≤1018 (search "Highly Composite Numbers" for more info).

How to calculate the answer ai for each divisor d? There are two ways.

The intended solution: for each d we are searching for the minimum x that d=xy and y≤n. Since d is fixed, the minimum x means the maximum y≤n. So let's find y instead. In other words, for each d we need to find the maximum y such that y divides d and y≤n. We can do it efficiently with dp on divisors.

Let dp[d] be the maximum y that is a divisor of d and y≤n. If d≤n then, obviously, dp[d]=d. Otherwise, we know that we are searching y<d.

Let say that p1,p2,…,pk are the prime divisors of the initial number m. Since y is a divisor of d and y<d then exists some pi among the set of prime divisors such that y is a divisor of dpi as well. So, instead of brute search, it's enough to take a value dp[dpi].

In other words, if d>n we can calculate dp[d]=maxpi|ddp[dpi].

Ok, now we know value dp[d] for each divisor d. Since we found the maximum y≤n, the last step is to calculate the desired x=ddp[d] and if x≤n we found the answer ai, otherwise (x>n) it means that d is not presented n×n table and ai=0.

The total complexity is O(m1+m2−−−−−−−√+divs(m)⋅z(m)⋅log(divs(m))) per test, where divs(m) is the number of divisors of m (divs(m)≤105000) and z(m) is the number of prime divisor of m (z(m)≤15). Note that complexity is quite high, so you should write it at least a little accurate, for example store dp[d] in an array, not map, and search position of dp[dpi] with lower_bound().

There is also a way to get rid of extra log(divs(m)) factor if you iterate through dp is a smart way.

The alternative solution (faster, easier, unproven): Let's generate a list of all divisors of m as d1,d2,…,dl in the increasing order. For some divisor di we are searching the minimum x that is a divisor of di and dix≤n. It means that x≥⌈din⌉.

So let's just find the first position j such that dj≥⌈din⌉ with lower_bound and start iterating from j onward searching the first dj that is a divisor of di. The found dj would be the minimum x we need.

It looks like, in average, we will find the correct dj quite fast, or we'll break when dj>n.

Solution (adedalic)1792F1 - Graph Coloring (easy version)

Idea: BledDest

Tutorial1792F1 - Graph Coloring (easy version)Lemma: if an undirected graph is disconnected, then its complement is connected. Similarly, if its complement is disconnected, then the graph itself is connected.

Proof: suppose a graph is disconnected. Pick two vertices x and y from different components. Every vertex outside of x's component is connected to x in the complement, and every vertex outside of y's component is connected to y in the complement; the complement also contains the edge from x to y, so all vertices in the complement graph belong to the single component.

Why do we need this lemma at all? We can treat the graph formed by blue edges as the complement to the graph formed by red edges. So, if the "red" graph is disconnected, then the "blue" graph is connected, so we don't need to consider the case when some set of vertices is connected by neither color. We only need to make sure that no set of vertices is connected by both colors.

Let An be the answer for n. Every graph counted in An is either red-disconnected or blue-disconnected; since there is a bijection between red-disconnected and blue-disconnected graphs (you can flip the colors of all edges to transform one type into the other), we will count only red-disconnected graphs and multiply it by 2.

Let Bn be the number of blue-connected graphs with n vertices meeting the properties of the problem statement. It's easy to see that An=2⋅Bn if n>1, otherwise An=Bn (the case n=1 is special because a graph on one vertex is both red-connected and blue-connected). To calculate An, let's iterate on k — the number of vertices which are in the same "red" component as 1. This component must be a red-connected graph which meets the problem statement, so the number of ways to build the graph on these k vertices is Bk; there are (n−1)!(k−1)!(n−k)! ways to choose the vertices in the same component as 1, and the remaining graph can be either red-connected or blue-connected, so the number of ways to build the remaining graph is An−k.

Thus, we get the following two relations:

Bn=∑k=1n−1BkAn−k(n−1)!(k−1)!(n−k)!An=2⋅Bn if n>1, otherwise BnWe can calculate all values with dynamic programming using these formulas in O(n2).

Solution (BledDest)1792F2 - Graph Coloring (hard version)

Idea: BledDest

Tutorial1792F2 - Graph Coloring (hard version)Please read the tutorial for the easy version first, since this tutorial uses some definitions from it.

Okay, we need more definitions. Here they come:

C0=0,Ci=Aii! if i>0D0=0,Di=Bi(i−1)! if i>0This way, we can transform the formula for Bn to the following:

Bn=(n−1)!⋅∑k=1n−1Cn−kDk.

Or even this, since C0=D0=0:

Bn=(n−1)!⋅∑k=0nCn−kDk.

This is almost the convolution of the sequences C and D (with a bit extra additional operations after the convolution), so, to compute the sequence B, we just need to compute the sequences C and D, and then calculate their convolution with NTT. All that's left is to multiply every element by the corresponding factorial.

But wait, that's not so easy. In order to calculate Ci and Di, we need to know Bi. Note that we can ignore the fact that Ci and Di appear in the formula for Bi, since they are multiplied by 0, so at least we don't have a dependency cycle. Unfortunately, we cannot just straightforwardly use convolution if we don't know the sequences Ci and Di.

The model solution handles it using the following approach. Let's generate A, B, C and D in parallel: on the i-th iteration, calculate Bi, then calculate Ai, Ci and Di using it. And sometimes we will calculate the convolution of the sequences C and D.

Suppose we want to calculate Bi, and the last time we calculated the convolution of C and D was after the iteration t. Back then, we knew all elements from C0 to Ct and from D0 to Dt. So, the i-th term in the convolution of C and D contained the sum of Ci−kDk over all k such that k≤t and i−k≤t. So, in order to calculate Bi, we have to pick this value from the convolution and then add the sum of Ci−kDk over all k such that k>t or k≤i−t, and there are 2(i−t) such values.

Suppose we compute the convolution every K iterations. Then the maximum value of i−t is K, and every value of Bi is calculated in O(K). We also make nK convolutions, so the total complexity of this solution will be O(n2lognK+nK), which can be transformed into O(nnlogn−−−−−√) if we pick K=nlogn−−−−−√.

Solution (BledDest)

Educational Codeforces Round 141 Editorial

By awoo, history, 2 months ago, translation, In English1783A - Make it Beautiful

Idea: BledDest

Tutorial1783A - Make it BeautifulIf we put the maximum in the array on the first position, then for every element, starting from the third one, the sum of elements before it will be greater than it (since that sum is greater than the maximum value in the array). So, the only element that can make our array ugly is the second element. We need to make sure that it is not equal to the first element.

Let's put the maximum element on the first position, the minimum element on the second position, and then fill the rest of the array arbitrarily. The only case when it fails is when the maximum element is equal to the minimum element — and it's easy to see that if the maximum is equal to the minimum, then the first element of the array will be equal to the second element no matter what, and the array cannot become beautiful.

So, the solution is to check if the maximum is different from the minimum, and if it is so, put them on the first two positions, and the order of remaining elements does not matter. Note that the given array is sorted, so the minimum is the first element, the maximum is the last element.

Solution (BledDest)1783B - Matrix of Differences

Idea: BledDest

Tutorial1783B - Matrix of DifferencesThe first step is to notice that beauty doesn't exceed n2−1, because the minimum difference between two elements is at least 1, and the maximum difference does not exceed n2−1 (the difference between the maximum element n2 and the minimum element 1).

At first, finding a matrix with maximum beauty seems to be a quite difficult task. So let's try to find an array of n2 elements of maximum beauty. In this case, it is not difficult to come up with an array of the form [n2,1,n2−1,2,n2−2,3,…]. In such an array, there are all possible differences from 1 to n2−1. So we found an array with the maximum possible beauty.

It remains to find a way to "convert" the array to the matrix, i.e. to find such a sequence of matrix cells that each two adjacent cells in it are side-adjacent. One of the ways is the following: traverse the first row of the matrix from left to right, go down to the second row, traverse it from right to left, go down to the third row, traverse it from left to right, and so on.

Thus, we constructed a matrix with the maximum possible beauty n2−1.

Solution (Neon)1783C - Yet Another Tournament

Idea: BledDest

Tutorial1783C - Yet Another TournamentSuppose, at the end, you won x matches, what can be your final place? Look at each opponent i with i<x (0-indexed). Since the i-th opponent (0-indexed) won i games against the other opponents, even if they win against you, they'll gain i+1≤x wins in total and can't affect your place (since your place is decided by only opponents who won strictly more matches than you).

From the other side, let's look at each opponent i with i>x (0-indexed). Even if they lose to you, they still have i>x wins (you have only x), so all of them have strictly more wins than you.

As a result, there is only one opponent i=x, whose match against you can affect your final place: if you won against them, your place will be n−x, otherwise your place will be n−x+1.

Now, let's compare your possible places if you win x games with places for winning only x−1 games: x wins gives you places n−x or n−x+1, while winning x−1 leads you to places n−x+1 or n−x+2 that objectively worse.

In other words, it's always optimal to win as many matches as possible.

How to win the most number of games? It's to choose the easiest opponents. Let's sort array a and find the maximum prefix [0,x) with a0+a1+⋯+ax−1≤m. So, we found maximum number of games x we can win. The last is to check: can we get place n−x, or only n−x+1.

If ax contains among x smallest values, then we'll take place n−x. Otherwise, let's try to "insert" ax in this set, i. e. let's erase the biggest among them and insert ax. If the sum is still lower or equal to m, it's success and we get place n−x. Otherwise, our place is n−x+1.

The total complexity is O(nlogn) because of sorting.

Solution (Neon)1783D - Different Arrays

Idea: BledDest

Tutorial1783D - Different ArraysOne of the key observations to this problem is that, after the first i operations, the first i elements of the array are fixed and cannot be changed afterwards. Also, after the i-th operation, the elements on positions from i+3 to n are the same as they were before applying the operations.

This allows us to write the following dynamic programming: dpi,x,y — the number of different prefixes our array can have, if we have performed i operations, the (i+1)-th element is x, and the (i+2)-th element is y. The elements after i+2 are the same as in the original array, and the elements before i+1 won't be changed anymore, so we are interested only in these two elements.

Let's analyze the transitions in this dynamic programming. We apply the operation i+1 to the elements ai+1, ai+2 and ai+3. If we add ai+2 to ai+1, then we subtract it from ai+3, so we transition into state dpi+1,y,ai+3−y. Otherwise, we transition into state dpi+1,y,ai+3+y. The element we leave behind is either x−y or x+y, and if y≠0, these two transitions give us different prefixes. But if y=0, we need to make only one of these transitions, because adding or subtracting 0 actually makes no difference.

Okay, now we've got a solution with dynamic programming in O(n3A2), where n is up to 300 and A is up to 300. This is too slow. But we can notice that the value of ai+1 actually does not affect our transitions at all; we can just discard it, so our dynamic programming becomes O(n2A), which easily fits into TL.

Small implementation note: elements can become negative, and in order to store dynamic programming with negative states in an array, we need to do something about that. I don't recommend using maps (neither ordered nor unordered): you either get an extra log factor, or make your solution susceptible to hacking. Instead, let's say that the value of dpi,y, where y can be a negative number, will be stored as dp[i][y+M] in the array, where M is some constant which is greater than the maximum possible |y| (for example, 105 in this problem). That way, all array indices will be non-negative.

Solution complexity: O(n2A).

Solution (BledDest)1783E - Game of the Year

Idea: BledDest

Tutorial1783E - Game of the YearConsider some value of k. When is it included in the answer? When Monocarp spends a lower or an equal amount of "blocks" of attempts than Polycarp for killing every boss.

Formally, ⌈aik⌉≤⌈bik⌉ for all i from 1 to n.

Let's reverse this condition. k is not in the answer if there exists such i from 1 to n that ⌈bik⌉<⌈aik⌉. So, there exists at least one value between ⌈bik⌉ and ⌈aik⌉. Let's call it x. Now it's ⌈bik⌉<x≤⌈aik⌉. I set the ≤ and < signs arbitrarily, just so that it shows that such a value exists. You can't put both ≤ or both <, because that will accept 0 values or at least 2 values, respectively.

Would be cool if we could multiply everything by k and it still worked. Is it completely impossible, though? Take a look at bi<xk≤ai. What it says is that there exists a multiple of k between bi and ai. A multiple of k is a number that's the last in each "block" of attempts (the block of value that are rounded up the same). Turns out, this is what we are looking for already. Right after the multiple of k, the new block starts. Thus, we are wrong we our signs. It should be bi≤xk<ai — ai is in the block after bi, so it requires more blocks of attempts.

So for k to not be included in the answer, there should exist at least one i such that there exists a multiple of k in the half-interval [bi;ai).

That is pretty easy to implement. For each x, calculate the number of half-intervals that cover x. I think this is called delta-encoding. Iterate over all half-intervals and make two updates for each one: increment by 1 on position bi and decrement by 1 on position ai. Then make a prefix sum over these updates. Now the value in the x-th position tells you the number of half-intervals that cover x.

To check a particular value of k, iterate over all multiples of k and check that none are covered by half-intervals. It's known that the total number of multiples over all numbers from 1 to n is n+n2+n3+⋯+nn=O(nlogn).

Overall complexity: O(nlogn) per testcase.

Solution (BledDest)1783F - Double Sort II

Idea: BledDest

Tutorial1783F - Double Sort IIThe solution to this problem uses cyclic decomposition of permutations. A cyclic decomposition of a permutation is formulated as follows: you treat a permutation as a directed graph on n vertices, where each vertex i has an outgoing arc i→pi. This graph consists of several cycles, and the properties of this graph can be helpful when solving permutation-based problems.

First of all, how does the cyclic decomposition of a sorted permutation look? Every vertex belongs to its own cycle formed by a self-loop going from that vertex to itself. We will try to bring the cyclic decompositions of the given permutations to this form.

What does an operation with integer i do to the cyclic decomposition of the permutation? If i is in its own separate cycle, the operation does nothing (pi=i, so we swap an element with itself).

Otherwise, let's suppose that x is the element before i in the same cycle (px=i), and y is the element after i in the same cycle (pi=y). Note that this can be the same element. When we apply an operation on i, we swap px with pi, so after the operation, pi=i, and px=y. So, i leaves the cycle and forms its separate cycle, and y becomes the next vertex in the cycle after x. So, using the operation, we exclude the vertex i from the cycle.

Suppose we want to sort one permutation. Then each cycle having length ≥2 must be broken down: for a cycle of length c, we need to exclude c−1 vertices from it to break it down. The vertex we don't touch can be any vertex from the cycle, and all other vertices from the cycle will be extracted using one operation directed at them. It's easy to see now that if we want to sort a permutation, we don't need to apply the same operation twice, and the order of operations does not matter.

Okay, then what about sorting two permutations in parallel? Let's change the problem a bit: instead of calculating the minimum number of operations, we will try to maximize the number of integers i such that we don't perform operations with them. So, an integer i can be left untouched if it is the only untouched vertex in its cycles in both permutations... Can you see where this is going?

Suppose we want to leave the vertex i untouched. It means that in its cycles in both permutations, every other vertex has to be extracted with an operation. So, if two cycles from different permutations have a vertex in common, we can leave this vertex untouched, as long as there are no other vertices left untouched in both of these cycles. Let's build a bipartite graph, where each vertex in the left part represents a cycle in the first permutation, and each vertex in the right part represents a cycle in the second permutation. We will treat each integer i as an edge between two respective vertices in the bipartite graph. If the edge corresponding to i is "used" (i is left untouched), we cannot "use" any edges incident to the same vertex in left or right part. So, maximizing the number of untouched numbers is actually the same as finding the maximum matching in this bipartite graph.

After you find the maximum matching, restoring the actual answer is easy. Remember that the edges saturated by the matching correspond to the integers we don't touch with our operations, the order of operations does not matter, and each integer has to be used in an operation only once. So, the actual answer is the set of all integers without those which correspond to the edges from the matching.

This solution runs in O(n2) even with a straightforward implementation of bipartite matching, since the bipartite graph has at most O(n) vertices and O(n) edges.

Solution (BledDest)1783G - Weighed Tree Radius

Idea: BledDest

Tutorial1783G - Weighed Tree RadiusFirstly, let's define the weight of path (u,v) as wp(u,v)=au+du(v)+av. On contrary to weighted distances, wp(u,v)=wp(v,u) and also wp(v,v)=2av.

Now, let's define the diameter of a tree as path (u,v) with maximum wp(u,v). It's okay if diameter may be explicit case (v,v). The useful part of such definition is next: our diameter still holds most properties of the usual diameter. Let's look at two of them:

There is a vertex on diameter path (x,y) with wv(x)=⌈wp(x,y)2⌉ and wv(y)=wp(x,y)−wv(x). It's easy to prove after noting the fact that ax≤dx(y)+ay and ay≤dy(x)+ax (otherwise, you could choose diameter (x,x) or (y,y)).For any vertex v eccentricity e(v)=max(wv(x),wv(y)). In other words, either x or y has the maximum distance from v. (You can also prove it by contradiction). It also means that e(v)≥⌈wp(x,y)2⌉.The two properties above give us an easy way to calculate the radius: just maintain diameter (x,y), and the answer is a half of it.Now let's look how the diameter changes when we change the weight av. If av is increasing it's quite easy. The only paths that change weights are the paths ending at v. Denote such path as (v,u) and note that either v=u or wp(v,u)=av+wv(u)≤av+e(v) = av+max(wv(x),wv(y)). In other words, there will be only three candidates for a new diameter:

path (v,v) with wp(v,v)=2av;path (v,x) with wp(v,x)=av+dv(x)+ax;path (v,y) with wp(v,y)=av+dv(y)+ay.The only thing you need to calculate fast enough is the two distances dv(x) and dv(y). And since dv(x)=depth(v)+depth(x)−2⋅depth(lca(v,x)), your task is to calculate lca.

Finally, how to handle decreasing av's? Let's get rid of them using DCP (dynamic connectivity problem) technique. Keep track of each value av: each possible value av for some vertex v will be "active" on some segment of queries [l,r)∈[0,m). Since there are only m queries, there will be exactly n+m such segments for all vertices v in total.

Now, all queries becomes "assign av=x on some segment of queries [l,r)". Note that in that case, the previous value of av was 0, so you are dealing with only "increasing value" queries.

Finally, to handle all range queries efficiently, you build a Segment Tree on queries, set all queries and then traverse your Segment Tree while maintaining the current diameter in order to calculate answers for all queries.

Each of n+m queries transforms in O(logm) queries to segment tree vertices, and preforming each query asks you to calculate lca two times.

If you use the usual binary lifting, then your complexity becomes O((n+m)logmlogn) what is okay. But if you use Sparse Table on Euler tour, you can take lca in O(1) and your complexity will be O(nlogn+(n+m)logm).

Solution 1 (adedalic)Solution 2 (adedalic)

Codeforces Round #140 Editorial

By Malinovsky239, 10 years ago, translation, In EnglishA div2. Where do I Turn?Let's consider cross product of vectors  and , which is equal to . Sign of cross product defines sign of a sine of oriented angle between vectors (because cross product is also equal to ), and that sign leads us to the correct answer.

If cross product is equal to zero, then A, B and C lay on the same straight line. So the answer is <>.

If cross product is more than zero, then answer is <>.

And, at last, if it's less than zero, the answer is <>.

Also you should notice that the value of cross product doesn't fit 32-bit type, so you have to use 64-bit type in order to avoid integer overflow.

Implementation

B div2. Effective ApproachLet's assume that number t is on the indtth position in the original permutation. Then, obviously, during iterating from left to right this number will be found in indt comparisons, and during iterating from right to left — in n - indt + 1 comparisons. Let's declare additional array, in ith element of each there will be such number j, that aj = i. This array allows to process each query in O(1) using formulas referred above. Additional array is built in O(n) during iterating array a. So, the final complexity is O(n + m).

Implementation

C div2 — A div1. Flying Saucer Segments.Let Fn be the answer for the task, where n is equal to the amount of aliens. Let's assume, that we've solved problem for n - 1 aliens, i.e. we know the value of Fn - 1. Let's try to find value of Fn. Notice, that the most junior alien in rank will be able to leave the 3rd section, if and only if all other aliens are in the 1st section. So, now we know first Fn - 1 actions. Then the most junior alien may go to the

Unable to parse markup [type=CF_TEX]

section. To make for him entrance to the 1st section possible, it's necessary for all other aliens to return to the first one. So, Fn - 1 more actions are necessary. At last, after the most junior alien will go to the 1st section, Fn - 1 more actions are required for n - 1 other aliens to return to the 1st section from the 3rd. So, Fn = Fn - 1 + 1 + Fn - 1 + 1 + Fn - 1. It allows to count Fn using matrix exponentiation in O(log n), but we'll improve current solution. Let's add 1 to both parts of the equality and after elementary operations we'll have Fn = 3·(Fn - 1 + 1) - 1. Now it's easy to solve this reccurence: Fn = 3n - 1.To count Fn quickly you should use binary power method. Solution's complexity — O(log n).

Don't forget that if 3n mod m = 0, answer is equal to m - 1, but not  - 1.

And, in conclusion, notice that the task is equal to Hanoi Towers problem with a slight modification (it's impossible to move disks between one pair of rods).

Implementation

D div2 — B div1. Naughty Stone PilesConsider the following interpretation of the problem: stone piles are graph vertices. Operation "add pile a to pile b" changes to operation of suspencion of subtree of vertice b to vertice a. Numbers, written on vertices, — piles' sizes. Your task is to get such tree configuration, that each vertice has no more than k subtrees suspended to it, and sum of the products of numbers, written on vertices, and vertices' depth (where root's depth is 0) is minimal. In order to minimize the sum, at first, vertice with a larger number must be not deeply than vertice with smaller number (otherwise it's possible to change them and to get less sum), at second, each inner vertice, besides, maybe, one, has exactly k successors (the second condition is also proved using proof by contradiction). Now you are to learn how to calculate sum (described above) for this configuration quickly. In order do to it, let's sort piles' size array, and then let's do the following: at first, let's add to answer sum of sizes of piles from 1st to kth (in 0-indexed array, sorted in non-increasing order), multiplied by 1; then sum of sizes of next k2 piles, multiplied by 2; and so on till the end of array. In order to answer for the query about the sum of segment, precalculate sums of prefixes immediately after array sorting. Now in the case k > 1 we can find answer in O(log n). If you follow the same considerations for k = 1, answer for query will get O(n) operations that's why solution will get TL, if k is equal to 1 in most of the queries. So you should calculate the answer for k = 1 beforehand and memorize it, in order to response such queries in O(1).

Complexity — O(n · log n  +  q · log n).

Implementation

E div2 — C div1. AnniversaryAt first, let's prove the statement: GCD(Fn, Fm) = FGCD(n, m).

Let's express Fn + k using Fn and Fk. We'll get the formula: Fn + k = Fk·Fn + 1 + Fk - 1·Fn, which is easy to prove by induction.

Then use the derived formula and notice, that GCD(Fn + k, Fn) = GCD(Fk, Fn).

Now you are to notice an analogy with Euclidean algorithm and to understand, that we've got necessary equality for GCD of two Fibonacci numbers.

So, our current task is to find in the given set subset of k (or at least of k) elements with maximal possible GCD. To be exactly, to find this GCD.

Let the answer be equal to q. Then   -  ⌉ + 1 ≥ k (1) must be true.

Notice, that for each summand from left part of inequality O(  ) segments exist, in which its value is constant. Moreover, we can find all these segments and values in . To be more precise, we are intersted in such q, that in the point q - 1 value of at least one summand changes (obviously, increases). There are also  such values. Go over all of them and try to use each of them as the answer (i.e., check inequality (1) for each of them), and choose maximum from all satisfying numbers. The answer always exists, as q = 1 is true for any input.

So, we've found index of required Fibonacci number. The number itself can be calculated by matrix exponentiation.

Implementation

Complexity — .

D div1. The table.Let's get the required table. Act in the following way: find any row or column with negative sum and invert it. Notice, that sum of numbers in the entire table will always increase (at least, by 2). It can't increase permanently, because its maximal possible summary change is 200·n·m. So we'll get the required table anyway. It takes us not more than 100·n·m operations (applying of the spell), each of those is performed in O(n) or O(m). So, we've learned how to get required table in not more than ~ 1004 operations.

Now let's restore the answer. It's easy to understand that it will contain those rows and columns, which we've inverted odd times.

Implementation

E div1. Noble Knight's PathSolution 1It's easy to guess that castles form a tree. Let's build heavy-light decomposition over it. Moreover, let's build persistent segment tree (with sum as the function) over each path. Tree's vertex will contain 0, if castle wasn't attacked by barbarians, and 1 otherwise.

Each knight's path should be divided into not more than two subpaths each of them lays on the path from one of the route's end to tree's root (just use lca in order to do it). Now let's solve the problem for each of the subpaths separately. We should sequentially process paths from heavy-light decomposition and single vertices, which lay on subpath. We are going to count the amount of vertices, which was not visited since year y + 1 up to the current year, i.e. (in the case of a path of the decomposition) such vertices, that the difference between values in the current version of persistent segment tree and in the version corresponding to year y (use binary search to find required version in the list of versions) is equal to zero (in case with single vertice it's enough to remember time when vertice was visited). As soon as the amount of appropriate vertices become not less than k, we should simultaneously walk down in two tree's versions in order to get the answer.

If the kth vertex isn't found on the first subpath, you should pay attention on the fact, that as we always go from down to up, we should accurately recalculate required vertex's number, in order to know it's position in the second subpath from down to up.

Complexity: O(m·log2 n) — in each query of the first type it can be necessary to update some segment tree, this action takes O(log n) operations; in each query of the second type there are O(log n) decomposition's paths, each of them is processed in O(log n) (firstly, binary search through versions' list, then query to the tree/walking down).

Implementation

Solution 2Let's go round the tree using dfs. When we enter the vertex and when we leave it let's put down vertex's number in the additional array (you can find out that this list has something same with regular brackets sequence). Assign 0 as the second number to all elements of the array. Then build persistent segment tree on the described array.

Now, when the first event happens, we'll assign  + 1 to the second number in position of the first occurence of a castle's number, and  - 1 to a position of the last one.

In order to answer for the second query, just notice, that we should count sum of the second numbers assigned to positions between first occurences of the vertices a and b in the array described above for finding the amount of visited vertices in the path connecting them.

Now on each of the paths separately start binary search for an answer — position of required castle. For the answer's check use the idea from the previous paragraph.

Complexity: O(m·log2 n) — in each query of the first type it can be necessary to update some segment tree, this action takes O(log n) operations; in each query of the second type there are O(log n) iterations of binary search on answer, each of iterations takes O(log n) operations.

Implementation

Questions?

Educational Codeforces Round 139 Editorial

By awoo, history, 3 months ago, translation, In English1766A - Extremely Round

Idea: BledDest

Tutorial1766A - Extremely RoundThere are many ways to solve this problem.

The most naive one (iterating through all numbers from 1 to n in each test case and checking if they are extremely round) fails, since it is O(tn), but you can optimize it by noticing that extremely round numbers are rare. So, for example, we can iterate through all numbers from 1 to 999999 once, remember which ones are extremely round, store them into an array, and while answering the test case, only check the numbers from the array we have created.

There is also a solution in O(1) per test case with a formula, try to invent it yourself.

Solution (BledDest)1766B - Notepad#

Idea: BledDest

Tutorial1766B - Notepad#Why does the problem ask us only to check if we can do less than n operations instead of just asking the minimum amount? That must be making the problem easier, so let's focus our attention on that.

What if it was ≤n instead of <n? Well, then the problem would be trivial. You can type the word letter by letter and be done in n operations. So we only have to save one operation. In order to save at least one operation, we have to use the copy operation and copy more than one character in that.

Let's take a closer look at any of the copy operations we do. Basically, it has to be a substring that has at least two non-intersection occurrences in the string. Thus, if the string has any substring that has length at least two that appears at least twice in the string, we can copy it, and the answer will be "YES".

That's still not enough to solve the problem — we'd have to check all substrings, which is O(n2).

Let's think further. Imagine we found a substring that works. Let it have length k. Notice how you can remove its last character, obtaining a substring of length k−1, and it will still occure in the same set of positions (possibly, even more occurrences will be found). Remove characters until the substring has length 2. Thus, if any appropriate substring exists, an appropriate substring of length 2 also exists.

Finally, we can check if there exists a substring of length 2 that appears at least twice in the string so that the occurrences are at least 2 apart. That can be done with a set/hashset or a map/hashmap. Some implementations might require careful handling of the substrings of kind "aa", "bb" and similar.

Overall complexity: O(n) or O(nlogn) per testcase.

Solution (awoo)1766C - Hamiltonian Wall

Idea: BledDest

Tutorial1766C - Hamiltonian WallWhy is there a constraint of each column having at least one black cell? Does the problem change a lot if there were white columns? Well, if such a column was inbetween some black cells, then the answer would be "NO". If it was on the side of the grid, you could remove it and proceed to solve without it. So, that doesn't really change the problem other than removing some casework.

Let's try to fix a start. Find a column that has only one black cell in it. If there are no such columns, the answer is immediately "YES". Otherwise, the path will always go through it in known directions: to the left and to the right (if both of them exist). Let's solve the problem separately for the left part of the path and for the right one — find a path that starts to the left of it and covers everything to the left and the same for the right part.

Consider the right part.

If the next column also has one black cell, then we can determine where to go uniquely. If this cell is on the opposite row, then the answer is "NO". Otherwise, go there and proceed further.

Let it have two black cells now. Find the entire two black row rectangle of maximum size that starts there. If there's nothing after it, you can easily traverse it any way you like. Otherwise, you have to traverse it in such a way that you end up in its last column, then go to the right from there. Turns out, there's only one way to achieve that. Go up/down to another row, go right, up/down to another row, right and so on. Now you just have to check if you end up in the correct row.

Thus, you can simulate the path to the left and to the right and check if you never get stuck.

Overall comlexity: O(n) per testcase.

Solution (awoo)1766D - Lucky Chains

Idea: BledDest

Tutorial1766D - Lucky ChainsSuppose, gcd(x+k,y+k)=g. It means that (y+k)−(x+k)=(y−x) is also divisible by g, or gcd(x+k,y−x)=h is divisible by g. And backward: if gcd(x+k,y−x)=h, then (x+k)+(y−x)=(y+k) is also divisible by h, or gcd(x+k,y+k)=g is divisible by h.

Since h is divisible by g and g is divisible by h, so h=g. In other words, we proved that gcd(x+k,y+k)=gcd(x+k,y−x).

Now, knowing the equivalence above, we can understand that we are looking for the smallest k≥0 such that gcd(x+k,y−x)>1. In other words, we are searching k such that x+k is divisible by some d>1, where d is some divisor of (y−x).

The problem is that there are a handful of divisors for some (y−x). But we can note that we can consider only prime divisors of (y−x): if d|(y−x) and d is composite then there is some prime p|d, thus p|(y−x).

It's easy to prove that there are no more than log2n prime divisors of some n. Now the question is how to find all these prime divisors.

Note that if you know only one prime divisor for each value from 1 to n, then you can find all prime divisors for all k≤n in O(logk). The prime divisors pi are next:

p1=minD[k], k1=kminD[k];p2=minD[k1], k2=k1minD[k1];p3=minD[k2], k3=k2minD[k2];and so on until ki>1.The final step is to calculate a prime divisor minD[i] for each value from 1 to A, where A≥max(yi) or A≥107. We can do it by slight modifications of Sieve of Eratosthenes: at the step, where you have some prime p and want to "throw out" all values k⋅p, set minD[kp]=p for each kp (plus set minD[p]=p).

As a result, we, firstly, calculate Sieve in O(NloglogN) and, secondly, calculate answer for each pair (xi,yi) in O(logN).

Note that the input and output is large, so you should you tricks to speed up your input and output.

Solution (adedalic)1766E - Decomposition

Idea: BledDest

Tutorial1766E - DecompositionLet's assume that we don't have any zeroes in our array. We'll deal with them later.

The key observation is that the number of sequences in the decomposition is not more than 3. To prove this, we can use the fact that each element 3 will be appended to the first subsequence in the decomposition; so, if the second/third subsequence in the decomposition ends with the number 2 or 1, all such numbers can be appended to that subsequence, thus they won't create any new subsequences. So, if we consider the combination of the last elements in the subsequences of the decomposition, there are only 33+32+31+30=40 such combinations (even less in practice).

Okay, now let's try to use the fact that the number of such combinations is small. There are many ways to abuse it, but, in my opinion, the most straightforward one (and also a bit slow, but fast enough to easily pass the time limit) is to run the following dynamic programming: dpi,c, where i is the index of the element we are processing, and c is the vector representing the combination of last elements of subsequences in the decomposition.

But it's not clear what do we store in this dynamic programming. The model solution stores the total number of subsequences added to the decomposition, if right now the state of decomposition is c, we process the i-th element, and we consider all possible stopping points (i. e. we will consider the number of subsequences added while processing the elements a[i..i],a[i..i+1],a[i..i+2],…,a[i..n]). So, our dynamic programming automatically sums up the answers for all possible right borders of the segment we decompose. Transitions in this dynamic programming is easy: we need to see how does the element ai alter the state of decomposition c (let it change it to c′), take the value of dpi+1,c′, and if the element ai forms a new subsequence, let's account for it by increasing dpi,c by n−i+1, because this increase will affect n−i+1 different right endpoints of the segment we decompose.

And now it's easy to see how to add zeroes to our solution. We can just assume they don't change the state of decomposition, they simply add a new subsequence which won't take any other elements. So, in our transitions, processing 0 means that c′=c, but the size of decomposition increases.

To actually get the answer to the problem, we need to consider all possible starting points of the segment, so we sum up dpi,o (where o is the empty vector) for all i∈[1,n].

Solution (BledDest)1766F - MCF

Idea: BledDest

Tutorial1766F - MCFThis problem is solved using minimum cost flows (duh).

Suppose all arcs have even capacity. Then we can just divide each arc's capacity by 2 and solve a usual minimum cost flow problem. However, when we have arcs with odd capacity, it's not that simple. We will deal with them as follows: split an arc with capacity 2k+1 into two arcs: one with capacity 2k, the other with capacity 1, and somehow enforce that the second arc must be saturated. We cannot divide all arcs by 2 now, because that would lead to non-integer capacities; instead, we will exclude these arcs with capacity 1 and somehow handle the fact that they must be saturated, and only then divide all capacities by 2.

Okay, how do we handle the edges we deleted? For each vertex, let's check if the number of such arcs connected to it is even. If it is not — the total flow for this vertex cannot be 0, so it's impossible to find the answer (the only case when it might be possible is if this vertex is the source or the sink; in this case, we need to check that both of these vertices have an odd number of arcs we want to delete connected to them, and consider an additional arc 1→n with capacity 1 and weight 0 to make it even).

If for each vertex, the number of odd arcs connected to it is even, let's consider how much excess flow these arcs bring into the vertices. For example, if a vertex has 4 ingoing odd arcs, it has 4 units of flow going into it, which will be lost if we remove the edges we want to ignore. To handle this, add a new source and a new sink to our network (let's call them s and t), and process excess flow going into the vertex using an arc from s to that vertex (in the previous example, we can add an arc from s to the vertex with capacity 2 — not 4 since we divide all capacities by 2). Similarly, excess flow going outside the vertex can be processed with an arc from that vertex to t. We need to make sure that all these edges must be saturated.

Okay, what about actually running the flow from 1 to n? We can do it as in "flow with lower bounds" problem by adding an arc n→1 with infinite capacity... Wait a minute, this may cause a negative cycle to appear! If your implementation of mincost flow handles them, you can use this approach; but if you don't want to mess with negative cycles, instead do the following:

add an arc s→1 and an arc n→t, both with infinite capacities, to make sure that flow can go from 1 to n;since these arcs don't have to be saturated, but other arcs going from s or into t must be saturated, set the costs of these "other" arcs to −109.Okay, that's it — we just need to find the minimum cost flow in the resulting network. The constraints are low enough so any minimum cost flow algorith can pass.

Solution (BledDest)

Educational Codeforces Round 138 Editorial

By awoo, history, 4 months ago, translation, In English1749A - Cowardly Rooks

Idea: BledDest

Tutorial1749A - Cowardly RooksFirst, note that m is always less than or equal to n. If there were at least n+1 rooks on the board, at least two of them would share a row or a column (by pigeonhole principle).

If m<n, then there is always at least one free row and at least one free column. You can move any rook into that row or column.

Otherwise, all rows and columns are taken, so any move will make two rooks share a row or a column, which is prohibited.

Thus, if m=n, then it's "NO". Otherwise, it's "YES".

Overall complexity: O(1) per testcase.

Alternatively, you could check every rook and every possible move.

Overall complexity: O(m2⋅n2) per testcase.

Solution 1 (awoo)Solution 2 (awoo)1749B - Death's Blessing

Idea: BledDest

Tutorial1749B - Death's BlessingNote that whichever order you choose, the total time will always contain all initial health ai, in other words, any answer will contain ∑ni=1ai as its part. So the lower the sum of bi you will add to the answer — the better.

Look at some monster i. If you kill it while it has both left and right neighbor, it will add 2⋅bi to the answer. If it is the first or the last in the row, it will add just bi. And if it is the last monster, it will add 0.

There can be only one last monster, so any other will add at least bi to the answer. And for any chosen last monster l you can find the order that gives exactly bi for all other monsters. For example, you can firstly kill monsters 1,2,…,(l−1), then n,(n−1),…,(l+1) and, finally, moster l.

In other words, if the last monster is the l-th one, the total answer will be equal to ∑ni=1ai+∑ni=1bi−bl. Since we need to minimize answer, we can choose monster with maximum bl.

So, the answer is ∑ni=1ai+∑ni=1bi−maxni=1bi.

Solution (adedalic)1749C - Number Game

Idea: BledDest

Tutorial1749C - Number GameNote that if Bob has increased some element, then Alice can't remove it on the next stages. Obviously, it is more profitable for Bob to "prohibit" the smallest element of the array. Using this fact, we can iterate over the value of k, and then simulate the game process. To simulate the game, we can maintain the set of elements that Alice can remove. On the i-th stage, Alice removes the maximum element x, such that x≤k−i+1, if there are no such elements, then Alice lost. Bob always removes the minimum element of the set.

Thus, the complexity of the solution is O(n2logn) for each test case.

There is another possible solution: we can notice that, if Alice wins, Bob will "prohibit" the elements on positions 1,2,…,k−1 of the sorted array. So, Alice has to delete the next k elements. So, if the segment [k…2k−1] of the sorted array can be deleted by Alice during the game phases, she wins with this value of k.

Solution (Neon)1749D - Counting Arrays

Idea: BledDest

Tutorial1749D - Counting ArraysWe will calculate the answer by subtracting the number of arrays which have only one removal sequence from the total number of arrays. The latter is very simple — it's just m1+m2+⋯+mn.

How do we calculate the number of unambiguous arrays? We can always delete the 1-st element of an array; so, [1,1,1,…,1] is a removal sequence for each array. So, we have to calculate the number of arrays which have no other removal sequences.

How do we check if the array has no removal sequences other than [1,1,…,1]? If, at any time, it's possible to remove some element other than the 1-st from the array, it creates another removal sequence since we can always complete that sequence.

Let's analyze the constraints on each element of the array. a1 can be any integer from 1 to m. a2 should be divisible by 2 (otherwise, we can remove it on the first step). a3 should be divisible by 3 (otherwise, we can remove it on the first step) and by 2 (otherwise, we can remove it on the second step). a4 should be divisible by 2 and 3, but not necessarily by 4 since an element which is divisible by 2 already has a common divisor with 4. And so on — using induction, we can show that the i-th element should be divisible by p1⋅p2⋅p3⋅⋯⋅pk, where p1,p2,…,pk are all of the primes in [1,i]. Obviously, the number of such elements is mp1⋅p2⋅p3⋅⋯⋅pk.

So, we can easily calculate the number of possible elements for each index of the array, and that allows us to count all unambiguous arrays.

Solution (BledDest)1749E - Cactus Wall

Idea: BledDest

Tutorial1749E - Cactus WallIn order to block any path from the top row to the bottom row, you have to build a path from the left side to the right side consisting of '#'. Since two consecutive cacti in a path cannot be placed side by side, they should be placed diagonally (i.e (x,y) should be followed by (x±1,y±1) on the path). So we can rephrase the task as a shortest path problem. The edge weight is 0 if cactus is already in the cell that corresponds to the end of the edge, and 1 otherwise. Don't forget that some cells can't contain a cactus, thus be part of a path, because of the cacti initially placed. The shortest path can be found using Dijkstra's or 0-1 BFS algorithm.

Solution (Neon)1749F - Distance to the Path

Idea: BledDest и adedalic

Tutorial1749F - Distance to the PathFor the purpose of solving the task, let's choose some root in the tree and introduce another operation to the tree: add k to all vertices that are in the subtree of the given vertex v and on the distance d from v. For example, if d=0, it's v itself or if d=1 then it's all children of v.

Let's p[v] be the parent of vertex v, p2[v]=p[p[v]], p3[v]=p[p[p[v]]] and so on (p0[v]=v). So, how to perform this operation? Instead of adding k to all vertices in the subtree, we can add k only to the vertex v. And when we need to get the answer for some vertex u, we will get it from ans[pd[u]].

Of course, since there are different d-s, we'll create different arrays ansd for each possible d. So, the answer for the vertex will be equal to ∑di=0ansi[pi[d]].

Now, let's discuss how to use the introduced operation to perform the given one. We can make the given operation "u v k d" using ours in the following way:

Let's find l=lca(u,v) using any standard algorithm (binary lifting, for example).Let's split all affected vertices in three groups: subtrees of path [v,l) (v inclusive, l exclusive), subtrees of path [u,l) and subtrees of path l,p[l],p2[l],…,pd[l]. Note that in such way all affected vertices belong to at least one group.Let's look at group of path [v,l). The lowest vertices are on distance d from v, the next "level" are on distance d from p[v], the next "level" are on distance d from p2[v] and so on. The last "level" we'll consider in this group is the vertices in the subtree of the child of l on distance d from it. In such a way, all we need to do is add k to all ansd on the path from [v,l).The group of the path [u,l) is handled in the same way.What's left? It's verticesin subtree of l on distances d,(d−1),…,0;in subtree of p[l] on distances (d−1),(d−2),…,0;in subtree of pi[l] on distances (d−i),(d−i−1),…,0;in subtree of pd[l] on distance 0.Note that vertices in subtree of l on distance d−2 are included in vertices in subtree of p[l] on distance d−1. Analogically, vertices on distance d−3 from l are included in vertices on distance d−2 from p[l].Moreover, vertices on distance d−4 from l are included in "d−3 from p[l]" that are included in "d−2 from p2[l]" and so on. In other words, all we need to proccess are vertices:

in subtree of l on distances d and (d−1),in subtree of p[l] on distances (d−1) and (d−2),in subtree of pi[l] on distances (d−i) and (d−i−1).In total, it's at most 2d operations: "add k to some vertex x".As a result, all we need to do is

add k on path from v to some ancestor l of v;add k in some vertex v (can be done as operation 1 on path [v,p[v]));ask value in some vertex v.We can do all of these operations in O(logn) using Fenwick tree (BIT) on tin-s and tout-s (we can get from binary lifting). So the first statement operation will work in O(dlogn) time and the second one — also in O(dlogn).In total, complexity is O(nlogn+mdlogn) time and O(n(logn+d)) space.

P.S.: the second operation can be further optimized to O(d+logn), but it's not really necessary.

Solution (adedalic)

Educational Codeforces Round 137 Editorial

By awoo, history, 5 months ago, translation, In English1743A - Password

Idea: fcspartakm

Tutorial1743A - PasswordThere are two possible solutions for the problem.

The first solution is basically brute force. Each password can be obtained from an integer from 0 to 9999. If the number is from 1000 to 9999, then it's already a password of length 4. Otherwise, you have to prepend it with enough zeros so that it becomes length 4.

Then you have to check if the password is valid. First, check if it consists of exactly two different digits: make a set of all its characters (set<char> in case of C++, for example) and check its size. Then check if the first digit of the password appears exactly twice. It would mean that the other digits appears exactly twice as well. Finally, check if neither of the found digits are forbidden.

The second solution is based on combinatorics. First, choose the two digits that will appear in the password: C(10−n,2). Since n digits are prohibited, the remaining 10−n are allowed. Second, choose the positions that will be taken by the first one: C(4,2). The answer is the product of these two values.

Solution 1 (awoo)Solution 2 (fcspartakm)1743B - Permutation Value

Idea: BledDest

Tutorial1743B - Permutation ValueThe subsegment [1], as well as the whole permutation, will always be a permutation, so the value is at least 2. Let's try to find a way to generate a permutation of n elements with value equal to 2.

Every permutation must contain the number 1. Let's try to construct the answer in such a way that if a subsegment contains the number 1, then it also contains the number n (if it is so, it can only be a permutation if it contains all n numbers). If we begin our permutation with the numbers 1 and n, we will reach our goal: the only subsegment which does not contain n but contains 1 is [1], and the only subsegment which contains n and also a permutation is the whole permutation itself. So, any permutation that begins with [1,n…] can be the answer.

Solution (BledDest)1743C - Save the Magazines

Idea: fcspartakm

Tutorial1743C - Save the MagazinesLet's process the boxes from left to right.

Consider the first box. If it has a lid, then you can just add the number of magazines in it to the answer and forget about this box. To be exact, proceed to solve the problem with the first box removed.

If it doesn't have a lid, then look at the next box. If it doesn't have a lid too, then this box can never be covered. Remove it and proceed further.

If the next box has a lid, then look at the next one. Again, if it doesn't have a lid, then these two first boxes are solved independently of everything else. You can cover exactly one of them. Choose the bigger one and remove them both.

To propagate the argument, let's derive a pattern. First, there's a box without a lid. Then some number of boxes with lids in a row. Then a box without a lid again. Among the first box and the box with lids, you can choose exactly one to not be covered. However, that can be any one of them. The best box to be left uncovered is the one with the smallest number of magazines in it.

Thus, the solution is the following. As long as the first box has a lid, keep removing the first box and adding it to the answer. Then, as long as there are boxes left, take the first box and the largest number of consecutive boxes with lids after it (that number might be zero). On that segment, find the minimum value and the sum. Add the sum minus the minimum to the answer, remove the entire segment.

The removals can be done explicitly with a queue or just a reversed vector or implicitly with maintaining a pointer to the first non-removed box.

Overall complexity: O(n).

Solution (awoo)1743D - Problem with Random Tests

Idea: BledDest

Tutorial1743D - Problem with Random TestsThe first observation we need is that we can choose two prefixes of s as the substrings used in forming the results. This can be proved easily: suppose we chose a substring which does not contain the leftmost character of s; if we expand it to the left, the answer won't become worse. So, it is optimal to choose two prefixes of s as the substrings.

Furthermore, one of these prefixes must be s itself: if the leftmost index of 1 is i, the length of the answer won't exceed n−i+1, but the only way to have a 1 in the (n−i+1)-th bit of the answer is to choose a prefix of s where the (n−i+1)-th character (from the right) is 1; and there is only one such prefix of s, which is s itself.

So, now we can solve the problem in O(n2) — try to combine all prefixes of s with s itself, and choose the one that yields the best answer. To speed this up, we need to somehow cut down on the number of prefixes of s we check.

Let's look at the first block of 1's in s. The next character after this block is 0; since we take s as one of the substring, in order to get 1 instead of 0 in the corresponding position of the answer, we need to choose a prefix which has 1 in that position. This 1 represents one of the 1's from the first block of 1's, since only one of them can shift to that position. So, we need to check only the prefixes such that, by using them, we shift some character 1 from the first block to the position of the first 0 after this block. Since the tests are random, the expected length of the first block of 1's is O(1) (furthermore, even the probabiliy that its length is 20 or bigger is about 10−6), so the expected number of prefixes we need to check is also O(1). Thus, the expected runtime of our solution is O(n).

Solution (BledDest)1743E - FTL

Idea: BledDest

Tutorial1743E - FTLAt any time, we have three possible choices: wait and shoot the first laser, the second laser and both lasers. Sometimes it makes sense to wait to both because you can deal s more damage than you would do by shooting both lasers separately.

The first claim: greedy won't work. Maybe there is a sufficiently smart greedy, we weren't able to come up with it. The second claim: bruteforce won't work. The funny thing is that it actually worked on the constraints up to 2000, but again, we couldn't code any sufficiently fast one for 5000.

Thus, let's try some dynamic programming. Since all the times are huge, we'd want to avoid having them as the states. What is small, however, is the durability of the enemy ship and the number of shots we have to make to destroy it.

Ideally, we'd like to have some dp[i] — the smallest time to deal i damage to the enemy ship. This way, dp[n] would be the answer. Sadly, it's not immediately clear how to get rid of reload times completely. There might be states with different times until the charge with the same damage dealt, and we don't know which of those we want to keep.

Thus, let's make the dp state more complicated. Let dp[i] be the smallest time it takes to deal i damage if the last shot was from both lasers at the same time. This way we know the reload times of both lasers — they are full t1 and t2.

dp[0]=0, as moment 0 has both lasers zero charged as if after a shot.

What are the transitions? Well, now we have to shoot each laser multiple times, then wait until both are charged and shoot both. Both lasers can now be considered independent of each other.

Let the time between the previous double shot and the next one be some value t. During this time, it never made sense to wait until shooting each laser. So we waited t1, shot the first laser, waited another t1, shot again, until we couldn't shoot anymore, since the laser wouldn't recharge in time before the double shot. Same for the second laser. Notice that if both tmodt1≠0 and tmodt2≠0, then you could just decrease t by 1 and shoot each laser the same number of times. Thus, only t that are multiples of either t1 or t2 are optimal.

Thus, we can iterate over all possible waiting times t. Just iterate over i⋅t1 and i⋅t2 for all i from 1 to h. Having a fixed t, calculate the number of shots of each laser, calculate the damage, go into the corresponding dp state.

It could also happen that the last shot before destroying the ship wasn't a double one. However, it still follows the same ideas. It means that each laser was shooting non-stop until the ship was destroyed. Thus, the destruction time is still a multiple of either of the reload times.

Overall complexity: O(h2).

Solution (awoo)1743F - Intersection and Union

Idea: BledDest

Tutorial1743F - Intersection and UnionWe will use the Contribution to the Sum technique to solve this problem: for every integer from 0 to 300000, let's calculate the number of ways to choose the operators so it belongs to the result, and add all of the results.

For a fixed integer x, the number of ways to choose the operators so that x belongs to the result can be done as follows: let dpi,f be the number of ways to choose the first i operators so that, after applying them, the resulting set contains x if f=1, and does not contain x if f=0. The transitions from dpi to dpi+1 depend on whether the number x belongs to the segment i+1.

Obviously, this is too slow if we compute the dynamic programming from scratch for every integer x. Instead, we can notice that the transitions from dpi to dpi+1 are linear combinations: both dpi+1,0 and dpi+1,1 are linear combinations of dpi,0 and dpi,1 with coefficients depending on whether the element x belongs to the set or not. So, transitioning from dpi to dpi+1 can be written in terms of multiplying by a 2×2 matrix.

Let's build a segment tree where each vertex stores a transition matrix, and operations are "calculate the product of matrices on a segment" and "replace a matrix at some index". We can build a sequence of these transition matrices for x=0 and store them in the segment tree; for x=1, this sequence of transition matrices will change only in positions j such that either 0 belongs to [lj,rj] and 1 does not belong to it, or vice versa. So, we can go from x=0 to x=1 by replacing these transition matrices in the segment tree. For x=2, the only changes from x=0 are in positions j such that either 1 belongs to [lj,rj] and 2 does not belong to it, or vice versa — and we can replace the matrices in these positions as well. In total, there will be only O(n) such replacements; so, we solve the problem in O(M+nlogM), where M is the constraint on the numbers belonging to the sets.

Solution (BledDest)1743G - Antifibonacci Cut

Idea: BledDest

Tutorial1743G - Antifibonacci CutThe first idea that comes to mind is running some sort of dynamic programming: dpi — the number of ways to cut the string consisting of the first i characters. When we calculate dpi, we need to take the sum of the previous values of dp, and then subtract dpj for every j such that the string from the j-th character (inclusive) to the i-th character (non-inclusive) is a Fibonacci string. Unfortunately, there are two main issues with this solution: firstly, we cannot store the array dp in memory; and secondly, we have to search for the Fibonacci strings ending in a certain index quickly (something like Aho-Corasick could work with a less strict memory limit, but right now we cannot use it).

We will try to resolve both of these issues with the following approach: while we process the characters, we will maintain the list of tuples (j,dpj) such that the string from the j-th character to the current one is a prefix of some Fibonacci string. How do we maintain them?

Every Fibonacci string fi (except for f0) is a prefix of fi+1. So, all Fibonacci strings we are interested in (except for f0 again) are prefixes of the same long Fibonacci string. Suppose a tuple (j,dpj) represents some index j such that the string from the j-th character to the current one is a prefix of that long Fibonacci string. Each time we append a character, we filter this list of tuples by trying to check if this new character matches the next character in the prefix (if it does not, the tuple is discarded). For the tuples that represent the prefixes equal to Fibonacci strings, we need to subtract the value of dpj from the new dp value we are trying to calculate (checking if a prefix is a Fibonacci string is easy, we just need to check its length). How do we check that if we add a character 1 or 0, it is still a prefix? There are two ways to do this:

either generate the first 3⋅106 characters of the long Fibonacci string;or represent the current prefix as the sum of Fibonacci strings fi1+fi2+⋯+fik such that for every j∈[1,k−1], the condition fij>fij+1+1 holds (i. e. the Fibonacci strings we split the current prefix into are arranged in descending order, and there is no pair of equal or adjacent (by index) Fibonacci strings in the split). This representation is very similar to writing an integer in Zeckendorf system. The next character in the prefix depends on whether f1 belongs to this split: if it belongs, it is the last string in the split, so we need to append 0 to transform f1 into f2; otherwise, we need to append 1.Okay, so now we can solve the problem in O(NM) time (where N is the total length of the strings in the input, and M is the size of the list of tuples (j,dpj) we discussed earlier). This actually works since it looks like the size of the list of tuples is bounded as O(logN). Unfortunately, we don't have a strict mathematical proof of this; we checked this by brute force with N up to 3⋅106, so it definitely works under the constraints of the problem.

Solution (BledDest)

Educational Codeforces Round 136 Editorial

By awoo, history, 5 months ago, translation, In English1739A - Immobile Knight

Idea: BledDest

Tutorial1739A - Immobile KnightLet's consider some cases.

If at least one of n or m are 1, then all cells are isolated. A knight can't move one in a perpendicular direction.

If at least one of n or m are at least 4, then the knight always has at least one move. No matter where you place it, it can move two cells along the greater of the dimensions and move one in a perpendicular direction, because it's at least 2.

Three cases are left. (2,2), (2,3) and (3,3). For all of these cases, the middle cell is isolated. That cell is (⌊n2⌋+1,⌊m2⌋+1).

Since it doesn't matter which cell you print in the first two cases, you can always print (⌊n2⌋+1,⌊m2⌋+1).

Overall complexity: O(1) per testcase.

Alternatively, you can check every possible cell. Iterate over a cell and check all eight possible knight moves from it. If none are inside the board, the cell is isolated.

Overall complexity: O(nm) per testcase.

Solution 1 (awoo)Solution 2 (awoo)1739B - Array Recovery

Idea: BledDest

Tutorial1739B - Array RecoveryNote that ai=ai−1+di or ai=ai−1−di. Since there is no upper bound for the values of ai, the case where ai=ai−1+di for all i always exists. It remains to check if there are other ways. To do this, it is enough to check whether there is such a position pos that:

pos>1;dpos≠0;the change apos=apos−1+dpos to apos=apos−1−dpos doesn't result in a negative value of apos.The reason for dpos≠0 is that for dpos=0 no matter the plus or minus we choose, the array a doesn't change. If you could change at least one sign to minus, that would be another answer.

Solution (Neon)1739C - Card Game

Idea: BledDest

Tutorial1739C - Card GameThe example tests suggest that there is only one possible distribution with a draw. Let's find out why it is so. We will use a process similar to induction/recursion to distribute the cards between the two players so that the game ends in a draw:

suppose Alex receives the card n. Then he wins since he can play it immediately. So, for the game to result in a draw, Boris must receive the card n.suppose Boris receives the card n−1. Then he wins since he also has the card n, he can use it to answer any first move of Alex, and then win the game by playing n−1. So, for the game to result in a draw, Alex must receive the card n−1.suppose Boris receives the card n−2. Then he wins since he also has the card n: if Alex plays the card n−1, Boris responds with n and then plays n−2; if Alex plays some other card, Boris responds with n−2 and the plays n. So, for the game to result in a draw, Alex must receive the card n−2.and so on.In fact, if Alex receives the card n−1 and Boris receives the card n, Alex must play the card n−1 or something equivalent to it on the first move, and Boris must respond with the card n, so we can consider the game without these two cards with the roles swapped.

So, if we consider the distribution of cards as a string with characters A and B, where A denotes the card belonging to Alex, and B denotes the card belonging to Boris, and the i-th character of the string represents the card n−i+1, the only possible distribution for the draw is BAABBAAB... But there's more to this string representation of the distribution of cards: the first character that is different from this pattern denotes the winner; if the first different character is A in the draw distribution and B in the distribution we consider, the winner is Boris; otherwise, the winner is Alex.

This may lead us to the following ways to count the number of possible distributions which win/lose for Alex:

we can use dynamic programming of the form dpx,y,t, where x is the number of characters A we used, y is the number of characters B we used, and t is 0, 1 or 2 depending on whether our string coincides with the draw string (t=0), differs from it in a way that Alex wins (t=1), or differs from it in a way that Boris wins (t=2); the actual value of dpx,y,t must be the number of ways to reach this state of dynamic programming. The answer then is stored in the states of the form dpn2,n2,t.or we can use combinatorics: let's iterate on the length of the prefix that is common in the draw string and in the string representing the distribution of cards, and then count the number of ways to distribute the remaining characters with a binomial coefficient. To calculate the binomial coefficients, we can use one of the following methods: Pascal's triangle, precalculating factorials and modular inverses to then, or calculating factorials with big integers in Java or Python.Solution 1 (BledDest)Solution 2 (BledDest)1739D - Reset K Edges

Idea: BledDest

Tutorial1739D - Reset K EdgesStart with the following. Let's look at the input format and consider what the operation actually does to it. Since it only changes the parent of some vertex, it modifies only one value in it. Moreover, it just assigns it to 1. Thus, the goal is to assign at most k values of parents to 1 to minimize the resulting height of the tree.

In particular, that implies that we can freely rearrange the operations, since the assignments don't depend on each other.

One more conclusion. Imagine we have already built some answer. One by one, we moved some subtrees to be children of the root. It could happen that we first moved some subtree of a vertex u and then applied the operation to an edge inside the subtree of u. Let's show that it's always possible to rearrange the operations in the answer to avoid that. Just apply the operations in order of decreasing the depth of the vertex u.

If we knew what height h we want to get, we could have been making sure that cut subtree u has height at most h−1 (since it gets increased by 1 when glueing it to the root), then pretending that that subtree doesn't exist anymore.

Moreover, it's always required to cut subtrees with height at most h−1. If you cut a higher subtree, then the answer can't be smaller than h+1, since we rearranged the operation to not touch that subtree anymore.

Well, let's fix that height h if we wanted that. Let's try the solve the opposite problem. How many operations will it require to make the tree height at most h? Obviously, the values for this problem are non-increasing — the greater we allow the height to be, the less operations it will require. Thus, we will be able to apply binary search to it to find the smallest height we can achieve with at most k operations.

Now we want to be choosing the subtrees of height at most h−1 repeatedly and cutting them off until the height of the tree becomes at most h.

Let's think greedily. If the height of the tree is not at most h yet, then there exists a vertex with the depth greater than h. Let's look at the deepest of them. That leaf has to be cut in some subtree. Otherwise, the tree won't become any less higher. What subtree is the best for it? What options do we have? That vertex itself and all its parents up until h−1 above. It's always optimal to cut the highest of them — the (h−1)-st parent, since it will remove at least all the vertices of any other cut and some other vertices along with them. It's also always possible to remove the (h−1)-st parent, since it will always have height exactly h−1. The vertex we are looking at is the deepest in the entire tree — there are no deeper vertices in the subtree of the (h−1)-st parent.

Thus, the strategy is to keep cutting the (h−1)-st parent of the deepest vertex until the tree becomes at most h height.

Now about the implementation details.

First, we can process the vertices from the deepest upwards in their order in the original tree. The operation only removes some vertices but doesn't change the depth of the remaining ones. For example, you can do a bfs from the root to find the order.

Now the (h−1)-st parent. Let's find it for each vertex before starting the process. Run a dfs and maintain the stack of the ascendants. When going down the child, append it to the stack. What exiting, pop from the stack. Now you can just look at the (h−1)-st element from the top of the stack. To be able to do that, simulate the stack with a vector (C++) or a list (Python).

Finally, we would have to determine if the current vertex in the order is removed or not. For that, we could maintain a boolean array used for the removed vertices. Once you apply the operation, run the dfs from the removed vertex and mark all the newly removed descendants of it in used. If you don't go into already marked vertices, there will be no more than n calls of the dfs.

The number of cut vertices is the answer for the fixed height h.

Overall complexity: O(nlogn) per testcase.

Solution (awoo)1739E - Cleaning Robot

Idea: BledDest

Tutorial1739E - Cleaning RobotWhy did the author choose the width of the hallway to be only 2? Well, in that case you can show that the robot will never move to the left while cleaning. That is not true on width 3 already.

When does the robot break? Let the robot currently be in the cell (j,i) (0-indexed) and the next column with a dirty cell be nxti (possibly, nxti=i). The robot breaks only if both (1−j,nxti) and (j,nxti) are dirty.

That helps us to do a dynamic programming solution. Since we can only care about O(1) next columns, we would want to have some dp[i][j] — the largest number of dirty cells we can leave to the robot if we processed the first i columns of the hallway and are currently standing in the j-th row of the i-th column. Maybe with some additional states of the current or the next columns.

We want the dp to maintain the invariant that everything to the left of the i-th column is cleaned in such a way the robot can reach the cell (j,i). We can choose when to fix the i-th column: either maintain it being correct prior to entering the state or handling it in the transition to the next one. I chose the former option. There probably exists a million different dps that work, I'll describe the one I did.

Let dp[i][j][f] be the largest number of dirty cells that we can leave to the robot if:

we fixed which of the dirty cells in the first i columns, inclusive, are cleaned by hand;the robot reaches the cell (j,i) from the left;f is true if the cell in the opposite row of the i-th column is dirty.The transitions handle what to do with the dirty cells in the (i+1)-st column and where the robot goes based on that.

In particular, there are the following transitions:

if f is true, then we have to clean the cell (j,i+1), and the robot will move into (1−j,i+1) — otherwise the robot breaks from having two options;if f is false, then let's say that the robot doesn't break immediately but moves into the next column in a unique way: it moves horizontally first, then possibly vertically;we can leave the next column as is, and the robot will move into (j,i+1) if the cell (1−j,i+1) is clean, or (1−j,i+1) if it's dirty;if f is false, then we can clean the cell (1−j,i+1), and the robot will move into (j,i+1).Since we maintained the invariant that the i-th column is valid, we can update the answer from all four states in the last column.

Overall complexity: O(n).

Solution (awoo)1739F - Keyboard Design

Idea: BledDest

Tutorial1739F - Keyboard DesignFor each word, let's consider a graph on 12 vertices where the i-th and the j-th vertices are connected by an edge iff the i-th character of the alphabet is adjacent to the j-th character of the alphabet in this string. Obviously, this graph is connected (except for the isolated vertices). If there is a vertex of degree 3 or more in this graph, or if there is a cycle in this graph, it is impossible to design a keyboard to type the word easily: in the first case, the letter represented by that vertex must have at least three neighbors on the keyboard, but can have only at most two; in the second case, the keyboard must be cyclic (and it is not). So, the word can be typed easily only if the graph representing it consists of one path and several isolated vertices.

Let's write the letters along the path we constructed for the word in a single string. For example, for the word abacabacd, we get edges ab, ac and cd in the graph, so the letters along the path are either dcab or bacd (and, obviously, one can be obtained from the other by reversing the string). Let f(s) and f′(s) be the two strings we obtain from the word s using this method. Now, we claim that the word s can be typed easily if and only if one of these two strings (f(s) and f′(s)) is a substring of the keyboard — this would mean that every pair of letters that should be on adjacent positions are actually on adjacent positions.

Okay, now we construct f(si) and f′(si) for each word, and our goal is to find the permutation of the first 12 characters of Latin alphabet such that the sum of ci over all words having either f(si) or f′(si) as a substring is the maximum possible. There are two key observations that allow us to solve this problem:

f(si) and f′(si) cannot be the substrings of the same keyboard (the proof is simple: if f(si) is a substring, its first character must be before its second character; and if f′(si) is a substring, its second-to-last character (which is the second character of f(si)) must be before its last character (which is the first character of f(si));neither f(si) nor f′(si) can appear in the keyboard twice (it's obvious since the keyboard is a permutation).So, we can reformulate the problem as follows: let ci be the cost of the string f(si) and the cost of the string f′(si) as well; find the permutation of the first 12 characters of the Latin alphabet so that its cost (which is the sum of costs of its substrings) is the maximum possible. To solve this problem, we can store the strings in an Aho-Corasick automaton, and for every state of the automaton, precalculate the total cost of all string ending in this state (that is, the cost of this state and all states reachable from it via the suffix links). Then run a dynamic programming of the form dpmask,v — the maximum possible cost of a partial keyboard if we used a mask of characters and the Aho-Corasick automaton is currently in the state v. This dynamic programming runs in O(2K⋅K⋅A), where K is the size of the alphabet (12), and A is the size of the automaton (up to 4000).

Solution (BledDest)

Educational Codeforces Round 135 Editorial

By awoo, history, 6 months ago, translation, In English1728A - Colored Balls: Revisited

Idea: BledDest

Tutorial1728A - Colored Balls: RevisitedLet's prove that the color with the maximum value of cnt is one of the possible answers.

Let the color x have the maximum value of cnt; if there are several such colors, choose any of them. Let's keep taking the balls of two different colors out of the bag without touching the balls of color x for as long as possible.

After such operations, two cases exist. In one case, only balls of color x are left — then everything is fine. In other case, there are balls of color x and some color y (let cnty be the remaining number of balls of this color). Since initially cntx was one of the maximums, cnty≤cntx. However, the number of remaining balls is odd, which means cnty≠cntx and cnty<cntx. Therefore, we can keep taking the balls of colors y and x until only balls of color x are left.

Solution (Neon)1728B - Best Permutation

Idea: BledDest

Tutorial1728B - Best PermutationLet xi be the value of the variable x after i steps. Note that xn−1 should be less than pn for xn to be not equal to 0. It means that xn does not exceed 2pn−1. It turns out that for n≥4 there is always a permutation such that xn is equal to 2n−1.

The only thing left is to find out how to build such a permutation. There are many suitable permutations, let's consider one of the possible options. For an even n, a suitable permutation is [2,1,4,3, dots,n−2,n−3,n−1,n]. You can see that x in such a permutation changes as follows: [0,2,0,4,0,…,n−2,0,n−1,2n−1]. For an odd n, there is a similar permutation [1,3,2,5,4,…,n−2,n−3,n−1,n], where x changes as follows: [0,1,4,0,5,0,…,n−2,0,n−1,2n−1].

Solution (Neon)1728C - Digital Logarithm

Idea: BledDest

Tutorial1728C - Digital LogarithmFirst, why can you always make the arrays similar? Applying a digital logarithm to any number will eventually make it equal to 1. Thus, you can at least make all numbers into 1s in both arrays.

Then notice the most improtant thing — applying the digital logarithm to a number greater than 1 always makes this number smaller.

Thus, if a number appears in only one of the arrays, you will have to do one of the followings two things:

decrease some greater number to make it equal to this one;decrease this number.What if there is no greater number at all? This is the case for the largest number in both arrays altogether. If it appears in only one of the arrays, you must always decrease. If it appears in both, though, why decrease it further? Worst case, you will decrease it in one array, then you'll have to decrease it in the other array as well. This is never more optimal than just matching one occurrence in both arrays to each other and removing them from the arrays.

So, the proposed solution is the following. Consider the largest element in each array. If they are equal, remove both. If not, apply digital logarithm to the larger of them. Continue until the arrays are empty.

What's the estimated complexity of this algorithm? Each number in the first array will be considered at most the number of times you can decrease it with a digital logarithm operation plus one. That is at most 2+1 — a number greater than 9 always becomes a single digit and a single digit always becomes 1. Same goes for the second array. So the complexity is basically linear.

To implement it efficiently, you will have to use some data structure that provides three operations:

peek at the maximum;remove the maximum;insert a new element.The perfect one is a heap — priority_queue in C++.

Overall complexity: O(nlogn) per testcase.

Solution (awoo)1728D - Letter Picking

Idea: BledDest

Tutorial1728D - Letter PickingWhat do we do, when the array loses elements only from the left or from the right and the constraints obviously imply some quadratic solution? Well, apply dynamic programming, of course.

The classic dp[l][r] — what is the outcome if only the letters from positions l to r (non-inclusive) are left. dp[0][n] is the answer. dp[i][i] is the base case — the draw (both strings are empty). Let −1 mean that Alice wins, 0 be a draw and 1 mean that Bob wins.

How to recalculate it? Let's consider a move of both players at the same time. From some state [l;r), first, Alice goes, then Bob. The new state becomes [l′,r′), Alice picked some letter c, Bob picked some letter d. What's that pick exactly? So, they both got a letter, prepended it to their own string. Then continued the game on a smaller string s and prepended even more letters to the string. Thus, if we want to calculate [l,r) from [l′,r′), we say that we append letters c and d. Now it's easy. If dp[l′][r′] is not a draw, then the new letters change nothing — the result is still the same. Otherwise, the result of the game is the same as the comparison of letters c and d.

How to perform both moves at once? First, we iterate over the Alice's move: whether she picks from l or from r. After that we iterate over the Bob's move: whether he picks from l or from r. Since we want dp[l][r] to be the best outcome for Alice, we do the following. For any Alice move, we choose the worse of the Bob moves — the maximum of dp[l′][r′]. Among the Alice's moves we choose the better one — the minimum one.

Overall complexity: O(n2) per testcase.

Solution (awoo)1728E - Red-Black Pepper

Idea: BledDest

Tutorial1728E - Red-Black PepperLet's start by learning how to answer a query (1,1) — all red pepper and black pepper options are available.

Let's iterate over all options to put the peppers and choose the maximum of them. First, let's use the red pepper for all dishes. Now we want to select some k of them to use black pepper instead of red pepper. Which ones do we choose? When we switch from the red pepper to the black pepper, the total tastiness changes by −ai+bi for the i-th dish. They are completely independent of each other, so we want to choose k largest of these values.

Let d1,d2,…,dn be the sequence of values of −ai+bi in a non-increasing order.

Thus, k black peppers will yield the result of ∑i=1nai+∑i=1kdi. We can answer a query (1,1) by looking for a maximum in the sequence.

Now consider an arbitrary query. Let p1,p2,…,pt be all options for the amount of available black peppers for the query. Naively, we could iterate over all of them and choose the maximum one.

However, notice an interesting thing about the sequence of the answers. By definition, it is non-strictly convex. In particular, one idea that can be extracted from this is the following. Find the position of an arbitrary maximum in this sequence. Then everything to the left of is is non-increasing. Everything to the right of it is non-increasing.

Thus, for a query, it's enough to consider only two options: the one closest to the maximum from the left and from the right.

Now we only have to learn how to get these options fast enough. For a query (x,y) we want to solve what's called a diophantine equation ax+by=n. An arbitrary solution can be obtained by using extended Euclid algorithm. Let it be some (a,b). Then we would want to check the answer for ax black peppers. The amount of solutions to the equation is either infinite or zero. If it's infinite, all solutions will be of the form ax+k⋅lcm(x,y) for any integer k. Remember that not all the solutions will be in a range [0,n].

Finally, find the two solutions that are the closest to the maximum, check that they are in the range [0,n] and print the best answer of them.

Overall complexity: O(nlogn+qlogX).

Solution (awoo)1728F - Fishermen

Idea: BledDest

Tutorial1728F - FishermenSuppose we have fixed some order of fishermen and calculated the values of bi. Then, we have the following constraints on bi:

all values of bi are pairwise distinct;for every i, ai divides bi.Not every possible array b meeting these constraints can be achieved with some order of fishermen, but we can show that if we choose an array b with the minimum possible sum among the arrays meeting these two constraints, there exists an ordering of fishermen which yields this array b. The proof is simple — suppose the ordering of fishermen is the following one: the first fisherman is the one with minimum bi, the second one — the one with the second minimum bi, and so on. It's obvious that if we generate the values of b according to this order, they won't be greater than the values in the array we have chosen. And if some value is less than the value in the chosen array b, it means that we haven't chosen the array with the minimum possible sum. So, we can rephrase the problem as the following one: for each ai, choose the value of bi so that it is divisible by ai, all bi are distinct, and their sum is minimized.

Using the pigeonhole principle, we can show that for every ai, we need to consider only the values of bi among [ai,2⋅ai,3⋅ai,…,n⋅ai]. So, we can formulate the problem as an instance of the weighted bipartite matching: build a graph with two parts, where the left part contains n nodes representing the values of ai, the right part represents the values of the form k⋅ai where 1≤k≤n, and there exists an edge between a vertex in the left part representing the number x and a vertex in the right part representing the number y with cost y if and only if y=k⋅x for some integer k∈[1,n]. Note that we don't add the edge if k>n because we need to ensure that the size of the graph is O(n2).

Okay, now we need to solve this weighted matching problem, but how? The number of vertices is O(n2), and the number of edges is O(n2) as well, so mincost flow will run in O(n4) or O(n3logn), which is too much. Instead, we can notice that the cost of the edges incident to the same vertex in the right part is the same, so we can swap the parts of the graph, sort the vertices of the new left part (representing the numbers k⋅ai) according to their costs, and run the classical Kuhn's algorithm in sorted order. Kuhn's algorithm in its original implementation will always match a vertex if it is possible, so it obtains the minimum total cost for the matching if we do it in sorted order.

But this is still O(n4)! What should we do? Well, there are some implementations of Kuhn's algorithm which can run on graphs of size about 105 (sometimes even 106). Why can't we use one of these? Unfortunately, not all optimizations that can be used in Kuhn's algorithm go together well with the fact that the vertices of the left part have their weights. For example, greedy initialization of matching won't work. So we need to choose optimizations carefully.

The model solution uses the following optimization of Kuhn's algorithm: if you haven't found an augmenting path, don't reset the values representing which vertices were visited by the algorithm. With this optimization, Kuhn's algorithm works in O(M(E+V)), where M is the size of the maximum matching, E is the number of edges, and V is the number of vertices. So, this results in a solution with complexity of O(n3).

I think it's possible to show that some other optimizations of Kuhn can also work, but the one I described is enough.

Solution (BledDest)1728G - Illumination

Idea: BledDest

Tutorial1728G - IlluminationLet's start without the queries. How to calculate the number of ways for the given n lanterns?

First, it's much easier to calculate the number of bad ways — some point of interest is not illuminated. If at least one point of interest is not illuminated, then all lanterns have power lower than the distance from them to this point of interest. More importantly, it's less than d. Thus, the number of good ways is (d+1)n minus the number of bad ways.

Let's use inclusion-exclusion. For a mask of non-illuminated points of interest, let's calculate the number of ways to assign the powers to the lanterns in such a way that at least these points of interest are not illuminated. All other points can be either illuminated or not. Let's call it ways[mask]. With the values for all masks, the answer is the sum of ways[mask]⋅(−1)popcount(mask) over all masks.

How to calculate the value for the mask? First, let's do it in O(nm) for each mask. Each lantern can have any power from 0 to the distance to the closest point of interest inside the mask non-inclusive. Thus, we can iterate over the lanterns and find the closest point to each of them, then multiply the number of ways for all lanterns.

Let's calculate it the other way around. Initialize the answers for the masks with 1. Then iterate over the lantern and the point of interest that will be the closest non-illuminated one to this lantern. Let the distance between them be some value d. Which masks will this pair affect? Let the lantern be to the right of that point of interest. The opposite can be handled similarly.

All points to the left of the chosen point can be in either state. All points between the chosen one and the lantern must be illuminated. All points to the right of the lantern and with distance smaller than d must also be illumunated. All point to the right of these can be in either state. Thus, the masks look like "**..**1000..000**..**", where 1 denotes the chosen non-illuminated point.

All masks that correspond to this template will be multiplied by d. You have to be careful when there are two points of interest with the same distance d to some lantern — one to the left of it and one to the right of it. In particular, in one case, you should force illumination on all points with distance <d. In another case, you should force illumination on all points with distance ≤d.

How to multiply fast enough? We'll use a technique called sum-over-subsets. Let's express the template in terms of submasks. For a template "***100000***", all submasks of "111100000111" will be multiplied by d. However, we accidentally multiplied masks of form "***000000***" too. Let's cancel them by dividing the submasks of "111000000111" by d. Record all multiplications for all pairs, them force push them into submasks with sum-over-subsets (well, product-over-subsets in this case :)).

Now we have the values of ways[mask] for all masks in basically O(nm+2m⋅m), give or take the time to find the points that must be forced illuminated (extra O(logm) from lower_bound or two pointers, which is not really faster).

Now for the queries. How does the answer change after an extra lantern is added? Again, let's iterate over the closest point of interest and find the mask template. All masks corresponding to this template will get multiplied by d. Thus, the answer will change by the sum of values of these masks, multiplied by d, including the inclusion-exclusion coefficient. How to handle that? Well, yet another sum-over-subsets. Just collect the sum of values over the submasks beforehand and use these during the query. That gives us an O(m) per query.

Overall complexity: O(nm+qm+2m⋅m).

Solution (awoo)

Educational Codeforces Round 134 Editorial

By awoo, history, 6 months ago, translation, In English1721A - Image

Idea: BledDest

Tutorial1721A - ImageThere are some solutions based on case analysis, but in my opinion, the most elegant one is the following:

Let's pick a color with the maximum possible number of pixels and repaint all other pixels into it. We will try to pick all pixels of some other color and repaint them in one operation, and we can ignore the constraint that we can repaint no more than 2 pixels, since we will never need to repaint 3 or 4 pixels in one operation. So, the number of operations is just the number of colors other than the one we chosen, or just d−1, where d is the number of different colors in the image. To calculate this, we can use a set or an array of size 26, where we mark which colors are present.

Solution (BledDest)1721B - Deadly Laser

Idea: BledDest

Tutorial1721B - Deadly LaserFirst, let's determine if it's possible to reach the end at all. If the laser's field doesn't span until any wall, then it's surely possible — just stick to the wall yourself.

If it touches at most one wall, it's still possible. If it's the bottom wall or the left wall, then take the path close to the top and the right wall. Vice versa, if it's the top wall or the right wall, then take the path close to the bottom and the left wall.

What if both of these paths are locked? That means that the laser touches at least two walls at the same time: the top one and the left one, or the bottom one and the right one. Turns out, it's completely impossible to reach the end in either of these two cases. Just draw a picture and see for yourself.

Thus, we can always take at least one of the path sticking to the walls. The distance from the start to the end is |n−1|+|m−1|, and both of these paths are exactly this long. So the answer is always either -1 or n+m−2.

To check if the laser touches a wall with its field, you can either use a formula or check every cell adjacent to a wall.

Overall complexity: O(1) or O(n+m) per testcase.

Solution (awoo)1721C - Min-Max Array Transformation

Idea: BledDest

Tutorial1721C - Min-Max Array TransformationFor the start, let's note that ai≤bi for each i. Otherwise, there is no way to get b from a.

Firstly, let's calculate dmini for each i. Since all di≥0 then bj is always greater or equal than ai you get it from. So, the minimum di would come from lowest bj that still ≥ai. Since b is sorted, we can find such bj with lower_bound in O(logn).

Let's prove that we can build such d that transforms ai to bj we found earlier. Let's just make dk=bk−ak for k∈[1..j)∪(i..n]; dk=bk+1−ak for k∈[j..i) and di=bj−ai. It's easy to see that all di are non-negative, so such d is valid.

Now, let's calculate dmaxi. Suppose, we transform ai to bj for some j≥i. It's not hard to prove that the "proving" array d may be constructed in the similar way: dk=bk−ak for k∈[1..i)∪(j..n]; dk=bk−1−ak for k∈(i..j] and di=bj−ai.

In order to build such array d, you need bk−1≥ak for each i∈(i..j]. In other words, if there is some position l such that l>i and bl−1<al you can't choose j such that j≥l. It means that we can iterate i in descending order and just keep track of leftmost l≥i with bl−1<al. Then, dmaxi is equal to b[l−1]−a[i] (or b[n]−a[i] if there are no such l).

The resulting complexity is O(nlogn) because of the first part. But it can be optimized to O(n) if we use two pointers instead of lower_bound.

Solution (adedalic)1721D - Maximum AND

Idea: BledDest

Tutorial1721D - Maximum ANDWe will build the answer greedily, from the highest significant bit to the lowest one. Let's analyze how to check if the answer can have the highest bit equal to 1. It means that every value in c should have its highest bit equal to 1, so for every i, exactly one of the numbers {ai,bi} should have this bit equal to 1. For both of the given arrays, we can calculate how many elements have which value of this bit, and then the number of elements with 1 in this bit in the array a should be equal to the number of elements with 0 in the array b (and the same for elements with 0 in a and elements with 1 in b). If these values are equal, it means that the elements of a and b can be matched in such a way that in every pair, the XOR of them has 1 in this bit. If it is so, then the highest bit of the answer is 1, otherwise it is 0.

Okay, then let's proceed to the next bit. Should we just do the same to check if this bit can be equal to 1 in the answer? Unfortunately, that's not enough. Let's look at the case: a=[3,0], b=[2,1]. We can get the value 1 in the 0-th bit or in the 1-st bit, but not in both simultaneously. So, for the next bit, we need to make sure that not only we can get 1 in the result, but we can also do this without transforming some of the 1-s to 0-s in the higher bits. If it is impossible, it doesn't matter if we can get 1 in the current bit since it will be suboptimal, so we have to use an ordering that gets 0 in this bit.

In general case, it means that we have to solve the following subproblem: check if we can obtain 1 in several bits of the answer; let these bits be {x1,x2,…,xk} (x1 to xk−1 are the bits that we have already checked; xk is the new bit we are trying to check). Let mask be the number that has 1 in every bit xi and 0 in every other bit. The elements should be matched in such a way that (ai&mask)⊕(bi&mask)=mask. If we group all numbers from a and from b according to the value of ai&mask (or bi&mask), then for every group of elements from a, there is a corresponding group in b such that we can match the elements from the first group only with the elements from the second group. So, if for every such group, its size in a is equal to the size of the corresponding group in b, then we can set all bits from {x1,x2,…,xk} to 1 simultaneously.

Some implementation notes: if the number of bits we need to check is big, the number of groups can become too large to handle all of them (since it is 2k). So, to store the number of elements in each group, we should use some associative data structure, like, for example, std::map in C++. If you use a map, splitting elements into groups will be done in O(nlogn), so in total, you will get complexity of O(nlognlogA), where A is the maximum possible value in the input.

Solution (Neon)1721E - Prefix Function Queries

Idea: BledDest

Tutorial1721E - Prefix Function QueriesWhat's the issue with calculating the prefix function on the string s and then appending the string t with an extra |t| recalculations? Calculating prefix function is linear anyway. Well, it's linear, but it's also amortized. So while it will make O(n) operations for a string in total, it can take up to O(n) on every particular letter. These particular letters can appear in string t, making the algorithm work in O(q⋅(|s|+|t|)).

Let's analyze the classic way to calculate the prefix function. To append a character to the string and calculate the new value of the prefix function, you have to do the following:

take the longest proper prefix of a string before appending the letter, which is also a suffix;if the letter right after it is the same as the new one, then the new value is length of it plus one;if it's empty, then the new value is 0;otherwise, take its longest proper prefix and return to step 2.Basically, from having the value of the prefix function of the string and the new letter, you can determine the new value of the prefix function.

If |t| was always equal to 1, then you would only want to try all options for the next letter after a string.

That should remind you of a structure known as prefix function automaton. Its states are the values of the prefix function, and the transitions are appending a letter to a string with a certain value of the prefix function.

So you can append a letter in O(1) if you have an automaton built on the string s. However, you can't just append more letters after one — you don't have the automaton built this far.

You can follow two paths.

The first one is to jump with a regular way of calculating the prefix function until you reach the state of the automaton which exists.

The second one is to continue building the automaton onto the string t, calculating the prefix function along the way. Appending a layer to the automaton takes O(AL) non-amortized. After you calculated everything you needed, pop the states back to the original.

Overall complexity: O(|s|⋅AL+q⋅|t|) or O(|s|⋅AL+q⋅|t|⋅AL).

Solution (awoo)1721F - Matching Reduction

Idea: BledDest

Tutorial1721F - Matching ReductionLet's start by finding the maximum matching in the given graph. Since the constraints are pretty big, you need something fast. The model solution converts the matching problem into a flow network and uses Dinic to find the matching in O(m1.5), but something like heavily optimized Kuhn's algorithm can also work.

Okay, then what about finding the minimum possible number of vertices to delete in order to reduce the maximum matching? We claim that it is always enough to remove one vertex, and the proof will also provide a way to quickly search for such vertices.

Let's recall that the size of the maximum matching is equal to the size of the minimum vertex cover (this only works in bipartite graphs). So, we will try to find a way to reduce the minimum vertex cover by 1, and it's actually pretty easy — just remove any vertex belonging to the vertex cover; it's obvious that it reduces the vertex cover by 1, and the maximum matching by 1 as well. So, we can find the minimum vertex cover in the graph using the standard algorithm to convert the MM into MVC (or, if you're using Dinic to find the maximum matching, you can represent the minimum vertex cover as the minimum cut problem), and for each query of type 1, just take a vertex from the vertex cover we found.

Now the only thing that's left is discussing how to maintain the structure of the maximum matching in the graph. In fact, it's quite easy:

on the one hand, since we remove the vertices belonging to the minimum vertex cover, every edge (including the edges from the matching) will be incident to one of the vertices we will remove;on the other hand, due to the definition of the maximum matching, there is no vertex that is incident to two or more edges from the maximum matching;so, every vertex from the vertex cover has exactly one edge from the maximum matching that is incident to it, and when we remove a vertex, we can simply remove the corresponding edge from the maximum matching.So, the only thing we need to do is to maintain which edge from the matching corresponds to which vertex from the minimum vertex cover, and it will allow us to maintain the structure of the maximum matching — and since these "pairs" don't change when we remove a vertex, it is enough to get this information right after we have constructed the maximum matching in the given graph; we won't need to rebuild it.

Solution (BledDest)

Educational Codeforces Round 133 Editorial

By awoo, history, 7 months ago, translation, In English1716A - 2-3 Moves

Idea: vovuh

Tutorial1716A - 2-3 MovesIf n=1, the answer is 2 (we can't get 1, so we can move by 3 to the right and by 2 to the left). If n=2 or n=3, the answer is obviously 1. Otherwise, the answer is always ⌈n3⌉. We can't get the answer less than this value (because we need at least ⌈n3⌉ moves to get to the point greater than or equal to n) and we can always get this answer by the recurrence.

Solution (vovuh)1716B - Permutation Chain

Idea: BledDest

Tutorial1716B - Permutation ChainIdeally, we would want the fixedness values to be n,n−1,n−2,…,0. That would make a chain of length n+1.

However, it's impossible to have fixedness of n−1 after one swap. The first swap always makes a permutation with fixedness n−2.

Okay, how about n,n−2,n−3,…,0 then? That turns out to always be achievable.

For example, swap elements 1 and 2, then elements 2 and 3, then 3 and 4 and so on.

Overall complexity: O(n2) per testcase.

Solution (awoo)1716C - Robot in a Hallway

Idea: BledDest

Tutorial1716C - Robot in a HallwayLet's first consider the possible paths across the grid that visit all cells. You can immediately think of two of them. The first one is: go right to the wall, turn into the other row and return. Let's call it a hook. The second one is: go down, go right, go up, go right and so on. Let's call it a snake.

Turns out, these two are basically the two extremes of all paths. You can start with a snake and turn into a hook when you wish. You can see that once you move right twice in a row, you can only continue with a hook. And as long as you didn't move right twice, you are just doing a snake.

Let's fix some path across the grid. What will its minimum time be? Calculate it iteratively. If you want to enter the next cell, and it's still locked, wait until it isn't. So there are some seconds of waiting (possibly, zero) before each cell.

However, why not instead do the following. Let's calculate the sum of waiting time required and wait for that amount of seconds before starting to move. All cells will be visited at the same time as before or even later. Thus, they will surely be unlocked if they were in the original plan.

So the goal is to calculate the minimum amount of time required to wait in the start, then add the movement time to it.

Once again, the path is fixed. Let the k-th cell of the path be (xk,yk). If you start after waiting for t seconds, then you reach the k-th cell at time t+k (k is 1-indexed). Thus, the k-th cell should have axk,yk≤t+k−1. If all cells satisfy this condition, then the path can be done after waiting for t seconds at the start.

Let's rewrite it into t≥axk,yk−k+1. So, the condition tells us that t should be greater or equal than this value for all cells. In other words, t should be greater or equal than the maximum of the values over all cells.

Study the formula. Imagine we have some path with a known length and want to append a cell to it. That's pretty simple. Just update the maximum with the value with the corresponding cell and increase the length.

What if we wanted to prepend a cell to it? Turns out, it's not that hard as well. Every cell in the path gets its value k increased by 1. From the formula, you can see that this actually decreases the value of each cell by 1. So the maximum decreases by 1 as well. The only thing left is to update the maximum with the value of the new first cell. Well, and increase the length again.

Finally, let's learn how to choose the best path. We can iterate over the length of the snake part. The hook part is determined uniquely.

It's easy to maintain the maximum on the snake. Just append the new cell to the path.

How to glue up the hook part to that?

Well, actually, realize that the formula allows us to glue up two paths into one. Let path 1 have length n1 and maximum mx1 and path 2 have length n2 and maximum mx2. To make path 2 start after path 1, we just decrease its maximum by n1. The resulting path has length n1+n2 and maximum max(mx1,mx2−n1).

Let's look closer into what the hooks look like. They start in some column j, traverse all the way right, then left up to the same column j. If the snake part took both cells in its last column, then that's it. Otherwise, the hook has to take the final cell in the last column — column j−1.

If we manage to precalculate something for hooks that start in some column j and end in column j, then we will be able to use that. Appending the final cell is not a hard task, since we know its index in the path (k=2⋅m).

Let sui,j be the waiting time required for a hook that starts in cell (i,j) and ends in a cell (3−i,j) as if the path started with the hook (cell (i,j) is the first one).

sui,j can be calculated from sui,j+1. Prepend it with a cell (i,j) and append it with a cell (3−i,j).

The only thing left is to find the best answer. I found the most convenient to start with a snake of length 1 (only cell (1,1)) and progress it two steps at the time:

update the answer;progress the snake to the other cell of the current column;update the answer;progress the snake into the next column.Overall complexity: O(m) per testcase.

Solution (awoo)1716D - Chip Move

Idea: BledDest

Tutorial1716D - Chip MoveLet's calculate dynamic programming dps,i — the number of ways to achieve i in s moves. From the state (s,i), you can make a transition to the states (s+1,j), where i<j and j−i is divisible by k+s.

Let's try to estimate the maximum number of moves, because it seems that there can't be very many of them. For m moves, the minimum distance by which a chip can be moved is k+(k+1)+⋯+(k+m−1) or (k+k+m−1)⋅m2. From here one can see that the maximum number of transitions does not exceed 2n−−√ (maximum at k=1). So it remains to make transitions in dynamic programming faster than O(n) from a single state for a fast enough solution. Let's use the fact that j≡i(modk+s). Let's iterate over the value of j and maintain the sum of dynamic programming values with smaller indices for each remainder modulo k+s in a separate array.

The final complexity of such a solution is O(nn−−√).

It remains to solve the memory problem, because with the existing limits, it is impossible to save the entire dp matrix of size n32. However, this is easy to solve if you notice that only the previous layer is used for transitions in dp, i.e. it is enough to store dps to calculate dps+1.

Solution (Neon)1716E - Swap and Maximum Block

Idea: BledDest

Tutorial1716E - Swap and Maximum BlockLet's carefully analyze the operation denoted in the query. Since the length of the array is always divisible by 2k+1, every element will be swapped with some other element. The elements can be split into two groups — the ones whose positions increase by 2k, and the ones whose positions decrease by 2k.

Let's find some trait of the elements which will allow us to distinguish the elements of one group from the elements of the other group. The first 2k elements will be shifted to the right, the next 2k elements will be shifted to the left, the next 2k elements will be shifted to the right, etc. If we look at the binary representations of integers 0,1,…,n−1, then we can see that the first 2k elements have 0 in the k-th bit, the next 2k elements have 1 in the k-th bit, the next 2k elements have 0 in the k-th bit, and so on. So, if we consider the positions of elements as 0-indexed, then the operation can be described as follows: "Let the position of the element be i. If the k-th bit in i is 0, i gets increased by 2k, otherwise i gets decreased by 2k". What does it look like? Actually, it is just i⊕2k (where ⊕ denotes XOR).

So, each query can be represented as "swap ai with ai⊕x for some integer x". The combination of two queries can also be represented with a single query; in fact, the state of the array can be denoted as the XOR of all 2k from the previous queries.

Now, let's try to solve the following problem: for every x∈[0,2n−1], calculate the maximum sum of subsegment if every element ai is swapped with ai⊕x. To solve this problem, we can use a segment tree.

First of all, we need to understand how to solve the problem of finding the maximum sum on subsegment using a segment tree. To do this, we should store the following four values in each vertex of the segment tree:

sum — the sum of elements on the segment denoted by the vertex;pref — the maximum sum of elements on the prefix of the segment denoted by the vertex;suff — the maximum sum of elements on the suffix of the segment denoted by the vertex;ans — the answer on the segment.If some vertex of the segment tree has two children, these values for it can be easily calculated using the values from the children. So, we can "glue" two segments represented by the vertices together, creating a new vertex representing the concatenation of these segments.

Okay, but how do we apply XOR to this? For every vertex of the segment tree, let's create several versions; the x-th version of the vertex v represents the segment corresponding to this vertex if we apply swapping query with x to it. For a vertex v representing the segment of length 2k, we can use the following relation to get all its versions (here, we denote t(v,x) as the x-th version of v, and vl and vr as the children of v):

if x≥2k−1, then t(v,x)=combine(t(vr,x−2k−1),t(vl,x−2k−1));else t(v,x)=combine(t(vl,x),t(vr,x));The function combine here denotes the "glueing together" of two vertices we described above.

Now let's try to analyze how many versions of each vertex we need. For the root, we will need all 2n versions. For its children, we need only 2n−1 versions. For the children of the children of the root, we need only 2n−2 versions, and so on; so, overall, the total number of versions is only O(n2n), and each version can be constructed in O(1), so the solution works in O(n2n).

Solution (BledDest)1716F - Bags with Balls

Idea: BledDest

Tutorial1716F - Bags with BallsThe main idea of this problem is to use a technique similar to "contribution to the sum". We will model the value of Fk as the number of tuples (i1,i2,…,ik), where each element is an index of a bag from which we have taken an odd ball. Let G(t) be the number of ways to take balls from bags so that all elements from tuple t are indices of bags with odd balls; then, the answer to the problem can be calculated as the sum of G(t) over all possible tuples t.

First of all, let's obtain a solution in O(k2) per test case. We need to answer the following questions while designing a solution to the problem:

How do we calculate G(t) for a given tuple?How do we group tuples and iterate through them?The first question is not that difficult. Every element from the tuple (i1,i2,…,ik) should be an index of a bag from which we have taken an odd ball; so, for every bag appearing in the tuple, we can take only a ball with odd number; but for every bag not appearing in the tuple, we can choose any ball. So, if the number of distinct elements in a tuple is d, then G(t) for the tuple can be calculated as ⌈m2⌉d⋅mn−d.

This actually gives as a hint for the answer to the second question: since G(t) depends on the number of distinct elements in the tuple, let's try to group the tuples according to the number of distinct elements in them. So, the answer will be calculated as ∑i=1kH(i)⌈m2⌉i⋅mn−i, where H(i) is the number of tuples with exactly i different elements.

How do we calculate H(i)? First of all, if i>n, then H(i) is obviously 0. Otherwise, we can use the following recurrence: let dpi,j be the number of tuples of i elements with j distinct ones; then:

if i=1 and j=1, dpi,j=n (for a tuple with one element, there are n ways to choose it);if i=1 and j≠1, dpi,j=0;if i>1 and j=1, dpi,j=dpi−1,j (there is only one distinct element, and it was already chosen);if i>1 and j>1, dpi,j=dpi−1,j⋅j+dpi−1,j−1⋅(n−j+1) (we either add an element which did not belong to the tuple, and there are n−j+1 ways to choose it, or we add an already existing element, and there are j ways to choose it).Obviously, this recurrence can be calculated in O(k2) with dynamic programming, so we get a solution in O(k2) per test case.

How do we speed this up? Let's change the way we calculate H(i). Instead of considering tuples with values from 1 to n, we will consider only tuples where values are from 1 to k, and the first appearance of a value i is only after the first appearance of the value i−1. So, these tuples actually represent a way to split a set of integers {1,2,…,n} into several subsets; so they are the Stirling numbers of the second kind, and we can calculate them in O(k2) with dynamic programming outside of processing the test cases.

How do we calculate H(i) using these values? If we use i distinct integers as the elements of the tuple, there are n ways to choose the first one, n−1 ways to choose the second one, etc. — so H(i)=S(k,i)⋅∏j=0i−1(n−j), where S(k,i) is the Stirling number of the second kind for the parameters k and i. We can maintain the values of ∏j=0i−1(n−j) and ⌈m2⌉i⋅mn−i while iterating on i from 1 to k, and that gives us a way to solve the problem in O(k) per test case.

Overall complexity: O(k2) for precalculation and O(k) per test case.

Solution (BledDest)

Educational Codeforces Round 132 Editorial

By awoo, history, 7 months ago, translation, In English1709A - Three Doors

Idea: BledDest

Tutorial1709A - Three DoorsNote that we never have a choice in what door should we open. First, we open the door with the same number as the key in our hand. Then, the door with the same number as the key behind the first opened door. Finally, the door with the same number as the key behind the second opened door.

If any of the first and second opened doors didn't have a key behind it, then it's impossible. Otherwise, we open every door.

Let a1,a2,a3 be the keys behind the corresponding doors. Then we should check if a[x] is not zero and a[a[x]] is not zero.

Overall complexity: O(1) per testcase.

Solution (awoo)1709B - Also Try Minecraft

Idea: BledDest

Tutorial1709B - Also Try MinecraftSo, the first idea that is coming into mind is prefix sums. Let's define two values li=max(0,ai−ai+1) and ri=max(0,ai+1−ai). The value li means the amount of fall damage when we are going to the right from the column i to the column i+1, and ri means the amount of fall damage when we are going to the left from the column i+1 to the column i. Then let's build prefix sums on these two arrays. Now let pli be the sum of all li on a prefix [0;i) (i. e. pl0=0), and pri be the sum of all ri on a prefix [0;i). Then if s<t in a query, the answer is plt−1−pls−1, otherwise (if s>t) the answer is prs−1−prt−1.

Time complexity: O(n).

Solution (vovuh)1709C - Recover an RBS

Idea: BledDest

Tutorial1709C - Recover an RBSThere are many different approaches to this problem, but I think the model solution has the most elegant one.

First of all, let's construct an RBS from the given string (it always exists, so it is always possible). By calculating the number of opening brackets, closing brackets and questions in the given string, we can compute the number of question marks that should be replaced with opening brackets (it is easy since exactly half of the characters in each RBS are opening brackets). Then, let's form the RBS greedily: replace the first several question marks with opening brackets, and all remaining ones with closed brackets.

Okay, then what about finding a second RBS? Recall that a bracket sequence is an RBS when for each of its positions, the number of closing brackets before it is not greater than the number of opening brackets before it (and these two values should be equal at the end of the sequence, but it is less important now). Consider the segment between the last question mark replaced with an opening bracket, and the first question mark replaced by the closing bracket. If we try to change the order of characters corresponding to question marks, the balance on this segment will decrease at least by 2 (since at least one opening bracket to the left of it will become a closing bracket). Is there a way to affect only this segment, and change the balance on it only by 2? Yes — just swap the endpoints of this segment (i. e. the last opening bracket that was a question mark and the first closing bracket that was also a question mark). If it yields an RBS, then the answer is NO. Otherwise, the answer is YES since any other permutation of characters that were replacing question marks will also decrease the balance on this segment by at least 2.

Solution (Neon)1709D - Rorororobot

Idea: BledDest

Tutorial1709D - RorororobotWhat if there were no blocked cells? Then the movement is easy. From cell (x,y) we can go to cells (x+k,y), (x,y+k), (x−k,y) or (x,y−k). Thus, we can visit all cells that have the same remainder modulo k over both dimensions. The answer would be "YES" if xsmodk=xfmodk and ysmodk=yfmodk.

Let's choose the following path from start to finish. Let xs be less or equal to xf. If that isn't the case, swap the cells. First, move up until the row is the same, then move to the side until the column is the same.

What stops us from doing the same on a grid with blocked cells? The first part of the part can remain the same — we can always move up from the cell. Only cells below the start cell can be blocked. The second part is trickier. If there is a column with too many blocked cells between the start and the finish column, then we won't be able to pass through it.

Let's adjust the path for that. Move up as high as possible — to the highest cell with the same remainder modulo k in this column. Then move to the finish column and go down to the finish cell.

If there still exists a column with too many blocked cells, then the answer is "NO". No matter what we do, we won't be able to go around that column. Otherwise, the answer is "YES".

Thus, the solution is to check for remainders, then find the largest number of blocked cells between the query columns and compare it to the highest row with the same remainder modulo k as the start or the finish. You can use any RMQ data structure you want.

Overall complexity: O(nlogn+q) with sparse table for RMQ, for example.

Solution (awoo)1709E - XOR Tree

Idea: BledDest

Tutorial1709E - XOR TreeTo begin with, we note that there are no restrictions on the values that can be written on the vertices, so we can use numbers of the form 230+x for the x-th replacement. Then, if we replaced the value of a vertex, then no path passing through this vertex has weight 0.

Let's root the tree at the vertex number 1. We can use a greedy approach: consider some vertex v such that it is the LCA for two vertices x and y, the path between which has XOR equal to 0. Among such vertices v, pick one with the maximum distance from the root. We need to change at least one vertex on the path (x,y). It turns out that changing the vertex v is always no worse than changing any other vertex u on this path, because all the remaining bad paths that pass through the vertex u also pass through the vertex v (that's why we have chosen the deepest LCA). This means that in order to solve the problem, it is necessary to quickly find the deepest LCA of some bad path.

For the convenience of solving the problem, let's denote the XOR on the path (x,y) as bx⊕by⊕aLCA(x,y), where bv is XOR on the path from the root to the vertex v. For all vertices v, let's maintain a set of values bx, such that x belongs to the subtree of v. Let's use the small-to-large method to obtain such sets. Also, during the union of sets, we can check if there is a bad path in this subtree, i. e. if two values in the sets we merge have the same XOR as the value written on the current vertex (because that's when the XOR on path is 0). If such a path exists, then we have to change the value of the vertex v and mark that the vertices of this subtree cannot be the ends of a bad path anymore — that means we just clear the set instead of pulling it up the tree.

This solution works in O(nlog2n).

Solution (Neon)1709F - Multiset of Strings

Idea: BledDest

Tutorial1709F - Multiset of StringsFirst of all, let's visualize the problem in a different way. We have to set some constraints on the number of strings which have some kind of prefix. Let's think about a data structure that would allow us to understand it better. One of the most common data structures to store strings which works with their prefixes and maintains the number of strings with some prefix is a trie; so, we can reformulate this problem using tries.

Now the problem is the following one: we have a binary trie of depth n; the leaves of this trie may store strings, and for each vertex except for the root, we can set a constraint on the number of strings stored in the subtree; what is the number of ways to choose these constraints so that the maximum number of strings (possibly with copies) the trie can store is exactly f? To handle it, we can use dynamic programming of the form dpv,i — the number of ways to choose the constraints for the vertex v and its subtree so that the maximum number of strings which can be stored in the subtree is exactly i. When calculating dpv,i, we can iterate on the constraint for the vertex v (let it be a), and the maximum number of strings in the subtrees of v1 and v2 (let these be b and c), and make updates of the form "add dpv1,b⋅dpv2,c to the value of dpv,min(a,b+c)". This dynamic programming will work in O(2nk2) or O(2nk3) depending on the implementation, which is too slow.

However, we can use the following optimizations to improve the complexity of the solution:

all vertices on the same depth can be treated as equivalent, so we can actually calculate this dynamic programming not for O(2n) vertices, but just for O(n);when handling transitions from some node's children to that node, let's split these transitions into two steps. The first step is iterating on the number of strings which fit into the subtrees of the children; the second step is iterating on the constraint for the subtree of the node. The first step is actually a convolution: if we don't consider the constraint for the node itself, then the transitions would be something like "add dpv1,b⋅dpv2,c to the value of dpv,b+c)"; so it can be improved to O(klogk) with FFT. The second step can be improved to O(k) as well, if we iterate on the minimum between the constraint for the node and the total number of strings which can be stored in the children, and maintain the sum on suffix for the values of dynamic programming.Overall, these optimizations lead to a solution with complexity O(nklogk).

Educational Codeforces Round 131 Editorial

By awoo, history, 8 months ago, translation, In English1701A - Grass Field

Idea: BledDest

Tutorial1701A - Grass FieldIf there is no grass on the field, the answer is 0. If the whole field is filled with grass, the answer is 2, because there always will be one cell that we can't clear with one move. Otherwise, the answer is 1. This is because if the cell (i,j) is empty, we can just choose other row than i and other column than j and clear three other cells in one move.

Solution (vovuh)1701B - Permutation

Idea: BledDest

Tutorial1701B - PermutationLet's notice that for a fixed value of d, the answer (the cost of permutation) does not exceed nd, because only numbers from 1 to nd can have a pair. It turns out that it is always possible to construct a permutation with the cost of exactly nd. It is enough to consider the number "chains" of the form: x,x⋅d,x⋅d2,…,x⋅dk, where x≠0(modd). It is not difficult to understand that each number is included in exactly one such chain. Therefore, if we append the chains one after another, then in such a permutation the answer will be equal to n−the_number_of_chains (because all numbers will have a pair except the last element in the chain). The number of chains is equal to n−nd, which means the cost of the permutation is equal to n−(n−nd)=nd. By choosing d=2 the permutation will have the maximum possible cost.

Solution (Neon)1701C - Schedule Management

Idea: BledDest

Tutorial1701C - Schedule ManagementThe statement should instantly scream binary search at you. Clearly, if you can assign the workers in such a way that the tasks are completed by time t, you can complete them all by t+1 or more as well.

How to check if the tasks can be completed by some time t? What that means is that all workers have t hours to work on some tasks. If all tasks took 2 hours to complete, then each of them could complete ⌊t2⌋ of them. Thus, together they would be able to complete ⌊t2⌋⋅n tasks.

How to incorporate the 1-hour tasks into that? Well, we can redistribute the tasks in such a way that each worker first completes the tasks they are proficient in, then some other tasks if they have more time.

So the general idea is the following. Let each worker i complete min(t,cnti) 1-hour tasks, where cnti is the number of tasks the i-th worker is proficient in. Then remember how many 2-hour tasks they can complete, which is ⌊t−min(t,cnti)2⌋. Finally, remember how many tasks that they are proficient in they didn't have time to complete, which is cnti−min(t,cnti). If the sum of the number of incomplete tasks doesn't exceed the sum of the number of tasks they have time to complete, then everything can be completed in time t.

Worst case, it can take up to 2m hours to complete everything — if you assign all tasks to a single worker, and they are not proficient in any of them.

Overall complexity: O(nlogm) per testcase.

Solution (awoo)1701D - Permutation Restoration

Idea: BledDest

Tutorial1701D - Permutation RestorationWe have bi=⌊iai⌋ for each i, we can rewrite this as follows: ai⋅bi≤i<ai⋅(bi+1), or ibi+1<ai≤ibi. From here we can see that for each i there is a segment of values that can be assigned to ai. So we have to match each number from 1 to n with one of these segments.

To solve this problem, we can iterate from 1 to n. Let the current number be x, then it can be paired with a segment i without a pair such that ibi+1<x≤ibi and the right bound is minimum among all such segments (because it will be the first to end among these segments). To do this, it is enough to maintain a set with open segments that have not yet been assigned a pair and choose from it a segment with the minimum right bound. Before running this method, you can sort the segments by their left border so they can be easily added to this set when we go from x to x+1 (we will need to insert all segments that begin with x+1, that's why it's convenient to have them sorted by their left border beforehand).

Solution (Neon)1701E - Text Editor

Idea: vovuh

Tutorial1701E - Text EditorOf course, there is no need to press "home" more than once (and no need to press "end" at all), because suppose we did something on suffix, then pressed "home", did something on prefix and then pressed "end" and continue doing something on suffix. Then we can merge these two sequences of moves on suffix and press "home" after we did anything we wanted on suffix, and the answer will not get worse.

Now, let's iterate over the position pos at which we will press "home" (in range from 0 to n). In other words, we iterate over the position till which we press only "left" and "backspace" to fix the suffix. So now we have the string s[pos;n) and we want to get some suffix of t from this string, but we actually don't know which suffix of t we want. So let's iterate over the length of this suffix suf in a range from 0 to m. Now we have the string s[pos;n) and the string t[m−suf;m) and we have to check if we can obtain this suffix of t from this suffix of s. This part can be precalculated in O(n) greedily (we just can store for each suffix of t the rightmost position in s in which this suffix is obtainable). If we can obtain the current suffix, then we obviously can say the number of moves to do that — it is n−pos and actually do not depend on the suffix length (because if we meet the character we need, we just press "left" and move to the next character, otherwise we press "backspace" and move to the next character deleting the one we don't need).

After that, we press "home" and now we have to check if we can obtain t[0;m−suf) from s[0;pos). This part can also be precalculated greedily in O(n) like the part with rightmost positions for suffixes. But the minimum number of moves required to obtain the prefix is tricky. Actually, if we consider these prefixes from right to left, we want to match as many characters from the beginning as possible. In other words, if we reverse s[0;pos) and t[0;m−suf), we want to find their longest common prefix, and this will be the number of characters we don't want to touch at all (and if it is the longest common prefix, it means that the next character is bad, and we want to remove it anyway, so the length of LCP of these two reversed prefixes is the only thing affecting the number of moves on the prefix). This part can be precalculated in O(n2) with simple dynamic programming (using O(n2) memory) or with z-function in O(n2) time and O(n) memory — we just need to build a z-function on a string s[0;pos)−1+#+t−1, where + is the concatenation of strings and −1 is the reverse operation. The required value of the z-function for the fixed values pos and suf will be in the position pos+1+m−suf. And the answer for the prefix will be pos−suf (this is the number of extra characters on the prefix we have to delete) plus pos−zpos+1+m−suf plus 1 because we have to press "home". But there is a corner case. If the prefix is empty, then we don't need to do all of this and the answer for prefix will be 0.

Complexity: O(n2) time and O(n) memory.

Solution (vovuh)1701F - Points

Idea: BledDest

Tutorial1701F - PointsWe are going to calculate the answer as follows: for every point i, let f(i) be the number of points j such that 1≤j−i≤d (i. e. the number of points that are to the right of i and have distance at most d from it). Then, the number of beautiful triples where i is the leftmost point is f(i)(f(i)−1)2. We can sum these values over all points to get the answer; so, the solution should somehow maintain and update the sum of these values efficiently.

Let's see what happens when we add a new point or remove an existing point. For all points to the left of it with distance no more than d, the value of f(i) increases or decreases by 1. So, we need some sort of data structure that allows adding/subtracting 1 on segment and maintains the sum of f(i)(f(i)−1)2. This looks like a lazy segment tree, but updating the sum of f(i)(f(i)−1)2 can be tricky.

One way to do this is to notice that f(i)(f(i)−1)2=f(i)22−f(i)2. So maybe we can maintain the sum of f(i)2 and the sum of f(i) on the segment? It turns out we can.

The model solution does this as follows: the leaf of the segment tree corresponding to the position i stores a vector with three values: (f(i)0,f(i)1,f(i)2). The inner nodes store the sums of these vectors in the subtree. We can find a matrix which, when multiplied by (x0,x1,x2), gets the vector ((x+1)0,(x+1)1,(x+1)2), and the inverse matrix to it. Then adding 1 to f(i) on segment means multiplying all vectors on segment by that matrix, and subtracting 1 means multiplying by the inverse matrix; and since matrix multiplication is both associative and distributive, the segment tree can handle these queries.

Side note: this method with matrices is asymptotically fine, but the constant factor in it is fairly large. You can speed this up by getting rid of the matrices and instead storing the sum of f(i) and the sum of f(i)2 in each node, and coding the formulas that allow you to add/subtract 1 on segment by hand, without any matrix operations. This can make a noticeable improvement in terms of actual time consumption, although it wasn't needed in this problem since the time limit was pretty generous.

Okay, there's only one small issue left: right now our structure can store the sum of f(i) and f(i)2 over all possible points (we build it on segment [0,200000], for example), but we only need the sum over existing points. One way to handle it is to use a flag for each leaf of the segment tree, and pull the value up from the leaf only if this flag is true. We will need a function that changes the value of this flag for a single leaf, but it's not very different from a function that changes one value in a lazy segment tree.

Time complexity of the solution is O(A+qlogA), where A is the maximum coordinate of the point, although the constant factor of the described approach is fairly large since it involves 3×3 matrix multiplications. You can improve the constant factor by getting rid of the matrices, as mentioned earlier.

Solution (BledDest)

Educational Codeforces Round 130 Editorial

By awoo, history, 9 months ago, translation, In English1697A - Parkway Walk

Idea: vovuh

Tutorial1697A - Parkway WalkIf you have at least sum(ai) units of energy, then the answer is 0, because you can just walk to the end. Otherwise, the answer is sum(ai)−m, because you can just sit on the first bench and then just go.

Time complexity: O(n).

Solution (vovuh)1697B - Promo

Idea: BledDest

Tutorial1697B - PromoFirst of all, there is an answer with exactly x items bought. Suppose items worth p1≤p2≤⋯≤pm (x<m) were purchased. Then by removing p1 from this set, the sum of y the cheapest items in the set will change by py+1−p1≥0, which means the answer will not decrease.

The second fact that is necessary to solve the problem  — x of the most expensive items should be chosen. Otherwise, one can remove the minimum price item from the set and add an item with a higher price (it can always be found), which means the answer will not decrease.

Using these two facts, it is enough to sort the array and use prefix sums.

Solution (Neon)1697C - awoo's Favorite Problem

Idea: BledDest

Tutorial1697C - awoo's Favorite ProblemFirst, check that the counts of all letters are the same in both strings.

Then consider the following restatement of the moves. The letters 'b' in the string s are stationary. Letters 'a' and 'c', however, move around the string. The move of the first type moves a letter 'a' to the right. The move of the second type moves a letter 'c' to the left.

Notice that letters 'a' and 'c' can never swap with each other. Thus, if you remove all letters 'b' from both strings, the remaining strings should be the same.

Again, since letters 'a' and 'c' can never swap with each other, you can deduce where each of these letters should end up after the swaps. The first letter '{a}' in s should be on the position of the first letter 'a' in t and so on.

After that, we recall that 'a's can only move to the right and 'c's can only move to the left. Thus, we check that the i-th occurrence of 'a' in s is to the left or equal to the i-th occurrences of 'a' in t and vice versa for 'c's.

Finally, we can see that this is a sufficient condition. Easy to show by construction: you can just fix the positions one after another left to right.

Overall complexity: O(n) per testcase.

Solution (awoo)1697D - Guess The String

Idea: BledDest

Tutorial1697D - Guess The StringThere are several ways to solve this problem. The model solution does it as follows:

Restore the characters of s from left to right. The first character is restored by query ? 1 1. For each of the next characters, let's ask if this character is new (by querying ? 2 1 i and comparing the result with the number of different characters on the segment [1,i−1]). If it's new, ask ? 1 i to obtain the i-th character (there will be at most 26 such queries).

Otherwise, we can find the previous occurrence of the i-th character with binary search. Let f(x,y) be the number of different characters from position x to position y. If we want to find the previous occurrence of the i-th character, we need to find the last index j such that f(j,i)=f(j,i−1). Since the value f(j,i)−f(j,i−1) does not decrease when we increase j, we can find the last j such that f(j,i)−f(j,i−1)=0, with binary search.

Unfortunately, the number of queries of type 2 will be too large if we just use binary search over the whole segment [1,i−1]. To decrease the number of queries, we can use the fact that the value of j we are interested in is the last occurrence of some character we already met; there are at most 26 such values, and binary search among them will need only 5 iterations.

Solution (BledDest)1697E - Coloring

Idea: BledDest

Tutorial1697E - ColoringLet's call a point i isolated if its color does not match the color of any other point. If a point is not isolated, then it has the same color as the points with minimum distance to it (and only these points should have this color).

Let's build a directed graph where the arc i→j means that the point j is one of the closest to the point i (i. e. d(i,j)=mink=1,k≠ind(i,k)). If there is a path from the vertex i to the vertex j, it means that if the vertex i is not isolated, the vertex j should have the same color as vertex i.

Suppose the set of vertices reachable from i (including i itself) is S(i). Finding S(i) is easy — just run DFS from the vertex i. Let's analyze two cases:

there exists a pair of vertices (j,k) such that j∈S(i), k∈S(i), and there is no arc from j to k;for every pair of vertices (j,k) such that j∈S(i) and k∈S(i), there is an arc j→k.Why do we need to analyze these two cases? In the first case, the vertex i must be isolated, because painting it and some other vertex into the same color means that every vertex from S(i) will have this color, and it will break the condition in the statement. In the second case, the vertex i may be isolated, or it may have the same color as all vertices in S(i) — and if it is isolated, then the whole set S(i) should consist of isolated vertices.

Let's find all such set of vertices that meet the second case. Each vertex will belong to at most one of these sets; if it doesn't belong to any, it must be isolated, otherwise either the whole its set consists of isolated vertices, or the whole set has the same color. So, for each set, we either use 1 color or |S(i)| colors. This allows us to implement a knapsack-like dynamic programming: let dpi,j be the number of ways to paint i first sets into j colors, such that the colors are not ordered. After running this dynamic programming, we can get the answer by simple combinatorics: iterate on the number of colors we use in these sets in total, multiply the dynamic programming for it by the (ordered) number of ways to choose these colors from n, and then by the number of ways to choose the colors for points that must be isolated.

This dynamic programming can even be implemented a bit easier if we treat every vertex that must be isolated as a set of size 1, and this is the way it's written in the model solution.

Solution (BledDest)1697F - Too Many Constraints

Idea: BledDest

Tutorial1697F - Too Many ConstraintsImagine there were no constraints of the second or the third types. Then it would be possible to solve the problem with some greedy algorithm. Unfortunately, when both these constraints are present, it's not immediately clear how to adapt the greedy.

Dynamic programming is probably also out of question, because you can't maintain all possible cuts between equal values on each prefix.

Thus, let's try to make a graph problem out of this. Who knows, maybe a flow or something else could work.

Create k nodes for each position. Let the x-th of them on the i-th position represent the condition of kind "is ai equal to x?". Then all constraints can be described as edges on this graph. Binary variables, restrictive edges. Surely, this is 2-SAT.

Connect the pairs of values that satisfy each constraint. Add the edges between the adjacent positions to enforce the restriction on the non-decreasing order. Prohibit each position to be assigned to multiple values. Force each position to be assigned at least one value. Huh, it's not that easy. That's where the 2-SAT idea fails. We want the conditions of form (ai=1∨ai=2∨⋯∨ai=k). But that is not allowed, since 2-SAT has to have two variables in a clause.

That's where the main idea of the problem comes up. Instead of making our nodes (i,x) represent ai=x, let's make them ai≥x and try building the graph again.

If ai=x, then all nodes (i,y) for y≤x will be true, and the rest will be false. So if (i,x) is false, then (i,x+1) is false. That will enforce the validity of the nodes themselves.

First, the order. If (i,x) is true, then (i+1,x) is true.

The first type of constraints. ai≠x is basically the same as (ai<x or ai>x). For our conditions, it's rather ((not ai≥x) or ai≥x+1).

The second type of constraints. ai+aj≤x. Let ai be greater than or equal to some y. Then, for this constraint to hold, aj should be no greater than x−y. Thus, if (ai≥y) is true, then (aj≥x−y+1) should be false. Same for i and j swapped.

The third type of constraints is similar. ai+aj≥x. Let ai be less than or equal to some y. Then, for this constraint to hold, aj should be greater than or equal to x−y. Thus, if (ai≥y+1) is false, then (aj≥x−y) should be true. Same for i and j swapped.

And that's it. Solve the 2-SAT and restore the answer. I can advise making not k but actually k+2 nodes for ai≥0,1,…,k+1 and force the values to be between 1 and k. That will simplify the checks while adding the constraints.

Overall complexity: O((n+m)k).

Solution (awoo)

Educational Codeforces Round 129 Editorial

By awoo, history, 9 months ago, translation, In English1681A - Game with Cards

Idea: BledDest

Tutorial1681A - Game with CardsLet the maximum card among all n+m cards be x.

If only one player has a card of value of x, then he/she can win by playing it on the first turn or on the second turn; the opponent won't be able to respond with any of their cards.

Otherwise (if both players have a card with value x), the player who plays this card earlier wins the game. So, in this case, the winner is the player who makes the first turn.

Solution (BledDest)1681B - Card Trick

Idea: BledDest

Tutorial1681B - Card TrickThe easiest way to solve to problem is probably to see the resemblense of a shuffle operation to an std::rotate function. So you can obtain the final deck by applying cyclic shifts of the deck by b1, then b2 and so on.

Since the shifts are cyclic, it doesn't matter if you shift by x or by x+n or by x+k⋅x for any non-negative k. The result will be the same. Thus, you can calculate the sum of rotations you apply, and subtract n, until it becomes less than n. That is taking it modulo n.

Finally, after rotating a sequence by some x, the x-th element of it (0-indexed) becomes the first one. Thus, you just want to print the (summodn)-th element of a.

Overall complexity: O(n+m) per testcase.

Solution (awoo)1681C - Double Sort

Idea: BledDest

Tutorial1681C - Double SortImagine that all elements of a are distinct. This way, sorting a in increasing order will fix the order of b.

If b turns out sorted in a non-decreasing order, then the answer exists. Otherwise, it doesn't. To obtain the sequence of swaps, you can sort a with any comparison-based sorting algorithm you want: even bubble sort will not exceed the allowed number of swaps.

What changes if a has repeated elements? Distinct elements are still ordered among themselves, but now there are also blocks of equal elements. For each block, look into the corresponding values in b. Obviously, these have to be sorted in a non-decreasing order. Rearrange them as they should be.

In fact, this is exactly the same as sorting the sequence of pairs (ai,bi) with a default comparator — first by ai, then by bi.

Since we fixed the wanted order, we can proceed with the same steps we made in a distinct case.

Overall complexity: O(nlogn) or O(n2) per testcase.

Solution (awoo)1681D - Required Length

Idea: BledDest

Tutorial1681D - Required LengthOne of the possible approaches to this problem is to try multiplying x only by the largest digit in it. Unfortunately, this doesn't work quite well, since it gives WA on one of the examples. That example is too big to consider, but a smaller version of it can prove that this is an incorrect solution: let n=5, x=403. If we multiply 403 by 4, we get 1612, and there's no way to obtain a number with 5 digits using the next action. But, if we multiply 403 by 3, we get 1209, which can then be multiplied by 9 to obtain a 5-digit number. So, considering only the largest digit is not enough.

This implies that we somehow need to consider the options that are not optimal locally, but optimal globally (i. e. choose a lower digit right now to obtain a higher digit in the future).

Let's try to estimate the number of possible integers that can be obtained using these operations to see if we can consider all possible options. The key observation is that each integer we obtain will have the form x⋅2a⋅3b⋅5c⋅7d, since only one-digit primes can be added to the factorization. Since we consider only numbers less than 1019, a is not greater than 63, b is not greater than 39, c is not greater than 27, and d is not greater than 22, and the number of reachable integers is about 1.5 million (note that this is a very generous bound since not all combinations of (a,b,c,d) yield an integer less than 1019, and not all such integers can be reached with the operations).

This allows us to use BFS or dynamic programming to calculate the answer.

Solution (BledDest)1681E - Labyrinth Adventures

Idea: BledDest

Tutorial1681E - Labyrinth AdventuresWLOG, assume all queries ask to move from a lower layer to a higher layer. The first thing to notice in the problem is that it is always optimal to never go down a layer.

You have an optimal path that is going down some layers, and then returning to the same layer. So it leaves a layer in some its cell and returns to it in some other cell (or the same one). The best distance it can achieve is the Manhattan distance between these two cells. However, we can also achieve the Manhattan distance by just going along this layer, and the answer will be at least as optimal.

If the query asks about the cells of the same layer, just answer with the Manhattan distance. Otherwise, we can describe the path as follows: go from the first cell to some door on its layer, enter the door and go to another door on the next layer, so on until the layer of the second cell, where you go from a door to the second cell.

Thus, we could potentially write dpi,j — the shortest distance from the start to the j-th door of the i-th layer. Initialize both doors of the first layer, take the best answer from the both doors of the last layer. That would be O(n) per query, which is too slow.

Let's optimize it with some precalculations. In particular, we want to know the shortest distance between one door of some layer and one door of another layer.

We can use the technique similar to binary lifting. Calculate the distance between a pair of doors on layers which are 2x apart for all x up to logn. Let dpi,x,d1,d2 be the distance from door d1 of layer i to door d2 of layer i+2x. dpi,0,d1,d2 can be initialized straightforwardly. Then, to calculate dpi,x,d1,d2, we can use the values for x−1: dpi,x−1,d1,t and dpi+2x−1,x−1,t,d2 for some intermediate door t on layer i+2x−1.

To obtain the answer, use O(logn) jumps to reach the layer one before the last one. Then iterate over the last door.

Alternatively, you could pack this dynamic programming into a segment tree, use divide and conquer on queries or do square root decomposition.

Overall complexity: O((n+m)logn).

Solution (awoo)1681F - Unique Occurrences

Idea: BledDest

Tutorial1681F - Unique OccurrencesLet's use contribution to the sum technique to simplify the problem. Instead of counting the number of colors that occure only once for each path, let's, for each color, count the number of paths that contain this color exactly once. Now we can solve the problem independently for each color, and sum up the answers.

The first intended solution was the following. So we want to calculate the answer for some color c. Mark all edges of color c as good, the rest are bad. Then we can calculate dpv,i — the number of paths up to vertex v such that they contain either 0 or 1 good edges. The transitions should be pretty easy, and the answer should be updated when you consider gluing up paths from different children in each vertex. Obviously, this is O(n) per color, so O(n2) overall.

However, we can only calculate this dynamic programming as easily on a virtual tree of vertices adjacent to all good edges. How to calculate the dp for some vertex v? First, push the paths from all virtual children to v. That was enough in the dp for the entire tree but now there are also removed vertices that could also have paths starting in them. All these paths contain 0 good edges (otherwise, they would have had virtual vertices on them). Their amount is the following: the size of the real subtree of v minus the sizes of real subtrees of all its virtual children. The rest is exactly the same as in the dp on the real tree.

A little fun trick. Usually, you want to add lca of adjacent vertices to the virtual tree. But that's actually not needed here: you can just add the root of the tree and link the vertices without a parent to them. That won't change the result of the dp.

That solution works in O(nlogn) or O(n).

The second intended solution is slower complexity-wise but not time-wise. In the first solution we wanted to leave only the good edges in the tree. Here, we want to remove only them. Consider the resulting connected components. What's the number of paths that contain only one of the good edges? It's actually the product of sizes of the connected components this edge connects.

So we want to remove edges, add edges and maintain the sizes of the connected components of the tree. That's basically the same problem as dynamic connectivity. The O(nlog2n) implementation works well enough.

Solution 1 (awoo)Solution 2 (awoo)

Educational Codeforces Round 128 Editorial

By awoo, history, 10 months ago, translation, In English1680A - Minimums and Maximums

Idea: BledDest

Tutorial1680A - Minimums and MaximumsFirstly, since we are interested in minimum possible size of the array, we don't need any elements other than minimums and maximums. So, the array has at most 2 distinct elements.

Now there are many possible solutions. The simplest one is to iterate on the number of minimums (let this be i) and maximums (let this be j). If the number of minimums is equal to the number of maximums, then the array should have all elements as both its minimums and maximums, so its length should be i; otherwise, it should be i+j. We can iterate on all possible pairs (i,j) and find the best result over all of them.

A solution in O(1) is possible if you see that you only have to consider l1 and l2 as the number of minimums/maximums, or check if the segments [l1,r1] and [l2,r2] intersect in O(1).

Solution (BledDest)1680B - Robots

Idea: BledDest

Tutorial1680B - RobotsLet's assume that the rows are numbered from 0 to n−1 from top to bottom, and columns are numbered from 0 to m−1 from left to right.

If there is no robot in the cell (0,0) initially, we have to perform several moves up and/or left. If the first row with at least one robot is the i-th row, then we can make at most i steps up (and we should do at least i steps up, since otherwise there will me no robot in the upper row). Similarly, if the first column with at least one robot is the j-th column, then we can make at most j steps to the left (and we should do at least j steps to the left, since otherwise there will me no robot in the leftmost column).

Now there are two possible solutions, both starting with finding i and j: we afterwards either simulate i moves up and j moves to the left and check that everything is fine, or just check that there is a robot in the cell (i,j) (since only this robot can end up in (0,0)).

Solution (BledDest)1680C - Binary String

Idea: BledDest

Tutorial1680C - Binary StringThere are many different approaches to this problem: dynamic programming, binary search, greedy, two pointers, anything you want. The model solution uses an approach based on binary search, so I'll describe it.

First of all, why does binary search work? Let's say that the number of 1's is c. If the cost of deletion is k, then we have deleted at most k characters 1, and have left at most k characters 0. Let's increase the number of characters we delete from the prefix of the string until the number of deleted 1's becomes k+1: if c≥k+1, it's always possible. So, if we consider the segment of values [0,c], the fact that we can get cost k implies that we can get cost k+1, so we can use binary search on segment [0,c] to find the minimum achievable cost.

Now, how to check if we can obtain the cost of deletion equal to k? One possible way to do this is to form an array pos, where posi is the position of the i-th character 1 in the string, and find the minimum value of posi+c−k−1−posi in this array: the string that should remain has to contain at least c−k characters 1, and the minimum value of posi+c−k−1−posi is the minimum possible length of such string. Then we can find the number of 0's in this string and check if it is greater than k or not.

Solution (BledDest)1680D - Dog Walking

Idea: vovuh and BledDest

Tutorial1680D - Dog WalkingConsider every cyclic shift of the array a. Suppose that now the array a starts from the position i (the first element is a[i] and the last element is a[(i+n−1)%n]). Assume that before the position i our dog reached her minimum possible position and now the minimum position will not change. So our problem is to fill all zeros in the array a in such a way that the maximum prefix sum of a is the maximum possible and the total sum of a is zero.

For simplicity, consider the array b which is the i-th cyclic shift of a (i. e. the first element b[0] is a[i], the second element b[1] is a[(i+1)%n], and so on). Let's iterate from left to right and maintain the current sum of the array b. Let this variable be s. Now, when we meet bj=0, we should replace it with the maximum possible value we can (because in such a way we will increase the maximum number of prefix sums). Let x be the number of zeros in b starting from the position j+1. This value can be calculated in advance in O(n) for every cyclic shift using suffix sums. Then the segment of positions we can have at the end is [s−xk;s+xk] and we want to place the maximum possible value in b[j] in such a way that this remaining segment (with addition of our current element) will cover 0. This maximum value equals b[j]=min(k,xk−s). If b[j] becomes less than −k then this cyclic shift is invalid, and we should skip it. Otherwise, let's add b[j] to s and proceed. If there are no values b[j]<−k, then we placed anything correctly.

Now can just simulate the movements of our dog to find the answer for the current cyclic shift. But there are cases when a do not contain zeros, so these cases should be handled somehow (I just checked that after simulation we returned to 0). If we returned to 0, we can update the answer as the difference between the maximum and the minimum positions plus one. If there is no valid cyclic shift, then the answer is -1.

Time complexity: O(n2).

Solution (vovuh)1680E - Moving Chips

Idea: vovuh

Tutorial1680E - Moving ChipsFirstly, I want to say a few words about the difficulty of this problem. Till the last moment, we didn't know easy to prove (and easy to write) solutions, so we decided that this is a good problem E. But now we realized it is a lot easier than we expected.

Now, let's talk about the solution. At the beginning, let's remove redundant columns from the beginning and from the end (i. e. columns without chips) and change the value n correspondingly. Now, let costi,j be 1 if sj,i is '*', and 0 otherwise. This array needed to make the implementation easier.

Let's calculate the dynamic programming dpi,j, where i is the index of the last processed column and j is the number of the row where our chip is standing. This seems a bit suspicious why we can calculate such a dynamic programming, so let's explain some things about it.

It can be shown that in the optimal answer there will be some column where the last move happens. And if the number of this column is j then all chips to the left of j will move only to the right and all chips to the right of j will move only to the left.Actually, we can always consider that j is the last column. Consider paths of two chips that will survive till the last move. The first chip is to the left of j and will move only to the right, and the second one is to the right of j and will move only to the left. Then we can replicate the path of the second chip in the reverse order using the first chip. So the second chip can stay still until the last move.In the optimal answer, it is always better to have exactly one chip in the current column, because moving two chips to the right is always worse than just eat one of them and move the remaining one.Initial states of dp are +∞ except the values of the first column. For the first column, dp0,0=cost0,1 and dp0,1=cost0,0. The answer will be min(dpn−1,0,dpn−1,1).

Okay, how to make transitions from dpi,j? For all i from 0 to n−2, let's consider four cases:

dpi,0→dpi+1,0 — here we need one move to go to the next column and, probably, one more move to delete the figure in the second row in the column i+1. So the transition seems like dpi+1,0=min(dpi+1,0,dpi,0+1+costi+1,1);dpi,1→dpi+1,1 — same as the previous transition, dpi+1,1=min(dpi+1,1,dpi,1+1+costi+1,0);dpi,0→dpi+1,1 — because the cost of this transition is always 2 (the distance between these cells is 2), we just go firstly to the right and then down (to ensure that we eat the figure in the first row). So the transition is dpi+1,1=min(dpi+1,1,dpi,0+2);dpi,1→dpi+1,1 — same as the previous transition, dpi+1,0=min(dpi+1,0,dpi,1+2).Time complexity: O(n).

Solution (vovuh)1680F - Lenient Vertex Cover

Idea: BledDest

Tutorial1680F - Lenient Vertex CoverLet's think about why we can't always make a perfect vertex cover — such a vertex cover that each edge has exactly one endpoint in it. Or why the answer can not exist at all.

Consider a bamboo. It's always possible to find a perfect vertex cover. Just choose every other vertex in it and account for parity.

Make a bamboo into a loop. Now you can see that an even length loop has a perfect vertex cover. An odd length doesn't.

That tells us that each odd length loop in a graph will have a bad edge on it. Odd length loops should instantly make you think about bipartite colorings.

So we can see that a bipartite graph always has a perfect vertex cover. Just choose one of the parts into a cover, and each edge will have exactly one endpoint in it. At the same time, a non-bipartite graph never has a perfect cover.

So our general goal is to remove (basically, mark as bad) at most one edge in such a way that the remaining graph is bipartite.

Consider a dfs tree of the graph, colored bipartitely. Every edge in the tree is good (has endpoints in different parts). Every edge outside the tree can be either good or bad. What happens to the tree if we remove an edge?

If we remove an edge outside the dfs tree, then nothing happens to it. So if there is no more than one bad edge outside the tree, then we found the answer. That was the easy part.

Now what happens if we remove an edge from the tree? The back edges from the subtree of the edge can force the subtree to either remain colored the same or flip all its colors. We don't really care if it remains the same, because we already took care of it in the first part. So let's pretend it always flips the colors.

Thus, all edges that go from the subtree upwards above the removed edge, have only one of their endpoints colors changed. Good edges turn bad, bad edges turn good.

All other edges don't change.

So you should choose such an edge to remove that all bad edges in the graph go from its subtree upwards above that edge and no good edges go from its subtree upwards above that edge.

That can be calculated with a dfs. Since all non-tree edges in the dfs tree are back edges, you can simply increment a counter on the bottom vertex, decrement the counter on the top vertex and collect sums from the bottom. The sum in the vertex will tell you the number of edges that start below or in the vertex and end above the vertex.

Do this for both kinds of edge and check the conditions for all vertices. Finally, choose such a part to be a vertex cover that the removed edge has both ends in it (if you choose the other part, that edge won't be covered at all).

The solution is linear, but the problem still requires a massive time and memory limit only because of recursion in the dfs.

Overall complexity: O(n+m) per testcase.

Solution (awoo)

Educational Codeforces Round 127 Editorial

By awoo, history, 10 months ago, translation, In English1671A - String Building

Idea: BledDest

Tutorial1671A - String BuildingEvery character in strings aa, aaa, bb and bbb has at least one character adjacent to it that is the same. So, if there is an isolated character in our string (a character that has no neighbors equal to it), we cannot build it.

It's easy to see that in the other case, we can build the string: we can split it into blocks of consecutive equal characters, and since there are no isolated characters, each block will have at least 2 characters, so it can be formed from strings of length 2 and/or 3 consisting of equal characters.

So, the problem is reduced to checking if each character has a neighbor equal to it.

Solution (BledDest)1671B - Consecutive Points Segment

Idea: vovuh

Tutorial1671B - Consecutive Points SegmentWe can see that the answer is YES if and only if there are no more than two gaps of length 1 between the given points. If there is no gap, the answer is obviously YES. If there is only one gap of length 1, we can just move the left (or the right) part of the set to this gap. When there are two gaps, we can move the part before the first gap to the right and the part after the second gap to the left. Of course, if there is a gap of length at least 3 (or multiple gaps with the total length 3), we can't move the points from the left and the right part to satisfy the middle gap.

Time complexity: O(n).

Solution (vovuh)1671C - Dolce Vita

Idea: vovuh and BledDest

Tutorial1671C - Dolce VitaFirstly, note that if we want to buy as many packs as possible, then it's optimal to buy the cheapest packs. In other words, if we sort all packs, we'll always buy a prefix of array a.

Next, note that each day we buy some number of packs i∈[1,n], so, instead of iterating through the days, we can iterate through the number of packs i and for each i calculate the number of days we'll buy exactly i packs.

Since the prices increasing and at day k+1 the price is ai+k, then exists last day ki+1 such that as days 1,2,…,ki+1 we could buy i packs and at days ki+2,ki+3,… we can't. And we can find ki as maximum possible integer solution to inequation (a1+ki)+⋯+(ai+ki)≤x or ki=⌊x−(a1+⋯+ai)i⌋.

We can calculate all ki using prefix sums a1+⋯+ai in linear time. As a result, we buy

n packs in days (0,k1+1]; n⋅(k1+1) in total;n−1 packs in days (k1+1,k2+1]; (n−1)⋅(k2−k1) in total;n−2 packs in days (k2+1,k3+1]; (n−2)⋅(k3−k2) in total and so on.The resulting complexity is O(nlogn) because of sort.

Solution (adedalic)1671D - Insert a Progression

Idea: vovuh and BledDest

Tutorial1671D - Insert a ProgressionObserve the cost of inserting a single element. Notice that inserting any value between the minimum of the sequence and the maximum of the sequence is free.

Why is this true? The argument is similar to the algorithm of finding some x such that f(x)=0 for a continous function f if you know some x1 such that f(x1)<0 and x2 such that f(x2)>0.

As a more general idea, it's free to insert some value s into a segment [l;r] such that al≤s and s≤ar (WLOG assume al≤ar). Let's find the position that is free. If r−l=1, then you can insert s between al and ar, since it's free. Otherwise, you can choose an arbitrary position l<i<r. s will be either between ai and al or between ai and ar (or both of them). Descend into the one that holds to continue the search. Since the lenght decreases, at some point you will reach the segment of length 1.

How does that help? Well, you can insert 1 somewhere, then insert x somewhere. The rest of insertions will be free.

Now it's an algorithmic problem. First, consider all options to insert both 1 and x between the same pair of elements. Next, assume you insert 1 somewhere before x. Iterate from left to right, maintaning the lowest price to insert 1. Try to insert x at the current position and 1 into the cheapest position before it. Then update the lowest price for inserting 1. After you finish, reverse the sequence and solve the problem again — that will be the same as inserting x before 1.

Overall complexity: O(n) per testcase.

Solution (awoo)1671E - Preorder

Idea: BledDest

Tutorial1671E - PreorderIn terms of preorder strings, the operation "swap two children of some vertex" means "swap two substrings of equal length in some specific location". This operation can be inverted by applying it an additional time, so for every positive integer k, all of the strings of length 2k−1 are split into equivalence classes in such a way that two strings from the same class can be transformed into each other, and two strings from different classes cannot. For each vertex, the set of its possible preorder strings is one of these classes.

Let's calculate the answer for the problem recursively: let dpv be the number of preorder strings for the vertex v. For a leaf, the number of its preorder strings is 1. For a vertex x with children y and z, one of the two holds:

if the equivalence class for vertex y is different from the equivalence class for vertex z, then we have to pick a string from the class of vertex y, pick a string from the class of vertex z, and choose the order in which we take them. So, dpx=dpy⋅dpz+dpz⋅dpy=2⋅dpy⋅dpz;if the equivalence class for y is the same as the equivalence class for z, then swapping y and z doesn't do anything, so we pick a string from the equivalence class of y, and then a string from the equivalence class of z. So, dpx=dpy⋅dpz=dp2y.The only thing we don't know is how to determine if two vertices represent the same equivalence class. The model solution uses hashing for this, but there's a much simpler method: for each vertex v, let tv be the lexicographically smallest string that can be a preorder string of v. If a vertex x has children y and z, then tx=min(ty+sx+tz,tz+sx+ty), and we can calculate these strings recursively since the total length is O(n2n) — each of 2n−1 characters will be present in O(n) strings.

Solution (BledDest)1671F - Permutation Counting

Idea: BledDest

Tutorial1671F - Permutation CountingA lot of solutions which were written during the contest use Berlekamp-Messey or some other algorithms related to analyzing linear recurrences, but the model solution is based on other principles.

First of all, if the number of inversions is at most 11, it means that most elements of the permutation will stay at their own places, and those which don't stay at their places can't be too far away from them.

Let's denote a block [l,r] in a permutation as a segment of indices [l,r] such that:

all elements less than l are to the left of the block;all elements greater than r are to the right of the block;all elements from [l,r] belong to the block.Let's say that a block is non-trivial if it contains at least two elements.

Suppose we split a permutation into the maximum number of blocks. Then, for each block, we can see that:

if its length is b, it has at least b−1 inversions (to prove it, you can use the fact that the number of inversions is equal to the number of swaps of adjacent elements required to sort the permutation; and if we cannot split the block into other blocks, it means that we have to swap each pair of adjacent elements in it at least once to sort it)if the block is non-trivial, it has at least one i such that pi>pi+1.From these two facts, we can see that:

there will be at most 11 non-trivial blocks;there will be at most 22 elements in total belonging to non-trivial blocks;the maximum possible length of a block is 12.The main idea of the solution is to calculate the following dynamic programming: dpi,j,a,b is the number of ways to split j elements into i non-trivial blocks such that there are exactly b inversions in them and exactly a pairs pi>pi+1. Then, to get the answer for the test case "n k x", we can iterate on the number of non-trivial blocks and the number of elements in them, and choose the elements belonging to that blocks with a binomial coefficient.

The only thing that's left is how to calculate this dynamic programming efficiently. There are a few ways to do it, but the model solution uses a table cnta,b,c — the number of different non-trivial blocks of length a with b elements pi>pi+1 and c inversions — to handle transitions. This table is not very big, so you can run an exhaustive search for 2-3 minutes to calculate it and then just paste its results into the source code of your program. Note that you have to make sure that you consider only the blocks which cannot be split any further.

Solution (BledDest)

Educational Codeforces Round 126 Editorial

By awoo, history, 11 months ago, translation, In English1661A - Array Balancing

Idea: BledDest

Tutorial1661A - Array BalancingLet's look at our arrays a and b. Note that for any position p such that |ap−1−ap|+|bp−1−bp|>|ap−1−bp|+|bp−1−ap| we can always "fix it" by swapping all positions i from p to n. In that case, contribution from all i<p won't change, contribution of pair (p−1,p) will decrease and contribution from all i>p won't change again, since we swapped all of them.

It means that we already can use the following algorithm: while exists such p that |ap−1−ap|+|bp−1−bp|>|ap−1−bp|+|bp−1−ap| just swap all i from p to n. This solution works for O(n2) per test, that should be enough.

But we can optimize our approach by realizing that we can (instead of searching p each time) just go from 2 to n and fix pairs one by one: if |a1−a2|+|b1−b2|>|a1−b2|+|b1−a2| then swap a2 with b2; next, if |a2−a3|+|b2−b3|>|a2−b3|+|b2−a3| then swap a3 with b3 and so on. In such way, solution works in O(n).

Solution (adedalic)1661B - Getting Zero

Idea: adedalic

Tutorial1661B - Getting ZeroNote that 32768=215, so you can make any value equal to 0 by multiplying it by two 15 times, since (v⋅215)mod215=0. So, the answer for each value ai is at most 15.

Now, let's note that there is always an optimal answer that consists of: at first, add one cntAdd times, then multiply by two cntMul times — and cntAdd+cntMul is the minimum answer. In other words, let's just iterate over all cntAdd≤15 and cntMul≤15 and check that (v+cntAdd)⋅2cntMulmod32768=0. The answer is minimum cntAdd+cntMul among them.

To prove that it's optimal to add at first and only then to multiply, note that it's not optimal to add more than once after muptiplying (v→2v→2v+2 can be replaced by v→v+1→2(v+1)). So there is at most one +1 between two ⋅2, but it's not optimal to make even one +1 since we need to make v divisible by 215 and +1 break divisibility.

There are many other approaches to this task except this one: for example, since ai<32768 you can write bfs to find the shortest paths from 0 to all ai.

Solution (adedalic)1661C - Water the Trees

Idea: vovuh

Tutorial1661C - Water the TreesThe first observation we need to solve this problem: the required height is either max or max+1, where max is the maximum initial height of some tree. We don't need heights greater than max+1, because, for example, if the height is max+2, we can remove some moves and get the answer for the height max. The same thing applies to all heights greater than max+1. Why do we even need the height max+1? In some cases (like [1,1,1,1,1,1,2]) the answer for the height max+1 is better than the answer for the height max (in this particular case, it is 9 vs 11).

Now, we have two ways to solve the problem: either use some gross formulas, or just write a binary search on the answer. I won't consider the solution with formulas (but we have one), so let's assume we use binary search. Let the current answer be mid. Then let cnt1=⌈mid2⌉ be the number of +1 operations we can do and cnt2=⌊mid2⌋ be the number of +2 operations we can do. We can use +2 operations greedily and then just check if the number of +1 operations is sufficient to grow up the remaining heights.

Time complexity: O(nlogn) per test case.

Solution 1 (vovuh)Solution 2 (awoo)1661D - Progressions Covering

Idea: vovuh

Tutorial1661D - Progressions CoveringLet's solve the problem greedily. But not from the beginning, because if we solve it from the beginning, we can't be sure what option is more optimal for the next elements (e.g. for the second element it is not clear if we need to add 2 to it starting our segment from the first position or add 1 to it starting our segment from the second position). So, let's solve the problem from right to left, then anything becomes clearer.

Actually, let's operate with the array b and decrease its elements instead of using some other array. Let's carry some variables: sum, cnt and the array closed of length n (along with the answer). The variable sum means the value we need to subtract from the current element from currently existing progressions, cnt is the number of currently existing progressions, and closedi means the number of progressions that will end at the position i+1 (i.e. will not add anything from the position i and further to the left).

When we consider the element i, firstly let's fix sum (decrease it by cnt). Then, let's fix cnt (decrease it by closedi). Then, let's decrease bi by sum, and if it becomes less than or equal to zero, just proceed. Otherwise, the number by which we can decrease the i-th element with one progression, equals to el=min(k,i+1) (zero-indexed). Then the number of progressions we need to satisfy this element is need=⌈biel⌉. Let's add this number to the answer, increase sum by el⋅need, increase cnt by need, and if i−el≥0 then we need to end these progressions somewhere, so let's add need to closedi−el.

Time complexity: O(n).

Solution (vovuh)1661E - Narrow Components

Idea: BledDest

Tutorial1661E - Narrow ComponentsConsider the naive approach to the problem.

Cut off the columns directly and count the connected components. There are two main solutions to this problem: either DFS (or BFS) or DSU. I personally found the DSU method easier to adjust to the full problem.

So, to count connected components with DSU, you should do the following. Initialize the structure without edges: every free cell is its own connected component. Then add edges one by one. Each edge connects two cells either vertically or horizontally. When an edge connects different components, they merge, and the number of components decreases by one.

Thus, the number of components on a range of columns is the number of free cells on it minus the number of meaningful edges on it (the ones that will merge components if the algorithm is performed only on these columns — the spanning forest edges).

Let's try to adjust this algorithm to the full problem. It would be great if we could just calculate the spanning forest of the entire matrix, and then print the number of free cells minus the number of its edges on the segment. Unfortunately, it's not as easy as that. For components that lie fully in the segment, it works. However, if a component is split by a border of a segment, it can both stay connected or fall apart. If we determine its outcome, we can fix the answer.

There are probably a lot of ways to adjust for that, but I'll tell you the one I found the neatest to code. Let's add the edges into DSU in the following order. Go column by column left to right. First add all vertical edges in any order, then all horizontal edges to the previous column in any order.

If you start this algorithm at the first column, you will be able to answer all queries with l=1. Since the algorithm adds columns iteratively, the spanning forest it's building is correct after every column. So the answer for each query is indeed the number of cells minus the number of edges on the range.

Let's investigate the difference between starting at the first column and an arbitrary column l.

Look at the column l. If it contains 1 or 3 free cells or 2 that are adjacent, then the cells are always in the same component, regardless of what has been before column l. If there are no free cells, nothing to the left matters, too. This tells us that the spanning forest that the first algorithm has built, is correct for any queries that start in this l.

The only non-trivial case is when only rows 1 and 3 of the l-th column contain a free cell. Then we can't tell if the algorithm is correct or not, because these two cells can be in the same component already or not. Let's call this a "101" column.

Imagine you started processing from the leftmost column of the query, left to right to the rightmost column. Our previous observations tell us that once we encounter a column that is not a "101", the algorithm onwards will be correct. Until then, we only have some "101" columns to deal with.

We can add the part from the first non-"101" column onwards to the answer (the number of cells minus the number of edges). And then handle the prefix with some easy casework:

if the leftmost column is not "101", then add nothing;if all columns in the query are "101", then the answer is 2;if the first non-"101" column is "111", then add nothing (since the "101"s get merged into the component of this column);if the first non-"101" column is "000" or "010", then add 2 components (since neither row 1 nor row 3 is merged anywhere);otherwise, add 1 component.The number of free cells and edges on a segment can be precalculated with some prefix sums. The closest non-"101" column can also be precalculated with a linear algorithm.

Overall complexity: O(n⋅α(n)+q).

Solution (awoo)1661F - Teleporters

Idea: vovuh

Tutorial1661F - TeleportersInitial n+1 portals divide the path from 0 to an into n separate sections. If we place a new portal between two given ones, it only affects the section between these two portals.

Let's suppose we want to place k new portals into a section of length x. This will divide it into (k+1) sections, and it's quite easy to prove that these sections should be roughly equal in size (to prove it, we can show that if the sizes of two sections differ by more than 1, the longer one can be shortened and the shorter one can be elongated so the sum of squares of their lengths decreases). So, a section of length x should be divided into xmod(k+1) sections of length ⌈xk+1⌉ and (k+1)−xmod(k+1) sections of length ⌊xk+1⌋. Let's denote the total energy cost of a section of length x divided by k new portals as f(x,k); since we divide it in roughly equal parts, it's easy to see that

f(x,k)=(xmod(k+1))⋅(⌈xk+1⌉)2+((k+1)−xmod(k+1))⋅(⌊xk+1⌋)2The key observation that we need to make now is that f(x,k)−f(x,k+1)≥f(x,k+1)−f(x,k+2); i. e. if we add more portals to the same section, the energy cost change from adding a new portal doesn't go up. Unfortunately, we can't give a simple, strict proof of this fact, but we have faith and stress (this would be easy to prove if it was possible to place portals in non-integer points, we could just analyze the derivative, but in integer case, it's way more difficult).

Okay, what should we do with the fact that f(x,k)−f(x,k+1)≥f(x,k+1)−f(x,k+2) for a section of length x? The main idea of the solution is binary search over the value of f(x,k)−f(x,k+1); i. e., we use binary search to find the minimum possible change that a new portal would give us. Let's say that we want to check that using the portals that give the cost change ≥c is enough; then, for each section, we want to find the number of new portals k such that f(x,k−1)−f(x,k)≥c, but f(x,k)−f(x,k+1)<c; we can use another binary search to do that. For a fixed integer c, we can calculate not only the number of new portals that we can add if the cost change for each portal should be at least c, but also the total cost of the path after these changes; let's denote g(c) as the total cost of the path if we place new portals until the cost change is less than c, and h(c) is the number of portals we will place in that case.

We have to find the minimum value of c such that g(c)≤m. Now, it looks like h(c) is the answer, but this solution gives WA on one of the sample tests. The key observation we are missing is that, for the value c, we don't have to add all of the portals that change the answer by c; we might need only some of them. To calculate the answer, let's compute four values:

g(c+1);h(c+1);g(c);h(c).If we place h(c+1) portals and add new portals one by one, until the total cost becomes not greater than m, the cost change from each new portal will be equal to g(c+1)−g(c)h(c)−h(c+1) (or just c if we consider the fact that we start using the portals which change the cost by c). So, we can easily calculate how many more additional portals we need to add if we start from h(c+1) portals and cost g(c+1).

The total complexity of our solution is O(nlog2A): we have a binary search over the cost change for each new portal; and for a fixed cost change, to determine the number of portals we place in each section, we run another binary search in every section separately.

Solution (BledDest)

Educational Codeforces Round 125 Editorial

By awoo, history, 11 months ago, translation, In English1657A - Integer Moves

Idea: BledDest

Tutorial1657A - Integer MovesNote that the answer does not exceed 2, because the chip can be moved as follows: (0,0)→(x,0)→(x,y). Obviously, in this case, both operation are valid. It remains to check the cases when the answer is 0 or 1. The answer is 0 only if the destination point is (0,0), and the answer is 1 if x2+y2−−−−−−√ is integer.

Solution (Neon)1657B - XY Sequence

Idea: adedalic

Tutorial1657B - XY SequenceStrategy is quite easy: we go from a1 to an and if ai−1+x≤B we take this variant (we set ai=ai−1+x); otherwise we set ai=ai−1−y. Note that all ai are in range [−(x+y),B] so there won't be any overflow/underflow.

It's also not hard to prove that this strategy maximizes the sum. By contradiction: suppose the optimal answer has some index i where ai−1+x≤B but ai=ai−1−y. Let's find first position j≥i where aj=aj−1+x and swap operations between i and j. As a result, B≥ai>ai+1>⋯>aj, all ai from [i,j−1] were increased while aj remained the same, i. e. there is no violation of the rules and the total sum increased — contradiction.

Solution (adedalic)1657C - Bracket Sequence Deletion

Idea: BledDest

Tutorial1657C - Bracket Sequence DeletionConsider the first character of the string. If it is '(', then we can remove the first two characters of the string and continue (because the prefix of length 2 will be either a palindrome or a regular bracket sequence). If the first character of the string is ')' then this is a bad case. Of course, the regular bracket sequence can't start with '(', so this prefix should be a palindrome. And what is the shortest palindrome we can get with the first character ')'? It is the closing bracket ')', then some (possibly, zero) amount of opening brackets '(', and another one closing bracket. We can see that we can't find a palindrome shorter than this one because we have to find a pair for the first character. So, if the first character of the string is ')', then we just remove anything until the next character ')' inclusive. To not remove any characters explicitly, we can just use pointers instead. And the last thing is to carefully handle cases when we can't do any operations.

Solution (vovuh)1657D - For Gamers. By Gamers.

Idea: BledDest

Tutorial1657D - For Gamers. By Gamers.Imagine you are fighting the j-th monster, and you fixed the type of units i and their amount x.

What's the win condition? Hjdi⋅x<hiDj. Rewrite it as Hj⋅Dj<di⋅x⋅hi. Notice how we only care about d⋅h for both the units and the monster, but not about d and h on their own.

Let's call d⋅h⋅x and D⋅H the power of the squad and the monster.

You can see that for each cost c we can only leave one unit type of that price that has the largest value of d⋅h. Let's call it bstc.

Now let's learn to determine the maximum power we can obtain for cost exactly c. We can iterate over the cost c of one unit and the count x of units in the squad. Since c⋅x should not exceed C, that will take C1+C2+⋯+CC=O(ClogC). Propagate bstc to be the maximum power for cost exactly c.

We have the knowledge about cost exactly c, but we actually want no more than c. Calculate prefix maximums over bst — that will be the maximum power we can obtain with no more than c coins.

For each monster, we just have to find the smallest c such that bstc>D⋅H. Since the array is monotone, we can use binary search.

Overall complexity: O(n+(C+m)logC).

Solution (awoo)1657E - Star MST

Idea: BledDest

Tutorial1657E - Star MSTLet the weight of the edge between the vertex x to the vertex y be wx,y.

Suppose there exists a pair of vertices x and y (with indices greater than 2) such that wx,y<w1,x or wx,y<w1,y. Then, if we choose the spanning tree with all vertices connected to 1, it won't be an MST: we can remove either the edge (1,x) or the edge (1,y), add the edge (x,y) instead, and the cost of the spanning tree will decrease. So, we should have wx,y≥max(w1,x,w1,y) for every pair (x,y).

It can be shown that this condition is not only necessary, but sufficient as well: if for every pair (x,y) the condition wx,y≥max(w1,x,w1,y) holds, the MST can't have the weight less than ∑i=2nw1,i. We can prove this by induction (suppose that w1,2≤w1,3≤…≤w1,n for simplicity):

in the spanning tree, there should be at least one edge incident to vertex n, and its weight is at least w1,n;there should be at least two edges incident to vertices n and n−1, and their weights are at least w1,n−1+w1,n;...;there should be at least n−1 edges incident to vertices from 2 to n, and their weights are at least ∑i=2nw1,i.Okay, now let's show how to calculate the number of such graphs. We can run the following dynamic programming: let dpi,j be the number of graphs where we have already connected i vertices to the vertex 1, and the maximum weight we have used is j. We start with dp0,0, and for each transition from dpi,j, we will iterate on the number of vertices we connect to the vertex 1 with edges with weight (j+1) (let the number of those vertices be t), choose them with a binomial coefficient (n−1−i)!t!(n−1−i−t)!, and also choose the weights for the edges that connect one of the chosen vertices with one of the vertices already connected to 1 (since for each of those edges, we know that their weights should be in [j+1,k]) — so, we need to multiply the value in transition by (k−j)e, where e is the number of such edges.

Implementing this dynamic programming can be done in O(n2k) or O(n2klogn), both are sufficient.

Solution (awoo)1657F - Words on Tree

Idea: BledDest

Tutorial1657F - Words on TreeLet's design a naive solution first. For each of the given triples, we have two options: either write the string on the tree in the order from xi to yi, or in reverse order. Some options conflict with each other. So, we can treat this problem as an instance of 2-SAT: create a variable for each of the given strings, which is true if the string is not reversed, and false if it is reversed; find all conflicting pairs of options and then run the usual algorithm for solving 2-SAT.

Unfortunately, the number of conflicting pairs can be up to O(n2), so we need to improve this solution. Let's introduce a variable for each vertex of the tree which will define the character we write on it. At first, it looks like we can't use these variables in 2-SAT, since the number of possible characters is 26, not 2. But if a vertex is covered by at least one path in a triple, then there are only two possible characters we can write in this vertex: either the character which will land on this position if we write the string from xi to yi, or the character on the opposite position in the string si. And, obviously, if a vertex is not covered by any triple, we can write any character on it.

Okay, now for each vertex i, we have two options for a character: ci,1 and ci,2. Let the variable pi be true if we write ci,1 on vertex i, and false if we write ci,2. Also, for each triple j, let's introduce a variable wj which is true if the string sj is written from xj to yj, and false if it is written in reversed order. If the vertex i is the k-th one on the path from xj to yj, then we should add the following constraints in our 2-SAT:

if sj,k≠ci,1, we need a constraint "NOT pi OR NOT wj";if sj,k≠ci,2, we need a constraint "pi OR NOT wj";if sj,|sj|−k+1≠ci,1, we need a constraint "NOT pi OR wj";if sj,|sj|−k+1≠ci,2, we need a constraint "pi OR wj".Thus, we add at most 16⋅105 constraints in our 2-SAT. The only thing we haven't discussed is how to actually restore each path from xj to yj; this can be done either with any fast algorithm that finds LCA, or by searching for LCA "naively" by ascending from one of those vertices until we arrive at the ancestor of another vertex; this approach will visit at most ∑j=1q|sj| vertices.

Overall, this solution runs in O(n+q+∑j=1q|sj|).

Solution (awoo)

Educational Codeforces Round 124 Editorial

By awoo, history, 12 months ago, translation, In English1651A - Playoff

Idea: BledDest

Tutorial1651A - PlayoffDuring the first stage, every player with an even index competes against a player with an odd index, so in each match during the first stage, the player whose index is smaller wins. The pairs are formed in such a way that, in each pair, the player with an odd index has smaller index, so all players with even indices get eliminated, and all players with odd indices advance to the next stage.

All of the remaining matches are between players with odd indices, so the winner of each match is the player with the larger index. So, the overall winner of the tournament is the player with the greatest odd index, which is 2n−1.

Note: in some languages (for example, C++), standard power functions work with floating-point numbers instead of integers, so they will produce the answer as a floating-point number (which may lead to wrong formatting of the output and/or calculation errors). You might have to implement your own power function that works with integers, or compute 2n using a loop.

Solution (BledDest)1651B - Prove Him Wrong

Idea: adedalic

Tutorial1651B - Prove Him WrongSuppose the initial sum of a is equal to S. If we perform the operation, the new sum will be equal to S′=S−(ai+aj)+2|ai−aj|. We want the sum not to decrease, or S′≥S. If ai≥aj, we will get:S′≥S,S−(ai+aj)+2(ai−aj)≥S,ai−3aj≥0,ai≥3aj.If ai≤aj we'll get 3ai≤aj analogically.

In other words, array a you need (if sorted) will have a2≥3a1, a3≥3a2 and so on. And one of the variants (and, obviously, an optimal one) is just [1,3,9,27,…,3n−1].

As a result, since ai≤109, we just need to check: if 3n−1≤109 then we found an answer, otherwise there is no counterexample.

Solution (awoo)1651C - Fault-tolerant Network

Idea: adedalic

Tutorial1651C - Fault-tolerant NetworkThere is a criterion when the given network becomes fault-tolerant: the network becomes fault-tolerant if and only if each of corner computers (let's name them A1, An, B1 and Bn) is connected to the other row.

From the one side: if, WLOG, A1 is not connected to other row then if A2 is broken — A1 loses connection to the other network (since A1 is connected only with A2).

From the other side: suppose, WLOG, Ai is broken, then the row A is falling in at most two parts: A1−⋯−Ai−1 and Ai+1−⋯−An. But since both A1 and An are connected to row B and B is still connected, then the resulting network is still connected.

Now the question is: how to connect all corner computers? Because sometimes it's optimal not to connect corners directly. One of the approaches is described below.

Let's look at A1. Essentially, there are three ways to connect it to row B: to B1, Bn or bestB(A1) (where bestB(A1) is Bj with minimum possible |ai−bj|). The same applies to An.

So, let's just iterate over all these 3×3 variants. For each of these variants,

if we didn't cover B1 then we should also add one more connection between B1 and bestA(B1);if we didn't cover Bn then we should also add one more connection between Bn and bestA(Bn);As a result, we choose the best variant.

Solution (adedalic)1651D - Nearest Excluded Points

Idea: BledDest

Tutorial1651D - Nearest Excluded PointsFirstly, we can find answers for all points that are adjacent to at least one point not from the set. The distance for such points is obviously 1 (and this is the smallest possible answer we can get). On the next iteration, we can set answers for all points that are adjacent to points with found answers (because they don't have neighbors not from the set, the distance for them is at least 2). It doesn't matter which point we will take, so if the point i is adjacent to some point j that have the answer 1, we can set the answer for the point i as the answer for the point j. We can repeat this process until we find answers for all points. In terms of the code, this can be done by breadth first search (BFS). In other words, we set answers for the points that have the distance 1 and then push these answers to all adjacent points from the set in order of the increasing distance until we find all the answers.

Time complexity: O(nlogn).

Solution (vovuh)1651E - Sum of Matchings

Idea: BledDest

Tutorial1651E - Sum of MatchingsInstead of counting the edges belonging to the maximum matching, it is easier to count the vertices. So, we will calculate the total number of vertices saturated by the maximum matching over all possible tuples (l,r,L,R), and then divide the answer by 2. Furthermore, it's easier to calculate the number of unsaturated vertices than the number of saturated vertices, so we can subtract it from the total number of vertices in all graphs we consider and obtain the answer.

Let's analyze how to calculate the total number of unsaturated vertices. Each graph G′(l,r,L,R) is a subgraph of the given graph, so it is still bipartite, and the degree of each vertex is still not greater than 2. A bipartite graph where the degree of each vertex is at most 2 can be represented as a set of cycles and paths, and the maximum matching over each of these cycles/paths can be considered independently. Each cycle has an even number of vertices (since otherwise the graph would not be bipartite), so we can saturate all vertices on a cycle with the matching. For a path, the number of unsaturated vertices depends on its length: if the number of vertices in a path is even, we can match all vertices on it; otherwise, one vertex will be unsaturated. So the problem reduces to counting paths with odd number of vertices in all possible graphs G′(l,r,L,R).

Every path with an odd number of vertices has a center (the vertex which is exactly in the middle of the path). Let's iterate on the center of the path and its length, and calculate the number of times this path occurs in all graphs we consider. Suppose the center of the path is the vertex x, and the number of vertices in it is 2k+1. Then, for this path to exist, two conditions must hold:

every vertex y such that the distance from x to y is not greater than k should be present in the graph;every vertex z such that the distance from x to z is exactly k+1 should be excluded from the graph.It means that, for each of the two parts of the graph, there are several vertices that should be present in the graph, and zero or two vertices that should be excluded from the graph. It's easy to see that among the vertices we have to include, we are only interested in the minimum one and the maximum one (all vertices between them will be included as well if these two are included). So, we need to implement some kind of function that allows us to calculate the number of segments that cover the minimum and the maximum vertex we need, and don't cover any of the vertices that we have to exclude — this can be easily done in O(1). Note that the segments should be considered independently for both parts of the graph.

Overall, for each vertex we have to consider at most O(n) different lengths of odd paths with the center in this vertex. The minimum/maximum indices of vertices in both parts we have to include in the graph can be maintained while we increase the length of the path, so the whole solution works in O(n2).

Solution (BledDest)1651F - Tower Defense

Idea: BledDest

Tutorial1651F - Tower DefenseLet's start thinking about the problem from the easy cases.

How to solve the problem fast if all towers have full mana? We can store prefix sums of their capacities and find the first tower that doesn't get drained completely with a binary search.

Let's try the opposite. How to solve the problem fast if all towers were drained completely in the previous second? It's the same but the prefix sums are calculated over regeneration rates.

What if all towers were drained at the same second, earlier than the previous second, and no tower is fully restored yet? It's also the same but the regeneration rates are multiplied by the time passed since the drain.

What if we drop the condition about the towers not being fully restored? How would a data structure that can answer prefix sum queries work? It should store the total mana capacity of all towers that are full. Then mana regeneration rates for all towers that aren't. If these are kept separately, then it's easy to obtain the prefix sum by providing the time passed. This will be total capacity plus total regeneration rate, multiplied by the time passed.

How to determine if the tower is fully restored since the drain or not? That's easy. For each tower, we can calculate the number of seconds it takes it to get restored from zero. That is ⌈cr⌉. Thus, all towers that have this value smaller than the time passed won't get restored. All the rest will.

Unfortunately, in the actual problem, not all towers were last drained at the same time. However, it's possible to reduce the problem to that. Store the segments of towers that were drained at same time. There are also towers that weren't drained completely, but they can be stored as segments of length 1 too. When a monster comes, it drains some prefix of the towers completely and possibly one more tower partially. In terms of segments, it removes some prefix of the them and possibly cuts one. Then it creates a segment that covers the prefix and possibly a segment of length 1 (with a partially drained tower). So each monster creates O(1) segments and removes no more segments than were created. Thus, if we were to process each creation and removal in some O(T), then the complexity will be O(qT).

All towers on each segment have the same time passed since the drain. We want to query the sum on the entire segment. If it is greater than the remaining health of the monster, we want to find the largest prefix of this segment that has a smaller or equal sum than the monster health.

Given time passed, let's learn to query the range sum. If we knew the queries beforehand, it would be easy. Initialize a segment tree as if all towers are completely restored. Then make events of two kinds: a tower with restore time ⌈cr⌉ and a query with time t. Sort them in the decreasing order and start processing one by one. When a tower event happens, update a single position in the segment tree from capacity to regeneration rate. When a query event happens, find the sum.

Since the queries are not known beforehand, make that segment tree persistent and ask specific versions of it. If a segment of towers was last drained at time tlst, and the query is at time t, then you should query the segment tree in version t−tlst. Obviously, you can store not all versions but only ones that have some tower change. Moreover, it's more convenient to make one version responsible for one tower update. Then you can lower_bound the array of sorted ⌈cr⌉ to find the version you want to ask at.

To determine the largest prefix of this segment that has a smaller or equal sum than the monster health, you can either binary search for O(log2n) or traverse the segment tree for O(logn). The time limit might be a little tight for the first approach, but it can still pass.

Overall complexity: O((n+q)logn).

Solution (awoo)

Educational Codeforces Round 123 Editorial

By awoo, history, 12 months ago, translation, In English1644A - Doors and Keys

Idea: BledDest

Tutorial1644A - Doors and KeysThe necessary and sufficient condition is the following: for each color the key should appear before the door.

Necessary is easy to show: if there is a key after a door, this door can't be opened.

Sufficient can be shown the following way. If there are no closed doors left, the knight has reached the princess. Otherwise, consider the first door the knight encounters. He has a key for this door, so he opens it. We remove both the key and the door from the string and proceed to the case with one less door.

Overall complexity: O(1).

Solution (awoo)1644B - Anti-Fibonacci Permutation

Idea: BledDest

Tutorial1644B - Anti-Fibonacci PermutationLet's consider one of the possible solutions. Let's put the first element in the x-th permutation equal to x, and sort all the other elements in descending order. Thus, we get permutations of the form: [1,n,n−1,…,2], [2,n,n−1,…,1], ..., [n,n−1,n−2,…,1]. In such a construction pi−1>pi for all i (3≤i≤n), and hence pi−2+pi−1>pi.

Solution (Neon)1644C - Increase Subarray Sums

Idea: BledDest

Tutorial1644C - Increase Subarray SumsConsider the naive solution.

Iterate over k. Then iterate over the segment that will have the maximum sum. Let its length be l. Since x is non-negative, it's always optimal to increase the elements inside the segment. So if k≤l, then the sum of the segment increases by k⋅x. Otherwise, only the elements inside the segment will affect the sum, thus, it will increase by l⋅x. That can be written as min(k,l)⋅x.

Notice that we only care about two parameters for each segment. Its length and its sum. Moreover, if there are several segments with the same length, we only care about the one with the greatest sum.

Thus, the idea of the solution is the following. For each length, find the segment of this length with the greatest sum. Then calculate f(k) in O(n) by iterating over the length of the segment.

Overall complexity: O(n2) per testcase.

Solution (awoo)1644D - Cross Coloring

Idea: BledDest

Tutorial1644D - Cross ColoringLet's take a look at a final coloring. Each cell has some color. There exist cells such that there were no operation in their row and their column. They are left white, and they don't affect the answer.

All other cells are colored in one of k colors. For each cell (x,y) there is a query that has been the last one to color this cell (it covered row x, column y or both of them). So all cells that have the same query as the last one will have the same color. Since the color for each query is chosen independently, the number of colorings will be k to the power of the number of queries that have at least one cell belong to them.

How to determine if a query has at least one cell. This is true unless one of these things happen afterwards:

both its row and its column are recolored;all rows are recolored;all columns are recolored.So the solution is to process the queries backwards. Maintain the set of colored rows and colored columns. For each query, check the conditions. If none hold, multiply the answer by k.

Overall complexity: O(qlog(n+m)) or O(q) per testcase.

Solution 1 (awoo)Solution 2 (awoo)1644E - Expand the Path

Idea: BledDest

Tutorial1644E - Expand the PathFirst, get rid of the corner cases. If the string doesn't contain either of the letters, the answer is n.

The general solution to the problem is to consider every single way to modify the path, then find the union of them. Well, every single path is too much, let's learn to reduce the number of different sequences of modifications that we have to consider.

The main observation is that all cells that the robot can visit are enclosed in the space formed by the following two paths:

the first 'R' is duplicated the maximum number of times, then the last 'D' is duplicated the maximum number of times;the first 'D' is duplicated the maximum number of times, then the last 'R' is duplicated the maximum number of times.You can realize that by drawing the visited cells for some large test.

To show that more formally, you can consider the visited cells row by row. Let's show that for every two different visited cells in the same row, all cells in-between them can also be visited.

In general case, we want to show that we can take the prefix of the path to the left one of these cells and duplicate any 'R' on it to reach the right cell. The suffixes of the paths will remain the same as in the initial path.

If there exists an 'R' on the prefix, then we are good. Otherwise, the reason that it doesn't exist is that we duplicated 'D' too many times. Reduce that and there will be 'R' immediately after reaching the cell or earlier.

We should also show that the number of 'R's on the path to the left cell won't reach the maximum allowed amount until reaching the right cell. Use the fact that the number of 'D's on both prefixes of the paths is the same.

The other non-obvious part is that you can't reach cells outside this space. However, that can also be shown by analyzing each row independently.

Finally, about the way to calculate the area of this space. The main idea is to calculate the total number of cells outside this area and subtract it from n2.

Notice that non-visited cells form two separate parts: the one above the first path and the one to the left of the second path. These are pretty similar to each other. Moreover, you can calculate them with a same function. If we replace all 'D's in the string with 'R' and vice versa, then these parts swap places. So we can calculate the upper part, swap them and calculate it again.

I think the algorithm is best described with a picture. Consider test n=15, s= DDDRRDRRDDRRR, for example.

First, there are some rows that only have one cell visited. Then the first 'R' in the string appears. Since we duplicate it the maximum amount of times, it produces a long row of visited cells. The remaining part of the part becomes the outline of the area.

Note that the row that marks the end of the string, always ends at the last column. Thus, only at most first |s| rows matter. To be exact, the amount of rows that matter is equal to the number of letters 'D' in the string.

For each letter 'D', let's calculate the number of non-visited cells in a row it goes down to.

I found the most convenient way is to go over the string backwards. We start from the row corresponding to the number of letters 'D' in the string. It has zero non-visited cells. We can maintain the number of non-visited cells in the current row. If we encounter an 'R' in the string, we add 1 to this number. If we encounter a 'D', we add the number to the answer.

We have to stop after the first 'R' in the string. The later (well, earlier, since we are going backwards) part corresponds to the prefix of letters 'D' — the starting column on the picture.

Each of these rows have 1 visited cell, so n−1 non-visited. So we can easily calculate this part as well.

Overall complexity: O(|s|) per testcase.

Solution (awoo)1644F - Basis

Idea: BledDest

Tutorial1644F - BasisFirst of all, since the second operation changes all occurrences of some number x to other number y and vice versa, then, by using it, we can convert an array into another array if there exists a bijection between elements in the first array and elements in the second array. It can also be shown that F(G(a,x,y),m)=G(F(a,m),x,y), so we can consider that if we want to transform an array into another array, then we first apply the function F, then the function G.

Another relation that helps us is that G(G(a,x,y),x,y)=a, it means that every time we apply the function G, we can easily rollback the changes. Considering that we have already shown that a sequence of transformations can be reordered so that we apply G only after we've made all operations with the function F, let's try to "rollback" the second part of transformations, i. e. for each array, find some canonical form which can be obtained by using the function G.

Since applying the second operation several times is equal to applying some bijective function to the array, we can treat each array as a partition of the set {1,2,…,n} into several subsets. So, if we are not allowed to perform the first operation, the answer to the problem is equal to ∑i=1min(n,k)S(n,i), where S(n,i) is the number of ways to partition a set of n objects into i non-empty sets (these are known as Stirling numbers of the second kind). There are many ways to calculate Stirling numbers of the second kind, but in this problem, we will have to use some FFT-related approach which allows getting all Stirling numbers for some value of n in time O(nlogn).

For example, you can use the following relation:

S(n,k)=1k!∑i=0k(−1)i(ki)(k−i)nS(n,k)=∑i=0k(−1)i⋅k!⋅(k−i)nk!⋅i!⋅(k−i)!S(n,k)=∑i=0k(−1)ii!⋅(k−i)n(k−i)!If we substitute pi=(−1)ii! and qj=jnj!, we can see that the sequence of Stirling numbers for some fixed n is just the convolution of sequences p and q.

For simplicity in the following formulas, let's denote Ai=∑j=1min(i,k)S(i,j). We now know that this value can be calculated in O(ilogi).

Okay, now back to the original problem. Unfortunately, we didn't take the operation F into account. Let's analyze it.

The result of function F(a,m) consists of several blocks of equal elements, and it's easy to see that the lengths of these blocks (except for maybe the last one) should be divisible by m. The opposite is also true — if the lengths of all blocks (except maybe for the last one) are divisible by some integer m, then the array can be produced as F(a,m) for some array a.

What does it mean? If the greatest common divisor of the lengths of the blocks (except for the last one) is not 1, the array that we consider can be obtained by applying the function F to some other array. Otherwise, it cannot be obtained in such a way. Now, inclusion-exclusion principle comes to the rescue.

Let's define Bi as the number of arrays that we consider which have the lengths of all their blocks (except maybe for the last one) divisible by i. It's easy to see that Bi=A⌈ni⌉ (we can compress every i consecutive elements into one). Then, using inclusion exclusion principle, we can see that the answer is

∑i=1nμ(i)Bi=∑i=1nμ(i)A⌈ni⌉,

where μ(i) is the Mobius function. Using this formula, we can calculate the answer in O(nlog2n).

Note 1. This inclusion-exclusion principle handles the arrays according to the GCD of the blocks that they consist of, except for the last one. But what if the array consists only of one block? These arrays can be counted wrongly, so we should exclude them — i. e. use Ai−S(i,1) instead of just Ai and count the arrays consisting of the same element (if we need any of them in the answer separately).

Note 2. Depending on the way you implement this, n=1 or k=1 (or both) may be a corner case.

Educational Codeforces Round 122 — Editorial

By BledDest, 13 months ago, In English1633A - Div. 7

Idea: BledDest, preparation: BledDest

Tutorial1633A - Div. 7A lot of different solutions can be written in this problem. The model solution relies on the fact that every 7-th integer is divisible by 7, and it means that there is always a way to change the last digit of n (or leave it unchanged) so that the result is divisible by 7. So, if n is already divisible by 7, we just print it, otherwise we change its last digit using some formulas or iteration on its value from 0 to 9.

Solution (BledDest)1633B - Minority

Idea: BledDest, preparation: awoo and Neon

Tutorial1633B - MinorityLet's try to estimate the maximum possible answer. Best case, you will be able to remove either all zeros or all ones from the entire string. Whichever has the least occurrences, can be the answer.

If the amounts of zeros and ones in the string are different, this bound is actually easy to reach: just choose the substring that is the entire string.

If the amounts are the same, the bound is impossible to reach. Choosing the entire string will do nothing, and asking a smaller substring will decrease the answer.

The smallest we can decrease the answer by is 1. If you choose the substring that is the string without the last character, you will decrease one of the amounts by one. That will make the amounts different, and the bound will be reached.

Overall complexity: O(|s|) per testcase.

Solution (awoo)1633C - Kill the Monster

Idea: BledDest, preparation: Neon

Tutorial1633C - Kill the MonsterFirst of all, let's understand how to solve the problem without upgrades. To do this, it is enough to compare two numbers: ⌈hMdC⌉ and ⌈hCdM⌉ — the number of attacks that the character needs to kill the monster and the number of attacks that the monster needs to kill the character, respectively. So, if the first number is not greater than the second number, then the character wins.

Note that the number of coins is not very large, which means we can iterate over the number of coins that we will spend on weapon upgrades, and the remaining coins will be spent on armor upgrades. After that, we can use the formula described above to check whether the character will win.

The complexity of the solution is O(k).

Solution (awoo)1633D - Make Them Equal

Idea: BledDest, preparation: Neon

Tutorial1633D - Make Them EqualLet's calculate di — the minimum number of operations to get the number i from 1. To do this, it is enough to use BFS or dynamic programming. Edges in the graph (transitions in dynamic programming) have the form (i,i+⌊ix⌋) for all 1≤x≤i.

Now the problem itself can be reduced to a knapsack problem: there are n items, i-th item weighs dbi and costs ci, you have to find a set of items with the total weight of no more than k of the maximum cost. This is a standard problem that can be solved in O(nk), but it is too slow (although some participants passed all the tests with such a solution). However, we can notice that the values of di should not grow too fast, namely, the maximum value of di for 1≤i≤103 does not exceed 12. This means that the maximum possible weight is no more than 12n, and we can limit k to this number (i. e. make k=min(k,12n)).

Solution (Neon)1633E - Spanning Tree Queries

Idea: BledDest, preparation: awoo

Tutorial1633E - Spanning Tree QueriesConsider a naive solution using Kruskal's algorithm for finding MST. Given some x, you arrange the edges in the increasing order of |wi−x| and process them one by one.

Look closely at the arrangements. At x=0 the edges are sorted by wi. How does the arrangement change when x increases? Well, some edges swap places.

Consider a pair of edges with different weights w1 and w2 (w1<w2). Edge 1 will go before edge 2 in the arrangement as long as x is closer to w1 than w2. So for all x up to w1+w22, edge 1 goes before edge 2. And for all x from w1+w22 onwards, edge 2 goes before edge 1.

This tells us that every pair of edge with different weights will swap exactly once. So there will be at most O(m2) swaps. Which is at most O(m2) different arrangements. Each of them corresponds to some range of x's.

We can extract the ranges of x's for all arrangements and calculate MST at the start of each range. We can also find the arrangement that corresponds to some x from a query with a binary search.

However, only knowing the weight of the MST at the start of the range is not enough. The weights of edges change later in the range, and we can't predict how. Some edges have their weight increasing, some decreasing.

First, let's add more ranges. We want each edge to behave the same way on the entire range: either increase all the way or decrease all the way. If we also add x=wi for all i into the MST calculation, this will hold.

Second, let's store another value for each range: the number of edges that have their weight increasing on it. With that, we can easily recalculate the change in the cost of the spanning tree.

The TL should be free enough for you to sort the edges for each MST calculation, resulting in O(m2(mlogm+nlogn)+klogm) solution. You can also optimize the first part to O(m3).

Solution (awoo)1633F - Perfect Matching

Idea: BledDest, preparation: BledDest

Tutorial1633F - Perfect MatchingLet's root the tree at vertex 1 and try to analyze when a tree contains a perfect matching. If we want to find the maximum matching in a tree, we can use some greedy approaches like "take a leaf of the tree, match it with its parent and remove both vertices, repeat this process until only isolated vertices remain". If we are interested in a perfect matching, then this process should eliminate all of the vertices.

Let's modify this process a bit by always picking the deepest leaf. If there exists a perfect matching, picking the deepest leaf will ensure that the tree always remains a tree and doesn't fall apart, i. e. there will always be one connected component. It means that when we remove the leaf with its parent, this leaf is the only descendant of its parent.

It's easy to see that whenever we remove a pair of vertices in this process, for each remaining vertex, the number of its descendants is either left unchanged or decreased by 2. It means that if a vertex has an even number of descendants, it will have an even number of descendants until it is removed, and the same for odd number of descendants.

Let's call the vertices with even number of descendants (including the vertex itself) even vertices, and all the other vertices — odd vertices. A vertex cannot change its status in the process of building the perfect matching. Each leaf is and odd vertex, and if its parent has only one child, this parent is an even vertex. So, when we remove a pair of vertices, one of them (the child) is odd, and the other of them (the parent) is even.

This leads us to another way of building the perfect matching: match each odd vertex with its parent, and make sure that everything is correct. Unfortunately, implementing it is O(n) per query, so we need something faster. We can see that each even vertex has at least one odd child (because if all children of a vertex are even, then the number of its descendants, including the vertex itself is odd). In order to find a perfect matching, we have to make sure that:

each even vertex has exactly one odd child;each odd vertex has an even vertex as its parent.All this means is that the number of even vertices should be equal to the number of odd vertices: it cannot be greater since each even vertex has at least one odd child, and if it is smaller, it's impossible to match the vertices. The perfect matching itself consists of edges that connect odd vertices with their parents.

Okay, now we need some sort of data structure to maintain the status of each vertex (and the sum of edges that lead to an odd vertex if directed from top to bottom). In our problem, we have to add new leaves to the tree (it happens when a vertex is activated), and this increases the number of descendants for every vertex on the path from the root to this new leaf. So, we need some sort of data structure that supports the operations "add a new leaf" and "flip the status of all vertices on a path". One of the structures that allow this is the Link/Cut Tree, but we can use the fact that the whole tree is given in advance to build a Heavy-Light Decomposition on it, which is much easier to code. Operations on segments of paths can be done with a lazy segment tree, and each vertex then will be added in O(log2n).

Solution (BledDest)

Educational Codeforces Round 121 Editorial

By awoo, history, 14 months ago, translation, In English1626A - Equidistant Letters

Idea: BledDest

Tutorial1626A - Equidistant LettersLet's consider a very special case of equal distances. What if all distances were equal to 1? It implies that if some letter appears exactly twice, both occurrences are placed right next to each other.

That construction can be achieved if you sort the string, for example: first right down all letters 'a', then all letters 'b' and so on. If a letter appears multiple times, all its occurrences will be next to each other, just as we wanted.

Overall complexity: O(|s|log|s|) or O(|s|) per testcase.

Solution (awoo)1626B - Minor Reduction

Idea: BledDest

Tutorial1626B - Minor ReductionLet's think how a reduction changes the length of x. There are two cases. If two adjacent letters sum up to 10 or greater, then the length doesn't change. Otherwise, the length decreases by one.

Obviously, if there exists a reduction that doesn't change the length, then it's better to use it. Which among such reduction should you choose? Well, notice that such a reduction always makes the number strictly smaller (easy to see with some case analysis). Thus, the logical conclusion is to leave the longest possible prefix of x untouched. So, the rightmost such reduction will change the number as little as possible.

If all reductions decrease the length, then a similar argument can be applied. The sum will be a single digit, but a digit that is greater than or equal to the left one of the adjacent pair. If it was just greater, it's easy to see that the leftmost such reduction will make the number the largest possible. The equal case adds more case analysis on top of the proof, but the conclusion remains the same: the leftmost reduction is the best one.

As an implementation note, since all the reductions are of the same type, the leftmost reduction always includes the first and the second digits.

Overall complexity: O(|x|) per testcase.

Solution (awoo)1626C - Monsters And Spells

Idea: BledDest

Tutorial1626C - Monsters And SpellsConsider the problem with n=1. There is a single monster with some health h that appears at some second k. In order to kill it, we have to wind up our spell until it has damage h. So we have to use it from second k−h+1 to second k. Look at it as a segment [k−h+1;k] on a timeline.

Actually, to avoid handling zero length segments, let's instead say that a segment covers the time from k−h non-inclusive to k inclusive, producing a half-interval (k−h;k]. This way, the total mana cost will be len(len+1)2, where len is the length of the half-interval.

Now n=2. There are two time segments.

If they don't intersect (segments (1;2] and (2;3] don't intersect, since they are half-intervals), then it's always better to wind up the spell for the monsters separately instead of saving the damage.

However, if they intersect, then we don't have the choice other than to save the damage from the earlier one to the later one. Otherwise, there won't be enough time to wind up the spell.

What that means in a mathematic sense? The answer is the union of two half-intervals. If they don't intersect, they are left as is. Otherwise, they become one half-interval that covers them both.

Now add the third monster into the construction. The same argument applies. While there exists a pair of intersecting half-intervals, keep uniting them.

The union of all half-intervals can be found in O(nlogn), but the constraints allowed slower approaches as well.

Solution (awoo)1626D - Martial Arts Tournament

Idea: BledDest

Tutorial1626D - Martial Arts TournamentSort the weights, now choosing x and y will split the array into three consecutive segments.

Consider a naive solution to the problem. You can iterate over the length of the first segment and the second segment. The third segment will include everyone remaining.

Now you have to check if there exist some x and y that produce such segment. x can be equal to the first element of the second segment (since only all elements of the first segment are smaller than it). Similarly, y can be equal to the first element of the third segment.

However, if the last element of some segment is equal to the first element of the next segment, no x or y can split the array like that.

Otherwise, you can split an array like that. So you can iterate over the lengths, check the correctness and choose the best answer.

Now let's optimize it using the condition about powers of two.

First, iterate over the size of the middle division (which is a power of two). Then over the length of the first segment (which can be not a power of two). Check if the first segment is valid.

So we fixed the length of the first segment and some value which is greater or equal than the length of the second segment. That value isn't necessarily equal to the length of the second segment because the produced segment might be invalid.

So there is a greedy idea that the second segment should be as long as possible under the constraint that it doesn't exceed the fixed value. The intuition is the following. Consider the longest possible valid segment. Now take the last element away from it. We will have to invite one more participant to the middle division. And that element will also get added to the third segment, increasing its length. So potentially, you can only increase the required number of participants to invite.

This can be implemented in the following fashion. For each position i precalculate lefti — the closest possible segment border from the left. Iterate over the size of the middle division mid as a power of two. Iterate over the length of the first segment len1. Find the closest border to the left of len1+mid=left[len1+mid]. Get the lengths of the second and the third segments. Find the closest powers of two to each length and update the answer.

Overall complexity: O(nlogn) per testcase.

Solution (awoo)1626E - Black and White Tree

Idea: BledDest

Tutorial1626E - Black and White TreeI think there are some ways to solve this problem with casework, but let's try to come up with an intuitive and easy-to-implement approach.

It's always possible to move closer to some black vertex, no matter in which vertex you are currently and which black vertex was used in the previous operation. However, sometimes if you try to move along an edge, you immediately get forced back. Let's analyze when we can move without being forced back.

We can move along the edge x→y so that our next action is not moving back if:

either y is black (there is no next action);or, if we remove the edge between x and y, the number of black vertices in y's component is at least 2 (we can use one of them to go from x to y, and another one to continue our path).Note that the cases x→y and y→x may be different (sometimes it will be possible to move in one direction, and impossible to move in the opposite direction).

Let's treat this possible move x→y as an arc in a directed graph. We can find all such arcs if we can answer the queries of the type "count black vertices in a subtree of some vertex", and this can be done by rooting the tree and calculating this information for each subtree with DFS.

Now, if there is a way from some vertex i to some black vertex along these arcs, the answer for the vertex i is 1. How can we find all such vertices? Let's transpose the graph (change the direction of each arc to opposite), now we need to find all vertices reachable from black ones — which is easily done with multisource BFS or DFS.

The complexity of this solution is O(n).

Solution (BledDest)1626F - A Random Code Problem

Idea: BledDest

Tutorial1626F - A Random Code ProblemI think it's easier to approach this problem using combinatorics instead of probability theory methods, so we'll calculate the answer as "the sum of values of ans over all ways to choose the index on each iteration of the loop".

If a number aidx is chosen on the iteration i of the loop, then it is reduced to the maximum number divisible by i that doesn't exceed the initial value. So, if a number is divisible by all integers from 1 to k, i. e. divisible by L=LCM(1,2,…,k), it won't be changed in the operation. Furthermore, if ⌊aidxL⌋=x, then the value of this element won't become less than x⋅L.

It means that we can interpret each number ai as ai=x⋅L+y, where x=⌊aiL⌋ and y=aimodL. The part with x⋅L will always be added to the variable ans when this element is chosen, so let's add k⋅nk−1⋅x⋅L to the answer (which is the contribution of x⋅L over all ways to choose the indices in the operations), and work with aimodL instead of ai.

Now all elements of the array are less than L. We can use this constraint by writing the following dynamic programming to solve the problem: dpi,j is the number of appearances of the integer i in the array a over all ways to choose the indices for the first j iterations.

For j=0, dp is just the number of occurrences of each integer in the array a. The transitions from dpi,j are the following ones:

if this element is chosen in the operation, then it becomes i′=i−(imod(j+1)), and we transition to the state dpi′,j+1;otherwise, the element is unchanged, and we transition to the state dpi,j+1, multiplying the current value by n−1, which is the number of ways to choose some other element in the operation.How can we use this dynamic programming to get the answer? On the (j+1)-th iteration, the number of times we choose the integer i is exactly dpi,j, and the number of ways to use the integers in the next operations is nk−j−1, so we add i⋅dpi,j⋅nk−j−1 to the answer for every such state dpi,j.

This solution runs in time O(n+LCM(1,2,…,k)⋅k), which may be too slow if not implemented carefully. Fortunately, we have an easy way to optimize it: use L=LCM(1,2,…,k−1) instead of L=LCM(1,2,…,k), which divides L by 17 in the worst case scenario for our solution. We can do this because even if an integer is changed on the k-th operation, we are not interested in this change since this is the last operation.

Solution (BledDest)

Educational Codeforces Round 120 Editorial

By awoo, history, 14 months ago, translation, In English1622A - Construct a Rectangle

Idea: BledDest

Tutorial1622A - Construct a RectangleFirst, the condition about being able to construct a rectangle is the same as having two pairs of sticks of equal length.

Let's fix the stick that we are going to break into two parts. Now there are two cases.

The remaining two sticks can be the same. In that case, you can break the chosen stick into equal parts to make the second equal pair of sticks. Note, however, that the stick should have an even length, because otherwise the length of the resulting parts won't be integer.

The remaining two sticks can be different. In that case, the chosen stick should have the length equal to their total length, because the only way to make two pairs of equal sticks is to produce the same two sticks as the remaining ones.

Overall complexity: O(1) per testcase.

Solution (Neon)1622B - Berland Music

Idea: adedalic

Tutorial1622B - Berland MusicSince we know that every disliked song should have lower rating than every liked song, we actually know which new ratings should belong to disliked songs and which should belong to the liked ones.

The disliked songs take ratings from 1 to the number of zeros in s. The liked songs take ratings from the number of zeros in s plus 1 to n. Thus, we have two independent tasks to solve.

Let the disliked songs have ratings d1,d2,…,dk. Their new ratings should be 1,2,…,k. We can show that if we sort the array d, then |d′1−1|+|d′2−2|+⋯+|d′k−k| will be the lowest possible. The general way to prove it is to show that if the order has any inversions, we can always fix the leftmost of them (swap two adjacent values), and the cost doesn't increase.

So the solution can be to sort triples (si,pi,i) and restore q from the order of i in these.

Overall complexity: O(nlogn) per testcase.

Solution (awoo)1622C - Set or Decrease

Idea: adedalic

Tutorial1622C - Set or DecreaseFirst, we can prove that the optimal way to perform operations is first, decrease the minimum value several (maybe, zero) times, then take several (maybe, zero) maximums and make them equal to the minimum value.

The proof consists of several steps:

Prove that first, we make decreases, only then sets:if some ai=ai−1 is done after some aj=ak then if there were no modification of ai then you can just move ai=ai−1 earlier. Otherwise, there were ai=ak, and you can replace (... ai=ak, ai=ai−1 ...) with (... ak=ak−1, ai=ak ...). We demonstrated how to move decrease operations before set operations.Prove that it's optimal to decrease only one element ai:instead of decreasing ai by x and aj by y (where ai≤aj), we can decrease ai by x+y and replace all ak=aj with ak=ai.It's optimal to decrease the minimum element — it follows from proof of previous step.If we make y set operations, it's optimal to set minimum value to y maximum elements — should be obvious.To use the strategy, we'll firstly sort array a in non-decreasing order. In this case, we'll decrease a1 by x and perform set to y elements an−y+1,…,an. The question is: how to minimize value of x+y?

Note, that 0≤y<n (since setting the same position multiple times has no sense). Let's iterate over all possible values of y and determine the minimum x needed.

The resulting array will consists of (a1−x),a2,a3,…,an−y,(a1−x),(a1−x),…,(a1−x). Let's say that P(i)=a1+a2+⋯+ai (and all P(i) can be precomputed beforehand). Then the sum of array will become (a1−x)(y+1)+P(n−y)−a1, and we need(a1−x)(y+1)+P(n−y)−a1≤k(a1−x)(y+1)≤k−P(n−y)+a1a1−x≤⌊k−P(n−y)+a1y+1⌋or, since we need minimum possible x,x=a1−⌊k−P(n−y)+a1y+1⌋Using the formula above, we can for each y (0≤y<n) calculate minimum x required. But to be accurate, value k−P(n−y)+a1 may be negative, and, usually in programming languages, integer division cd for negative c returns ⌈cd⌉ instead of ⌊cd⌋.

There is an alternative solution: note that if ∑ai≤k, then a1≤kn. Note that if a1≥kn then resulting value of a1−x is in kn−n<a1−x≤nk and there are at most n possible value for x. So, you can iterate over all possible x and for each x calculate minimum required y either with binary search or two pointers.

Solution (adedalic)1622D - Shuffle

Idea: BledDest

Tutorial1622D - ShuffleWe could iterate on the substrings we want to shuffle and try to count the number of ways to reorder their characters, but, unfortunately, there's no easy way to take care of the fact that shuffling different substrings may yield the same result.

Instead, we will iterate on the first and the last character that are changed. Let these characters be i and j. First of all, let's check that they can belong to the same substring we can shuffle — it is the case if the string contains at least k characters 1, and the substring from the i-th character to the j-th character contains at most k characters 1.

Then, after we've fixed the first and the last characters that are changed, we have to calculate the number of ways to shuffle the characters between them (including them) so that both of these characters are changed. Let's calculate c0 and c1 — the number of characters 0 and 1 respectively in the substring. Then, we need to modify these two values: for example, if the i-th character is 0, then since it is the first changed character, it should become 1, so we need to put 1 there and decrease c1 by one. The same for the j-th character. Let c′0 and c′1 be the values of c0 and c1 after we take care of the fact that the i-th and the j-th character are fixed. The remaining characters can be in any order, so the number of ways to arrang them is (c′0+c′1c′0).

We can add up these values for all pairs (i,j) such that we can shuffle a substring containing these two characters. We won't be counting any string twice because we ensure that i is the first changed character, and j is the last changed character. Don't forget to add 1 to the answer — the string we didn't count is the original one.

This solution works in O(n2), but the problem is solvable in O(n).

Solution (BledDest)1622E - Math Test

Idea: BledDest

Tutorial1622E - Math TestNote that there are only two ways to fix the result of the operation of taking an absolute value in the expression |xi−ri|: xi−ri or ri−xi. Since the value of n is small enough that we can iterate over all 2n options, and choose the one for which the sum is maximum.

For each student, let's fix with which sign their total points will contribute to the answer, then xi will contribute with the opposite sign. Now, for the question j we can calculate valj — the coefficient with which pj will contribute to the answer. It remains to choose such a permutation p that the sum ∑j=1mpjvalj is the maximum possible. From here we can see that if valj<vali (for some i and j), then pj<pi must holds, otherwise we can swap pj and pi, and the answer will increase. This means that we can sort all questions in ascending order by the value in the val array, and assign the value x in the array p to the x-th question in ascending order.

For some of 2n options, the permutations we found may be illegal because it can happen that we consider the case that some |xi−ri| evaluates as (xi−ri), but in the best permutation we found for that option, it evaluates as (ri−xi). We can just ignore it because this will never be the case with the option giving the highest possible surprise value — if this thing happened for some option to choose the signs of ri, then, if we flip the signs for the students such that the conditions on them are not met in the optimal permutation, we'll get a combination of signs that yields a higher surprise value.

Solution (Neon)1622F - Quadratic Set

Idea: Neon

Tutorial1622F - Quadratic SetA good start to solve the problem would be to check the answers for small values of n. One can see that the answers (the sizes of the maximum subsets) are not much different from n itself, or rather not less than n−3. Let's try to prove that this is true for all n.

Consider n is even. Let n=2k, let's see what the product is equal to if we take all the numbers from 1 to n.

∏i=12ki!=∏i=1k(2i−1)!(2i)!=∏i=1k(2i−1)!22i=(∏i=1k(2i−1)!)2∏i=1k2i=(∏i=1k(2i−1)!)22kk!From here we can see that for even k the answer is at least n−1, because we can delete k! and the product of the remaining factorials will be the square of an integer, for odd k the answer is at least n−2, because we can delete 2! and k!.

It remains to prove that the answer is at least n−3 for odd n. This is easy to do, because the answer for n is not less than the answer for n−1 minus 1, because we can delete n! and solve the task with a smaller n value. Moreover, it can be seen from the previous arguments that the answer 3 can only be for n≡3(mod4), and we already know that in this case one of the correct answers is to remove the factorials 2,n−12,n.

It remains to learn how to check whether it is possible to remove 1 or 2 numbers so that the remaining product of factorials is the square of an integer.

To do this, we can use XOR hashes. Let's assign each prime number a random 64-bit number. For composite numbers, the hash is equal to the XOR of hashes of all its prime divisors from factorization. Thus, if some prime is included in the number an even number of times, it will not affect the value of the hash, which is what we need. The hash of the product of two numbers is equal to the XOR of the hashes of these numbers. Let's denote the hash function as H.

Using the above, let's calculate H(i) for all i from 1 to n, as well as H(i!) for all i from 1 to n, this is easy to do, because H(i!)=H((i−1)!)⊕H(i). We will also store a map H(i!)→i. Let's calculate the hash H(1!2!⋯n!) and denote it as fp. It remains to consider the following cases:

if fp=0, then the current product is already the square of an integer;for an answer of size n−1, we have to check that there exists such a i that H(i!)⊕fp=0. To find such i, let's check whether the map contains fp;for an answer of size n−2, we have to check that there are such i and j that H(i!)⊕H(j!)⊕fp=0. To do this, iterate over i, and then check whether map contains H(i!)⊕fp;otherwise, the answer is n−3, and there is an answer, where all numbers except 2,n−12,n are taken.Solution (Neon)

Educational Codeforces Round 119 Editorial

By awoo, history, 14 months ago, translation, In English1620A - Equal or Not Equal

Idea: BledDest

Tutorial1620A - Equal or Not EqualLet's look at a group of E: it's easy to see that each such a group is equal to the same number. Now, let's look at how these groups are distributed on the circle:

If there are no N then all ai are just equal to each other. It's okay.If there is exactly one N then from one side, all of them are still in one group, so they should be equal, but from the other side, one pair should have different values. It's contradiction.If there are more than one N then all numbers are divided in several groups with different values. It's okay.As a result, array a exists as long as the number of N isn't 1.

Solution (Neon)1620B - Triangles on a Rectangle

Idea: BledDest

Tutorial1620B - Triangles on a RectangleThe area of a triangle is equal to its base multiplied by its height divided by 2. Let the two points that have to be on the same side of a rectangle form its base. To maximize it, let's choose such two points that are the most apart from each other — the first and the last in the list.

Then the height will be determined by the distance from that side to the remaining point. Since there are points on all sides, the points on the opposite side are the furthest. Thus, the height is always one of h or w, depending on whether we picked the horizontal or the vertical side.

So we have to check four options to pick the side and choose the best answer among them.

Solution (awoo)1620C - BA-String

Idea: BledDest

Tutorial1620C - BA-StringFind all segments of asterisks in the string. Let there be t of them, and the number of asterisks in them be c1,c2,…,ct. That tells us that the i-th segment of asterisks can be replaced with at most ci⋅k letters 'b'.

Notice that we can compare two strings lexicographically using just the number of letters 'b' that replace each of t segments of asterisks. Let that sequence for some string a be A1,A2,…,At and that sequence for some string b be B1,B2,…,Bt. Then a<b if and only if A<B. That is, there exists such position i that Ai<Bi. The proof is trivial.

So we can actually look at the sequence A1,A2,…,At as some kind of number in a mixed base. The lowest "digit" At can be of one of ct⋅k+1 values (from 0 to ct⋅k). The second lowest — one of ct−1⋅k+1. And so on. Then, comparison of two strings is the same as comparison of these two mixed base numbers.

Thus, the task is to convert number x−1 to this mixed base. Turns out, it's not that hard. In base 10, for example, the lowest digit can be determined as the remainder of the number of dividing by 10. Here it will be the remainder of dividing by ct⋅k+1. After that, divide and floor the number and proceed to the next "digit".

After t steps are done, the "digits" of that mixed base number tell exactly how many letters 'b' should replace each segment of asterisks.

Overall complexity: O(n) per testcase to recover the string, O(nk) to print it.

Solution (awoo)1620D - Exact Change

Idea: adedalic

Tutorial1620D - Exact ChangeLet's define m=max(ai), then it should be obvious that we need at least r=⌈m3⌉ coins to buy a bag of chips of cost m. Now, it's not hard to prove that r+1 coins is always enough to buy a bag of chips of any cost c≤m. Proof:

if m≡0(mod3), we'll take r−1 coins of value 3, coin 1 and coin 2;if m≡2(mod3), we'll take r−1 coins 3 and two coins 1;if m≡1(mod3), we'll take r−2 coins 3, one coin 2 and two coins 1.So the question is how to decide, is r coins enough. The solution is to note that there is no need to take more than 3 coins 1 and more than 3 coins 2, so we can just brute force the number of coins 1 we'll take c1 and the number of coins 2 we'll take c2. Then, the number of coins 3 c3=⌈m−c1−2c23⌉, and we can check: is it possible to pay exactly ai using at most c1, c2 and c3 coins respectively.

There exists casework solution as well, but it's quite tricky, so brute force is preferable. The main problem for case work is the case m≡1(mod3), since there are two different ways to take r coins: either r−1 coins 3 and coin 1 or r−2 coins 3 and two coins 2. In the first way, you can't gather exactly ai≡2(mod3) and in the second one, you can gather neither ai=m−1 nor ai=1.

Solution (adedalic)1620E - Replace the Numbers

Idea: Neon

Tutorial1620E - Replace the NumbersLet's solve the problem from the end. Let's maintain the array px — what number will x become if we apply to it all the already considered queries of type 2. If the current query is of the first type, then we simply add px to the resulting array. If the current query is of the second type, then we have to change the value of px. Since all occurrences of x must be replaced with y, it is enough to assign px=py.

Since we process each query in O(1), the final complexity is O(n).

There is also an alternative solution. Let's process queries in the direct order. Let's store all its positions in an array for each number. Then for the first query, it is enough to put the index in the corresponding array of positions. And for a query of the second type, we have to move all the positions of the number x into an array of positions of the number y. The naive implementation is obviously too slow, but we can use the small to large method, then the complexity of the solution will be O(nlogn).

Solution 1 (Neon)Solution 2 (Neon)1620F - Bipartite Array

Idea: BledDest and Neon

Tutorial1620F - Bipartite ArrayTo begin with, let's understand that an array is bipartite if and only if there is no decreasing subsequence of length 3 in the array.

Now we can write dynamic programming dpi,x,y: is there an array a of length i such that x is the maximum last element of a decreasing subsequence of length 1, and y is the maximum last element of a subsequence of length 2. Note that x>y.

Let's consider all possible transitions from the state (i,x,y) if we are trying to put the number z on the i-th position, where z=±pi:

if z>x, then the new state will be (i+1,z,y);if z>y, then the new state will be (i+1,x,z);if z<y, then such a transition is not valid, because a decreasing subsequence of length 3 is formed in the array.With a naive implementation, such dynamic programming works in O(n3).

We can note that for fixed values of i and x (i and y) it is enough for us to store only the minimum available value of y (x). So, we can write dynamic programming dpi,x, which is defined similarly to the above, but now instead of being Boolean, stores the minimum value of y (or infinity if the state is not valid).

We have speeded up our solution to O(n2), but it is still too slow.

To speed up the solution even more, we have to look at the transitions in dynamics and notice that for a fixed i, either x or y is always equal to ±pi−1. So we can rewrite our dynamic programming in the following form — dpi,pos,sign. Here, the pos flag says which of the numbers x and y is equal to ±pi−1, and the sign flag is responsible for the sign of pi−1, and the minimum value of y or x is stored in the value itself (depending on pos).

Thus, we got a solution with a linear running time.

In fact, this solution can be simplified if we see the following relation: the number we use on position i is not less than dpi,0,sign and not greater than dpi,1,sign. This allows us to get rid of one of the states in our dynamic programming altogether, so we get an easier solution. This optimization wasn't required to get AC, but the code becomes shorter.

Solution 1 (Neon)Solution 2 (Neon)1620G - Subsequences Galore

Idea: BledDest

Tutorial1620G - Subsequences GaloreFor a string t, let's define its characteristic mask as the mask of n bits, where i-th bit is 1 if and only if t is a subsequence of si. Let's suppose we somehow calculate the number of strings for each characteristic mask, and we denote this as G(x) for a mask x. How can we use this information to find f([si1,si2,…,sik])? Suppose this set of strings is represented by a mask x, then the strings which are not included in f are the strings such that their characteristic mask has bitwise AND with x equal to 0, i. e. these characteristic masks are submasks of 2n−1⊕x. We can use SOS DP to calculate these sums of G(x) over submasks in O(2nn).

The only problem is how to calculate G(x) for every mask. Let's analyze when a string is a subsequence of a sorted string si. The subsequence should be sorted as well, and the number of occurrences of every character in a subsequence should not exceed the number of occurrences of that character in si. So, if there are c1 characters a in si, c2 characters b in si, and so on, then the number of its subsequences is ∏j=126(1+cj).

What about subsequences of every string from a set? These conditions on the number of occurrences should apply to every string in the set, so, for each character, we can calculate the minimum number of occurrences of this character in each string of the set, add 1, and multiply these numbers to get the number of strings that are subsequences of each string in a set.

These values can be calculated in O(2n(n+A)) for all 2n subsequences of [s1,s2,…,sn] using recursive approach. Can these numbers be used as G(x)? Not so fast. Unfortunately, these values (let's call them H(x)) are the numbers of subsequences of the chosen sets of strings, but we have no information about the strings that are not included in the chosen set of strings. To handle it, we can use the following equation: H(x)=∑x⊆yG(y), where x⊆y means that x is a submask of y. To transform the values of H(x) into the values of G(x), we can flip all bits in the masks (so H(x) is the sum of G(y) over all submasks of x), apply inverse SOS DP (also known as Mobius transformation), and then flip all bits in the masks again. So, we found a way to calculate all values of G(x) in O(2n(n+A)), and we have already discussed what to do with them in the first paragraph of the editorial.

The overall complexity of the solution is O(2n(n+A)).

Solution (BledDest)

Educational Codeforces Round 118 Editorial

By awoo, history, 15 months ago, translation, In English1613A - Long Comparison

Idea: BledDest

Tutorial1613A - Long ComparisonFirst, let's say that appending the number with p zeros is the same as multiplying it by 10p.

The given numbers are so large that they can't fit into any reasonable integer type. Even if you use a language with unlimited length integers (python, for example) or store the numbers in strings, you should still face the time limit issue. So let's learn to shrink the numbers a bit.

Note that the result of the comparison of two numbers doesn't change if you divide both numbers by the same positive number. So we can keep dividing both numbers by 10 until one of them is not divisible anymore. Let's also ignore the trailing zeros in x1 and x2 and leave them as is. If the first number is appended with p1 zeros and the second numbers is appended with p2 zeros, we can subtract min(p1,p2) from both values, effectively dividing both numbers by 10min(p1,p2).

This way, one of the numbers becomes short enough to fit into an integer type (because it has p=0 and x is only up to 106). The other number might still be large enough.

However, if it's really large, we can instantly say that it's larger than another one. Say, if its p is at least 7. This number it at least 107 and the other number is at most 106.

Otherwise, we can calculate this number as well and compare the values normally.

Overall complexity: O(1) per testcase.

Solution (awoo)1613B - Absent Remainder

Idea: BledDest

Tutorial1613B - Absent RemainderThere is one important observation: x mod y<y.

Thus, you can obtain at least n−1 pair by choosing y as the minimum number in the sequence and x as anything else. n−1≥⌊n2⌋ for any positive n.

Overall complexity: O(n) per testcase.

Solution (Neon)1613C - Poisoned Dagger

Idea: BledDest

Tutorial1613C - Poisoned DaggerLet's find out the total damage for a fixed value of k. Since the effect of the poison from the i-th attack deals damage min(k,ai+1−ai) seconds for i<n and k seconds for i=n, then the total damage is k+∑i=1n−1min(k,ai+1−ai). We can see that the higher the value of k, the greater the total sum. So we can do a binary search on k and find the minimum value when the sum is greater than or equal to h.

Solution (Neon)1613D - MEX Sequences

Idea: BledDest

Tutorial1613D - MEX SequencesLet's understand what MEX-correct sequences look like. It turns out there are only two types: [0,…,0––––––––,1,…,1––––––––,…,x−1,…,x−1––––––––––––––––,x,…,x––––––––] and [0,…,0––––––––,1,…,1––––––––,…,x−1,…,x−1––––––––––––––––,x+1,…,x+1––––––––––––––––,x−1,…,x−1––––––––––––––––,x+1,…–––––––––]. For example, the sequences [0,0,1,1,1,2,3,3] and the empty sequence are MEX-correct sequences of the first type, and [1,1,1,1] and [0,0,1,2,4,4,2,4,2,2] of the second one.

Let's calculate the dynamic programming dp1i,j — the number of MEX-correct subsequences of the first type on the prefix of length i with MEX equal to j and similarly dp2i,j — the number of MEX-correct subsequences of the second type on the prefix of length i with MEX equal to j.

Let's look at the transitions in these dps, and show that there are no other MEX-correct sequences at the same time.

Let the current state be dp1i,j, and we are trying to add an element equal to x:

if x<j−1, then such an element cannot be added;if x=j−1, then the value of MEX will not change and the sequence is still of the first type, which means we have a transition to dp1i+1,j;if x=j, then the value of MEX will increase by 1, but it will still be of the first type, which means we have a transition to dp1i+1,j+1if x=j+1, then the value of MEX will not change, but the sequence will become of the second type, which means we have a transition to dp2i+1,j;if x>j+1, then such an element cannot be added.Let the current state be dp2i,j, and we are trying to add an element equal to x:

if x<j−1, then such an element cannot be added;if x=j−1, then the value of MEX will not change and the sequence is still of the second type, which means we have a transition to dp2i+1,j;if x=j, then such an element cannot be added, because MEX will increase by 2, which means the absolute difference between MEX and x is greater than 1;if x=j+1, then the value of MEX will not change and the sequence is still of the second type, which means we have a transition to dp2i+1,j;if x>j+1, then such an element cannot be added.Thus, we considered all possible transitions (adding a new element to the already MEX-correct sequences) and made sure that there are only two types.

While the solution itself works in O(n) time (because each element x has O(1) possible transitions in the dps), it uses O(n2) memory, which does not allow us to write that solution as is. However, note that dp1i and dp1i+1 (similarly for dp2) differ in only a few positions (in those that the element ai allowed us to make), which means we can store only one-dimensional arrays, dp1j and dp2j. Thus, the final complexity of the solution is O(n).

Solution (Neon)1613E - Crazy Robot

Idea: BledDest

Tutorial1613E - Crazy RobotOne way to think about this problem is in game theory terms.

Imagine a following game. Two players alternate moves. The first players chooses a direction. The second player chooses a different direction and moves a robot there. The game ends when the robot reaches the lab, and the first player wins. Otherwise, it's a draw. What's the outcome of the game if both players play optimally (as in the first player tries to win, the second player tries to draw)?

Does it sound easier? Well, it sure does if you ever dealt with solving games on arbitrary graphs. You can skim through this article if that's unfamiliar to you. The state of the game is a pair (cell,direction). If a direction is not chosen (denote it with −1), it's the first player's move. Otherwise, it's the second player's move.

You can even implement it as is. Or you can adjust a part of this algorithm for this particular problem.

Initially, all the states are drawing, only the state (lab,−1) is winning. What we basically need is a way to determine if a state is winning or not. From game theory, we can tell that the state is winning if there's a transition from it to a losing state. The state is losing if all the transitions from it lead to winning states. So (cell,−1) is winning if any of (cell,direction≠−1) are losing.

Promote that one step further. The state is winning if there exists such a direction that all neighbouring free cells except in this direction are winning states. Rephrase it. The state is winning if it has at least one winning state neighbour and no more than one non-winning state neighbour.

Let's store the number of non-winning neighbouring states for each cell. Initially, it's the number of neighbouring free cells. If some state becomes marked as winning, decrease the value for each of its neighbours by 1. If some state's value reaches 0 or 1 after this operation, mark it as winning.

Since what this does is basically a traversal of a grid, this can be done with a DFS/BFS, starting from the lab.

Overall complexity: O(nm) per testcase.

Solution (awoo)1613F - Tree Coloring

Idea: BledDest

Tutorial1613F - Tree ColoringWhen a problem asks us to calculate the number of combinatorial objects that meet some constraints, we can sometimes use inclusion-exclusion formula. Let's try to apply it in this problem.

We could use n−1 constraints that should not be violated. The i-th constraint is formulated as follows: ci≠cpi−1 (there will be a constraint of this type for each i∈[2,n]). Suppose we violated k of these constraints (and have chosen which k constraints to violate), then the number of colorings that meet these violations is (n−k)! (for k vertices, the colors on them depend on some other independent vertices, so we can assign only colors for independent vertices). So, the answer can be calculated as follows:

∑k=0n−1(−1)kf(k)(n−k)!,

where f(k) is the number of ways to choose k constraints to violate.

One initial guess how to calculate f(k) is that f(k)=(n−1k), as it would be calculated in other, more usual inclusion-exclusion problems. Unfortunately, in this problem, the constraints we violate are not independent. For example, if a vertex has several sons, we can violate the constraint only on at most one edge leading from a vertex to its son simultaneously, we cannot violate two or more such constraints.

Let's take care of this issue as follows: we can write a dynamic programming of the form dpi,j is the number of ways to process i first vertices of the tree and choose exactly j edges leading from these nodes to their sons so that no vertex has more than one edge leading to its sons chosen. Then, dpn,k is exactly the number of ways to choose k edges in the tree so that no vertex has more than one chosen edge leading to its sons, and that will be equal to f(k).

We can calculate this dynamic programming in a knapsack fashion in O(n2), but it is too slow. Instead, let's optimize this knapsack DP with FFT: for each vertex i, introduce a polynomial 1+di⋅x, where di is the number of children of the vertex i. Coefficients of this polynomial for the first vertex are the values of dp1,k; coefficients of the product of this polynomial with the polynomial for the second vertex are the values of dp2,k, and so on; to obtain the values of dpn,k, we have to multiply all these polynomials, and using FFT + divide-and-conquer, we can do it in O(nlog2n).

Solution (BledDest)

Codeforces Round #115 — editorial A-E

By I_Remember_Olya_ashmelev, 11 years ago, translation, In EnglishProblem 175A - Robot Bicorn AttackGo over all possible partitions of the given string into 3 substrings (for example, go over a pair of indexes — the ends of the first and the second substrings). If all three substrings of the partition satisfy constraints (there are no leading zeroes and the corresponding number does not exceed 1000000), then update the current answer with the sum of obtained numbers (if it is necessary). The total amount of partitions is O(N^2), where N is the length of the string. The check of one partition takes O(N).

Problem 175B - Plane of Tanks: ProThe solution is to simulate actions described in the statement. Find the best result for each player and count total amount of players N. Then find a number of players C for each player , those results are not better than best result of the considering player (this can be done by going over all players). Then it is necessary to determine players category using numbers C and N. In order to avoid rounding error use the following approach:

if C * 100 >= N * 99, then the player belongs to category "pro"if C * 100 >= N * 90, then the player is "hardcore"if C * 100 >= N * 80, then the player is "average"if C * 100 >= N * 50, then the player is "random"In other case the player is "noob".

Problem 175C - Geometry HorseObvious, that figures should be destroyed in the cost increasing order. Sort figures type in ascending order of their costs. Consider two pointers – position i in the array P (current factor) and position j in the array of figures type. Consider the current answer and the number of figures G, those need to be destroyed to move to the next value of factor. If the number of figures F of the current type does not exceed G, then add F * (i + 1) * Сj to the answer and reduce G by F and increase pointer j by 1. In other case add G * (i + 1) * Cj to the answer, reduce F by G, increase i by 1 and set G = Pi – P(i-1). Continue iteration until all figure types are considered.

Problem 175D - Plane of Tanks: DuelFirst consider case when at least one probability of not-piercing is equal to 100%. If Vasya does not pierce the enemy tank with probability 100%, then the answer is 0. If the enemy tank cannot pierce Vasya's tank with probability 100% then the answer is 1. Then consider that the probability of shot does not pierce tank does not exceed 99%. It can be checked that the probability that tank will stay alive after D = 5000 shots is less than 10^-6 (for any damage value, probability of not-piercing and amount of hit points). For each tank calculate the following table dp[i][j] — probability that tank will have j hit points after i shots to him. dp[0][hp] = 1, where hp – is the initial amount of hit points. In order to calculate the line dp[i+1] it is necessary to go over all possible damages for each value of j in the line dp[i], which shot (i+1)-th damages (considering cases when the shot does not pierce the tank armour) and update appropriate values of the line (i+1):

dp[i + 1][max(0, j – x)] += dp[i][j] * (1 – p) / (r – l + 1)where p – is the probability of not-piercing, x – possible shot damage. Let's dpv – calculcated table for Vasya's tank and dpe is the table for enemy's tank. Now it is necessary to find probability that enemy's tank will be destroyed after i shots of Vasya's tank: pk[i] = dpe[i][0] – dpe[i-1][0]. Vasya wins the following way: Vasya fired (K — 1) shots and do not destroy enemy tank and is still alive also. After that Vasya fires K-th shot and destroy the enemy. Go over K and calculate the probability of Vasya's victory with the K-th shot. In order to do this find how many shots T can fire the enemy before Vasya makes K-th shot (here is the only place in the solution where we must use the gun recharge speed):

T = ((K – 1) * dtv + dte - 1) / dtewhere dtv is the time required to recharge the gun, dte is the time of enemy gun recharge. Then the probability of victory is (1 – dpv[T][0]) * pk[K]. The answer for the problem is the sum all these probabilities for each K from 1 to D. The algorithmic complexity of the algorithm is O(D * hp * (r – l)).

Задача 175E - Power DefenceIf we reflect the position of towers alogn the line OX then the interval where towers will affect the Villain will not change. So, we can consider that towers can be built in the points (_x_, 1), not more than two towers in the same point. If there exists point X that there are towers to the left and to the right from X but in the point X there is no tower, then abscissas of all towers "to the right" can be reduced by 1 and the answer will not become worse. The same way, we can prove that there are no adjacent points with exactly one tower in each one. Now it is easy to check that in order to construct the optimal solution it is enough to check 13 successive points.

Go over positions of freezing towers. In the worst case there are approximately 200000 cases to put freezing towers into 13 points. Consider the case when we fixed positions of several freezing towers. Let's calculate how much damage can hit fire-tower or electric-tower in the point for each empty points (points where we can put two towers are splitted into two) and save numbers into the array d (_d_[k].f and d[k].e – damage by fire and electricity in the point k correspondingly). Sort the array d in the order of decreasing of the value d[k].f. Then optimal position of the rest towers can be found using dynamic programming. Designate dp[i][j] – the maximum possible damage, which can be hitted if we have i fire-towers and j electric-towers. Designate p — the amount of towers have been set already: p = cf – i + ce – j. If i = 0 then we used first p values of array d and the answer is the sum of j maximum elemets of d[k].e, starting from index p. Otherwise we put one fire-tower or one electric tower in the position p. It is necessary to put the tower into position p because in the opposite case the d[p].f will decrease. Then:

dp[i][j] += max(dp[i - 1][j] + d[p].f, d[i][j – 1] + d[p].e)The answer is the value dp[cf][ce], which is calculated in O(cf * ce * log(ce))

Comment1: exhaustive search can be reduced in 2 times because any two symmetric towers arrangements are equivalent and have the same answer. However, this optimization is not required with a given constraints.

Comment2: the formula of Villain speed decrease 1 / (K + 1) allows to calculate the tower damage for a case when all freezing towers are fixed easily. Freezing towers can be taken into account separately.

Codeforces Round #114 — Tutorial

By Dmitry_Egorov, 11 years ago, translation, In EnglishI am sorry for mistakes in English and I will be glad if you tell me about them.

168A - Wizards and Demonstration Аuthor PavelKunyavskiy.In this task, it was necessary to write exactly what has been described in statement. In particular, it was necessary to have  people, who come to the meeting. For this it was necessary to create  clones.

168B - Wizards and Minimal Spell Аuthor PavelKunyavskiy.In this problem you had to write exactly what has been described in statment too. Read lines one by one. Also keep the last block of lines that are not amplyfying. If the next line is amplyfying (which can be checked by linear search), we print the last block, if any, and the line itself. Otherwise, remove all spaces from the string and add to the last block. It only remains to distinguish between an empty block and a block of empty lines.

167A - Wizards and Trolleybuses Аuthor Alex-Gran.This was the first problem where you had a little bit away from translating statements to a programming language. Because acceleration trolleybuses are all the same and they can slow down immediately, the answer for the next trolleybus is the maximum of the time when it would come if it were not to stop when he reach the rest trolleybuses which was traveling in front of him and the arrival time of the previous trolleybus.

It remains only to calculate the arrival time of each trolleybus if ignore others. Here, the easiest way to analyze two cases. If , then trolley should accelerate as long as it can and the answer is equal to . Otherwise the trolley should accelerate all the time and the answer is equal to .

167B - Wizards and Huge Prize Author PavelKunyavskiy.This problem can be solved using dynamic programming.

Let d[i][j][m] — the probability we won j of first i days and get bags total capacity of m. For convenience, we assume that the bag is also a prize and the prize is a bag of capacity 0. To do that, retaining a task we must add 1 to all a[i]. Then from d[i][j][m] we can go to the d[i+1][j+1][m+a[i]] with probability p[i]/100, and to d[i+1][j][m] with probability 1-p[i]/100. The answer will be the sum of d[n+1][j][m] for all j,m such that L ≤ j ≤ m + k. This solution works for 2004, and do not fit into the time limit.

It remains to note that if we have over 200 places for prizes, it does not matter how many exactly. So we need to calculate states with m ≤ 200 and now solution works for 2003.

167C - Wizards and Numbers Author Alex-Gran.Consider the position (a, b). Let a < b. From this there is a move to . Recursively check if this position is a winning or a losing. If it is losing, then (a, b) exactly winning. Otherwise, no one will take the remainder. So everyone will subtract from larger number nonnegative degree of smaller. Then the left to learn to solve such problem. You can subtract the nonnegative powers of a from x, and player who cannot move losses. And solve it for . This problem can be solved as follows. If a is odd, then all odd number are wining. In other all the numbers, giving an odd residue modulo a+1 or -1 residue on the same module are wining. This can be easily proved by induction.

167D - Wizards and Roads Author PavelKunyavskiy.This was the first really hard problem in the contest. One of the challenges was to understand the statement. I hope that we had written the statement as clear as it possible in this problem.

Consider this graph. In particular, we consider more closely the point with the largest y.

1) It is connected with the highest points on the left and right of it.

2) It is not connected to all other points.

3) It is inside all corners on points from different sides of it.

All three of these properties are seen quite clearly in the pictures.

So,

1) Building roads on the left and right sides are independent.

2) The graph is a tree.

Once a graph is a tree, the maximum matching in it can be found greedy, or with a simple dynamic. But it works in linear time, which clearly is not enough to answer all of 105 queries.

But this is not just a tree! Those who know what it is probably already noticed, that it is Cartesian tree (also known as treep). This allows to get a tree for the subsegments in time which is O(h), counting all the necessary dynamics, where h is the height of the tree.

Well, since the city built at random points (the method for the construction of cities guarantees this), the height of the tree h = O(K + logN).

167E - Wizards and Bets Author Dmitry_Egorov.This task was about the pathes from the sources to sinks. For this pathes there was a condition which made them dependent — they should not interfere at vertexes. But in any combinatorics is much easier when everything is independent. So we should try to get rid of the condition of the absence of crossings at the vertices. It is very easy — just forget about it. Lets understand why the answer will not change: Suppose that a certain set of ways in which the two paths intersect. We show that taking into account this way, we at the same time take into account an another with the opposite sign. To do this, change the endings for paths that intersect. The signum of the permutation in this case has changed, so this set of paths is taken into account with the opposite sign and their sum is 0.

How can it helps us? If we fix the permutation, the number of sets of paths that it corresponds well to the product of the number of paths for each pair of corresponding source and sink.

Suppose that from the i-th source in the j-th sink there are cntij paths. This value can be calculated by depth-first-search and simple dynamic.

Then the answer is

. This value is called the determinant of matrix cnt, which can be calculated using Gauss method in O(S3) time where S is the number of sinks and sources.

And we had to remember about isolated vertexes. Deleting one of them either do not change the answer or multiply the answer by -1.

It remains to see that after deleting all isolated vertexes , and 3003 fine fits into TL.

Codeforces Round #113 (Div. 2) Tutorial

By RAD, 11 years ago, translation, In EnglishInitially the order of problems was A-C-E-D-B. But we were not sure about last two.

166A - Rank List

This is simple straight-forward problem — you were asked to sort the teams with the following comparator: (p1 > p2) or (p1 = p2 and t1 < t2). After that you can split the teams into groups with equal results and find the group which shares the k-th place. Many coders for some reason used wrong comparator: they sorted teams with equal number of problems by descending of time. Such submits accidentally passed pretests but get WA #13.

166B - Polygons

Polygon A is convex, so it is sufficient to check only that every vertex of polygon B is strictly inside polygon A. In theory the simplest solution is building common convex hull of both polygons. You need to check that no vertex of polygon B belongs to this hull. But there is a tricky detail: if there are many points lying on the same side of convex hull than your convex hull must contain all these points as vertices. So this solution is harder to implement and has some corner case.

Another solution: cut polygon A into triangles (by vertex numbers): (1, 2, 3), (1, 3, 4), (1, 4, 5), ..., (1, n - 1, n). The sequences of angles 2 - 1 - 3, 2 - 1 - 4, 2 - 1 - 5, ..., 2 - 1 - n is increasing. It means that you can find for each vertex of B to which triangle of A it can belong using binsearch by angle.

Similarly you can cut polygon A into trapezoids (with vertical cuts). In this case you'll need a binsearch by x-coordinate.

166C - Median

If the initial array doesn't contain number x, than you definitely need to add it (that's +1 to answer). Than do the following. While median is strictly less than x you need to increase it. Obviously the surest way to increase the median is to add a maximal possible number (105). Similarly while the median is strictly more than x, add a number 1 to the array. Constraints are small, so you can add the numbers one by one and recalculate the median after every addition.

Also there is a solution without any cases: while the median isn't equal to x, just add one more number x to array.

166D - Shoe Store

Let's sort the people by decreasing of shoes size. Observe that when considering the i-th man we are interested in no more than 2 pairs of shoes: with size li and li + 1. It allows solving with dynamics. The state will be (the number of first unconsidered man i, is pair of shoes with size li available, is pair of shoes with size li + 1 available). You have 3 options: leave the i-th man without shoes or sell him a pair of shoes of one of suitable size (if available).

166E - Tetrahedron

Obvious solution with dynamics: you need to know only how many moves are left and where is the ant. This is 4n states, each with 3 options – most of such solution passes. Observe that the vertices A, B, C are equivalent. This allows writing such solution:

int zD = 1;int zABC = 0;for (int i = 1; i <= n; i++) {	int nzD = zABC * 3LL % MOD;	int nzABC = (zABC * 2LL + zD) % MOD;	zD = nzD;	zABC = nzABC;}cout << zD;Also this problem could be solved by log(n) with binary exponentiation of some 2 × 2 matrix into power n.

Codeforces Round #112 (Div. 2) Tutorial

By HolkinPV, 11 years ago, translation, In English165A - Supercentral Point

In this problem you should just code what was written in the problem. For every point you can check if it is supercentral. Consider every point consecutively and find neighbors from every side. The complexity is O(N2).

165B - Burning Midnight Oil

This problem can be solved using binary search for the answer. obviously, if number v is an answer than every number w > v is also the answer, because the number of written lines of code could only become more. To check some number v you can use formula given in the problem, because it will have less than O(logN) positive elements. The complexity is O(log2(N)).

165C - Another Problem on Strings

You was to find number of segments [lf;rg] of the strings on which the sum equals to k (we are working with array of integers 0 and 1). We will count array sum where the value sum[i] equals to sum on segment [0;i]. We will count the answer going from left to right. Let's say we are in position pos. Now we will add the number of segments on which the sum equals to k and ends in position pos. To do it we will count array cnt where cnt[i] — number of occurrences of sum[i]. Then in position pos we add cnt[sum[pos] - k] to the answer. The complexity is O(N).

165D - Beard Graph

Beard-graph is a tree. It consists of one root and several paths from this root. There is a single path between every pair of vertices. That's why you should check whether every edge on the path between two vertices is black. If some edge is white there is no path between two vertices now.

The distances could be found separately. For every vertex v precalc such information: index of path from the root where v is situated and d[v] distance between root and v. If you know such information you can find distance between any two vertices.

To check whether every edge on the path between two vertices is black we will use segment tree. Mark black edge with value 0 and white with 1. Than repainting some edge — update in some point. The query — sum on some segment (the path between two vertices). If the sum equals to 0 there is a single path. Else the answer is -1 now. Complexity is O(NlogN).

165E - Compatible Numbers

Consider some number x from the array. Inverse all bits in x and say it is number y. Consider an integer a[i] from array. It can be an answer to the number x if for every position of zero bit from y there is zero bit in a[i] in the same position. Other bits in a[i] we can change to ones.

Then we will use such dynamic programming z[mask] = {0, 1} which means if we can change some zero bits to ones in some integer from given array a and get mask mask. Initial states are all integers from array a (z[a[i]] = 1). To go from one state to another we consider every bit in mask and try to change it to one. The length of bit representation of all integers in a is less or equal than 22.

To answer the question YES or NO for some number x you need to get value [z(y)&(1«22) - 1] (inverse all bits in x and make the length of the number 22). If you want to know the exact answer what number a[i] you should choose you can save previous states for every state z[mask] or just save it in z[mask]. Complexity O(2K * K), where K – length of bit representation of numbers (K <  = 22).

Codeforces Round #111 (Div. 2) Solution

By object022, 11 years ago, In EnglishUPD:Minor mistakes in grammar and expression fixed.

Disclaimer: This is not an official editorial.

If you have better or easy-to-understand solutions and thoughts, feel free to share your idea. Also welcome to point out mistakes so I can fix it.

160A - TwinsIt's obvious that you should take the most valueable coins. so sort values in non-decreasing order, then take coins from the most valueable to the least, until you get strictly more than half of total value.

Time complexity depends on the sorting algorithm you use. O(n^2) is also acceptable, but if you use bogosort which runs in O(n!)...

160B - Unlucky TicketDeal with the situation that "first half is strictly less than second half" first. the other one can be solved accordingly.

You can use greedy here: sort digits in first and second half seperately. then if the i-th digit in first half is always less than i-th in second half for 1<=i<=n, answer is YES.

Time complexity is as same as problem A. Count sort may run faster in O(n+10), but it's not necessary .

160C - Find PairThis is a tricky problem. When contest ends, I found there are 12 pages of accepted submissions while 60 pages of "WA on pretest 3" submissions.

First of all, sort a[].

A natural consideration is that the answer equals to (a[k/n] , a[k%n]). This algorithm will pass the sample and get "WA on pretest 3". In fact, it works only when all a[i] are distinct.

To get an AC, let's make elements distinct and weighted. For example, if there are ten 1s, we remain one of them and set its weight as 10. Now go over the whole array. for each element a[i], we can make weight[i]*n pairs using a[i] as first element. If k doesn't exceed that, go over the array again and find the second element, then print the answer. Otherwise, subtract it from K and go on.

Sort algorithm working in O(n log n) is acceptable. Java and Pascal users should beware of anti-quicksort tests.

160D - Edges in MSTLet's take a look at Kruskal Algorithm which solve MST in O(m log m) time. Sort the edges first in weight non-decreasing order, then process each edges. if the edge connects two different connected compoments, add this edge to MST then combine two compoments. We use disjoint-set union here to maintain connectivity.

The main point is that only those edges with same weight may replace each other in MST. First of all, sort edges as what Kruskal do. To get the answer, we construct MST in weight non-decreasing order, and process all edges with same weight together. Now on each step we are to face some edges with same weight x and a forest of connected compoments.

Note that for an edge, what points it connects does not matter, we only need to know what compoments it connects. Now build a new graph G', each point in G' is a connected compoment in the original forest,and edges are added to connect compoments that it connected before. Time complexity is O(|E|) here, with careful implementation.

Let's answer queries on these edges. First of all, if an edge in G' is a loop(connects the same compoment), this edge must not appear in any MSTs. If after deleting an edge V in G', G's connectivity is changed (A connected compoment in G' spilt into two. We call these edges bridge), V must be in any of MST. All edges left can appear in some MSTs, but not any.

What's left is to get all of V quickly. Maybe you hear about Tarjan before, he invented an algorithm based on DFS to get all bridges in an edge-undirected graph in O(|V|+|E|). Read this page on Wikipedia for detailed information: http://en.wikipedia.org/wiki/Bridge_(graph_theory)

Considering those compoments which don't have any edges connected don't need to be appear in G', we have |V|<=2|E|, so time complexity for Tarjan's DFS is O(|E|), where |E| is count of edges weighted x. Because each edge will be used exactly once in G', total time complexity except sorting is O(m).

160E - Buses and PeopleAs what problem setter say, we sort the people and bus together with non-decreasing order of time first(if a bus and a person has same time, put the person first). Solving it by "For each person find which bus he should take" will become rather difficult, so let's take another idea: For each bus, find who it will take.

Abstract a person as a element in currently waiting list. Now, go over the sorted people and buses, we should apply two operations:

For a person, add it to the list.

For a bus, find all person in list satisfying sj ≤ li, ri ≤ fj ,remove them from the list and record the answer.(bi ≤ tj is hold, because we process these operation by time order.)

You will find it easy to solve this using any kind of balanced trees, like AVL or SBT. For each node i on balanced tree, we store r[i] as keyword and l[i] as value, then maintain the maxinum l[i] on every subtrees. Operating on a person is to add him to the tree. When dealing with a bus, we find the node i with maxinum l[i] in the range x<=f[j] (x is keyword), if l[i]>=s[j] is satisfied, delete the node i, set ans[i]=j, update the tree and search again until found l[i]<s[j].

If you are not familiar with balanced tree, discretize every r[i] and f[j], then use a segment tree to solve it.

Time complexity is O((n+m) log (n+m)) with balanced trees or segment tree.

Codeforces Round #109: editorial

By Endagorion, 11 years ago, translation, In English155A - I_love_\%username\%

You should do what is written: go through the sequence and count the elements which are greater or less than all of its predecessors. We don't even have to store the whole sequence, just the current minimum and maximum. Complexity — O(N), but squared still works fine.

155B - Combination

Clearly, we can play the cards with bi > 0 first as each of them gives at least one extra move. After that, the number of extra moves left doesn't depend on the order of playing. The left cards all have bi = 0, so we play those of them which have larger ai. Simpler version of this solution: sort all the cards by decrease of bi, if equal — by decrease of ai, and then go through the sorted array from beginning to end, simulate the counter and sum up the points. Remember not to fall over the edge of array if the sum of bi's is larger than the number of cards. Complexity — O(n log n) (or O(n^2), if using bubblesort, which is still accepted).

155C - Hometask

154A - Hometask

Constriction saying that no letter occurs in more than one forbidden pair lets us to use the greedy solution. Without the constriction the problem is quite hard.

Let's look at all occurences of letters from some pair. They form several continuous substrings divided by some other letters. We can note that in optimal solution the substrings cannot merge, 'cause we can leave at least one letter in each of such parts. So, for each of these substrings problem is solved independently. To resolve conflicts within a substring, one has to remove all letters of some kind, 'cause while there are letters of both kinds there will be conflicts. Clearly, from each continuous substring of forbidden letters we remove all letters of the kind which number is less than another.

The answer can be counted in O(kN) with k runs through the string.

155D - Colliders

154B - Colliders

The clueless solution ''store all the enabled numbers and compare each new number with each of them'' works too slow, as we can add all the prime numbers below n, number of which is O(n / log n).

We can note that for each number k > 1 at any time no more than one collider is turned on which number is divided by k. Let us store an array which has in k-th element the number of turned-on collider which is divided by k, on 0 if there is no such at the moment. To enable the collider with number q we can look over q's divisors and check whether all the array's elements with these numbers have 0's. If some of them has a positive integer, that's the number of collider we conflict with — we can just print it and go on. Otherwise, we have to put q into all the overlooked elements.

This works in O(M sqrt(N) + N). There's faster solution as we can store all of the above only for prime divisors. Total size of the prime divisors list for number from 1 to N is O(N log log N). Thus we have a solution with complexity O(N log log N + M log N), as the number of prime divisors of k doesn't exceed log k (exact upper bound — log k / log log k * (1 + o(1)).

155E - Double Profiles

154C - Double Profiles

We want to count the number of pairs of vertices in a undirected graph which neighbours' sets are equal up to these vertices. To count the pairs which sets of neighbours are equal we can hash these sets (for instance, count the polynomial hash of adjacency matrix row) and sort the hashes. Than we have to add the pairs of doubles which have an edge between them.

We can note that there are no more such pairs than there are edges in the graph. So we can iterate through edges and check hashes for equivalence considering the presence of the edge (in case of polynomial hash we just add some degrees to them and then compare them). Other solution was to count another version of the previous hash, now adding a loop to each vertex, and to count the number of pairs just like in the previous case.

Moreover, we could try and sort the whole lists of adjacencies (which previuosly should be sorted too). As their total size is 2M, this works fine too, but needs an accurate realization. Hash solution complexity — O(N log N + M).

154D - Flatland Fencing

As the moves choices are symmetrical for both players, if one player can reach another in one move from some disposition, the other player also can reach the first. So, if we are allowed to stand in one place (i.e. a <= 0 <= b), we can just stand still and wait for another player to come. If she wants to win, she will have to step within our reach before that so that we can get her. So, if the first player doesn't reach the second initially, there is a draw as no one can ensure her victory. Thus we finished the case a <= 0 <= b: either the first player wins in one move, or there is a draw.

Now, let a and b have the same sign. Denote d = x2 — x1. If a <= b < 0, we can go to the situation with (d, a, b) = (-d, -b, -a), which is similar to the initial. So later on 0 < a.

So we have the following game: there are integers d and 0 < a <= b. In one move each player can substract an arbitrary integer number from segment [a; b] from d. The player who gets d = 0 after her move wins. If at some point d < 0, a draw is proclaimed (as no one can win anymore).

The interesting case is d > 0. Note that if d mod (a + b) = 0, the second player can use the symmetrical strategy: for every first player's move x of she can make a move a + b — x, and support the condition d mod (a + b) = 0. As d decreases, the second player eventually moves to 0 and wins. So, if d mod (a + b) = 0, the second player wins. Thus, if d mod (a + b) is in [a; b], the first player wins, as he can reduce the game to the previous case by letting the second player move in the losing situation.

What about all the other situations? Turns out all the other position are draws. We prove that by induction: let d = k(a + b) + l, where l in [0; a + b). Case l = 0, as we just proved, is losing, cases l in [a; b] are winning. If l is in [1; a — 1], we cannot move to losing position (we use the induction assumption for lesser k), but after the move a, we move to the draw position (if k = 0, we move to the negative number, otherwise we get into [(k — 1)(a + b) + b + 1; k(a + b) — 1] segment, every position from which is a draw by assumption). Similarily for l = [b + 1; a + b — 1], move to a draw — b.

154E - Martian Colony

We have to find the area of intersection of all circles containing the given set of points (it's clear that the intersection has the least area, and we have an unlimited number of circles). First, what shape does such an intersection have? Its border contains some circle arcs of radius R meeting at some points of convex hull. If we determine which points are present in the border, we can count the total area as the sum of polygon area and several circle segments.

So, how to determine those points? It's clear that if there is a circle of radius R containing all the points and having some of them on its border, then this particular point is present in the border of the intersection. If we fix the circle and move it in some direction, it eventually will run into some point — so we can find at least one point. Then we can perform something similar to ''present wrapping'' — go around the convex hull and support the set of the border points while controlling the relative position of the arcs. While this solution is fast, it is very hard to write and it was not assumed that it should be written during the contest.

There is much simpler solution based on quite different idea. We build the convex hull of the set so that no three points lie on the same line. Let us take the very large R so that every point of convex hull is present in the intersection border. As we gradually decrease R, some points will start to disappear from the border. How to determine which point falls out first? For point u in the convex hull denote its left and right neighbours l(u) and r(u). It's clear, that the first point to disappear will be such point u which has the largest radius of circle going through u, l(u) and r(u) (when R becomes equal to this radius, two arcs will merge into one in point u, while all the other will have joints in them; we will call this radius critical for u). Then we remove u from convex hull and do not take it into account. We repeat while the largest critical radius is larger than R. The rest points will be exactly the points forming the border.

How to do this fast? Note that when we remove some point from the set the critical radii will change only for its two neighbours. Let us store a priority queue containing critical radii along with point numbers. On every iteration we extract the largest critical radius, remove the corresponding point from the set, and refresh the information about the neighbours in the queue. We repeat while the largest radius is greater than R. As we just simulate the process of R decreasing, everything works correctly. The complexity of this procedure is O(n log n), as we have no more than n iterations and on every iteration we perform the constant number of operations with the queue of size at most n.

There is an unclear case, when the border contains only two points. Then on the last phase we have three points in the set and the algorithm doesn't have a clue which one to remove as they have equal critical radii. But we know that the triangle with vertices in these points is obtuse-angled, as we cannot shrink the circumcircle of an acute-angle triangle, as that would contradict with the circle existence condition. So we have to remove the point with the obtuse angle.

Разбор задач Codeforces Round #108 (Div. 2)

By Gerald, 11 years ago, translation, In English152A - MarksIn this problem you should do exactly what is written in the statement. Here is rough code of solution:

for (int i = 0; i < n; ++i){       bool wasBest = false;    for(int j = 0; j < m; ++j){        bool isBest = true;        for(int k = 0; k < n; ++k)            if(a[k][j] > a[i][j])                isBest = false;        if(isBest)                    wasBest = true;    }    if(wasBest)        ans++;}      152B - StepsLet's find a formula for the position (x, y) and vector (dx, dy), how many steps to stop the boy can do. You should use "almost" binary search, for example, see the code written by RAD.

for (long long cof = 1100000000; cof; cof /= 2)    while (onField(xc + cof * dx, yc + cof * dy)) {        xc = xc + cof * dx;        yc = yc + cof * dy;        ans += cof;    }      152C - Pocket BookIn this task, it was necessary to understand that in position 1 Vasya can get any name of a special form. More exactly, it's the name of form s = s1 s2 s3 s4 ... sm, where s1 — the first letter of any of the names, s2 — the second letter of any of the names, ... sm — m-th letter of any of the names. Then the answer to the problem is the product of cnti (1 ≤ i ≤ m), where cnti is a number of different letters in the names placed in position i.

152D - FramesIt was necessary to understand if there are two borders or not.

Let's distinguish those x — and y-coordinates, in which there are at least 3 consecutive symbols '#', becouse the length of each border is no less then 3. It is clear that the coordinates of the corners of borders should be chosen only from those selected x and y. In general, the various selected x no more then 4 and various selected y no more then 4.

Except that case when the height or width of the first border is 3, and length of the second side of this border is more than 3, and one side of the second border fills a part of the inside first at least.

For example:

######################.....########The first border:

########.....########..............The second border:

.......########.....##.....########There are 7 different y-coordinates in the example.

Carefully processed these cases separately, it is quite simple. (Let's choose 4 y-coordinates: minimum, maximum, second minimum and second maximum).

Otherwise, if the amount selected x — and y-coordinates no more then 4, then let's choose opposite corners of the first and second borders and verify that the selected borders — the correct borders and there are no other characters '#'. Checking is carried out at O(n + m) or O(1) (using partial sums).

152E - GardenThe solution of this problem is based on dynamic programming. dp[mask][v] — the value of the minimum correct concrete cover, if we consider as important elements only elements of the mask mask, and there are additionally covered the vertex v = (i, j) of the field.

There are two types of transfers.

First of all we can, as if to cut coverage on the vertex v. Then you need to go through subpattern of vertex submask, which will go to the left coverage and make an optimizing transfer. Update dp[mask][v] with the value dp[submask][v] + dp[mask ^ submask][v] - cost(v).

Second, perhaps in the vertex v in the optimal coverage mask mask, which covers the vertex v, you can not make the cut separating the set of vertices. In this case, this vertex forms something a kind of <>. And there a vertex u exists, on which we can make the cut, with the whole shortest path from a vertex u to v belongs to the optimal coverage. Let's precalculate the shortest paths between all pairs of cells. Now to make this transition, we should count the value of dynamics dp[mask][v] for all vertices v only on the basis of the first transition. Now you can make the second transition. For all u, dp[mask][v], update the value of dp[mask][u] + dist(v, u) - cost(u).

Let's process separately state in which exactly one bit in the mask, and the vertex which corresponding to this bit is equal to v. In this case the answer is equal to cost(v), of course.

Thus, each solution is obtained for the O(min(3k·n·m, 2k·(n·m)2)).

Codeforces Round #107. Tutorial.

By SergeiFedorov, 11 years ago, translation, In English150E - Freezing with StyleIf there exists a path with the median  ≥ k, for some k, then there exists a path with the median  ≥ q, for each q ≤ k. That means we can use binary search to calculate the answer. So now the task is: is there any path with the median greater or equal to Mid ?

We will calc the edge as  + 1 if it's wight  ≥ Mid, or as  - 1 in other case. Now we only need to check if there exists a path with legal length and the sum greater than or equal to zero.

Let's denote some node V as a root.

All paths can be divided into two types: that contains v, and that do not. Now we are to process all first-type paths and run the algorithm on all subtrees. That is so-called divide-and-conquer strategy.

We can trivially show that it is always possible to choose such vertex v that all it's subtrees will have size less than or equal to the size of the whole tree. That means that each node will be proccessed in LogN trees max.

So, if we solve the task for one level of recursion in O(F(N)), we'll solve it in time O(F(N) * log2(N)) on the whole.

First, lets get O(N * Log(N)). For each node we shall calc it's deepness, cost of the path to the root ans the first edge (the number of the root's subtree). It will be better now to use 2 and 0 as the edges costs, instead of -1 and 1. Now we shall process root's subtrees one by one. For each node we want to know if there exists a node u in any other subtree such that the

Unable to parse markup [type=CF_TEX]

and cost[v] - deep[v] + cost[u] - deep[u] ≥ 0. To do that we need to know the maximum of the function (cost[u] - deep[u]) with the deep values between max(0, L - deep[v]) and R - deep[v] inclusive. To achieve O(N * log(N)) you need only to use segment tree.To achieve an AC contestants were to write all code optimally, or to think of one more idea. It is possible to have O(N) on one level of recursion and O(N * log2(N)) in total if you sort roots subtrees in non-decreasing order and use any structure that can answer getmax query on all segments of length (R - L + 1) and all prefixes and suffixes.

Best of luck to you in upsolving this problem!

150D - Mission ImpassableIn this problem you have to use dynamic programming. For our convenience we will calulate three type of values:

Best[l][r] — best result player can achieve on the segment [l, r].

Full[l][r] — best result player can achieve on the segment from [l, r] if he fully destroys it.

T[l][r][Len] — best result player can achieve on the segment from [l, r] and remain the palindrome of length len and only it.

Now solution:

Full[l][r]. Let's look which move will be the last. This will be removing the palindrome of length len and c[len] ≥ 0. What is the best result we can achieve? c[len] + T[l][r][len].

Best[l][r]. Either we will destroy all subtring from l to r, either there exists a letter which we did not touch. That means that all our moves lies fully to the left or fully to the rigth to that position. So Best[l][r] = Full[l][r] or Best[l][r] = Best[l][m] + Best[m + 1][r] for some m, l ≤ m < r.

T[l][r][len]. len = 0, len = 1 — two special cases, which is easy to solve without any dynamic. In other case, let's take a look on the left-most position. It either will lie in the result string or not. If not, then let's find the first position which does. Denote it as m (l < m ≤ r). Everything what lies to the left need to be fully deleted. So the answer is Full[l][m - 1] + T[m][r][len] (for l < m ≤ r). Similarly, for the right-most letters. If it does not lies in the result string we remove everything to the right and our result is T[l][m][len] + Full[m + 1][r] (for l ≤ m < r). The last option: both left-most and rigth-most letters lies in the result string. It is possible only if s[l] = s[r]. So our result is T[l + 1][r - 1][len - 2] (only if s[l] =  = s[r]).

150C - Smart CheaterFirst lets use the linearity of expected value and solve task independently for each passanger.

For each path segment (route between neighboring stations) we calculate expected value of profit in case we do not sell a ticket for this segment. In case we sell it the expectation of profit is 0.

Now we only need to find the subsegment of segment [a, b] of maximal sum for each passanger.

That's easy to do by the segment tree, we only need to calc four values for each node:

best — the maximal sum of elements on some subsegment

max_left — the maximal sum on prefix

max_right — the maximal sum on suffix

sum — the sum of all elements

150B - Quantity of StringsWe can offer you two solitions:

You can build a graph with positions in sting as a nodes and equality in any substring of length k as edges. Lets denote e the number of components in the graph. The answer is me.

Analyze four cases:

k = 1 or к > n, the answer is mn.k = n, the answer is m(n + 1) / 2.k mod 2 = 1, any string like abababab... is ok, so the answer is m2.k mod 2 = 0, all symbols coincide and the answer is m.150A - Win or Freezeif Q is prime or Q = 1 than it's victory.

We loose if: Q = p * q or Q = p2, where p and q are prime.

It is quite obvious that it is always possible to move in bad position in any other case. That means all other numbers grants us the victory.

We only have to check if Q has a divisor of the loose type. We can easily do it in O(sqrt(Q)) time.

151B - Phone NumbersIn this task you were to implement the described selection of the maximum elements.

151A - Soft DrinkingSoda will be enough for gas = (K * L) / (N * l) toasts.

Limes will last for laim = (C * D) / N toasts.

Salt is enough for sol = P / (p * N) toasts.

Total result: res = min(gas, laim, sol).

Codeforces Round #106 (Div. 2) Tutorial

By NALP, 11 years ago, translation, In English149A - Business tripFirst, it is clear that if the sum of all numbers ai is less than k, then Peter in any case will not be able to grow a flower to the desired height, and you should output <<-1>>.

Secondly, it is easy to see that if we want to choose a one month of two, in which we watered the flower, it is better to choose one where the number of ai is more. Thus, the solution is very simple: let's take months in descending order of numbers ai and in these months water flowers. As soon as the sum of the accumulated ai becomes greater than or equal to k — should stop the process, the answer is found.

149B - Martian ClockIn this task required only the ability to work with different numeral systems. Let's try to go through numeral bases, each base to check whether it is permissible, as well as convert hours and minutes to the decimal system and compared with 24 and 60, respectively.

What is maximal base, that we need to check? In fact, it is enough to 60, because 60 — upper limit on the allowable number. It follows from the fact that if the number in an unknown number system consists of one digit, then its value in decimal not ever change, otherwise its value is not less than the base.

It is also worth to consider the case with the response <<-1>>, for this example, you can check a big base, such as 100, and even if the time for him correct, then for all large, it is also correct and the answer is <<-1>>.

149C - Division into TeamsSort all the boys on playing skill. Then, if we send in the first team all the boys standing in a sorted array for odd places, and the second — even standing on the ground, then all requirements for division executed.

The first two requirements are obviously satisfied.

To prove the third we consider the geometric representation: Let each child designated point on the X axis with a value equal his playing skill. Connect the points with segments numbered 1 and 2, 3 and 4, and so on. If n is odd, then join the last point with the nearest the previous one.

Obviously, all these segments don't intersect in pairs, except at the points, and their total length is equal to the difference amounts to play boys' skills contained into the first team and second team. It is also clear that all of these segments completely contained in the interval [0, max(ai)], as well as the pairs are a length of zero crossing, the third requirement is satisfied, which we proved.

149D - Coloring BracketsWe introduce the notation of colors: 0 — black, 1 — red, 2 — blue. Note that a single pair of brackets has 4 different coloring: 0-1, 1-0, 0-2, 2-0.

Consider the dynamic programming, where the state is (l, r, cl, cr), where the pair (l, r) defines a pair of brackets, and cl and cr denote a fixed color for them. The value of the dynamic is a number of ways to paint all the parenthesis brackets inside the interval (l, r) in compliance with all conditions.

We write down all the pairs of brackets that are directly placed into a pair of (l, r), let k of their pieces. Moreover, we consider only the first level of nesting, it is directly attached.

In order to calculate the value of the dynamics for the state, within this state shall calculate the another dynamic, where the state is a pair (i, c) which means the number of correct colorings of the first i directly nested parentheses, and all inside them, if the latter closing bracket has a color c. Calcing the values of this dynamic is very simple, let's try to paint a (i + 1)-th parenthesis in one of four variants, but you should keep in mind possible conflicts. In such dynamics the initial state is a pair (0, cl), and the final result is sum over the states of the form (k, c), where c must not conflict with the cr.

The answer to the whole problem may be calced as the internal dynamic. Time of solution — O(n2) by a factor of about 12.

149E - Martian StringsWe will solve the problem separately for each m strings. Thus, suppose we have a string p, its length is l, and we need to check whether the Martian be seen.

We introduce additional arrays: let pref[i] is minimal position in the s of the begin of occurrence p with length exactly i, and let suff[j] is the maximum position in the s of the end of occurrence p with length exactly j

It is easy to understand that a Martian could see the p, if there exists an i, that suff[l - i] ≥ pref[i] + l - 1.

How to calculate the arrays? For pref array is sufficient to find Z-function p#s, but for an array of suff — Z-function r(p)#r(s), where r(t) means the reversed string t. Using an array of Z-functions calcing of arrays suff and pref is trivial.

Codeforces Round #105 (Div. 2): editorial

By Nickolas, 11 years ago, translation, In EnglishSo, here goes the editorial. I'll tell you right away that nobody guessed MikeMirzayanov's problem (nice disguise, er?) — it was problem C about the picky princess. Actually, this was the first problem of the round, the rest of problems I invented to keep up the lovely topic.

148A - Insomnia cure

The number of dragons D can be quite small, so the problem can be solved in a straightforward way, by iterating over dragons 1 through D and checking each dragon individually. Time complexity of such solution is O(D). There exists a smarter solution with O(1) complexity, based on inclusion-exclusion principle. You'll have to count the numbers of dragons which satisfy at least one, two, three or four of the damage conditions Ni, i.e., dragons who have index divisible by LCM of the corresponding sets of numbers. Remember that the number of numbers between 1 and D which are divisible by T equals D / T. Finally, the number of dragons that get damaged equals N1 - N2 + N3 - N4. You'd have to use this method if the total number of dragons was too large for iterating over it.

148B - Escape

In this problem it was enough to simulate the sequence of events that happen on the line between the cave and the castle. My solution focused on two types of evens — "the dragon is in the cave and sets off after the princess" and "the dragon and the princess are at the same coordinate"; in this case it's enough to keep track of time and princess' coordinate, no need to store dragon's one. The first type of event happens for the first time at time T, when the princess' coordinate is T  *  Vp. If at this time she has already reached the castle, no bijous are needed. Otherwise we can start iterating. The time between events of first and second type equals the princess' coordinate at the moment of first event, divided by Vd - Vp. Adjust the princess' coordinate by the distance she will cover during this time and check whether she reached the castle again. If she didn't, she'll need a bijou — increment the number of bijous required. The second part of the loop processes the return of the dragon, i.e., the transition from second type of event to the first one. The time between the events equals princess' new coordinate, divided by the dragon's speed, plus the time of straightening things out in the treasury. Adjust princess' coordinate again and return to the start of the loop (you don't need to check whether the princess reached the castle at this stage, since it doesn't affect the return value).

The complexity of the algorithm can be estimated practically: the number of loop iterations will be maximized when dragon's speed and distance to the castle are maximum, and the rest of parameters are minimum. This results in about 150 bijous and the same number of iterations.

You'll also need to check for the case Vp ≥ Vd separately — the dragon can be old and fat and lazy, and he might never catch up with the princess.

148D - Bag of mice

Initially this problem was a boring homework one about drawing balls out of the bag. But seriously, do you think a dragon would have something so mundane as a bag of balls in his cave? And he definitely could find some use for a bag of mice — for example, using them to scare the princess or as a snack.

If mice were balls and never jumped out of the bag, the problem would be doable in a single loop. Suppose that at some step we have W white and B black mice left in the bag, and the probability to get into this state is P (initially W and B are input values, and P = 1). The absolute probability to get a white mouse at this step is P * W / (B + W) (the probability of getting to this state, multiplied by the conditional probability of getting white mouse). If it's princess' turn to draw, this probability adds to her winning probability, otherwise her winning probability doesn't change. To move to the next iteration, we need the game to continue, i.e., a black mouse to be drawn on this iteration. This means that the number of black mice decreases by 1, and the probability of getting to the next iteration is multiplied by B / (B + W). Once we've iterated until we're out of black mice, we have the answer.

Unfortunately, the mice in the bag behave not as calmly as the balls. This adds uncertainty — we don't know for sure what state we will get to after the dragon's draw. We'll need a recursive solution to handle this (or dynamic programming — whichever one prefers). When we solve a case for (W, B), the princess' and the dragon's draws are processed in a same way, but to process the mouse jumping out of the bag, we'll need to combine the results of solving subproblems (W, B — 3) and (W — 1, B — 2). The recursive function of the reference solution is:

map<pair<int, int>, double> memo;

double p_win_1_rec(int W, int B) {    if (W <= 0) return 0;    if (B <= 0) return 1;    pair<int, int> args = make_pair(W, B);    if (memo.find(args) != memo.end()) {        return memo[args];    }    // we know that currently it's player 1's turn    // probability of winning from this draw    double ret = W * 1.0 / (W + B), cont_prob = B * 1.0 / (W + B);    B--;    // probability of continuing after player 2's turn    cont_prob *= B * 1.0 / (W + B);    B--;    // and now we have a choice: the mouse that jumps is either black or white    if (cont_prob > 1e-13) {        double p_black = p_win_1_rec(W, B - 1) * (B * 1.0 / (W + B));        double p_white = p_win_1_rec(W - 1, B) * (W * 1.0 / (W + B));        ret += cont_prob * (p_black + p_white);    }    memo[args] = ret;    return ret;}The time complexity of recursion with memoization is O(W*B), i.e., the number of different values the input can take. Note that in this implementation access to the map adds log(W*B) complexity, but you can avoid this by storing the values in an 2-dimensional array.

148E - Porcelain

This problem involved dynamic programming with precalculation.

The first part of the solution was to precalculate the maximal cost of i items taken from the shelf (i ranging from 1 to the number of items on the shelf) for each shelf. Note that this can't be done greedily: this can be seen on the shelf 6: 5 1 10 1 1 5.

The second part is a standard dynamic programming, which calculates the maximal cost of items taken for index of last shelf used and total number of items taken. To advance to the next shelf, one has to try all possible numbers of items taken from it and increase the total cost of items taken by corresponding precalculated values.

Codeforces Round #104 - EditorialBy witua, 11 years ago, translation, In EnglishDIV2-A Lucky Ticket:

In this problem everything is obvious: if all digits are lucky and sum of the digits of the first half equals to the sum of the digits of the second half, then answer is YES, in other case - NO. All this can be checked by single loop through all the digits. 



DIV2-B Lucky Mask:

You can see that, in worst case, the answer will be equal to 177777. It can't be greater. So, only thing you need is to write some function F(x) which will return mask of the x. After that you need to write such kind of code: 



x = a + 1;

while (F(x) is not equal to b)

increase x;



and x will contain the answer.



DIV2-C DIV1-A Lucky Transformation:

You need to find two numbers: c47 (number of such positions i, that ai = 4 and bi = 7) and c74 (number of such positions that ai = 7 and bi = 4). After that the result will be max(c47, c74) (because you need to obtain min(c47, c74) swaps, the rest max(c47, c74) - min(c47, c74) are editings of digits).



DIV2-D DIV1-B Lucky Number 2:

Let we have some string result s. Let then delete all repititions, i. e. while we have some pair adjacent equal digits, we delete one of them. Let call formed string a root. In root there will be no adjacent equal digits, so |cnt(47) - cnt(74)| ≤ 1. So, if |a3 - a4| > 1, then answer is "-1". Now, if we would know the root, that will be used in our result, we can create result. 

You can see, that if a3 = a4, then root must be 47474747...474 or 747474...747. If a3 < a4, then root is 74747474....74. If a3 > a4, then root is 474747...47. Length of the root must be such that it fulfill a3 and a4.

Now, when you have a root, you can build result. You just need to find first occurrence of 4 in root and insert the rest of 4 from a1 right next to that digit. To add the rest of 7, you need to find last occurrence of 7 in root.

The answer does not exits if, after constructing the root, you have used more 4 than a1 or more 7 than a2.



DIV2-E DIV1-C Lucky Different: 

As you probably know, the number of lucky numbers in range [1;109] is 1022. We use this fact to solve problem. Let C[i] - number of occurrences of i-th lucky number in array a. Now we schould calculate DP with parameters DP[pos][cnt] - what is the number of subsequences that we use lucky numbers up to pos-th and our subsequence contains exactly cnt lucky number. If we are on state DP[pos][cnt] we can do two things: do not use pos-th lucky number (and do DP[pos+1][cnt] += DP[pos][cnt]) or use pos-th lucky (and do DP[pos+1][cnt+1] += DP[pos][cnt]*C[pos], because you have C[pos] of pos-th lucky number).

Now we need to find total result. To do that we iterate through the number of lucky numbers in our subsequence i. Then you need to multiple that number by C(countunlucky, k - i) (bin. coefficient), where countunlucky - number of unlucky numbers of sequence. Sum for all such i will be the total result.



DIV1-D Lucky Pair:

The main point of this problem is that number of lucky numbers in array is  ≤ 1000. Imagine that there is array of 1000 number in range [1;1000] each, and you want to find number of such pairs that there is no equal number in both segments. How to solve this problem? Let we have fixed left point of right segment, let it be i. The you should iterate through all j (i ≤ j) - right point of right segment. If you have some fixed right segment [i;j], then there is some set S of numbers that are in that right segment. So, segment [0;i - 1] will be divided in some subsegments that don't contain any number from S. For example, let S = {1, 2, 3} and segment [0;i - 1] is [2, 4, 2, 3, 6, 5, 7, 1], then there will be such subsegments (0-based numeration): [1;1], [4;6]. Of course, any subsegment of that subsegments will be good too: they dont contain any number from S, too. So, you can keep in set (or some structure like set) all good subsegments and keep number of all good subsegments in [0;i - 1]. When you iterate j from i to n - 1, you will add some numbers to S. When you add some number in S, you should add all occurrences of that number in subarray [0;i]. Notice, that when some number is already in S, you don't need to look at that numbers. So, for fixed i you should do O(n * logn) operations - any number from a[0;i - 1] will be added at most once to set. 

Now, we have not only lucky numbers. So, the problem is the same, but between number there are some "bad" numbers - in this case this are unlucky numbers. But, you can notice, that if we will fix only such i that a[i] is lucky and iterate j only such that a[j] is lucky then you can calculate result in the same way that in simpler problem. But that method allow you to only count such pairs that right one contains some lucky number. So you also need to count other ones. To do so you can fix some i - left point of right segment, such that a[i] is unlucky. Let F(i) equals to minimum such j (j > i) that a[i] is lucky. Then there are F(i) - i ways to expand right segment. All such right segments doesn't contain any lucky number. So any left segment will be good. And there are i * (i + 1) / 2 of such left segments (0-based). 



DIV1-E Lucky Switch:

(with help of sjtu_pigoneand)

To solve this problem you need to handle segment tree with following information:

n4: number of 4-digits in node range.n7: number of 7-digits in node range.n47: maximum non-decreasing subsequence in range.n74: maximum non-increasing subsequence in range.

When we reverse digits in some node we just swap(n4, n7), swap(n47, n74). When we update node we keep n4(father) = n4(left_son) + n4(right_son), n47(father) = max(n47(left_son) + n7(right_son), n4(left_son) + n47(right_son), n4(left_son) + n7(right_son)). Then for each count query result is n47.

Read this tutorial about segment trees.

Codeforces Round #103 (Div. 2) Разбор Задач.By Polichka, 11 years ago, translation, In EnglishProblem A

It's clear that the leftmost soldier with the maximum height should be the first and the rightmost soldier with the minimum height should be the last. Thus we will minimize the number of  swaps. And the answer is number of leftmost soldier with the maximum height - 1 + n - number of rightmost soldier with the minimum height. And if the leftmost soldier with the maximum height is more right then the rightmost soldier with the minimum height we should subtract one from the answer.

Problem B

Let's try to check all integer points of the table perimeter and add to the answer such of them that don't cover by circles of radiators. Let xa < xb and ya < yb, and if it's not true then swap xa and xb, ya and yb. So generals sit in the next integer points: (xa, y), (xb, y), (x, ya), (x, yb), where  xa ≤ x ≤ xb и ya ≤ y ≤ yb. We should be attentive when we count the generals who sits in points: (xa, ya), (xa, yb), (xb, ya), (xb, yb),  that don't count them twice.

Problem C

Let's count number of each letter in the second string and save it, for example, in array a[1..26]. For the first strings' prefix of length n, where n is the length of second string, (it's the first substring) we count number of each letter in array b[1..26]. We don't count characters ``\texttt{?}''. If there are b[i] ≤ a[i] for all i, then it's good substring. Then go to the second substring: subtract from the array b the first character:  b[s[1] - 'a' + 1] –  and add n + 1 character: b[s[n + 1] - 'a' + 1] +  + . If some of these characters is ``\texttt{?}'' then we shouldn't do for it the subtraction or addition. Then repeat the showed check and go to the next substring. Let's repeat this procedure for all substrings of length n.

Problem D

d[i] --- the minimum distance from vertex s to vertex i, that counted by algorithm of Dijkstra. "et's count the number of points on each edge of the graph that are on the distance l form the vertex s (and l --- the minimum distance from these points to s).

For edge (u, v):

if d[u] < l and l - d[u] < w(u, v) and w(u, v) - (l - d[u]) + d[v] > l then add to the answer the point on this edge, the distance of which to the vertex u is l - d[u];

if d[v] < l and l - d[v] < w(u, v) and w(u, v) - (l - d[v]) + d[u] > l then add to the answer the point on this edge, the distance of which to the vertex v is l - d[v];

if d[v] < l and d[u] < l and d[u] + d[v] + w(u, v) = 2 * l then add to the answer the point on this edge, the distance of which to the vertex v is l - d[v] and to the vertex u is l - d[u].

And if d[i] = l, then let's add to the answer this point.

Problem E

It's clear that the nearest squares of the secondary diagonal to some sportsman form the "segment" of the squares of the secondary diagonal. Let's write these segments for each sportsman.

Let's consider sportsmen so that we should compare to each sportsman excactly one square of the secondary diagonal from his "segment" and to each square of the secondary diagonal no more then one sportsman. It's clear that sportsmen can reach theirs squares without occupying the same square simultaneously with another sportsman. We should maximize the number of choosen sportsmen. And solution of this reformulated problem is greedy.

Codeforces Round #102 - EditorialBy goryinyich, 11 years ago, In EnglishThis is initial version only. TeX-style and Russian version will appear soon.

Problem A (div. 2) - Help Vasilisa the Wise 2

There are many ways of solving this easiest problem of the contest. I list them in the order of increasing realization difficulty:1. If you use C++. Take permutation (1, 2, ..., 9). Suppose elements 1-4 are numbers we're looking for. Use next_permutation() to generate all possible combinations of numbers and just check that all conditions are met.2. Pure brute-force - just 4 nested for() cycles for each unknown number. Here one should not forget to check that all numbers are pairwise different. This takes additional 6 comparisons.3. One may note that, given the first number in the left upper cell, one may restore rest of the numbers in O(1). So, just check 9 numbers in the first cell (let it be x), restore other numbers from the given conditions:

(x, a)(b, c)

a = r1-x, b = c1-x, c = r2-b = r2-c1+x

and check that they all lie in [0..9] and rest of the conditions are met.4. O(1) solution - one may derive it from the previous approach: since x+c = d1 => 2*x + r1 - c1 = d1 => x = (d1+c1-r1)/2So, you find x, check that it is in [0..9], restore all other numbers as in the previous approach and check that all conditions are met.

Problem B (div. 2) - Help Kingdom of Far Far Away 2

This was purely technical problem. String type is the best way to store the number. The main steps to get this problem is just to follow problem statement on how a number in the financial format is stored:1. Divide the number in the input into integer and fractional parts looking for position of the decimal point in the input number (if input number doesn't have decimal point - assume fractional part is empty string)2. Insert commas into integer part. This is done with one for() / while() cycle3. Truncate/add zeroes to length 2 in the fractional part4. Form the answer [integer part].[fractional part]. If initial number had minus in the beginning - add brackets to both sides of the answer.

Problem A (div. 1) / C (div. 2) - Help Farmer

Due to quite low constraint this problem is easily solvable by brute-force. Without loss of generality assume that A <= B <= C. Then it is clear that A cannot exceed , and, given A, B cannot exceed . Then all solution is just two cycles:

for (long long a = 1; a*a*a <= n; ++a) if (n%a == 0){ for (long long b = a; b*b <= n/a; ++b) if ((n/a)%b == 0){  long long c = n/a/b;  ...   }}

Since we assumed A <= B <= C, now it is not clear which parameter (A, B or C) is the height of haystack, so inside the cycle one should consider all three possibilities. For any N <= 10^9 the code inside the second loop runs no more than 25000 times, so this solution fits timelimit even for N <= 10^11 and maybe larger. Why it's so quick? It's because of the fact that number of divisors of arbitrary number N does not exceed about . That's why all similar solutions and maybe some other streetmagic that has anything common with divisors of N, should get AC.

Problem B (div. 1) / D (div. 2) - Help General

This problem was not on derivation of the general formula m*n - (m*n)/2 (only this would be too simple for the second/fourth problem, isn't it?) but rather on accurate investigation of several cases. Unfortunately, many participants were very eager to submit the formula above, that's why there were so many hacks. I would say: this is not jury fault - pretests were made very weak intentionally, partially - to give you some space for hacks; but jury didn't presume there would be so many hacks. This is your fault of submitting unproven solutions. This is large risk given Codeforces rules, and this time risk-lovers were not lucky =)

Ok, let's come to the solution. Without loss of generality let's assume m <= n. Then we have the following cases:1. m = 1 x n fields. It is obvious that here the answer is n.2. m = 2 x n >= 2 fields. Here the correct formula is 2*[2*(n/4) + min(n%4, 2)]. Why so? To see this draw the board for arbitrary n and draw all possible knight moves on it. In general, you'll see four not overlapping chains. Since you cannot place soldiers in the neighboring cells of any chain, then for a chain of length L the answer doesn't exceed (L - L/2). On the other hand, it is clear that the answer (L - L/2) is always possible since soldiers on different chains never hurt each other. If you consider fields with different remainders n%4, the formula above becomes clear.3. m >= 3 x n >= 3 fields, except the cases 3 x 3, 3 x 5, 3 x 6 and 4 x 4. Here one may use general formula m*n - (m*n)/2. Why so? It is known (or becomes known with google) that for all such fields knight tours exists. Any knight tour is just a chain of lenght m*n, so by the logic above one cannot place more than m*n - (m*n)/2 soldiers on it. On the other hand, if one makes chessboard coloring of the field, it is clear that the answer above is always achievable if one chooses cells of one color as places for soldiers. So, formula above is proved.4. Cases 3 x 3, 3 x 5, 3 x 6 and 4 x 4. Here we can't use the logic above to prove that the above formula is also right here. The easiest way is to verify it using brute-force or pen and paper. This concludes the solution.

Problem C (div. 1) / E (div. 2) - Help Caretaker

This is technical problem, one may use several approaches to solve it. Additional complexity is to restore the answer after you got it.1. Dynamic programming "on the broken profile" - I'll not explain the approach here in detail, you can find explanation of it on the Internet or even on Codeforces. Worth to point out, care should be taken of your code memory usage.2. Search with memorization - one jury solution uses logic like DP with usual (not broken) profile: move by rows (or by columns), try all possible T placements such that upper cell of T's is in the given row and run the same search procedure for the next raw, passing the state of the two last filled rows of the board to it. For the given board state save the answer recursive function returned (max number of T's one may place on the not-yet-filled part of the board) and use it in the future as the answer for the given state. This requires only O(n*2^(2^m)) of memory and works about 2 sec. on maxtest 9 x 9.3. Branch and bound. Another jury solution recursively tries all possible tilings of the board with T's. If on some step it occured that number of T's on the board plus number of T's one can theoretically place on the remaining part of the board doesn't exceed existing best answer - trim this node. Such solution is the easiest to code and it works only 0.5 sec. on maxtest, however it is not obvious from the very beginning.4. Precalc - not to write a lot of code (applying DP or search with memorization) and not to deal with possible time/memory limits, some participants did the right thing: using the third approach, just precalculated answers for large (or for all possible) inputs.

Problem D (div. 1) - Help Donkey and Shrek 2

Solving this problem involves two basic steps: firstly, to recognize that we have nothing else than generalised version of Nim and secondly, to solve it.The first part is not difficult: assuming we don't have rows with soldiers of only one color (in which case the game usually becomes trivial, since one or both players may play infinitely long), let the number of cells between two soldiers in every non-empty line be the size of the corresponding piles in nim. Then attack according to the rules of the given game is the move in the corresponding nim that allows you to take as much as you like stones from at most k piles (but at least 1 stone should be taken). Such generalized nim is called Moore's nim-k, and we should solve it to find the winner in the initial game. As any source you may google (except Russian Wikipedia) shows, solution to the Moore's nim-k is the following:

Let's write binary expansions of pile sizes, and for any position check that sum of digits on the given position in all expansions is divisible by k+1. If this holds for all positions - then the winner is the second player, otherwise - the first player. Proof of the fact may be found here: http://www.stat.berkeley.edu/~peres/yuvalweb/gath9.pdf

Let's consider the following case for k = 2:

R-G--R--G-R---GR---G

Corresponding 4-piles nim-2 for this test is (1, 2, 3, 3). After writing binary expansions of piles sizes we get01101111Sums of digits in both positions (3) are divisible by k+1=3, so here Second wins.

But this is still not full solution to the initial game, because we forget about retreat possibility. But it is simple here: only player losing the game in which only attacks allowed may want to retreat (winner just plays corresponding nim by attacking). But if loser retreats, winner just restores initial position attacking in the corresponding rows. And since loser cannot retreat infinitely, he cannot improve his win chances with retreat moves. That's it.

And finally, don't forget about tests like:2 2 2GGRRAnswer: SecondAll such tricky cases were in pretests.

Problem E (div. 1) - Help Greg the Dwarf 2

This problem was "just" about finding the shortest path on a cone. Unfortunately, even though jury lowered precision requirements to 10^-6 and included all possible general cases in pretests, nobody tried it =(For solution, let's consider all possible cases of two points on the cone surface (including its basement):1. Both points on the basement. Here it is clear that Euclidean distance between points is the answer to our problem.2. Both points on the lateral surface. One may think that optimal path is also always lies on the lateral surface. In this case it is easy to find length of an optimal path from geometric considerations (by considering loft of the lateral surface). But 10-th pretest disproves that it is always optimal:

100 10099 0 1-99 0 1Answer: 202.828427124746210

So, optimal path may go through the basement. In this case it has two points that lie at the same time on the basement and on the lateral surface (let's call them A' and B'), so length of the path through this points is easy to find by adding length of the three different segments - AA', A'B' and B'B. So the problem is reduced to finding optimal positions of A' and B'? Let's assume that polar angle of the first point in XOY plane is a1 (0 <= a1 < 2*PI) and polar angle of the second point is a2 (0 <= a2 < 2*PI). Length of the shortest path between A and B passing through the points A' and B' (AA' + A'B' + B'B) is some function of two arguments that we want to minimize - f (a1, a2). One may minimize it using, for example, grid or any other suitable numerical approach.3. One point on the basement and another point on the lateral surface. This case is similar to the previous one - optimal path passes some point C' on the "brink" whose optimal polar angle we are to find. In this case we optimize function of one argument g(polar angle(C')) = AC' + C'B.

Codeforces Round #101 (Div. 2) Разбор Задач.By Gerald, 11 years ago, translation, In English141A - Amusing Joke It was enough for solving this problem to calculate for each letter: ac - amount of occurrences of letter c in first and second strings in input, bc - amount of occurrences of letter c in third string in input. If  the answer is "YES" else "NO". 

141B - Hopscotch  Let's bust the "level" 0 ≤ i ≤ 106, in which assumedly the stone could hit. Let’s find the minimal number of square on this level. Then we can understand, how many squares there are on this level: one or two. Then we check with one or two ifs (if on this level two squares) if the stone is in corresponding square or not. If the stone is inside then output the answer. If we didn't find any square, where the stone is, output "-1".  

141C - Queue  Let's sort the pairs (namei, ai) by ascending of ai. If there is an index i: 0 ≤ i < n that ai > i, then answer is "-1". Otherwise the answer exists. We will iterate through the array of sorted pairs from left to right with supporting of vector of results res. Let on the current iteration ai = n - i, then we must transfer the current man in the position ai. It can be done in C++ with one line: res.insert(res.begin() + a[i], man); 

141D - Take-off Ramps  Let's generate the weighted directed graph of all ramps. The graphs' vertexes are the important points on the line Ox, there are points: 0, L, xi - pi, xi + di. The graphs' edges are the possible ramp jumps: transfer from point xi - pi to point xi + di or transfer from vertex in neighboring vertexes (neighboring means that we get the next and previous important points on the line). The weights of these edges are correspondingly pi + ti and xv + 1 - xv, xv - xv - 1. We must note that in the transfers we can't get in the negative part of Ox, and we must delete this transfers.

Then we must find and output the shortest path in this graph from vertex 0 to L. This can be done, for example, with Dijkstra's algorithm for the sparse graphs. 

141E - Clearing Up  In this problem we must find the minimum spanning tree, in which the half of edges are marked with letter 'S'.

There are  n - 1 edges in this tree, because of it if n is even then the answer is "-1".

Let's delete from the given graph all S-edges. And there are cnt components in obtained graph. For making this graph be connected we must add cnt - 1 edges or more, that's why if cnt - 1 > (n - 1) / 2 the answer is "-1". Then we find cnt - 1 S-edges, that we must add to the graph, so that it become connected. If cnt - 1 < (n - 1) / 2 then we will try to add in this set of edges another S-edges, so that the S-edges don't make circle. We must do all of this analogically to Kruskal's algorithm of finding a minimum spanning tree. If we could get a set of S-edges of (n - 1) / 2 elements, that there are exactly cnt - 1 edges and no S-circles, then the answer exists, Then we must add to this set (n - 1) / 2 M-edges, that forms with our set of edges the minimum spanning tree, it must be done analogically with Kruskal's algorithm.


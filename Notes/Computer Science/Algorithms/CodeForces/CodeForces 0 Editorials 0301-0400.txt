ICM Technex 2017 and Codeforces Round #400 (Div. 1 + Div. 2, combined) Editorial

By DeshiBasara, 6 years ago, In English776A - A Serial KillerYou just have to store the current two strings. This can simply be done by replacing the string to be deleted with the new string. This can be done in O(n)

Code776B - Sherlock and his girlfriendHint: Observe that if i + 1 is prime, then only would the pieces having their prices as the multiples of i + 1 would have to be of a different color.

Editorial: We are required to color the jewelry pieces such that for every jewelry piece i having a price i + 1, all the pieces whose prices are prime divisors of i + 1 should have colors different from that of the ith piece. This can be achieved by simply coloring all the pieces with their prices as primes in one color, and all the other pieces in a second color. We calculate the Sieve of Eratosthenes upto the range of n( ≤ 105) and thus, obtain the list of primes as well as non-primes.

Code776C - Molly's ChemicalsHint: The number of possible powers will be less than 50 for any k.

Editorial: We are going to loop over all possible non-negative powers of k. Since the maximum possible value of subarray sum can be 105 × 109 = 1014, there can be at most  possible powers that can be the sum of subarrays. Let p[i] be the sum of elements from index 1 to index i. We can precalculate p[i] in O(n) time complexity. (Prefix sum)

We will try to find the count of subarrays starting from index l. The sum of any such subarray ending at index r can be written as p[r] - p[l - 1]. Now,  where w is a power of k. We have to count the values of r ≥ l such that p[r] = w + p[l - 1]. For this part, we can store the count of p[r] in a dictionary as we move from right of the array and use the dictionary to find count of p[r] for corresponding p[l] and w.

PS: Do take care of a corner case for k =  ± 1 while calculating powers of k.

Code776D - The Door ProblemHint : Try to model the situation as a graph with rooms as edges and switches as nodes.

Editorial : All rooms are represented as edges. Mark the edges as 1 if the room is open else mark the edge as closed. The answer will be "YES" if you can color the graph in such a manner that the edges having value 0 have both nodes under different color (if the door is locked then one of the switches should be selected) and the edges having 1 have both nodes under same color (if the door is unlocked you should either select both switches or neither of them). For checking the same start a bfs from switch 1 and toggle it and proceed, if you are able to color all of the switches then the answer is "YES" else it is not possible.

Complexity: O(N + M)

See the setter's solution for implementation details.

Code776E - The Holmes ChildrenHint: For n = 10, the pairs satisfying the conditions are (1, 9), (3, 7), (7, 3), (9, 1). The first members of each pair form the set {1, 3, 7, 9}. Similarly, for n = 12, the corresponding set is {1, 5, 7, 11}. Also, observe that f(n) = n - 1 whenever n is a prime.

Editorial: Given,     Now,let's prove the converse. Let x be coprime to n and y = n - x. Let gcd(x, y) = k ≠ 1     Thus, number of distinct ordered pairs (x,y) satisfying the conditions= φ(n) where φ() denotes Euler totient function.

Now,. Let S denote the set {1, 2, ..., n}. We distribute the integers of S into disjoint sets as follows. For each divisor d of n, let A(d) = {k∈S: gcd(k, n) = d}.The sets A(d) form a disjoint collection whose union is S. Let n(A(d)) denote the number of integers in A(d). If k is a number in A(d), then k = d * m for some m coprime to n / d. There are φ(n / d) such m in the interval [1, n]. Hence, n(A(d)) = φ(n / d). Since the sets A(d) are disjoint,   

So, we only need to consider the number of times we apply f() in Fk which is (k + 1) / 2 for a given k.

Now, let us consider the numbers in the set {1, 2, ..., 2n}. There are exactly n even and n odd numbers in the set. The n even numbers can never be coprime to 2n. So, φ(2n) ≤ n. Thus, we need to calculate φ() at most log(n) times.

Complexity: 

Code776F - Sherlock's bet to MoriartyHint: Observe that if we consider all regions as nodes for a graph and connect two regions if they share an edge (in the form of sharing a diagonal), we will get a tree.

Editorial: Use a greedy approach to form a tree from the given polygon. Let us take one diagonal between vertex a and b (b > a). Let us define a value x as minimum of two values b - a - 1 and n - 2 - (b - a - 1). Sort all the diagonals on the basis of this value x. This value is the minimum number of nodes between a and b. Remove the diagonals one by one. We can see that a new region will be formed each time which cannot be divided further, and this region will be formed on the side from where we got the value of x. Thus we can get the nodes in each region and form a tree. Then, this problem reduces to coloring the tree such that two regions have same color only if atleast one node between the two nodes with same color has a color with lesser value. This can be done by using the divide and conquer technique of centroid decomposition. Give each height in centroid tree a different color in increasing order.

Complexity: O(n * log(n))

Code776G - Sherlock and the Encrypted DataHint: This problem can be solved using dynamic programming approach by maintain dp for mask of digits appearing in the number(mask1) along with position in the number(l) and mask of last 16 bits(mask2) of the number formed upto l.

Editorial: Observe that only the most significant bit of the mask1 is required to check if the number will decrease or not. So, form a dp[most: significant: bit: of: mask1][mask2][len].

Complexity: O(16 * 216 * 16 * 16)

Code

Editorial Divide by Zero and Codeforces Round #399 (Div. 1+2, combined)

By vntshh, 6 years ago, In English768A. Oath of the Night's WatchSet and Editorial by: vntshh

You just have to find the number of elements greater than the minimum number occurring in the array and less than the maximum number occurring in the array. This can be done in O(n) by traversing the array once and finding the minimum and maximum of the array, and then in another traversal, find the good numbers.

Complexity: O(n)

Code768B. Code For 1Set and Editorial by: killer_bee

It is easy to see that the total number of elements in the final list will be  . The problem can be solved by locating each element in the list and checking whether it is '1' .The ith element can be located in O(logn) by using Divide and Conquer strategy. Answer is the total number of all such elements which equal '1'.

Complexity : O((r - l + 1) * logn)

Code768C. Jon Snow and his Favourite NumberSet and Editorial by: vntshh

The range of strengths of any ranger at any point of time can be [0,1023]. This allows us to maintain a frequency array of the strengths of the rangers. Now, the updation of the array can be done in the following way: Make a copy of the frequency array. If the number of rangers having strength less than a strength y is even, and there are freq[y] rangers having strength y, ceil(freq[y] / 2) rangers will be updated and will have strengths y^x, and the remaining will retain the same strength. If the number of rangers having strength less than a strength y is odd,and there are freq[y] rangers having strength y, floor(freq[y] / 2) rangers will be updated and will have strengths y^x, and remaining will have the same strength. This operation has to be done k times, thus the overall complexity is O(1024 * k).

Complexity: O(k * 210)

Code768D. Jon and OrbsSet and Editorial by: arnabsamanta

This problem can be solve using inclusion-exclusion principle but precision errors need to be handled. Therefore, we use the following dynamic programming approach to solve this problem.

On n - th day there are two possibilities,Case-1 : Jon doesn't find a new orb then the probability of it is .Case-2 : Jon does find a new orb then the probability of it is .

Therefore, We need to find the minimum n such that where,n = number of days Jon waited.x = number of distinct orbs Jon have till now.dp[n][x] = probability of Jon having x distinct orbs in n days.k = Total number of distinct orbs possible.

CodePS:The ε was added so that the any solution considering the probability in the given range  passes the system tests.

768E. Game of StonesSet and Editorial by: AakashHanda

This problem can be solved using DP with Bitmasks to calculate the grundy value of piles. Let us have a 2-dimensional dp table, dp[i][j], where the first dimension is for number of stones in the pile and second dimension is for bitmask. The bitmask has k-th bit set if we are allowed to remove k + 1 stones from the pile.

Now, to calculate dp[i][j] we need to iterate over all possible moves allowed and find the mex.

CodeFinally for the game, we use the grundy values stored in dp[i][2i - 1] for a pile of size i. We take the xor of grundy values of all piles sizes. If it is 0, then Jon wins, otherwise Sam wins.

The complexity of this solution is . This will not be accepted. We can use the following optimizations for this problem:

Use a top-down approach to calculate the values of dp[i][2i - 1], hence calculating only those values that are required.Since we can only remove at most i stones from a pile, as stated above, we need to store values from j in range [0, 2i - 1].So we can rewrite the above code to incorporate these change. Hence, the final solution is as follows

CodeBonus: Try to find and prove the O(1) formula for grundy values

768F. Barrels and boxesSet and Editorial by: arnabsamanta, apoorv_kulsh

Every arrangement of stacks can expressed in the form of linear arrangement. In this linear arrangement, every contiguous segment of wine barrels are separated by food boxes. For the arrangement to be liked by Jon each of the f + 1 partitions created by f food boxes must contain either 0 or greater than h wine barrels.

Let u out of f + 1 partitions have non-zero wine barrels then the remaining r + 1 - u partitions must have 0 wine barrels..

Total number of arrangements with exactly u stacks of wine barrels are  is the number of ways of choosing u partitions out of f + 1 partitions.X is the number of ways to place w wine barrels in these u partitions which is equal to the coefficient of xw in {xh + 1·(1 + x + ...)}u. Finally we sum it up for all u from 1 to f + 1.

So the time complexity becomes O(w) with pre-processing of factorials.

w = 0 was the corner case for which the answer was 1.We did not anticipate it will cause so much trouble. Not placing it in the pretests was a rookie mistake.

Code

768G. The Winds of WinterSet and Editorial by: apoorv_kulsh

We are given a tree. We remove one node from this tree to form a forest. Strength of forest is defined as the size of largest tree in forest. We need to minimize the strength by changing the parent of atmost one node to some other node such that number of components remain same.

To find the minimum value of strength we do a binary search on strength. It is possible to attain Strength S if1. There is less than one component with size greater than S.2. There exists a node in maximum component with subtree size Y such that,M - Y ≤ S (Here M is size of maximum component and m is size of minimum component)m + Y ≤ S.Then we can change the parent of this node to some node in smallest component.

The problem now is to store Subtree_size of all nodes in the maximum component and perform binary search on them. We can use Stl Map for this.Let X be the node which is removed and Xsize be its subtree size There are two cases now -:1. When max size tree is child of X.2. When max size tree is the tree which remains when we remove subtree of X from original tree.(We refer to this as outer tree of X).

In the second case the subtree sizes of nodes on path from root to X will change when X is removed. Infact their subtree size will decrease exactly by Xsize. While performing binary search on these nodes there will be an offset of Xsize. So we store them seperately. Now we need to maintain 3 Maps,wheremapchildren : Stores the Subtree_size of all nodes present in heaviest child of X.mapparent : Stores the Subtree_size of all nodes on the path from root to X.mapouter : Stores the Subtree_size of all nodes in outer tree which are not on path from root to X.

Go through this blog post before reading further (http://codeforces.com/blog/entry/44351).

Maintaining the Mapsmapchildren and mapparent are initialised to empty while mapouter contains Subtree_size of all nodes in the tree.

mapparent : This can be easily maintained by inserting the Subtree_size of node in map when we enter a node in dfs and remove it when we exit it.mapchildren : mapchildren can be maintained by using the dsu on tree trick mentioned in blogpost.mapouter : When we insert a node's subtree_size in mapchildern or mapparent we can remove the same from mapouter and similarly when we insert a node's Subtree_size in mapchildern or mapparent we can remove the same from mapouter.

Refer to HLD style implementation in blogpost for easiest way of maintaining mapouter.Refer to code below for exact point of insertions and deletions into above mentioned 3 maps.

Code

Complexity O(NlogN2)

Codeforces Round #398 (Div. 2) Editorial

By KAN, 6 years ago, translation, In English767A - SnacktowerIt is enough to do what is written in the statements. You can maintain an array has, and mark in it which snacks has already fallen, and which hasn't. Create another variable next which tracks the next snack which should be put on the top. Let's proceed with the integers in the input one by one. After reading next integer, mark it in the has array and go from next to the first snack which is not marked. Print all integers which we passed by.

767B - The QueueLet's calculate the point of time when each visitor would be served. Let array a contain the points of time when visitors arrive. The receptionist would begin to serve the first visitor at the point of time when the receptionist begins to work ts, if the first visitor came to the passport office before it, or when he comes to the office, if he didn't. We can calculate the point of time when the receptionist would begin to serve the i-th visitor in the same way if we know when the receptionist began to serve the i - 1-th visitor. Let's suppose that the receptionist began to serve the i - 1-th visitor at bi - 1 minute. It means that receptionist would begin to serve the i-th visitor no sooner than t minutes later, that is bi - 1 + t minute. The receptionist would begin to serve him at this point of time if i-th visitor came before (ai ≤ bi - 1 + t). If he came later, his serving would begin when he comes. This way we will find the time bi when the receptionist would begin to serve him.

If any visitor came later than the previous visitor was served (ai > bi - 1 + t), the receptionist was free. It means that Vasya can be served immediately if he arrives at the proper time, for example, at bi - 1 + t minute. If there are no such visitors, to be the i-th person served this day, Vasya has to arrive at the passport office no later than (ai - 1) and he would have to wait a minimum of bi - (ai - 1) minutes. From all of these options we have to find a point of time with the minimal waiting time.

There are several special cases we have to consider:

If i-ый and (i - 1)-ый visitors arrived at the same time, Vasya can't arrive between them.Some visitors wouldn't be served this day if the time the receptionist would begin to serve them is more or equal to Tf - t and that means we shouldn't attive to the passport office after them.Vasya can be the last person served this day if there are at least t minutes between the point of time receptionist serves the last customer and the point of time he stops working.Vasya can be the first person served only if he comes before every other visitor.Considering the 1012 bound, all calculations should use the 64-bit data.

To conclude, this task is reduced to careful calculation of the visitors' serving times (O(n) time), considering the aforementioned edge cases.

767C - GarlandWe can note that the given graph is a tree. Let's perform a dfs from the root of the tree.

Let's calculate the sums if ti in each subtree, let this value be sv for the subtree of the vertex v. In order to compute sv we need to recursively call dfs from all sons of v and add the value tv.

Let the overall sum of ti be equal to x. If x is not divisible by three, there is no answer. Otherwise there are two different cases (let the answer lamps be v1 and v2) to obtain three subtrees with equal sum (x / 3):

1. One of the vertices is an ancestor of the other (we can think that v2 is ancestor of v1), then sv2 = 2x / 3, sv1 = x / 3.

2. Neither v1 nor v2 is ancestor of the other. In this case sv1 = sv2 = x / 3

To check the first option, it is enough to track is the dfs if there is at least one vertex u in the subtree of current vertex v with sum su = x / 3. If there is one, and sv = 2x / 3, then there is an answer v2 = v, v1 = u.

To check the second option, let's write down all vertices v such that sv = x / 3 and there isno other u with su = x / 3 in the subtree of v. Note that we do the same thing when checking the first option. So, if there are at least two vertices we wrote down, they form the answer we are looking for.

767D - Cartons of milkLet t be the maximum expiry date in the input.

The key observation in this problem is the fact that if we can buy some x cartons from the shop and not have to throw away the cartons, we can buy x cartons with the biggest expiry dates and we won't have to throw away any cartons either. It happens because if we increase the carton's expiry date while having fixed distribution of cartons per days, the distribution would stay correct.

Then, let's learn to check for an arbitrary x is it true that if we take x cartons with the maximum expiry dates we can distribute those cartons per days so that we won't have to throw cartons away. To do this, it is sufficient to check for each day i from 0 to t that the amount of cartons with expiry dates  ≤ i (both from a fridge and bought) is no bigger than (i + 1)k. Then the solution would be to search for maximum x using the binary search. If z is the answer, the check would pass for all x from 0 to z and wouldn't for x > z, this monotony is sufficient for the binary search to work. Then we output the found z and the z cartons with maximum expiry dates (we don't even have to sort si, we can justdo an enumeration sort because si ≤ 107). This soluton runs in O(tlogm) time.

767E - Change-freeThe first thing to note is that during day i it makes sense to either pay  notes и  coins (in this case, the cashier's dissatisfaction would be equal to 0), or just  notes (in that case, the cashier's dissatisfaction would be equal to )/ Moreover, the second case is impossible if , so in that case you just have to pay the required amount of notes.

In order to solve the problem, we have to note the additional fact. Let's suppose Arseny paid change-free during the i-th day and gave the cashier  coins. Then, if we change the payment way this day, the amount of coins availible to Arseny would increase by 100 regardless of the ci! Indeed, Arseny wouldn't spend those  coins, and he would aso receive  coins in change, which adds up to exactly 100 coins.

Let's build the optimal solution day-by-day beginning from day one, trying to pay change-free every time to minimize the cashier's dissatisfaction. Let i-th day be the first one when Arseny wouldn't be able to pay change-free. It means that Arseny has to get some change at least once during days from first to i-th. But, regardless of the day, after i-th day he would have the same amount of coins! It means that the optimal way is to get change during the day when the cashier's dissatisfaction would be minimal. Then, let's continue to pay change-free whenever we can. If Arseny again can't pay change-free during day j, there must be a day from first to j-th when he got change. Using similiar considerations, whe should choose the day with the minimal cashier's dissatisfaction (except the first one). We should do these operations until we process all days.

The simple implementation of this process works in O(n2) time and hits TLE. But if you use any structure of data which allows you to add or delete element or find minimum in  time, for example, heap or binary seach tree, we can save all previous days into it and find a day with the minimal cashier's dissatisfaction faster than O(n). The final time is .

Codeforces Round #397 Editorial

By Endagorion, history, 6 years ago, translation, In EnglishSorry for the wait! We'll be glad to answer your questions in the commens.

765A - Neverending competitionsEach competition adds two flights to the list — there and back. The only exception is the last competition: if Jinotega is now there, it adds only one flight. So if n is odd, the answer is contest, otherwise home.

765B - Code obfuscationIn this problem you needed to check that the first occurrences of letters a, b, ... appear in order (that is, first "a" is before first "b", which, in order, is before first "c", so on). One possible solution: for each letter x check that there is at least one letter x - 1 before it.

765C - Table Tennis Game 2There are several possible cases how the game could go:

The first player won all the sets. In this case, each set gave him exactly k points, hence a must be divisible by k. Moreover, b ≤ (a / k)·(k - 1) since the second player could get at most k - 1 points per set. If we have k|a and 0 ≤ b ≤ (a / k)·(k - 1), then the answer is at least a / k.The second player won all the sets. The analysis in symmetrical.Each player has won at least one set. In this case we must have a ≥ k and b ≥ k. If this condition holds, the game is possible with the maximal number of sets ⌊ a / k⌋ + ⌊ b / k⌋. Indeed, consider the following sequence of sets: , , (⌊ a / k⌋ - 1) copies of (k, 0), (⌊ b / k⌋ - 1) copies of (0, k).In short: if (a ≥ k and b ≥ k) or (a divisible by k) or (b divisible by k) the answer ⌊ a / k⌋ + ⌊ b / k⌋, otherwise  - 1. One can check that this is equivalent to the reasoning above.

765D - Artsem and SaundersSuppose that h(g) ≡ f (that is, the functions match on all inputs), and  (the identity function). Hence, we must have . It means that if f(x) = y, then f(y) = f(f(x)) = f(x) = y, that is, all distinct values of f must be its stable points. If this is violated, we can have no answer.

We will put m equal to the number of stable points. Let's enumerate all distinct values of f as p1, ..., pm, and define a function q that maps a point pi to the index i. We will determine functions g(x) = q(f(x)), and h(x) = px. We can see that:

if , then h(g(x)) = pq(f(x)) = f(x).if , then g(h(x)) = q(px) = x.All enumeration can be done in linear time.

765E - Tree FoldingLet's look at the performed actions in reverse. First, we have some path of odd length (by saying length we mean the number of edges} and double it several times. Now we do several "unfoldings". Among two leaves of this path exactly one (or its copy) participate in each unfolding; depending on it we call the unfolding "left" or "right". Note that left and right unfoldings have no edges in common; thus there is some vertex on the path which is not being unfolded. Let's call this vertex root.

Here is a criterion that a vertex can be a valid root. Root the tree at it and look at its certain subtree: the depths of all leaves there must be equal. Moreover, among all subtrees of the root there must be not more than 2 different depths of the leaves. This criterion follows directly if you look at the sequence of unfoldings.

Now we have a solution: for each directed edge in a tree compute a set of depths to the leaves by a 2-way tree DP (actually, it must be computed only if its size is at most 1). Afterwards for each vertex check the root criterion.

However, there is an idea which makes the solution simpler: the midpoint of the diameter of the given tree is always an appropriate root. Given this, we should only run a standard tree DP which checks if all leaves in a subtree have the same depth.

Here is the outline of a proof: in the path from the first paragraph select the leftmost and the rightmost possible root, now look through all possible distances from left root to the left leaf and from the right root to the right leaf. There are several configurations which are easy to check manually.

765F - SouvenirsWe will answer queries offline, moving right endpoint to the right and storing the answer for each left endpoint in a segment tree. The tree will support two operations: set minimum on a segment and get a value in the point. More, we assume that among two elements ai and aj in our array ai > aj and i < j and solve the problem twice — for the original array and for the reversed one.

Consider one step of moving the right endpoint and adding new element x to the position i. We find the first element to the left of i which is not less than x; denote it with aj = y. Obviously, now the answer for all left endpoints in range [0, j] is y - x. Now we find some aj' = y' such that x ≤ y' < y and j' < j, and the answer for all left endpoints in range [0, j'] is at most y' - x. If we repeat this step while possible, we maintain correct values in our segment tree.

The crucial idea of the problem is the following inequality: y' - x < y - y'. Why? Because each segment with r = i and 0 ≤ l ≤ j' contains elements y and y', and adding x will improve the answer for these endpoints only if this inequality holds. Having this, we need to consider only  values of y.

The asymptotic of the solution is .

765G - Math, math everywhereFirst I'll describe our original approach to this problem, and then some issues we encountered after the round finished.

Suppose that p1 = 2. If we have , then the string s must look like 0?0?0?..., that is, all even positions 0, 2, 4, ... will have 0's (for all others, we can't say), and if , then s looks like ?0?0?0.... Similarly, knowing the remainder of x modulo a prime p in factorization of N implies that there are zeros in s with p positions apart. If we fix all remainder modulo p1, ..., pn, then the string will be determined unambigiously. Notice that after fixing the modulos, there are still N' = p1α1 - 1... pnαn - 1 possible x's between 0 and N - 1; we will simply multiply the answer by N' in the end.

At this point we have a brute-force solution: try all values for remainders, count how many of the values give the string s. This is of course too slow, but we can make a few optimizations:

Make a brute-force into a DP by introducing memoization. We will count the number of ways to obtain each partial string s after fixing first i remainders. Of course, we don't have to store all 2m masks, but just the reachable ones.Once pi > m, each choice of remainder either places a single zero into a string, or doesn't change anything. At this point we are not interested in the full mask, but rather in the number of "unsatisfied" zeros of initial string s. Each transition either satisfies one zero, or doesn't change anything; the number of transitions of each kind is easy to count.We will do a full memoization DP for pi ≤ m, and continue with a compressed DP once pi > m. The second part can be done in O(nm) time and O(m) memory. The complexity of the first part depends on the total number of states in the memoization DP.

Turns out this number can be much larger than we anticipated on certain tests, for instance, primes starting from 5 or 7. On these cases, all our model solutions received time out. Such tests didn't appear in the original test set, of course.

[user:KAN] and myself tried to improve the solution. The idea behind our optimization is that once pi > m / 2, several central bits of the mask behave just like the "unsatisfied" bits in the large-prime part of the original solution: if we choose to cover them, it will be the single bit we cover. Thus we can do a "hybrid" DP that has parameters (number of unsatisfied bits in the middle, mask of all the rest bits).

[user:KAN]'s solution used "naive" mask DP for pi ≤ 23, switched to static array for pi = 29, 31, 37, and then proceeded to large primes as before. I tried to write a self-adaptive solution that handles all ranges of primes pretty much the same way. [user:KAN] was more successful: his solution works in  seconds on all cases we could counstruct; my solution works in  seconds and uses a lot of excess memory.

[user:KAN]'s solution: [submission:24707930], my solution: [submission:24707929].

Codeforces round #396 editorial

By mohammedehab2002, history, 6 years ago, In English766A - Mahmoud and Longest Uncommon Subsequence

If the strings are the same, Any subsequence of a is indeed a subsequence of b so the answer is "-1", Otherwise the longer string can't be a subsequence of the other (If they are equal in length and aren't the same, No one can be a subsequence of the other) so the answer is maximum of their lengths.

Code : http://pastebin.com/aJbeTTjw

Time complexity : O(|a| + |b|).

Problem author : me.

Solution author : me.

Testers : me and mahmoudbadawy.

766B - Mahmoud and a Triangle

First solution :-Let x, y and z be the lengths of 3 line segments such that x ≤ y ≤ z, If they can't form a non-degenerate triangle, Line segments of lengths x - 1, y and z or x, y and z + 1 can't form a non-degenerate triangle, So we don't need to try all the combinations, If we try y as the middle one, We need to try the maximum x that is less than or equal to y and the minimum z that is greater than or equal to y, The easiest way to do so is to sort the line segments and try every consecutive 3.

Code : http://pastebin.com/NsCkbQFS

Time complexity : O(nlog(n)).

Second solution :-Depending on the note from the first solution, If we try to generate a sequence such that after sorting, Every consecutive 3 line segments will form a degenerate triangle, It will be 1 1 2 3 5 8 13 ... which is Fibonacci sequence, Fibonacci is a fast growing sequence, fib(45) = 1134903170, Notice that Fibonacci makes maximum n with "NO" as the answer, That means the answer is indeed "YES" for n ≥ 45, For n < 45, You can do the naive O(n3) solution or the first solution.

Code : http://pastebin.com/82XcJfgp

Let x be the number that satisfies these inequalities:-

fib(x) ≤ maxAi.

fib(x + 1) > maxAi.

Time complexity : O(x3) or O(xlog(x)).

Problem author : me.

Solutions author : me.

Testers : me and mahmoudbadawy.

766C - Mahmoud and a Message

Let dp[i] be the number of ways to split the prefix of s ending at index i into substrings that fulfills the conditions. Let it be 1-indexed. Our base case is dp[0] = 1. Our answer is dp[n]. Now let's calculate it for every i. Let l be the minimum possible index such that the substring from l to i satisfies the condition, Let x be a moving pointer, At the beginning x = i - 1 and it decreases, Every time we decrease x, We calculate the new value of l depending on the current character like that, l = max(l, i - as[x]). While x is greater than or equal to l we add dp[x] to dp[i], To find the longest substring, Find maximum i - x, To find the minimum number of substrings, there is an easy greedy solution, Find the longest valid prefix and delete it and do the same again until the string is empty, The number of times this operation is repeated is our answer, Or see the dynamic programming solution in the code.

Code : http://pastebin.com/4JiXSwfU

Time complexity : O(n2).

Try to find an O(n) solution(I'll post a hard version of some problems on this blog soon).

Problem authors : me and mahmoudbadawy.

Solution authors : me and mahmoudbadawy.

Testers : me and mahmoudbadawy.

766D - Mahmoud and a Dictionary

Let's build a graph containing the words, For every relation in the input add a new edge with the weight of 0 if they are equal and 1 if they are opposites, If adding the edge doesn't make the graph cyclic, Our relation is valid, Otherwise it may be valid or invalid so we'll answer them offline. Check if adding that edge will make the graph cyclic or not using union-find like Kruskal's algorithm. Suspend answering relations that will make the graph cyclic, Now we have a forest of trees, Let cum[i] be the xor of the weights on the edges in the path from the root of the component of node i to node i. Calculate it using dfs. To find the relation between 2 words u and v, Check if they are in the same component using union-find, If they aren't, The answer is 3 otherwise the answer is , Now to answer suspended relations, Find the relation between the 2 words and check if it's the same as the input relation, Then answer the queries.

Code : http://pastebin.com/WqwduaYs

Time complexity : O((n + m + q)log(n) * maxL) where maxL is the length of the longest string considering that union-find works in constant time.

Problem author : mahmoudbadawy.

Solution author : me.

Testers : me and mahmoudbadawy.

Wait for a hard version of this problem.

766E - Mahmoud and a xor trip

If we have an array ans[i] which represents the number of paths that makes the ith bit sit to 1, Our answer will be 

Let arr[i][x] be the binary value of the xth bit of the number attached to node i(just to make work easier).

There are 2 types of paths from node u to node v where u is less in depth than or equal to v, Paths going down which are paths with lca(u, v)=u and other paths, Let's root the tree at node 1 and dfs, let current node be node, Let dp[i][x][j] be the number of paths going down from node i that makes the xth bit's value equal to j. A path going down from node i is a path going down from a child of i with node i concatenated to it so let's calculate our dp. A path that isn't going down is a concatenation of 2 paths which are going down from lca(u, v), Now we can calculate ans. See the code for formulas.

Code : http://pastebin.com/n2a3kijD

Time complexity : O(nlog(ai)).

Problem author : me.

Solution author : me.

Tester : mahmoudbadawy.

Codeforces Round #395 [Editorial]

By ilya_the_lamer, history, 6 years ago, In English764A - Taymyr is calling youYou can look over all minutes of the day. If both events happen on the some minute, we increment our answer.

Author's solution: http://pastebin.com/jBB0fbu5

Author: s17b2_voroneckij Development: s17b2_voroneckij

764B - Timofey and cubesNote that Dima's operations are reversible. If we apply them to the current order, we will get the initial. Also note that all the elements on even positions will remain on their places. Such numbers are affected an even number of times, so nothing will change. Similarly all elements on odd positions will change places with simmetrial ones relatively the centre. So, we change elements on odd places with their pairs. This works for O(n) time.

Author's solution: http://pastebin.com/X8R0i9vM

Author: akvasha Development: akvasha

763A - Timofey and a treeTake any edge which vertices are colored in different colors. If such edge doesn't exist you can print any vertex, because all the tree is colored in the same color. Otherwise, try to make a root from each of these vertices. Check if is possible with simple dfs. If it succeedes for one of them, print "YES" and this vertex. If it fails for both vertices, the answer is "NO". Indeed, if both of them cannot be the root, they lay in the same subtree and they are colored differently. So the condition isn't fulfilled. The asymptotics of this solution is O(n + m).

Author's solution: http://pastebin.com/M58NY7C1

Author: akvasha Development: akvasha , ilya_the_lamer

763B - Timofey and rectanglesLet's consider vertical touchings graph, where vertex is rectangle. For each vertex we keep x coordinate of bottom-right angle. While moving to next rectangle it changes by odd number. In this graph doesn't exist cycle of odd length (sum of odd number of odd numbers can't be zero). Similar to this you can see about horizontal touchings. Let's consider two touching rectagles. Sides lengths are odd, so  give different colors for adjacent rectangles, where x is x coordinate of bottom-left angle and y is y coordinate of bottom-left angle.

Author's solution: http://pastebin.com/ntEV9bGt

Author: ilya_the_lamer Development: ilya_the_lamer , akvasha

763C - Timofey and remodulingFirst, let's think about the case when 2n < m.

In this editorial we say that an outcoming sequence is s, s + d, s + 2d, ..., s + (n - 1)d

Assume x is the difference of some two elements a and b of A (). Let's say that a was on i-th place in the sequence and b was on i + k-th place. Then .

On the other hand, we have that n is less then , so x must be difference of exactly n - k + 1 pairs of elements of A. We can count this value in  time using binary search or in O(n) time using a hashtable. Then we know the value of k. After that we calculate the value  (m is prime so we can use Fermat's little theorem) and then we know the difference of the sequence. Then we just take any element y of A and look on values y, y + d, y + 2d, ..., and also on y - d, y - 2d, .... If we can get all of the numbers in A in this way, then we know the first element of the sequence. Otherwise, the answer is NO.

If 2n > m, we just solve the problem for the complement of A in , and then add to the first element value (m - n)d. If we had a correct sequence in A, then we must have a correct sequence in its complement with the same difference (as long as m is coprime with the difference, the complement is just set of numbers s + nd, s + (n + 1)d, ..., s + (m - 1)d).

Author's solution: http://pastebin.com/jTdcUpFM

Author: platypus179 Development: platypus179

763D - Timofey and a flat treeThere are only 2·(n - 1) subtrees in the whole tree: two for each edge. Let's calculate hashes of each of them.

We can calculate hash of a subtree, for example, in a following. Let's associate each vertex with a correct bracket sequence. Leaves are associated with "()", other vertices are associated with their sequences according to the following rule. Assume that the children of our vertex are associated with sequences s1, s2, ..., sk. Let's sort strings s1, s2, ..., sk in some order, for example, in order of ascending hashes. Then our vertex is associated with sequence (s1s2... sk). It's easy to check that isomorphic subtrees are associated with equal sequences and non-isomoriphic are associated with different sequences. Then hash of a subtree is the hash of the sequence associated with the root of the subtree. In this problem we will calculate the polynomial hash because we will need to count the hash of concatenation of several strings knowing only their hash and length.

We know hashes for all of the leaves. Let's do a bfs-like algorithm that will greedily count all of the hashes. Let's count outv – number of outer edges for vertex v, for which we have already counted hashes of their subtrees. Then we know new hashes in two cases:

. Then we can calculate the hash for the inner edge of v, for which we don't already know the outer hash in  time.. Then we can calculate the hash for all of the inner edges, for which we don't already know it. Let's calculate hashes for all of concatenations of prefixes and suffixes of the sorted array. If we count polynomial hash, we can calculate them knowing only their hashes and length. Then when we calculate the hash for particular edge, we just have to concatenate the prefix and the suffix of our array. This all works in  time.Now we have to calculate for each vertex v the number of distinct hashes in case v is the root. Let's select some vertex and calculate this number fairly, using dfs and storing for each hash number of its occurrences in a hashtable. Then we go through the tree in order of Euler tour and maintain the hashtable. When we go through edge , we should add hash of the edge  and remove hash of the edge , other hashes in the hashtable doesn't change.

This works in  time.

Author's solution: http://pastebin.com/05KPvqN1

Bonus: Find the vertex with minimal amount of distinct subtrees in terms of isomorphism in O(n) time.

Author: platypus179 Development: platypus179

763E - Timofey and our friends animalsLet's build a segment tree on crow families. Let's save DSU in each vertex, having information about number of components of connectivity on it. In one vertex will be DSU with size n. In two vertices will be DSU with size n / 2. In four vertices will be DSU with size n / 4. It's easy to show that we will store only O(nlogn) values. Let's understand how we can unite segments. Knowing answer (number of components) for [a; b) and [b; c) we can obtain answer for [a; c) in the following way: We can sum answers for for [a; b) and [b; c) and substract number of components, which united during the "gluing". If components become united, there is edge between vertex in one and vertex in another. We have constraint on edge legth: vertex u and vertex v can be connected only if abs(u - v) ≤ k Then we can easily unite two segments of the segment tree in O(k2) time: we just unite some of the k components of families represented in the end of each segment when they are connected by edge. Segment tree can split query in  already calculated segments. So we can answer the query in  time. Precalc will take nearly .

Author's solution: http://pastebin.com/1CwUVyME

Bonus: Solve the problem in  time for the precalculation and  time for the query.

Author: KAN Development: platypus179 , ilya_the_lamer , akvasha

Codeforces Round #394 (Div. 2) [Editorial]

By altruist, history, 6 years ago, translation, In EnglishI'm extremely sorry for late publication.

761A - Dasha and StairsIt's obvious, that if |a - b| > 1 — the answer is «NO». «NO» answer was also in the case, when a and b are equal to 0, because according to the statement, such interval should exist. In other cases the answer is «YES».

Complexity: O(1).Author of the idea: Vladik.Worked on the problem: Vladik.

761B - Dasha and friendsLet's add distances between pairs of adjacent barriers of both tracks in arrays and check if it possible to get one of them from another using cycling shift of the elements.

Complexity: O(n2).Author of the idea: MikeMirzayanov.Worked on the problem: fcspartakm.

761C - Dasha and PasswordLet's iterate the string, where we want to get a digit to the password, then the string, where we'll get a letter to the password and the string, where we'll get one of the characters '&', '*', '#'. Obviously, in the other strings we can pick any character, so we only need to compute minimal number of moves we have to do to get corresponding characters in fixed strings. We can do it just by iterating that strings.

Complexity: O(n3 * m).Author of the idea: altruist.Worked on the problem: Vladik.

761D - Dasha and Very Difficult ProblemLet's match each element of a interval of values, which corresponding element of c could take, i.e for i-th element interval [l - ai;r - ai]. Let posi be the index of element equal to i in permutation p. Now you can know, that solving the initial task is reduced to picking a number of each interval, so that this numbers form an increasing sequence in order from pos1 to posn. It is easy to know that we can pick the numbers greedily, picking a number that is greater than previous and belongs to current interval.

Complexity: O(n).Author of the idea: altruist.Worked on the problem: altruist.

761E - Dasha and PuzzleThe answer doesn't exist, when there is a vertex with degree > 4. We'll use power of two as length of each edge in the tree. Let's dfs our tree and store in the recursion: the direction, where our parent is located (one of four possible), and the length of the edge we'll build from current vertex. Then iterate the new direction, some neighbour of the vertex and continue recursion. The edges will not intersect, except in the verteces, because 20 + 21 + ... + 2k < 2k + 1.

Comment: It's worth noting that it is possible to solve problem for greater n, using the fact that nothing depends on the coordinates, only ratios between X and Y coordinates seperatly, so we can compress them.

Complexity: O(n).Author of the idea: MikeMirzayanov.Worked on the problem: altruist.

761F - Dasha and PhotosLet special photo be the matrix, made by changing subrectangle in the initial, and changed submatrix — changed subrectangle itself. Firsly, let's calculate cnt(x, y, ch) — the number of special photos, in which cell (x, y) belongs to changed submatrix, such that cell (x, y) contains character ch. It can be done using addition on submatrix in offline. Then, using cnt array, let's compute f(x, y) — sum of the distances from all k photos to initial, in cell (x, y): . Let  ( g(x, y) — sum of the distances from all k photos to initial on submatrix (1, 1, x, y). Let cnt'(x, y, ch) — the number of special photos, in which cell (x, y) contains character ch. Then calculate, similarly to g(x, y), sums . Now, using dp's alltogether, we can count for some special photo sum of the distances to all other photos : for all cells, except changed submarix, find the distance using g(x, y) and inclusion-exclusion method in O(1). For the cells in changed submatrix, let's iterate the character and find the answer for it similarly.

Complexity: O(d * (N * M + K)), where d — alphabet power.Author of the idea: Vladik.Worked on the problem: Vladik.

8VC Venture Cup 2017 — Final Round and Codeforces Round #393 Editorial

By KAN, 6 years ago, In English760A - Petr and a calendarJust implement writing dates one by one and keeping current column and row, or use the formula answer = ((d - 1) + ndays - 1) / 7 + 1, where ndays is the number of days in the month.

Problem author: KAN.

760B - Frodo and pillowsLet's do binary search on the answer. How to check if Frodo can have x pillows or more? We need to calculate the least amount of pillows we need to give to all the hobbits and compare it to m.

The number of pillows is minimized if we give x - 1 pillows to Frodo's neighbors, x - 2 pillows to the hobbits at the distance 2 from Frodo and so on, until we reach 1 pillow or until we reach an end of beds row. The total amount of pillows on one side of Frodo can be calculated using a formula.

Suppose there are y beds on one side of Frodo. There are two cases: if y > x - 1, then the total number of pillows is , otherwise the total number of pillows is .

Problem author: KAN.

756A - Pavel and barbecueAt first, let's deal with the permutation. We can see that p should have exactly one cycle to suit Pavel. The minimum number of changes is 0 if there is only one cycle, and the number of cycles if there is more than one cycle.

What should we do with b? We can see that the skewers visit a particular position x in the same direction again and again if and only if the total number of ones in b is even. If the total number of ones in b is odd, then each time a skewer visits a particular position x, it has direction different from the previous time. Thus, the condition is satisfied if and only if the number of ones in b is odd. We should add 1 to the answer if it isn't.

Problem author: pashka.

756B - Travel CardHint: the problem looks difficult because tickets can change, however, it's can be solved with simple dynamic programming. You are asked the difference between neighboring dp's subtasks.

More detailed editorial will be added soon.

Problem author: pashka.

756C - Nikita and stackHint 1: look at the operations in the reverse order. Let's count the balance for each prefix, i.e. the difference between the number of push(x) operations and the number of pop() operations.

Hint 2: Now we have to find the first operation that makes balance positive. This can be done using segment tree.

Solution: Let's reverse the order of operations. Now we can see that on the top of the stack will be the first integer added with push(x) such that the number of pop() operations and the number of push(x) operations before this operation is equal, if there is one. Let's keep for each position a value called balance: the number of push(x) operations minus the number of pop() operations before and including this position. To find the answer, we should find the first position with posivive balance. When we add an operation, we should add -1 or 1 to all posisions starting with the position of the operation, depending on the type of the operation.

To cope with the operations quickly, we can store the balance in a segment tree. The addition is done with lazy propogation, finding the first position with positive balance can be done in two ways. First way is to perform binary search on the answer and then query the segment tree for maximim on some prefix. The compexity is  per query then. The other way is to walk down the tree always moving to the leftmost son with positive maximum. When we reach the leaf, the position of this leaf is the answer. The complexity is  per query.

The overall complexity is  or  depending on the realization.

Problem author: Umqra.

756D - Bacterial MeleeHint: find a condition when a string is reachable from another string in terms of subsequences, then apply DP for counting suitable subsequences.

Solution: How to determine if a string can be obtained from another string after a number of operations? It helps to consider (maximal) blocks of adjacent characters. Let us define comp(s) as a "compressed" version of s that keeps a single character from each block of s in the same order, for example, . It is not hard to see that each operation either preserves the sequence of blocks (if we ignore their lengths) or erases a single block (when it consists of a single character and is overwritten by an adjacent character). This is the same as saying that each operation applied to s either doesn't change comp(s) or erases a single character from it. Therefore, if t can be obtained from s after a number of operations, then comp(t) must be a subsequence of comp(s).

In fact, this is an "if and only if" condition. Indeed, suppose that comp(t) is a subsequence of comp(s). We start our process of making t from s by eliminating the blocks not present in t, effectively making comp(s) = comp(t). After that, it can be seen that the borders of the blocks can be moved rather freely (but carefully enough not to murder any block) so that s can be indeed made equal to t.

We can see from the last argument that from the reachability point of view the two strings s and t are essentially different if comp(s) ≠ comp(t). If s is the given string, and a string u is a subsequence of comp(s) that doesn't have equal adjacent characters, then there are  reachable strings with comp(...) = u; indeed, this is exactly the number of ways to split n characters into |u| non-empty blocks.

Now, for each l we have to count the number of subsequences of s with length l that do not have equal adjacent characters. There are several ways to do that. One way is storing dpc, l — the number of valid subsequences of length l that end in character c. We now process characters one by one and recompute values of dpc, l. If the new character is ci, then clearly values of dpc, l with c ≠ ci do not change. We can also see that we can find the new values of dpci, l with the formula

Indeed, consider a valid subsequence that ends in ci. If we take any occurence of this subsequence, we are free to move the last character to the newly appended occurence of ci. It follows that there is a bijection between valid subsequences that end in ci and valid subsequences that end in anything but ci (that includes an empty subsequence). This solution takes O(kn2) time (where k = 26 is the number of different characters), but can easily by optimized to O(n2) time.Problem author: Endagorion.

756E - Byteland coinsLet's calculate DP[pref][x] — number of ways to pay x tugriks using only pref first types. Of course, x can be very big, but we will store DP only for those x which are not bigger than the sum of all the coins of first pref types and can lead to answer: x = k·D + (m%D) where D is the last coin denomination.

Every next layer of this DP can be calculated in O(szi) time using prefix sums where sz is the size of the new layer. .

Now all that remains is to calculate some info about m%D to know what DP elemnts we are interested in. We should represent m in a form of Σi = 1nci·Di. To find ci we should successively divide m by all ai, ci will be the reminders. All the divisions can be done in  time if we will not divide by 1.

Total complexity — 

Problem author: Um_nik.

756F - Long numberFirst of all we need to somehow parse the expression. Let's suppose we've builded a parse tree for the expression. Every number X can be seen as operation "concatenate something and X". We should understand how such an operation changes the number. YX = Y·10len(X) + X. So we can represent each number X as pair (10len(X)%MOD, X%MOD).

Two such pairs can be merged: (X1, Y1) + (X2, Y2) = (X1·X2, Y1·X2 + Y2).

Z((X,Y))  = (X·Z, Σi = 0Z - 1Y·Xi) = (X·Z, Y·Σi = 0Z - 1Xi). Geometric series can be calculated in  time (using binary exponentiation) in both cases X = 1 and X ≠ 1.

L-R: if len(L) = len(R) then L-R  = (len(L)·(R - L + 1), Σi = 0R - L(R - i)·(10len(L))i) . This sum also can be calculated in O(len(L)).

If len(L) ≠ len(R) then we should iterate over all lengths between len(L) + 1 and len(R) - 1. But for every such length we can first calculate powers (9·10len - 1 + eps) modulo φ(MOD) = MOD - 1 and then do the calculation in  time.

Overall complexity will be .

Problem author: Um_nik.

Разбор Codeforces Round #392 (Div. 2)

By Kniaz, 6 years ago, translation, In English758A - Holiday Of EqualityAs it's impossible to decrease numbers, we have to increase them to at least max(a1, a2, ..., an). If all the numbers are already equal to max(a1, a2, ..., an) then there is no need to increase any of them as it will cost extra operations.

So you should find max(a1, a2, ..., an) using one iteration over the array. Then iterate one more time summing up differences between ai and maximum. And the answer is .

Overall complexity — O(n).

Problem author: MikeMirzayanov.

758B - Blown GarlandFour consecutive bulbs should not be of the same color, and it is four possible colors, so the color of the fifth bulb is the same as the first bulb has, the color of the sixth is the same as the second bulb has, it means that the color of the n-th bulb equals the color of the (n - 4)-th bulb.

Thus, the coordinates of all bulbs of the same color equal in module 4.

According to the conditions of the problem the coordinate of at least one light bulb of each color is given, so we can restore the garland and by one pass count the number of blown bulbs.

By one pass we learn how numbers in module 4 correspond to the colors. By the second pass we know the place of the bulb and count the number of blown bulbs of each color.

The asymptotic behavior of the solutions is  — O(n).

There is also a second solution:

You can just fix order of first four light bulbs by bruteforce (there is only 4! = 24 variants), checking the conformity of each option of the given garland. By finding the color of the first four bulbs we easily recreate the garland with working lights and count the number of blown bulbs.

At worst this decision will work for 24·n.

Problem author: MikeMirzayanov, Kniaz.

758C - Unfair PollLet's learn to count f(x, y) — the number of questions which were asked to the pupil in the x-th row, at the y-th place in the order.

Note that the process of asking is periodic. During one period children were asked in the following order:

the pupil from the first row who seats at the first table;the pupil from the first row who seats at the second table;the pupil from the first row who seats at the ... table;the pupil from the first row who seats at the m table;the pupil from the second row who seats at the first table;the pupil from the second row who seats at the second table;the pupil from the second row who seats at the ... table;the pupil from the second row who seats at the m table;the pupil from the ... row who seats at the ... table;the pupil from the n - 1 row who seats at the first table;the pupil from n - 1 row who seats at the second table;the pupil from the n - 1 row who seats at the ... table;the pupil from the n - 1 row who seats at the m table;the pupil from the n row who seats at the first table;the pupil from the n row who seats at the second table;the pupil from the n row who seats at the ... table;the pupil from the n row who seats at the m table;the pupil from the n - 1 row who seats at the first table;the pupil from the n - 1 row who seats at the second table;the pupil from the n - 1 row who seats at the ... table;the pupil from the n - 1 row who seats at the m table;the pupil from the ... row who seats at the ... table;the pupil from the second row who seats at the first table;the pupil from the second row who seats at the second table;the pupil from the second row who seats at the ... table;the pupil from the second row who seats at the m table.The next the pupil from the first row who seats at the first table, the period starts from the beginning.Thus, during one period T = n·m + (n - 2)·m pupils who seats at the outer rows will be asked once, others will be asked twice. If n = 1, then T = m.

The number of full periods equals . The remaining questions are k mod T  ≤ T, so we can only make poll on the remaining questions for the O(n·m) or for individual x and y print the formula.

Thus, f(x, y) can be seen as O(n·m) or as O(1).

On what places are people who may be asked more times than the other? Firstly, this is the first row and the first table, because the poll begins from it. Secondly, this is the second row and the first table, because the poll of the central, not outer part of a class at the right side, begins from it. Thirdly, the n - 1 row and the first place because the poll of the central, not outer part of a class at the left side, begins from it.

The maximum number of asked questions to one pupil equals max(f(1, 1), f(2, 1), f(n - 1, 1)).

The minimum number of asked questions to one pupil equals f(n, m), because the pupil who seats on the last row and at the last table will be asked less than others.

Thus, we have decisions with the asymptotic O(n·m) or O(1).

Problem author: Kniaz.

758D - Ability To ConvertLet's compare answers for numbers k and , that is k without the rightmost digit.

Note that for any x number  is either contains less substrings (valid digits in base-n numeric system) or it's possible to decrease value of the last substring of number x.

That proves that partition of number without the rightmost digit isn't worse than partition of the number itself. Thus, greedy strategy will work. On each step take the longest suffix of a string as the last base-n digit and proceed to same task for string with this suffix excluded. Repeat until the string isn't empty.

Check carefully that the suffix is a number less than n and also doesn't have any leading zeros except for the case when it's equal to zero.

Overall complexity — O(k), where k — length of input string.

Problem author: MikeMirzayanov, Kniaz.

758E - Broken TreeFirst, let's calculate min and max weight for subtrees of each vertex.

Minimal weight of a subtree is sum of minimal weights of all adjacent to the root of current subtree subtrees and sum of weights of all outgoing edges reduced in weight to minimal possible.

Thus, minimal weight is , where x —subtree root, nx —number of outgoing edges from x, yx, i — each adjacent to x vertex, px, i — its strength, wx, i — its weight.

Note that minimal weight should be less or equal to strength of incoming edge. If this condition isn't satisfied for at least one subtree then the answer is  - 1.

Maximal weight of a subtree is sum of maximal weights of all adjacent to the root of current subtree subtrees and sum of weights of all outgoing edges. Note that this maximum should stay in such boundaries that the tree remains unbroken. So maximal weight should not exceed strength of incoming edge of a root.

Therefore, maximum is , where x —subtree root, pz, i — weight of an incoming edge of x, that is j-th edge outgoing from some vertex z, nx —number of outgoing edges from x, yx, i — each adjacent to x vertex, wx, i — its weight.

After that, let's calculate current weight of every subtree to find difference between actual value and the optimal one. Weight of subtree is sum of weights of all adjacent to the root of current subtree subtrees and sum of weights of all outgoing edges.

Then actual weight is , where x —subtree root, nx —number of outgoing edges from x, yx, i — each adjacent to x vertex, wx, i — its weight.

One dfs from the root of the tree is enough to calculate all these values.

Note that dpmin, dpmax and dpW are set to 0 for leaves .

dpmaxx is maximal possible weight of each subtree, so weight of the whole tree can be reduced to dpmax1, it means that weight of subtree of vertex 1 should be reduced by dpW1 - dpmax1.

Next goal is to learn how to reduce weight of subtree of vertex x by s units. At first, you should reduce weights of subtrees of adjacent to x vertices to their maximum. So after this step . Then while s > 0, reduce weight of each next subtree. If it's still s > 0 then reduce weights of outgoing edges from x maintaining unbroken state of tree.

This process also takes one dfs.

Overall complexity is the complexity of two dfs calls, that is O(n).

Problem author: Kniaz.

758F - Geometrical ProgressionLet d — is the denominator of the progression. d — is the rational number, because all numbers of progression are integers. ,where x, y — are integers, gcd(x, y) = 1. Then . Because all numbers of progression are integers, so . Let , then a1 = b·yn - 1 and an = b·xn - 1.

According to the condition of the problem it must be done: l ≤ b·yn - 1 ≤ r и l ≤ b·xn - 1 ≤ r.

Count the number of increasing progressions, it means d > 1 (y < x). Note that there are decreasing progressions as much as increasing, any decreasing progression   — is increasing, but written from right to left.

If y < x, then l ≤ b·yn - 1 < b·xn - 1 ≤ r.

Then for certain x and y the number of possible integers b is calculated by the formula .

Let's sort y from 1 to , x from y + 1 to . Before you add the number of options for the next x and y you need to check that gcd(x, y) = 1. Better to count gcd(x, y) using Euclidean algorithm for . Remember that we counted only increasing progressions, the answer would be higher twice.

Note that when n = 1 this algorithm is meaningless, so it is necessary to separately register the answer, for n = 1 it equals r - l + 1, it means that you choose one element from l to r.

Also for n = 2 it is necessary to print the formula, any pair of integers is the geometrical progression, so for n = 2 the answer equals (r - l + 1)·(r - l), the first integer can be chosen by using r - l + 1 ways, the second which is not equal to the first by using r - l ways.

Possible asymptotic behavior:

;

 — when we make the binary transfer to the degree;

 — with preliminary count;

 — with binary preliminary count.

Problem author: Kniaz.

I want to thank Mikhail Piklyaev (awoo) for translation of tutorial!

CodeCraft-17 and Codeforces Round #391 (Div. 1 + Div. 2, combined) Editorial

By Baba, history, 6 years ago, In English757A — Gotta Catch Em' All!Author: BabaTesters: virus_1010 born2rule

Expected complexity: Main idea: Maintain counts of required characters.

Since we are allowed to permute the string in any order to find the maximum occurences of the string "Bulbasaur", we simply keep the count of the letters 'B', 'u', 'l', 'b', 'a', 's', 'r'. Now the string "Bulbasaur" contains 1 'B', 2'u', 1 'l', 2'a', 1 's', 1'r' and 1 'b', thus the answer to the problem is Min(count('B'), count('b'), count('s'), count('r'), count('l'), count('a')/2, count('u')/2). You can maintain the counts using an array.

Corner Cases:1. Neglecting 'B' and while calculating the answer considering count('b')/2.2. Considering a letter more than once ( 'a' and 'u' ).

Tester's code:757B — Bash's Big DayAuthor: architraiTesters: mprocks, deepanshugarg

Expected complexity: Main idea: Square-root factorization and keeping count of prime factors.

The problem can be simplified to finding a group of Pokemons such that their strengths have a common factor other that 1. We can do this by marking just the prime factors, and the answer will be the maximum count of a prime factor occurring some number of times. The prime numbers of each number can be found out using pre-computed sieve or square-root factorization.

Corner Cases : Since a Pokemon cannot fight with itself (as mentioned in the note), the minimum answer is 1. Thus, even in cases where every subset of the input has gcd equal to 1, the answer will be 1.

Tester's code:757C — Felicity is Coming!Author: shivamkakkarTesters: codelegend

Expected complexity: Main idea: Divide pokemon types into equivalence classes based on their counts in each list.

Consider a valid evolution plan f. Let c[p, g] be the number of times Pokemon p appears in gym g. If f(p) = q then .

Now consider a group of Pokemon P such that all of them occur equal number of times in each gym (i.e. for each ). Any permutation of this group would be a valid bijection.

Say we have groups s1, s2, s3, ..., then the answer would be |s1|! |s2|! |s3|! ...  mod 109 + 7.

For implementing groups, we can use vector < vector < int >  >  and for i-th pokemon, add the index of the gym to i-th vector.

Now we need to find which of these vectors are equal. If we have the sorted vector < vector < int >  > , we can find equal elements by iterating over it and comparing adjacent elements.

Consider the merge step of merge sort. For a comparison between 2 vectors v1 and v2, we cover at least min(v1.size(), v2.size()) elements. Hence  work is done at each level. There are  levels.

Bonus : Try proving the time complexity for quicksort as well.

Authors's code:757D — Felicity's Big Secret RevealedAuthor: saatwik27Testers: imamit,abhinavaggarwal,Chipe1

Expected complexity: Main idea: DP with Bitmask.

This problem can be solved using Dynamic Programming with bitmask.

The important thing to note here is that the set of distinct numbers formed will be a maximum of 20 numbers, i.e. from 1 to 20, else it won't fit 75 bits(1*(1 bits) + 2*(2 bits) + 4*(3 bits) + 8*(4 bits) + 5*(5 bits) = 74 bits). So, we can use a bitmask to denote a set of numbers that are included in a set of cuts.

Let's see a Top-Down approach to solve it :

Lets define the function f(i, mask) as : f(i, mask) denotes the number of sets of valid cuts that can be obtained from the state i, mask. The state formation is defined below.

Let M be the maximum number among the numbers in mask. mask denotes a set of numbers that have been generated using some number of cuts, all of them before bi. Out of these cuts, the last cut has been placed just before bi. Now, first we check if the set of cuts obtained from mask is valid or not(in order for a mask to be valid, mask == 2X - 1 where X denotes number of set bits in the mask) and increment the answer accordingly if the mask is valid. And then we also have the option of adding another cut. We can add the next cut just before bx provided the number formed by "bi bi + 1...bx - 1" <= 20. Set the corresponding bit for this number formed to 1 in the mask to obtain newMask and recursively find f(x, newMask).

Author's code:757E — Bash Plays with FunctionsAuthor: satyam.pandeyTesters: Superty,vmrajas

Expected complexity: Main idea: Multiplicative Functions.

We can easily see that f0 = 2(number of distinct prime factors of n). We can also see that it is a multiplicative function.

We can also simplify the definition of fr + 1 as:

Since f0 is a multiplicative function, fr + 1 is also a multiplicative function. (by property of multiplicative functions)

For each query, factorize n.

Now, since fr is a multiplicative function, if n can be written as:

n = p1e1p2e2 ... pqeqThen fr(n) can be computed as:

fr(n) = fr(p1e1) * fr(p2e2) * ... * fr(pqeq)Now observe that the value of fr(pn) is independent of p, as f0(pn) = 2. It is dependent only on n. So we calculate fr(2x) for all r and x using a simple R * 20 DP as follows:

And now we can quickly compute fr(n) for each query as:

fr(n) = dp[r][e1] * dp[r][e2] * ... * dp[r][eq]Author's code:757F — Team Rocket Rises AgainAuthor: BabaTesters: shubhamvijay, tanmayc25, vmrajas

Expected complexity: Main idea: Building Dominator tree on shortest path DAG.

First of all, we run Dijkstra's shortest path algorithm from s as the source vertex and construct the shortest path DAG of the given graph. Note that in the shortest path DAG, the length of any path from s to any other node x is equal to the length of the shortest path from s to x in the given graph.

Now, let us analyze what the function f(s, x) means. It will be equal to the number of nodes u such that every path from s to u passes through node x in the shortest path DAG, such that on removing node x from the DAG, there will be no path from s to u.

In other words, we want to find the number of nodes u that are dominated by node x considering s as the sources vertex in the shortest path DAG. This can be calculated by building dominator tree of the shortest path DAG considering s as the source vertex.A node u is said to dominate a node w wrt source vertex s if all the paths from s to w in the graph must pass through node u.You can read more about dominator tree here.

Once the dominator tree is formed, the answer for any node x is equal to the number of nodes in the subtree of x in the tree formed.

Author's code:Another approach for forming dominator tree is by observing that the shortest path directed graph formed is a DAG i.e. acyclic. So suppose we process the nodes of the shortest path dag in topological order and have a dominator tree of all nodes from which we can reach x already formed. Now, for the node x, we look at all the parents p of x in the DAG, and compute their LCA in the dominator tree built till now. We can now attach the node x as a child of the LCA in the tree.For more details on this approach you can look at amiya's solution here.

757G — Can Bash Save the Day?Author: BabaTesters: Toshad, abhinavaggarwal

Expected complexity: Main idea: Making the Centroid Tree Persistent.

Simpler ProblemFirst let's try to solve a much simpler problem given as follows.

Question: Given a weighted tree, initially all the nodes of the given tree are inactive. We need to support the following operations fast :Query v : Report the sum of distances of all active nodes from node v in the given tree.Activate v : Mark node v to be an active node.

Solution: The above problem can be easily solved by a fairly standard technique called Centroid Decomposition. You can read more about here

Solution IdeaEach query of the form (L R v) can be divided into two queries of form (1 R v)  -  (1 L - 1 v). Hence it is sufficient if we can support the following query: (i v) : Report the answer to query (1 i v)To answer a single query of the form (i v) we can think of it as what is the sum of distance of all active nodes from node v, if we consider the first i nodes to be active.Hence initially if we can preprocess the tree such that we activate nodes from 1 to n and after each update, store a copy of the centroid tree, then for each query (i v) we can lookup the centroid tree corresponding to i, which would have the first i nodes activated, and query for node v in  time by looking at it’s ancestors.To store a copy of the centroid tree for each i, we need to make it persistent.Persistent Centroid Tree : Key IdeasImportant thing to note is that single update in the centroid tree affects only the ancestors of the node in the tree.Since height of the centroid tree is , each update affects only  other nodes in the centroid tree.The idea is very similar to that of a persistent segment tree BUT unlike segtree, here each node of the centroid tree can have arbitrarily many children and hence simply creating a new copy of the affected nodes would not work because linking them to the children of old copy would take  for each affected node and this number could be as large as N, hence it could take  time in total !Binarizing the Input TreeTo overcome the issue, we convert the given tree T into an equivalent binary tree T' by adding extra dummy nodes such that degree of each node in the transformed tree T' is  <  = 3, and the number of dummy nodes added is bounded by .The dummy nodes are added such that the structure of the tree is preserved and weights of the edges added are set to 0.To do this, consider a node x with degree d > 3 and let c1, c2...cd be it's adjacent nodes. Add a new node y and change the edges as follows :Delete the edges (x - c3), (x - c4) ... (x - cd) and add the edge (x - y) such that degree of node x reduces to 3 from d.Add edges (y - c3), (y - c4) ... (y - cd) such that degree of node y is d - 1. Recursively call the procedure on node y.Since degree of node y is d - 1 instead of original degree d of node x, it can be proved that we need to add at most  new nodes before degree of each node in the tree is  <  = 3.ConclusionHence we perform centroid decomposition of this transformed tree T'. The centroid tree formed would have the following properties.

The height of the centroid tree is Each node in the centroid tree has  ≤ 3 children.Now we can easily make this tree persistent by path-copying approach.To handle the updates,

Way-1 : Observe that swapping A[i] and A[i + 1] would affect only the i'th persistent centroid tree, which can be rebuilt from the tree of i - 1 by a single update query. In this approach, for each update we add  new nodes. See author's code below for more details.Way-2 : First we go down to the lca of A[x] and A[x + 1] in the x'th persistent tree, updating the values as we go. Now, let cl be the child of lca which is an ancestor of A[x], and let cr be the child which is an ancestor of A[x + 1]. Now, we replace cr of x'th persistent tree with cr of (x + 1)'th persistent tree. Similarly, we replace cl of x + 1'th persistent tree with cl of x'th persistent tree. So now A[x + 1] is active in x'th persistent tree and both A[x] and A[x + 1] are active in (x + 1)'th persistent tree.To deactivate A[x] in x'th persistent tree we replace cl of x'th persistent tree with cl of (x - 1)'th persistent tree. Hence in this approach we do not need to create new  nodes for each update. See testers's code below for more details.Author's code:Testers's code:Hope you enjoyed the problemset! Any feedback is appreciated! :)

Editorial. Codeforces Round #390 (Div. 2)

By netman, history, 6 years ago, translation, In English754A - Lesha and array splittingOnly in one case there is no answer. When array consists entirely of zeros. Because all subarrays of such array has zero sum.

Otherwise there are two cases:

Array sum is not zero. In this case we can divide array into one subarray A[1... n].

Array sum is zero. But we know that array has non-zero elements. Then there is exists such prefix A[1... p], which sum is s and s ≠ 0. If sum of array is zero and sum of prefix is s, then sum of remaining suffix is equals to 0 - s =  - s ( - s ≠ 0). Therefore array can be divided into two parts A[1... p] and A[p + 1... n].

Time complexity — O(n).

Code754B - Ilya and tic-tac-toe gameThis problem can be solved by simple bruteforce. Let's brute cell in which Ilya put X. Let's put X in this cell. Next step is to check if there is three consecutive Xs on field. This is done as follows. Let's brute cell which is first of three consecutive Xs. Next let's brute direction of three consecutive Xs. If we know first cell and direction, we should check that there is three consecutive cells from first cell towards fixed direction.

Code754C - Vladik and chatLet's number users from 1 to n. Let's us know for every message users mentioned in message. Let's define arrays A and S. Ai =  index of sender of i-th message, if sender of i-th message is unknown, then Ai =  - 1. Si =  set of mentioned users in i-th message. Now for every message where sender is unknown we need to restore sender. In other words for every i, such that Ai =  - 1, we need to find number from 1 to n, such that for every j, that 1 ≤ j < n, condition Aj ≠ Aj + 1 satisfied.

This can be solved using Dynamic Programming:

DP(pref, last) = true, if over first pref messages we can restore all unknown senders, and pref-th message has sender number last, otherwise false.

There next transitions in DP:

, where new — index of user, who send (pref + 1)-th message. new should be not equals to last and new should be not equals to every number from set Spref + 1. Also if for (pref + 1)-th message we know sender then new should be equals to Apref + 1.

Time complexity of this DP is O(N2 * M).

Also there is exist another solution. Greedy:

While we have messages with unknown sender, for every of which there is only one possible user, which can be put as sender not violating conditions described in statement, then put this user as sender. If in one moment we will have a message with zero possible users, which can be put as sender not violating conditions in statement, then we can't restore senders of messages in chat. Otherwise if every message has two or more possible users which can be senders, then we should choose any such message and put as sender any user, which is possible for this message.

Code754D - Fedor and couponsFormalized version of this problem:

Given n segments, we need to choose k of them, such that intersection of chosen segments has maximum possible length.

Let's use binary search to find maximum possible length of intersection.

Let's this length equals to len. If exist k segments, which have length of intersection greater or equals to len, then if we decrease right border of this segments by (len - 1), then length of intersection will be greater than of equal to 1.

So solution is:

Fix len — length of intersection by binary search. Now we should check if there is exist k such segments, that their intersection length greater than or equal to len. This can be done as follows. Decrease right border of every segment by (len - 1). Now we should check if there is exist k such segments, which have intersection length greater or equals to 1. This can be done by different ways. For example using method of events — segment starts, segment ends. And we should find such point, which covered by k segments.

Time complexity — , where R ≈ 109.

Code754E - Dasha and cyclic tableLet's consider simple bruteforce.

Let's T — cyclic table, P — pattern, R — result.

Then simple bruteforces looks like that:



fill(R, true) // fill matrix R by true values

for i := 0 .. n - 1 {  for j := 0 .. m - 1 {    for x := 0 .. r - 1 {      for y := 0 .. c - 1 {        R[i][j] := R[i][j] and (P[x][y] == T[(i + x) mod n][(j + y) mod m])      }    }  }}

Let's rewrite bruteforce:



fill(R, true) // fill matrix R by true values

for x := 0 .. r - 1 {  for y := 0 to c - 1 {    c := P[x][y]    if (c == '?') continue;    for i := 0 .. n - 1 {      for j := 0 .. m - 1 {        R[(i - x) mod n][(j - y) mod m] := R[(i - x) mod n][(j - y) mod m] and (T[i][j] == c)      }    }  }}

Let's define G. Gc, i, j = true, if Ti, j = c, otherwise false.

It's easy to understand, that (T[i][j] == c) is equivalent G[c][i][j].

Then line of code R[(i - x) mod n][(j - y) mod m] := R[(i - x) mod n][(j - y) mod m] and (T[i][j] == c) is equivalent to R[(i - x) mod n][(j - y) mod m] := R[(i - x) mod n][(j - y) mod m] and G[c][i][j]

Let's write shift of matrix H of size n × m by i to the up and by j to the left as shift(H, i, j).

Also let's write element-wise and of two matrix A and B, as A and B.

Then bruteforce looks like that:



fill(R, true) // fill matrix R by true values

for x := 0 .. r - 1 {  for y := 0 to c - 1 {    c := P[x][y]    if (c == '?') continue;

    R := R and shift(G[c], x, y)  }}

Operations shift and and on boolean matrices of size n × m have time complexity  operations using std::bitset.

As result, we improved simple bruteforces which gives accepted.

Improved bruteforce works in  operations.

C++ codeJava code

Codeforces Round 389 (Div.2) Editorial

By Kostroma, 6 years ago, translation, In English748A - Santa Claus and a Place in a ClassIt can be easily seen that the side on which Santa should sit depends only on the parity of k, while the number of desk and the number of lane depend only on a value . We can see that in such numeration the number of lane equals , while the number of desk equals .

748B - Santa Claus and Keyboard CheckDenote the two strings from the input by s and t. It's enough to find all pairs of distinct si and ti and then do the following:

Ensure that each symbol is in no more than one different pair,Ensure that if symbol c is in a pair with another symbol d, then each occurrence of c in s on the i-th place takes place iff ti = d, and vice versa.If at least one of these conditions fails, there is no answer, otherwise, it's enough to print the obtained pairs.

748C - Santa Claus and RobotSolution #1: denote by dpi the least possible number of points if the robot passed only i unit segments, and we assume that dp0 = 0. Thus, the answer to the problem is dpn. It's clear that dpk + 1 ≥ dpk for every k, so for every i ≤ n one can obtain that dpi = dpj + 1, where j is the minimal of such indices that s[j + 1... i] can be a path from one point to another. That means two constraints:

either s[j + 1... i] doesn't contain any L, or it doesn't contain any R;either s[j + 1... i] doesn't contain any U, or it doesn't contain any D.This fact is offered to the reader.

Such j can be found in O(1) if we iterate over all i-s from 1 to n and keep the last occurence of L, R, U and D. So one can, storing these occurences and dp itself, implement the algorithm above and pass each test for O(n) time.

Solution #2: since we know the way to determine whether the path is valid or not (from the first solution), let's find the longest prefix of s and say that that's a path to the first point of the required collection. Then we find the longest prefix of the remaining string and state that this is the shortest path from p1 to p2, and so on.

This greedy algorithm works (obviously, in linear time), since the first solution is in fact the same greedy algorithm applied to the reversed string.

748D - Santa Claus and a PalindromeImagine a palindrome split into substrings of equal size (say, n). Here is how it may look like:

ABC DEF XYX FED CBA

We may notice a regular structure: each block, except the middle one, has its pair, which is the same string, but reversed. Here, the first block (ABC) is paired with the last (CBA), the second — with the first-but-last.

For now, let's assume that we take an even number of strings, so each string has its pair. Let's split given strings into groups; strings S and rev(S) belong to one group. Clearly, if S is not a palindrome, we must make a pair with the string S with maximum value and the string rev(S) with maximum value, until both strings exist and the sum of their values is nonnegative. If S is a palindrome, we will take two its occurrences with maximum value at a time (of course, again, if there are still at least two occurrences and the sum of values is nonnegative).

The trickiest part is the central block. Clearly, only the palindromic strings may be at the central block. However, there may be many of them, and we should select the one which gives the maximum value overall. There are several cases. Consider the point when you've taken the last pair from the list of S-s and stopped.

If the value of the next element is nonnegative (say, x), we may simply take it and say that x is our possible score for S being in the center. We wouldn't make a valuable pair of it anyway. Otherwise we need to split the last taken pair. Denote the values of last taken strings as a and b (a ≥ b). Note that b < 0, because otherwise it makes no sense to use a separately. If we take a pair, we get score a + b. If we take just the first element, we get score a. So, in this case our possible score is  - b (while a + b is already added to the main answer!)

Now, the central string will be the one with the maximum possible score, and its value should be added to the answer.

748E - Santa Claus and TangerinesIt is obvious that if the total number of slices is less than k, then the answer is  - 1. Otherwise it's at least 1. Let's find the answer in this case.

Let's divide tangerines and parts in halves one by one in order to find the best answer. It's easy to see that it makes no sense to divide a part of size x if there is an undivided part of size y > x. So we are going to proceed dividing the largest part on each step. Let's also maintain current answer, i. e. the size of the k-th biggest current part, and a set of parts which we are going to present to the pupils. When we divide the largest part, there are two possible cases:

If the size of any part is less then the current answer, then it's obvious that the answer will never be greater if we proceed further, so we can stop the process.If the sizes of both parts are greater than or equal to the current answer, then we should delete the initial part and add the resulting parts to those we present to the pupils in the current answer, and then delete the smallest part from the set making it of size k again.We can see that in the second case the answer never decreases so we can just proceed until the first case happens.

To emulate this process in a fast way, we can keep an array from 1 to A, where A = 107 is the maximum possible number of slices in a part, where each cell contain the current number of parts of that size. Thus, we can maintain two pointers: one to the current answer and one to the current maximum size, so the whole process can be done in O(n). The overall complexity is O(n + A).

748F - Santa Clauses and a Soccer ChampionshipFirstly, let's prove that there exists a vertex v in the tree such that if we make it a root, all subtrees of its neighbours (which does not contain v) contain no more than k vertices in which some games are played (we call these vertices chosen further). We root the tree in some vertex root and denote f(u) the number of chosen vertices in the subtree of u. Now we need to prove that there exists vertex v such that f(v) ≥ k (then no more than k vertices outside subtree of v are chosen), but for all children to of v f(to) ≤ k holds. Assume there is no such vertex v, then each vertex u such that f(u) > k has some child u' such that f(u') > k. So we can build a sequence u0, u1, ... such that u0 = root,  ui + 1 is a child of ui and f(ui) > k. But obviously, at some point we will go to the leaf, which clearly has f(u) ≤ 1. This leads us to a contradiction.

This argument also gives us an easy way to find the desired vertex v: just calculate f(u) for all subtrees of the rooted tree and then go from the root down, always going to the child with f(ui + 1) > k, at some point we will find that such vertex does not exist — then current vertex is the one we were looking for.

We claim that the answer to the original problem is always 1, i.e. we can always choose one vertex, where all teams will live. Consider vertex v having f(to) ≤ k for all its children. We create a list of all chosen vertices, firstly we write all chosen vertices of the first child's subtree of v, then all chosen vertices of the second child's subtree, and so on. In the end, if v is chosen too, we add it to the end of the list. Now we have a list of 2k vertices a. Let's create k pairs of the form (ai, ai + k). Since for all children of v f(to) ≤ k holds, the vertices which numbers in the list differ by k can not belong to the same subtrees, and thus the shortest path between ai and ai + k passes through the vertex v.

Codeforces Round #388 (Div. 2) Editorial

By Slamur, 6 years ago, translation, In English749A - Bachgold ProblemWe need represent integer number N (1 < N) as a sum of maximum possible number of prime numbers, they don’t have to be different.

If N is even number, we can represent it as sum of only 2 - minimal prime number. It is minimal prime number, so number of primes in sum is maximal in this case.

If N is odd number, we can use representing of N - 1 as sum with only 2 and replace last summand from 2 to 3.

Using of any prime P > 3 as summand is not optimal, because it can be replaced by more than one 2 and 3.

749B - Parallelogram is BackDenote the input points as A, B, C, and the point we need to find as D.

Consider the case when the segments AD and BC are the diagonals of parallelogram. Vector AD is equal to the sum of two vectors AB + BD = AC + CD. As in the parallelogram the opposite sides are equal and parallel, BD = AC, AB = CD, and we can conclude that AD = AB + AC. So, the coordinates of the point D can be calculated as A + AB + AC = (Ax + Bx - Ax + Cx - Ax, Ay + By - Ay + Cy - Ay) = (Bx + Cx - Ax, By + Cy - Ay).

The cases where the diagonals are BD and AC, CD and AB are processed in the same way.

Prove that all three given points are different. Let's suppose it's wrong. Without losing of generality suppose that the points got in cases AD and BD are equal.

Consider the system of two equations for the equality of these points:

Bx + Cx - Ax = Ax + Cx - BxBy + Cy - Ay = Ay + Cy - ByWe can see that in can be simplified as

Ax = BxAy = ByAnd we got a contradiction, as all the points A, B, C are distinct.

749C - VotingWe will emulate the process with two queues. Let’s store in the first queue the moments of time when D-people will vote, and in the second queue - the moments of time of R-people. For every man where will be only one element in the queue.

Now compare the first elements in the queues. The man whose moment of time is less votes first. It’s obvious that it’s always profitable to vote against the first opponent. So we will remove the first element from the opponent’s queue, and move ourselves to the back of our queue, increasing the current time by n - next time this man will vote after n turns.

When one of the queues becomes empty, the corresponding party loses.

749D - Leaving AuctionFor every man at the auction we will save two values: his maximum bid and the list of all his bids. Then save all men in the set sorted by the maximal bid.

Now, when the query comes, we will remove from the set all men who left the auction, then answer the query, and then add the men back. The total number of deletions and insertions will not exceed 200000.

How to answer the query. Now our set contains only men who has not left.

If the set is empty, the answer is 0 0. Otherwise, the maximal man in the set is the winner. Now we have to determine the winning bid. Let’s look at the second maximal man in the set.If it doesn’t exist, the winner takes part solo and wins with his minimal bid.Otherwise he should bid the minimal value that is greater than the maximal bid of the second man in the set. This is where we need a list of bids of the first maximal man. We can apply binary search and find the maximal bid of the second man there.749E - Inversions After ShuffleLets calculate all available segments count – . It will be a denominator of answer fraction.

Also, necessary to understand, that expected value of inversion count in shuffled permutation with length len equal  (It can be prooved by fact, that for each permutation there are mirrored permutation (or biection i -  > n - i + 1) and sum of inversion count his permutations are equal  inversions).

Next, we will find expected value of difference between expected value of inversion count after operation and inversion count in the source array. And add it to the inversion count in the source array.

Naive solution:

For every segment we will calculate the count of inversions in it, and also the expected value of the inversion count in it after shuffle. Take the difference and divide by a denominator. Sum these values for all segments. This solution has quadratic asympthotics, try to improve it.

Optimized solution:

We will go through the permutation from right to left and for each position count the sum of inversions in the initial permutation for all segments that start in the current position (denote that the largest segment which ends at the position n has the length len), also we will maintain the sum of expected values of the inversion counts on the segments of lengths 1..len. Knowing these two numbers, increase the answer by their difference divided by the denominator.

To calculate the first value we will use the data structure that can get the sum of numbers on the prefix and modify the value at the single position (e.g. Fenwick tree). For the position i we need to know how many numbers are less than ai, and every number should be taken t times, where t is number of segments where it is contained. Suppose we have calculated answers for some suffix and are now standing at the position i. For every position to the left it will be added n - i + 1 times (the number of positions j >  = i as the candidates for the right bound, in 1-indexation). Perform fenwick add(a[i], n - i + 1).

Codeforces Round #387 (Div.2) Editorial

By fcspartakm, history, 6 years ago, translation, In English747A - Display SizeWe can iterate through the values of a from 1 to n. For each i if n mod i = 0 and if abs(i - n / i) is less than already found different we need to update answer with values min(i, n / i) and max(i, n / i) (because a must be less than b).

747B - Mammoth's Genome DecodingLet n is the length of the given string. The number of each letter in the resulting string must be equals to n / 4. If n mod 4 does not equal to 0 — there is no solution.

If some letter meets in the given string more than n / 4 times — there is no solution.

After that we always can build the answer. We need to iterate through the given string and change question symbols on any letter, which meets in the current string less than n / 4 times.

747C - ServersThe given constraints allow to simply modulate described process. Let's use array server, where server[i] is equals to the time when i-th server will become free. Than for each query let's find the number of servers which free in moment when this query came. We can do it in O(n), where n is the number of servers. If the number of free servers is less than k we need to print -1. In the other case, we can iterate through all free servers and find the sum of k servers with smallest numbers and store in array server for this servers time of release equals to t + d.

747D - Winter Is ComingAt first let's process the case when there is no solution — when the number of days with negative temperature cnt more than k. Now we need to subtract from k the number of days cnt.

If we will use winter rubber only in days with negative temperature we will get the maximum value of answer: it is the number of segments where all days have negative temperature multiply by 2.

Between the segments with negative temperatures there are segments which we ride on the summer rubber. Let's put in set the lengths of this segments (not include the segments with first and last days if thеy have non-negative temperatures, this cases we need to process separately from the main solution).

After that we need to delete from the set smallest lengths of segments one by one, decrease k on this value and decrease answer on 2. We can make it until k >  = 0 and the set is not empty.

Now we only need to check if we can ride on winter rubber the last segment of days with non-negative temperature. If it is possible we need decrease the answer on 1, in the other case the answer remains unchanged.

747E - CommentsLet pos is a global variable equals to the current position in the given string. To solve we can use recursive function rec(lvl, cnt), means that in the current moment we are on the level of replies lvl and there is cnt comments on this level. Than we need iterate by i from 1 to cnt and on each iteration we will make the following: read from the position pos comment, add this comment to the answer for level lvl and than read the number of it children nxtcnt. After that pos will in the beginning of the first child of this comment and we need to run rec(lvl + 1, nxtcnt). For the higher level we can put in cnt big number and return from the function rec in the moment when pos will become equals to the length of the given string.

747F - Igor and Interesting NumbersLet's use dynamic programming and dp[i][j] — the number of valid numbers with length i and maximal digit in this numbers is j. Let iterate by nj from j + 1 and brute len (how many times we will take digit nj). Than new length ni - i + len, number will ends to nj repeated len times. Then dp[ni][nj] = dp[i][j] * (ni! / (i! * len!)).

After that we need to find the length of the answer number lenAns. Let iterate by lenAns from 1 and calculate the number of numbers with length lenAns. It can be done with help of dp (brute maximum digit and calculate dp for len - 1).

Codeforces Round #386 (Div.2) Editorial

By fcspartakm, history, 6 years ago, translation, In English746A - CompoteAt first let's calculate how many portions of stewed fruit (in one portion — 1 lemon, 2 apples and 4 pears) we can cook. This number equals to min(a, b div 2, c div 4), where x div y is integer part of x / y. After that we need to multiply this number of 7, because there is 7 fruits in 1 portion, and print the result.

746B - DecodingTo find the answer we can iterate through the given string from the left to the right and add each letter in the answer string — one letter to the begin, next letter to the end, next letter to begin and so on. If n is even than the first letter must be added to the begin and the second letter to the end. In the other case, the first letter — to the end, second — to the begin. We need to make it until we do not add all letters from the given string.

746C - TramIt is easy to show that if Igor faster than the tram the answer is |x1 - x2|·t2.

In the other case we need to use the following hint: the time of arrive does not depend on how much Igor walk before enter the tram, if the tram will reach the finish point faster than Igor. So Igor can wait the tram in the point x1.

The answer is minimum of the following values: the time during which Igor will reach the point x2 by foot and the time during which the tram will reach at first the point x1 and than the point x2.

746D - Green and Black TeaLet's use greedy to solve this problem. On the current step we choose tea, which left more, but if the last k cups were equal we need to use the other tea. If we can't use the other tea — there is no answer and we need to print «NO». So, we need to store the number of last cups, which were equals and how many of green and black tea left we greedily build the answer. If we use all tea with this algorithm — we found the answer and it is guaranteed that it is correct answer.

746E - Numbers ExchangeBecause of all resulting numbers must be distinct we necessarily need to change all numbers with meet more than once in the given sequence a. We will use two pointers: pointer on next even number in the sequence b (at first this pointer equals to 2) and pointer on next odd number in the sequence b (at first it is 1). Also we will store the number of odd and even numbers in a.

At first let brute the numbers in a. If current number meets more than once we have two ways: if the number of numbers with it parity less or equal to the number of numbers with other parity in a, we change this number to the number with same parity from b and move needed pointer; in the other case — change this number to number with different parity and move needed parity.

After we finished iterations all numbers will be different but the number of odd numbers can be not equal to the number of even numbers. We need to make similar iterations and change only numbers for which the number of numbers with such parity more. If in some moment we can not change next number — the answer is -1.

746F - Music in CarThis problem can be solved with help of two pointers. We will store two sets — set with songs with full time and set with songs with partly time. How to move left and right pointers and recalculate current answer? Let left end of the current segment is l and right end of the segment is r. Let the set of songs with partly time is half and with full time — full. In this sets we will store pairs — time of listening each song and it number.

Right end we will move in the following way: if we can add partly song and we have enough time to listen it — we take it (also add this song to half) and add to time (tr + 1) / 2 and add to the answer ar. In the other case we have two cases. First — we add current song as full song, second — we add current song as partly song. Here we need to choose case with less with the total time. Also here we need to correctly add song to sets and update total time and the answer. If total time became more than k we are not allowed to move r. Now we need to update global answer with the current value of answer.

Left end we will move in the following way: if we took song as full song we delete it from full, subtract from total time length of this song. In the other case we delete it from half and subtract from the total time the (tl + 1) / 2. After that we try to take some song from full. If the size of full is 0, we can not do that. If we done it we need to change total time on the songs on the current segment.

746G - New RoadsThe statement of this problem equals to: we need to build rooted tree with k leafs and for each i from 1 to n on the depth i there are ai vertices.

Let m is sum of all numbers from a — the number of vertices in the tree without root.

At first let build the path from the root to the leaf on the depth n, i. e. on each level we create one vertex which connect with vertex on previous level. In resulting tree we necessarily have such path.

Let c is the number of vertices (do not consider already created vertices) which we need to make "not leafs". It is equals to c = m - k - n + 1.

If now c < 0 there is no answer — we can not make less number of leafs which we already have.

In the other case we need to each level i until c > 0 and on the level i - 1 we have leafs and the level i does not filled we will add new vertex to random vertex from the level i - 1, which does not a leaf. Other vertices on the level i we can add to vertex which has been created when we built path from the root to the depth n.

If on the current step c > 0 — there is no solution. In the other case we built needed tree and can print the answer.

Codeforces Round #385 Editorial

By Lewin, 6 years ago, In EnglishShort solutions:

Div2A: How many times do we need to do a cyclic shift to consider all possible ones? Afterwards, what data structure allows us to easily check number of distinct elements?Div2B: Imagine the process in reverse. What types of identical shapes can I get if I cut a rectangle into two pieces? Remember, pieces cannot be rotated or flipped.Div2C / Div1A: How do we handle components with special nodes? What do we do with the ones without special nodes?Div2D / Div1B: We don't get many questions, so is there a way to "parallelize" questions? Another approach, can we split up the condition i != j somehow using bits?Div2E / Div1C: First, somehow reduce it so r_i,b_i <= n. Now, we can bound the excess tokens by a small number, so we can do bitmask dp from here.Div1D: The optimal circle must touch a blue point. Now, either consider the inversion, or do a binary searchDiv1E: What makes a list good? How fast can we do this check, and how many times do we need to do this check?Long solutions:

Hongcow Learns the Cyclic ShiftWe only need to consider at most |s| cyclic shifts (since |s| cyclic shifts returns us back to the original string).

So, we can put these all in a set, and return the size of the set.

codeHongcow Solves A PuzzleI really apologize for the ambiguity of this problem. We worked hard to make it concise and accurate, but we left out too many details.

Basically, the idea is we want to overlay two of these pieces together so that no square has more than 1 X, and the region of X's forms a rectangle.

Now for the solution:

First, let's look at it backwards. I have a rectangle, and I cut it in two pieces. These two pieces have the same exact shape. What shapes can I form?

A necessary and sufficient condition is that the piece itself is a rectangle itself! There are a few ways to check this. One is, find the min/max x/y coordinates, and make sure the number of X's match the bounding box of all the points.

codeHongcow Builds a NationFirst, let's make all connected components cliques. This graph is still stable.

Now, there are some components without special nodes. Where should we connect them?

If there is a component with size A and a component with size B, we can add A*B edges if we connect these two components. So, it makes sense to choose the largest component.

codeHongcow's GameFor the bits solution: We want to create 20 questions where for every i != j, there exists a question

that contains j and not i, and also a qusetion that contains i and not j. If we can do this, we can find the min for each row.

Note that i != j implies that there exists a bit index where i and j differ.

So, let's ask 2 questions for each bit position, one where all indices have a value of 0 in that position, and one where all indices have a value of 1 in that position. This is a total of at most 20 questions, and we can show that this satisfies the condition above, so this solves the problem.

Parallelization will basically reduce to the above solution, but is another way of looking at the problem.

First, let's ask {1,2,...,n/2} and {n/2+1,...,n} This handles the case where the min lies on the opposite half.

[OOOOXXXXOOOOXXXXOOOOXXXXOOOOXXXXXXXXOOOOXXXXOOOOXXXXOOOOXXXXOOOO]For example, this handles the case where the min lies in the X part of the matrix, and we split it into two identical problems of size n/2 within the O matrix.

Now, we can ask questions for each submatrix, but we can notice that these two don't interact so we can combine all the questions at this level.

However, we should ask the questions in parallel, as we don't have that many questions For example, for n=8, we should ask

First level:[1,2,3,4][5,6,7,8]

Second level[1,2],[5,6] (i.e. ask 1,2,5,6 all together, but this is actually two different subproblems, one for the top left, and one for the bottom right).[3,4],[7,8]

Third level[1],[3],[5],[7][2],[4],[6],[8]As you can see, this reduces to the bit approach above if N is a power of 2.

codeHongcow Buys a Deck of CardsAlso note that if r_i or b_i >= n, we need to collect tokens no matter what since those costs can't be offset. So, we can assume that r_i, b_i <= n.

Let's only buy tokens when we need them. Note that after buying a card, you will have either 0 red tokens or 0 blue tokens, so our dp state can be described by [mask][which one is zero][how many of the other] The dimensions of this dp table are 2^n * 2 * (n^2) (n^2 because the costs to buy cards is at most n).

See the code for more details on how to update this dp.

codeHongcow Draws a CircleFirst to check if an answer can be arbitrarily large, we can see if there is any red point that is on the convex hull of all our points. So from now on, we can assume the answer is finite.

We can show that the optimal circle must touch a blue point. To see this, consider any optimal circle that doesn't touch a blue point. We can make it slightly bigger so that it does touch one.

So, let's binary search for the answer. However, you have to very careful and notice that the binary search isn't monotonic if we only consider circles touching blue points. However, if we consider circles that touch either a red or blue point, then the binary search is monontonic, so everything works out.

To check if a radius works, we can do a angle sweep around our center point. We have a fixed radius and fixed center, so each other point has at most two angles where it enters and exits the circle as we rotate it about the center point. We can keep track of these events and find an interval where the circle only contains red points.

code for binary searchFor the inversion solution, let's fix the blue point that our circle touches. Then, let's take the inversion around this point (i.e. https://en.wikipedia.org/wiki/Inversive_geometry). Now, circles that pass through our center points become lines, and the interior of those circles are in the halfplane not containing the center point. The radius of the circle is inversely proportional to the distance between our center point to the line after inversion.

So, we can say we want to solve the following problem after inversion. Find the closest line that contains no blue points in the halfplane facing away from our center point and at least one red point. We can notice that we only need to check lines that contain a blue point on the convex hull after inversion.

To make implementation easier, you can make the additional observation that the sum of all convex hull sizes will be linear through the process of the algorithm. Some intuition behind this observation is that only adjacent nodes in a delaunay triangluation can appear on the convex hull after inversion, so the sum is bounded by the number of edges in such a triangulation (of course, we do not need to explicitly find the triangulation).

code for inversionHongcow Masters the Cyclic ShiftLet M denote the total number of characters across all strings.

Consider how long it takes to compute f(L) for a single list.

Consider a graph where nodes are suffixes of strings. This means we already spelled out the prefix, and still need to spell out the suffix.

There are at most M nodes in this graph. Now, draw at most N edges connecting suffixes to each other. We can find the edges efficiently by doing suffix arrays or z algorithm or hashes.

Now, we claim is the list is good if and only if there is no cycle in this graph. You can notice that a cycle exists => we can construct a bad word. Also, if a bad word exists => we can form a cycle. So, we can check if there is a cycle, which takes O(N*M) time.

Next step is to notice that extending a bad list will never make it good. So we can do two pointers to find all good intervals, which requires O(n) calls to the check function. So, overall this runs in O(N^2*M) time.

You might be wondering why this problem asks for sublists rather than the entire list. To be honest, it's just to make tests slightly stronger (i.e. I get ~30^2x the number of tests in the same amount of space).

code

Codeforces Round #384 Editorial

By hloya_ygrt, history, 6 years ago, translation, In English743A - Vladik and flightsThe answer is 0, if airports with numbers a and b belong to one company. Otherwise there are two adjacent airports, that belong to different companies. We can get to one of them for free, then pay 1 to fly from one to another and then fly to airport number b for free. So, in this case the answer is 1. Complexity O(n).

Setter's code743B - Chloe and the sequenceConsider the string after n steps of algorithm. We can split it into three parts: string from previous step, new character, another one string from previous step. Lets find the part, where our k-th character is, and reduce our string to the string from the previous step.

The complexity is O(n).

Setter's code743C - Vladik and fractionsNote that for n = 1 there is no solution, and for n > 1 there is solution x = n, y = n + 1, z = n·(n + 1).

To come to this solution, represent  and reduce the problem to represent  as a sum of two fractions. Let's find the difference between  and  and get a fraction , so the solution is 

Setter's code743D - Chloe and pleasant prizesOur task is to choose two disjoint subtrees, such that sum of numbers in the first plus the sum in the second is maximal.

Lets calculate for each vertex this dynamic programming using dfs seach: sumv — sum of all the numbers in subtree of vertex v, and mxv — maximal value from all sumk in subtree of vertex v (k belongs to subtree of v).

We can calculate the answer using another dfs search, maintaining the value of maximal subtree, which is outside of current subtree. For example, if we are in vertex v, to update this value when going to call dfs(s) (where s is some son of v) we have to find maximal mxv from all other sons of v.

The complexity is O(n).

Setter's code743E - Vladik and cardsSuppose we have taken at least len cards of each color and b colors of them have len + 1 cards.

Then the answer will look like: (8 - b) * len + b * (len + 1). Obviously, if our sequence of cards allows us to take len cards of each color, then it allows to take len - 1, and len - 2, so on.

Lets binary search for len value, and check allowability this way:

Define bitmask dynamic programming dp[pos][mask] (1 ≤ pos ≤ n, 0 ≤ mask ≤ 28 - 1) as the number of colors, for which we have taken len + 1 element, if we passed pos cards in the sequence and the colors, which has bit equal to one in bitmask mask.

We will have two different transitions. Iterate the new color, which has zero bit in the mask, to make the first transition, and find its occurrence number len in subarray [pos + 1, n]. The second transition is completely the same, but we have to find occurrence number (len + 1).

To find the occurrence number len of some color in subarray we should maintain an array of the remaining cards for each color.

Finally, find the maximal allowable len, and in dp calculated for len find the maximal additional cards in dp[n][28 - 1].

This solution for k colors of cards (8 in our case) has complexity O(log(n) * n * k * 2k).

Setter's code

Codeforces Round #383 editorial

By Arpa, history, 6 years ago, In EnglishHello again, and hope you have been Joon-Joon of the round :P

I’m preparing harder version of some of the problems (Div.2 A, B, and Div.1 A, D) and I’ll put them on some gym, so if you are interested in harder version of problems please wait for about one week.

You can see and download the problem archives (pretests, tests, statements, validator, checker, solutions) here. You can see solutions in solutions folder, note that there are several codes there, there is a descriptor for each code (.desc) that shows the verdict of that code.

Preparation details:On 25 May Batman came up with problem Div.1 D and other problems authored inchmeal.

9/25/16: Proposal sent to Gleb.

11/12/16: Answer from Gleb: Your proposal has been redirected to Nikolay KAN.

11/15/16: Nikolay has replied, and commented about problems, saying some problems are easy, some are hard, some are ok.

I changed some of the problems, change the constraints for some others and we talked about solutions through email.

11/17/16: We switched to Telegram.

Creating tests, writing generators, writing statements, etc started in the Polygon.

12/06/16: Round #383 hold.

gKseni told me how you want to get your money and I had no idea.

gKseni told me that it is possible to transfer my money and finally May 4, 2017, I received my money through Okpay.

I have another problem set to prepare another div.1 + div.2 round, but I haven’t enough time now :(.

Paintings in problems were suggested by me, painted by Batman and edited by me. Problem stories and this editorial were suggested and written by me. KAN helped us preparing the round very much, we are thankful to him. This table for each person and for each problem shows the number of the committed changes (in polygon) he has made in preparing the problem (it is good for showing how much someone was involved in preparing).

I used Google Docs for writing everything.

User\Problem	Div.2 A	Div.2 B	Div.1 A	Div.1 B	Div.1 C	Div.1 D	Div.1 E	TotalMe	8	9	16	16	10	19	37	114Batman	3	2	1	0	7	0	1	14KAN and testers	3	3	5	9	7	7	13	61Here is another table, showing the number of expected accepts (in my opinion, before the contest) and the number of accepts (after system testing).

Div.2 A	Div.2 B	Div.2 C	Div.2 D	Div.2 E	Div.1 A	Div.1 B	Div.1 C	Div.1 D	Div.1 EExpected	6000	4500	2000	500	150	600	400	300	50	10Accepted	3966	1723	1131	684	10	479	474	50	15	1HintsDiv.2 A: Write the last digit of 1378n for several small values.

Div.2 B : Note that if  then .

Div.1 A: If the answer exists, it depends on the lengths of cycles in the functional graph.

Div.1 B: It’s similar to a simple knapsack problem, think on O(n·W) solution using dynamic programming.

Div.1 C: Build a graph and put edges between each 2 * i, 2 * i + 1 and each BF and GF.

Div.1 D: Keep a mask for each vertex, i-th bit of maskv is true if the number of edges in the path from root to v such that letter i is written on them is odd. Now if number of bits in  is 0 or 1, path between v and u is Dokhtar-kosh.

Div.1 E: Sort all of the options, then the problem becomes easier, solve the new problem with sqrt decomposition.

DetailsDiv.2 A

Idea, authoring, solution by Batman, preparation by Batman and me.

My and Batman ’s birth year in Solar Hijri calendar is 1378.

Div.2 B

Idea, authoring, solution by Batman, preparation by Batman and me.

Div.1 A

Idea, authoring, solution, preparation by me.

Attractive boys/girls are called Joon-Joon in Persian. Owf is a sound used when we (Persian) are interested in something, especially when we see something attractive, such as our crush :P

Div.1 B:

Idea, authoring, solution, preparation by me.

The problem authored by me 2 days before the contest :D (#FastAsFerrari). Attractive girls are called (some word similar to) “Hos” in Persian. It’s a good place to thank amsen, whose name (Hir) gave me this idea (to use word “Hos” instead of “attractive girl”).

Div.1 C :

Idea, authoring, solution by Batman, preparation by Batman and me.

“Kooft” is something make people die. “Zahre-mar” meaning is “Venom of Snake”.

Div.1 D:

Idea by Batman, authoring, solution, preparation by me.

“Dokhtar-kosh” is an adjective, used when something is very very attractive.

Div.1 E:

Idea, authoring, solution, preparation by me.

Solutions742A - Arpa’s hard exam and Mehrdad’s naive cheatYou know . If n = 0 answer is 1, otherwise, you can prove with induction that if:

-  then answer is 6.

-  then answer is 8.

-  then answer is 4.

-  then answer is 2.

Time complexity: .

Corner case: Solutions that forget to add n = 0 case got failed system testing.

742B - Arpa’s obvious problem and Mehrdad’s terrible solutionNote that if  then . Keep in numx the number of repetitions of number x. Now for each x, add  to answer. Then divide answer by 2 (if X is 0, don’t).

Time complexity: .

Corner case #1: Some codes got WA when X is 0.

Corner case #2: Some codes got RE because  can be as large as max(x, y)·2.

741A - Arpa's loud Owf and Mehrdad's evil planMake a directed graph and put edge from i and crushi. If the graph has vertex such that its in-degree is 0 then obviously answer doesn't exist. Otherwise, the graph consists of some cycles. For each cycle suppose that its length is len. If it has odd length, add len to S, otherwise, add len / 2.

The answer is the LCM of numbers in S.

Time complexity: .

741B - Arpa's weak amphitheater and Mehrdad's valuable HosesIt’s a simple knapsack problem. Let’s solve this version of knapsack problem first: we have n sets of items, each item has value and weight, find the maximum value we can earn if we can choose at most one item from each set and the sum of the chosen items must be less than or equal to W. Let dpw be the max value we can earn if the sum of weights of chosen items is less than or equal to w. Now iterate on sets one by one and update dp as follows: for each item X, and for each weight w, newDpw = max(newDpw, oldDpw - X.weight + X.value).

Run dfs and find groups at first. The problem is same with above problem, each group is some set in above problem, just add the whole group as an item to the set that related to this group.

Time complexity: .

741C - Arpa’s overnight party and Mehrdad’s silent enteringBuild a graph and put an edge between each 2·i, 2·i + 1 and each BF and GF. This graph doesn’t have cycles with odd length. So it is a bipartite graph. Now give Kooft to some part and Zahre-mar to other.

Time complexity: .

741D - Arpa’s letter-marked tree and Mehrdad’s Dokhtar-kosh pathsPlease read my dsu on tree (sack) tutorial before you read.

Let’s calculate for each vertex such v, length of longest Dokhtar-kosh path that starts in some vertex of subtree of v, passes from v, and ends in some other vertex of subtree of v using sack (explained below); then we can sum up this values and get answer for each vertex.

First keep a mask for each vertex, i-th bit of maskv is true if the number of edges on the path from the root to v such that the letter i is written on them is odd. Now if the number of bits in  is 0 or 1, the path between v and u is Dokhtar-kosh.

Let’s use sack, assume bagMask is the maximum height for a vertex that is present in our sack and its mask is equal to Mask.

Let’s define two functions used in sack:

AddToSack(vertex x) : If bagmaskx is less than hx, set bagmaskx = hx.

UpdateCurrentAnswer (vertex x, vertex root) : For each Mask such that  has at most one bit, update the CurrentAnswer, with hx + bagMask - 2·hroot (updating means if CurrentAnswer is less than hx + bagMask - 2·hroot, set CurrentAnswer to it).

Suppose dfs function arrives to vertex v. Call dfs for each child of v except the biggest one (which has more vertices in its subtree than others) and clear the sack each time. Call dfs for big child of v and don’t clear the sack. Then for each other child u and for each vertex , call UpdateCurrentAnswer(x, v). Then for each vertex , call AddToSack(x). After the addition of the children is done, call UpdateCurrentAnswer(v, v) and AddToSack(v). Now the answer for this vertex is CurrentAnswer.

To clear the sack, for each vertex  set bagmaskx =  - inf (i.e.  - 109) and set CurrentAnswer to 0.

Note that there exists another solution using centroid decomposition, but it’s harder.

Time complexity:  (z is number of characters which is equal to 22).

Corner case: You must use an array, no map or unordered map for bag, these solutions got TLE.

741E - Arpa’s abnormal DNA and Mehrdad’s deep interestFirst sort all of the options. Use suffix array to compare two options. Give rank to each option.

Then problem is to find minimum rank in each query. Use sqrt decomposition and divide queries into two groups:

- 

There are less than  segments that satisfy the conditions. Keep all of them, solve them at the end together with some method (it's a simple RMQ).

- 

Keep the query in some vector assigned to this K.

Now for each K from 1 to :

Break array into K arrays. i-th of them contains indexes j such that . Then break each query assigned to this K into these arrays and solve them with some method (it's a simple RMQ).

Time complexity :  (if you use some  method for solving RMQ part).

I’d like to finish the editorial with the below poem by Hafez:



از صدای سخن عشق ندیدم خوش‌تر    یادگاری که در این گنبد دوار بماندTranslation: I have never seen anything that sounds better than love, it’s the relic which will remain in the universe.

Good luck and see you soon in “Round #383 hard version” ;)

Разбор Codeforces Round #382

By albertg, history, 6 years ago, translation, In English735A - Ostap and Grasshopper

Problem on programming technique. You have to find at which positions are grasshoper and insect. If k does not divide the difference of position, then answer is NO. Otherwise we have to check positions pos+k, pos+2k, ..., where pos is the minimal poisiton of grasshoper and insect. If somewhere is an obstacle, then answer is NO, otherwise the answer is YES.

735B - Urbanization

First of all, note that n1+n2 chosen ones should be people with top (n1+n2) coeficients. Secondly, if the person with intelegence C will be in the first city then he will contribute to our overall IQ with C/n1 points. So, if n1<n2, then top-n1 ratings should be in the small city and the top-n2 from others — in the big city.

736A - Tennis Championship

Let us solve the inverse problem: at least how many competitors should be, if the champion will have n matches. Then there's obvious reccurrent formula: f(n+1)=f(n)+f(n-1) (Let us make the draw in a way, where the champion will play n matches to advance to finals and the runner-up played (n-1) matches to advance the final). So, we have to find the index of maximal fibunacci number which is no more that number in the input.

736B - Taxes

The first obvious fact is that the answer for prime numbers is 1. If the number is not prime, then the answer is at least 2. When is it possible? It is possible in 2 cases; when it is sum of 2 primes of its maximal divisor is 2. If 2 divides n, then so does integer n/2. n/2<=2=>n<=4=>n=4, where n is prime. According to Goldbach's conjecture, which is checked for all numbers no more than 10^9, every number is a sum of two prime numbers. Odd number can be sum of two primes, if (n-2) is prime (the only even prime number is 2). Otherwise, the answer is 3 — n=3+(n-3), (n-3) is sum of 2 primes, because it is even.

736C - Ostap and Tree

First of all, thanks to albert96 and GlebsHP for their help with the tutorial of this problem. Secondly, sorry for being late.

Problem can be solved by the method of dynamic programming. Let dp[v][i][j] be the number of possibilities to color subtree of vertex v in such a way that the closest black vertex is on depth i, and the closest white vertex — on depth j (we also store dp[v][-1][j] and dp[v][i][-1] in the cases where there are no black and white vertexes in diapason k of v respectively). In order to connect two subtrees, we can check all pairs (i,j) in both subtrees (by brute-force algorithm). Then let we have pair (a,c) in the first subtree and pair (b,d) in the second one. If min(a,c)+max(b,d)<=k, then we update value of current vertex.

Complexity of the algorithm O(n*k^4), which is acceptable for this particular problem (n — the number of vertexes, k^4 brute force search of pairs (a,b); (c,d)).

736D - Permutations

This problem consists of 3 ideas. Idea 1: remainder modulo 2 of the number of permutation is equal to the remainder modulo 2 of the determinant of the matrix whose entries are 1 if (ai,bi) is in our list and 0 otherwise. Idea 2: If we cahnge 1 by 0, then the determinant will differ by algebraic compliment. That is, if we count inverse matrix, than it will reflect reminders modulo 2 (B(m,n)=A'(m,n)/detA, detA is odd). Idea 3: Inverse matrix can be counted for O((n/32)^3) time. However, we can work is field of integers modulo 2. The summation can be replaced by XOR. So if we store in one "int" not a single but 32 numbers, then we can reduce our assymptocy to O(n^3/32), which is OK.

736E - Chess Championship

Suppose set (a1,a2,...,am). Then the list is valid if set {2m-2, 2m-4, 2m-6, ..., 0} majorizes the set {a1,a2,...,am}. Let us prove it! Part 1: Suppose n<=m. Top n players will play n(n-1)/2 games with each other and n(m-n) games with low-ranked contestants. In these games they will collect 2*n(n-1)/2 points (in each game there is exactly 2 points) for sure and at most 2*n*(m-n) points in games with others. So they will have at most 2*(n*(n-1)/2+n*(m-n))=2*((m-1)+(m-2)+...+(m-n)) points. Now construction: Let's construct results of participant with most points and then use recursion. Suppose the winner has even number of points (2*(m-n) for some n). Then we consider that he lost against contestants holding 2,3,4,...,n places and won against others. If champion had odd number of points (2*(m-n)-1 for some n), then we will construct the same results supposing that he draw with (n+1)th player instead of winning agianst him. It is easy to check that majorization is invariant, so in the end we will have to deal with 1 men competition, when set of scores {a1} is majorized by set {0}. So a1=0, and there is obvious construction for this case. So we have such an algorithm: we search for a compiment set which is majorized by {2m-2,2m-4,...,0}. If there is no such set answer is NO. Otherwise answer is YES and we construct our table as shown above. Assymptosy is O(m^2logm) (calling recursion m times, sorting the array (we can lose non-decreasing order because of poor results) and then passing on it linearly.

Codeforces Round #381 Editorial

By halin.george, history, 6 years ago, In Russian740A - Alyona and copybooksLet k - is the smallest non-negative integer such that n + k is a multiple of 4.

If k is 0, then, obviously, the answer is 0.

If k is equal to 1, then you can buy one set of one notebook, you can buy 3 sets of three notebooks, you can buy 1 set of three notebooks and 1 set of two notebooks. Take the most optimal response.

If k equals 2, you can buy 2 sets of one notebook, 1 set of two notebooks, two sets of three notebooks. Take the most optimal response.

If k is equal to 3, you can buy 3 sets of one book, 1 set of single and 1 set of two notebooks, one set of three notebooks. Take the most optimal response.

740B - Alyona and flowersIf you restate the problem, it is clear that you need to take sub-arrays that have positive sum.

739A - Alyona and mexObviously, the answer to the problem can not be greater than the minimum length among the lengths of the sub-arrays. Suppose that the minimum length of all the sub-arrays is equal to len. Then the desired array is: 0, 1, 2, 3, ..., len - 1, 0, 1, 2, 3, ... len - 1... . Not hard to make sure that mex of any subarray will be at least len.

739B - Alyona and a treeLet's fix a vertex v. This node adds +1 to all the ancestors whose depth depth[v] - a[v] ≤ depth[p] (depth[v] = the sum of the weights of edges on the path from the root to the vertex v). It's a segment of the ancestors, ending in v, as the depth increases when moving to the leaves. It remains to find the first ancestor on the way up, it does not hold for him - so you can make a binary lifting or binary search, if you will be storing the path to the root in dfs. With the partial sums you can calculate the answer for each vertices.

739C - Alyona and towersLet's consider the difference between two adjacent elements of array: a[i] = arr[i + 1] - arr[i]. Let us add d in the segment from l to r. Then it is clear that in the array a will change no more than two values ​​(at the ends of the addition of the segment), because if l < i < r, then a[i] = arr[i + 1] + d - (arr[i] + d) = arr[i + 1] - arr[i]. Note that the answer is a sequence of positive elements of a + a sequence of negative elements of a (i.e., ... +1 +1 +1 +1 -1 -1 ..., as the mountain first increases and then decreases). To solve this problem it's enough to take the tree segments and store at each vertex response to the prefix, suffix, and the middle. Two segments [l; m] and [m + 1; r] can be merged in case sign(a[m + 1]) ≤ sign(a[m]) and they are not equal to zero.

suffix  + 1 + 1 + 1 + 1 - 1 - 1 - 1 - 1 и  - 1 - 1 - 1 - 1 can be merged with prefix  - 1 - 1 - 1 - 1

suffix  + 1 + 1 + 1 + 1 can be merged with prefix  - 1 - 1 - 1 - 1 or prefix  + 1 + 1 + 1 + 1 - 1 - 1 - 1 - 1

Author's solution: http://codeforces.com/contest/739/submission/22453451

739D - Recover a functional graphLet's think what has to hold after we put numbers in place of question marks:

number of vertices with precycle = 0 and cycle = y should be divisible by y.if there exists a vertex with precycle = x > 0 and cycle = y, then there should also exist a vertex with precycle = x - 1 and cycle = y.Now looking at vertices without question marks, let's count for every cycle length y how many vertices have to be added for condition 1 to hold (keeping in mind that this number cannot be 0 if there exist vertices of the form (x, y) or (?, y)) and which precycle lengths are missing for condition 2 to hold.

Here it's important that for 2 we have to consider vertices of the form (x, ?). Specifically, in order for everything to be univocally determined, it is necerrary to try all the cycle lengths for the vertex of this form with maximal x. Some contestants tried to assign cycle lengths for such vertices greedily and got WA#15.

Let's build the network for the flow which will have two parts. Vertices of the left part will correspond to the vertices of the functional graph that have at least one question mark. Vertices of the right part are the requirements of the form "need k vertices of the form (0, y)" (for 1 to hold) and "need one vertex of the from (x, y)" (for 2 to hold). Add edges from the source to the left part, form the right part to the sink, and between requirements and vertices that satisfy them. If done correctly, with only one vertex created in the left part for all vertices of the same form in the functional graph, there will be O(n) nodes and O(n) edges in the network and the maximum flow will also be O(n). Edmonds-Karp algorithm, which works in O(E * flow) will work in O(n2) on this network. Accounting for the bruteforce of the cycle length for the maximal vertex of the form (x, ?) we get O(n3) for the whole solution. In practice, any decent algorithm for finding maximum flow would most likely pass the system testing. Dinic works in 15 ms.

If all of the vertices in the right part are saturated - the answer is found. Rolling back the flow, we will find which vertices in the left part saturated which ones in the right part. Now we can change the question marks to numbers for those vertices in the left part, that were used, but some question marks might still remain. This is no big deal. Let's change all vertices of the form (x, ?) to (x, maxc), where maxc is that cycle length we bruteforce in the outermost loop. Instead of vertices of the form (?, y) we can write (1, y). Remember, that we created at least one cycle for all such y's. Instead of (?, ?) simply put (0, 1).

Now it's quite simple to get the answer to the problem. First create cycles out of the vertices of the form (0, y), and then add edges (x, y) -> (x - 1, y).

739E - Gosha is huntingLet's divide Pokemons into 4 types: 0, A, B and AB depending on Balls that we throw to them. Let's sort them by u in descending order. Let's iterate over last Pokemon in which we throw Ultra Ball (his type is B or AB). Let i be the index of this Pokemon. It is not hard to prove that there are no Pokemons to the left of i that have type 0 and all Pokemons to the right of i have type 0 or A. Let's sort all Pokemons to the left of i by (1 - p) * u in descending order. Let's iterate last Pokemon of type AB. Let j be his index. We can prove that to the left of j every Pokemon has type AB or B (Let's call this group of Pokemons X). Between j and i every Pokemon has type A or B (will call them Y). To the right of i only 0 and A (will call them Z). We know that we throw an Ultra Ball to every Pokemon in X. So let's add to our answer sum of u of all Pokemons in X. Number of Pokemons in Y of type B equals to the difference between b (number of Ultra Balls) and size of X. Therefore we know number of Pokemons in Y of type A and we know how many Poke Balls are left for X and Z summarily. Not hard to prove that in group Y we should throw Poke Balls to Pokemons with greatest u - p. Now we have to understand in which Pokemons in X and Z we should throw Poke Balls. If we throw Poke Ball to Pokemon from X, it adds to the answer p * (1 - u), from Z - adds p. So we should throw Poke Balls to Pokemons with greatest values. When we iterate over j, each iteration one Pokemon moves from Y to X. We can keep structure that can add and delete one element, find minimum and keep sum of all elements in the structure. For example, treap or map (in c++). Let's keep 2 such structures: for calculating answer for Y and for calculating answer for throwing Poke Balls to Pokemons in X and Z. The complexity - O(n2·logn).

Technocup 2017 — Elimination Round 2 (and Codeforces Round 380) Editorial

By KAN, history, 6 years ago, translation, In English729A - Interview with OlegIn this problem it is enough to iterate through the given string from the left to the right and find the longest substring like "ogo...go" from each position of the string. If such substring was founded add "***" and move to the end of this substring. In the other case, add current letter to the answer and move to the next position.

729B - SpotlightsLet's find the number of good positions where projector directed to the left. It can be done separately for each row. To make it we need to iterate through the row from the left to the right and store information about we met '{1}', for example, in the variable f. Then if we process the current value:

if it is equal to '0', add one to the answer if f equals to true;if it is equal to '1', then f := true.We can find the answer for the 3 remaining directions in the same way.

729C - Road to CinemaLet's note that there is a value for the fuel tank capacity (call it w), that if the car has the fuel tank capacity equal or more than w it will be able to reach the cinema if time, else — will not be able.

The value w can be found with help of binary search because the function can(w) (it is possible and it has enough time for such cur) is monotonic — in the beginning all values of this function is false, but after some moment the values of this function is always true.

After we found w it remain only to choose the cheapest car from the cars which fuel tank capacity equal or more than w.

The function can(w) can be realized with greedy algorithm. It is easy to write down the formula for find the number of kilometers which we can ride in fast mode if the nearest gas station is on the distance x and we have f liters of fuel in fuel tank:

if x > f, then it is impossible to reach the nearest gas station and can(w) must return false,if x ≤ f, then it is possible to ride in the fast mode min(x, f - x) kilometers.So, now we know how to find the value can(w) in one iterate through the array of gas stations in the increasing order of their positions.

729D - Sea BattleLet's note that in on the field there are b zeroes in a row we must to shoot in at least one of them. We suppose that all ships was pressed to the right. Let's put the number 2 in cells where ships can be placed. Then iterate through the field from the left to the right and shoot in the cell if there is 0 and before it was b - 1 zero in a row. After iteration ended it is left only to shoot in any cell which value equals to 2. All described shoots are the answer for this problem.

729E - SubordinatesAt first if the chief reported that he has one or more superiors let's change as in zero. If there are workers who do not chiefs but reported that they have no superiors let assume that they reported a number which more than the other workers, for example, number n.

It is necessarily that there must be the worker which has exactly one superior. If there is no such worker let's take the worker who reported the maximum number and change this number on 1. Then we need to make the same algorithm for numbers 2, 3, and etc. while there are workers, which have not yet considered.

After we considered all workers the answer is the number of workers which reported numbers were changed.

729F - Financiers GameLet's solve this problem using dynamic programming. We can see that any position in the game can be described with three integers: the left and right bounds of the segment of papers that are still on the table, and the number of papers the previous player took; and who's turn it is. So, let Ilrk be the game result if there were only papers from l to r initially, Igor moved first by taking k or k + 1 papers. Similarly, let Zlrk be the same but Zhenya moved first. It can be easily seen that in general case



We need to carefully proceed the states where a player can't take the needed number of papers. The answer for the problem is I1n1.

At first sight it seems that this solution runs in O(n3). However, it doesn't. What values can l, r and k be equal to?

First,  because if the previous player took k papers then there are at least as  already taken papers. So, k is not greater than .

Second, let's take a look at the difference between number of papers taken by Zhenya and Igor, i. e. at the value d = (n - r) - (l - 1). We consider only cases in which both players made the same number of moves, so now it's Igor's move. Then 0 ≤ d ≤ k - 1. Indeed, on each turn Zhenya took as many papers as Igor did, or one paper more, but in the latter case the "length" of move increased. The length of move increased by k - 1 overall, so the difference is at most k - 1. Thus, we can describe the dynamic programming state with l, d and k, and there are O(n2) states in total. We don't consider states in which it's Zhenya's turn, instead, we try all his possible moves to compute the states. The overall complexity is O(n2). I find it easier to code by the use of recursion and memoization.

737E - Tanya is 5!The problem was invented by the recollections of the recent celebration of the fifth birthday of Tanya Mirzayanova.

At first let's solve this problem in simplified form: let there is no duplicate machines (in the other word it does not enough the budget b to rent any duplicate).

We consider, that each kid would like to play in each machine. Let ti, j = 0 in such case. So, we consider, that the values of t is a rectangular table — for each pair kid/machine in the cell written down the time of the game.

Note that minimal time when all games will ended does not less than sum of values in each row Ri = ti, 1 + ti, 2 + ... + ti, m. Similarly, the minimal time when all games will ended does not less than the sum in each column Cj = t1, j + t2, j + ... + tn, j, because on each machine in one moment of time can play no more than one kid.

Because of that the minimal time does not less than max(R1, R2, ..., Rn, C1, C2, ..., Cm). Note that there is always such a schedule that needed minimal time equals to maximum of all rows sums and all columns sums. Let's call this value T.

Now we need to show this fact and consider the way to get this schedule.

Let's build the weighted bipartite graph. In each part of this graph is n + m vertices.

Let's assume that each machine has a fake kid (i. e. now we have n + m kids) — n real and m fake kids. The vertices from the first part will for kids: u1, u2, ..., un — for real kids and un + 1, un + 2, ..., un + m — for fake kids, and un + j is a fake kid for the machine j.

Similarly, let consider that each kid has a fake machine (totally there will be n machines). The vertices from the second part will for machines: the first m vertices is for real machines (v1, v2, ..., vm), and following n for fakt machines (vm + 1, vm + 2, ..., vm + n). The vertex vm + i will for the fake machine of kid i.

Let's make the edges. We will have 4 types of edges:

between the real kids and the real machines,between the fake kids and the real machines,between the real kids and the fake machines,between the fake kids and the fake machines.We need to make the edges in such a way that the sum of weights of incident edges for each vertex is equals to T.

The edges of type 1. Let's add the edge between ui and vj, if ti, j > 0. the weight is ti, j. This edge means that the kid must play on the machine needed number of minutes.

The edges of type 2. This edges mean that the machine will has downtime equals to some number of minutes (in the other words in downtime the fake kid will play on this machine). For all j from 1 to m let's find a - Cj. If such vertices is positive, then we need to add edge between un + j и vj with such weight.

The edges of type 3. This edges mean that the kid will have time, when he does not play (we consider that in this time the kid play on the fake machine). For all i from 1 to n let's find a - Ri. If this value is positive we add edge between ui and vm + i with such weight.

The edges of type 4. After we added the edges of types 1-3 it is easy to show that the sum of weights of incident edges equal to T. For the vertices un + 1, un + 2, ..., un + m, vm + 1, vm + 2, ..., vm + n this sum now less or equal to T. Let's add remaining edges to make this sums equal to T. It's always possible if we add this edges in greedy way.

We know the following fact: in any regular bipartite graph there is a perfect matching (a consequence of the Hall's theorem).

If we look on the given graph like on the unweighted multigraph where the weight of the edge in our graph equals to the number of edges between the pair of vertices, then the resulting graph will be regular graph and for it will be correct described fact (i. e. there is perfect matching in this graph).

Let's find the perfect matching with help of the Kuhn's algorithm in weighted graph. Let's choose the weight of the minimal edge and it is equals to M. Then let's appoint kids on machines for each edge between the vertices u1, u2, ..., un и v1, v2, ..., vm on the time M. Also let's subtract M from the weight of each edge of the matching. If the weight of the edge became 0, we delete this edge.

After that it is correct the sum for each vertices is a constant. It means that the remaining graph has the perfect matching. We need to make with this graph similar operations, which was described above.

Let's do it until the graph contains at least one edge. So we found needed schedule.

To make the solution faster we can rebuild the matching from the unsaturated vertices from the first part if such vertices exist. This algorithm will works totally in O(e2), where e is the number of edges in the beginning, i. e. e = O(nm), so the asymptotic behavior is O(n2m2). In this problem there were small restricts so we could build the matching with Kuhn's algorithm.

By the way we build the optimal painting of the bipartite graph. Here we can use the well known algorithm (read about the optimal painting of the bipartite graph).

So, we solved the problem without rent the duplicates. Besides it, the value of the answer is a maximum from all sums of rows and columns of the table with times for pairs kid/machine.

If we have a duplicated it equals to adding the column in which we can partially distribute the values from this column. Of course, it is profitably to make it with columns which sum Cj = T (i. e. the answer rests in this column). This operation makes sense only if we make it for all columns with Cj = T simultaneously.

The algorithm to choose of machines to rent follows. Let's find the sum of rent for all machines with Cj = T. If this value less or equal to the budget b than we must rent this machines. Then add the appropriate columns in the table and put as evenly as possible the values of the duplicated columns. Recalculate T. Repeat the process and end it when the sum of rent for each operation became more than b.

737F - Dirty platesAt first we wil try to solve the problem without taking the restrictions placed on a and b into consideration. If we can't solve the new problem, we surely can't solve the original one with the restrictions on a и b.

Let's examine the operations we can and can't do. It's easy to understand that we can't place any plates into the dryer which wouldn't fit the sequence, because they can't be removed from that stack. It is also clear that if we are able to take a sequence of plates from the top of the intermediate stack onto the top of the dryer stack and they would fit the proper sequence in the dryer stack, it can be done immediately. This statement is also right for the top of dirty stack, but it would take two operations for the plates to end up in the drier. Alos, it's easy to notice a situation which makes it impossible to reach the answer: if there is a plate with the size y right above the plate with the size x in the intermediate stack, and y < x - 1. Indeed, no sequence of operations will allow us to insert the «missing» plates in between them. Let's call the state of the stacks a dead-end if this situation happens.

Let's call the operation which moves the plates into the dryer in the right sequence an output. Because the output can be done at any moment, let's check the possibility of the output when we finish performing any operation and perform the output whenever we can. In the following paragraphs, we will examine the situations where the output is impossible.

Let's call the sequence of the plates an almost decreasing sequence if it consists of one or more sections and in every section the sizes of the plates are consecutive natural numbers, and all plates in the following sections are smaller than in the previous ones. To describe it in another way, this is how an almost decreasing sequence looks like: x1, x1 + 1, x1 + 2, ..., y1, x2, x2 + 1, x2 + 2, ..., y2, x3, ..., where x1 > y2, x2 > y3 and so on. Let's examine the maximum almost decreasing sequence on the top of the dirty stack. It's easy to see that before we move all plates from that sequence to the intermediate stack the operation which moves a plate that does not belong to that sequence to the intermediate stack would create a dead-end, because the size of the last plate in this sequence is at least 2 less than the size of the next plate. It's also clear that we can't perform an output before moving all of the sequence into the intermediate stack. This means that the only actions we can perform will lead to all of the plates of this sequence ending up in the intermediate stack, but the question is in the order in which they will be placed. There are two cases possible:

The sizes of the plates in this sequence form an continious segment of the natural number sequence, which means that y2 = x1 - 1, y3 = x2 - 1 and so on. In this situation we can move sections one-by-one onto the intermediate stack to be able to move all of it to the dryer later at once. It's obvious that there wouldn't be a dead-end inside of the sequence. If the dead-end situation happened on a junction with the lower plates in this stack, it would have happened no matter the way we move the sequence. A similiar statement can be said about the junction with the plates that would later appear on the top of this sequence. This means that our way of moving plates is optimal, therefore let's perform it.There are «holes» in the set of plate sizes in the sequence. Then we can notice that if we won't move the sequence to the intermediate stack with one operation, we will arrive at the dead-end if we try to move this sequence with any other set of operations. This can be shown more formally by assuming we moved a part of sequence that was higher than «hole» below it or vice-versa, the part that was below the «hole» above it. In this situation, we have no choice but to move a sequence as a whole.We found an optimal operation for every situation and that means we can solve the problem with a = b = ∞ by modelling an optimal turn by using O(n2) time, or O(n) if we want so. If all plates end up in the dryer, our order of operations is the solution, otherwise there's no solution.

Let's now discuss how to incorporate our solution for a = b = ∞ to our problem with finite a and b. The output from the dirty stack can still be performed by moving plates one-by-one to the intermediate stack and then moving them from the intermediate stack one-by-one. Output from the intermediate stack isn't always possible, and because of this you have to keep an eye on the size of the sections in the intermediate stack. However, if an output exists that is possible to perform, we must perform it, and if it isn't possible, we won't be able to put the plates into the correct order. Due to this we assume that all possible outputs are done. Again we will examine the maximum almost decreasing sequence on the top of the dirty stack and there are again two similiar cases::

If «holes» exist, the only possible operation, as discussed earlier, is to move the whole sequence. If the length of this sequence exceeds a, we have no way to place the plates in the right order at all.If there are no «holes», there are several possibilities. The length of the sections is now important and that means it isn't always optimal to put the plates into the ascending order. Let's consider several cases:If a and b are big enough to be able to do the same operations with it as if they were infinite. Then we need to do it because if any other section would join this one from above or below this would be the only situation that wouldn't be a dead-end. Otherwise we would be able to output this sequence by using a single operation, and because of the fact that its size does not exceed b it would be a possible and optimal operation.In any other situation we have to move this sequence to the intermediate stack in some other way. Let's consider the case where the length of the sequence exceeds b. There are several cases:If the sequence consists of a lone section, we need to move it so the sizes of plates in the section would form a descending sequence in the intermediate stack by moving the plates one-by-one. Indeed, there's no way to make the smallest plate the top one or to make the biggest plate the bottom one (it would allow our sequence to join other blocks) without meeting a dead-end or making a section with its length bigger than b, so it's optimal to make all sections as short as possible (length 1) so we would certainly be able to output them.In the case of the sequence having more than two sections, the only way to move them without creating a dead-end is to move the section as a whole. If it's impossible, there's no solution.The only case left here is the case of the sequence consisting of two sections. There are only two ways to move those sections without meeting a dead-end — we either move the part of the top section and then we move everything else, or we move the first section and the part of the second and then we move the remaining part of the second section. We have to make the length of the parts we move to be no more than a and the length of the resulting sections to be no more than b. It's easy to write the inequalities which describe whether these operations are possible. It's also easy to check that we can't make the smallest plate the top one or to make the biggest plate the bottom one and that means our sections wouldn't join any other sections. Because of this, any sequence of moves which satisfies the inequalities would suit us.Let's now assume that b is large enough to move the whole sequence at once, but a is smaller than the size of a particular section and so we are unable to sort the sequence into the ascending order.If there is only one section, we can just move them one-by-one as discussed earlier.If there are more than two sections, we are unable to move them without meeting a dead-endIf there are two sections, the situation is similiar to the situation where we couldn't perform our operations due to b being too small, although we don't have to limit the length of the section after moving our plates to the intermediate stack (because it would be less than b).As we can see, there's an optimal operation on an every step. The solution is to model the optimal operations. A program that would solve this problem in O(n) time could be written, but the constraints were set which allowed to write the solution which would run in O(n2) time so as not to complicate matters with extra operations.

Tutorial of Codeforces Round #379 (Div. 2)

By gepardo, history, 6 years ago, translation, In EnglishTutorial for the tasks of the contest. If something isn't clear, you can write in comments :)

734A - Anton and DanikLet ka will be amount of characters "A" in the string and kd will be amount of characters "D" in the string. Then, if ka > kd, we print "Anton". If ka < kd, we print "Danik". If ka = kd, we print "Friendship".

Time complexity is .

Code734B - Anton and DigitsWe will act greedily. At first we'll make maximal possible amount of 256 numbers. It will be equal to . From the rest of the digits we'll make maximal possible amount of 32 numbers. It will be equal to  (we use k2 - n256 instead of k2, because n256 twos we've already used to make 256 numbers. Now it's not hard to observe that the answer will be equal to .

Time complexity is .

Code734C - Anton and Making PotionsAt first, observe that if we'll take the i-th potion of the first type and the j-th potion of the second type, then we can prepare all the potions in  seconds. So, we have to minimize this number.

Let's iterate over what potion of the first type we'll use. Then we must find such spell of the second type that will prepare instantly as many as possible potions, and we'll have enough manapoints for it. It can be done using binary search, because the characteristics of potions of the second type — ci and di are sorted in non-decreasing order.

Time complexity is .

Code734D - Anton and ChessLet's observe that the king can attack only pieces that lay in eight directions (up, down, left, right vertically and horizontally, and also up-left, up-right, down-left and down-right diagonally from the cell where the king stands). Also we can observe that from all the pieces that lay in the eight directions, only the nearest one to the king can attack it (the rest of the pieces must "leap" over the nearest one, but it's impossible). So, we'll keep for all the eight directions the nearest piece to the king, and then we'll check if one of the nearest pieces can attack the king (don't forget that bishops can attack only diagonally, rooks — vertically and horizontally, queens — in all the directions).

Time complexity is .

Code734E - Anton and TreeAt first, let's observe that if we unite some two vertices connected by an edge, that are the same color, in one vertex, the answer will not change. Let's do this. Then, for instance, the tree

will look in this way:

We'll also do such tree "compression" after every painting operation. Then, for instance, the tree

will change after paint(2) operation and the tree "compression" in this way:

It's obvious that the tree will be painted in one color if and only if, when after such painting operations with the "compression" only one vertex remains.

Let's call the tree diameter maximal possible shortest path between two vertices of the tree. It's not hard to observe that the tree will be painted in one color if and only if, when the tree diameter becomes equal to 0, because the diameter is 0 only in the tree with one vertex.

Then, we'll see the following fact: the tree diameter can't be decreased more than by two per one painting operation with the "compression". So the answer cannot be less than , where d is the tree diameter.

Now, we'll prove that it's always possible to paint the tree in  operations. Find such vertex that the shortest path from it to any other vertex doesn't exceed . Such vertex can always be found, because otherwise the tree diameter won't be less that d + 1, which is impossible. Now see that if we paint this vertex  times, we will paint the tree in one color.

Time complexity is .

Code734F - Anton and SchoolWe'll prove that . At first, let's prove that it's true when  и . To do it, let's consider all the possible values of a and b:



Here we can see that the equality is true. Now, we'll prove it for any positive integers. To do it, let's divide a and b into bits:





Here ba0, ba1, ... mean the bits of a and bb0, bb1, ... mean the bits of b.

Now, let's divide (a and b) and (a or b) into bits:





Rewrite the initial equality:



Now it's not hard to observe that  is true because the equality  is true for bits. Similarly, we see that  is true and so on.

From all this it follows that the equality  is true.

Let's create an array di where . It's obvious that



See that



from where 

Now it's not hard to find ai: 

Now, we only must check the answer for correctness. It's obvious then, if answer exists, it's alway unique, because it's explicitly derived from the formula above. To check if the answer exists, let's build arrays b and c from the found array a and compare it with the arrays given in the input. We'll do this separately for every bit. Let's calculate kj — amount of numbers in array a that has a one in the j-th bit. Let's denote the j-th bit of ai as Ai, j. Now, let's count Bi, j and Ci, j such as

 

It's not hard to do since we know kj:



See that if we calculate Bi, j и Ci, j, it will be easy to find bi и ci:

 

Time complexity is , where .

Code

Codeforces Round #378 (Div. 2) editorial

By Kniaz, history, 6 years ago, translation, In EnglishI'm sorry for a delay with publishing the editorial.

733A - Grasshopper And the StringIn this problem you have to find the longest sequence of consonants. The answer is its length + 1.

Iterate over each letter of string maintaining cur — current number of consecutive consonants and len — length of longest sequence. If current letter is consonant then increase cur by 1, otherwise update len = max(len, cur) and set cur = 1. Don't forget to update len value after exiting loop (as string can possibly end with consonant).

Time complexity — O(n), n — length of the specified string.

Problem author: MikeMirzayanov.

733B - ParadeLet's calculate L and R values before update moves. Result will be stored in maxk — maximum beauty that can be achieved. So initially maxk = |L - R|.

Now for every columm let's calculate ki - beauty of the parade after switching starting leg of i-th column. ki = |(L - li + ri) - (R - ri + li)|. If ki > maxk then update maxk value and store index i for answer.

If there were no such i that ki > maxk then answer is 0.

Time complexity — O(n).

Problem author: MikeMirzayanov, Kniaz.

733C - Epidemic in MonstropolisThe key observation to solution is to notice that b1 is union (monsters eat one another one by one in such a way that only one is being left) of elements of some prefix of a. And if you remove this prefix and first element of b then this condition will remain true for new arrays a and b.

Answer is "NO" when:

There is no such prefix that has sum of bi.Prefix of sum bi consists of equal elements and its size  > 1.Now let's consider certain prefix. Our goal is to find sequence of moves to get only one monster left.

Here is one of possible solutions:

Find such i that ai is maximum in prefix and either ai - 1 or ai + 1 is strictly less that ai.Eat any of possible neighbors.If only one monster is left then move to next segment.If all weights become equal then print "NO".The only thing left is to carefully calculate real positions of monsters on each step.

Also you can't output them at a moment of calculation as there might be a "NO" answer afterwards.

Time complexity — O(n2).

And challenge: can you optimize it to O(n)?

Problem author: MikeMirzayanov.

733D - Kostya the SculptorRadius of inscribed sphere = min(a, b, c) / 2.

Let's create list of pairwise distinct edges where two edges is condered different when either minimal sides of edges differ or maximal ones.

For every edge (a, b) let's find two maximal lengths of adjacent side c1 and c2. These are two parallelepipeds of maximal volume with one of edges being equal to (a, b). If you glue them together then you will get parallelepiped with sides (a, b, c1 + c2). Also don't forget cases where there is only one maximal side for edge.

There are no more than 3·n edges. So iterating over every parallelepiped with structure map to store maximums works in  where k ≤ 3.

Problem author: MikeMirzayanov, Kniaz.

733E - Sleep in ClassOlga is always able to go beyond stairs. To prove that let's consider some segment of stairs. If we enter it from upper step then we move down until reaching 'U' which reverses our moving direction. After that we leave segment from above. Now this 'U' became 'D' and other symbols remained the same as they were either visited twice or not visited at all. So we enter segment once again from upper step, this time we proceed to next 'U'. And at the some point we leave segment from below. It will happen in ku + 1 turn where ku — number of 'U' symbols in segment. Leaving segment from above when it's entered from below is done in kd + 1 turns, kd - number of 'D' symbols in segment. It can be proven the same way.

Then we can divide stairs into three parts:

Segment below current stepCurrent stepSegment above current stepIt can be easily seen that we will go beyond stairs either from 1st or from 3rd segment.

Now let's calculate values of ku and kd for every step. kui — number of 'U' symbols in prefix of stairs s (exluding si), kdi — number of 'D' symbols in suffix (exluding si).

kui = kui - 1 + int(si =  = 'U')

kdi = kdi + 1 + int(si =  = 'D')

We will also need values of tli and tri, tli - time in seconds to leave stairs from below as if si is always equal to 'D' and tri - time in seconds to leave stairs from above as if si is always equal to 'U'.

It's obvious that by moving iterator by one position to the right we increase distance to every calculated symbol 'U' by 1, so it's  + 2 for each symbol to overall time (we go to this symbol and back to i). If previous symbol was 'U' then we should add 2 more to overall time. In total this will be equal to kui·2. And as we moved one step away from exit we should increase time by 1.

tli = tli - 1 + kui·2 + 1

And it's the same for tri.

tri = tri + 1 + kdi·2 + 1

And finally let's derive formula to get answer in O(1) for each step.

Olga will go beyond stairs from the side which has least amount of obstacles. If amounts are equal then it's the matter of current letter. Let's imply that we are exiting from both sides at the same time and just subtract from time the part from the side opposite to exiting one. So we should subtract tlj or trj (it depends on exiting side), where j is position in string of last visited element of side opposite to exiting one. And also subtract doubled distance between current step and last visited obstacle multiplied by number of unvisited onstacles.

So if we go beyond stairs from below then this is the derived formula:

tli + tri - trposd[kdi - kui - f] - (posd[kdi - f - kui] - i) - 2·(kdi - kui - f)·(posd[kdi - f - kui] - i)

posd — reversed array of indices (positions in string) of 'D' symbol.

kdi - kui - f — number (not position) of last visited element from above. f is 0 if si = 'D', 1 if si = 'U'. (This will be reversed on exiting from above)

Answer for last step is calculated the same way.

For deriving formula for exiting from above you will also need posu — array of indices (positions in string) of 'U' symbol (not reversed this time).

Автор задачи: Kniaz.

733F - Drivers DissatisfactionIf you choose any n - 1 roads then price of reducing overall dissatisfaction is equal to min(c1, c2, ..cn - 1) where сi is price of reducing by 1 dissatisfaction of i-th edge. So the best solution is to choose one edge and reduce dissatisfaction of it until running out of budget.

Let's construct minimal spanning tree using Prim or Kruskal algorithm using edges of weights equal to dissatisfaction and calculate minimal price of reducing dissatisfaction. Time complexity — .

Now we can iterate over edges implying that current is the one to be reduced to minimum. For example, for every edge we can build new MST and recalculate answer. It's . Therefore we should use this fact: it's poinless to reduce dissatisfaction of edges which weren't selected to be main.

Then we can transform original MST instead of constructing m new ones. Add next edge to MST, now it contains a cycle from which edge with maximal dissatisfaction is about to be deleted. This can be achieved in such a way: find LCA of vertices of new edge in  and using binary lifting with precalc in  find the edge to delete.

Time complexity — .

Автор задачи: MikeMirzayanov.

I want to thank Mikhail Piklyaev (awoo) for translation of tutorial!

Codeforces Round #377 (Div. 2) Editorial

By vovuh, history, 6 years ago, translation, In English732A - Buy a ShovelIn this problem we have to find the minimal possible value of x such that k·x mod 10 = 0 or k·x mod 10 = r. It's easy to see that this x always exists and it is not greater than 10 (because k·10 mod 10 = 0). Let's iterate on x, and if its current value satisfies any of the requirements, we print the answer.

Time complexity: O(const), where const = 10.

732B - Cormen --- The Best Friend Of a ManIf we don't make enough walks during days i and i + 1, it's better to make an additional walk on day i + 1 because it also counts as a walk during days i + 1 and i + 2 (and if we walk one more time on day i, it won't help us in the future). So we can start iterating from the second day (1"=indexed). We will add max(0, k - ai - ai - 1) walks to the day i (and to our answer), so Cormen has enough walks during days i and i - 1. After we have iterated through all days, we can print the answer.

Time complexity: O(n).

732C - SanatoriumLet's iterate on the time of day when Vasiliy arrived at the sanatorium (breakfast, dinner or supper) and on the time when Vasiliy left. We sum the changed values of b, d and s (considering that we take all possible meals during the first and the last day) into the variable sum, find mx — the maximum of these three variables (also changed), and if our current answer is more than 3·mx - sum, we update it with this value. After considering all 9 possible scenarios, we print the answer.

Time complexity: O(const), const = 33.

732D - ExamsLet's use binary search to find the answer (the latest day when we have passed all the exams). To check whether we can pass all the exams until some fixed day x, we will take all the examples as late as possible. We will prepare to the earliest exam, then to the second earliest, and so on. If we are not ready for some exam or if we don't pass them until the day x ends, then we can't pass all the exams in time. After finishing our binary search we print the answer.

Time complexity: O(mlogn).

732E - SocketsFirstly, we need to sort both arrays (with computers and with sockets) in non-descending order (also we need to sustain their indices to print the answer). Then we iterate on the value x until it reaches the logarithm of the maximum value in s (or until it reaches 31). For each value of x we iterate on computers in non-descending order, also we maintain the index of the most suitable socket (let's call this index i). If socket number i is already used or if its power is less than current computer's requirement, we increase i. If our current socket's power matches current computer's requirement, then we connect this computer with current socket. Each iteration connects the largest possible number of computers and sockets. After each iteration we install adapters on all non"=used sockets: . After all iterations we print the answer.

Time complexity: O(nlogn + mlogm + (n + m)logA), where A is the maximum power of socket.

732F - Tourist ReformFirstly, we have to find all the bridges and divide the graph into 2"=edge"=connected components. Then we calculate the size of each component. It can be easily proved that the answer is equal to size of the largest component. Then we need to orient the edges somehow. Start DFS from any vertex of the largest component. If we traverse the edge (v, to) (coming from vertex v) and it has not been oriented yet, we orient it from to to v, if it's a bridge (so it leads to the largest component) or from v to to otherwise. When all vertices are visited and all edges are oriented, we can print the answer.

Time complexity: O(n + m).

Codeforces Round #376 (Div. 2) editorial

By Zlobober, 6 years ago, translation, In EnglishI'm sorry for a delay with publishing the editorial.

731A - Night at the MuseumProblem author: egor-belikov, developer: timgaripov

In this problem you have to implement exactly what is written in the statement, i. e. you should find minimum number of rotations from letter a to the first letter in the input, then to the second one and so on. The only useful knowledge that may simplify the solution is that the distance between points x and y on the circle of length l (26 in our case) is min(|x - y|, l - |x - y|).

This solution works in O(|s|), and, of course, fits in time limit.

731B - Coupons and DiscountsProblem author: olympiad jury, developer: platypus179

In a correct answer we may guarantee that for any two consecutive days we use no more than one coupon for bying pizzas in these days. Indeed, if we have two coupons for buying pizzas in days i and i + 1, replace these coupons for two discounts, one for each of the days i and i + 1.

Consider the first day. According to the fact above, we may uniquely find the number of coupons for buying pizzas in 1 and 2 days we are going to use: it's either 0, if there is going to be an even number of pizzas in the first day, or 1 otherwise. The remaining pizzas in the first day will be bought by using discounts. If we use 1 coupon, then we may subtract 1 from the number of pizzas in the second day, and in both cases consider the second day and repeat the same actions.

If at some moment we have the odd number of pizzas and we don't need any pizzas in the following day, then it is impossible to buy all pizzas using only coupons and discounts, and we may output "NO". If it didn't happen, then we were able to buy everything using only coupons and discounts.

Such a solution works in O(n).

Question: Prove that the answer is "YES" if and only if any maximal contiguous segment without zeroes in the input sequence has the even sum.

731C - SocksProblem author: egor-belikov, developer: wilwell

When solving this problem, it is convenient to use graph interpretation of the problem. Consider the graph, whose vertices correspond to the socks and edges connect those socks that Arseniy wears on some day. By the statement, we have to make that any two vertices connected by an edge have the same color. It actually means that any connected component should share the same color.

For each connected component let's find out which color should we choose for it. In order to recolor the minimum possible number of vertices, we should leave the maximum number of vertices with their original color. It means that the optimum color is the color shared by the most number of vertices in this connected component.

So, we have the following solution: consider all connected components, in each component choose the most popular color and add the difference between the component size and the number of vertices of this color. In order to find the most popular color you may, for example, write all colors in an array, sort it and find the longest contiguous segment of colors.

Such a solution works in .

Question: How to implement this solution so that it works in O(n + m)?

731D - 80-th Level ArcheologyProblem author: olympiad jury, developer: Flyrise

Denote as x the number of alphabet cyclic shifts we will perform. Our goal is to formulate the statement of lexicographical order in terms of x.

Note that x may be considered as an integer between 0 and c - 1, i. e., as a residue modulo c. Let's also consider all characters as values between 0 до c - 1 as we may subtract 1 from the value of each character.

Consider two consecutive words in the given list. There are two possibilities corresponding two cases in the definition of lexicographical order:

The first case is when there exists such a position that these words differ in this position and coincide before this position. Suppose that first word has value of a on this position, and second word has the value of b. Then these words will follow in lexicographical order if and only if . It's easy to see that if we consider all residues modulo c as a circle, then this inequality defines an arc of possible x's on this circle. So, this pair of contiguous words produces the following statement "x belongs to some arc on the circle".

The second case is when there is no such a position, i. e. one word is a prefix of another. If the first word is a prefix of second one then these words always follow in lexicographical order irrespective to the choice of x. In the other case (second word is a proper prefix of the first word) we can't do anything with these to words since they will never follow in a lexicographical order, so we should print  - 1.

Now we have to find a point on the circle belonging to the given set of arcs. Suppose we have k arcs. Consider a line segment from 0 to c - 1 instead of a circle; each arc will transform to either one or two its subsegments.

Now we have to find out if there exists a point covered by exactly k segments. It may be done in different ways, for example you may add 1 on each of this segment by using some data structure, or you may add 1 to the left endpoint of each segment and  - 1 to the point after the right endpoint of each segment, and consider prefix sums (an off-line way to handle range addition queries). Or you may write down all endpoints of all segments, sort them by a coordinate and iterate over them from left to right, keeping the number of open segments. If at some moment you have exactly k open segments, then the answer is "YES".

731E - Funny GameProblem author: meshanya, developer: ipavlov

First of all, comment on such type of games. In CS the game where two players are willing to maximize the difference between their own score and the score of their opponent is called a "zero-sum game". A useful knowledge is that problems for such a kind of games are usually solved using dynamic programming.

Note that at any moment the first sticker contains the sum of numbers on some prefix of an original sequence. This means that the state of a game is defined by a single number i: the length of an original sequence prefix that were summed into a single number.

Let's make two observations. First of all, for any state i the turn that current player will perform doesn't depend on scores of both players. Indeed, at any moment we may forget about the scores of both players since they add the constant factor to the resulting score difference, so we may virtually discard both players current scores. So, all we need to know about state i is what difference there will be between the current player score and his opponent score if the game would have started from the state i with zero scores.

Second observation is that the turn chosen by a player from the state i and the final difference of scores at the end does not depend from which player is currently making a turn (Petr or Gennady), i. e. the game is symmetric.

Denote as D[i] the difference between the first player score and the second player score if the game would have started from the state i with zero scores.

It is a convenient way to think about this game as if there were no separate scores of two players, but only a single balance value (difference) between them, and the first player is adding some numbers to the balance at his turn аnd second player subtracts some numbers from the balance. In such formulation D[i] is a balance change at the end of the game if the current player is willing to maximize it and he is currently in the state i. The answer for a problem will be, as one can see, D[1]. Note that if the current player would be willing to minimize balance, then the final balance change from the state i would be  - D[i] because the game is symmetric.

Let's calculate all D[i] using dynamic programming. At the end of the game, i. e. in the state n the value D[n] is equal to zero because the players won't be making any turns, and so the balance won't change.

Consider some state i. Suppose current player will take all the stickers up to the j-th (here j-th means the index in the original sequence). In such case he will change balance by S[j] (where S[j] is the sum of first j numbers in an original sequence), and game will move to the state j. After that his opponent will change the balance by  - D[j] (note that the balance change value is added with an opposite sign since the opponent will be playing from this state).

So, the final balance change when making such a turn will be S[j] - D[j]. In the DP definition we play for a player that is willing to maximize the balance, so .

Such a formula produces a solution in O(n2), but one may find that that it's enough to keep the maximum value of S[j] - D[j] on suffix j > i, recalculating it in O(1) when moving from i to i - 1. So, we have the solution that works in O(n).

Question: Which data type should be used for D[i] (and for the answer, in particular)?

731F - Video CardsProblem author: olympiad jury, developer: vintage_Vlad_Makeev

First observation is that if we fix the leading video card power x, we may take all the video cards of power at least x, as each of them brings the positive power value. So, we may sort all the cards in the ascending power order and then we will always choose some suffix of cards in such an order.

The final total power equals to . Note that under the summation there is a number that is divisible by x and that is no larger than 200 000 at the same time. It means that there are no more than  different terms in this sum. Let's calculate the value of a sum spending the operations proportional to the number of different terms in it.

To do it we need to find out for each of the values x, 2x, 3x, ..., how many video cards will have exactly such power at the end. It's easy: final power kx corresponds to those video cards, which originally had the power between kx and (k + 1)x - 1. Their number can be found out in O(1) if we build an array C[i] storing the number of video cards of each power and calculate prefix sums on it.

It means that we got a solution that performs about  operations. It's useful to know that the sum inside brackets is called a harmonic series, and that its sum is very close to the natural logarithm of the number of terms (up to a constant factor in limit).

It means that we got a solution in complexity of  where m is the maximum power of a single video card.

Question: One may try to submit a solution assuming that the optimum power is always one of the first, let's say, 100 unique video cards in an ascending power order. How to build a test where the optimum power lies between 1/4 and 3/4 of a sorted power list, i. e. a counter-test for such a solution?

Codeforces Round #375 (Div.2) Editorial

By fcspartakm, history, 6 years ago, In English723A - The New Year: Meeting FriendsTo solve this problem you need to understand that friends must meet in the middle point of the given points, so friends who live in the leftmost and in the rightmost points must go to the middle point. Because of that the answer equals to max(x1, x2, x3) - min(x1, x2, x3).

723B - Text Document AnalysisIt is an implementation problem. Let's store in the variable cnt the number of words inside brackets and in the variable maxL — the maximum length of the word outside brackets. You can add the symbol «_» to the end of the given string, to correctly process the last word.

Let's iterate through the given string from the left to the right and store in the variable cur the current word. Also in the variable bal we need to store balance of the open and close brackets.

If the current symbol is letter — add it to the end of the string cur and go to the next symbol of the given string.

If the current symbol is open bracket, make bal = bal + 1. If the current symbol is close bracket, make bal = bal - 1. After that if cur is non-empty string add 1 to cnt if bal equals to 1. Else if bal equals to 0 update maxL with length of the string cur. After that we need to assign cur to the empty string and go to the next symbol of the given string.

723C - Polycarp at the RadioIt is easy to understand that we always can get the maximum value of the minimum of the values bj which equals to n / m. So, we need to make vector can which will store positions of the given array in which we will change values. At first it is all positions of the given array, in which the values are more than m. Then we need to store for all i from 1 to m in vectors posi the positions of the given array, in which the bands equal to i. Then for every vector, which size is more than n / m we need to add tje first sz(posi) - (n / m) elements in the vector can, where sz(posi) is the size of the vector posi.

After that we need to iterate through the numbers of bands from 1 to m. If sz(posi) is less than n / m we need to take regular (n / m) - sz(posi) positions from the vector can and change the values in this positions to i. In the same time we need to count the number of changes in the playlist.

723D - Lakes in BerlandTo solve this problem we need to find all connected components consisting of dots, which do not have common border with ocean. For that we need to implement depth search which returns vector of the points from which the current connected component consists.

Then we need to sort all connected components in order of increasing of their sizes and changes all dots on asterisks in components, beginning from the component with minimum size, until the number of left components does not equals to k.

723E - One-Way ReformLet's solve this problem for each connected component separately.

At first we need to understand fact that in each connected component there are even number of vertices with odd degree. Let in the current connected component there are k vertices with odd degree and they have numbers o1, o2, ..., ok. Then we need to add in graph non-directional edges (o1, o2), (o3, o4), ... (ok - 1, ok). So in the current component now all vertices have even degree and there is exist Euler cycle, which we need to find and orientate all edges in the order of this cycle. It is easy to show that after that for all vertices which had even degree before we added the edges in-degree is equal to out-degree. In the other words, we show that the maximum number of vertices with equal in- and out-degrees in orientated graph equals to the number of vertices with even degree in non-orientated graph.

After we found Euler cycles for all connected components we need to print orientation of the edges and be careful and do not print edges which we added to the graph to connect vertices with odd degrees.

723F - st-Spanning TreeAt first lets delete vertices s and t from the graph, find all connected components in the remaining graph and build for every component any spanning trees.

Now we need to add in spanning tree vertices s and t. At first let add edges from s to all components, which have no edges to t. Then let add edges from t to all components, which have no edges to s.

If after that the degree of s became more than ds or the degree of t became more than dt answer does not exist.

Now we have components which have edges and to s and to t. Also currently we have two spanning trees which does not connect. Let's choose how to connect them — with vertex s, with vertex t or with both of them (only if we have in the graph an edge {s, t}). For each option we need to greedily connect remaining components (if it is possible for current option). If we done it for any option we need only to print the answer.

Codeforces Round #374 (Div. 2) Editorial

By vovuh, 6 years ago, translation, In English721A - One-dimensional Japanese CrosswordIn this problem we have to compute the lengths of all blocks consisting of consecutive black cells. Let's iterate from the left cell of crossword to the end: let i be the number of the cell where we are currently; if s[i] = B, let j = i, and while j < n and s[j] = 'B', we increase j by one. When we come to a white cell or to the end of the crossword, we can compute the length of the block we have just passed (it is equal to j - i, and we need to store this value), and now move to cell j (make i = j). And if we are in a white cell, all we need to do is increase i by one. When i = n, it means that we have gone through the whole crossword, and now we print the answer.

Time complexity — O(n), and memory complexity — O(n).

721B - PasswordsThe author suggests a solution with formulas: let's count two variables — cntl (the number of passwords that are shorter than Vanya's Codehorses password) and cntle (the number of passwords that are not longer than Vanya's Codehorses password). Then it's easy to see that in the best case answer will be equal to , and in the worst case it will be .

Time complexity of solution — O(n), memory complexity — O(n).

721C - JourneyAuthor's solution uses dynamic programming. Let dpi, j be the minimum time required to arrive at the vertex i, if we visit j vertices (including vertices 1 and i). We have a DAG (directed acyclic graph), so we can compute it recursively (and memory constraints were a bit strict in this problem, so it's better to use recursion to compute it). Let's store the transposed version of the graph: if we had an edge (u, v) in the input, we will store (v, u). Then our function calc(i, j), which will compute the answer for dpi, j, will be like that: the base of dynamic programming is dp1, 1 = 0, all other states are equal to «-1». If we call calc(i, j), then it will work like that: if the state we want to compute is incorrect (j < 0), we return a very large integer number (any number that is greater than 109, because T ≤ 109). If the answer for this state has already been calculated, then we return dpi, j (it is easy do determine: if dpi, j ≠  - 1, then it has already been calculated). Else we begin to calculate the state. Firstly, let's put INF (a number greater than 109) into dpi, j. Then look at all the edges beginning in i and try to update dpi, j with the value of calc(to, j - 1) + w (to is the vertex at the endpoint of current edge, w is the weight of this edge). If this value is less than dpi, j, then we update dpi, j and store the information that our last update in dpi, j was from the vertex to. If we try to go by path which doesn't end in the vertex 1, then we get a value which is greater than 109, that's because that the only value we didn't denote as  - 1 is dp1, 1. So, now we have our calc function, let's compute the answer. We will iterate on the number of vertices in the path from n to 1 in descending order, and if calc(n, i) ≤ T, then we have found the answer, now we iterate on the parent vertices we stored while calculating our dp, until we come to vertex 1 (it's important because some participants sent solutions that continued even past vertex 1!) and print the answer.

Time complexity of this solution — O((n + m)n), and mempry complexity — O(nm).

721D - Maxim and ArrayMain idea: we act greedily, trying to make the best possible answer every action (each time we choose an action with minimum possible product after it).

Detailed explanation:

While we have zeroes in our array, we have to get rid of them, changing each of them exactly one time. Also we keep the quantity of negative numbers — we need it to make the product negative after changing the last zero. Let m be the number of zeroes in the array. If m > k, then we cannot make the product negative or positive (it will always be equal to 0), so any sequence of operations will lead to a correct answer. However, if m ≤ k, then we are able to come to negative product (if the number of negative elements was even, then we subtract x from one zero and add it to all other zeroes; if the number of negative elements was odd, then we can just add x to all zeroes).If current product is still positive, then we want to change the sign of exactly one element. Its absolute value has to be minimal: suppose we have two elements a and b, |a| < |b|; let's prove that if we change b's sign, then our answer is wrong. Let m be the minimum number of operations required to change b's sign. If we perform m operations with b, then the absolute value of a won't change, and absolute value of b will become x·m - |b|. If, on the other hand, we perform m operations with a (this may not be optimal, but now we need to prove that if we change b, then the result will be worse), then the absolute value of a will become x·m - |a|, the absolute value of b won't change. The product becomes negative, so we need to maximize the product of absolute values. And then x·m - |a| > x·m - |b| and |b| > |a|, so if we change b, then the product of absolute values will be less than if we change a.Now, until we have performed k operations, we choose a number with minimum absolute value and enlarge it (add x if this number if positive, subtract if negative). Let's prove that the answer will be optimal. Suppose that this algorithm chooses a on some iteration, but we can't get optimal answer if we change a. This means that we can't change a after this iteration at all (we can reorder our operations in an arbitrary way, and the answer won't change). Suppose we have to change b instead, and |b| > |a|. Let's consider the sequence of operations leading to the optimal answer when we choose b, and replace change of b with change of a, and let the product of all remaining numbers (the whole array excluding a and b after all operations) be c. If we change a, the total product will be  - (|a| + x)·(|b| + x·m)·|c|, and if we change b, we get  - |a|·(|b| + x·(m + 1))·|c| (m is the number of times we change b). Now |a| < |b| + x·m, so (|a| + x)·(|b| + x·m) - |a|·(|b| + x·(m + 1)) = |b| + x·m - |a| > 0, so the absolute value of total product will be greater if we change a. This proves that we won't come to unoptimal answer if we change a.Time complexity:  if we use a data structure similar to set or priority_queue to get the number with minimal absolute value. Memory complexity: O(n).

721E - Road to HomeFirstly, if we are in some segment and we are going to sing in it, we want to sing as much as possible in this segment. So there are two cases for each segment: either we sing in the segment while we can or we just skip it.

Now we consider two different cases:

1) p ≤ 100

If we have stopped singing in the segment, then the distance we need to walk to reach the end of this segment is strictly less than p. Let's calculate two values — dpleft[i] — the answer (how many times we can sing a song) if we start from the beginning of segment number i (from li), and dpright[i][j] — the answer if we start from ri - j (0 ≤ j < p, as we already said before). To calculate the value using the value from point x, we have to find the segment which contains the point x + t and the segment which begins after this point. If we are in segment number k, we either skip it and update next segment (dpleft[k + 1]), or start singing and update the value in the point y where we stop singing (dpright[k][y]).

To find the segment containing point x + t, we can use binary search or precalculate the required indices using iterations on the array of segments.

Time complexity:  or O(np).

2) p > 100

Let's use the fact that the answer is not greater than . For each value i we calculate lfi - the leftmost point where we can get it. We will iterate on those values considering that we have already calculated lfj for every j < i when we start calculating lfi. Then if lfi is before the beginning of some segment, and lfi + 1 is after its beginning, then we can try singing starting from the beginning of this segment with i performed songs currently, updating lf for next values (from i + 1 till  with the values rk - (rk - lk) mod p). Using this fact we update the value for the largest answer, skipping the points in the middle of the segment. To calculate these values we need a data structure (for example, Fenwick tree) which sustains the minimum value on the suffix (lfi is the minimum on suffix beginning from element number i). All lf values are increasing, so we need only one variable to sustain the index of the segment we are using to update.

How we have to consider the points in the middle of some segment. So we have a variable storing the index of the rightmost segment which begins before lfi for current answer i. It may seem that the values from the beginning and from the middle of some segment may be used in the wrong order, but it's easy to prove that it's not true.

Copmplexity: . We can use a special updating structure based on stack to get rid of Fenwick tree, then complexity will be .

Codeforces Round #373 — Editorial

By _XuMuk_, 6 years ago, translation, In EnglishSpecial thanks to Seyaua for help with translation.

Div. 2 A — Vitya in the CountrysideIdea: _XuMuk_.Preparation: _XuMuk_.

There are four cases that should be carefully considered:

an = 15   —  the answer is always DOWN.

an = 0   —  the answer is always UP.

If n = 1   —  the answer is -1.

If n > 1, then if an–1 > an   —  answer is DOWN, else UP.

Time Complexity: .

Div. 2 B — Anatoly and CockroachesIdea: _XuMuk_.Preparation: _XuMuk_.

We can notice that there are only two possible final coloring of cockroaches that satisfy the problem statement: rbrbrb... or brbrbr...

Let’s go through both of these variants.

In the each case let's count the number of red and black cockroaches which are not standing in their places. Let's denote these numbers as x and y. Then it is obvious that the min(x, y) pairs of cockroaches need to be swapped and the rest should be repaint.

In other words, the result for a fixed final coloring is exactly min(x, y) + max(x, y) - min(x, y) = max(x, y). The final answer for the problem is the minimum between the answers for the first and the second colorings.

Time Complexity: .

Div. 1 A — Efim and Strange GradeIdea: BigBag.Preparation: BigBag.

One can notice that the closer to the decimal point we round our grade the bigger grade we get. Based on this observation we can easily solve the problem with dynamic programming.

Let dpi be the minimum time required to get a carry to the (i - 1)-th position.

Let's denote our grade as a, and let ai be the (i)-th digit of the a. There are three cases:

If ai ≥ 5, then dpi = 1.

If ai < 4, then dpi = inf (it means, that we cann't get a carry to the (i - 1)-th position).

If ai = 4, then dpi = 1 + dpi + 1.

After computing dp, we need to find the minimum pos such that dppos ≤ t. So, after that we know the position where we should round our grade.

Now we only need to carefully add 1 to the number formed by the prefix that contains pos elements of the original grade.

Time Complexity: .

Div. 1 B — Alyona and CopiersIdea: _XuMuk_.Preparation: BigBag.

Deleted

div. 1 C — Sasha and ArrayIdea: BigBag.Preparation: BigBag.

Let's denote 

Let's recall how we can quickly find n-th Fibonacci number. To do this we need to find a matrix product .

In order to solve our problem let's create the following segments tree: in each leaf which corresponds to the element i we will store a vector  and in all other nodes we will store the sums of all the vectors that correspond to a given segment.

Now, to perform the first request we should multiply all the vectors in a segment [l..r] by  and to get an answer to the second request we have to find a sum in a segment [l..r].

Time Complexity: .

Div. 1 D — Andrew and ChemistryIdea: _XuMuk_.Preparation: BigBag.

Let’s first figure out how we can solve the problem in  time.

Let’s pick a vertex we’re going to add an edge to and make this vertex the root of the tree. For each vertex vi we’re going to assign a label a[vi] (some number). The way we assign labels is the following: if the two given vertices have the same subtrees they’re going to get the same labels, but if the subtrees are different then the labels for these vertices are going to be different as well.

We can do such labeling in a following way: let’s create a map<vector<int>, int> m (the maximum degree for a vertex is 4, but let’s assume that the length of the vector is always equal to 4). Let m[{x, y, z, w}] be a label for a vertex which has children with the labels x, y, z, w. Let’s note that the vector {x, y, z, w} should be sorted to avoid duplications, also if the number of children is less than 4 then we’ll store  - 1’s for the missing children (to make the length of a vector always equal to 4). Let’s understand how we can compute the value for the label for the vertex v. Let’s recursively compute the labels for its children: v1, v2, v3, v4.Now, if m.count({a[v1], a[v2], a[v3], a[v4]}) then we use the corresponding value. Otherwise, we use the first unused number: m[{a[v1], a[v2], a[v3], a[v4]}]=cnt++.

Now, let’s pick another vertex which we’re going to add an edge to. Again, let’s make it the root of the tree and set the labels without zeroing out our counter cnt. Now, let’s do the same operation for all the other possible roots (vertices, n times). Now, one can see that if the two roots have the same labels, then the trees which can be obtained by adding an edge to these roots, are exactly the same. Thus, we only need to count the amount of roots with different labels. Also, we should keep in mind that if a degree for a vertex is already 4 it’s impossible to add an edge to it.

The solution described above has the time complexity , because we consider n rooted trees and in the each tree we iterate through all the vertices (n), but each label update takes .

Let’s speed up this solution to .

Let b be an array where b[vi] is a label in a vertex vi if we make this vertex the root of the tree. Then the answer to the problem is the number of different numbers in the array b. Let’s root the tree in a vertex root and compute the values a[vi]. Then b[root] = a[root] and all the other values for b[vi] we can get by pushing the information from the top of the tree to the bottom.

Time complexity: .

Div. 1 E — Matvey's BirthdayIdea: BigBag.Preparation: BigBag, GlebsHP.

Let’s prove that the distance between any two vertices is no more than MaxDist = 2·sigma - 1, where sigma is the size of the alphabet. Let’s consider one of the shortest paths from the position i to the position j. One can see that in this path each letter ch occurs no more than two times (otherwise you could have skipped the third occurrence by jumping from the first occurrence to the last which gives us a shorter path). Thus, the total amount of letters in the path is no more than 2·sigma which means that the length of the path is no more than 2·sigma - 1.

Let disti, c be the distance from the position i to some position j where sj = c. These numbers can be obtained from simulating bfs for each letter c. We can simulate bfs in O(n·sigma2) (let’s leave this as an exercise to the reader).

Let dist(i, j) be the distance between positions i and j. Let’s figure out how we can find dist(i, j) using precomputed values disti, c.

There are two different cases:

The optimal path goes through the edges of the first type only. In this case the distance is equal to .

The optimal path has at least one edge of the second type. We can assume that it was a jump between two letters c. Then, in this case the distance is disti, c + 1 + distc, j.

Adding these two cases up we get: .

Let’s iterate over the possible values for the first position i = 1..n. Let’s compute the distance for all such j, where  by the above formula.

Now, for a given i we have to find max(dist(i, j)) for . In this case dist(i, j) = min(disti, c + 1 + distc, j).

Let’s compute one additional number distc1, c2  —  the minimal distance between positions i and j where si = c1 and sj = c2. This can be easily done using disti, c.

One can notice that distsj, c ≤ distj, c ≤ distsj, c + 1. It means that for every position j we can compute a mask maskj with sigma bits where i-th bit is equal to distj, c - distsj, c. Thus, we can compute the distance using only sj and maskj.I.e. now distj, c = distsj, c + maskj, c.

Let cnt be an array where cntc, mask is the number of such j where , sj = c and maskj = mask. Now, instead of iterating over j for a given i we can iterate over (c, mask) and if cntc, mask ≠ 0 we’ll be updating the answer.

Time complexity: .

Codeforces Round #372 Editorial

By zscoder, history, 6 years ago, In EnglishWe hope everyone enjoyed the problems. Here is the editorial for the problems. I tried to make it more detailed but there might be some parts that might not be explained clearly.

Div. 2 A — Crazy ComputerPrerequisites : None

This is a straightforward implementation problem. Iterate through the times in order, keeping track of when is the last time a word is typed, keeping a counter for the number of words appearing on the screen. Increment the counter by 1 whenever you process a new time. Whenever the difference between the time for two consecutive words is greater than c, reset the counter to 0. After that, increment it by 1.

Time Complexity : O(n), since the times are already sorted.

Code (O(n))Div. 2 B — Complete The WordPrerequisites : None

Firstly, if the length of the string is less than 26, output  - 1 immediately.

We want to make a substring of length 26 have all the letters of the alphabet. Thus, the simplest way is to iterate through all substrings of length 26 (there are O(n) such substrings), then for each substring count the number of occurrences of each alphabet, ignoring the question marks. After that, if there exist a letter that occurs twice or more, this substring cannot contain all letters of the alphabet, and we process the next substring. Otherwise, we can fill in the question marks with the letters that have not appeared in the substring and obtain a substring of length 26 which contains all letters of the alphabet. After iterating through all substrings, either there is no solution, or we already created a nice substring. If the former case appears, output  - 1. Otherwise, fill in the remaining question marks with random letters and output the string.

Note that one can optimize the solution above by noting that we don't need to iterate through all 26 letters of each substring we consider, but we can iterate through the substrings from left to right and when we move to the next substring, remove the front letter of the current substring and add the last letter of the next substring. This optimization is not required to pass.

We can still optimize it further and make the complexity purely O(|s|). We use the same trick as above, when we move to the next substring, we remove the previous letter and add the new letter. We store a frequency array counting how many times each letter appear in the current substring. Additionally, store a counter which we will use to detect whether the current substring can contain all the letters of the alphabet in O(1). When a letter first appear in the frequency array, increment the counter by 1. If a letter disappears (is removed) in the frequency array, decrement the counter by 1. When we add a new question mark, increment the counter by 1. When we remove a question mark, decrement the counter by 1. To check whether a substring can work, we just have to check whether the counter is equal to 26. This solution works in O(|s|).

Time Complexity : O(|s|·262), O(|s|·26) or O(|s|)

Code (O(26^2*|s|)Code (O(26*|s|)Code (O(|s|)Div. 2 C/Div. 1 A — Plus and Square RootPrerequisites : None

Firstly, let ai(1 ≤ i ≤ n) be the number on the screen before we level up from level i to i + 1. Thus, we require all the ais to be perfect square and additionally to reach the next ai via pressing the plus button, we require  and  for all 1 ≤ i < n. Additionally, we also require ai to be a multiple of i. Thus, we just need to construct a sequence of such integers so that the output numbers does not exceed the limit 1018.

There are many ways to do this. The third sample actually gave a large hint on my approach. If you were to find the values of ai from the second sample, you'll realize that it is equal to 4, 36, 144, 400. You can try to find the pattern from here. My approach is to use ai = [i(i + 1)]2. Clearly, it is a perfect square for all 1 ≤ i ≤ n and when n = 100000, the output values can be checked to be less than 1018

Unable to parse markup [type=CF_TEX]

which is a multiple of i + 1, and  is also a multiple of i + 1.The constraints ai must be a multiple of i was added to make the problem easier for Div. 1 A.

Time Complexity : O(n)

Code (O(n))Div. 2 D/Div. 1 B — Complete The GraphPrerequisites : Dijkstra's Algorithm

This problem is actually quite simple if you rule out the impossible conditions. Call the edges that does not have fixed weight variable edges. First, we'll determine when a solution exists.

Firstly, we ignore the variable edges. Now, find the length of the shortest path from s to e. If this length is  < L, there is no solution, since even if we replace the 0 weights with any positive weight the shortest path will never exceed this shortest path. Thus, if the length of this shortest path is  < L, there is no solution. (If no path exists we treat the length as ∞.)

Next, we replace the edges with 0 weight with weight 1. Clearly, among all the possible graphs you can generate by replacing the weights, this graph will give the minimum possible shortest path from s to e, since increasing any weight will not decrease the length of the shortest path. Thus, if the shortest path of this graph is  > L, there is no solution, since the shortest path will always be  > L. If no path exists we treat the length as ∞.

Other than these two conditions, there will always be a way to assign the weights so that the shortest path from s to e is exactly L! How do we prove this? First, consider all paths from s to e that has at least one 0 weight edge, as changing weights won't affect the other paths. Now, we repeat this algorithm. Initially, assign all the weights as 1. Then, sort the paths in increasing order of length. If the length of the shortest path is equal to L, we're done. Otherwise, increase the weight of one of the variable edges on the shortest path by 1. Note that this will increase the lengths of some of the paths by 1. It is not hard to see that by repeating these operations the shortest path will eventually have length L, so an assignment indeed exists.

Now, we still have to find a valid assignment of weights. We can use a similar algorithm as our proof above. Assign 1 to all variable edges first. Next, we first find and keep track of the shortest path from s to e. Note that if this path has no variable edges it must have length exactly L or strictly more than L, so either we're already done or the shortest path contains variable edges and the length is strictly less than L. (otherwise we're done)

From now on, whenever we assign weight to a variable edge (after assigning 1 to every variable edge), we call the edge assigned.

Now, mark all variable edges not on the shortest path we found as ∞ weight. (we can choose any number greater than L as ∞) Next, we will find the shortest path from s to e, and replace the weight of an unassigned variable edge such that the length of the path becomes equal to L. Now, we don't touch the assigned edges again. While the shortest path from s to e is still strictly less than L, we repeat the process and replace a variable edge that is not assigned such that the path length is equal to L. Note that this is always possible, since otherwise this would've been the shortest path in one of the previous steps. Eventually, the shortest path from s to e will have length exactly L. It is easy to see that we can repeat this process at most n times because we are only replacing the edges which are on the initial shortest path we found and there are less than n edges to replace (we only touch each edge at most once). Thus, we can find a solution after less than n iterations. So, the complexity becomes . This is sufficient to pass all tests.

What if the constraints were n, m ≤ 105? Can we do better?

Yes! Thanks to HellKitsune who found this solution during testing. First, we rule out the impossible conditions like we did above. Then, we assign all the variable edges with ∞ weight. We enumerate the variable edges arbitarily. Now, we binary search to find the minimal value p such that if we make all the variable edges numbered from 1 to p have weight 1 and the rest ∞, then the shortest path from s to e has length  ≤ L. Now, note that if we change the weight of p to ∞ the length of shortest path will be more than L. (if p equals the number of variable edges, the length of the shortest path is still more than L or it will contradict the impossible conditions) If the weight is 1, the length of the shortest path is  ≤ L. So, if we increase the weight of edge p by 1 repeatedly, the length of the shortest path from s to e will eventually reach L, since this length can increase by at most 1 in each move. So, since the length of shortest path is non-decreasing when we increase the weight of this edge, we can binary search for the correct weight. This gives an  solution.

Time Complexity :  or 

Code (O(mnlogn))Code (O(mlogn(logm+logL))Div. 2 E/Div. 1 C — Digit TreePrerequisites : Tree DP, Centroid Decomposition, Math

Compared to the other problems, this one is more standard. The trick is to first solve the problem if we have a fixed vertex r as root and we want to find the number of paths passing through r that works. This can be done with a simple tree dp. For each node u, compute the number obtained when going from r down to u and the number obtained when going from u up to r, where each number is taken modulo M. This can be done with a simple dfs. To calculate the down value, just multiply the value of the parent node by 10 and add the value on the edge to it. To calculate the up value, we also need to calculate the height of the node. (i.e. the distance from u to r) Then, if we let h be the height of u, d be the digit on the edge connecting u to its parent and val be the up value of the parent of u, then the up value for u is equal to 10h - 1·d + val. Thus, we can calculate the up and down value for each node with a single dfs.

Next, we have to figure out how to combine the up values and down values to find the number of paths passing through r that are divisible by M. For this, note that each path is the concatenation of a path from u to r and r to v, where u and v are pairs of vertices from different subtrees, and the paths that start from r and end at r. For the paths that start and end at r the answer can be easily calculated with the up and down values (just iterate through all nodes as the other endpoint). For the other paths, we iterate through all possible v, and find the number of vertices u such that going from u to v will give a multiple of M. Since v is fixed, we know its height and down value, which we denote as h and d respectively. So, if the up value of u is equal to up, then up·10h + d must be a multiple of M. So, we can solve for up to be  - d·10 - h modulo M. Note that in this case the multiplicative inverse of 10 modulo M is well-defined, as we have the condition . To find the multiplicative inverse of 10, we can find φ(M) and since by Euler's Formula we have xφ(M) ≡ 1(modM) if , we have xφ(M) - 1 ≡ x - 1(modM), which is the multiplicative inverse of x (in this case we have x = 10) modulo M. After that, finding the up value can be done by binary exponentiation.

Thus, we can find the unique value of up such that the path from u to v is a multiple of M. This means that we can just use a map to store the up values of all nodes and also the up values for each subtree. Then, to find the number of viable nodes u, find the required value of up and subtract the number of suitable nodes that are in the same subtree as v from the total number of suitable nodes. Thus, for each node v, we can find the number of suitable nodes u in  time.

Now, we have to generalize this for the whole tree. We can use centroid decomposition. We pick the centroid as the root r and find the number of paths passing through r as above. Then, the other paths won't pass through r, so we can remove r and split the tree into more subtrees, and recursively solve for each subtree as well. Since each subtree is at most half the size of the original tree, and the time taken to solve the problem where the path must pass through the root for a single tree takes time proportional to the size of the tree, this solution works in  time, where the other  comes from using maps.

Time Complexity : 

CodeDiv. 1 D — Create a MazePrerequisites : None

The solution to this problem is quite simple, if you get the idea. Thanks to danilka.pro for improving the solution to the current constraints which is much harder than my original proposal.

Note that to calculate the difficulty of a given maze, we can just use dp. We write on each square (room) the number of ways to get from the starting square to it, and the number written on (i, j) will be the sum of the numbers written on (i - 1, j) and (i, j - 1), and the edge between (i - 1, j) and (i, j) is blocked, we don't add the number written on (i - 1, j) and similarly for (i, j - 1). We'll call the rooms squares and the doors as edges. We'll call locking doors as edge deletions.

First, we look at several attempts that do not work.

Write t in its binary representation. To solve the problem, we just need to know how to construct a maze with difficulty 2x and x + 1 from a given maze with difficulty x. The most direct way to get from x to 2x is to increase both dimensions of the maze by 1. Let's say the bottom right square of the grid was (n, n) and increased to (n + 1, n + 1). So, the number x is written at (n, n). Then, we can block off the edge to the left of (n + 1, n) and above (n, n + 1). This will make the numbers in these two squares equal to x, so the number in square (n + 1, n + 1) would be 2x, as desired. To create x + 1 from x, we can increase both dimensions by 1, remove edges such that (n + 1, n) contains x while (n, n + 1) contains 1 (this requires deleting most of the edges joining the n-th column and (n + 1)-th column. Thus, the number in (n, n) would be x + 1. This would've used way too many edge deletions and the size of the grid would be too large. This was the original proposal.

There's another way to do it with binary representation. We construct a grid with difficulty 2x and 2x + 1 from a grid with difficulty x. The key idea is to make use of surrounding 1s and maintaining it with some walls so that 2x + 1 can be easily constructed. This method is shown in the picture below. This method would've used around 120 × 120 grid and 480 edge deletions, which is too large to pass.

 

Now, what follows is the AC solution. Since it's quite easy once you get the idea, I recommend you to try again after reading the hint. To read the full solution, click on the spoiler tag.

Hint : Binary can't work since there can be up to 60 binary digits for t and our grid size can be at most 50. In our binary solution we used a 2 × 2 grid to multiply the number of ways by 2. What about using other grid sizes instead?

Full SolutionOf course, this might not be the only way to solve this problem. Can you come up with other ways of solving this or reducing the constraints even further? (Open Question)

Time Complexity : 

CodeDiv. 1 E — Complete The PermutationsPrerequisites : Math, Graph Theory, DP, Any fast multiplication algorithm

We'll slowly unwind the problem and reduce it to something easier to count. First, we need to determine a way to tell when the distance between p and q is exactly k. This is a classic problem but I'll include it here for completeness.

Let f denote the inverse permutation of q. So, the minimum number of swaps to transform p into q is the minimum number of swaps to transform pfi into the identity permutation. Construct the graph where the edges are  for all 1 ≤ i ≤ n. Now, note that the graph is equivalent to  and is composed of disjoint cycles after qi and pi are filled completely. Note that the direction of the edges doesn't matter so we consider the edges to be  for all 1 ≤ i ≤ n. Note that if the number of cycles of the graph is t, then the minimum number of swaps needed to transform p into q would be n - t. (Each swap can break one cycle into two) This means we just need to find the number of ways to fill in the empty spaces such that the number of cycles is exactly i for all 1 ≤ i ≤ n.

Now, some of the values pi and qi are known. The edges can be classified into four types :

A-type : The edges of the form , i.e. pi is known, qi isn't.

B-type : The edges of the form , i.e. qi is known, pi isn't.

C-type : The edges of the form , i.e. both pi and qi are known.

D-type : The edges of the form , i.e. both pi and qi are unknown.

Now, the problem reduces to finding the number of ways to assign values to the question marks such that the number of cycles of the graph is exactly i for all 1 ≤ i ≤ n. First, we'll simplify the graph slightly. While there exists a number x appears twice (clearly it can't appear more than twice) among the edges, we will combine the edges with x together to simplify the graph. If there's an edge , then we increment the total number of cycles by 1 and remove this edge from the graph. If there is an edge  and , where a and b might be some given numbers or question marks, then we can merge them together to form the edge . Clearly, these are the only cases for x to appear twice. Hence, after doing all the reductions, we're reduced to edges where each known number appears at most once, i.e. all the known numbers are distinct. We'll do this step in O(n2). For each number x, store the position i such that pi = x and also the position j such that qj = x, if it has already been given and  - 1 otherwise. So, we need to remove a number when the i and j stored are both positive. We iterate through the numbers from 1 to n. If we need to remove a number, we go to the two positions where it occur and replace the two edges with the new merged one. Then, recompute the positions for all numbers (takes O(n) time). So, for each number, we used O(n) time. (to remove naively and update positions) Thus, the whole complexity for this part is O(n2). (It is possible to do it in O(n) with a simple dfs as well. Basically almost any correct way of doing this part that is at most O(n3) works, since the constraints for n is low)

Now, suppose there are m edges left and p known numbers remain. Note that in the end when we form the graph we might join edges of the form  and  (where a and b are either fixed numbers or question marks) together. So, the choice for the ? can be any of the m - p remaining unused numbers. Note that there will be always m - p such pairs so we need to multiply our answer by (m - p)! in the end. Also, note that the ? are distinguishable, and order is important when filling in the blanks.

So, we can actually reduce the problem to the following : Given integers a, b, c, d denoting the number of A-type, B-type, C-type, D-type edges respectively. Find the number of ways to create k cycles using them, for all 1 ≤ k ≤ n. Note that the answer is only dependent on the values of a, b, c, d as the numbers are all distinct after the reduction.

First, we'll look at how to solve the problem for k = 1. We need to fit all the edges in a single cycle. First, we investigate what happens when d = 0. Note that we cannot have a B-type and C-type edge before an A-type or C-type edge, since all numbers are distinct so these edges can't be joined together. Similarly, an A or C-type edge cannot be directly after a B or C-type edge. Thus, with these restrictions, it is easy to see that the cycle must contain either all A-type edges or B-type edges. So, the answer can be easily calculated. It is also important to note that if we ignore the cyclic property then a contiguous string of edges without D must be of the form AA...BB.. or AA...CBB..., where there is only one C, and zero or more As and Bs.

Now, if d ≥ 1, we can fix one of the D-type edges as the front of the cycle. This helps a lot because now we can ignore the cyclic properties. (we can place anything at the end of the cycle because D-type edges can connect with any type of edges) So, we just need to find the number of ways to make a length n - 1 string with a As, b Bs, c Cs and d - 1 Ds. In fact, we can ignore the fact that the A-type edges, B-type edges, C-type edges and D-type edges are distinguishable and after that multiply the answer by a!b!c!(d - 1)!.

We can easily find the number of valid strings we can make. First, place all the Ds. Now, we're trying to insert the As, Bs and Cs into the d empty spaces between, after and before the Ds. The key is that by our observation above, we only care about how many As, Bs and Cs we insert in each space since after that the way to put that in is uniquely determined. So, to place the As and Bs, we can use the balls in urns formula to find that the number of ways to place the As is  and the number of ways to place the Bs is . The number of ways to place the Cs is , since we choose where the Cs should go.

Thus, it turns out that we can find the answer in O(1) (with precomputing binomial coefficients and factorials) when k = 1. We'll use this to find the answer for all k. In the general case, there might be cycles that consists entirely of As and entirely of Bs, and those that contains at least one D. We call them the A-cycle, B-cycle and D-cycles respectively.

Now, we precompute f(n, k), the number of ways to form k cycles using n distinguishable As. This can be done with a simple dp in O(n3). We iterate through the number of As we're using for the first cycle. Then, suppose we use m As. The number of ways to choose which of the m As to use is  and we can permute them in (m - 1)! ways inside the cycle. (not m! because we have to account for all the cyclic permutations) Also, after summing this for all m, we have to divide the answer by k, to account for overcounting the candidates for the first cycle (the order of the k cycles are not important)

Thus, f(n, k) can be computed in O(n3). First, we see how to compute the answer for a single k. Fix x, y, e, f, the number of A-cycles, B-cycles, number of As in total among the A-cycles and number of Bs in total among the B-cycles. Then, since k is fixed, we know that the number of D-cycles is k - x - y. Now, we can find the answer in O(1). First, we can use the values of f(e, x), f(f, y), f(d, k - x - y) to determine the number of ways to place the Ds, and the As, Bs that are in the A-cycles and B-cycles. Then, to place the remaining As, Bs and Cs, we can use the same method as we did for k = 1 in O(1), since the number of spaces to place them is still the same. (You can think of it as each D leaves an empty space to place As, Bs and Cs to the right of it) After that, we multiply the answer by  to account for the choice of the set of As and Bs used in the A-only and B-only cycles. Thus, the complexity of this method is O(n4) for each k and O(n5) in total, which is clearly too slow.

We can improve this by iterating through all x + y, e, f instead. So, for this to work we need to precompute f(e, 0)f(f, x + y) + f(e, 1)f(f, x + y - 1) + ... + f(e, x + y)f(f, 0), which we can write as g(x + y, e, f). Naively doing this precomputation gives O(n4). Then, we can calculate the answer by iterating through all x + y, e, f and thus getting O(n3) per query and O(n4) for all k. This is still too slow to pass n = 250.

We should take a closer look of what we're actually calculating. Note that for a fixed pair e, f, the values of g(x + y, e, f) can be calculated for all possible x + y in  or O(n1.58) by using Number Theoretic Transform or Karatsuba's Algorithm respectively. (note that the modulus has been chosen for NFT to work) This is because if we fix e, f, then we're precisely finding the coefficients of the polynomial (f(e, 0)x0 + f(e, 1)x1 + ... + f(e, n)xn)(f(f, 0)x0 + f(f, 1)x1 + ... + f(f, n)xn), so this can be handled with NFT/Karatsuba.

Thus, the precomputation of g(x + y, e, f) can be done in  or O(n3.58).

Next, suppose we fixed e and f. We will calculate the answer for all possible k in  similar to how we calculated g(x + y, e, f). This time, we're multiplying the following two polynomials : f(d, 0)x0 + f(d, 1)x1 + ... + f(d, n)xn and g(0, e, f)x0 + g(1, e, f)x1 + ... + g(n, e, f)xn. Again, we can calculate this using any fast multiplication method, so the entire solution takes  or O(n3.58), depending on which algorithm is used to multiply polynomials.

Note that if you're using NFT/FFT, there is a small trick that can save some time. When we precompute the values of g(x + y, e, f), we don't need to do inverse FFT on the result and leave it in the FFTed form. After that, when we want to find the convolution of f(d, i) and g(i, e, f), we just need to apply FFT to the first polynomial and multiply them. This reduces the number of FFTs and it reduced my solution runtime by half.

Time Complexity :  or O(n3.58), depending on whether NFT or Karatsuba is used.

Code (NFT)Code (Karatsuba)

Codeforces Round #371 Editorial

By Sonechko, 6 years ago, translation, In EnglishWe want to say thanks to Sereja for the translation.

714A - Meeting of Old FriendsLets find two numbers l and r — lower and upper bound on time which guys can spend together. l =  max(l1, l2), r =  min(r1,r2). If l > r then answer is definitely 0. In case l ≤ r we need to number k belongs to the interval. If is it true — answer is r - l, otherwise it is r - l + 1.

714B - Filya and HomeworkAnswer can be calculated according to next options:

1). If all numbers are equal — answer is «Yes»

2). If there are two distinct numbers in the array — answer is «Yes»

3). If there are at least four distinct numbers in the array — answer is «No»

4). In other case lets there are three distinct numbers q < w < e, answer is «Yes» if and only if 2 * w = q + e.

713A - Sonya and QueriesLets exchange every digit by value of digit modulo 2 and receive binary string. We will convert it to binary form in number r. G — array for counts. If we have '+' query we increase G[r]. If we have '-' query we decrease G[r]. Otherwise we output G[r].

713B - Searching RectanglesAssume we have just one rectangle. First we can find its right side. In binary search we check is out rectangle to the left of some line x2 using function get(1,1,x2,n). As soon as we found right coordinate we can 'cut' everything to the right of the line, because there is nothing to look. In the same way we will find all sides.

O(12 * logN):

Main idea is to find a line which will split space in the way that rectangles will lie in different parts, as rectangles are not intersected it is always possible.

We can assume that intersected line is parallel to y coordinate and use binary search by x. On each step of search we will count amount of rectangles on each side. If we have pair (1, 1) then line is found. If we have pair (0, 0) then intersected line is parallel to x coordinate. Otherwise we should search in the half where we have some rectangles.

In worst case we will have 2 searches each will take 2 * log(n) time, also we have 4 * log(n) time to find separated rectangle. In total we 2 * 2 * log(n) + 2 * 4 * log(n) = 12 * log(n).

O(8 * logN):

We can find first rectangle assuming that here is just one rectangle. In each of four of our search we will assume that rectangle is present if get will return 1 or 2.

When we have one rectangle we can search second assuming that we can modify get function to get2, which will assume coordinates of first rectangle and decrease original value if it is required.

713C - Sonya and Problem Wihtout a LegendLets first solve easier problem. Given an array of number what it is minimal amount of operations ( + 1 to element,  - 1 to element) to make all numbers in array equal? We need to solve this problem for each prefix. Optimal solution would be making all numbers equal to median value of the prefix (middle element in sorted list). For this problem we can simply use two heaps and insert element in right one (removing elements from inserted if need) to keep heaps equal and fit the constraint max_value(Heap1)  ≤  min_value(Heap2).

Now lets solve harder problem. What is minimal amount of operations ( + 1 to element,  - 1 to element) to make array be arithmetics progression with step 1? We can just reduce number ai in array by value i and will receive previous problem.

Finally we have original problem. Dpi — answer for prefix ending in i, i.e. number of operations to make prefix of first i elements in increasing order. Also for each i will remember minimal last number in resulting sequence. For each i will bruteforce value j (i > j) and calculate answer for j if [i + 1, j] if arithmetics progression with step 1. Also we need to assume if median value in [i + 1, j] is lower than minimal value at i than we cannot update answer for j by answer for i.

713D - Animals and PuzzleFirst lets calculate dp[i][j] — maximum square ending in cell (i, j). For each cell if input matrix contain 0 then dp[i][j] = 0 else dp[i][j] = min(dp[i - 1][j - 1], dp[i−1][j], dp[i][j−1]) + 1.

We will use binary search to find the answer. Lets fix some value x. For each square (i, j)..(i + x - 1, j + x - 1) we need to find maximum and compare it to x. To find maximum we can use 2D sparse table.

So preprocessing takes O(NMlogNlogM), and query works in O(logN).

713E - Sonya PartymakerWill use binary search to find the answer. Assume that we need to know if it is enough x minutes to visit each vertex. Lets dp[i][0...1] is equal to minimum number of vertices to the left of i, which wasn't visited yet, second parameter is equal to 1, if we have't launched robot from vertex i. I.e. when dp[i][j] > 0 vertices [i−dp[i][j], i−1] haven't been visited, and if dp[i][j] < 0 then dp[i][j] vertices to the right we still can visit. We need to calculate such DP for two starting states (dp[0][0] = 0, dp[0][1] = 0). Now we need to implement next:

• if 0 < dp[i][1] ≤ x then distance can be walked and we need to update dp[i][0] by 0

• if dp[i][1] ≤ 0 then we can update dp[i][0] by −x

• using dp[i][0], update dp[i + 1][1]

• using dp[i][1], update dp[i + 1][0]

Walk in time x is also possible if dp[n][0..1 (depending on start state)]  ≤ 0. Need to assume few other facts:

if dp[n][j] ≠ 0 then we can repeat DP with param dp[0][j] = dp[n][j], and if, dp[n][j] ≤ dp[0][j], then distance can be walked

To assume every case we need to calculate this DP for each pair of sequent vertices

Codeforces Round #370 Editorial

By send_nodes, history, 6 years ago, In EnglishHi everyone, here are the solutions to the contest problems.

712A — Memory and Crow

Note that a[i] + a[i + 1] = b[i]. Use the initial condition b[n] = a[n] and we can figure out the entire array b.

Time Complexity: O(n)

Code712B — Memory and Trident

First, if S has odd length, there is no possible string because letters must come in opposite pairs. Now, let's denote the ending coordinate after following S as (x, y). Since S has even length, |x| has the same parity as |y|. Suppose they are both even. Then clearly, we can make x = 0 in exactly  moves, and same for y. If instead they are both odd, then we can change exactly one x-character into a y-character. With the correct choices of these characters, now our string has |x| and |y| with even parity, thus reducing to the problem above. Therefore, the answer is (|x| + |y|) / 2.

Time Complexity: O(|S|)

Code712C — Memory and De-Evolution

Let's reverse the process: start with an equilateral triangle with side length y, and lets get to an equilateral triangle with side length x. In each step, we can act greedily while obeying the triangle inequality. This will give us our desired answer.

Time Complexity: O(log x)

Code712D — Memory and Scores

One approach to this problem is by first implementing naive DP in O((kt)2). The state for this is (diff, turn), and transitions for (diff, turn) is the sum (diff - 2k, turn - 1) + 2(diff - 2k + 1, turn - 1) + 3(diff - 2k + 2, turn - 1) + ... + (2k + 1)(diff, turn - 1) + 2k(diff + 1, turn - 1) + ...  + diff( + 2k, turn - 1).

Now, if we use prefix sums of all differences in (turn-1), along with a sliding window technique across the differences, we can cut a factor of k, to achieve desired complexity O(kt2).

However, there is a much nicer solution in O(kt log kt) using generating functions(thanks to minimario). We can compute the coefficients of , and the coefficient to xi corresponds to the number of ways we can form the difference i. To compute these coefficients, we can use the binomial theorem.

Time Complexity: O(kt2)

CodeTime Complexity: O(kt log kt)

Code712E — Memory and Casinos

Lets think about two segments of casinos [i, j] and [j + 1, n]. Let L([a, b]) denote the probability we dominate on [a, b], and let R([a, b]) denote the probability we start on b and end by moving right of b. Let

l1 = L([i, j]),

l2 = L([j + 1, n]),

r1 = R([i, j]),

r2 = R([j + 1, n]).

You can use a geometric series to figure out both L([i, n]) and R([i, n]) using only l1,l2,r1, and r2. To derive these series, think about the probability we cross over from j to j + 1 once, twice, three times, and so on. The actual formulas are,





Now we can build a segment tree on the casinos, and use the above to merge segments.

Time Complexity: O(N + QlogN)

Code

Codeforces Round #369 Editorial

By zscoder, history, 7 years ago, In EnglishHere are the editorials for all the problems. Hope you enjoyed them and found them interesting!

711A - Bus to UdaylandFor each row, check whether there exists two consecutive Os. Once you find a pair of consecutive Os, you can replace them with +s and output the bus. If no such pair exists, output NO.

Time Complexity : O(n)

Code711B - Chris and Magic SquareFirstly, when n = 1, output any positive integer in the range will work. Otherwise, we calculate the sum of the values in each row, column and the two long diagonals, and also keep track which row and column the empty square is in and also which diagonals it lies on. Finally, we can use the sums to determine the value of the empty square or that it is impossible to make the square magic. Keep in mind that the blank must be filled with a positive integer, so 0 doesn't work. Also, remember to use 64-bit integers to store the sums or it will overflow. (and will fail on the overflow test)

Time Complexity : O(n2)

Code711C - Coloring TreesWe compute the following array : dp[i][j][k] denoting the minimum amount of paint needed to color the first i trees such that it has beauty j and the i-th tree is colored by color k, and initialize all these values to ∞. We can compute this dp array easily by considering two cases :

1. When the last color used is equal to the current color, then we should compare it with dp[i - 1][j][k] + cost[i][k] if it was originally uncolored or dp[i - 1][j][k] otherwise, since the beauty of the coloring is the same.

2. When the last color used is different from the current color, then we should compare it with dp[i - 1][j - 1][l] + cost[i][k] or dp[i - 1][j - 1][l] for all 1 ≤ l ≤ m except when l is equal to the current color, by similar reasoning.

If the current tree is uncolored, we loop through all the m possible colors to color it.

Naively implementing this dp will give an O(nkm2), which is sufficient to pass for this problem. However, it is possible to optimize it into O(nkm) by avoiding iterating through all colors when considering the last color used and store two global minimums. See the code for more the details.

Time Complexity : O(nkm2) or O(nkm)

Code (O(nkm^2))Code (O(nkm))711D - Directed RoadsWe want to find the number of ways to assign directions to the edges of the graph so that it is acyclic, i.e. contains no cycles. First, we investigate what the graph looks like. It can be easily seen that the graph consists of several connected components, where each component is either a path or a cycle with some paths connected to some of the vertices. We'll solve the problem for each component and multiply the result for each component. If the component is a path, then however we orient the edges we won't form a cycle. So, if there are x edges in the component, there are 2x ways to orient the edges. Next, if the component has a cycle, then we can orient the remaining edges in any way (it will not affect the existence of cycles), then for the x edges on the cycle, we have 2x - 2 ways to orient them. This is because there are a total of 2x ways to orient the edges, but only 2 ways gives a directed cycle. (fix the direction of one of the edges, then the directions of the other edges are uniquely determined to form a directed cycle) Thus, if there are t edges not on the cycle and x edges on the cycle, the total number of ways for this component is 2t(2x - 2). Finally, to compute the final answer we multiply the answers for each component. Computing the powers of 2 can be done by a simple precomputation or using binary exponentiation. (the former works because the number of vertices is small) Finding the cycles can be easily done with a dfs.

Time Complexity : O(n)

Code711E - ZS and The Birthday ParadoxNote that MOD = 106 + 3 is a prime.

Firstly, if we have k > 2n, then by pigeonhole principle we must have 2 people with the same birthday. Thus, we can directly output 1 1.

Thus, now we suppose k ≤ 2n. Then, instead of computing the probability directly, we compute the complement, i.e. the probability that all the people have distinct birthdays. This probability turns out to be much simpler to calculate, as it is just . (Fix the birthday of the first person, the probability that the second person has different birthday is , and for the next person it's  and so on.

Now, we know that the denominator is just a power of 2. However, we still have to reduce the fraction to the lowest terms. Note that  is in the lowest terms if and only if  is in the lowest terms, since . Also, note that the gcd is a power of 2 since the denominator is a power of 2. Thus, we need to find the highest power of 2 that divides (2n - 1)(2n - 2)...(2n - (k - 1)). This is also equal to the sum of the highest power of 2 that divides 2n - 1, 2n - 2, ..., 2n - (k - 1).

Now, if a power of 2 divides x < 2n, then it must also divides 2n - x and vice versa. So, we can actually translate this to finding the sum of highest power of 2 that divides 1, 2, ..., k - 1, or the highest power of 2 that divides (k - 1)!. Now, this is simple to calculate by Legendre's formula (which is quite easy to prove) in .

Now that we find the gcd of the numerator and denominator, we can immediately find the reduced denominator by binary exponentiation. For the numerator, we need a bit more work, since we have to deal with (2n - 1)(2n - 2)...(2n - (k - 1)). However, it is not hard either. The key fact is that MOD is small, so if k - 1 ≥ MOD, the product above is equal to 0 modulo MOD, because among MOD consecutive integers there must be one that is a multiple of MOD. Thus, the above product can be calculated in O(MOD) if k - 1 ≤ MOD and O(1) otherwise. The remaining parts can be calculated using direct binary exponentiation.

One minor note is that when we're calculating 2(k - 1)n, the value of (k - 1)n might overflow. One way to resolve this is to reduce it modulo MOD - 1, since 2MOD - 1 ≡ 1 modulo MOD by Fermat's Little Theorem. Another way is to just evaluate 2k - 1 first, then take the result and raise it to the n-th power.

Time Complexity : 

Code

Codeforces Round #368 (Div.2) разбор

By zloyplace35, 7 years ago, translation, In EnglishThanks all participants. I hope, you liked problems.

A — Brain's photos

We need to do exactly what is written in the task: to consider all of the characters, and, if there is at least one of the set {C, M, Y} print "#Color" else — "#Black&White"

B — Bakery

Note that it makes no sense to choose the city for bakeries and the city with the warehouse so that had more than one way between them, as every road increases the distance over which you have to pay.

So, the problem reduces to the following: select two neighboring cities so that one is a warehouse, and in the other & mdash; no. For doing this, simply iterate through all the city with the warehouse, among the neighbors of each town without looking for a warehouse and update the answer. If there is such a pair of cities, print -1.

C — Pythagorean triples

D — Persistence bookcase

Solution №1:

Note that the data is delivered all at once (offline). Then we can build a tree of versions, then run out of the DFS root and honestly handle each request in the transition from the top to the top.

Solution №2:

Note that Alina uses operations that relate to the columns. We can make an array of versions of the shelves, and each version of the cabinet to provide an array of indices and the corresponding shelves to store it explicitly. Then, for the operation, such as changing wardrobe, shelves, a new version which has been changed, this version of the index is recorded on the same shelf position. This approach eliminates the decision on the use of extra memory for storing unnecessary information.

E — Garlands

Let us handle each request as follows:

Let's go for a "frame" request and remember lamp garlands, which lies on the boundary. Then, in order to find concrete garland, what part of it lies within the query, sum all of its segments, the ends of it are lamps that lie on the "frame".

Also, do not forget the garland wich lies entirely within the request. Each garland at the beginning we find the extreme points, and to check whether it lies entirely within the query, check whether the lie inside its extreme points.

Codeforces Round #367 (Editorial)

By NBAH, history, 7 years ago, translation, In EnglishAWe know that time=distance/speed. For each car we should find timei, than if it is less than answer we should update it.

Time Complexity: O(n).

Solution

BConsider c[x] the number of stores in which the price per drink is x. We calculate this array prefix sum. Then the following options:

1) If the current amount of money m is larger than the size of the array with the prefix sums than answer is n.

2) Otherwise, the answer is c[m].

Time Complexity: O(n+q).

Solution

CWe will solve the problem with the help of dynamic programming. dp[i][j] is the minimum amount of energy that should be spent to make first i strings sorted in lexicographical order and i-th of them will be reversed if j = 1 and not reversed if j = 0. dp[i][j] is updated by dp[i - 1][0] and dp[i - 1][1]. It remains to verify that the i-th string is lexicographically greater than (i - 1)-th (if j = 1 then we should check reversed i-th string, similar to (i - 1)-th). Then we update dp[i][j] = min(dp[i][j], dp[i - 1][0] + c[i] * j), dp[i][j] = min(dp[i][j], dp[i - 1][1] + j * c[i]). The answer is a minimum of dp[n][0] and dp[n][1].

Time Complexity: O(n+sum_length).

Solution

DLet's store each number in binary system (each number consists of 32 bits, 0 or 1) in such a data structure as trie.The edges will be the bits 1 and 0, and the vertices will be responsible for whether it is possible to pass the current edge. To reply to a query like "? X" will descend the forest of high-order bits to whether the younger and now we can look XOR in the i-th bit to get one, if we can, then move on, otherwise we go to where we can go.

Time Complexity: O(q*log(10^9)).

Solution

ELet's surround the matrix with the frame of elements. In each element of the matrix, and frame we need to store value, the number of the right element and the number of down element. When a request comes we should change only values of the elements along the perimeter of rectangles.

Time Complexity: O(q*(n+m)).

Solution

Codeforces Round #366 (Editorial)

By PrinceOfPersia, history, 7 years ago, In EnglishHere are the solutions to all problems.

Div.2 AJust alternatively print "I hate that" and "I love that", and in the last level change "that" to "it".

 

Time Complexity: 

Div.2 BFirst of all, instead of cycles, imagine we have bamboos (paths). A valid move in the game is now taking a path and deleting an edge from it (to form two new paths). So, every player in his move can delete an edge in the graph (with components equal to paths). So, no matter how they play, winner is always determined by the parity of number of edges (because it decreases by 1 each time). Second player wins if and only if the number of edges is even. At first it's even (0). In a query that adds a cycle (bamboo) with an odd number of vertices, parity and so winner won't change. When a bamboo with even number of vertices (and so odd number of edges) is added, parity and so the winner will change.

 

Time Complexity: 

AConsider a queue e for every application and also a queue Q for the notification bar. When an event of the first type happens, increase the number of unread notifications by 1 and push pair (i, x) to Q where i is the index of this event among events of the first type, and also push number i to queue e[x].

When a second type event happens, mark all numbers in queue e[x] and clear this queue (also decreese the number of unread notifications by the number of elements in this queue before clearing).

 

When a third type query happens, do the following:

while Q is not empty and Q.front().first <= t:	i = Q.front().first	x = Q.front().second	Q.pop()	if mark[i] is false:		mark[i] = true		e[v].pop()		ans = ans - 1 // it always contains the number of unread notificationsBut in C++ set works much faster than queue!

Time Complexity: 

BReduction to TSP is easy. We need the shortest Hamiltonian path from s to e. Consider the optimal answer. Its graph is a directed path. Consider the induced graph on first i chairs. In this subgraph, there are some components. Each components forms a directed path. Among these paths, there are 3 types of paths:

In the future (in chairs in right side of i), we can add vertex to both its beginning and its end.In the future (in chairs in right side of i), we can add vertex to its beginning but not its end (because its end is vertex e).In the future (in chairs in right side of i), we cannot add vertex to its beginning (because its beginning is vertex s) but we can add to its end. 

There are at most 1 paths of types 2 and 3 (note that a path with beginning s and ending e can only exist when all chairs are in the subgraph. i.e. induced subgraph on all vertices).

This gives us a dp approach: dp[i][j][k][l] is the answer for when in induced subgraph on the first i vertices there are j components of type 1, k of type 2 and l of type 3. Please note that it contains some informations more than just the answer. For example we count d[i] or  - x[i] when we add i to the dp, not j (in the problem statement, when i < j). Updating it requires considering all four ways of incoming and outgoing edges to the last vertex i (4 ways, because each edge has 2 ways, left or right). You may think its code will be hard, but definitely easier than code of B.

Time Complexity: 

CBuild a graph. Assume a vertex for each clause. For every variable that appears twice in the clauses, add an edge between clauses it appears in (variables that appear once are corner cases). Every vertex in this graph has degree at most two. So, every component is either a cycle or a path. We want to solve the problem for a path component. Every edge either appear the same in its endpoints or appears differently. Denote a dp to count the answer. dp[i][j] is the number of ways to value the edges till i - th vertex in the path so that the last clause(i's) value is j so far (j is either 0 or 1). Using the last edge to update dp[i][j] from dp[i - 1] is really easy in theory.

 

Counting the answer for a cycle is practically the same, just that we also need another dimension in our dp for the value of the first clause (then we convert it into a path). Handling variables that appear once (edges with one endpoint, this endpoint is always an endpoint of a path component) is also hard coding. And finally we need to merge the answers.

Time Complexity: 

DAssume r < b (if not, just swap the colors). Build a bipartite graph where every vertical line is a vertex in part X and every horizontal line is a vertex in part Y. Now every point(shield) is an edge (between the corresponding vertical and horizontal lines it lies on). We write 1 on an edge if we want to color it in red and 0 if in blue (there may be more than one edge between two vertices). Each constraint says the difference between 0 and 1 edges connected to a certain vertex should be less than or equal to some value. For every vertex, only the constraint with smallest value matters (if there's no constraint on this vertex, we'll add one with di = number of edges connected to i).

Consider vertex i. Assume there are qi edges connected to it and the constraint with smallest d on this vertex has dj = ei. Assume ri will be the number of red (with number 1 written on) edges connected to it at the end. With some algebra, you get that the constraint is fulfilled if and only if . Denote  and . So Li ≤ ri ≤ Ri. This gives us a L-R max-flow approach: aside these vertices, add a source S and a sink T. For every vertex v in part X, add an edge with minimum and maximum capacity Lv and Rv from S to v. For every vertex u in part Y, add an edge with minimum and maximum capacity Lu and Ru from u to T. And finally for every edge v - u from X to Y add an edge from v to u with capacity 1 (minimum capacity is 0).

 

If there's no feasible flow in this network, answer is -1. Otherwise since r ≤ b, we want to maximize the number of red points, that is, maximizing total flow from S to T.

Since the edges in one layer (from X to Y) have unit capacities, Dinic's algorithm works in  (Karzanov's theorem) and because  and  Dinic's algorithm works in .

Time Complexity: 

EFirst, we're gonna solve the problem for when the given tree is a bamboo (path). For simplifying, assume vertices are numbered from left to right with 1, 2, .., n (it's an array). There are some events (appearing and vanishing). Sort these events in chronological order. At first (time  - ∞) no suit is there. Consider a moment of time t. In time t, consider all available suits sorted in order of their positions. This gives us a vector f(t).

 

Lemma 1: If i and j are gonna be at the same location (and explode), there's a t such that i and j are both present in f(t) and in f(t) they're neighbours.

This is obvious since if at the moment before they explode there's another suit between them, i or j and that suit will explode (and i and j won't get to the same location).

Lemma 2: If i and j are present in f(t) and in time t, i has position less than j, then there's no time e > t such that in it i has position greater than j.

This hold because they move continuously and the moment they wanna pass by each other they explode.

So this gives us an approach: After sorting the events, process them one by one. consider ans is the best answer we've got so far (earliest explosion, initially ∞). Consider there's a set se that contains the current available suits at any time, compared by they positions (so comparing function for this set would be a little complicated, because we always want to compare the suits in the current time, i.e. the time when the current event happens). If at any moment of time, time of event to be processed is greater than or equal to ans, we break the loop. When processing events:

First of all, because current event's time is less than current ans, elements in se are still in increasing order of their position due to lemma 2 (because if two elements were gonna switch places, they would explode before this event and ans would be equal to their explosion time). There are two types of events:

Suit i appears. After updating the current moment of time (so se's comparing function can use it), we insert i into se. Then we check i with its two neighbours in se to update ans (check when i and its neighbours are gonna share the same position).

Suit i vanishes. After updating the current moment of time, we erase i from se and check its two previous neighbours (which are now neighbours to each other) and update ans by their explosion time.

This algorithm will always find the first explosion due to lemma 1 (because the suits that're gonna explode first are gonna be neighbours at some point).

This algorithm only works for bamboos. For the original problem, we'll use heavy-light decompositions. At first, we decompose the path of a suit into heavy-light sub-chains (like l sub-chains) and we replace this suit by l suits, each moving only within a subchain. Now, we solve the problem for each chain (which is a bamboo, and we know how to solve the problem for a bamboo). After replacing each suit, we'll get  suits because  and we need an extra log for sorting events and using set, so the total time complexity is .

In implementation to avoid double and floating point bugs, we can use a pair of integers (real numbers).

Time Complexity (more precisely): 

Codeforces Round #365 (Div. 2) Editorial

By Eran, 7 years ago, translation, In English703A — Mishka and GameIn this problem you had to do use the following algo. If Mishka wins Chris in the current round, then increase variable countM by 1. Otherwise (if Chris wins Mishka) increase variable countC. After that you had to compare this values and print the answer.

703B — Mishka and tripLet's look at the first capital. Note that the total cost of the outgoing roads is c[id1] · (sum - c[id1]), where sum — summary beauty of all cities. Thus iterating through the capitals we can count the summary cost of roads between capitals and all the other cities. But don't forget that in this case we count the roads between pairs of capitals twice. To avoid this on each step we should update sum = sum - c[idcur] , where idcur is the position of current capital. In the end we should add to the answer the cost of roads between "non-capital" neighbour cities.

Complexity — O(n).

703C — Chris and RoadImagine that the bus stands still and we move "to the right" with a constant speed v. Then it's not hard to see that movement along the line y = (u / v) · (x  -  v · t0) is optimal, where t0 — time in which we begin our movement. In this way answer is t = t0 + (w / u).

If t0 = 0, then we start our movement immediately. In this case we need to check that our line doesn't intersect polygon (either we can cross the road in front of a bus, or the bus is gone).

Otherwise we need to find such minimal t0 that our line is tangent to the polygon. It can be done with binary search.

Complexity — O(n log n).

Exercise: Solve this problem in O(n).

703D — Mishka and Interesting sumEasy to see, that the answer for query is XOR-sum of all elements in the segment xored with XOR-sum of distinct elements in the segment. XOR-sum of all numbers we can find in O(1) using partial sums. As for the XOR-sum of distinct numbers... Let's solve easier problem.

Let the queries be like "find the number of distinct values in a segment". Let's sort all the queries according to their right bounds and iterate through all elements of our array. We also need to make a list last, where last[value] is the last position of value on the processed prefix of array. Assume we are at position r. Then the answer for the query in the segment [l,  r] (l ≤ r) is , where cnt[i] = 1 if last[ai] = i and 0 otherwise. It's easy to store and update such values in cnt. When moving to the next position we have to make the following assignments: cnt[last[ai]] = 0, cnt[i] = 1, last[ai] = i. To get described sum in O(log n) we can use segment tree (or Fenwick tree) instead of standard array.

Now let's turn back to our problem. Everything we have to do is to change assignment cnt[i] = 1 to cnt[i] = ai and count XOR-sum instead of sum. Now we can solve this problem in O(n log n).

Solution (with Fenwick)

P.S.: Also there is a solution with O(n sqrt n) complexity (using Mo's algo), but we tried to kill it :D

703E — Мишка и делителиLet's use dp to solve this problem.

Suppose dp[i][d] is the minimal number of elements on prefix of size i, that their product is divisible by d. It's easy to see that dp[i][d] = min(dp[i  -  1][d],  dp[i  -  1][d  /  gcd(d,  ai)]  +  1). That is so because it's optimal to take as much divisors of ai as possible. Answer — dp[n][k].

Let's imrove our solution. Notice, that as d we should use only divisors of k (which in the worst case would be 6720). As for gcd, we can easily find it in O(primes(k)), where primes(k) — number of primes in decomposition of k. We also need to renumber our divisors according to their prime decomposition.

To get AC in this problem you had to optimize described dp and add minimization of used elements' sum. Final complexity — O(n · divs(k) · primes(k)).

Solution

informal EDITORIAL for Codeforces Round #364 (Div. 2)

By -skyline-, history, 7 years ago, In EnglishCodeforces Round #364 (Div. 2)

There is still no formal EDITORIAL for Codeforces Round #364 (Div. 2) yet ,so I write a informal one.

Sorry for my poor English and poor format.

701A - Cards

You can calculate the sum (x) of a pair of cards.

x=2*(a1+a2+...+an)/n

For every card ai,find a card ak which ai+ak=x and k is not used.

The n is small,so you can simplely write a o(n*n) solution(also there is a o(n) one,o(n*n) is enough).

My o(n*n) solution:19328905

701B - Cells Not Under Attack

You can just record the number of rows and columns that is not under attack.

If r rows and c columns is not under attack there is r*c cells that is not under attack.

It's o(m).

My o(m) solution:19330540

701C - They Are Everywhere

You can just use two pointers

There are x types of Pokemon

if [i,dp[i]-1] has x-1 types of Pokemon and [i,dp[i]] has x types of Pokemon

dp[i+1]>=dp[i]

so it's o(n)

my o(xlogx+n) solution:19332828

701D - As Fast As Possible

It's a math problem.

let d=ceil(n/k)

Just look at the bus.

it goes like that:

_>>>>>>>>>>>>

____<<<<<<<<<

____>>>>>>>>>>>>

_______<<<<<<<<<

_______>>>>>>>>>>>>

__________<<<<<<<<<

__________>>>>>>>>>>>>

The '_' means empty(I cannot format it).

The long lengths are the same(x) and goes to right.

The short lengths are the same(y) and goes to left.

It goes to right and put the old students down and does to left and welcome new students.

so x+y:x-y=v2:v1

it goes for d xs and (d-1) ys

so:

1:d*x-(d-1)*y=l

2:x+y:x-y=v2:v1

3:ans=(d*x+(d-1)*y)/v2

so ans=l/v2*((d*2-1)*v2+v1)/(v2+(d*2-1)*v1)

It's o(1).

my o(1) solution:19334768

701E - Connecting Universities

Let's take 1 as the root of the tree.

Record the depth of every vertex(depth of 1 is 0).

Record the number of schools of the subtree of every vertex.

The sum of the depth of the lca of every pair of school should as small as possible.

Consider 2x schools of the subtree of vertex y(may be 2x is not the number of all the schools of the subtree of vertex y)

every depth of lca of the 2x schools is at least the depth of y .

If a subtree of the son of y has k schools in the 2x schools(not in all the schools).

1:if the k of every son is always mink<=x

you can match the schools to make every lca y

2:if for son z,mink>x

match (2x-mink) schools of the subtree of z with the schools not in the subtree of z but in the subtree of y

just look at z like look at y

so,it's o(n)

my o(n) solution:19344918

701F - Break Up

First,find a way from s to t.

If there is no such way,the answer is 0.

If there is such way,try to stop every edge on it and try to find bridges and upuate the answer.

How to find a bridge?

DFS it with root s,record the depth of every vertex and the least depth it can reach without passing its father.

If the least depth x can reach without passing x's father > the depth of y then (x,y) is a bridge.

Try to stop edges o(n),and finding bridges o(m).

It's o(nm).

My o(nm) solution:19462368

Other solutions are welcomed.

If you find any mistakes,tell me.

UPD1:solution to problem F

Codeforces Round #363 problems analysis

By GlebsHP, history, 7 years ago, In EnglishNew problems will be added as soon as the analysis is ready.

699A - Launch of ColliderTo solve this problem it is enough to look at all pairs of adjacent particles such that the left particle will move to the right and the right particle will move to the left. If there is no such pair the answer is -1. Otherwise, let's iterate through the particles from the left to the right. If the particle i will move to the right and the particle i + 1 will move to the left we know that this particles will be at the same point simultaneously, so we need to update the answer with value (xi + 1 - xi) / 2. The answer is always integer because all coordinates of the particles are even numbers.

699B - One BombTo solve this problem we need to calculate two arrays V[] and G[], where V[j] must be equal to the number of walls in the column number j and G[i] must be equal to the number of walls in the row number i. Also let's store the total number of walls in the variable cur.

Now we need to look over the cells. Let the current cell be (x, y). Let's count the value cur — how many walls will destroy the bomb planted in the cell (x, y): cnt = V[y] + G[x]. If the cell (x, y) has a wall we count it twice, so we need to subtract 1 from the cnt. If cur = cnt we found the answer and need to plant the bomb in the cell (x, y).

If there is no such cell we need to print "NO".

699C - VacationsThis problem can be solved with dynamic programming. Let's solve the opposite problem and find the maximum number of days which Vasya will not have a rest. We need o use two-dimensional array d, where d[i][j] equals to the maximum number of days, which Vasya will not have a rest, if i days passed and j equals to:

0, if Vasya had a rest during the i-th day,1, if Vasya participated in the contest on the i-th day,2, if Vasya went to gym on the i-th day.Then the transitions for the day number i look like:

d[i][0] must be updated with maximum value of the array d for the previous day;if there will be a contest on the i-th day (i. e. ai equals to 1 or 3), than we update d[i][1] with values d[i - 1][0] + 1 and d[i - 1][2] + 1;if the gym is open on the i-th day (i. e. ai equals to 2 or 3), than we update d[i][2] with values d[i - 1][0] + 1 and d[i - 1][1] + 1.After that we need to choose max from all values of the array d for the last day and print n - max.

699D - Fix a TreeOne can easily see that given sequence describes a functional graph, thus a directed graph with edges going from i to ai for every i. This graph represents a set of cycles and each cycle vertex is a root of its own tree (possibly consisting of one vertex).

Picture above shows an example of a functional graph. It consists of two cycles 1, 6, 3 and 4. Vertex 6 is the root of the tree consisting of vertices 0, 2, 6 and 8, vertex 3 roots the tree of vertices 3 and 5, vertex 4 — root of tree of vertices 4 and 7 and vertex 1 forms a tree of only one vertex.

In terms of functional graph, our goal is to make the graph consisting of exactly one cycle of exactly one vertex looped to itself.

Operation of change is equivalent to removing some outgoing edge and adding a new one, going to somewhat else vertex. Let's firstly make our graph containing only one cycle. To do so, one can choose any of initially presented cycles and say that it will be the only one. Then one should consider every other cycle, remove any of its in-cycle edges and replace it with an edge going to any of the chosen cycle's vertices. Thus the cycle will be broken and its vertices (along with tree ones) will be connected to the only chosen cycle. One will need to do exactly cycleCount - 1 such operations. Note that the removing of any non-cycle edge does not make sense, because it does not break any cycle.

The next thing is to make the cycle length be equal to 1. That might be already satisfied, if one will choose a cycle of minimal length and this length equals 1. Thus, if the initial graph contains any cycle of length 1, we are done with cycleCount - 1 operations. Otherwise, the cycle contains more than one vertex. It can be fixed with exactly one operation — one just need to break any of in-cycle edges, say from u to au, and add an edge from u to u. The graph will remain consisting of one cycle, but consisting of one self-looped vertex. In that case, we are done with cycleCount operations.

To do all the operations above, one can use DSU structure, or just a series of DFS. Note that there is no need in realisation of edge removing and creating, one just needs to analyze initial graph.

699E - LRUTutorial is not available

699F - Limak and Shooting PointsTutorial is not available

698E - CronTutorial is not available

Codeforces Round #362 (Editorial)

By PrinceOfPersia, history, 7 years ago, In EnglishHere is git repository to solutions of problems of this contest.

Div.2 AYou should check two cases for YES:

x mod s = t mod s and t ≤ xx mod s = (t + 1) mod s and t + 1 < x 

Time Complexity: 

Codes

Div.2 BNothing special, right? just find the position of letters . and e with string searching methods (like .find) and do the rest.

 

Time Complexity: 

Codes

ADo what problem wants from you. The only thing is to find the path between the two vertices (or LCA) in the tree. You can do this in  since the height of the tree is . You can keep edge weights in a map and get/set the value whenever you want. Here's a code for LCA:

LCA(v, u):        while v != u:                if depth[v] < depth[u]:                        swap(v, u)                v = v/2        // v/2 is parent of vertex v 

Time Complexity: 

Codes

BFirst of all starting_time of a vertex is the number of dfs calls before the dfs call of this vertex plus 1. Now suppose we want to find the answer for vertex v. For any vertex u that is not in subtree of v and is not an ancestor v, denote vertices x and y such that:

x ≠ yx is an ancestor of v but not uy is an ancestor of u but not vx and y share the same direct parent; That is par[x] = par[y]. 

The probability that y occurs sooner than x in children[par[x]] after shuffling is 0.5. So the probability that starting_time[u] < starting_time[v] is 0.5. Also We know if u is ancestor of v this probability is 1 and if it's in subtree of v the probability is 0. That's why answer for v is equal to  (depth is 1-based and sub[v] is the number of vertices in subtree of v including v itself). Because n - sub[v] - h[v] is the number of vertices like the first u (not in subtree of v and not an ancestor of v).

Thus answer is always either an integer or an integer and a half.

Time complexity: 

Codes

CIt gets tricky when the problem statement says p and q should be coprimes. A wise coder in this situation thinks of a formula to make sure this happens.

First of all let's solve the problem if we only want to find the fraction . Suppose dp[i] is answer for swapping the cups i times. It's obvious that dp[1] = 0. For i > 0, obviously the desired cup shouldn't be in the middle in (i - 1) - th swap and with this condition the probability that after i - th swap comes to the middle is 0.5. That's why .

 

Some people may use matrix to find p and q using this dp (using pair of ints instead of floating point) but there's a risk that p and q are not coprimes, but fortunately or unfortunately they will be.

Using some algebra you can prove that:

if n is even then  and q = 2n - 1.if n is odd then  and q = 2n - 1.You can confirm that in both cases p and q are coprimes (since p is odd and q is a power of 2).

The only thing left to handle is to find 2n (or 2n - 1) and parity. Finding parity is super easy. Also 2n = 2a1 × a2 × ... × ak = (...((2a1)a2)...)ak. So it can be calculated using binary exponential. Also dividing can be done using Fermat's little theorem.

Time complexity: O(klg(MAX_A)).

Codes

DBuild the prefix automaton of these strings (Aho-Corasick). In this automaton every state denotes a string which is prefix of one of given strings (and when we feed characters to it the current state is always the longest of these prefixes that is a suffix of the current string we have fed to it). Building this DFA can be done in various ways (fast and slow).

Suppose these automaton has N states () and state v has edges outgoing to states in vector neigh[v] (if we define our DFA as a directed graph). Suppose state number 1 is the initial state (denoting an empty string).

If l was smaller we could use dp: suppose dp[l][v] is the maximum score of all strings with length equal to l ending in state v of our DFA when fed into it.

It's easy to show that dp[0][1] = 0 and dp[1][v] ≤ bv + dp[l + 1][u] for u in neigh[v] and calculating dps can be done using this (here bv is sum of a of all strings that are a suffix of string related to state v).

 

Now that l is large, let's use matrix exponential to calculate the dp. Now dp is not an array, but a column matrix. Finding a matrix to update the dp is not hard. Also we need to reform + and * operations. In matrix multiplying we should use + instead of * and max instead of + in normal multiplication.

Time complexity: .

Codes

EFirst of all, for each query of 1st type we can assume k = 1 (because we can perform this query k times, it doesn't differ).

Consider this problem: there are only queries of type 1.

For solving this problem we can use heavy-light decomposition. If for a vertex v of the tree we denote av as the weight of the lightest girl in it (∞ in case there is no girl in it), for each chain in HLD we need to perform two type of queries:

Get weight of the lightest girl in a substring (consecutive subsequence) of this chain (a subchain).Delete the lightest girl in vertex u. As the result only au changes. We can find this value after changing in  if we have the sorted vector of girls' weights for each vertex (and then we pop the last element from it and then current last element is the lightest girl, ∞ in case it becomes empty). 

This can be done using a classic segment tree. In each node we only need a pair of integers: weight of lightest girl in interval of this node and the vertex she lives in (a pair<int, int>).

This works for this version of the problem. But for the original version we need an additional query type:

3. Increase weight of girls in a substring (consecutive subsequence) of this chain (a subchain) by k.

This can be done using the previous segment tree plus lazy propagation (an additional value in each node, type 3 queries to pass to children).

Now consider the original problem. Consider an specific chain: after each query of the first type on of the following happens to this chain:

Nothing.Only an interval (subchain) is effected.Whole chain is effected.When case 2 happens, v (query argument) belongs to this chain. And this can be done using the 3rd query of chains when we are processing a 2nd type query (effect the chain v belongs to).

When case 3 happens, v is an ancestor of the topmost vertex in this chain. So when processing 1st type query, we need to know sum of k for all 2nd type queries that their v is an ancestor of topmost chain in current chain we're checking. This can be done using a single segment/Fenwick tree (using starting-finishing time trick to convert tree to array).

So for each query of 1st type, we will check all chains on the path to find the lightest girl and delete her.

Time Complexity: 

Codes

FIn the first thoughts you see that there's definitely a binary search needed (on r). Only problem is checking if there are such two points fulfilling conditions with radius r.

For each edge, we can shift it r units inside the polygon (parallel to this edge). The only points that can see the line coinciding the line on this edge are inside the half-plane on one side of this shifted line (side containing this edge). So problem is to partition these half-planes in two parts such that intersection of half-planes in each partition and the polygon (another n half-planes) is not empty. There are several algorithms for this propose:

 Algorithm:

 

It's obvious that if intersection of some half-planes is not empty, then there's at least on point inside this intersection that is intersection of two of these lines (lines denoting these half-planes). The easiest algorithm is to pick any intersection of these 2n lines (n shifted half-planes and n edges of the polygon) like p that lies inside the polygon, delete any half-plane containing this point (intersection of deleted half-planes and polygon is not empty because it contains at least p) and check if the intersection of half-planes left and polygon is not empty (of course this part needs sorting half-planes and adds an additional log but we can sort the lines initially and use something like counting sort in this step).

Well, constant factor in this problem is too big and this algorithm will not fit into time limit. But this algorithm will be used to prove the faster algorithm:

 Algorithm:

In the previous algorithm we checked if p can be in intersection of one part. Here's the thing:

Lemma 1: If p is inside intersection of two half-planes (p is not necessarily intersection of their lines) related to l - th and r - th edge (l < r) and two conditions below are fulfilled, then there's no partitioning that in it p is inside intersection of a part (and polygon):

At least one of the half-planes related to an edge with index between l and r exists that doesn't contain p.At least one of the half-planes related to an edge with index greater than r or less than l exists that doesn't contain p.Because if these two lines exist, they should be in the other part that doesn't contain p and if they are, intersection of them and polygon will be empty(proof is easy, homework assignment ;)).

 

This proves that if such partitioning is available that p is in intersection of one of them, then it belongs to an interval of edges(cyclic interval) and the rest are also an interval (so intersection of both intervals with polygon should be non-empty). Thus, we don't need p anymore. We only need intervals!

Result is, if such partitioning exists, there are integers l and r (1 ≤ l ≤ r ≤ n) such that intersection of half-planes related to l, l + 1, ..., r and polygon and also intersection of half-planes related to r + 1, r + 2, ..., n, 1, 2, ..., l - 1 and polygon are both non-empty.

This still gives an  algorithm (checking every interval). But this lemma comes handy here:

We call an interval(cyclic) good if intersection of lines related to them and polygon is non-empty.

Lemma 2: If an interval is good, then every subinterval of this interval is also good.

Proof is obvious.

That gives and idea:

Denote interval(l, r) is a set of integers such that:

If l ≤ r, then interval(l, r) = {l, l + 1, ..., r}If l ≤ r, then interval(l, r) = {r, r + 1, ..., n, 1, ..., l}(In other words it's a cyclic interval)

Also MOD(x) is:

x iff x ≤ nMOD(x - n) iff x > n(In other words it's modulo n for 1-based)

The only thing that matters for us for every l, is maximum len such that interval(l, MOD(l + len)) is good (because then all its subintervals are good).

If li is maximum len that interval(i, MOD(i + len)) is good, we can use 2-pointer to find values of l.

Lemma 3: lMOD(i + 1) ≥ li - 1.

Proof is obvious in result of lemma 2.

Here's a pseudo code:

check(r):        len = 0        for i = 1 to n:                while len < n and good(i, MOD(i+len)):        // good(l, r) returns true iff interval(l, r) is good                        len = len + 1                if len == 0:                        return false        // Obviously                if len == n:                        return true        // Barney and Lyanna can both stay in the same position                l[i] = len        for i = 1 to n:                if l[i] + l[MOD(i+l[i])] >= n:                        return true        return falsegood function can be implemented to work in  (with sorting as said before). And 2-pointer makes the calls to good to be .

So the total complexity to check an specific r is .

Time Complexity: 

Codes

Feel free to comment and ask your questions.

Codeforces Round #361 (Div. 2) Editorial

By I_Love_Tina, history, 7 years ago, In EnglishA.Mike and Cellphone

Author:danilka.pro.

Developed:I_Love_Tina,ThatMathGuy

We can try out all of the possible starting digits, seeing if we will go out of bounds by repeating the same movements. If it is valid and different from the correct one, we output "NO", otherwise we just output "YES".

C++ codeAnother C++ codeAnother C++ codePython codeB. Mike and Shortcuts

Author:danilka.pro,I_Love_Tina

Developed:I_Love_Tina,ThatMathGuy

We can build a complete graph where the cost of going from point i to point j if |i - j| if ai! = j and 1 if ai = j.The we can find the shortest path from point 1 to point i.One optimisation is using the fact that there is no need to go from point i to point j if j ≠ s[i],j ≠ i - 1,j ≠ i + 1 so we can add only edges (i, i + 1),(i, i - 1),(i, s[i]) with cost 1 and then run a bfs to find the shortest path for each point i.

You can also solve the problem by taking the best answer from left and from the right and because ai ≤ ai + 1 then we can just iterate for each i form 1 to n and get the best answer from left and maintain a deque with best answer from right.

Complexity is O(N).

C++ code with queueC++ code with dequePython code What if you have Q queries Q ≤ 2 × 105 of type (xi, yi) and you have to answer the minimal distance from xi to yi.

C. Mike and Chocolate Thieves

Author:danilka.pro,I_Love_Tina

Developed:I_Love_Tina,ThatMathGuy

Suppose we want to find the number of ways for a fixed n.

Let a, b, c, d ( 0 < a < b < c < d ≤ n ) be the number of chocolates the thieves stole. By our condition, they have the form b = ak, c = ak2, d = ak3,where k is a positive integer. We can notice that  , so for each k we can count how many a satisfy the conditions 0 < a < ak < ak2 < ak3 ≤ n, their number is . Considering this, the final answer is .

Notice that this expression is non-decreasing as n grows, so we can run a binary search for n.

Total complexity: Time ~ , Space: O(1).

C++ codeAnother C++ codeD. Friends and Subsequences

Author:I_Love_Tina

Developed:I_Love_Tina,ThatMathGuy

First of all it is easy to see that if we fix l then have . So we can just use binary search to find the smallest index rmin and biggest index rmax that satisfy the equality and add rmax - rmin + 1 to our answer. To find the min and max values on a segment [l, r] we can use Range-Minimum Query data structure.

The complexity is  time and  space.

C++ code O(N)C++ code O(N log N)C++ code O(N log ^ 2 N)Another C++ code What if you need to count (l1, r1, l2, r2), 1 ≤ l1 ≤ r1 ≤ n, 1 ≤ l2 ≤ r2 ≤ n and .

Hint:Take idea from this problem.

C++ code for BonusE. Mike and Geometry Problem

Author:I_Love_Tina

Developed:I_Love_Tina,ThatMathGuy

Let define the following propriety:if the point i is intersected by p segments then in our sum it will be counted  times,so our task reduce to calculate how many points is intersected by i intervals 1 ≤ i ≤ n.Let dp[i] be the number of points intersected by i intervals.Then our answer will be . We can easily calculate array dp using a map and partial sum trick,here you can find about it.

The complexity and memory is  and O(n).

C++ codeAnother C++ solution what if  where l, r are given in input.

I'm really sorry that problem A was harder than ussually.

Codeforces Round #360 Editorial [+ Challenges!]

By M.Mahdi, 7 years ago, In EnglishHi again!

If you notice typos or errors, please send a private message.

688A: OpponentsSolutionLet's find out for each row of the given matrix if it is completely consisting of ones or not. Make another array canWin, and set canWini equal to one if the i-th row consists at least one zero. Then the problem is to find the maximum subsegment of canWin array, consisting only ones. It can be solved by finding for each element of canWin, the closest zero to it from left. The complexity of this solution is O(nd), but the limits allow you to solve the problem in O(nd2) by iterating over all possible subsegments and check if each one of them is full of ones or not.

C++ codePython code688B: Lovely PalindromesHintTry to characterize even-length palindrome numbers.

SolutionFor simplifications, in the following solution we define lovely integer as an even-length positive palindrome number.

An even-length positive integer is lovely if and only if the first half of its digits is equal to the reverse of the second half.

So if a and b are two different 2k-digit lovely numbers, then the first k digits of a and b differ in at least one position.

So a is smaller than b if and only if the first half of a is smaller than the the first half of b.

Another useful fact: The first half of a a lovely number can be any arbitrary positive integer.

Using the above facts, it's easy to find the first half of the n-th lovely number — it exactly equals to integer n. When we know the first half of a lovely number, we can concatenate it with its reverse to restore the lovely integer. To sum up, the answer can be made by concatenating n and it's reverse together.

The complexity of this solution is .

C++ codePython codeChallengeWhat if you were asked to find n-th positive palindrome number? (1 ≤ n ≤ 1018)

687A: NP-Hard ProblemHintTry to use all of the vertices. Then look at the two vertex covers together in the graph and see how it looks like.

SolutionLooking at the two vertex covers in the graph, you see there must be no edge uv that u and v are in the same vertex cover. So the two vertex covers form a bipartition of the graph, so the graph have to be bipartite. And being bipartite is also sufficient, you can use each part as a vertex cover. Bipartition can be found using your favorite graph traversing algorithm(BFS or DFS). Here is a tutorial for bipartition of undirected graphs.

The complexity is O(n + m).

C++ codeChallengeIn the same constraints, what if you were asked to give two disjoint edge covers from the given graph? (The edge covers must be edges-disjoint but they can have common vertex.)

687B: Remainders GameHintAssume the answer of a test is No. There must exist a pair of integers x1 and x2 such that both of them have the same remainders after dividing by any ci, but they differ in remainders after dividing by k. Find more facts about x1 and x2!

SolutionConsider the x1 and x2 from the hint part. We have x1 - x2 ≡ 0 () for each 1 ≤ i ≤ n.

So:

We also have  (). As a result:

We've found a necessary condition. And I have to tell you it's also sufficient!

Assume , we are going to prove there exists x1, x2 such that x1 - x2 ≡ 0 () (for each 1 ≤ i ≤ n), and  ().

A possible solution is x1 = lcm(c1, c2, ..., cn) and x2 = 2 × lcm(c1, c2, ..., cn), so the sufficiency is also proved.

So you have to check if lcm(c1, c2, ..., cn) is divisible by k, which could be done using prime factorization of k and ci values.

For each integer x smaller than MAXC, find it's greatest prime divisor gpdx using sieve of Eratosthenes in .

Then using gpd array, you can write the value of each coin as p1q1p2q2...pmqm where pi is a prime integer and 1 ≤ qi holds. This could be done in  by moving from ci to  and adding gpdci to the answer. And you can factorize k by the same way. Now for every prime p that , see if there exists any coin i that the power of p in the factorization of ci is not smaller than the power of p in the factorization of k.

Complexity is .

C++ codeAnd a nice implementation by Reyna: 18789803

687C: The values you can makeHintUse dynamic programming.

SolutionLet dpi, j, k be true if and only if there exists a subset of the first i coins with sum j, that has a subset with sum k. There are 3 cases to handle:

The i-th coin is not used in the subsets.The i-th coin is used in the subset to make j, but it's not used in the subset of this subset.The i-th coin is used in both subsets.So dpi, j, k is equal to dpi - 1, j, k OR dpi - 1, j - ci, k OR dpi - 1, j - ci, k - ci.

The complexity is O(nk2).

C++ codeChallengeIn the same constraints, output the numbers you can never not make! Formally, the values x such that for every subset of coins with the sum k, there exists a subset of this subset with the sum x.

687D: Dividing Kingdom IIUnfortunately, our mistake in setting the constrains for this problem made it possible to get Ac with O(qm) solution. We hope you accept our apology.

HintConsider the following algorithm to answer a single query: Sort the edges and add them one by one to the graph in decreasing order of their weights. The answer is weight of the first edge, which makes an odd cycle in the graph. Now show that there are only O(n) effective edges, which removing them may change the answer of the query. Use this idea to optimize your solution.

SolutionFirst, let’s solve a single query separately. Sort edges from interval [l, r] in decreasing order of weights. Using dsu, we can find longest prefix of these edges, which doesn’t contains odd cycle. (Graph will be bipartite after adding these edges.) The answer will be weight of the next edge. (We call this edge “bottleneck”).

Why it's correct? Because if the answer is w, then the we can divide the graph in a way that none of the edges in the same part have value greater than w. So the graph induced by the edges with value greater than w must be bipartite. And if this graph is bipartite, then we can divide the graph into two parts as the bipartition, so no edge with value greater than w will be in the same part, and the answer is at most w.

Let's have a look at this algorithm in more details. For each vertex, we keep two values in dsu: Its parent and if its part differs from its parent or not. We keep the second value equal to "parity of length of the path in original graph, between this node and its parent". We can divide the graph anytime into two parts, walking from one vertex to its parent and after reaching the root, see if the starting vertex must be in the same part as the root or not.

In every connected component, there must not exist any edge with endpoints in the same part.

After sorting the edges, there are 3 possible situations for an edge when we are adding it to the graph:

The endpoints of this edge are between two different components of the current graph. Now we must merge these two components, and update the part of the root of one of the components.

The endpoints of this edge are in the same component of the current graph, and they are in different parts of this component. There is nothing to do.

The endpoints of this edge are in the same component of the current graph, and they are also in the same part of this component. This edge is the "bottleneck" and we can't keep our graph bipartite after adding it, so we terminate the algorithm.

We call the edges of the first and the third type "valuable edges".

The key observation is: If we run above algorithm on the valuable edges, the answer remains the same.

Proof idea: The edges of the first type are spanning trees of connected components of the graph, and with a spanning tree of a bipartite graph, we can uniquely determine if two vertices are in the same part or not.

So if we can ignore all other edges and run our algorithm on these valuable edges, we have O(n) edges instead of original O(n2) and the answer is the same.

We answer the queries using a segment tree on the edges. In each node of this tree, we run the above algorithm and memorize the valuable edges. By implementing carefully (described here), making the segment tree could be done in .

Now for each query [l, r], you can decompose [l, r] into  segments in segment tree and each one has O(n) valuable edges. Running the naive algorithm on these edges lead to an  solution for each query, which fits in time limit.

C++ code687E: TOFHint: What the actual problem isLooking at the code in the statement, you can see only the first edge in neighbors of each node is important. So for each vertex with at least one outgoing edge, you have to choose one edge and ignore the others. After this the graph becomes in the shape of some cycles with possible branches, and some paths. The number of dfs calls equals to 998 × ( sum of sizes of cycles ) + n +  number of cycles.

SolutionThe goal is to minimize the sum of cycle sizes. Or, to maximize the number of vertices which are not in any cycle. Name them good vertices.

If there exists a vertex v without any outgoing edge, we can make all of the vertices that v is reachable from them good. Consider the dfs-tree from v in the reverse graph. You can choose the edge  from this tree as the first edge in neighbors[u], in order to make all of these vertices good.

Vertices which are not in the sink strongly connected components could become good too, by choosing the edges from a path starting from them and ending in a sink strongly connected component.

In a sink strongly connected component, there exists a path from every vertex to others. So we can make every vertex good except a single cycle, by choosing the edges in the paths from other nodes to this cycle and the cycle edges.

So, every vertices could become good except a single cycle in every sink strongly connected component. And the length of those cycles must be minimized, so we can choose the smallest cycle in every sink strongly connected component and make every other vertices good. Finding the smallest cycle in a graph with n-vertex and m edges could be done in O(n(n + m)) with running a BFS from every vertex, so finding the smallest cycle in every sink strongly connected component is O(n(n + m)) overall.

C++ codeChallengeWhat if the target function is reversed? It means you have to choose a single outgoing edge from every node with at least one outgoing edge, and maximize the sum of cycle sizes in the chosen graph.

I thought about this one a lot but can't find any solution. Do you have any idea?

Codeforces Round #359 Editorial

By ch_egor, 7 years ago, translation, In EnglishIf you notice typos or errors, please send a private message.

Div2A Free Ice Cream

Author: cdkrotDeveloper: ch_egor

You just needed to implement the actions described in statement.

If you solution failed, then you probably forgot to use 64-bit integers or made some small mistake.

Correct solution:

C++ codePython codeDiv2B Little Robber Girl's Zoo

Author: ch_egorDeveloper: ch_egor

We need to sort an array with strange operations — namely, to swap elements with even and odd indices in subarray of even length. Note that we can change the 2 neighboring elements, simply doing our exchange action for subarray of length 2 containing these elements. Also, note that n ≤ 100, and it is permission to do 20 000 actions, therefore, we can write any quadratic sort, which changes the neighboring elements in each iteration (bubble sort for example).Complexity O(n2)

C++ codePython codeBonus: Is anyone able to search the shortest solution of this problem? If yes, what complexity?

Div2C Robbers' watch/Div1A Robbers' watch

Author: cdkrotDeveloper: themikemikovi4

In this problem we use the septimal number system. It is a very important limitation. Let's count how many digits are showed on the watch display and call it cnt. If cnt more than 7, the answer is clearly 0 (because of pigeonhole principle). If cnt is not greater than 7, then you can just bruteforces all cases.Depending on the implementation it will be O(BASE BASEBASE), O(BASEBASE) or O(BASE BASE!), where BASE = 7. Actually the most simple implementation is just to cycle between all posible hour:minute combinations and check them.In the worst case, it will work in O(BASE BASEBASE).

C++ codePython codeBonus: Suppose the base is not fixed. Solve a problem with n ≤ 109, m ≤ 109, BASE ≤ 109. Can you do it in ?

Div2D Kay and Snowflake/Div1B Kay and Snowflake

Author: cdkrotDevelopers: ch_egor, cdkrot

There are many possible approaches.

Solution by cdkrot:

Look at the all candidates for the centroid of the vertices v subtree. The size of centroid subtree must be at least  of the vertex v subtree size. (If it isn't, then after cutting the upper part will have too big size)

Choose the vertex with the smallest subtree size satisfying the constraint above. Let's prove, that this vertex is centroid indeed. If it isn't, then after cutting some part will have subtree size greater than  of subtree size of query vertex. It isn't upper part (because of constraint above), it is one of our sons. Ouch, it's subtree less than of selected vertex, and it's still greater than  of subtree size of query vertex. Contradiction.

So we find a centroid.We write the euler tour of tree and we will use a 2D segment tree in order to search for a vertex quickly.Complexity 

C++ codeYou can consider all answers by one in dfs using this idea. Use std::set for pair (subtree size, vertex number) and at each vertex merge sets obtained from children. (Also known as "merging sets" idea)Thus we get the answers for all vertex and we need only output answers for queries.Complexity 

C++ codeSolution by ch_egor:Solve it for all subtrees. We can solve the problem for some subtree, after solving the problem for all of it's children. Let's choose the heaviest child. Note that the centroid of the child after a certain lifting goes into our centroid. Let's model the lifting.Thus we get the answers for all vertex and we need only output answers for queries.Complexity O(n + q)

C++ codeDiv2E Optimal Point/Div1C Optimal Point

Author: cdkrotDeveloper: cdkrot

Let's say few words about ternary search. It works correctly, but too slow.It's complexity is , where n = 105, and v = 1018.Don't use it.

Solution.1) Let's make binary search on answer2) Consider areas of "good" points (with dist  ≤ mid) for each source point.3) Intersect those areas and check for solution.

This area can be decsribed by following inequalities:(You can achieve them if you expand modules in inequality "manhattan distance <= const")

.. ≤ x + y + z ≤ ..

.. ≤  - x + y + z ≤ ..

.. ≤ x - y + z ≤ ..

.. ≤ x + y - z ≤ ..

.. denote some constants.

If you intersect set of such system, you will get system of the same form, so let's learn how to solve such system.

Let's replace some variables:

a =  - x + y + z

b = x - y + z

c = x + y - z

Then:

x + y + z = a + b + c

x = (b + c) / 2

y = (a + c) / 2

z = (a + b) / 2

Now the system transforms into:

.. ≤ a ≤ ..

.. ≤ b ≤ ..

.. ≤ c ≤ ..

.. ≤ a + b + c ≤ ..

We need to check if the system has solution in integers, also the numbers a, b, c must be of the same parity (have equal remainder after division by 2). (This is required for x, y, z to be integers too)

Let's get rid of parity constraint. Bruteforce the parity of a, b, c (two cases)

Make following replacement: a = 2a' + r, b = 2b' + r, c = 2c' + r, where r = 0 or r = 1. Substitute in equations above, simplify, and gain the same system for a', b', c' without parity constraint.

And now the system can be solved greedy (At first set a, b, c with minimum, and then raise slowly if necessary).

Total complexity is .

C++ codeBonus. This task can be solved in a lot of modifications, for example euclidian distance instead of manhattan, 2d instead of 3d, floats instead of integers. How to solve this varations?

Div1D Kay and Eternity

Authors: platypus179, EndagorionDeveloper: platypus179

Let's solve this problem with scanline. Go through all rows from left to right and maintain the array in which in j index we will store the number of points in a square with bottom left coordinate (i, j), where i is current row of scanline.

This takes O(MAXCORD2) time. Note that the set of squares that contain some of the shaded points is not very large, namely — if the point has coordinates (x, y), then the set of left bottom corners of square is defined as {(a, b)|x - k + 1 <  = a <  = x, y - k + 1 <  = b <  = y}. Let's consider each point (x, y) as the 2 events:Add one to the all elements with indexes from y - k + 1 to y on the row x - k + 1 and take one at the same interval on the row x + 1. How to calculate answer? Suppose we update the value of a cell on the row a, and before it was updated the value x on the row b. Let add to the answer for the number of squares containing x points value a - b. We can implement the addition of the segment directly and have O(nk) for processing all the events that fit in time limit. To get rid of O(MAXCORD) memory, we need to write all interested in the coordinates before processing events (them no more than nk) and reduce the coordinates in the events. It takes  time and O(nk) memory. Now we can execute the previous point in O(nk) memory.Complexity is  time and O(nk) memory.

C++ codeBonus:  time and O(n) memory.

C++ codeDiv1E Travelling Through the Snow Queen's Kingdom

Authors: cdkrot, GlebsHPDevelopers: ch_egor, cdkrot

Unfortunately, due to my, cdkrot, failure, it was possible to get Ac with O(nm) solution, I apologise for that.

We propose following solution:Let's solve task with divide & conquer. At first let's lift l to the first index, where s was mentioned And lower the r to the last index, where t was mentioned. This will not affect answers, but will make implementation much more easy.

Let's look on all queries. For each query consider it's location relative to centre of edges array. If it's stricly on the left half or on the right half, then solve recursively (You need to implement function like solve(requests, l, r)).

How to answer on query, if it contains the centre? Let's precalculate two dp's:

dpr[i] =  bitset of vertices you can from to the vi or ui with l = m and r = i.

dpl[i] =  bitset of vertices you can go to starting from vi or ui with l = i and r = m - 1

vi and ui are vertices of i'th edge.

Using this dp the answer is yes if and ony if dpl[l][u] = true and dpr[r][u] = true for some u.

All above can be implemented using bitwise operations.So the time is 

C++ code

Codeforces Round #358 (Div. 2) Editorial

By halin.george, history, 7 years ago, translation, In English682A — Alyona and Numbers

Let's iterate over the first number of the pair, let it be x. Then we need to count numbers from 1 to m with the remainder of dividing 5 equal to (5 - xmod5)mod 5. For example, you can precalc how many numbers from 1 to m with every remainder between 0 and 4.

682B — Alyona and Mex

Let's sort the array. Let cur =  1. Then walk through the array. Let's look at current number. If it is greater or equal to cur, then let's increase cur by 1. Answer is cur.

682C — Alyona and the Tree

Let's do dfs. Suppose that we now stand at the vertex u. Let v be some ancestor of vertex u. Then dist(v, u) = dist(1, u) - dist(1, v). If dist(v, u) > au, then the vertex u makes v sad. So you must remove the whole subtree of vertex u. Accordingly, it is possible to maintain a minimum among dist(1, v) in dfs, where v is ancestor of u (vertex, in which we now stand). And if the difference between the dist(1, u) and that minimum is greater than au, then remove au with the whole subtree.

682D — Alyona and Strings

Let's use the method of dynamic programming. Let d[i][j][cnt][end] be answer to the problem for the prefix of string s of length i and for the prefix of string t of length j, we have chosen cnt substrings. end = 1, if both last characters of the prefixes are included in the maximum subsequence and end = 0 otherwise.

When the state is d[i][j][cnt][end], you can add the following letters in the string s or t, though it will not be included in the response subsequence. Then d[i + 1][j][cnt][0] = max(d[i + 1][j][cnt][0], d[i][j][cnt][end]), d[i][j + 1][cnt][0] = max(d[i][j + 1][cnt][0], d[i][j][cnt][end]). So the new value of end is 0, because the new letter is not included in the response subsequence.

If s[i] = t[j], then if end = 1, we can update the d[i + 1][j + 1][k][1] = max(d[i][j][k][end] + 1, d[i + 1][j + 1][k][1]). When we add an element to the response subsequence, the number of substring, which it is composed, will remain the same, because end = 1. If end = 0, we can update d[i + 1][j + 1][k + 1][1] = max(d[i][j][k][end] + 1, d[i + 1][j + 1][k + 1][1]). In this case, the new characters, which we try to add to the response subsequence, will form a new substring, so in this case we do the transition from the state k to the state k + 1.

The answer will be the largest number among the states of the d[n][m][k][end], where the values ​​of k and end take all possible values.

682E — Alyona and Triangles

Let's find the triangle with maximum area among ​​all triangles whose vertices belong to the set of points. (For N2 with the convex hull and the two pointers). We can prove that if we take the triangle, whose vertices are the midpoints of the sides of the triangle with maximum area, the area of ​​such a triangle is not greater than 4S, and it contains all the points of the set. Let us assume that there is a point lying outside the triangle-response. Then we can get longer height to some side of triangle, so we have chosen a triangle with not maximum area(contradiction).

Codeforces Round #357 (Div. 2) Editorial

By .tx, history, 7 years ago, translation, In English681A - A Good Contest

If for any participant beforei ≥ 2400 and afteri > beforei, then the answer is "YES", otherwise "NO"

Code

681B - Economy Game

We can simply try every a from 0 to n / 1234567 and b from 0 до n / 123456, and if n - a * 1234567 - b * 123456 is non-negative and divided by 1234, then the answer is "YES".

If there is no such a and b, then the answer is "NO".

Code

681C - Heap Operations

Let's solve this problem with greedy approach. Let's apply operations from log in given order.

If current operation is insert x, then add element x to heap.

If current operation is removeMin, then if heap is not empty, then simply remove minimal element, otherwise if heap is empty, add operation insert x, where x can be any number, and then apply removeMin

If current operation is getMin x then do follows:

While heap is not empty and its minimal element is less than x, apply operation removeMin.Now if heap is empty or its minimal element is not equal to x, apply operation insert x.Apply operation getMin x.In order to fit time limit, you need to use data structure, which allows you to apply given operations in O(logN) time, where N is a number of elements in it. For example, std::priority_queue or std::multiset.

Code

681D - Gifts by the List

Formal statement of the problem:

You have a directed acyclic graph, every vertex has at most one ingoing edge. Vertex A is an ancestor of vertex B if there is a path from A to B in graph. Also every vertex is an ancestor of itself.

Every vertex i has a pair – vertex ai, ai – ancestor of i.

You need to build such sequence of vertex, that for every vertex i the leftmost vertex in the sequence which is ancestor of i must be equal to ai.

Or you need to tell, that such sequence does not exists.

Solution:

Assume sequence ans, which contains every vertex from sequence an by once and only them. Let's order elements of this sequence in such way, that for every i and j if ansi – ancestor of ansj, then i ≥ j.

If this sequecne is the answer, then print it. Otherwise, there is no answer.

Why?

If some vertex ai from sequence a in not present in ans, then a man, who needs to give a gift to a man number ai, will not be able to do it. So every vertex ai must have place in the resulting sequence.

If ai – ancestor of aj and i < j, then a man, who needs to give a gift to a man number aj will not be able to do it.

How can we build this sequence?

Let's sort vertices topologically, than reverse it and remove redundant vertices.

Now we need to check if that this sequence can be the answer.

Let's calculate to whom every man will give his gift. At start for any man we don't know that. Let's iterate through vertices of the resulting sequence.

For every vertex (man) from current vertex subtree (i.e. for vertices whose ancestor is current vertex) such that we still don't know whom will this vertex (man) give a gift to, stays that these vertices would give a gift to current vertex, because it is their first ancestor in the list.

Iterate through that vertices (men) in dfs order and remember for them, to whom they will give their gift.

After we apply this operation to all vertices from resulting sequence, compare for each man to whom he will give his gift and to whom he needs to give his gift. If there is at least one mismatch, then the answer doesn't exist.

Code

681E - Runaway to a Shadow

At first assume the case when cockroach at the moment 0 is already inside or on the border of some circle. In that case the cockroach will always survive, i. e. the probability is 1.

Otherwise the cockroach will have time to run to every point inside the circle with center of x0, y0 and radius v × t.

Let's iterate through all the shadow circles and figure out how each circle relates to "cockroach circle". We want to find the maximum angle, such that choosing the direction from this angle the cockroach will have enough time to reach current circle and survive.

In general, maximal "surviving" angle, such that choosing the direction from it the cockroach will reach the circle in infinite time – is an angle between two tangents from a start point to the circle. If length of this tangents is not greater than v × t, then this angle is the needed one.

Otherwise we need to find intersections of cockroach circle and current circle. If there is no intersection points or there is only one, then current circle is too far away from cockroach. Otherwise intersection points and start point form the needed angle for this circle.

After we've found all the angles, we can figure out that those angles are segments that cover a segment from 0 to 2π. Sort their ends and find a length of their union. This length divided by 2π will give us the answer.

Code

Codeforces Round #356 — Editorial

By Errichto, 7 years ago, In English680A - Bear and Five CardsIterate over all pairs and triples of numbers, and for each of them check if all two/three numbers are equal. If yes then consider the sum of remaining numbers as the answer (the final answer will be the minimum of considered sums). Below you can see two ways to implement the solution.

code1code2680B - Bear and Finding CriminalsLimak can't catch a criminal only if there are two cities at the same distance and only one of them contains a criminal. You should iterate over the distance and for each distance d check if a - d and a + d are both in range [1, n] and if only one of them has ti = 1.

code1code2679A - Bear and Prime 100If a number is composite then it's either divisible by p2 for some prime p, or divisible by two distinct primes p and q. To check the first condition, it's enough to check all possible p2 (so, numbers 4, 9, 25, 49). If at least one gives "yes" then the hidden number if composite.

If there are two distinct prime divisors p and q then both of them are at most 50 — otherwise the hidden number would be bigger than 100 (because for p ≥ 2 and q > 50 we would get p·q > 100). So, it's enough to check primes up to 50 (there are 15 of them), and check if at least two of them are divisors.

code1code2, Python679B - Bear and Tower of CubesLet's find the maximum a that a3 ≤ m. Then, it's optimal to choose X that the first block will have side a or a - 1. Let's see why.

If the first block has side a then we are left with m2 = m - first_block = m - a3.If the first block has side a - 1 then the initial X must be at most a3 - 1 (because otherwise we would take a block with side a), so we are left with m2 = a3 - 1 - first_block = a3 - 1 - (a - 1)3If the first blocks has side a - 2 then the initial X must be at most (a - 1)3 - 1, so we are left with m2 = (a - 1)3 - 1 - first_block = (a - 1)3 - 1 - (a - 2)3.We want to first maximize the number of blocks we can get with new limit m2. Secondarily, we want to have the biggest initial X. You can analyze the described above cases and see that the first block with side (a - 2)3 must be a worse choice than (a - 1)3. It's because we start with smaller X and we are left with smaller m2. The situation for even smaller side of the first block would be even worse.

Now, you can notice that the answer will be small. From m of magnitude a3 after one block we get m2 of magnitude a2. So, from m we go to m2 / 3, which means that the answer is O(loglog(m)). The exact maximum answer turns out to be 18.

The intended solution is to use the recursion and brutally check both cases: taking a3 and taking (a - 1)3 where a is maximum that a3 ≤ m. It's so fast that you can even find a in O(m1 / 3), increasing a by one.

code1code2code3679C - Bear and Square GridLet's first find CC's (connected components) in the given grid, using DFS's.

We will consider every possible placement of a k × k square. When the placement is fixed then the answer is equal to the sum of k2 the the sum of sizes of CC's touching borders of the square (touching from outside), but for those CC's we should only count their cells that are outside of the square — not to count something twice. We will move a square, and at the same time for each CC we will keep the number of its cells outside the square.

We will used a sliding-window technique. Let's fix row of the grid — the upper row of the square. Then, we will first place the square on the left, and then we will slowly move a square to the right. As we move a square, we should iterate over cells that stop or start to belong to the square. For each such empty cell we should add or subtract 1 from the size of its CC (ids and sizes of CC's were found at the beginning).

And for each placement we consider, we should iterate over outside borders of the square (4k cells — left, up, right and down side) and sum up sizes of CC's touching our square. Be careful to not count some CC twice — you can e.g. keep an array of booleans and mark visited CC's. After checking all 4k cells you should clear an array, but you can't do it in O(number_of_all_components) because it would be too slow. You can e.g. also add visited CC's to some vector, and later in the boolean array clear only CC's from the vector (and then clear vector).

The complexity is O(n2·k).

code1code2code3, Java679D - Bear and ChaseCheck my code below, because it has a lot of comments.

First, in O(n3) or faster find all distances between pairs of cities.

Iterate over all g1 — the first city in which you use the BCD. Then, for iterate over all d1 — the distance you get. Now, for all cities calculate the probability that Limak will be there in the second day (details in my code below). Also, in a vector interesting let's store all cities that are at distance d1 from city g1.

Then, iterate over all g2 — the second city in which you use the BCD. For cities from interesting, we want to iterate over them and for each distinct distance from g2 to choose the biggest probability (because we will make the best guess there is).

Magic: the described approach has four loops (one in the other) but it's O(n3).

Proof is very nice and I encourage you to try to get it yourself.

Proof herecode1679E - Bear and Bad Powers of 42The only special thing in numbers 1, 42, ... was that there are only few such numbers (in the possible to achieve range, so up to about 1014).

Let's first solve the problem without queries "in the interval change all numbers to x". Then, we can make a tree with operations (possible with lazy propagation):

add on the intervalfind minimum in the whole treeIn a tree for each index  let's keep the distance to the next power of 42. After each "add on the interval" we should find the minimum and check if it's positive. If not then we should change value of the closest power of 42 for this index, and change the value in the tree. Then, we should again find the minimum in the tree, and so on. The amortized complexity is O((n + q) * log(n) * log42(values)). It can be proved that numbers won't exceed (n + q) * 1e9 * log.

Now let's think about the remaining operation of changing all interval to some value. We can set only one number (the last one) to the given value, and set other values to INF. We want to guarantee that if t[i] ≠ t[i + 1] then the i-th value is correctly represented in the tree. Otherwise, it can be INF instead (or sometimes it may be correctly represented, it doesn't bother me). When we have the old query of type "add something to interval [a, b]" then if index a - 1 or index b contains INF in the tree then we should first retrieve the true value there. You can see that each operation changes O(1) values from INF to something finite. So, the amortized complexity is still O((n + q) * log(n) * log42(values).

One thing regarding implementation. In my solution there is "set < int > interesting" containing indices with INF value. I think it's easier to implemement the solution with this set.

code1code2

Codeforces Round #355 (Div. 2) Editorial

By Wild_Hamster, history, 7 years ago, In English677A - Vanya and Fence

For each friend we can check, if his height is more than h. If it is, then his width is 2, else 1.

Complexity O(n).

Code677B - Vanya and Food Processor

The solution, that does same thing, as in the problem statement will fail with TL, because if the height of each piece of potato will be 109 and smashing speed will be 1, then for each piece we will do 109 operations.

With each new piece of potato ai we will smash the potato till a[i] MOD k, so we will waste a[i] / k seconds on it. If we can not put this piece of potato after that, we will waste 1 more second to smash everything, that inside, else just put this piece. We will get an answer same as we could get with actions from the statement.

Complexity O(n).

Code677C - Vanya and Label

We can transform our word in binary notation, we can do it easily, because 64 = 26. Move through the bits of this number: if bit is equal to 0, then we can have 3 different optinos of this bit in our pair of words: 0&1, 1&0, 0&0, else we can have only one option: 1&1. So the result will be 3nullbits, where nullbits — is amount of zero bits.

Complexity O(|s|).

Code677D - Vanya and Treasure

We can make dynamic programming dp[col][row], where dp[col][row] is minimal time, that we have waste to open the chest in the cell (col, row). For the cells of color 1: dp[x][y] = x + y. For each next color color we can look over all cells of color color - 1 and all cells of color color, then for each cell of color color with coordinates (x1, y1) and for each cell with color color - 1 and coordinates (x2, y2) dp[x1][y1] = dp[x2][y2] + abs(x1 - x2) + abs(y1 - y2).

But complexity of this solution is O(n2·m2), what is not enough.

We can do such improvement: let cnt[x] be the amount of cells of color x, then when cnt[color]·cnt[color - 1] ≥ n·m, we can do bfs from cells of color color - 1 to cells of color color.

Then we will have complexity O(n·m·sqrt(n·m)).

Proof

CodeThere also exists solution with 2D segment tree:

Code677E - Vanya and Balloons

For each cell (x, y) take the maximum possible cross with center in this cell, that doesn't contains zeros. To do it fast, we can make arrays of partial sums for all possible 8 directions, in which each cell will contain the number of non-zero balloons in each direction. For example, if we want to know, how many non-zero balloons are right to cell (x, y), we can create an array p[x][y], where p[x][y] = p[x][y - 1] + 1 if a[x][y]! = 0 else p[x][y] = 0

So now we can for each cell (x, y) we can find the maximum size of cross with the centre in this cell, that will not contain zeros.

We can compare product for crosses with centers in the cells (x, y) and radius r using logarythms. For example, if we need to compare 2 crosses with values x1·x2·...·xn and y1·y2·...·ym, we can compare log(x1·x2·...·xn) and log(y1·y2·...·yn), what will be equivalent to comparing log(x1) + log(x2) + ... + log(xn) and log(y1) + log(y2) + ... + log(ym).

We can also use partial sum arrays to find value log(x1) + log(x2) + ... + log(xn) for each cross, so we can find the product of the values in each cross for O(1) time.

Complexity O(n2).

Code

Editorial Codeforces #354 round div.2

By AGrigorii, 7 years ago, translation, In English676A - Nicholas and PermutationAll what you need to solve this problem — find the positions of numbers 1 and n in the given array. Let's this positions equal to p1 and pn, then the answer is the maximum of 4 values:

abs(n - p1),  abs(n - pn),  abs(1 - p1),  abs(1 - pn).Asymptotic behavior O(n).

676B - Pyramid of GlassesThe restrictions in this problem allow to simulate the process. Let the volume of one wineglass equals to 2n conventional units. So the volume of the champagne surpluses which will stream to bottom level will always integer number. So let's pour in the top wineglass q * 2n units of champagne, and then we have following case: if in the current wineglass is more champagne than its volume, let's make surplus = Vtek - 2n, and add surplus / 2 of champagne in each of the two bottom wineglasses.

Asymptotic behavior O(n2).

676C - Vasya and StringThis problem can be solved with help of two pointers. Let the first pointer is l and the second pointer is r. Then for every position l we will move right end r until on the substring slsl + 1... sr it is possible to make no more than k swaps to make this substring beautiful. Then we need to update the answer with length of this substring and move l to the right.

Asymptotic behavior O(n * alphabet).

676D - Theseus and labyrinthIt is easy to understand that we have only 4 states of the maze. How to solve this problem if there is no any buttons? It is just bfs on the maze (on the graph). Because of buttons we need to add to graph 3 additional levels and add edges between this levels. After that we need to run bfs on this graph and find the length of the minimum path if such exists.

Asymptotic behavior O(n * m).

676E - The Last Fight Between Human and AIIn this problem we have two main cases: k = 0,  k ≠ 0.

Case when k = 0. Then the division of the polynomial to the x - k depends only of the value of a0. If a0 is already known then we need to compare it with zero. If a0 = 0 then the human wins, otherwise the human loses. If ai is not known then win who make the move.

Case when k ≠ 0. Here we have two cases: all coefficients already known. Then we need to check x = k — is it the root of the given polynomial. Otherwise who will make the last move will win. Let we know all coefficient except one. Let this coefficient is the coefficient before xi. Let C1 is the sum for all j ≠ i  ajk j and C2 = k i ≠ 0. Then we have the equation ai * C2 =  - C1 which always have the solution. If the human will make the last move he need to write the root to the place of the coefficient, otherwise computer will write any number, but not the root.

Asymptotic behavior O(n).

Codeforces Round #353 (Div. 2) Editorial

By komendart, history, 7 years ago, translation, In EnglishSomeday I will arrange C and D correctly :)

675A - Infinite Sequence

Firstly, in case c = 0 we should output YES if a = b else answer is NO.

If b belongs to sequence b = a + k * c where k is non-negative integer.

So answer is YES if (b - a) / c is non-negative integer else answer is NO.

Code675B - Restoring Painting

x a y

b m c

z d w

Number in the center may be any from 1 to n because number in the center belongs to all subsquares 2 × 2. So, let's find answer with fixed number in the center and then multiply answer by n.

Let's iterate over all possible x. Sums of each subsquare 2 × 2 are the same so x + b + a + m = y + c + a + m and y = x + b - c.

Similarly, z = x + a - d and w = a + y - d = z + b - c.

This square is legal if 1 ≤ y, z, w ≤ n. We should just check it.

Also we can solve this problem in O(1).

Code675C - Money Transfers

We have array ai and should make all numbers in it be equal to zero with minimal number of operations. Sum of all ai equals to zero.

We can divide array into parts of consecutive elements with zero sum. If part has length l we can use all pairs of neighbours in operations and make all numbers be equal to zero with l - 1 operations.

So, if we sum number of operations in each part we get ans = n - k where k is number of parts. We should maximize k to get the optimal answer.

One of the part consists of some prefix and probably some suffix. Each of other parts is subarray of a.

Let's calculate prefix sums. Each part has zero sum so prefix sums before each part-subarray are the same.

So we can calculate f — number of occurencies of the most frequent number in prefix sums and answer will be equal to n - f.

Bonus: how to hack solutions with overflow?

Code675D - Tree Construction

We have binary search tree (BST) and should insert number in it with good time complexity.

Let we should add number x. Find numbers l < x < r which were added earlier, l is maximal possible, r is minimal possible (all will be similar if only one of this numbers exists). We can find them for example with std::set and upper_bound in C++.

We should keep sorted tree traversal (it's property of BST). So x must be right child of vertex with l or left child of vertex with r.

Let l hasn't right child and r hasn't left child. Hence lowest common ancestor (lca) of l and r doesn't equal to l or r. So lca is between l and r in tree traversal. But it's impossible because l is maximal possible and r is minimal possible. So l has right child or r has left child and we know exactly which of them will be parent of x.

That's all. Time complexity is .

Code675E - Trains and Statistic

Let the indexation will be from zero. So we should subtract one from all ai. Also let an - 1 = n - 1.

dpi is sum of shortests pathes from i to i + 1... n - 1.

dpn - 1 = 0

dpi = dpm - (ai - m) + n - i - 1 where m belongs to range from i + 1 to ai and am is maximal. We can find m with segment tree or binary indexed tree or sparse table.

Now answer equals to sum of all dpi.

Code

Codeforces Round #352 Editorial

By muratt, 7 years ago, In English672A - Летняя школаThis one is a simple brute force problem, we will construct our array. Adding numbers between 1 and 370 will be enough. After construction we just have to print n-th element of array.

672B - Разнообразие - это хорошоWe observe that in a good string all letters must be different, because all substrings in size 1 must be different. So if size of string is greater than 26 then answer must be  - 1 since we only have 26 different letters.

Otherwise, Let's suppose we have k different letters in string sized n, in our string k elements must be stay as before, all others must be changed. So will be (n — k). Here is the code.

671A - Мусор на переработкуLet's solve the problem when Adil and Bera in the same coordinate with bin. Then answer will be , let's say T to this value. If Adil will take i-th bottle and Bera will take j-th bottle (i ≠ j), then answer will be T + distance(Adil, Bottlei) - distance(Bin, Bottlei) + distance(Bera, Bottlej) - distance(Bin, Bottlej).

Because for all bottles but the chosen ones we have to add 2  *  distance(bottle,  bin).

For example if we choose a bottle i for Adil to take first then we have to add distance(Adil,  Bottlei) + distance(Bottlei,  Bin).

In defined T we already count 2 * distance(Bottlei,  Bin) but we have to count distance(Adil, Bottlei) + distance(Bottlei,  Bin) for i.

So we have to add distance(Adil,  Bottlei)-distance(Bottlei,  Bin) to T.

Because 2 * distance(Bin,  Bottlei)+distance(Adil,  Bottlei)-distance(Bin,  Bottlei) is equal to distance(Adil,  Bottlei)+distance(Bottlei,  Bin).

Lets construct two arrays, ai will be distance(Adil, Bottlei) - distance(Bin, Bottlei), and bj will be distance(Bera, Bottlej) - distance(Bin, Bottlej).

We will choose i naively, after that we have to find minimum bj where j is not equal to i. This one easily be calculated with precalculations, let's find optimal opt1 for Bera, also we will find second optimal opt2 for Bera, if our chosen i is equal to opt1 then Bera will go opt2, otherwise he will go opt1.

Don't forget to cases that all bottles taken by Adil or Bera!

Here is the code.

671B - Робин ГудWe observe that we can apply operations separately this means first we will apply all increase operations, and after will apply all decrease operations, vice versa. We will use following algorithm.

We have to apply following operation k times, add one to minimum number in array. We will simply binary search over minimum value after applying k operation. Let's look how to check if minimum will be great or equal to p. If  is less or equal to k then we can increase all elements to at least p. In this way we can find what will be minimum value after k operations.

Let's say this minimum value to m. After we find it we will increase all numbers less than m to m. But there may be some operations we still didn't apply yet, this number can be at most n - 1, otherwise minimum would be greater than m because we can increase all numbers equal to m by one with this number of increases. Since minimum has to be same we just have to increase some elements in our array that equal to m.

We will use same algorithm for decreasing operations. Finally we will print max element — min element in final array. Overall complexity will be O(nlogk).

Here is the code.

Solution with another approach code.

671C - Безграничная странность массиваIf we calculate an array H where Hi is how many (l - r)s there are that f(l,  r)  ≤  i, then we can easily calculate the answer.

How to calculate array H. Let's keep a vector, vi keeps all elements indexes which contain i as a divisor — in sorted order. We will iterate over max element to 1. When we are iterating we will keep another array next, Let's suppose we are iterating over i, nextj will keep leftmost k where f(j,  k)  ≤  i. Sometimes there is no such k, then nextj will be n + 1. Hi will be equal to , because if we choose p as l, r must be at least nextp, so for l we can choose n-nextp+1 different r s.

Let's look how we update next array when we iterate i to i - 1.

Let vi be b1, b2, b3...bk. Note that our l - r must be cover at least k - 1 of this indexes. l must less or equal to b2. So we have to maximize all nextp with n + 1 where p > b2. Otherwise If l ≥ b1 + 1 then r must be at least bk, that's we will maximize all nextp's where b1 < p ≤ b2 with bk. And finally for all nextp's where (1 ≤ p ≤ b1) we have to maximize them with bk - 1. Observe that next array will be monotonic  -  in non decreasing order  -  after all operations. So we can easily make our updates with a segment tree that can perform following operations:

 - Returns rightmost index i where nexti is less than some k.

 - Returns sum of all elements in next array.

 - Can assign some k to all elements between some l and r.

If all update and queries performed in O(logn) then overall complexity will be O(nlogn), we can also apply all this operations with STL set in same complexity.

Code with set structure: link

Code with segment tree: link

671D - Дороги в ЮсландииI want to thank GlebsHP, i originally came up with another problem similar to it, GlebsHP suggested to use this one in stead of it.

Let's look for a optimal subset of paths, paths may intersect. To prevent from this let's change the problem litte bit. A worker can repair all nodes between ui and some k, where k is in the path between ui and vi with cost ci, also paths must not intersect. In this way we will never find better solution from original problem and we can express optimal subset in original problem without any path intersections in new problem.

Let's keep a dp array, dpi keeps minimum cost to cover all edges in subtree of node i, also the edge between i and parenti. How to find answer of some i. Let's choose a worker which uj is in the subtree of i and vj is a parent of node i. Then if we choose this worker answer must be cj + (dpk where k is child of a node in the path from uj to i for all k's). Of course we have to exclude nodes chosen as k and in the path from uj to i since we will cover them with j-th worker. We will construct a segment tree by dfs travel times so that for all nodes, workers which start his path in subtree of this node can be reached by looking a contiguous segment in tree. In node i, segment will keep values what will be dpi equal to if we choose this worker to cover path between uj and parenti. We will travel our tree with dfs, in each i after we calculated node i's children dp's we will update our segment in following way, add all workers to segment where uj = i with value cj + (sum of node i's children dp's). For all workers vj equal to i, we must delete it from segment, this is assigning inf to it. The only thing we didn't handle is what to do with workers under this node. Imagine all updates in subtree of node k where k is a child of node i. We have to increase all of them by (sum of node i's children dp's-dpk). After applying all of this operations answer will be minimum value of workers start their path from a node in subtree of i in segment tree.

Overall complexity will be ((n + m)logm).

Please look at the code to be more clear.

671E - Организация гонкиIntended solution was . Here is Zlobober's  code: Link.

O(n2) SolutionLet cost(l,  r) be minimum cost to make l-r suitable for a race. In task we have to find such l-r that cost(l,  r)  ≤  k and r-l+1 is maximum.

How to calculate cost(l,  r): Let's look at how we do our increases to make race from l to r (first stage) possible. Greedily we will make our increases in right as much as possible. So if we run out of gas in road between i and i+1 we will add just enough gasoline to Gi. After make first stage possible we will add gasoline to r just enough to make second stage possible. This solution will be O(n3).

Let's find nexti, nexti will keep leftmost j that we can't reach with current gasoline, we will also keep needi that keeps how many liter gasoline we have to add to nexti-1. After applying this increase city nexti will be reachable from i, cars will be consumed all of their gasoline just before taking gasoline in city nexti.

How to find it: We will keep an array pre where prei  =  prei - 1 + Gi-Wi. If prej-prei - 1 < 0 then we can't reach to j + 1. If we find leftmost j (j ≥ i) where prej is strictly smaller than prei then nexti will be equal to j and needi will be equal to prej-prei - 1.

Building tree: Let's make a tree where nexti is father of node i. In dfs travel, when we are in a node i all increases will be made to make all first stages possible from i to all j's, now we will keep an array suff where suffi  =  suffi - 1 + Gi-Wi - 1. So when we are increasing a city u's Gu we have to increase all suff values from u to n. We will also keep another array cost, costj will keep the cost to make stage 1 possible from i to j+1. Increases will be nearly same, for u we will increase all v's costs v ≥ u. So when we reach a node i we will apply increases to make first stage possible between i ans nexti. When we are done with this node, we will revert increases.

Last part: Now we have to find rightmost j for all i's. Let's look at whether it is possible or not for a j. We can check it in O(1). First costj - 1 must be less or equal to k, also maximum(suffk i ≤ k < j)-(suffj-deltaj) + (costj-deltaj)  ≤  k. deltaj keeps how many increases we apply to node j. We will decrease them since direct increases in j are made for j+1, we don't need to keep delta array since it will not effect expression. Also observe that the only thing changes in expression is maximum(suffk i ≤ k < j). In this way problem can be solved in O(n2). Both sqrt dec. solutions are using the same idea. Main solution will be posted soon.

How to Reduce it to O(nlog2n)Let pi be costi-suffi. As we said before this value will never change.

Let's keep a segment tree. In each node we will keep such values. Assume this node of segment covers between l and r. We will keep such ind1, ind2 and mxsuff.

ind1 will keep minimum pj's index where l ≤ j ≤ r.

ind2 will keep minimum (maximum{suffl≤ k < j}+pj)'s index where mid + 1 ≤ j ≤ r this means we have to choose j from this nodes right child.

mxsuff will keep maximum{suffl≤k≤r}.

We also have to keep values for ind1 and ind2 (pind1 and (maximum{suffl≤ k < ind2}+pind2)).

How to update them: In a update we will increase some some suffixes costi and suffi values. So ind1 will be same for each node. For every covered node mxsuff will increase by k (k is increase value in update). Tricky part is how to update ind2. Let's define a function relax(). relax(u) calculates ind2 value for node u. Note that for relax function to work all nodes in subtree of u must be calculated already. We will call relax function after calculating this nodes children. We will come to relax function later.

How to query: We can use pretty much same function as relax. We have to query find values for a l-r segment. We will keep an extra value in function, let's call it t. If this node covers segment a-b then t will keep maximum{suffl≤ k < a}}. If this node doesn't intersect with l-r segment we will return worst values (for example for mx_suff value we will return -inf). Let's look what to do when this node is covered by l-r. If mxsuff value of this node's left child is greater or equal to t then ind2 value will be same. So if maximum{suffl≤ k < ind2}+pind2) is lower or equal to k for this node answer is ind2, it is greater than k then we will go this nodes left child to calculate answer. If mxsuff value of this node's left child is lower than t value then (maximum{suffl≤ j < mid}) will equal to t for each j. So we just have to rightmost j that pj  ≤  k - t in subtree of this node. This can be calculated in O(logn) time. We didn't look at right child yet, so we will go to right child again with same t value. What to do when this node intersects with l-r and l-r doesn't cover it. We will go both children, first to left, after we will update t value for right child by mxsuff value returned from left child. We will lazy prop to push values.

Other condition: In node l we have to query between l and r, r is rightmost index that costr - 1 < k. Since cost values are monotonic this r can be found easily in O(logn).

Relax function can be calculated nearly same as query. But this will work in O(logn), since we just have to go exactly one child, since we don't interested in rightmost values.

VK Cup 2016 — Round 3 — Editorial

By Radewoosh, history, 7 years ago, In EnglishEditorial was created by Errichto, but he said that he has enough contribution, so I'm posting it for you. ;)

1 673A - Bear and Game(invented by GlebsHP — thanks!)

You are supposed to implement what is described in the statement. When you read numbers ti, check if two consecutive numbers differ by more than 15 (i.e. ti - ti - 1 > 15). If yes then you should print ti - 1 + 15. You can assume that t0 = 0 and then you don't have to care about some corner case at the beginning. Also, you can assume that tn + 1 = 91 or tn + 1 = 90 (both should work — do you see why?). If your program haven't found two consecutive numbers different by more than 15 then print 90. If you still have problems to solve this problem then check codes of other participants.

18286606

2 673B - Problems for Round(invented by Errichto)

Some prefix of problems must belong to one division, and the remaining suffix must belong to the other division. Thus, we can say that we should choose the place (between two numbers) where we split problems. Each pair ai, bi (let's say that ai < bi) means that the splitting place must be between ai and bi. In other words, it must be on the right from ai and on the left from bi.

For each pair if ai > bi then we swap these two numbers. Now, the splitting place must be on the right from a1, a2, ..., am, so it must be on the right from A = max(a1, a2, ..., am). In linear time you can calculate A, and similarly calculate B = min(b1, ..., bm). Then, the answer is B - A. It may turn out that A > B though but we don't want to print a negative answer. So, we should print max(0, B - A).

18286633

3 673C - Bear and Colors(invented by Errichto)

We are going to iterate over all intervals. Let's first fix the left end of the interval and denote it by i. Now, we iterate over the right end j. When we go from j to j + 1 then we get one extra ball with color cj + 1. In one global array cnt[n] we can keep the number of occurrences of each color (we can clear the array for each new i). We should increase by one cnt[cj + 1] and then check whether cj + 1 becomes a new dominant color. But how to do it?

Additionally, let's keep one variable best with the current dominant color. When we go to j + 1 then we should whether cnt[cj + 1] > cnt[best] or (cnt[cj + 1] =  = cnt[best] and cj + 1 < best). The second condition checks which color has smaller index (in case of a tie). And we must increase answer[best] by one then because we know that best is dominant for the current interval. At the end, print values answer[1], answer[2], ..., answer[n].

18286663

4 673D - Bear and Two Paths(invented by Errichto)

There is no solution if n = 4 or k ≤ n. But for n ≥ 5 and k ≥ n + 1 you can construct the following graph:

 

Here, cities (x1, x2, ..., xn - 4) denote other cities in any order you choose (cities different than a, b, c, d). You should print (a, c, x1, x2, ..., xn - 4, d, b) in the first line, and (c, a, x1, x2, ..., xn - 4, b, d) in the second line.

Two not very hard challenges for you. Are you able to prove that the answer doesn't exist for k = n? Can you solve the problem if the four given cities don't have to be distinct but it's guaranteed that a ≠ b and c ≠ d?

18286683

5 673E - Levels and Regions(invented by Radewoosh)

When we repeat something and each time we have probability p to succeed then the expected number or tries is , till we succeed. How to calculate the expected time for one region [low, high]? For each i in some moment we will try to beat this level and then there will be S = tlow + tlow + 1 + ... + ti tokens in the bag, including ti tokens allowing us to beat this new level. The probability to succeed is , so the expected time is . So, in total we should sum up values  for i < j. Ok, we managed to understand the actual problem. You can now stop and try to find a slow solution in O(n2·k). Hint: use the dynamic programming.

Let dp[i][j] denote the optimal result for prefix of i levels, if we divide them into j regions.Let pre[i] denote the result for region containing levels 1, 2, ..., i (think how to calculate it easily with one loop).Let sum[i] denote the sum of tj for all 1 ≤ j ≤ i.Let rev[i] denote the sum of  for all 1 ≤ j ≤ i.Now let's write formula for dp[i][j], as the minimum over l denoting the end of the previous region:



So we can use convex hull trick to calculate it in O(n·k). You should also get AC with a bit slower divide&conquer trick, if it's implemented carefully.

18286696

6 673F - Bearish Fanpages(invented by Radewoosh)

Let's say that every company has one parent (a company it follows). Also, every copmany has some (maybe empty) set of children. It's crucial that sets of children are disjoint.

For each company let's keep (and always update) one value, equal to the sum of:

the income from its own fanpagethe income from its children's fanpagesIt turns out that after each query only the above sum changes only for a few values. If a starts to follows b then you should care about a, b, par[a], par[b], par[par[a]]. And maybe par[par[b]] and par[par[par[a]]] if you want to be sure. You can stop reading now for a moment and analyze that indeed other companies will keep the same sum, described above.

Ok, but so far we don't count the income coming from parent's fanpage. But, for each company we can store all its children in one set. All children have the same "income from parent's fanpage" because they have the same parent. So, in set you can keep children sorted by the sum described above. Then, we should always puts the extreme elements from sets in one global set. In the global set you care about the total income, equal to the sum described above and this new "income from parent". Check codes for details. The complexity should be , with big constant factor.

18286747

7 674E - Bear and Destroying Subtrees(invented by Errichto)

Let dp[v][h] denote the probability that subtree v (if attacked now) would have height at most h. The first observation is that we don't care about big h because it's very unlikely that a path with e.g. 100 edges will survive. Let's later talk about choosing h and now let's say that it's enough to consider h up to 60.

When we should answer a query for subtree v then we should sum up h·(dp[v][h] - dp[v][h - 1]) to get the answer. The other query is harder.

Let's say that a new vertex is attached to vertex v. Then, among dp[v][0], dp[v][1], dp[v][2], ... only dp[v][0] changes (other values stay the same). Also, one value dp[par[v]][1] changes, and so does dp[par[par[v]]][2] and so on. You should iterate over MAX_H vertices (each time going to parent) and update the corresponding value. TODO — puts here come formula for updating value.

The complexity is O(q·MAX_H). You may think that MAX_H = 30 is enough because  is small enough. Unfortunately, there exist malicious tests. Consider a tree with  paths from root, each with length 31. Now, we talk about the probability of magnitude:

1 - (1 - (1 / 2)d)N / dwhich is more than 10 - 6 for d = 30.

http://www.wolframalpha.com/input/?i=1+-+(1-(1%2F2)%5Ed)%5E(N%2Fd)+for+N+%3D+500000+and+d+%3D+30

18286721

8 674F - Bears and Juice(invented by Radewoosh)

Let's start with O(q·p2) approach, with the dynamic programming. Let dp[days][beds] denote the maximum number of barrels to win if there are days days left and beds places to sleep left. Then:

Here, i represents the number of bears who will go to sleep. If the same i bears drink from the same X barrels and this exact set of bears go to sleep then on the next day we only have X barrels to consider (wine is in one of them). And for X = dp[days - 1][beds - i] we will manage to find the wine then.

And how to compute the dp faster? Organizers have ugly solution with something similar to meet in the middle. We calculate dp for first q2 / 3 days and later we use multiply vectors by matrix, to get further answers faster. The complexity is equivalent to O(p·q) but only because roughly q = p3. We saw shortest codes though. How to do it guys?

You may wonder why there was 232 instead of 109 + 7. It was to fight with making the brute force faster. For 109 + 7 you could add sum +  = dp[a][b]·dp[c][d] about 15 times (using unsigned long long's) and only then compute modulo. You would then get very fast solution.

18286766

9 674G - Choosing Ads(invented by qwerty787788)

Let's first consider a solution processing query in O(n) time, but using O(1) extra memory. If p = 51%, it's a well known problem. We should store one element and some balance. When processing next element, if it's equal to our, we increase balance. If it's not equal, and balance is positive, we decrease it. If it is zero, we getting new element as stored, and setting balance to 1.

To generalize to case of elements, which are at least 100/k%, we will do next. Let's store k elements with balance for each. When getting a new element, if it's in set of our 5, we will add 1 to it's balance. If we have less, than 5 elements, just add new element with balance 1. Else, if there is element with balance 0, replace it by new element with balance one. Else, subtract 1 from each balance. The meaning of such balance becomes more mysterious, but it's not hard to check, that value is at least 100/k% of all elements, it's balance will be positive.

To generalize even more, we can join two of such balanced set. To do that, we sum balances of elements of all sets, than join sets to one, and then removing elements with smallest balance one, by one, untill there is k elements in set. To remove element, we should subtract it's balance from all other balances.

And now, we can merge this sets on segment, using segment tree. This solution will have complexity like n * log(n) * MERGE, where MERGE is time of merging two structures. Probably, when k is 5, k2 / 2 is fastest way. But the profit is we don't need complex structures to check which elements are really in top, so solution works much faster.

Codeforces Round #350 (Div.2) Editorial

By fcspartakm, history, 7 years ago, translation, In English670A - HolidaysThere are many ways to solve this problem. Let's talk about one of them. At first we need to write a function, which takes the start day of the year and calculate the number of days off in such year. To make it let's iterate on the days of the year and will check every day — is it day off or no. It is easy to show that if the first day of the year equals to the first day of the week (i.e. this day is Monday) in this year will be minimum possible number of the days off. If the first day of the year equals to the first day off of the week (i.e. this day is Saturday) in this year will be maximum possible number of the days off.

670B - Game of RobotsTo solve this problem we need to brute how many identifiers will called robots in the order from left to right. Let's solve this problem in one indexing. Let the current robot will call i identifiers. If k - i > 0 let's make k = k - i and go to the next robot. Else we need to print a[k], where a is the array with robots identifiers and end our algorithm.

670C - CinemaWe need to use map-ом (let's call it cnt) and calculate how many scientists knows every language (i. e. cnt[i] equals to the number of scientists who know the language number i). Let's use the pair res, where we will store the number of \textit{very pleased} scientists and the number of \textit{almost satisfied} scientists. At first let res = make_pair(0, 0). Now we need to iterate through all movies beginning from the first. Let the current movie has the number i. Then if res < make_pair(cnt[b[i]], cnt[a[i]]) let's make res = make_pair(cnt[b[i]], cnt[c[i]]) and update the answer with the number of current movie.

670D1 - Magic Powder - 1This problem with small constraints can be solved in the following way. Let's bake cookies one by one until it is possible. For every new cookie let's calculate val — how many grams of the magic powder we need to bake it. For this let's brute all ingredients and for the ingredient number i if a[i] ≤ b[i] let's make b[i] = b[i] - a[i], else let's make b[i] = 0 and val = val + a[i] - b[i]. When we bruted all ingredients if val > k than we can't bake more cookies. Else let's make k = k - val and go to bake new cookie.

670D2 - Magic Powder - 2Here we will use binary search on the answer. Let's we check the current answer equals to cur. Then the objective function must be realized in the following way. Let's store in the variable cnt how many grams of the magic powder we need to bake cur cookies. Let's iterate through the ingredients and the current ingredient has the number i. Then if a[i]·cur > b[i] let's make cnt = cnt + a[i]·cur - b[i]. If after looking on some ingredient cnt becomes more than k the objective function must return false. If there is no such an ingredient the objective function must return true.

If the objective function returned true we need to move the left end of the binary search to the cur, else we need to move the right end of the binary search to the cur.

670E - Correct Bracket Sequence EditorLet's solve this problem in the following way. At first with help of stack let's calculate the array pos, where pos[i] equals to the position of the bracket which paired for the bracket in the position i. Then we need to use two arrays left and right. Then left[i] will equals to the position of the closest to the left bracket which did not delete and right[i] will equals to the position of the closest to the right bracket which did not delete. If there are no such brackets we will store -1 in the appropriate position of the array.

Let's the current position of the cursor equals to p. Then if the current operation equals to \texttt{L} let's make p = left[p] and if the current operation equals to \texttt{R} let's make p = right[p]. We need now only to think how process the operation \texttt{D}.

Let lf equals to p and rg equals to pos[p]. If lf > rg let's swap them. Now we know the ends of the substring which we need to delete now. If right[rg] =  =  - 1 we need to move p to the left (p = left[lf]), else we need to move p to the right (p = right[rg]). Now we need to recalculate the links for the ends of the deleted substring. Here we need to check is there any brackets which we did not deleted to the left and to the right from the ends of the deleted substring.

To print the answer we need to find the position of the first bracket which we did not delete and go through all brackets which we did not delete (with help of the array right) and print all such brackets. To find the position of the first bracket which we did not delete we can store in the array all pairs of the ends of substrings which we deleted, then sort this array and find the needed position. Bonus: how we can find this position in the linear time?

670F - Restore a NumberAt first let's find the length of the Vasya's number. For make this let's brute it. Let the current length equals to len. Then if len equals to the difference between the length of the given string and the number of digits in len if means that len is a length of the Vasya's number.

Then we need to remove from the given string all digits which appeared in the number len, generate three strings from the remaining digits and choose smaller string from them — this string will be the answer. Let t is a substring which Vasya remembered. Which three strings do we need to generate?

Let's write the string t and after that let's write all remaining digits from the given string in the ascending order. This string can be build only if the string t does not begin with the digit 0.

Let's write at first the smallest digit from the remaining digits which does not equal to 0. If we have no such a digit we can't build such string. Else we need then to write all digits with smaller than the first digit in the t in the ascending order, then write the string t and then write all remaining digits in the ascending order.

Let's write at first the smallest digit from the remaining digits which does not equal to 0. If we have no such a digit we can't build such string. Else we need then to write all digits with smaller than or equal to the first digit in the t in the ascending order, then write the string t and then write all remaining digits in the ascending order.

Also we need to separately consider the case when the Vasya's number equals to zero.

Codeforces Round #349 Editorial

By ifsmirnov, history, 7 years ago, translation, In English667A - Pouring Rain

To know how much water you consume per second you should divide consumed volume, v, by the area of the cup, . Then you should compare thisit with e. If your speed of drinking is greater, then you'll drink all the water in  seconds. Otherwise you would never do it.

667B - Coat of Anticubism

It is possible to make a convex polygon with given side lengths if and only if a generalized triangle inequality holds: the length of the longest side is less than the sum of lengths of other sides. It is impossible to make a convex polygon from a given set, so there is a side which is longest than (or equals to) than sum of others. Assume it is greater by k; then it is sufficient to add a rod of length k + 1. More, it is clear that adding any shorter length wouldn't satisfy the inequality. Thus the answer for the problem is .

666A - Reberland Linguistics / 667C - Reberland Linguistics

This problem is solved with dynamic programming. We can select an arbitrary root of any length (at least five). Let's reverse the string. A boolean value dp2, 3[n] denotes if we could split a prefix of length n to a strings of length 2 and 3 so that the last string has a corresponding length. Transitions: . Similarly, . If any of dpk[n] is true we add the corresponding string to the set of answers.

666B - World Tour / 667D - World Tour

You are given the oriented graph, find four distinct vertices a, b, c, d such that each vertex if reachable from previous and the sum of shortest paths between consequitive vertices is as large as possible. First let's run a BFS from each vertex and find three most distant vertices over given graph and its reverse. Afterwards loop through each possible b and c. Having them fixed, loop through a among three most distant vertices from b in the reversed graph and through d among three most distant vertices from c in tie initial graph. This is sufficient, because if we've fixed b and c and d is not one of three furthest from c then we could replace it with one of them and improve the answer.

666C - Codeword

The first thing to notice: string itself does not matter, only its length does. In each sequence of length n containing a fixed subsequence s we can select s's lexicographically minimal occurance, let it be p1, ..., p|s|. No character sk + 1 may occur between pk and pk + 1 - 1, because otherwise the occurence is not lex-min. On the other hand, if there is an occurence which satsfies this criterion than it is lex-min.

Given this definition we can count number of strings containing given string as a subsequence. At first select positions of the lex-min occurance; there are  ways to do it. Next, you can use any of Σ - 1 characters at first s intervals between pi, and any of Σ at the end of the string. (Here, Σ denotes alphabet size).

Looping through p|s| — the position of last character in s in the lex-min occurence, we can count that there are exactly  strings containing s as a subsequence. So, having |s| fixed, answer for each n could be computed in linear time.

A final detail: input strings can have at most  different lengths. Thus simply applying the overmentioned formula we get a  solution, which was the expected one.

666D - Chain Reaction / 667E - Chain Reaction

You are given four points on the plain. You should move each of them up, down, left, or right, such that the new configuration is a square with positive integer sides parallel to coordinate axes.

Choose some d, length of the square side, and (x, y), the position of the bottom-left point. A set from where to choose will be constructed later. Then fix one of 24 permutations of initial points: first goes to the bottom-left point of the square, second goes to the bottom-right, etc. Having it fixed it is easy to check if this configuration is valid and relax the answer if needed. The only question is where to look for d, x and y.

First we deal with d. You can see that there are always two points which move among parallel but not the same lines. In this case d is the distance between these lines, i.e. one of |xi - xj| or |yi - yj|. This is the set from where d will be chosen.

Now fix d from the overmentioned set and look at two cases.

There are two points moving by perpendicular lines. Then there is a square vertex in the point of these lines intersection. In each coordinate this point either equals to bottom-left point of the square or differs by exactly d. Thus if bottom-left point has coordinates (x0, y0), than x0 must be some of xi, xi + d, xi - d, similarly for y0. Add all this values to the set.All points are moving among parallel lines; WLOG horisontal. Let's fix a permutation of points (yes, once again) and shift each point in such a way that after moving it would equal the bottom-left vertex of the square. Second point should be shifted by ( - d, 0), third by (0,  - d), fourth by ( - d,  - d). All four points must be on the same line now; otherwise this case is not possible with this permutation. Now the problem is: given four points on a line, move it to the same point minimizing the maximal path. Clearly, one should move points to the position (maxX - minX) / 2; rounding is irrelevant because of the constraint of integer answer. So, having looked through each permutations, we have another set for bottom-left vertex possible coordinates.By the way, the 10th test (and the first test after pretests) was case 2; it was intentionally not included in pretests.

Why does it work fast? Let D and X be the sizes of corresponding lookup sets. . Now for each d there are 4·3 = 12 coordinates in the first case and no more than 4! = 24 in the second. Thus X ≤ 12·(12 + 24) = 432. The main part works in ; however, it is impossible to build a test where all permutations in the second case give a valid position, so you can reduce this number. Actually, the model solution solves 50 testcases in 10ms without any kind of pruning.

666E - Forensic Examination

You are given string s and m strings ti. Queries of type ``find the string ti with number from [l;r] which has the largest amount of occurrences of substring s[a,  b]'' approaching. Let's build segment tree over the texts t_i. In each vertex of segment tree let's build suffix automaton for the concatenation of texts from corresponding segment with delimeters like a#b. Also for each state in this automaton we should found the number of text in which this state state occurs most over all texts from the segment. Also for each state v in this automaton we should find such states in children of current segment tree vertex that include the set of string from v. If you maintain only such states that do not contain strings like a#b, it is obvious that either wanted state exists or there is no occurrences of strings from v in the texts from child's segment at all. Thus, to answer the query, firstly we find in root vertex the state containing string s[a;b], and after this we go down the segment tree keeping the correct state via links calculated from the previous state.

Please refer to the code if something is unclear.

VK Cup 2016 — Раунд 2 (editorial)

By AlexFetisov, history, 7 years ago, In EnglishProblem A (div2):It is obvious that we need to make sequence of moves like: 1, 2, 1, 2, ...

So the answer is 2 * n / 3. After that we have either 0, 1 or 2 stones left. If we have 0, we are done, otherwise we have 1 or 2 left, so we only can give 1 more stone.

Final formula is: (2 * n) / 3 + (n % 3 != 0 ? 1 : 0);

Problem B (div2):We can just emulate grasshopper behavior and save all positions it visits. It is obvious that we will have no more than O(n) different positions. If grasshopper appears in the same position twice that means that there is a loop and the answer is INFINITE. Otherwise the answer is FINITE.

Problem A(div1)/C(div2):Let's have 2 matrices: a, idx. In a we will have NULL for cell if we don't know the value or the value. idx will be initialized with idx[i][j] = {i, j}; Then we need to emulate the process on matrix idx. If we have 3rd query we can set up the value in matrix a, because we know the original position of that cell keeping idx.

Problem B(div1)/D(div2):The key in this problem is that order of all elements in odd positions and in even positions is the same. Let's say we have 2 arrays: [1, 3, 5, ...] and [2, 4, ...] (odd positions and even positions). Now if we call 2nd commands we just swap these 2 arrays, but order is the same. Obviously 1st command also keeps the order. By order I mean cyclic order (right neighbor is the same in cycle position).

Let's just keep the position of 1st boy and 2nd boy. Now if we apply 1st operation we move it by X or -X. Second type of the query just swaps the positions. In the end we can construct the answer if we know positions of 1st and 2nd boys.

Problem C(div1):First, let's solve inverse problem: find minimum (maximum) of two distributions. Let's use the following formulas:

P(a = k) = P(a <= k) — P(a <= k-1) P(max(a, b) <= k) = P(a <= k) * P(b <= k)

For minimum:

P(min(a, b) >= k) = P(a >= k) * P(b >= k) = (1 — P(a <= k-1)) *(1 — P(b <= k-1))

Now in our original problem minimum and maximum defines system of square equations for each pair P(a <= k), P(b <= k).

Solving these equations we get P(a<=k), P(b<=k) = (u + v ± sqrt((u + v)^2 — 4u)) / 2, where u = P(max(a,b) <= k), v = P(min(a,b) <= k). Now we can notice that if there exists an answer, then there exists an answer when we chose the signs for each pair equally (check out this comment)

Problem D(div1)/E(div2):There are many ways to solve this problem. One of the ways was SQRT-decomposition. First let's compress all times. Now for each block in the decomposition we will store for each element the balance in that block. So to answer the query we need to calculate sum of balances from first block to the block before the one where our element is located and then just process all requests in the current block.

Another way was to use data structure from std library, described here. For each element we have two trees: remove times and add times. Then by getting order of the time in remove and add tree we can calculate the answer.

Problem E(div1):Let's build for both 2-SAT formulas implication graph and let's find strong connected components in this graph. If both of the formulas are not satisfiable then the answer is SIMILAR. If only one formula is not satisfiable then we can find an answer for the second one and output it.

Now, let's assume both formulas are satisfiable. Let's have a transitive closure for both of the graphs. Let's call the variable X fixed in the formula F if there is a path -> x or (x -> ). If there is a fixed variable in one formula, but not fixed in the other (or fixed but has other value) we can find the solution for that second formula with opposite value of that fixed variable — that will be an answer. If we could not find these variables, we can remove all of them. There is no fixed variables in the rest of them. Let's find an edge u->v, presented in one graph, but not presented in the other. Let's find the solution for formula without the edge with u = 1 and v = 0 (we always can find it). That is the answer.

Problem F(div1):Let's define k-clique B the descendant of k-clique A, if B could be produced from A with the sequence of the following steps: add vertex to the clique, connected with all clique vertices in the graph description and remove exactly one other vertex. Let's calculate the DP with states (k-clique, separation its vertices to the components) — number of spanning forests int the graph, induced by the clique and all its descendants so that clique will be divided to different connected components according to the defined vertices separation (all of the rest vertices will be connected with some of these components). To calculate that we need to precalculate all separations from k to k+1 elements and transitions:

1) (separation of k+1 vertices) x (separation k+1 vertices) -> (separation k+1 vertices | null), transform pair of separations — forests to the set of connected components of their union or null if there appears a cycle.

2) (separation of k+1 vertices) x (vertex) -> (separation of k+1 vertices | null), transform forest to the new forest, generated by adding new edge from vertex to vertex k+1 (or null, if there appears a cycle)

3) (separation of k+1 vertices) -> (separation of k vertices | null), projecting the separation on the first k vertices (or null, if k+1-th vertex creates a separate component)

Check out details in the author solution.

Full text and comments »

Editorial for CROC 2016 Finals and Codeforces Round #347

By Alex_2oo8, 7 years ago, translation, In English664A - Complicated GCDAuthor of the idea — GlebsHP

We examine two cases:

a = b — the segment consists of a single number, hence the answer is a.a < b — we have gcd(a, a + 1, a + 2, ..., b) = gcd(gcd(a, a + 1), a + 2, ..., b) = gcd(1, a + 2, ..., b) = 1.Code663A - RebusAuthor of the idea — gen

First we check whether any solution exists at all. For that purpose, we calculate the number of positive (the first one and any other with the  +  sign) and negative elements (with the  -  sign) in the sum. Let them be pos and neg, respectively. Then the minimum value of the sum that can be possibly obtained is equal to min = (1 · pos - n · neg), as each positive number can be 1, but all negative can be  - n. Similarly, the maximum possible value is equal to max = (n · pos - 1 · neg). The solution therefore exists if and only if min ≤ n ≤ max.

Now suppose a solution exists. Let's insert the numbers into the sum one by one from left to right. Suppose that we have determined the numbers for some prefix of the expression with the sum of S. Let the sign of the current unknown be sgn ( + 1 or  - 1) and there are some unknown numbers left to the right, excluding the examined unknown, among them pos_left positive and neg_left negative elements. Suppose that the current unknown number takes value x. How do we find out whether this leads to a solution? The answer is: in the same way we checked it in the beginning of the solution. Examine the smallest and the largest values of the total sum that we can get. These are equal to min_left = (S + sgn · x + pos_left - n · neg_left) and max_left = (S + sgn · x + n · pos_left - neg_left), respectively. Then we may set the current number to x, if min_left ≤ n ≤ max_left holds. To find the value of x, we can solve a system of inequalities, but it is easier simply to check all possible values from 1 to n.

BONUS Let k be the number of unknowns in the rebus. Prove that the complexity of the described solution (implementation shown below) is O(k2 + n), not O(k · n).

Code662D - International OlympiadAuthor of the idea — Alex_2oo8

Consider the abbreviations that are given to the first Olympiads. The first 10 Olympiads (from year 1989 to year 1998) receive one-digit abbreviations (IAO'9, IAO'0, ..., IAO'8). The next 100 Olympiads (1999 - 2098) obtain two-digit abbreviations, because all one-digit abbreviations are already taken, but the last two digits of 100 consecutive integers are pairwise different. Similarly, the next 1000 Olympiads get three-digit abbreviations and so on.

Now examine the inversed problem (extract the year from an abbreviation). Let the abbreviation have k digits, then we know that all Olympiads with abbreviations of lengths (k - 1), (k - 2), ..., 1 have passed before this one. The number of such Olympiads is 10k - 1 + 10k - 2 + ... + 101 = F and the current Olympiad was one of the 10k of the following. Therefore this Olympiad was held in years between (1989 + F) and (1989 + F + 10k - 1). As this segment consists of exactly 10k consecutive natural numbers, it contains a single number with a k-digit suffix that matches the current abbreviation. It is also the corresponding year.

Code662B - Graph ColoringAuthor of the problem — gen

Examine the two choices for the final color separately, and pick the best option afterwards. Now suppose we want to color the edges red.

Each vertex should be recolored at most once, since choosing a vertex two times changes nothing (even if the moves are not consecutive). Thus we need to split the vertices into two sets S and T, the vertices that are recolored and the vertices that are not affected, respectively. Let u and v be two vertices connected by a red edge. Then for the color to remain red, both u and v should belong to the same set (either S or T). On the other hand, if u and v are connected by a blue edge, then exactly one of the vertices should be recolored. In that case u and v should belong to different sets (one to S and the other to T).

This problem reduces to 0-1 graph coloring, which can be solved by either DFS or BFS. As the graph may be disconnected, we need to process the components separately. If any component does not have a 0-1 coloring, there is no solution. Otherwise we need to add the smallest of the two partite sets of the 0-1 coloring of this component to S, as we require S to be of minimum size.

Code662A - Gambling NimAuthor of the idea — GlebsHP

It is known that the first player loses if and only if the xor-sum of all numbers is 0. Therefore the problem essentially asks to calculate the number of ways to arrange the cards in such a fashion that the xor-sum of the numbers on the upper sides of the cards is equal to zero.

Let  and . Suppose that the cards with indices j1, j2, ..., jk are faced with numbers of type b and all the others with numbers of type a. Then the xor-sum of this arrangement is equal to , that is, . Hence we want to find the number of subsets ci with xor-sum of S.

Note that we can replace c1 with , as applying c1 is the same as applying . Thus we can freely replace {c1, c2} with  and c2 with . This means that we can apply the following procedure to simplify the set of ci:

Pick cf with the most significant bit set to oneReplace each ci with the bit in that position set to one to Remove cf from the setRepeat steps 1-5 with the remaining setAdd cf back to the setAfter this procedure we get a set that contains k zeros and n - k numbers with the property that the positions of the most significant bit set to one strictly decrease. How do we check now whether it is possible to obtain a subset with xor-sum S? As we have at most one number with a one in the most significant bit, then it tells us whether we should include that number in the subset or not. Similarly we apply the same argument for all other bits. If we don't obtain a subset with the xor-sum equal to S, then there is no such subset at all. If we do get a subset with xor-sum S, then the total number of such subsets is equal to 2k, as for each of the n - k non-zero numbers we already know whether it must be include in such a subset or not, but any subset of k zeros doesn't change the xor-sum. In this case the probability of the second player winning the game is equal to , so the first player wins with probability .

Code662C - Binary TableAuthor of the idea — Alex_2oo8

First let's examine a slow solution that works in O(2n · m). Since each row can be either inverted or not, the set of options of how we can invert the rows may be encoded in a bitmask of length n, an integer from 0 to (2n - 1), where the i-th bit is equal to 1 if and only if we invert the i-th row. Each column also represents a bitmask of length n (the bits correspond to the values of that row in each of the n rows). Let the bitmask of the i-th column be coli, and the bitmask of the inverted rows be mask. After inverting the rows the i-th column will become . Suppose that  contains  ones. Then we can obtain either k or (n - k) ones in this column, depending on whether we invert the i-th column itself. It follows that for a fixed bitmask mask the minimum possible number of ones that can be obtained is equal to .

Now we want to calculate this sum faster than O(m). Note that we are not interested in the value of the mask  itself, but only in the number of ones it contains (from 0 to n). Therefore we may group the columns by the value of . Let dp[k][mask] be the number of such i that , then for a fixed bitmask mask we can calculate the sum in O(n) — .

What remains is to calculate the value of dp[k][mask] in a quick way. As the name suggests, we can use dynamic programming for this purpose. The value of dp[0][mask] can be found in O(m) for all bitmasks mask: each column coli increases dp[0][coli] by 1. For k > 0, coli and mask differ in exactly k bits. Suppose mask and coli differ in position p. Then coli and  differ in exactly (k - 1) bits. The number of such columns is equal to , except we counted in also the number of columns coli that differ with  in bit p (thus, mask and coli have the same value in bit p). Thus we need to subtract dp[k - 2][mask], but again, except the columns among these that differ with mask in bit p. Let ; by expanding this inclusion-exclusion type argument, we get that the number of masks we are interested in can be expressed as dp[k - 1][next] - dp[k - 2][mask] + dp[k - 3][next] - dp[k - 4][mask] + dp[k - 5][next] - .... By summing all these expressions for each bit p from 0 to n, we get dp[k][mask] · k, since each column is counted in k times (for each of the bits p where the column differs from mask).

Therefore, we are now able to count the values of dp[k][mask] in time O(2n · n3) using the following recurrence:



This is still a tad slow, but we can speed it up to O(2n · n2), for example, in a following fashion:

  



BONUS Are you able to come up with an even faster solution?

Code662E - To Hack or not to HackAuthor of the idea — Alex_2oo8

Observation number one — as you are the only participant who is able to hack, the total score of any other participant cannot exceed 9000 (3 problems for 3000 points). Hence hacking at least 90 solutions automatically guarantees the first place (the hacks alone increase the score by 9000 points).

Now we are left with the problem where the number of hacks we make is at most 90. We can try each of the 63 possible score assignments for the problems in the end of the round. As we know the final score for each problem, we can calculate the maximum number of hacks we are allowed to make so the problem gets the assigned score. This is also the exact amount of hacks we will make in that problem. As we know the number of hacks we will make, we can calculate our final total score. Now there are at most 90 participants who we can possibly hack. We are interested only in those who are on top of us. By hacking we want to make their final score less than that of us. This problem can by solved by means of dynamic programming:

dp[p][i][j][k] — the maximum number of participants among the top p, whom we can push below us by hacking first problem i times, second problem j times and third problem k times.

The recurrence: we pick a subset of solutions of the current participant that we will hack, and if after these hacks we will push him below us, we update the corresponding dp state. For example, if it is enough to hack the first and the third problems, then dp[p + 1][i + 1][j][k + 1] = max(dp[p + 1][i + 1][j][k + 1], dp[p][i][j][k] + 1)

BONUS Can you solve this problem if each hack gives only 10 points, not 100?

Code

Editorial for Codeforces Round #346 (Div. 2)

By IlyaLos, history, 7 years ago, translation, In English659A — Round House

The answer for the problem is calculated with a formula ((a - 1 + b)  n + n)  n + 1.

Such solution has complexity O(1).

There is also a solution with iterations, modelling every of |b|'s Vasya's moves by one entrance one by one in desired direction, allowed to pass all the tests.

This solution's complexity is O(|b|).

659B — Qualifying Contest

Let's consider the participants from every region separately. So for every region we just need to sort all of its participants by their score in non-increasing order. The answer for a region is inconsistent if and only if the score of the second and the third participant in this order are equal, otherwise the answer is the first and the second participant in this order.

The solution complexity is .

659C — Tanya and Toys

Our task is to take largest amount of toys Tanya doesn't have yet the way the sum of their costs doesn't exceed m. To do that one can perform greedy algorithm: let's buy the cheepest toy Tanya doesn't have at every step, while the amount of money left are sufficient to do that. The boolean array used can be a handle in that, storing true values in indices equal to toy types which Tanya does have at the moment. As soon as 109 money is sufficient to buy no more than 105 toys , used is enough to be sized 2 × 105 (we won't buy the toys with types numbered greater). So we just need to iterate over the number of type we want to buy, and if corresponding value in used is equal to false, we should buy it, otherwise we can't.

The solution complexity is .

One can use the <> data structure (C++ \texttt{std::set}, for example), for storing the types Tanya has at the moment. In this case the complexity is .

659D — Bicycle Race

From the track description follows that Maria moves the way that the water always located to the right from her, so she could fall into the water only while turning left. To check if the turn is to the left, let's give every Maria's moves directions a number: moving to the north — 0, moving to the west — 1, to the south — 2 and to the east — 3. Then the turn is to the left if and only if the number of direction after performing a turn dir is equal to the number before performing a turn oldDir plus one modulo 4 .

This solution has complexity O(n).

One can solve this problem in alternative way. Let the answer be equal to x (that means that the number of inner corners of 270 degrees equals x, but the number of inner corners of 90 degrees to n - x). As soon as the sum of the inner corners' values of polygon of n vertices is equal to 180 × (n - 2), then x × 270 + (n - x) × 90 equals to 180 × (n - 2). This leads us to , being the answer for the problem calculated in O(1).

659E — New Reform

One should notice, that for every connected component of the graph the problem could be solved independently, so we just need to solve the problem for any connected graph.

Let this connected graph (of n vertices) contain n - 1 edge (such is called a tree). If one maintain a DFS from any of its vertex, every edge will be oriented, and each of them could given to its ending vertex, this way every vertex (except the one we launched DFS from, that is the root) will be satisfied by an edge. In this case the answer is equal to 1.

Let's then deal with a case when the graph contains more than n - 1 edges. This graph contains at least one cycle. Let's take arbitrary vertex from any of the cycles and launch a DFS (as above) from it. All vertices except chosen will be satisfied, so we are to give an edge to the chosen vertex. As soon as chosen vertex belongs to a cycle, at least one of its edge will not be taken to account in the DFS, so it can be given to a root. This way all the vertices will be satisfied.

Now we are able to solve the task for any connected graph, so we are to divide the graph into a connected components — this can be easily done by DFS or BFS.

The solution complexity is O(n + m).

659F — Polycarp and Hay

In this task one should find a connected area, in which the product of the minimum value of the cells and the number of the cells is equal to k. To find such, let's sort all the n × m cells by their values by non-increasing order. Then we will consecutively add them in this order one by one, maintaining a connected components on their neighbouring relations graph. It's enough to use Disjoint Set Union structure to do so, storing additionally size of every component.

Let ai, j be the last added element in some component id, so ai, j has the minimum value among all the cells in component id (according to our ordering). If ai, j does not divide k, then the component id could not consist of desired area. Otherwise (ai, j is divisor of k), let's find need = k / ai, j — desired area size (if it contains ai, j), and if CNTid is not less than need, then the component id contains desired area, which could be easily found by launching a DFS in a neighbouring relation graph from ai, j, visiting only the ap, q ≥ ai, j and exactly need of them.

The solution complexity is .

659G — Fence Divercity

Let the answer for the problem be the sum



where calc(l, r) is the number of ways to cut the top part of the fence the way its leftmost part is in position l and the rightmost in position r. If l = r, that is the case when the cutted top part consists of part of only one board, then calc(l, r) = hl - 1.

Let r > l, then



In other words, the number of ways to cut the top part of some board is equal to minimum value among heights of it and its neighbours minus one, otherwise the cutted part will be inconsistent. Leftmost board and rightmost board are considered separately, because each of them does have only one neighbouring board. So the answer looks like



The first summand is easy to calculate, so let's take a look at the second. Let us modify it as the following:



Let



Let's take a look how does the S(r) change after increasing r by one:

S(r + 1) = S(r) × min(hr - 1 - 1, hr - 1, hr + 1 - 1) + min(hr - 1, hr + 1 - 1).

This way this sum is easy to maintain if consecutively increase r from 2 to n.

The solution complexity is O(n).

Codeforces Round #345: editorial

By romanandreev, 7 years ago, In English651A - JoysticksIdea author: fcspartakm, preparation: fcspartakm.

Main idea is that each second we need to charge the joystick with lowest power level. We can just emulate it or get an O(1) formula, because process is very simple.

651B - Beautiful PaintingsIdea author: fcspartakm, preparation: fcspartakm.

Lets look at the optimal answer. It will contain several segment of increasing beauty and between them there will be drops in the beautifulness. Solution is greedy. Lets sort all paintings and lets select which of them will be in the first increasing segment. We just go from left to right and select only one painting from each group of several paintings with the fixed beauty value. We continue this operation while there is at least one painting left.

With the careful implementation we will get  solution.

But this solution gives us the whole sequence, but the problem was a little bit easier — to determine number of such segments. From the way we construct answer it is easy to see that the number of segments always equal to the maximal number of copies of one value. Obviously we can't get less segments than that and our algorithm gives us exactly this number. This solution is O(n).

651C - Watchmen/650A - WatchmenIdea author: ipavlov, preparation: ipavlov.

When Manhattan distance equals to Euclidean distance?

deu2 = (x1 - x2)2 + (y1 - y2)2

dmh2 = (|x1 - x2| + |y1 - y2|)2 = (x1 - x2)2 + 2|x1 - x2||y1 - y2| + (y1 - y2)2

So it is true only when x1 = x2 or y1 = y2. This means that to count the number of such pair we need to calculate number of points on each horizontal line and each vertical line. We can do that easily with the use of std::map/TreeMap/HashMap/Dictionary, or just by sorting all coordinates.

If we have k points on one horizontal or vertical line they will add k(k - 1) / 2 pairs to the result. But if we have several points in one place we will count their pairs twice, so we need to subtract from answer number of pairs of identical points which we can calculate with the same formula and using the same method of finding equal values as before.

If we use TreeMap/sort then solution will run in  and if unordered_map/HashMap then in O(n).

651D - Image Preview/650B - Image PreviewIdea author: fcspartakm, preparation: fcspartakm.

What photos we will see in the end? Some number from the beginning of the gallery and some from the end. There are 4 cases:

We always go right.We always go left.We initially go right, then reverse direction, go through all visited photos and continue going left.We initially go left, then reverse direction, go through all visited photos and continue going right.First two cases are straightforward, we can just emulate them. Third and fourth cases can be done with the method of two pointers. Note that if we see one more picture to the right, we spend more time on the right side and the number of photos seen to the left will decrease.

This solution will run in O(n).

Alternative solution is to fix how many photos we've seen to the right and search how many we can see to the left with binary search. For this method we will need to precompute times of seeing k pictures to the right and to the left. But this is solution is , which is slightly worse then previous one, but maybe it is easier for somebody.

651E - Table Compression/650C - Table CompressionIdea author: LHiC, preparation: iskhakovt.

First we will solve our problem when all values are different. We will construct a graph, where vertices are cells (i,  j) and there is an edge between two of them if we know that one is strictly less then the other and this relation should be preserved. This graph obviously has no cycles, so we can calculate answer as dynamic programming on the vertices:

for ( (u, v) : Edges) {	dp[v] = max(dp[v], dp[u] + 1);}We can do this with topological sort or with lazy computations.

But if we will construct our graph naively then it will contain O(nm(n + m)) edges. To reduce this number we will sort each row and column and add edges only between neighbours in the sorted order. Now we have O(nm) edges and we compute them in  time.

But to solve the problem completely in the beginning we need to compress all equal values which are in the same rows and columns. We can construct second graph with edges between equal cells in the same way as before and find all connected components in it. They will be our new vertices for the first graph.

650D - Zip-lineIdea author: LHiC, preparation: LHiC.

We need to find the longest increasing subsequence (LIS) after each change if all changes are independent.

First lets calculate LIS for the initial array and denote its length as k. While calculating it we will store some additional information: lenl[i] — maximal length of LIS ending on this element. Also we will need lenr[i] — maximal length of LIS starting from this element (we can calc it when searching longest decreasing sequence on reversed array).

Lets solve the case when we take our new element in the resulting LIS. Then we just calculate maxi < a, h[i] < b(lenl[i]) + 1 + maxj > a, h[j] > b(lenr[j]). It can be done online with persistent segment tree or offline with scanline with regular segment tree in  time. This is the only case when answer can be larger then k, and it can be only k + 1 to be exact. Second case is when we change our element and ruin all LIS of size k. Then answer is k - 1. Otherwise we will have at least one not ruined LIS of size k and it is the answer.

Lets calculate number of different LIS by some modulo. It can be done with the same dynamic programming with segment tree as just finding LIS. Then we can check if liscount = liscountleft[a] * liscountright[a]. This exactly means that all sequences go through our element.

But if you don't want the solution with such "hashing" there is another approach. For each element we can calc if it can be in LIS. If so then we know on which position it will go (lenl[i]). Then for each position we will know if there are several elements wanting to go on that position or only one. If only one then it means that all LIS are going through that element.

Overall complexity is .

P.S. We can solve this without segment tree, just using alternative approach to calculating LIS with dynamic programming and binary search.

650E - Clockwork BombIdea author: Zlobober, preparation: Zlobober.

First idea is that answer is always equals to the number of edges from the first tree, which are not in the second one. This means that if we have an edge in both trees we will never touch it. So if we have such edge we can remove this edge and merge its two vertices together, nothing will change.

Second idea that if we will take any edge from the first tree there always exists some edge from the second tree, which we can swap (otherwise second graph is not connected, but the tree is always connected). So the order of adding edges from the first tree can be arbitrary.

Third idea is that if we will select leaf node in the first tree, then cut its only edge, then we can add instead of it any edge going from this vertex in the second tree.

Overall algorithm: we store linked lists of edges in vertices, when edge is in both trees we use disjoint-set union to merge vertices and join their lists. We can simply traverse first tree to get any order of edges in which the current edge will always contain leaf as one of its vertices.

Complexity is O(nα), which in practice is almost linear.

Editorial Codeforces Round #344 (Div. 2)

By xfce8888, 7 years ago, translation, In English631A - Interview

You should know only one fact to solve this task: . This fact can be proved by the truth table. Let's use this fact: . Also . According two previous formulas we can get that f(a, 1, n) ≥ f(a, i, j). Finally we can get the answer. It's equal to f(a, 1, N) + f(b, 1, N).

Time: 

Memory: 

C++ Python3

631B - Print Check

Let's define timeRi as a number of last query, wich repaint row with number i, timeCj – as number of last query, wich repaint column with number j. The value in cell (i, j) is equal amax(timeRi, timeCj).

Time: 

Memory: 

C++ Python3

631C - Report

If we have some pair of queries that ri ≥ rj, i > j, then we can skip query with number j. Let's skip such queries. After that we get an array of sorted queries (ri ≤ rj, i > j). Let's sort subarray a1..max(ri) and copy it to b. For proccessing query with number i we should record to ari - 1..ri first or last(it depends on ti - 1) ri - 1 - ri + 1 elementes of b. After that this elements should be extract from b. You should remember that you need to sort subarray a1..rn, after last query.

Time: 

Memeory: 

C++ Python3

631D - Messenger

Let's define S[i] as i - th block of S, T[i] — as i - th block of T.Also S[l..r] = S[l]S[l + 1]...S[r] and T[l..r] = T[l]T[l + 1]...T[r].

T is substring of S, if S[l + 1..r - 1] = T[2..m - 1] and S[l].l = T[1].l and S[l].c ≥ T[1].c and S[r].l = T[m].l and S[r].c ≥ T[m].c. Let's find all matches of T[l + 1..r - 1] in S and chose from this matches, witch is equal T.You can do this by Knuth–Morris–Pratt algorithm.

This task has a some tricky test cases:

 and . Letters in the adjacent blocks are may be same.This problem can be solved by the union of adjacent blocks with same letter. and . Count of T blocks are less than 3. Such cases can be proccess singly. and . Answer for this test should be stored at long long.

Time: 

Memory: 

C++Python3

631E - Product Sum



The operation, which has been described in the statement, is cyclic shift of some subarray. Let's try to solve this problem separately for left cyclic shift and for right cyclic shift. Let's define  as answer before(or without) cyclic shift, Δans = ans - ans' — difference between answer after cyclic shift and before. This difference can be found by next formulas:

For left cyclic shift:

Δl, r = (al·r + al + 1·l + ... + ar·(r - 1)) - (al·l + al + 1·(l + 1) + ... + ar·r) = al·(r - l) - (al + 1 + al + 2 + ... + ar)

For right cyclic shift:

Δ'l, r = (al·(l + 1) + al + 1·(l + 2) + ... + ar·l) + (al·l + al + 1·(l + 1) + ... + ar·r) = (al + al + 1 + ... + ar - 1) + ar·(l - r)

You can find this values with complexity , using prefix sums, .



Let's try to rewrite previous formulas:

For left cyclic shift: Δl, r = (al·r - sumr) + (suml - al·l)

For right cyclic shift: Δ'l, r = (ar·l - suml - 1) + (sumr - 1 - ar·r)

You can see, that if you fix l for left shift and r for right shift, you can solve this problem with complexity  using Convex Hull Trick.

Time: 

Memory: 

C++

Editorial of Codeforces Round #343 (Div.2)

By dkjsfkhg, 7 years ago, In EnglishProblem A:Consider that we have rowi chocolates in the i'th row and coli chocolates in the i'th column.

The answer to the problem would be: . It is obvious that every pair would be calculated exactly once (as we have no more than one chocolate in the same square)

Time Complexity: O(n2)

C++ Solution

Problem B:Consider that we have boyi males in the i'th day of the year and girli females in the i'th day of the year. These arrays can be filled easily when you are reading the input (See the code). Then for the i'th day of the year, we could have 2 * min(boyi , girli) people which could come to the party. The answer would be maximum of this value between all days i (1 ≤ i ≤ 366)

Time Complexity: O(366*n)

C++ Solution

Bonus: Try to solve this problem with O(n). For each interval given in the input, you don't need to iterate from day ai to day bi. This idea is used to solve problem 276C.

Problem C:This problem can be solved with dynamic programming:

1. Calculate dpi, j : How many sequences of brackets of length i has balance j and intermediate balance never goes below zero (They form a prefix of a valid sequence of brackets).

2. For the given sequence of length n calculate the resulting balance a and the minimum balance b.

3. Try the length of the sequence added at the beginning c and its balance d. If  - b ≤ d then add dpc, d × dpm - n - c, d + a to the answer.

Time complexity: O((n - m)2)

C++ Solution

Problem D:First of all, we calculate the volume of each cake: vi = π × hi × ri2.

Now consider the sequence v1, v2, v3, ..., vn : The answer to the problem is the maximum sum of elements between all increasing sub-sequences of this sequence. How do we solve this? First to get rid of the decimals we can define a new sequence a1, a2, a3, ..., an such that 

We consider dpi as the maximum sum between all the sequences which end with ai and

dpi = 

The answer to the problem is: π × maxi = 1ndp[i]

Now how do we calculate  ? We use a max-segment tree which does these two operations: 1. Change the i't member to v. 2. Find the maximum value in the interval 1 to i.

Now we use this segment tree for the array dp and find the answer.

Consider that a1, a2, a3, ..., an is sorted. We define bi as the position of ai. Now to fill dpi we find the maximum in the interval [1, bi) in segment and we call it x and we set the bi th index of the segment as ai + x. The answer to the problem would the maximum in the segment in the interval [1,n]

Time complexity: O(nlgn)

Thanks to ATofighi who helped a lot for writing the editorial of problem D.

C++ Solution

Problem E:First of all, we assume that the tree is rooted! For this problem, first we need to compute some values for each vertex u: qdu and quu, cntu , paru, i and hu. qdu equals to the expected value of length of paths which start from vertex u, and ends in u’s subtree and also has length at least 1. quu equals to the expected value of length of paths which start from vertex u, and not ends in u’s subtree and also has length at least 1. to calculate this values we can use one dfs for qd, and one other dfs for qu. \ cntu is the number of vertices in u’s subtree except u, paru, i is the 2i ‘th ancestor of u and finally hu is the height of the vertex u. \ in first dfs (lets call it dfsdown) we can calculate qd, cnt and par array with this formulas:



for ecah $v$ as child of u and paru, i = parparu, i - 1, i - 1

in second dfs (lets call it dfsup) we calculate qu using this formula (for clearer formula, I may define some extra variables):

there are two cases:

u is the only child of its parent: let

then

\

u is not the only child of its parent: let





then

now we should process the queries. For each query u and v, we have to cases: one of the vertices is either one of the ancestors of the other one or not! In the first case, if we define w the vertex before u (u is assumed to be the vertex with lower height). In the path from v to u, the answer is

.

In the second case, if we assume w = LCA(u, v), then answer is

To check if u is one of ancestors of v, you can check if their LCA equals to u or you can use dfs to find out their starting and finishing time. u is an ancestor of v if the interval of starting and finishing time of v is completely inside starting and finishing time of u

The time complexity for the whole solution is O(n + mlgn) (O(n) for dfs and O(lgn) for each query so O(mlgn) for queries!).

C++ Solution

Codeforces Round #342 (Div. 2) : editorial

By romanandreev, 7 years ago, translation, In English625A - Guest From the PastIdea author: collaboration, preparation: feldsherov.

If we have at least b money then cost of one glass bottle is b - c. This means that if a ≤ b - c then we don't need to buy glass bottles, only plastic ones, and the answer will be . Otherwise we need to buy glass bottles while we can. So, if we have at least b money, then we will buy  glass bottles and then spend rest of the money on plastic ones. This is simple O(1) solution.

625B - War of the CorporationsIdea author: gustokashin, preparation: thefacetakt.

Lets find leftmost occurrence of the second word in the first one. We need to add # to remove this occurrence, so where we would like to put it? Instead of the last symbol of this occurrence to remove as many others as we can. After that we will continue this operation after the new # symbol. Simplest implementation of this idea works in O(|S|·|T|), but with the power of string algorithms (for example, Knuth–Morris–Pratt algorithm) we can do it in O(|S| + |T|) time.

Hint/Bug/Feature: in Python language there is already function that does exactly what we need:

print(input().count(input()))625C - K-special TablesIdea author: Elena Andreeva, preparation: wilwell.

Lets fill our table row by row greedily. We want to have maximal possible number on k-th place in the first row. After it we need at least n - k numbers greater than ours, so its maximum value is n2 - (n - k). If we select it then we are fixing all numbers after column k in the first row from n2 - (n - k) to n2. On the first k - 1 lets put smallest possible numbers 1,  2,  ... ,  k - 1. If we do the same thing in the second row then in the beginning it will have numbers from k to 2(k - 1), and from k-th position maximum possible values from n2 - (n - k) - (n - k + 1) to n2 - (n - k + 1). And so on we will fill all rows. With careful implementation we don't need to store whole matrix and we need only O(1) memory. Our algorithm works in O(n2) time.

625D - Finals in arithmeticIdea author: Sender, preparation: Sender.

Lets say that input has length of n digits, then size of answer can be n if we didn't carry 1 to the left out of addition, and n - 1 otherwise. Lets fix length m of our answer and denote i-th number in the representation as ai. Then we know  from the rightmost digit of the sum. Lets figure out what does  equals to. If the remainder is 9, it means that , because we can't get 19 out of the sum of two digits. Otherwise the result is defined uniquely by the fact that there was carrying 1 in the leftmost digit of the result or not. So after this we know a1 + am. It doesn't matter how we divide sum by two digits, because the result will be the same. After this we can uniquely identify the fact of carrying after the first digit of the result and before the last digit. Repeating this m / 2 times we will get candidate for the answer. In the end we will have O(n) solution.

If you've missed the fact that every step is uniquely defined, then you could've wrote basically the same solution, but with dynamic programming.

625E - Frog FightsIdea author: Elena Andreeva, preparation: iskhakovt.

We want to efficiently simulate the process from the problem statement. Lets have a data structure with times of key events that could've happened during simulation (some frog removed other frog from the board). Lets remove earliest event from our data structure and apply it to the board, make a critical jump. After that the speed of the first frog will decrease and we will be forced to recount times of collision of this frog this its 2 neighbors. This data structure could be set from C++, TreeSet from Java or self-written Segment Tree. To quickly find out who are we gonna remove from the board after the jump lets store double-linked list of all frogs sorted by their positions. Technical part is to calculate time of the collision, but it can be easily done with the simple notion of linear movement of two points on a line. There could be at max n - 1 collisions, so whole solution will be .

Codeforces Round #341 (Div. 2) Editorial

By minimario, history, 7 years ago, In English621A - Мокрая Акула и чётность

First, if the sum of all the numbers is already even, then we do nothing. Otherwise, we remove the smallest odd number. Since, if the sum is odd, we need to remove a number with the same parity to make the sum even. Notice it's always bad to remove more odd numbers, and it does nothing to remove even numbers.

621B - Мокрая Акула и слоны

Let's start with two bishops (x1, y1) and (x2, y2). Notice that if (x1, y1) attacks (x2, y2), either x1 + y1 == x2 + y2 OR x1 — y1 == x2 — y2. So, for each bishop (x, y), we will store x + y in one map and x — y in another map.

621C - Мокрая Акула и цветы

Let f(x) be the probability that the product of the number of flowers of sharks x and  is divisible by p.

We want the expected value of the number of pairs of neighbouring sharks whose flower numbers are divisible by p. From linearity of expectation, this is equal to the probabilities that each pair multiplies to a number divisible by p, or f(0) + f(1) + ... + f(n). (Don't forget about the wrap-around at n)

Now, for each pair of neighbouring sharks, we need to figure out the probability that their product is divisible by p. Consider an interval [li, ri]. How many numbers in this interval are divisible by p? Well, it is easier if we break the interval [li, ri] up into [1, ri] - [1, li - 1]. Since 1, 2, ..., x contains  numbers divisible by p, the interval [li, ri] contains  numbers divisible by p.

Now, consider two numbers  and , with . Let ai be the number of integers divisible by p in the interval [li, ri], and define aj similarly. Now what's the probability that fi·fj is divisible by p? We can count the opposite: the probability that fi·fj is not divisible by p. Since p is a prime, this means neither fi nor fj is divisible by p. The number of integers in [li, ri] not divisible by p is ri - li + 1 - ai. Similar for j. Therefore, the probability fi·fj is not divisible by p is given by . Therefore, the probability it is can be given by . Now, just sum over this for all i.

621D - Крыса Квеш и сыр

The tricky Rat Kwesh has finally made an appearance; it is time to prepare for some tricks. But truly, we didn't expect it to be so hard for competitors though. Especially the part about taking log of a negative number.

We need a way to deal with xyz and xyz. We cannot directly compare them, 200200200 is way too big. So what we do? Take log!  is an increasing function on positive numbers (we can see this by taking , then , which is positive when we are dealing with positive numbers). So if , then x ≥ y.

When we take log,  But yz can still be 200200, which is still far too big. So now what can we do? Another log! But is it legal? When x = 0.1 for example, , so we cannot take another log. When can we take another log, however? We need  to be a positive number. yz will always be positive, so all we need is for  to be positive. This happens when x > 1. So if x, y, z > 1, everything will be ok.

There is another good observation to make. If one of x, y, z is greater than 1, then we can always achieve some expression (out of those 12) whose value is greater than 1. But if x < 1, then xa will never be greater than 1. So if at least one of x, y, z is greater than 1, then we can discard those bases that are less than or equal to 1. In this case, . Remember that , so . Similarly, .

The last case is when x ≤ 1, y ≤ 1, z ≤ 1. Then, notice that for example, . But the denominator of this fraction is something we recognize, because 10 / 3 > 1. So if all x, y, z < 1, then it is the same as the original problem, except we are looking for the minimum this time.

621E - Мокрая Акула и блоки

First, let us build an X by X matrix. We will be applying matrix exponentiation on this matrix. For each modulo value T from 0 to X — 1, and each value in the array with index i between 1 and n, we will do: matrix[T][(10 * T + arr[i]) % X]++. This is because, notice that for each block we allow one more way to go between a modulo value T, and (10 * T + arr[i]) % X. We are multiplying T by 10 because we are "left-shifting" the number in a way (i.e. changing 123 -> 1230), and then adding arr[i] to it. Notice that this basically simulates the concatenation that Wet Shark is conducting, without need of a brute force dp approach.

Codeforces Round #340 (Div. 2) Editorial

By komendart, history, 7 years ago, In English617A - Elephant

It's optimal to do the biggest possible step everytime. So elephant should do several steps by distance 5 and one or zero step by smaller distance. Answer equals to 

Solution 15550796

617B - Chocolate

We are given array which contains only ones and zeroes. We must divide it on parts with only one 1.

Tricky case: when array contains only zeroes answer equals to 0.

In general. Between two adjacent ones we must have only one separation. So, answer equals to product of values posi - posi - 1 where posi is position of i-th one.

Bonus: what's the maximal possible answer for n < 100?

Solution 15550806

617C - Watering Flowers

First radius equals to zero or distance from first fountain to some flower. Let's iterate over this numbers. Second radius equals to maximal distance from second fountain to flower which doesn't belong to circle with first radius. Now we should choose variant with minimal r12 + r22.

Bonus: It's O(n2) solution. Can you solve problem in O(nlogn)?

Solution O(n2) 15550812

Solution O(nlogn) 15550822

617D - Polyline

Answer equals to one if all coordinates x or y of points are same.

When answer equals to two? Let's iterate over all pairs of points. Let first point in pair is beginning of polyline, second point is end. Only one or two such polylines with answer two exist. If third point is on the polyline it belongs to rectangle with corners in first two points. We can just check it.

Else answer equals to three. We can build vertical lines which contains the most left and the most right point and horizontal line through third point. If we erase some excess rays we will get polyline.

Solution 15550843

617E - XOR and Favorite Number

We have array a.

Let's calculate array pref (pref[0] = 0, ).

Xor of subarray a[l...r] equals to .

So query (l, r) is counting number of pairs i, j (l - 1 ≤ i < j ≤ r) .

Let we know answer for query (l, r) and know for all v cnt[v] — count of v in a[l - 1...r]. We can update in O(1) answer and cnt if we move left or right border of query on 1. So we can solve problem offline in  with sqrt-decomposion (Mo's algorithm).

Solution 15550846

Codeforces Round #339 Editorial

By Endagorion, history, 7 years ago, In EnglishI'm terribly sorry for the delay.

Please report any mistakes.

614A - Link/Cut Tree

Author: Tigutor

Developers: Tigutor, ch_egor

You had to print all numbers of form kx for non-negative integers x that lie with the range [l;r]. A simple cycle works: start with 1 = k0, go over all powers that do not exceed r and print those which are at least l. One should be careful with 64-bit integer overflows: consider the test l = 1, r = 1018, k = 109, the powers will be 1, 109, 1018, and the next power is 1027, which does not fit in a standard integer type.

614B - Gena's Code

Author, developer: ch_egor

You were asked to print the product of n large numbers, but it was guaranteed that at least n - 1 are beautiful. It's not hard to see that beautiful numbers are 0 and all powers of 10 (that is, 1 followed by arbitrary number of zeros). If there is at least one zero among the given numbers, the product is 0. Otherwise, consider the only non-beautiful number x (if all numbers are beautiful, consider x = 1). Multiplying x by 10t appends t zeros to its decimal representation, so in this case we have to find the only non-beautiful number and print it with several additional zeros.

We tried to cut off all naive solutions that use built-in long numbers multiplication in Python or Java. However, with some additional tricks (e.g., ``divide-and-conquer'') this could pass all tests.

613A - Peter and Snow Blower

Author, developer: platypus179

Consider distances between the point P and all points of the polygon. Let R be the largest among all distances, and r be the smallest among all distances. The swept area is then a ring between circles of radii R and r, and the answer is equal to π (R2 - r2).

Clearly, R is the largest distance between P and vertices of the polygon. However, r can be the distance between P and some point lying on the side of the polygon, therefore, r is the smallest distance between P and all sides of the polygon.

To find the shortest distance between a point p and a segment s, consider a straight line l containing the segment s. Clearly, the shortest distance between p and l is the length of the perpendicular segment. One should consider two cases: when the end of the perpendicular segment lies on the segment s (then the answer is the length of the perpendicular segment), or when it lies out of s (then the answer is the shortest distance to the ends of s).

613B - Skills

Author: cdkrot

Developers: cdkrot, galilei2000, ch_egor

Let's save the original positions of skills and then sort the skills in non-increasing order (almost decreasing) by current level. We can always restore original order after.

Imagine that we have decided that we want to use the minimum level X and now we're choosing which skills we should bring to the maximum.

At first, let's rise all skills below X to level X, this will set some tail of array to X. But the original array was sorted, and this new change will not break the sort! So our array is still sorted.

Obviously, the skills we want to take to the maximum are the ones with highest current level. They are in the prefix of array. It is easy to show that any other selection is no better than this greedy one.

Now we have shown that the optimal strategy is to max out the skills in some prefix. Now let's solve the problem.

Let's iterate over prefix to max out, now on each iteration we need to know the highest minimum we can achieve, let's store the index of the first element outside the prefix such that it is possible to reach the minimum level  ≥ arrindex.

It is easy to recalc this index, it slightly moves forward each turn and, after precalcing the sum of all array's tails, you can update it easily (just move it forward until the invariant above holds). And knowing this index is enough to calc the current highest possible minimum level (min(A, arrindex + ⌊ sparemoney / (n - index)⌋).

How to restore the answer? Actually, all you need to know is the count of maximums to take and minimum level to reach.

613C - Necklace

Author: cdkrot

Developers: cdkrot, crossopt, ch_egor

Surprisingly, the nice cuts can't be put randomly. Let's take a look on the first picture above (red lines represent nice cut points). But since the necklace is symmetrical relative to nice cuts, the cut points are also symmetrical relative to nice cuts, so there is one more cut (see picture two). Repeating this process, we will split the whole necklace into parts of the same size (picture three).

     

If the number of parts is even, then each part can be taken arbitrarily, but the neighbouring parts must be reverses of each other (e.g. "abc" and "cba"). This is an implication of the cuts being nice.

If the number of parts is odd, then each part is equal to each other and is a palindrome, this is an implication of the cuts being nice too.

Anyway, the number of characters in each part is equal, so amount of parts can't be greater than . Actually, it may be zero,  or its divisor.

If the number of odd-sized colors is zero, then the sum is even and gcd is even, this way we can construct a building block containing exactly  beads of i-th color, (gcd being gcd of all counts), then build beads of gcd parts, where each part equal to building block, with neighbouring parts being reverses. Since gcd is even, everything is ok.

If the number of odd-sized colors is one, then the sum is odd and gcd is odd. Building block have to be built as a palindrome containing  beads of i-th color, exactly n - 1 of colors will be even and one odd, put the odd one in center, others on sides (aabcbaa). Everything is ok.

If num of odd counts is geq2. Gcd is odd, all its divisors too, so our building block has to be palindrome. Let k denote the number of parts. A building block will contain  beads of color i, at least two of these numbers are odd, it is impossible to build such a palindrome. The answer is zero.

Complexity: O(sum), just to output answer.

Bonus. How to solve problem, if you are allowed to discard any subset of beads before constructing necklace?

Bonus. Given a necklace scheme (like one you were asked to output), how to determine number of nice cuts, O(sum), no suffix structures or hashes?

613D - Kingdom and its Cities

Authors: ch_egor and others

Developer: cdkrot

Obviously, the answer is -1 iff two important cities are adjacent.

If there was a single query, can we answer it in O(n) time? Let's choose a root arbitrarily. We can note there is an optimal answer that erases two types of vertices: vertices that lie on a vertical path between two important vertices, or LCA of some pair of important vertices.

Let's do a subtree DP that counts the answer for the subtree of v, as well as if there is any important vertex still connected to v in the answer. How do we count it? If v is important, then we should disconnect it from any still-connected vertices from below by erasing these children which contain them. If v is not important, then we erase it iff there are more than one still-connected important vertices below. All calculations are straightforward here.

How do we process many queries now? There are many possible approaches here (for reference, look at the accepted solutions). The author's solution was as follows: if we have a query with k important vertices, then we can actually build an auxiliary tree with O(k) vertices and apply the linear DP solution to it with minor modifications.

How to construct the auxiliary tree? We should remember the observation about LCAs. Before we start, let us DFS the initial tree and store the preorder of the tree (also known as "sort by tin"-order). A classical exercise: to generate all possible LCAs of all pairs among a subset of vertices, it suffices to consider LCAs of consecutive vertices in the preorder. After we find all the LCAs, it is fairly easy to construct the tree in O(k) time. Finally, apply the DP to the auxiliary tree. Note that important cities adjacent in the auxiliary tree are actually not adjacent (since we've handled that case before), so it is possible to disconnect them.

If we use the standard "binary shifts" approach to LCA, we answer the query in  time, for a total complexity of .

613E - Puzzle Lover

Author, developer: Endagorion

The key observation: any way to cross out the word w looks roughly as follows:

..v<1.>>v.2<.....>>>>^.>>>^...That is, there can be following parts:

go back a symbols in one row, then go forward a symbols in the other row (possibly a = 0)

go forward with arbitrarily up and down shifts in a snake-like manner

go forward b symbols in one row, then go back b in the other row (possibly b = 0)

Note that the "forward" direction can be either to the left or to the right. It is convenient that for almost any such way we can determine the "direction" as well as the places where different "parts" of the path (according to the above) start. To avoid ambiguity, we will forbid a = 1 or b = 1 (since such parts can be included into the "snake").

Fix the direction. We will count the DP dx, y, k for the number of ways to cross out first k letters of w and finished at the cell (x, y) while being inside the snake part of the way. The transitions are fairly clear (since the snake part only moves forward). However, we have to manually handle the first and the last part. For each cell and each value of k we can determine if the "go-back-then-go-forward" maneuver with parameter k can be performed with the chosen cell as finish; this can be reduced to comparing of some substrings of field of rows and the word w (and its reversed copy). In a similar way, for any state we can check if we can append the final "go-forward-then-go-back" part of the path to finally obtain a full-fledged path.

This DP has O(n2) states and transitions. However, there are still some questions left. How do we perform the substring comparisons? There is a whole arsenal of possible options: (carefully implemented) hashes, suffix structures, etc. Probably the simplest way is to use Z-function for a solution that does O(n2) precalc and answers each substring query in O(1) time (can you see how to do it?).

Also, there are paths that we can consider more than once. More precisely, a path that consists only of the "go-forward-the-go-back" part will be counted twice (for both directions), thus we have to subtract such paths explicitly. Every other path is counted only once, thus we are done. (Note: this does not exactly work when w is short, say, 4 symbols or less. The simplest way is to implement straightforward brute-force for such cases.)

Codeforces Round #338 (Div. 2) editorial

By maxkvant, 7 years ago, translation, In English615A - Bulbs (Author: TheWishmaster)Let's make a counter of number of buttons that switch every lamp off. If there is a lamp with zero counter, output NO, otherwise YES.

code: 15260902

615B - Longtail Hedgehog (Author: TheWishmaster)Way of solving — dynamic programming. We are given a graph of n vertices and m edges. We will calculate dp[i] — a maximum length of tail that is ending in i-th vertex. We can simply update dp by checking all the edges from i-th vertex(which are leading to vertices with bigger number), and trying to update them. When we have this dp, we can check the answer easily.

code: 15260851

615C - Running Track (Author: maxkvant)The idea is that if can make a substring t[i, j] using k coatings, then we can also make a substring t[i + 1, j] using k coatings. So we should use the longest substring each time.

Let n = |s|, m = |t|. On each stage we will search for the longest substring in s and s_reversed to update the answer. We can do it in several ways:

Calculate lcp[i][j] — longest common prefix t[i, m] and s[j, n], lcprev[i][j] — longest common prefix t[i, m] and s[j, 1]. Find longest means find max(max(lcp[i][1], lcp[i][2], ..., lcp[i][n]), max(lcprev[i][1], lcprev[i][2], ..., lcprev[i][n])).calculation lcp:

for (int i = m; i >= 1; i--)     for (int j = n; j >= 1; j--)           if (t[i] == s[j])              lcp[i][j] = lcp[i + 1][j + 1] + 1;code: 15277213

Let's check iterative t[i, i ] exists in s as a substring, t[i, i  + 1] t[i, i  + 2] .... We will make an array endPos, where endPos[j] is true when t[i, i + cur_len - 1] = s[j - cur_len + 1, j] (t[1, i — 1] greedy already got). We will update this array, adding symbols t[i], t[i + 1], t[i + 2] and so on. We will make one more array — for s_reversed. (more details in code)

Overall time complexity will be 

code: 15260867

trie solution: 15260870

bonusCan you solve with  complexity? ?  ?

Σ — alphabet size.

615D - Multipliers (Author: maxkvant)Let d(x) be a number of divisors of x, and f(x) be the product of divisors. Let x = p1α1p2α2... pnαn, then d(x) = (α1 + 1)·(α2 + 1)... (αn + 1)

. There is  pairs of divisors of type , , and if x is a perfect square we have one more divisor : .

for a prime m and a ≠ 0 the statement  (little Fermat theorem)

We can see that , if a and b are co prime.

Now we can count the answer:

d = 1;ans = 1;for (int i = 0; i < l; i++) {    fp = binPow(p[i], (cnt[i] + 1) * cnt[i] / 2);    ans = binPow(ans, (cnt[i] + 1)) * binPow(fp, d) % MOD;    d = d * (cnt[i] + 1) % (MOD - 1);}  code: 15260890

bonusAnother problem.

Given secquence (p1, k1),  (p2, k2), ...,  (pn, kn)(pi — distinct primes) and q queries (l, r) to calculate f(plkl·pl + 1kl + 1... prkr)%MOD.

Can you solve with  complexity?

Suppose r - l + 1 = M = const in all queries. Can you solve with  complexity?

615E - Hexagons (Author: TheWishmaster)Let's see how the coordinates are changing while we move from current cell to one of the 6 adjacent cells — let's call this 6 typed of moves. If we know the number of moves of each type on our way, then we know the coordinates of the end of the way. We will divide the way into rings.

 

Let's count the number of moves of each type for the first ring. Next ring will have one more move of each type. Length of each ring = length of previous + 6. It is an arithmetic progression. Using well-known formulas and binary search we calculate the number of the last ring and overall length of previous rings. Now we have to brute-force 6 types of the last move and calculate the answer.

code: 15260879

Codeforces Round #337 (Div.2) Editorial

By fcspartakm, history, 7 years ago, translation, In English610A — Pasha and Stick

If the given n is odd the answer is 0, because the perimeter of any rectangle is always even number.

If n is even the number of rectangles which can be construct equals to n / 4. If n is divisible by 4 we will count the square, which are deprecated, because we need to subtract 1 from the answer.

Asymptotic behavior — O(1).

610B — Vika and Squares

At first let's find the minimum in the given array and store it in the variable minimum. It is easy to understand, that we always can paint n * minimum squares. So we need to find such a minimum in the array before which staying the most number of elements, which more than the minimum. In the other words we need to find 2 minimums in the array which are farthest from each other (do not forget about cyclical of the array). If there is only one minumum we need to start paint from the color which stay in the array exactly after the minimum (do not forget about cyclical of the array too). It can be done with help of iterations from the left to the right. We need to store the position of the nearest minimum in the variable and update her and the answer when we meet the element which equals to minimum.

Asymptotic behavior — O(n), where n — the number of different colors.

610С — Harmony Analysis

Let's build the answer recursively. For k = 0 the answer is  - 1 or  + 1. Let we want to build the answer for some k > 0. At first let's build the answer for k - 1. As the answer for k let's take four copies of answer for k - 1 with inverting of values in last one. So we have some fractal with 2 × 2 base: 00, 01. Let's prove the correctness of such building by induction. Consider two vector from the top (down) half: they have zero scalar product in the left half and in the right, so the total scalar product is also equals to zero. Consider a vector from the top half and from the down: their scalar products in the left and the right halfs differs only in sign, so the total scalar product is also zero.

Note the answer is also is a matrix with element i, j equals to \texttt{+} if the number of one bits in number i|j is even.

Complexity O((2k)2).

610D — Vika and Segments

At first let's unite all segments which are in same verticals or horizontals. Now the answer to the problem is the sum of lengths of all segments subtract the number of intersections. Let's count the number of intersections. For this let's use the horizontal scan-line from the top to the bottom (is can be done with help of events — vertical segment is open, vertical segment is close and hadle horizontal segment) and in some data structure store the set of x-coordinates of the open segments. For example we can use Fenwick tree with precompression of the coordinates. Now for current horizontal segment we need to take the number of the opened vertical segmetns with value x in the range x1, x2, where x — vertical where the vertical segment are locating and x1, x2 — the x-coordinates of the current horizontal segment.

Asymptotic behavior: O(nlogn).

610E — Alphabet Permutations

Consider slow solution: for operations of the first type reassign all letters, for operations of the second type let's iterate over the symbols in s from left to right and maintain the pointer to the current position in alphabet permutation. Let's move the pointer cyclically in permutation until finding the current symbol from s. And move it one more time after that. Easy to see that the answer is one plus the number of cyclic movements. Actually the answer is also the number of pairs of adjacent symbols in s that the first one is not righter than the second one in permutation. So the answer depends only on values of cntij —- the number of adjacent symbols i and j.

To make solution faster let's maintain the segment tree with matrix cnt in each node. Also we need to store in vertex the symbol in the left end of segment and in the right end. To merge two vertices in the segment tree we should simply add the values in the left and in the right sons in the tree, and update the value for the right end of the left segment and the left end of the right segment.

Complexity: O(nk2 + mk2logn).

Codeforces Round #336 Editorial

By ed1d1a8d, history, 7 years ago, In English608A - Saitama Destroys HotelAuthor: ed1d1a8d

Code: https://ideone.com/HiZd9g

The minimum amount of time required is the maximum value of ti + fi and s, where t_i and f_i are the time and the floor of the passenger respectively.

The initial observation that should be made for this problem is that only the latest passenger on each floor matters. So, we can ignore all passengers that aren't the latest passenger on each floor.

Now, assume there is only a passenger on floor s. Call this passenger a. The time taken for this passenger is clearly ta + fa (the time taken to wait for the passenger summed to the time taken for the elevator to reach the bottom).

Now, add in one passenger on a floor lower than s. Call this new passenger b. There are 2 possibilities for this passenger. Either the elevator reaches the passenger's floor after the passenger's time of arrival or the elevator reaches the passenger's floor before the passenger's time of arrival. For the first case, no time is added to the solution, and the solution remains ta + fa. For the second case, the passenger on floor s doesn't matter, and the time taken is tb + fb for the new passenger.

The only thing left is to determine whether the elevator reaches the new passenger before ti of the new passenger. It does so if ta + (fa - fb) > tb. Clearly this is equivalent to whether ta + fa > tb + fb. Thus, the solution is max of max(ta + fa, tb + fb).

A similar line of reasoning can be applied to the rest of the passengers. Thus, the solution is the maximum value of ti + fi and s.

608B - Hamming Distance SumAuthor: ed1d1a8d

Code: https://ideone.com/nmGbRe

We are trying to find . Swapping the sums, we see that this is equivalent to .

Summing up the answer in the naive fashion will give an O(n2) solution. However, notice that we can actually find  without going through each individual character. Rather, all we need is a frequency count of different characters. To obtain this frequency count, we can simply build prefix count arrays of all characters on b. Let's call this prefix count array F, where F[x][c] gives the number of occurrences of the character c in the prefix [0, x) of b. We can then write . as . This gives us a linear solution.

Time Complexity — O(|a| + |b|), Memory Complexity — O(|b|)

607A - Chain ReactionAuthor: Chilli

Code: https://ideone.com/xOrFhv

It turns out that it is actually easier to compute the complement of the problem — the maximum number of objects not destroyed. We can subtract this from the total number of objects to obtain our final answer.

We can solve this problem using dynamic programming. Let dp[x] be the maximum number of objects not destroyed in the range [0, x] given that position x is unaffected by an explosion. We can compute dp[x] using the following recurrence:

Now, if we can place an object to the right of all objects with any power level, we can destroy some suffix of the (sorted list of) objects. The answer is thus the maximum number of destroyed objects objects given that we destroy some suffix of the objects first. This can be easily evaluated as

Since this is the complement of our answer, our final answer is actually

Time Complexity — O(max(ai)), Memory Complexity — O(max(ai))

607B - ZumaAuthor: Amor727

Code: https://ideone.com/Aw1bSs

We use dp on contiguous ranges to calculate the answer. Let D[i][j] denote the number of seconds it takes to collapse some range [i, j]. Let us work out a transition for this definition. Consider the left-most gemstone. This gemstone will either be destroyed individually or as part of a non-singular range. In the first case, we destroy the left-most gemstone and reduce to the subproblem [i + 1, j]. In the second case, notice that the left-most gemstone will match up with some gemstone to its right. We can iterate through every gemstone with the same color as the left-most (let k be the index of this matching gemstone) and reduce to two subproblems [i + 1, k - 1] and [k + 1, j]. We can reduce to the subproblem [i + 1, k - 1] because we can just remove gemstones i and k with the last removal of [i + 1, k - 1]. We must also make a special case for when the first two elements in a range are equal and consider the subproblem [i + 2, j].

Here is a formalization of the dp:

http://codeforces.com/blog/entry/22256?#comment-268876Why is this dp correct? Notice that the recursive version of our dp will come across the optimal solution in its search. Moreover, every path in the recursive search tree corresponds to some valid sequence of deletions. Since our dp only searches across valid deletions and will at some point come across the optimal sequence of deletions, the answer it produces will be optimal.

Time Complexity — O(n3), Space Complexity — O(n2)

607C - MarblesAuthor: ed1d1a8d

Code: https://ideone.com/giyUNE

Define the reverse of a sequence as the sequence of moves needed to negate the movement. For example, EEE and WWW are reverses, and WWSSSEE and WWNNNEE are reverses. I claim is impossible to get both balls to the end if and only if some suffix of the first sequence is the reverse of a suffix of the second sequence.

Let us prove the forward case first, that if two suffixes are reverses, then it is impossible to get both balls to the end. Consider a sequence and its reverse, and note that they share the same geometric structure, except that the direction of travel is opposite. Now imagine laying the two grid paths over each other so that their reverse suffixes are laying on top of each other. It becomes apparent that in order to move both balls to their ends, they must cross over at some point within the confines of the suffix. However, this is impossible under the movement rules, as in order for this to happen, the two balls need to move in different directions at a single point in time, which is not allowed.

Now let us prove the backwards case: that if no suffixes are reverses, then it is possible for both balls to reach the end. There is a simple algorithm that achieves this goal, which is to move the first ball to its end, then move the second ball to its end, then move the first ball to its end, and so on. Let's denote each of these "move the x ball to its end" one step in the algorithm. After every step, the combined distance of both balls from the start is strictly increasing. Without loss of generality, consider a step where you move the first ball to the end, this increases the distance of the first ball by some value k. However, the second ball can move back at most k - 1 steps (only its a reverse sequence can move back k steps), so the minimum change in distance is  + 1. Hence, at some point the combined distance will increase to 2(n - 1) and both balls will be at the end.

In order to check if suffixes are reverses of each other, we can take reverse the first sequence, and see if one of its prefixes matches a suffix of the second sequence. This can be done using string hashing or KMP in linear time.

Time Complexity — O(n), Memory Complexity — O(n)

607D - Power TreeAuthor: ed1d1a8d

Code: https://ideone.com/pObeIV

Let's solve a restricted version of the problem where all queries are about the root. First however, let us define some notation. In this editorial, we will use d(x) to denote the number of children of vertex x. If there is an update involved, d(x) refers to the value prior to the update.

To deal these queries, notice that each vertex within the tree has some contribution ci to the root power. This contribution is an integer multiple mi of each vertex's value vi, such that ci = mi·vi If we sum the contributions of every vertex, we get the power of the root.

To deal with updates, notice that adding a vertex u to a leaf p scales the multiplier of every vertex in p's subtree by a factor of . As for the contribution of u, notice that mu = mp.

Now, in order to handle both queries and updates efficiently, we need a fast way to sum all contributions, a way to scale contributions in a subtree, and a way to add new vertices. This sounds like a job for ... a segment tree!

We all know segment trees hate insertions, so instead of inserting new vertices, we pre-build the tree with initial values 0, updating values instead of inserting new vertices. In order to efficiently support subtree modification, we construct a segment tree on the preorder walk of the tree, so that every subtree corresponds to a contiguous segment within the segment tree. This segment tree will store the contributions of each vertex and needs to support range-sum-query, range-multiply-update, and point-update (updating a single element). The details of implementing such a segment tree and are left as an exercise to the reader.

Armed with this segment tree, queries become a single range-sum. Scaling the contribution in a subtree becomes a range-multiply (we don't need to worry about multiplying un-added vertices because they are set to 0). And adding a new vertex becomes a range-sum-query to retrieve the contribution of the parent, and then a point-set to set the contribution of the added vertex.

Finally, to solve the full version of the problem, notice that the power of a non-root vertex w is a scaled down range sum in the segment tree. The value of the scale is , the proof of which is left as an exercise to the reader.

Time Complexity — , Space Complexity — O(q)

607E - Cross SumAuthor: GlebsHP

Code: https://ideone.com/Di8gnU

The problem boils down to summing the k closest intersections to a given query point.

We binary search on the distance d of kth farthest point. For a given distance d, the number of points within distance d of our query point is equivalent to the number of pairwise intersections that lie within a circle of radius d centered at our query point. To count the number of intersections, we can find the intersection points of the lines on the circle and sort them. Two lines which intersect will have overlapping intersection points on the circle (i.e. of the form ABAB where As and Bs are the intersection points of two lines). Counting the number of intersections can be done by DP.

Once we have d, we once again draw a circle of size d but this time we loop through all points in O(k) instead of counting the number of points.

It may happen that there are I < k intersections inside the circle of radius d but also I' > k inside a circle of radius d + ε. In this case, we should calculate the answer for d and add d(k - I).

Time Complexity — , Space Complexity — O(n)

Codeforces Round #335 Problem Analysis

By craus, 7 years ago, In English606A - Magic Spheres. Let’s count how many spheres of each type are lacking to the goal. We must do at least that many transformations. Let’s count how many spheres of each type are extra relative to the goal. Each two extra spheres give us an opportunity to do one transformation. So to find out how many transformations can be done from the given type of spheres, one must look how many extra spheres there are, divide this number by 2 and round down. Let’s sum all the opportunities of transformations from each type of spheres and all the lacks. If there are at least that many opportunities of transformations as the lacks, the answer is positive. Otherwise, it’s negative.

606B - Testing Robots. Let’s prepare a matrix, where for each cell we will hold, at which moment the robot visits it for the first time while moving through its route. To find these values, let’s follow all the route. Each time we move to a cell we never visited before, we must save to the corresponding matrix’ cell, how many actions are done now. Let’s prepare an array of counters, in which for each possible number of actions we will hold how many variants there were, when robot explodes after this number of actions.

Now let’s iterate through all possible cells where mine could be placed. For each cell, if it wasn’t visited by robot, add one variant of N actions, where N is the total length of the route. If it was, add one variant of that many actions as written in this cell (the moment of time when it was visited first). Look, if there is a mine in this cell, robot would explode just after first visiting it.

The array of counters is now the answer to the problem.

605A - Sorting Railway Cars. Let’s suppose we removed from the array all that elements we would move. What remains? The sequence of the numbers in a row: a, a+1, …, b. The length of this sequence must be maximal to minimize the number of elements to move. Consider the array pos, where pos[p[i]] = i. Look at it’s subsegment pos[a], pos[a+1], …, pos[b]. This sequence must be increasing and its length as mentioned above must be maximal.

So we must find the longest subsegment of pos, where pos[a], pos[a+1], …, pos[b] is increasing.

605B - Lazy Student. Let’s order edges of ascending length, in case of a tie placing earlier edges we were asked to include to MST. Let’s start adding them to the graph in this order. If we asked to include the current edge to MST, use this edge to llink 1st vertex with the least currently isolated vertex. If we asked NOT to include the current edge to MST, use this edge to link some vertices that are already linked but have no edges between them. To do this it’s convenient to have two pointer on vertices (let’s call them FROM and TO). At the beginning, FROM=2, TO=3. When we are to link two already linked vertices, we add new edge (FROM, TO) and increment FROM. If FROM becomes equal to TO, we can assume we already added all possible edges to TO, so we increment TO and set FROM to 2. This means from this moment we will use non-MST edges to connect TO with all previous vertices starting from 2. If it appears that TO looks at currently isolated vertex, we can assume there are no place for non-MST edge it the graph, so the answer is Impossible. Keep doing in the described way, we’ll be adding MST edges as (1,2), …, (1,n) and non-MST edges as (2,3), (2,4), (3,4), (2,5), (3,5), (4,5), ...

605C - Freelancer's Dreams. We can let our hero not to receive money or experience for some projects. This new opportunity does not change the answer. Consider the hero spent time T to achieve his dream. On each project he spent some part of this time (possibly zero). So the average speed of making money and experience was linear combination of speeds on all these projects, weighted by parts of time spent for each of the projects.

Let’s build the set P on the plane of points (x, y) such that we can receive x money and y experience per time unit. Place points (a[i], b[i]) on the plane. Add also two points (max(a[i]), 0) and (0, max(b[i])). All these points for sure are included to P. Find their convex hull. After that, any point inside or at the border of the convex hull would correspond to usage of some linear combination of projects.

Now we should select some point which hero should use as the average speed of receiving money and experience during all time of achieving his dream. This point should be non-strictly inside the convex hull. The dream is realized if we get to point (A,B). The problem lets us to get upper of righter, but to do so is not easier than to get to the (A,B) itself. So let’s direct a ray from (0,0) to (A,B) and find the latest moment when this ray was inside our convex hull. This point would correspond to the largest available speed of receiving resources in the direction of point (A,B). Coordinates of this point are speed of getting resources.

To find the point, we have to intersect the ray and the convex hull.

605D - Board Game. Consider n vectors starting at points (a[i], b[i]) and ending at points (c[i], d[i]). Run BFS. On each of its stages we must able to perform such an operation: get set of vectors starting inside rectangle 0 <= x <= c[i], 0 <= y <= d[i] and never consider these vectors again. It can be managed like this. Compress x-coordinates. For each x we’ll hold the list of vectors which first coordinate is x. Create a segment tree with first coordinate as index and second coordinate as value. The segment tree must be able to find index of minimum for segment and to set value at point. Now consider we have to find all the vectors with first coordinate from 0 to x and second coordinate from 0 to y. Let’s find index of minimum in the segment tree for segment [0, x]. This minimum points us to the vector (x,y), whose x — that index of minimum and y — value of minimum. Remove it from list of vectors (adding also to the queue of the BFS) and set in the segment tree to this index second coordinate of the next vector with first coordinate x. Continue this way while minimum on a segment remains less than y. So, on each step we will find list of not yet visited vectors in the bottom right rectangle, and each vector would be considered only once, after what it would be deleted from data structures.

605E - Intergalaxy Trips. The vertex is the better, the less is the expected number of moves from it to reach finish. The overall strategy is: if it is possible to move to vertex better than current, you should move to it, otherwise stay in place. Just like in Dijkstra, we will keep estimates of answer for each vertex, and fix these estimates as the final answer for all vertices one by one, starting from best vertices to the worst. On the first step we will fix vertex N (the answer for it is zero). On the second step – vertex from which it’s easiest to reach N. On the third step – vertex from which it’s easiest to finish, moving to vertices determined on first two steps. And so on. On each step we find such vertex which gives best expected number of moves if we are to move from it to vertices better than it and then we fix this expected number – it cannot change from now. For each non-fixed yet vertex we can find an estimate of expected time it takes to reach finish from it. In this estimate we take into account knowledge about vertices we know answer for. We iterate through vertices in order of non-increasing answer for them, so the answer for vertex being estimated is not better than for vertices we already iterate through. Let’s see the expression for expected time of getting to finish from vertex x, considering use of tactic “move to best of i accessible vertices we know answer for, or stay in place”:

m(x) = p(x, v[0]) * ans(v[0]) + (1 — p(x, v[0]) * p(x, v[1]) * ans(v[1]) + (1 — p(x, v[0]) * (1 — p(x, v[1]) * p(x, v[2]) * ans(v[2]) + … + (1 — p(x, v[0]) * (1 — p(x, v[1]) * … * (1 — p(x, v[i-1]) * m(x) + 1

Here m(x) – estimate for vertex x, p(a,b) – the probability of existence of edge (a,b), and ans(v) – known answer for vertex v.

Note that m(x) expressed by itself, because there is a probability of staying in place.

We will keep estimating expression for each vertex in the form of m(x) = A[x] * m(x) + B[x].

For each vertex we will keep A[x] and B[x]. This would mean that with some probabilites it would be possible to move to some better vertex, and this opportunity gives contribution to expected time equal to B[x], and also with some probability we have to stay in place, and this probability is A[x] (this is just the same as coefficient before m(x) in the expression).

So, on each step we select one currently non-fixed vertex v with minimal estimate, then fix it and do relaxation from it, refreshing estimates for other vertices. When we refresh estimate for some vertex x, we change its A[x] and B[x]. A[x] is reduced by A[x] * p(x,v), because the probability of staying still consider it’s not possible to move to v. B[x] is increased by A[x] * p(x,v) * ans(v), where A[x] is the probability that it’s not possible to use some vertex better than v, A[x] * p(x,v) is the probability that it’s also possible to use vertex v, and ans(v) – known answer we just fixed for vertex v. To calculate the value of estimate for some vertex x, we can use expression m(x) = A[x] * m(x) + B[x] and express m(x) from it. Exactly m(x) is that value we should keep on the priority queue in out Dijkstra analogue, and exactly m(x) is the value to fix as the final answer for vertex x, when this vertex is announced as vertex with minimal estimate at the start of a step.

Codeforces Round #334 Editorial

By pi37, history, 7 years ago, In EnglishProblem 0: Richard has been infected with bovine spongiform encephalopathy. Help Kevin understand what he's saying!

Div 2 AHint: Just do it! But if you're having trouble, try doing your computations using only integers.

This problem is straightforward implementation---just code what's described in the problem statement. However, floating point error is one place where you can trip up. Avoid it by rounding (adding 0.5 before casting to int), or by doing all calculations with integers. The latter is possible since 250 always divides the maximum point value of a problem. Thus when we rewrite our formula for score as , it is easy to check that we only have integers as intermediate values.

Code: http://codeforces.com/contest/604/submission/14608458

Div 2 BHint: Try thinking about a sorted list of cowbells. What do we do with the largest ones?

Intuitively, we want to use as many boxes as we can and put the largest cowbells by themselves. Then, we want to pair the leftover cowbells so that the largest sum of a pair is minimized.This leads to the following greedy algorithm:

First, if k ≥ n, then each cowbell can go into its own box, so our answer is max(s1, s2, ..., sn). Otherwise, we can have at most 2k - n boxes that contain one cowbell. So as the cowbells are sorted by size, we put the 2k - n largest into their own boxes. For the remaining n - (2k - n) = 2(n - k) cowbells, we pair the i th largest cowbell with the (2(n - k) - i + 1) th largest. In other words, we match the smallest remaining cowbell with the largest, the second smallest with the second largest, and so on. Given these pairings, we can loop through them to find the largest box we'll need. The complexity of this algorithm is O(n) in all cases.

To prove that this greedy works, think about the cowbell the the largest one gets paired with. If it's not the smallest, we can perform a swap so that the largest cowbell is paired with the smallest and not make our answer worse. After we've paired the largest cowbell, we can apply the same logic to the second largest, third largest, etc. until we're done.

Code: http://codeforces.com/contest/604/submission/14608465

Div 2 C/Div 1 AHint: Is there any easy way to describe the longest alternating subsequence of a string? What happens at the endpoints of the substring that we flip?

Imagine compressing each contiguous block of the same character into a single character. For example, the first sample case 10000011 gets mapped to 101. Then the longest alternating subsequence of our string is equal to the length of our compressed string. So what does flipping a substring do to our compressed string? To answer this, we can think about flipping a substring as flipping two (possibly empty) prefixes. As an example, consider the string 10000011. Flipping the bolded substring 100 00 011 is equivalent to flipping the two bolded prefixes 10000011 and 10000.

For the most part, flipping the prefix of a string also flips the corresponding portion of the compressed string. The interesting case occurs at the endpoint of the prefix. Here, we have two possibilities: the two characters on either side of the endpoint are the same or different. If they are the same (00 or 11), then flipping this prefix adds an extra character into our compressed string. If they are different (01 or 10), we merge two characters in our compressed string. These increase and decrease, respectively, the length of the longest alternating subsequence by one. There is actually one more case that we left out: when the endpoint of our prefix is also an endpoint of the string. Then it is easy to check that the length of the longest alternating subsequence doesn't change.

With these observations, we see that we want to flip prefixes that end between 00 or 11 substrings. Each such substring allows us to increase our result by one, up to a maximum of two, since we only have two flips. If there exist no such substrings that we can flip, we can always flip the entire string and have our result stay the same. Thus our answer is the length of the initial longest alternating subsequence plus .

A very easy way to even simplify the above is to notice that if the initial longest alternating subsequence has length len - 2, then there will definitely be two 00 or 11 substrings. If it has length n - 1, then it has exactly one 00 or 11 substring. So our answer can be seen as the even easier .

Code: http://codeforces.com/contest/603/submission/14608473

Div 2 D/Div 1 BHint: First there are special cases k = 0 and k = 1. After clearing these out, think about the following: given the value of f(n) for some n, how many other values of f can we find?

We first have the degenerate cases where k = 0 and k = 1. If k = 0, then the functional equaton is equivalent to f(0) = 0. Therefore, pp - 1 functions satisfy this, because the values f(1), f(2), ..., f(p - 1) can be anything in {0, 1, 2, ..., p - 1}.

If k = 1, then the equation is just f(x) = f(x). Therefore pp functions satisfy this, because the values f(0), f(1), f(2), ..., f(p - 1) can be anything in {0, 1, 2, ..., p - 1}.

Now assume that k ≥ 2, and let m be the least positive integer such that  This is called the \emph{order} of  First, plug in x = 0 to find that  as p is prime, and . Now for some integer , choose a value for f(n). Given this value, we can easily show that  just by plugging in x = ki - 1n into the functional equation and using induction. Note that the numbers n, kn, k2n, ..., km - 1n are distinct , since m is the smallest number such that . Therefore, if we choose the value of f(n), we get the value of m numbers (). Therefore, if we choose f(n) of  integers n, we can get the value of all p - 1 nonzero integers. Since f(n) can be chosen in p ways for each of the  integers, the answer is .

Another way to think about this idea is to view each integer from 0 to p - 1 as a vertex in a graph, where n is connected to  for every integer i. If we fix the value of f(n) for some n, then f also becomes fixed for all other vertices in its connected component. Thus our answer is p raised to the the number of connected components in the graph.

Code: http://codeforces.com/contest/603/submission/14608476

Challenge: How quickly can we find m? For this problem we let O(p) pass, but faster methods certainly exist. (This is a very open-ended question.)

Div 2 E/Div 1 CHint: Is there a way to determine the winner of a game with many piles but looking at only one pile at a time?

We'll use the concepts of Grundy numbers and Sprague-Grundy's Theorem in this solution. The idea is that every game state can be assigned an integer number, and if there are many piles of a game, then the value assigned to that total game state is the xor of the values of each pile individually. The Grundy number of a state is the minimum number that is not achieved among any state that the state can move to.

Given this brief intro (which you can read more about many places), we have to separate the problem into 2 cases, k even and odd. Let f(n) denote the Grundy number of a pile of size n. By definition f(0) = 0.

If k is even, then when you split the pile of size 2n into k piles of size n, the resulting Grundy number of that state is  as k is even. Given this, it is easy to compute that f(0) = 0, f(1) = 1, f(2) = 2, f(3) = 0, f(4) = 1. Now I will show by induction that for n ≥ 2, f(2n - 1) = 0, f(2n) = 1. The base cases are clear. For f(2n - 1), the only state that can be moved to from here is that with 2n - 2 cows. By induction, f(2n - 2) = 1 > 0,  so f(2n - 1) = 0. On the other hand, for 2n, removing one stone gets to a state with 2n - 1 stones, with Grundy number f(2n - 1) = 0 by induction. Using the second operation gives a Grundy number of 0 as explained above, so the smallest positive integer not achieveable is 1, so f(2n) = 1.

The case where k is odd is similar but requires more work. Let's look at the splitting operation first. This time, from a pile of size 2n we can move to k piles of size n, with Grundy number  as k is odd. So from 2n we can achieve the Grundy numbers f(2n - 1) and f(n). Using this discussion, we can easily compute the first few Grundy numbers. f(0) = 0, f(1) = 1, f(2) = 0, f(3) = 1, f(4) = 2, f(5) = 0. I'll prove that for n ≥ 2, f(2n) > 0, f(2n + 1) = 0 by induction. The base cases are clear. Now, for n ≥ 3, since a pile of size 2n + 1 can only move to a pile of size 2n, which by induction has Grundy number f(2n) > 0, f(2n + 1) = 0. Similarly, because from a pile of size 2n, you can move to a pile of size 2n - 1, which has Grundy number f(2n - 1) = 0, f(2n) > 0. Now computing the general Grundy number f(n) for any n is easy. If n ≤ 4, we have them precomputed. If n is odd and n > 4, f(n) = 0. In n is even and n ≥ 6, then f(n) is the minimal excludent of f(n - 1) = 0 and f(n / 2) (because n - 1 is odd and  ≥ 5, so f(n - 1) = 0.) We can do this recursively,

The complexity is O(n) in the k even case and  in the k odd case.

Code: http://codeforces.com/contest/603/submission/14608484

Div 1 DHint: It seems like this would be O(n3) because of triples of lines. Can you reduce that with some geometric observations? Think of results from Euclidean geometry relating to 4 points lying on the same circle.

First, we will prove a lemma, known as the Simson Line:

Lemma:

Given points A, B, C, P in the plane with D, E, F on lines BC, CA,  and AB, respectively such that , then P lies on the circumcircle of  if and only if D, E,  and F are collinear.

 

Proof:

Assume that the points are configured as shown, and other other configurations follow similarly. Recall that a quadrilateral ABCP is cyclic if and only if . Note that this implies that a quadrilateral with two opposite right angles is cyclic, so in particular quadrilaterals AEPF, BFPD, CDPE are cyclic. Because

we get that ABPC is cyclic if and only if , if and only if .

Now note that  (again since BFPD is cyclic) and , so  if and only if , if and only if ABPC is cyclic. Thus the lemma is proven.

This lemma provides us with an efficient way to test if the circumcircle of the triangle formed by three lines in the plane passes through the origin. Specifically, for a line , let Xi be the projection of the origin onto . Then  form an original triangle if and only if Xi, Xj,  and Xk are collinear. Thus the problem reduces to finding the number of triples i < j < k with Xi, Xj, Xk collinear. The points Xi are all distinct, except that possibly two lines may pass through the origin, so we can have up to two points Xi at the origin.

Let us first solve the problem in the case that all points Xi are distinct. In this case, consider each i, and store for each slope how many points Xj with i < j the line Xi Xj has this slope. This storage can be done in O(1) or , depending on how hashing is done. Note also that we must consider a vertical line to have the valid slope . If  are the number of points corresponding to the distinct slopes  through Xi (for points Xj with i < j), then for Xi we add to the total count

If the Xi are not distinct, we only encounter an issue in the above solutions when we consider the slope through points Xi and Xj where Xi = Xj. In this case, for any third k, Xi, Xj,  and Xk are collinear. So when considering slopes from Xi in the original algorithm, we simply run the algorithm on all slopes other than the one through Xj, and simply add n - 2 to the count afterwards to account for the n - 2 points which are collinear with Xi and Xj.

Running the above, we get an algorithm that runs in O(n2) or .

Another approach which doesn't involve the Simson line follows a similar idea: we want to find some property f(i, j) between points Xi and Xj such that the triangle formed by indices i, j, k is original if and only if f(i, j) = f(i, k). Then we can use the same argument as above to solve the problem in O(n2) or . Instead of using the slope between points i, j as the property, suppose  and  meet at some point P, and let O be the origin (again O = P is a special case). Then we let f(i, j) be the angle between  and OP. Because of the properties of cyclic quadrilaterals explained above, the triangle is original if and only if f(i, j) = f(i, k), up to defining the angle as positive or negative and modulo . Following this approach carefully, we can finish as before.

Code: http://codeforces.com/contest/603/submission/14608489

Div 1 EHint: What is a necessary and sufficient condition for Kevin to be able to pave paths so that each edge is incident to an odd number of them? Does this problem remind you of constructing a minimum spanning tree?

We represent this problem on a graph with pastures as vertices and paths as edges. Call a paving where each vertex is incident to an odd number of paved edges an \emph{odd paving}. We start with a lemma about such pavings:

A connected graph has an odd paving if and only if it has an even number of vertices.

For connected graphs with even numbers of vertices, we can prove this observation by considering a spanning tree of the graph. To construct an odd paving, start from the leaves of the tree and greedily pave edges so that each vertex but the root is incident to an odd number of paved edges. Now consider the graph consisting only of paved edges. Since the sum of all vertex degrees in this graph must be even, it follows that the root is also incident to an odd number of paved edges, so the paving is odd.

Now we prove that no odd paving exists in the case of an odd number of vertices. Suppose for the sake of contradiction that one existed. Then the sum of the vertex degrees in the graph consisting only of paved edges would be odd, which is impossible. Thus no odd paving exists for graphs with odd numbers of vertices.

Note that this observation turns the degree condition into a condition on the parity of connected component sizes. We finish the problem using this equivalent condition.

Suppose we only want to solve this problem once, after all m edges are added. Then we can use Kruskal's algorithm to build a minimum spanning forest by adding edges in order of increasing length. We stop once each tree in the forest contains an even number of vertices, since the graph now satisfies the conditions of the lemma. If there are still odd-sized components by the time we add all the edges, then no odd paving exists. This algorithm, however, runs in  per query, which is too slow if we want to answer after adding each edge.

To speed things up, we maintain the ending position of our version of Kruskal's as we add edges online. We do this using a data structure called a link-cut tree. This data structure allows us to add and delete edges from a forest while handling path and connectivity queries. All of these operations take only  time per operation. (A path query asks for something like maximum-weight edge on the path between u and v; a connectivity query asks if u and v are connected.)

First, let's look at how we can solve the online minimum spanning tree problem with a link-cut tree. We augment our data structure to support finding the maximum-weight edge on the path between vertices u and v in . Adding an edge then works as follows: If u and v are not connected, connect u and v; otherwise, if the new edge is cheaper, delete the maximum-weight edge on the path between u and v and add the new edge. To make implementation easier, we can represent edges as vertices in the link-cut tree. For example, if u and v are connected, in the link-cut tree they would be connected as u--e--v, where e is a vertex representing edge u--v.

We solve our original problem with a similar idea. Note that the end state of our variation on Kruskal's is a minimum spanning forest after adding k edges. (We no longer care about the edges that are longer than the longest of these k edges, since the answer is monotonically decreasing---more edges never hurt.) So when we add another edge to the forest, we can use the online minimum spanning tree idea to get the minimum spanning forest that uses the old cheapest k edges and our new edge. Note that inserting the edge never increases the number of odd components: even linked to even is even, even linked to odd is odd, odd linked to odd is even.

Now, pretend that we got this arrangement by running Kruskal's algorithm, adding the edges one-by-one. We can "roll back" the steps of the algorithm by deleting the longest edge until deleting another edge would give us an odd-sized component. (If we started with an odd-sized component, we don't delete anything.) This gives us an ending position for our Kruskal-like algorithm that uses a minimal number of edges so that all components have even size---we're ready to add another edge. ("But wait a minute!" you may say. "What if edges have the same weight?" In this case, if we can't remove one of possibly many longest edges, then we can't lower our answer anyway, so we stop.)

Note that all of this takes amortized  time per edge. The path queries and the insertion of the new edge involve a constant number of link-cut tree operations. To know which edge to delete, the set of edges currently in the forest can be stored easily in an STL set sorted by length. When adding an edge, we also pay for the cost of deleting that edge, so the "rolling back" phase gets accounted for. Therefore, this algorithm runs in .

You may have noticed that executing this algorithm involves checking the size of a connected component in the link-cut tree. This is a detail that needs to be resolved carefully, since link-cut trees usually only handle path operations, not operations that involve subtrees. Here, we stop treating link-cut trees as a black box. (If you aren't familiar with the data structure, you should read about it at https://courses.csail.mit.edu/6.851/spring12/scribe/L19.pdf ) At each vertex, we track the size of its virtual subtree, as well as the sum of the real subtree sizes of its non-preferred children. We can update these values while linking and exposing (a.k.a. accessing), allowing us to perform root-change operations while keeping real subtree sizes. To get the size of a component, we just query for the real subtree size of the root.

Since the implementation of this algorithm can be rather challenging, here is a link to a documented version of my code:

Code: http://codeforces.com/contest/603/submission/14608500

Codeforces Round #333 — editorial

By Xellos, history, 7 years ago, In EnglishHints:div2A: Try conversions between bases.

div2B: Solve a simpler version of the problem where Ai + 1 ≠ Ai for all i.

div1A: What are the shortest paths of the vehicles? what's the shorter of those paths?

div1B: Forget about the ceiling function. Draw points (i, A[i]) and lines between them — what's the Lipschitz constant geometrically?

div1C: Some dynamic programming. Definitely not for the exp. score of one person — look at fixed scores instead.

div1D: Compute dif(v) in O(N) (without hashing) and then solve the problem in O(N2). You need some smart merges.

div1E: Can you solve the problem without events of type 1 or 2? Also, how about solving it offline — as queries on subsets.

 

Div. 2 A: Two BasesIt's easy to compare two numbers if the same base belong to both. And our numbers can be converted to a common base — just use the formulas

A straightforward implementation takes O(N + M) time and memory. Watch out, you need 64-bit integers! And don't use pow — iterating  is better.

 

Div. 2 B: Approximating a Constant RangeLet's process the numbers from left to right and recompute the longest range ending at the currently processed number.

One option would be remembering the last position of each integer using STL map<>/set<> data structures, looking at the first occurrences of Ai plus/minus 1 or 2 to the left of the current Ai and deciding on the almost constant range ending at Ai based on the second closest of those numbers.

However, there's a simpler and more efficient option — notice that if we look at non-zero differences in any almost constant range, then they must alternate: ..,  + 1,  - 1,  + 1,  - 1, ... If there were two successive differences of  + 1-s or  - 1-s (possibly separated by some differences of 0), then we'd have numbers a - 1, a, a, ..., a, a + 1, so a range that contains them isn't almost constant.

Let's remember the latest non-zero difference (whether it was +1 or -1 and where it happened); it's easy to update this info when encountering a new non-zero difference.

When doing that update, we should also check whether the new non-zero difference is the same as the latest one (if Ai - Ai - 1 = Aj + 1 - Aj). If it is, then we know that any almost constant range that contains Ai can't contain Aj. Therefore, we can keep the current leftmost endpoint l of a constant range and update it to j + 1 in any such situation; the length of the longest almost constant range ending at Ai will be i - l + 1.

This only needs a constant number of operations per each Ai, so the time complexity is O(N). Memory: O(N), but it can be implemented in O(1).

Bonus: the maximum difference permitted in an almost constant range is an arbitrary D.

 

Div. 2 C / Div. 1 A: The Two RoutesThe condition that the train and bus can't meet at one vertex except the final one is just trolling. If there's a railway , then the train can take it and wait in town N. If there's no such railway, then there's a road , the bus can take it and wait in N instead. There's nothing forbidding this :D.

The route of one vehicle is clear. How about the other one? Well, it can move as it wants, so the answer is the length of its shortest path from 1 to N... or  - 1 if no such path exists. It can be found by BFS in time O(N + M) = O(N2).

In order to avoid casework, we can just compute the answer as the maximum of the train's and the bus's shortest distance from 1 to N. That way, we compute ; since the answer is  ≥ 1, it works well.

In summary, time and memory complexity: O(N2).

Bonus: Assume that there are M1 roads and M2 railways given on the input, all of them pairwise distinct.

Bonus 2: Additionally, assume that the edges are weighted. The speed of both vehicles is still the same — traversing an edge of length l takes l hours.

 

Div. 2 D / Div. 1 B: Lipshitz SequenceLet  for i ≠ j.

Key observation: it's sufficient to consider j = i + 1 when calculating the Lipschitz constant. It can be seen if you draw points (i, Ai) and lines between them on paper — the steepest lines must be between adjacent pairs of points.

In order to prove it properly, we'll consider three numbers Ai, Aj, Ak (i < j < k) and show that one of the numbers L1(i, j), L1(j, k) is  ≥ L1(i, k). W.l.o.g., we may assume Ai ≤ Ak. There are 3 cases depending on the position of Aj relative to Ai, Ak:

Aj > Ai, Ak — we can see that L1(i, j) > L1(i, k), since |Aj - Ai| = Aj - Ai > Ak - Ai = |Ak - Ai| and j - i < k - i; we just need to divide those inequalities

Aj < Ai, Ak — this is similar to the previous case, we can prove that L1(j, k) > L1(i, k) in the same way

Ai ≤ Aj ≤ Ak — this case requires more work:

we'll denote d1y = Aj - Ai, d2y = Ak - Aj, d1x = j - i, d2x = k - jthen, L1(i, j) = d1y / d1x, L1(j, k) = d2y / d2x, L1(i, k) = (d1y + d2y) / (d1x + d2x)let's prove it by contradiction: assume that L1(i, j), L1(j, k) < L1(i, k)d1y + d2y = L1(i, j)d1x + L1(j, k)d2x < L1(i, k)d1x + L1(i, k)d2x = L1(i, k)(d1x + d2x) = d1y + d2y, which is a contradictionWe've just proved that to any L1 computed for two elements A[i], A[k] with k > i + 1, we can replace one of i, j by a point j between them without decreasing L1; a sufficient amount of such operations will give us k = i + 1. Therefore, the max. L1 can be found by only considering differences between adjacent points.

This is actually a huge simplification — the Lipschitz constant of an array is the maximum abs. difference of adjacent elements! If we replace the array A[1..n] by an array D[1..n - 1] of differences, D[i] = A[i + 1] - A[i], then the Lipschitz constant of a subarray A[l, r] is the max. element in the subarray D[l..r - 1]. Finding subarray maxima actually sounds quite standard, doesn't it?

No segment trees, of course — there are still too many subarrays to consider.

So, what do we do next? There are queries to answer, but not too many of them, so we can process each of them in O(N) time. One approach that works is assigning a max. difference D[i] to each subarray — since there can be multiple max. D[i], let's take the leftmost one.

We can invert it to determine the subarrays for which a given D[i] is maximum: if D[ai] is the closest difference to the left of D[i] that's  ≥ D[i] or ai = 0 if there's none, and D[bi] is the closest difference to the right that's  > D[i] or bi = n - 1 if there's none (note the strict/non-strict inequality signs — we don't care about differences equal to D[i] to its right, but there can't be any to its left, or it wouldn't be the leftmost max.), then those are all subarrays D[j..k] such that ai < j ≤ i ≤ k < bi.

If we don't have the whole array D[1..n - 1], but only some subarray D[l..r], then we can simply replace ai by  and bi by . The number of those subarrays is Pi = (i - ai)(bi - i), since we can choose j and k independently.

All we have to do to answer a query is check all differences, take ai, bi (as the max/min with some precomputed values) and compute Pi; the answer to the query is . We only need to precompute all ai, bi for the whole array D[1..n - 1] now; that's a standard problem, solvable using stacks in O(N) time or using maps + Fenwick trees in  time.

The total time complexity is O(NQ), memory O(N).

Bonus: Q ≤ 105.

 

Div. 1 C: Kleofáš and the n-thlonAs it usually happens with computing expected values, the solution is dynamic programming. There are 2 things we could try to compute: probabilities of individual overall ranks of Kleofáš or just some expected values. In this case, the latter option works.

"one bit is 8 bytes?""no, the other way around""so 8 bytes is 1 bit?"After some attempts, one finds out that there's no reasonable way to make a DP for an expected rank or score of one person (or multiple people). What does work, and will be the basis of our solution, is the exact opposite: we can compute the expected number of people with a given score. The most obvious DP for it would compute E(i, s) — the exp. number of people other than Kleofáš with score s after the first i competitions.

Initially, E(0, 0) = m - 1 and E(0, s > 0) = 0. How can we get someone with score s in competition i? That person can have any score k from 1 to m except xi (since Kleofáš has that one) with the same probability . The expected values are sums with probabilities P(i, s, j) that there are j people with score s:

Considering that the probability that one of them will get score k is , we know that with probability , we had j people with score s before the competition and one of them had score s + k after that competition — adding 1 to E(i + 1, s + k). By summation over j, we'll find the exp. number of people who had overall score s and scored k more:

Lol, it turns out to be so simple.

We can find the probability E(i + 1, t) afterwards: since getting overall score t after i + 1 competitions means getting score k in the currently processed competition and overall score s = t - k before, and both distinct k and expectations for people with distinct s are totally independent of each other, then we just need to sum up the exp. numbers of people with those scores (which we just computed) over the allowed k:

The formulas for our DP are now complete and we can use them to compute E(n, s) for all 1 ≤ s ≤ mn. Since E(n, s) people with s greater than the overall score sk of Kleofáš add E(n, s) to the overall rank of Kleofáš and people with s ≤ sk add nothing, we can find the answer as

This takes O(m2n2) time, since there are O(mn) scores, O(mn2) states of the DP and directly computing each of them takes O(m) time. Too slow.

We can do better, of course. Let's forget about dividing by m - 1 for a while; then, E(i + 1, t) is a sum of E(i, s) for one or two ranges of scores — or for one range minus one value. If you can solve div1C, then you should immediately know what to do: compute prefix sums of E(i, s) over s and find E(i + 1, t) for each t using them.

And now, computing one state takes O(1) time and the problem is solved in O(mn2) time (and memory).

Bonus: Really, how fast can you solve this problem?

 

Div. 1 D: Acyclic Organic CompoundsThe name is really almost unrelated — it's just what a tree with arbitrary letters typically is in chemistry.

If you solved problem TREEPATH from the recent Codechef November Challenge, this problem should be easier for you — it uses the same technique, after all.

Let's figure out how to compute  for just one fixed v. One more or less obvious way is computing hashes of our strings in a DFS and then counting the number of distinct hashes (which is why there are anti-hash tests :D). However, there's another, deterministic and faster way.

Compressing the subtree Tv into a trie.Recall that a trie is a rooted tree with a letter in each vertex (or possibly nothing in the root), where each vertex encodes a unique string read along the path from the root to it; it has at most σ sons, where σ = 26 is the size of the alphabet, and each son contains a different letter. Adding a son is done trivially in O(σ) (each vertex contains an array of 26 links to — possibly non-existent — sons) and moving down to a son with the character c is then possible in O(1).

Compressing a subtree can be done in a DFS. Let's build a trie Hv (because Tv is already used), initially consisting only of one vertex — the root containing the letter sv. In the DFS, we'll remember the current vertex R of the tree T and the current vertex cur of the trie. We'll start the DFS at v with cur being the root of Hv; all we need to do is look at each son S of R in DFS, create the son curs of cur corresponding to the character sS (if it didn't exist yet) and run DFS(S, curs). This DFS does nothing but construct Hv that encodes all strings read down from v in Tv. And since each vertex of Hv encodes a distinct string,  is the number of vertices of Hv.

This runs in O(|Tv|σ) time, since it can create a trie with |Tv| vertices in the worst case. Overall, it'd be O(N2σ) if T looks sufficiently like a path.

The HLD trickWell, what can we do to improve it? This trick is really the same — find the son w of v that has the maximum |Tw|, add sv to Hw and make it Hv; then, DFS through the rest of Tv and complete the trie Hv as in the slow solution. The trick resembles HLD a lot, since we're basically remembering tries on HLD-paths.

If v is a leaf, of course, we can just create Hv that consists of one vertex.

How do we "add" v to a trie Hw of its son w? Well, v should be the root of the trie afterwards and the original Hw's root should become its son, so we're rerooting Hw. We'll just create a new vertex in Hw with sv in it, make it the root of Hw and make the previous root of Hw its son. And if we number the tries somehow, then we can just set the number of Hv to be the number of Hw.

It remains true that dif(v) is |Hv| — the number of vertices in the trie Hv, which allows us to compute those values directly. After computing dif(v) for each v, we can just compute both statistics directly in O(N).

Since each vertex of T corresponds to vertices in at most  tries (for each heavy edge that's on the path from it to the root), we aren't creating tries with a total of O(N2) vertices, but . The time complexity is therefore . However, the same is true for the memory, so you can't waste it too much!

Bonus: you have an additional tiebreaker condition for vertices with identical . Count the number of distinct strings which occurred exactly k times for each k in an array Pr[]; take the vertex/vertices with lexicograhically maximum Pr[] (as many strings as possible which occur only once, etc).

Bonus 2: Can you get rid of the logarithm in the time complexity?

 

Comic strip name: Indy. Go read the whole thing, it's not very long, but pretty good.

Div. 1 E: A Museum RobberyIn this problem, we are supposed to solve the 0-1 knapsack problem for a set of items which changes over time. We'll solve it offline — each query (event of type 3) is asked about a subset of all N exhibits appearing on the input.

IntroductionIf we just had 1 query and nothing else, it's just standard knapsack DP. We'll add the exhibits one by one and update s(m) (initially, s(m) = 0 for all m). When processing an exhibit with (v, w), in order to get loot with mass m, we can either take that exhibit and get value at least s(m - w) + v, or not take it and get s(m); therefore, we need to replace s(m) by ; the right way to do it is in decreasing order of m.

In fact, it's possible to merge 2 knapsacks with any number of items in O(k2), but that's not what we want here.

Note that we can add exhibits this way. Thus, if there were no queries of type 2, we would be able to solve whole problem in O(Nk) time by just remembering the current s(m) and updating it when adding an exhibit. Even if all queries were of type 2 (with larger n), we'd be able to solve it in O(nk) time in a similar way after sorting the exhibits in the order of their removal and processing queries/removals in reverse chronological order.

The keyLet's have q queries numbered 1 through Q in the order in which they're asked; query q is asked on some subset Sq of exhibits.

MAGIC TRICK: Compute the values s(m) only for subsets  — the intersections of pairs of queries 2q, 2q + 1 (intersection of the first and the second query, of the third and fourth etc.), recursively. Then, recompute s(m) for all individual queries in O((N + Q)k) time by adding elements which are missing in the intersection, using the standard knapsack method.

What?! How does this work?! Shouldn't it be more like O(N2) time? Well, no — just look at one exhibit and the queries where it appears. It'll be a contiguous range of them — since it's displayed until it's removed (or the events end). This element will only be missing in the intersection, but present in one query (so it'll be one of the elements added using knapsack DP), if query 2q + 1 is the one where it appears first or query 2q the one where it appears last. That makes at most two addittions of each element and O(N) over all of them; adding each of them takes O(k) time, which gives O(Nk).

The second part of the complexity, O(Qk) time, is spent by copying the values of s(m) first from the intersection of queries 2q and 2q + 1 to those individual queries.

If we're left with just one query, we can solve it in O(Nk) as the usual 0-1 knapsack.

Since we're halving the number of queries when recursing deeper, we can only recurse to depth  and the time complexity is .

A different point of view (Baklazan's)We can also look at this as building a perfect binary tree with sets S1, ..., SQ in leaves and the intersection of sets of children in every other vertex.

 

For each vertex v of this tree, we're solving the knapsack — computing s(m) — for the set Dv of displayed exhibits in it. We will solve the knapsack for the root directly and then proceed to the leaves. In each vertex v, we will take s(m), the set Dp of its parent p and find s(m) for v by adding exhibits which are in Dv, but not in Dp.

We know that the set Dp is of the form  for some a, b and Dv is either of the form  or  for  (depending on whether it's the left or the right son). In the first case, only elements removed between the m-th and b-th query have to be added and in the second case, it's only elements added between the a-th and m + 1-th query. Since each element will only be added/removed once and the ranges of queries on the same level of the tree are disjoint, we will do O((N + Q)k) work on each level and the overall time complexity is .

Finding the intersections and exhibits not in the intersectionsOf course, bruteforcing them in O(NQ) isn't such a bad idea, but it'd probably TLE — and we can do better. We've just described how we can pick those exhibits based on the queries between which they were added/removed. Therefore, we can find — for each exhibit — the interval of queries for which it was displayed and remember for each two consecutive queries the elements added and removed between them; finding the exhibits added/removed in some range is then just a matter of iterating over them. Since we're actually adding all of them, this won't worsen the time complexity.

In order to efficiently determine the exhibits in some set , we can remember for each exhibit the interval of time when it was displayed. The exhibit is in the set  if and only if it was displayed before the a-th query and remained displayed at least until the b-th query.

To conclude, the time complexity is  and since we don't need to remember all levels of the perfect binary tree, but just the one we're computing and the one above it, the memory complexity is O(qk).

Editorial Codeforces Round #332 (Div. 2)

By Yury_Bandarchuk, 7 years ago, translation, In EnglishProblem A.

Everything that you needed to do — solve some similar cases.

You need to check the following cases:

Home  the first shop  the second shop  home

Home  the first shop  the second shop  the first shop  home

Home  the second shop  home  the first shop  home

Home  the second shop  the first shop  the second shop  home

Time: O(1)

Problem B.

First of all, you should read the statement carefully. Then, for every element 1 ... N create a list of integers from what we can get this number.

After that you have to check some cases, before that create a special mark for answer Ambiguity:

Let current element of the given array is bi

If two or more elements exist from which it's possible to get bi, then use your special mark that answer is AmbiguityIf no elements exist from which it's possible to get bi, then print ImpossibleIf only one element exists from which it's possible to get bi just change bi to the value of this elementFinally, if you marked your special mark then print Ambiguity, else print Possible and correct answer.

Time: O(N)

Problem C.

Let's take a minute to see how the best answer should look like.

Let Hi be a sorted sequence of hi. Let E — set of indices of the last elements of each block. Then  e  E, first e sorted elements of sequence hi are equal to the first e elements of the sequence Hj.

So, it is not difficult to notice that the size of E is the answer for the problem.

Firstly, we need to calculate two arrays: prefmax and suffmin, where prefmaxi — maximum between a1, a2, ..., ai, and suffmini — minimum between ai, ai + 1, ..., an.

If you want to get the answer, just calculate the number of indices i that prefmaxi  ≤  suffmini + 1.

Time: O(N)

Problem D.

First of all, let's solve this problem for n ≤ m, and then just swap n and m and print the answer. Important! Not to print squares twice!

We can use this formula for fixed n & m (n ≤ m) for calculating the value of x. 

Then 

Using the sum squares and the sum of the first k numbers we can easily solve this problem.

Getting 6x = 6n2 * m - 3(n2 + n3 - nm - n2) + 2n3 - 3n3 + n = 3 * m * n2 + 3 * m * n - n3 + n

As we solved this task for n ≤ m the 3n2 * m =  ≈ n3, it means that n is not greater than .

Time: 

Problem E.

The solution for this problem is dynamic programming.

Let froot, mask is the number of ways to build a tree with root in vertex root using vertices from the mask mask and all restrictions were met. For convenience we shall number the vertices from zero.

The answer is f0, 2n - 1.

Trivial states are the states where a mask has only one single bit. In such cases froot, mask = 1.

Let's solve this task recursively with memorization. To make the transition, we need to choose some kind of mask newMask, which is necessarily is the submask of mask mask. Then we should try to find new root newRoot in mask newMask. Also, in order not to count the same tree repeatedly impose conditions on the mask newMask. Namely, we shall take only such masks newMask, in which the senior bit (not in charge of the root) coincides with a senior bit (not in charge of the root) of the mask mask. After that, you need to check the fulfillment of all conditions to the edges and to the lca. If everything is OK, update . Where  means xor.

What about checking lca, it's possible to do it in time O(N2) — previously memorized lca for each pair or in the worst case in time O(Q) just iterating through all pairs of vertices, for which some vertex v is lca.

Time: O(3N·N3) or O(3N·N·Q)

Codeforces Round #331 Editorial

By numbertheorist17, 7 years ago, In EnglishProblem AIt is a necessary and sufficient condition that we have exactly 2 distinct values for x and y. If we have less than 2 distinct values for any variable, then there is no way to know the length of that dimension. If there are at least 3 distinct values for any variable, then that means more than 3 vertices lie on that dimension, which cannot happen since there can be at most 2 vertices in a line segment. The area, if it can be found, is just the difference of values of the x coordinates times the difference of values of the y coordinates.

Complexity: O(1)

Code: Solution

Problem BNo matter what, we make |b1| operations to make a1 equal to b1. Once this is done, a2, a3, ... an = b1. Then no matter what, we must make |b2 - b1| operations to make a2 equal to b2. In general, to make ai = bi we need to make |bi - bi - 1| operations, so in total we make |b1| + |b2 - b1| + |b3 - b2| + ... + |bn - bn - 1| operations.

Complexity: O(n)

Code: Solution

Problem CNote that if there is an integer d so that the number of wi equal to d differs from the number of the given squares whose weight equals d, then the answer is automatically "NO". This can be easily checked by using a map for the wi and the weights of the squares and checking if the maps are the same. This step takes  time.

Let d be an integer, and let D be the set of all i so that wi = d. Let W be the set of all special points (x, y) so that the weight of (x, y) is d. Note that W and D have the same number of elements. Suppose that i1 < i2 < ... < ik are the elements of D. Let (a, b) < (c, d) if a < c or a = c and b < d. Suppose that (x1, y1) < (x2, y2) < ... < (xk, yk) are the elements of W. Note that the point (xj, yj) has to be labeled by ij for 1 ≤ j ≤ k.

Now, each special point is labeled. It remains to check if this is a valid labeling. This can be done by taking an array of vectors. The vector arr[i] will denote the points with x-coordinate i. This vector can be easily made from the points given in O(n) time, and since the points are already labeled, arr[i][j] will denote the label for the point (i, j). Now, for all points (i, j), the point (i, j + 1) (if it is special) and the point (i + 1, j) (if it is special) must have a greater number than (i, j). This step takes a total of O(n) time.

Complexity: 

Code: Solution

Bonus: Can you do this problem in O(n) time?

Comments: This problem was inspired by the representation theory of the group of permutations Sn (Representation theory of the Symmetric Group). Essential objects in the study of Sn are Young diagrams and standard Young tableau (Young Tableau). The weight of a point as defined by the problem is basically the same thing as the content of a square in a standard Young tableaux. If you have questions, feel free to message me.

Problem DLet us solve this problem using dynamic programming.

First let us reindex the trees by sorting them by x-coordinate. Let f(i, j, b1, b2) where we would like to consider the problem of if we only have trees i... j standing where b1 = 1 indicates that tree i - 1 falls right and b1 = 0 if it falls left and b2 = 1 indicates that tree j + 1 falls right and b2 = 0 if it falls left.

We start with the case that Wilbur chooses the left tree and it falls right. The plan is to calculate the expected length in this scenario and multiply by the chance of this case occurring, which is . We can easily calculate what is the farthest right tree that falls as a result of this and call it wi.

Then if wi >  = j this means the entire segment falls, from which the length of the ground covered by trees in i... j can be calculated. However, be careful when b2 = 0, as there may be overlapping covered regions when the tree j falls right but the tree j + 1 falls left.

If only wi < j, then we just consider adding the length of ground covered by trees i... wi falling right and add to the value of the subproblem f(wi + 1, j, 1, b2).

There is another interesting case where Wilbur chooses the left tree and it falls left. In this case we calculate the expected length and multiply by the chance of this occurring, which is . The expected length of ground covered by the trees here is just the length contributed by tree i falling left, which we must be careful calculating as there might be overlapping covered regions with the ith tree falling left and the i - 1th tree falling right. Then we also add the value of subproblem f(i + 1, j, 0, b2).

Doing this naively would take O(n3) time, but this can be lowered to O(n2) by precalculating what happens when tree i falls left or right.

We should also consider the cases that Wilbur chooses the right tree, but these cases are analogous by symmetry.

Complexity: O(n2)

Code: Solution

Problem ESolution 1: Suppose that s is a string in the query. Reverse s and the direction of all the moves that can be made on the table. Note that starting at any point that is part of a cycle, there is a loop and then edges that go out of the loop. So, for every point, it can be checked by dfs whether the s can be made by starting at that point by storing what is in the cycle.

Moreover, note that in the reversed graph, each point can only be a part of one cycle. Therefore, the total time for the dfs in a query is O(nm·SIGMA + |s|). This is good enough for q queries to run in time.

Complexity:  where SIGMA = 10 is the number of distinct characters in the table, and si is the query string for the i th query.

Code: Solution

Solution 2 (Actually too slow, see comment by waterfalls below for more details): For each string s, dfs from every node that has in degree equal to 0 in the original graph. There will be a path which leads into a cycle after which anything in the cycle can be used any number of times in s. Only every node with in degree equal to 0 has to be checked because every path which leads to a cycle is part of a larger path which starts with a vertex of in degree 0 that leads into a cycle.

This solution is slower, but it works in practice since it is really hard for a string to match so many times in the table. Each query will take O(n2·m2 + si) time, but it is much faster in practice.

Complexity:  where SIGMA = 10 is the number of distinct characters in the table, and si is the query string of the i th query.

Codeforces Round #330 (Div.1 + Div.2) Editorial

By fcspartakm, history, 7 years ago, translation, In English595A — Vitaly and Night

It was easy realization problem. Let's increase the variable i from 1 to n, and inside let's increase the variable j from 1 to 2·m. On every iteration we will increase the variable j on 2. If on current iteration a[i][j] = '1' or a[i][j + 1] = '1' let's increase the answer on one.

Asymptotic behavior of this solution — O(nm).

595B — Pasha and Phone

Let's calculate the answer to every block separately from each other and multiply the answer to the previous blocks to the answer for current block.

For the block with length equals to k we can calculate the answer in the following way. Let for this block the number must be divided on x and must not starts with digit y. Then the answer for this block — the number of numbers containing exactly k digits and which divisible by x, subtract the number of numbers which have the first digit equals to y and containing exactly k digits and plus the number of numbers which have the first digit equals to y - 1 (only if y > 0) and containing exactly k digits.

Asymptotic behavior of this solution — O(n / k).

594A — Warrior and Archer

Let's sort the points by increasing x coordinate and work with sorted points array next.

Let's suppose that after optimal playing points numbered l and r (l < r) are left. It's true that the first player didn't ban any of the points numbered i l < i < r, otherwise he could change his corresponding move to point l or point r (one could prove it doesn't depend on second player optimal moves) and change the optimal answer. It turns out that all the  points banned by the first player have numbers outside of [l, r] segment, therefore . We should notice that if the first player choosed any [l, r] for , he could always make the final points numbers located inside this segment.

The second player wants to make  (he couldn't make less), what is equivalent if he always ban points inside final [l, r] segment (numbered l < i < r). As soon as the second player doesn't know what segment first player have chosen after every of his moves, he must detect a point which satisfies him in every first player choice. It's true number of this point is the median of set of point numbers left (the odd number) after the first player move. The number of moves of the first player left is lesser by one than moves of the second player, so the first player later could ban some points from the left and some points from the right, except three middle points. Two of it (leftmost and rightmost ones) shouldn't be banned by the second player as soon as it could increase the size of banned points from the left (or from the right), but third middle point satisfies the second player in every first player choice. This way the second player always bans the point inside final point segment.

Thus the answer is the minimum between every of  values.

594B — Max and Bike

The main proposition to solve this problem — in the middle of every competition the sensor must be or in the top point of the wheel or in the bottom point of the wheel.

To calculate the answer we need to use binary search. If the center of the wheel moved on the distance c, then the sensor moved on the distance c + rsin(c / r), if the sensor was on the top point of the wheel in the middle, or on the distance c - rsin(c / r), if the sensor was on the bottom point of the wheel in the middle, where r — the radius of the wheel.

Asymptotic behavior of this solution — .

594С — Edo and Magnets

Let's find the centers of every rectangle and multiple them of 2 (to make all coordinates integers).Then we need to by the rectangle door, which contains all dots, but the lengths of the sides of this door must be rounded up to the nearest integers.

Now, let's delete the magnets from the door one by one, gradually the door will decrease. Obviously every time optimal to delete only dots, which owned to the sides of the rectangle. Let's brute 4k ways, how we will do delete the magnets. We will do it with helps of recursion, every time we will delete point with minimum or maximum value of the coordinates. If we will store 4 arrays (or 2 deques) we can do it with asymptotic O(1). Such a solution works O(4k).

It can be easily shown that this algorithm delete always some number of the leftmost, rightmost, uppermost and lowermost points. So we can brute how k will distributed between this values and we can model the deleting with helps of 4 arrays. This solution has asymptotic behavior O(k4).

594D — REQ

To calculate the answer on every query let's use the formula , where p1, p2, ..., pk — all prime numbers which divided n. We make all calculations by the module 109 + 7

Let's suppose that we solving problem for fix left end l of the range. Every query now is a query on the prefix of the array. Then in formula for every prime p we need to know only about the leftmost position of it. Let's convert the query in the query of the multiple on the prefix: at first init Fenwick tree with ones, then make the multiplication in points l, l + 1, ..., n with value of the elements al, al + 1, ..., an. For every leftmost positions of prime p make in position i the multiplication in point i on the . This prepare can be done with asymptotic , where C — the maximum value of the element (this logarithm — the number of prime divisors of some ai).

We interest in all leftmost ends, because of that let's know how to go from the one end to the other. Let we know all about the end l — how to update the end l + 1? Let's make the multiplication in the Fenwick tree in the point l on the value al - 1. Also we are not interesting in all prime numbers inside al, so let's make the multiplications in point l on the all values . But every of this prime numbers can have other entries which now becoming the leftmost. Add them with the multiplication which described above. With helps of sort the transition between leftmost ends can be done in .

To answer to the queries we need to sort them in correct order (or add them in the dynamic array), and to the get the answer to the query we will make  iterations. So total asymptotic behavior of solution is  iterations and  additional memory.

594E — Cutting the Line

Let's describe the greedy algorithm, which allows to solve the problem for every k > 2 for every string S.

Let's think, that we always reverse some prefix of the string S (may be with length equals to one). Because we want to minimize lexicographically the string it is easy to confirm that we will reverse such a prefixes, which prefix (after reversing) is equals to the minimal lexicographically suffix of the reverse string S (let it be Sr) — this is prefix, which length equals to the length of the minimum suffix Sr (the reverse operation of the prefix S equals to change it with suffix Sr).

Let the lexicographically minimal suffix of the string Sr is s. It can be shown, that there are no 2 entries s in Sr which intersects, because of that the string s will be with period and minimal suffix will with less length. So, the string Sr looks like tpsaptp - 1sap - 1tp - 2... t1sa1, where sx means the concatenation of the string s x times, a1, a2, ..., ap — integers, and the strings t1, t2, ..., tp — some non-empty (exclude may be tp) strings, which do not contain the s inside.

If we reverse some needed prefix of the string s, we will go to the string S', and the minimal suffix s' of the reversing string S'r can't be lexicographically less than s, because of that we need to make s' equals to s. It will helps us to increase prefix which look like sb in the answer (and we will can minimize it too). it is easy to show, that maximum b, which we can get equals to a1 in case p = 1 и  (in case if p \geq 2$). After such operations the prefix of the answer will looks like sa1saitisai - 1... sa2t2. Because t_{i} — non-empty strings we can not to increase the number of concatenations s in the prefix of the answer. The reversing of the second prefix (sai...) can be done because k > 2.

From the information described above we know that if k > 2 for lost string we need always reverse prefix, which after reversing is equals to the suffix of the string Sr which looks like sa1. To find this suffix every time, we need only once to build Lindon decomposition (with helps of Duval's algorithm) of the reverse string and carefully unite the equals strings. Only one case is lost — prefix of the lost string does not need to be reverse — we can make the concatenation of the consecutive reverse prefixes with length equals to 1.

Because for k = 1 the problem is very easy, we need to solve it for k = 2 — cut the string on the two pieces (prefix and suffix) and some way of their reverse. The case when nothing reverse is not interesting, let's look on other cases:

Prefix do not reverse. In this case always reversing suffix. Two variants of the string with reverse suffix we can compare with O(1) with helps of z-function of the string Sr#S.

Prefix reverse. To solve this case we can use approvals from the editorial of the problem F Yandex.Algorithm 2015 Round 2.2 which was written by GlebsHP and check only 2 ways of reversing prefix. We need for them to brute the reverse of suffixes.

It is only need in the end to choose from 2 cases better answer. Asymptotic behavior of the solution is O(|s|).

Codeforces Round #329 (Editorial)

By josdas, history, 7 years ago, translation, In English593A - 2CharFor each letter will maintain the total length of words (cnt1ci), which found it was alone, and for each pair of letters will maintain the total length of words that contains only them (cnt2ci, cj).

For each row, count a number of different letters in it. If it is one, then add this letter to the length of the word. If two of them, then add to the pair of letters word`s length.

Now find a pair of letters that will be the answer. For a pair of letters ci, cj answer is cnt1ci + cnt1cj + cnt2ci, cj. Among all these pairs find the maximum. This is the answer.

The overall complexity is O (total length of all strings + 26 * 26)

593B - Anton and LinesNote that if a s line intersects with the j th in this band, and at x = x1 i th line is higher, at x = x2 above would be j th line. Sort by y coordinate at x = x1 + eps, and x = x2 - eps. Verify that the order of lines in both cases is the same. If there is a line that its index in the former case does not coincide with the second, output Yes. In another case, derive No. The only thing that can stop us is the intersection at the borders, as in this case we dont know the sorts order. Then add to our border x1 small eps, and by x2 subtract eps, and the sort order is set uniquely. The overall complexity is O(nlogn)

593C - Beautiful FunctionOne of the answers will be the amount of such expressions for each circle in the coordinate x and similarly coordinate y: 

For a = 1, b = abs(t - i), it can be written as 

Consider the a - b + abs(a - b):

if a ≤ b, то a - b + abs(a - b) = 0,

if a > b, то a - b + abs(a - b) = 2a - 2b

Now consider what means a > b:

1 > abs(t - i)

i > t - 1 and i < t + 1.

For integer i is possible only if i = t.

That is, this bracket is not nullified only if i = t.

Consider the 2a - 2b = 2 - 2 * abs(t - i) = 2. Then  differs from the wanted position by no more than 1, but since all the radiuses are not less than 2, then this point belongs to the circle.

The overall complexity is O(n).

593D - Happy Tree PartyConsider the problem ignoring the second typed requests. We note that in the column where all the numbers on the edges of  >  1 maximum number of assignments to  before x will turn into 0 is not exceeds 64. Indeed, if all the Rv = 2, the number of operations can be assessed as log2(x). Hang the tree for some top and call it the root.

Learn how to solve the problem, provided that for every v Rv > 1 and no requests of the second type. For each vertex except the root, we have identified it as the ancestor of the neighbor closest to the root. Suppose we had a request of the first type from the top a to b vertices with original number x. We divide the road into two vertical parts, one of which is close to the root, while the other moves away. We find all the edges in this way. To do this, we calculate the depth of each node to the root of the distance. Now we will go up in parallel to the tree of the two peaks, until he met a total. If in the course of the recovery, we have been more than 64 edges, in the substitutions  we get x = 0 and we can at the current step to stop the algorithm search. Thus, we make no more than O(log(x)) operations.

Let`s turn to the problem, where Rv > 0. We note that our previous solution in this case can work for O(n). Since the passage of the edge with Rv = 1 our value does not change. We reduce this problem to the above consideration. Compress the graph, that is, remove all single edges. To do this, run by dfs root and will keep the deepest edge on the path from the root to the top with Rv > 1.

Let us remember that we have had requests to reduce Rv. We maintain the closest ancestor of Pv c RPv > 1. We use the idea of compression paths. When answer to a request of the first type will be recalculated Pv. We introduce a recursive function F(v). Which returns the v, if Rv > 1, otherwise perform the assignment of Pv = F(Pv) and returns F(Pv). Each edge we will remove 1 times, so in total the call of all functions F(v) running O(n).

Final time is O(logx) on request of the first type and O(1) an average of request of the second type.

593E - Strange Calculation and CatsLearn how to solve the problem for small t. We use standard dynamic dpx, y, t = number of ways to get into the cell (x; y) at time t. Conversion is the sum of all valid ways to get into the cell (x; y) at time t — 1.

Note that this dp can be counted by means of the construction of the power matrix. Head of the transition matrix, Ti, j = 1, if we can get out of the cell i in a cell j. Suppose we had a vector G, where Gi equal to the number of ways to get into the cell i. Then a new vector G' by dt second G' = G * (Tdt).

So we learned to solve the problem without changes in O (log dt * S3), where dt — at a time, S — area.

Consider what happens when adding or removing a cat. When such requests varies transition matrix. Between these requests constant T, then we can construct a power matrix. Thus, at the moment of change is recalculated T, and between changes in the degree of erecting matrix. The decision is O (m * S3 log dt), m — number of requests

Codeforces Round #328 Problem Analysis

By Morphy, history, 7 years ago, In EnglishProblem A. PawnChessPlayer A wins if the distance of his nearest pawn to the top of the board is less than or equal to the distance of the Player’s B nearest pawn to the bottom of the board (Note that you should only consider pawns that are not blocked by another pawns).

Problem B. The monster and the squirrelAfter drawing the rays from the first vertex (n - 2) triangles are formed. The subsequent rays will generate independently sub-regions in these triangles. Let's analyse the triangle determined by vertices 1, i, i + 1, after drawing the rays from vertex i and (i + 1) the triangle will be divided into (n - i) + (i - 2) = n - 2 regions. Therefore the total number of convex regions is (n - 2)2

 

If the squirrel starts from the region that have 1 as a vertex, then she can go through each region of triangle (1, i, i + 1) once. That implies that the squirrel can collect all the walnuts in (n - 2)2 jumps.

Problem C. The Big RaceLet D be the length of the racetrack, Since both athletes should tie .

Let M = lcm(B, W), then D = k·M + r. None of the athletes should give one step further, therefore r ≤ min{B - 1, W - 1, T} = X.

D must be greater than 0 and less than or equal to T so  - r / M < k ≤ (T - r) / M.

For r = 0, the number of valid racetracks is , and for r > 0 the number of racetracks is .

Iterating over all possible r, we can count the number of racetracks in which Willman and Bolt ties: 

Note that . That means that  for exactly M values of r.

We can count the number of values of r in which , and the values of r in which . Each of the remaining values v1 - 1, v1 - 2, ..., v2 + 1 will appear exactly M times.

Problem D. Super MObservation 1: Ari should teleport to one of the attacked cities (it doesn't worth going to a city that is not attacked since then she should go to one of the attacked cities)

Observation 2: The nodes visited by Ari will determine a sub-tree T of the original tree, this tree is unique and is determined by all the paths from two attacked cities.

 

Observation 3: If Ari had to return to the city from where she started, then the total distance would be 2e, where e is the number of edges of T, that is because she goes through each edge forward and backward

Observation 4: If Ari does not have to return to the starting city (the root of T), then the total distance is 2e - L, where L is the distance of the farthest node from the root

Observation 5: In order to get a minimum total distance, Ari should chose one diameter of the tree, and teleport to one of its leaves.

The problem is now transformed in finding the diameter of a tree that contains the smallest index for one of its leaves. Note that all diameters pass through the center of the tree, so we can find all the farthest nodes from the center...and [details omitted].

Problem E. BCPCLet’s represent the reading and writing speeds of the students as points in a plane. Two students i, j are compatible if ri'·wj' - rj'·wi' > 0 this equation is identical to the cross product: (ri', wi') × (rj', wj′) > 0. Using this fact is easy to see that three students i, j, k are compatible if the triangle (ri, wi), (rj, wj), (rk, wk) contains the point (x, y). So the problem is reduced to count the number of triangles that contains the origin.

 

Let’s count the triangles that have two known vertices i and j (look at the picture above). It is easy to see that the third vertex should be inside the region S. So now we have to be able of counting points that are between two rays, that can be done using binary search (ordering the points first by slope and then by the distance to the origin).

 

Now given a point i, let’s count the triangles that have i as a vertex (look at the picture above again). We have to count the points that lie between the ray iO, and every other ray jO (the angle between iO and jO must be  ≤ 180).

Let Sj denote the number points that are between the rays OR and jO, then the number of triangles that have i as a vertex are . This summation can be calculated if we pre-calculate the cumulative sums of Sj.

The overall complexity is O(n·log(n)).

Codeforces Round #327 problems analysis

By GlebsHP, history, 7 years ago, translation, In EnglishI like the idea of Endagorion to supplement the problems analysis with small challenges, somehow related to the problem preparation, it's generalization, or more effective solution. Following this, some problems in this analysis are also complemented with this sort of tasks.

Div. 2A (Wizards' Duel)Idea of the problem: Roman Gusarev, development: timgaripov.

Let's start with determining the position of the first collision. Two impulses converge with a speed p + q, so the first collision will occur after  seconds. The coordinate of this collision is given by the formula .

Note, that the distance one impulse passes while returning to it's caster is equal to the distance it has passed from the caster to the first collision. That means impulses will reach their casters simultaneously, and the situation will be identic to the beginning of the duel. Hence, the second collision (third, fourth, etc) will occur at exactly the same place as the first one.

Code example: 13836780.

Div. 2B (Rebranding)Idea of the problem: glebushka98, development: thefacetakt.

Trivial solution will just emulate the work of all designers, every time considering all characters of the string one by one and replacing all xi with yi and vice versa. This will work in O(n·m) and get TL.

First one should note that same characters always end as a same characters, meaning the position of the letter doesn't affect the result in any way. One should only remember the mapping for all distinct characters. Let p(i, c) be the mapping of c after i designers already finished their job. Now:

p(0, c) = cIf p(i - 1, c) = xi, then p(i, c) = yiSame, if p(i - 1, c) = yi, then p(i, c) = xiThis solution complexity is O(|Σ|·m + n) and is enough to pass all the tests.

Challenge: improve the complexity to O(Σ + n + m).

Code examples: 13837577 implements O(|Σ|·m + n) and 13839154 stands for O(|Σ| + n + m).

Div. 2C\Div. 1A (Median Smoothing)Problem idea and development: Sender.

We will call the element of a sequence stable, if it doesn't change after applying the algorithm of median smoothing for any number of times. Both ends are stable by the definition of the median smoothing. Also, it is easy to notice, that two equal consecutive elements are both stable.

Now we should take a look at how do stable elements affect their neighbors. Suppose ai - 1 = ai, meaning i - 1 and i are stable. Additionaly assume, that ai + 1 is not a stable element, hence ai + 1 ≠ ai and ai + 1 ≠ ai + 2. Keeping in mind that only 0 and 1 values are possible, we conclude that ai = ai + 2 and applying a median smoothing algorithm to this sequence will result in ai = ai + 1. That means, if there is a stable element in position i, both i + 1 and i - 1 are guaranteed to be stable after one application of median smoothing. Now we can conclude, that all sequences will turn to stable at some point.

Note, that if there are two stable elements i and j with no other stable elements located between them, the sequence of elements between them is alternating, i.e. ak = (ai + k - i)mod2, where . One can check, that stable elements may occur only at the ends of the alternating sequence, meaning the sequence will remain alternating until it will be killed by effect spreading from ending stable elements.

The solution is: calculate max(min(|i - sj|)), where sj are the initial stable elements. Time complexity is O(n).

Challenge 1: hack the solution that just applies median smoothing until something changes.

Challenge 2: think of how to speed up the algorithm from challenge 1 using bitmasks (still gets TL).

Code examples: 13838940 and 13838480.

Div. 2D\Div. 1B (Chip 'n Dale Rescue Rangers)Problem idea and development: StopKran.

If the velocity of the dirigible relative to the air is given by the vector (ax, ay), while the velocity of the wind is (bx, by), the resulting velocity of the dirigible relative to the plane is (ax + bx, ay + by).

The main idea here is that the answer function is monotonous. If the dirigible is able to reach to target in  seconds, then it can do so in  seconds, for any x ≥ 0. That is an obvious consequence from the fact the maximum self speed of the dirigible is strictly greater then the speed of the wind at any moment of time.

For any monotonous function we can use binary search. Now we only need to check, if for some given value  it's possible for the dirigible to reach the target in  seconds. Let's separate the movement of the air and the movement of the dirigible in the air. The movement cause by the air is:

(xn, yn) = , if ;(xn, yn) = , for .The only thing we need to check now is that the distance between the point (xn, yn) and the target coordinates (x2, y2) can be covered moving with the speed vmax in  seconds assuming there is no wind.

Time complexity is , where C stands for the maximum coordinate, аnd ε — desired accuracy.

Challenge 1: think of the solution in case it's not guaranteed that the dirigible is faster than the wind.

Challenge 2: can you come up with O(1) solution?

Code examples: 13838659 and 13842505.

Div. 2E\Div. 1C (Three States)Problem idea and development: haku.

Affirmation. Suppose we are given an undirected unweighted connected graph and three distinct chosen vertices u, v, w of this graph. We state that at least one minimum connecting network for these three vertices has the following form: some vertex c is chosen and the resulting network is obtained as a union of shortest paths from c to each of the chosen vertices.

Proof. One of the optimal subgraphs connecting these three vertices is always a tree. Really, we can take any connecting subgraph and while there are cycles remaining in it, take any cycle and throw away any edge of this cycle. Moreover, only vertices u, v and w are allowed to be leaves of this tree, as we can delete from the network any other leaves and the network will still be connected. If the tree has no more than three leaves, it has no more than one vertex with the degree greater than 2. This vertex is c from the statement above. Any path from c to the leaves may obviously be replaced with the shortest path. Special case is than there is no node with the degree greater than 2, meaning one of u, v or w lies on the shortest path connecting two other vertices.

The solution is: find the shortest path from each of the chosen vertices to all other vertices, and then try every vertex of the graph as c. Time complexity is O(|V| + |E|).

To apply this solution to the given problem we should first build a graph, where cells of the table stand for the vertices and two vertices are connected by an edge, if the corresponding cells were neighboring. Now we should merge all vertices of a single state in one in order to obtain a task described in the beginning. Time complexity is a linear function of the size of the table .

Code examples: 13843265 — the solution described above that uses 0-1 bfs instead of merging, 13840329 — another approach that tries to different cases.

Div. 1D (Top Secret Task)Problem idea and development: glebushka98.

If , than the sum of k minimums is obviously an answer.

Let i1 < i2 <  ...  < ik be the indices of the elements that will form the answer. Note, that the relative order of the chosen subset will remain the same, as there is no reason to swap two elements that will both be included in the answer. The minimum number of operations required to place this k elements at the beginning is equal to  — .

T ≤ S    ≤  . .

Calculate the dynamic programming d[i][j][p] &mdash minimum possible sum, if we chose j elements among first i with the total indices sum no greater than p. In order to optimize the memory consumption we will keep in memory only two latest layers of the dp.

Time complexity is O(n4), with O(n3) memory consumption.

Code examples: 13845513 and 13845571.

Div. 1E (Birthday)Problem idea: meshanya, development: romanandreev.

The given problem actually consists of two separate problems: build the directed graph of substring relation and find the maximum independent set in it. Note, that if the string s2 is a substring of some string s1, while string s3 is a substring of the string s2, then s3 is a substring of s1. That means the graph of substring relation defines a partially ordered set.

To build the graph one can use Aho-Corasick algorithm. Usage of this structure allow to build all essential arc of the graph in time O(L), where L stands for the total length of all strings in the input. We will call the arc  essential, if there is no w, such that  and . One of the ways to do so is:

Build Aho-Corasick using all strings in the input;For every node of the Aho-Corasick structure find and remember the nearest terminal node in the suffix-link path;Once again traverse all strings through Aho-Corasick. Every time new symbol is added, add an arc from the node corresponding to the current string (in the graph we build, not Aho-Corasick) to the node of the graph corresponding to the nearest terminal in the suffix-link path;The previous step will build all essential arcs plus some other arcs, but they do not affect the next step in any way;Find the transitive closure of the graph.To solve the second part of the problem one should use the Dilworth theorem. The way to restore the answer subset comes from the constructive proof of the theorem.

Time complexity is O(L + n3) to build the graph plus O(n3) to find the maximum antichain. The overall complexity is O(L + n3).

Congratulation to ikatanic — — the only participant to solve this problem during the contest. View his code 13851141 for further clarifications.

Challenge: solve the problem with the same asymptotic, if we are to find the subset with the maximum total length of all strings in it.

Codeforces Round #326 (Editorial)

By PrinceOfPersia, history, 7 years ago, In EnglishDiv.2 A (Author: Haghani)Idea is a simple greedy, buy needed meat for i - th day when it's cheapest among days 1, 2, ..., n.

So, the pseudo code below will work:

ans = 0price = infinityfor i = 1 to n      price = min(price, p[i])      ans += price * a[i] 

Time complexity: 

C++ Code by PrinceOfPersia

Python Code by Haghani

Python Code by Zlobober

Div.2 B (Author: PrinceOfPersia)Find all prime divisors of n. Assume they are p1, p2, ..., pk (in ). If answer is a, then we know that for each 1 ≤ i ≤ k, obviously a is not divisible by pi2 (and all greater powers of pi). So a ≤ p1 × p2 × ... × pk. And we know that p1 × p2 × ... × pk is itself lovely. So,answer is p1 × p2 × ... × pk

 

Time complexity: 

C++ Code by PrinceOfPersia

Python Code by Haghani

Python Code by Zlobober

A (Author: PrinceOfPersia)Problem is: you have to find the minimum number of k, such there is a sequence a1, a2, ..., ak with condition 2a1 + 2a2 + ... + 2ak = S = 2w1 + 2w2 + ... + 2w2. Obviously, minimum value of k is the number of set bits in binary representation of S (proof is easy, you can prove it as a practice :P).

 

Our only problem is how to count the number of set bits in binary representation of S? Building the binary representation of S as an array in  is easy:

MAXN = 1000000 + log(1000000)bit[0..MAXN] = {} // all equal to zeroans = 0for i = 1 to n      bit[w[i]] ++ // of course after this, some bits maybe greater than 1, we'll fix them belowfor i = 0 to MAXN - 1      bit[i + 1] += bit[i]/2 // floor(bit[i]/2)      bit[i] %= 2 // bit[i] = bit[i] modulo 2      ans += bit[i] // if bit[i] = 0, then answer doesn't change, otherwise it'll increase by 1Time complexity: 

C++ Code by PrinceOfPersia

C++ Code by Haghani

B (Author: PrinceOfPersia)If we fix x and bix mod n, then problem will be solved (because we can then multiply it by the number of valid distinct values of ).

For the problem above, let dp[i][j] be the number of valid subsequences of b where x = j and  and . Of course, for every i, dp[i][1] = 1. For calculating value of dp[i][j]:



For this purpose, we can sort the array a and use two pointer:

if p0, p1, ...pn - 1 is a permutation of 0, ..., n - 1 where for each 0 ≤ t < n - 1, apt ≤ apt + 1:

for i = 0 to n-1      dp[i][1] = 1for j = 2 to k      pointer = 0      sum = 0      for i = 0 to n-1            while pointer < n and a[p[pointer]] <= a[i]                  sum = (sum + dp[p[pointer ++]][j - 1]) % MOD            dp[i][j] = sum 

Now, if  and x = l - 1 mod n, then answer equals to  (there are c - j + 1 valid different values of  for the first group and c - j for the second group).

Time complexity: 

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

C (Author: PrinceOfPersia)Solution is something like the fourth LCA approach discussed here.

For each 1 ≤ i ≤ n and 0 ≤ j ≤ lg(n), store the minimum 10 people in the path from city (vertex) i to its 2j - th parent in an array.

Now everything is needed is: how to merge the array of two paths? You can keep the these 10 values in the array in increasing order and for merging, use merge function which will work in . And then delete the extra values (more than 10).

And do the same as described in the article for a query (just like the preprocess part).

 

Time complexity: 

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

D (Author: PrinceOfPersia)Run binary search on the answer (t). For checking if answer is less than or equal to x (check(x)):

First of all delete all edges with destructing time greater than x. Now, if there is more than one pair of edges with the same color connected to a vertex(because we can delete at most one of them), answer is "No".

Use 2-Sat. Consider a literal for each edge e (xe). If xe = TRUE, it means it should be destructed and it shouldn't otherwise. There are some conditions:

For each vertex v, if there is one (exactly one) pair of edges like i and j with the same color connected to v, then we should have the clause .

For each vertex v, if the edges connected to it are e1, e2, ..., ek, we should make sure that there is no pair (i, j) where 1 ≤ i < j ≤ k and xe1 = xe2 = True. The naive approach is to add a clause  for each pair. But it's not efficient.

 

The efficient way tho satisfy the second condition is to use prefix or: adding k new literals p1, p2, ..., pk and for each j ≤ i, make sure . To make sure about this, we can add two clauses for each pi:  and  (the second one is only for i > 1).

And the only thing left is to make sure  (there are no two TRUE edges).

This way the number of literals and clauses are .

So, after binary search is over, we should run check(t) to get a sample matching.

Time complexity:  (but slow, because of the constant factor)

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

E (Authors: PrinceOfPersia and Haghani)Lemma #1: If numbers b1, b2, ..., bk are k Kheshtaks of a1, ..., an, then  is a Kheshtak of a1, ..., an.

Proof: For each 1 ≤ i ≤ k, consider maski is a binary bitmask of length n and its j - th bit shows a subsequence of a1, ..., an (subset) with xor equal to bi.

So, xor of elements subsequence(subset) of a1, ..., an with bitmask equal to  equals to . So, it's a Kheshtak of this sequence.

From this lemma, we can get another results: If all numbers b1, b2, ..., bk are k Kheshtaks of a1, ..., an, then every Kheshtak of b1, b2, ..., bk is a Kheshtak of a1, ..., an

Lemma #2: Score of sequence a1, a2, ..., an is equal to the score of sequence .

Proof: If we show the second sequence by b1, b2, ..., bn, then for each 1 ≤ i ≤ n:

bi = ai =  each element from sequence b is a Kheshtak of sequence a and vise versa. So, due to the result of Lemma #1, each Kheshtak of sequence b is a Kheshtak of sequence a and vise versa. So:

score(b1, ..., bn) ≤ score(a1, ..., an)score(a1, ..., an) ≤ score(b1, ..., bn) score(a1, ..., an) = score(b1, ..., bn)

 

Back to original problem: denote another array b2, ..., bn where . Let's solve these two problems:

1- We have array a1, ..., an and q queries of two types:

upd(l, r, k): Given numbers l, r and k, for each l ≤ i ≤ r, perform ask(i):  Given number i, return the value of ai.This problem can be solved easily with a simple segment tree using lazy propagation.

2- We have array b2, ..., bn and queries of two types:

modify(p, k): Perform bp = k.basis(l, r): Find and return the basis vector of bl, bl + 1, ..., br (using Gaussian Elimination, its size it at most 32).This problem can be solved by a segment tree where in each node we have the basis of the substring of that node (node [l, r) has the basis of sequence bl, ..., br - 1).

This way we can insert to a basis vector v:

insert(x, v)	for a in v		if a & -a & x			x ^= a	if !x		return	for a in v		if x & -x & a			a ^= x	v.push(x)But size of v will always be less than or equal to 32. For merging two nodes (of segment tree), we can insert the elements of one in another one.

For handling queries of two types, we act like this:

Type one: Call functions: upd(l, r, k),  and .

Type two: Let b = basis(l + 1, r). Call insert(al, b). And then print 2b.size() as the answer.

Time complexity:  = 

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

F (Author: PrinceOfPersia)Use Aho-Corasick. Assume first of all we build the trie of our strings (function t). If t(v, c) ≠  - 1 it means that there is an edge in the trie outgoing from vertex v written c on it.

So, for building Aho-Corasick, consider f(v) = the vertex we go into, in case of failure (t(v, c) =  - 1). i.e the deepest vertex (u), that v ≠ u and the path from root to u is a suffix of path from root to v. No we can build an automaton (Aho-Corasick), function g. For each i, do this (in the automaton):

cur = rootfor c in s[i]	cur = g(cur, c)	And then push i in q[cur] (q is a vector, also we do this for cur = root).

end[cur].push(i) 	// end is also a vector, consisting of the indices of strings ending in vertex cur (state cur in automaton)last[i] = cur // last[i] is the final state we get to from searching string s[i] in automaton gAssume cnt(v, i) is the number of occurrences of number i in q[v]. Also, denote .

Build another tree. In this tree, for each i that is not root of the trie, let par[i] = f(i) (the vertex we go in the trie, in case of failure) and call it C-Tree.

So now, problem is on a tree. Operations are : Each query gives numbers l, r, k and you have to find the number .

 

Act offline. If N = 105, then:

1. For each i such that , collect queries (like struct) in a vector of queries query[i], then run dfs on the C-Tree and using a partial sum answer to all queries with k = i. There are at most  of these numbers, so it can be done in . After doing these, erase i from all q[1], q[1], ..., q[N].

Code (in dfs) would be like this(on C-Tree):

partial_sum[n] = {}; // all 0dfs(v, i){	cnt = 0;	for x in q[v]		if(x == i)		++ cnt;	for u in childern[v]		cnt += dfs(u);	for x in end[v]		partial_sum[x] += cnt;	return cnt;}calc(i){	dfs(root, i);	for i = 2 to n		partial_sum[i] += partial_sum[i-1]	for query u in query[i]		u.ans = partial_sum[u.r] - partial_sum[u.l - 1]}And we should just run calc(i) for each of them.

2. For each i such that , collect queries (like struct) in a vector of queries query[i]. (each element of this vector have three integers in it: l, r and ans).

Consider this problem:

We have an array a of length N(initially all element equal to 0) and some queries of two types:

increase(i, val): increase a[i] by valsum(i): tell the value of a[1] + a[2] + ... + a[i]We know that number of queries of the first type is  and from the second type is . Using Sqrt decomposition, we can solve this problem in :

K = sqrt(N)tot[K] = {}, a[N] = {} // this code is 0-basedincrease(i, val)	while i < N and i % K > 0		a[i ++] += val	while i < K		tot[i/K] += val		i += Ksum(i)	return a[i] + tot[i/K]Back to our problem now.

Then, just run dfs once on this C-Tree and act like this:

dfs(vertex v):	for i in end[v]		increase(i, 1)	for i in q[v]		for query u in query[i]			u.ans += sum(u.r) - sum(u.l - 1)	for u in children[v]		dfs(u)	for i in end[v]		increase(i, -1)Then answer to a query q is q.ans.

Time complexity: 

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

Разбор Codeforces Round #325

By Edvard, history, 7 years ago, translation, In English586A - Alena's Schedule

The problem has been prepared by adedalic.

To solve this problem one should remove all leading and trailing zeroes from array and then calculate the number of ones and number of zeroes neighboured by ones. The sum of this values is the answer for the problem.

Complexity: O(n).

586B - Laurenty and Shop

The problem has been prepared by Oleg_Smirnov.

Let's call some path ith if we start it by going i times left, then we cross the prospect and go left n - 1 - i times again. Let di be equal to the time we should wait on traffic lights while following i-th path. If we consider any way from the shop to home, it is equal (but reversed) to only path from home to the shop, meaning that we need to find two distinct paths from home to the shop. So the answer to the problem is the sum of the smallest and the second smallest values among di. One could easily calculate di using calculated di - 1, so di could be found in one for cycle.

If we will consider only two minimum values among di, solution complexity will be O(n).

Complexity: O(n).

585A - Gennady the Dentist

The problem has been prepared by Neon.

Let's store for each child his current confidence value and a boolean indicating whether child had left the queue (or visited the dentist office) or not. Then one could easily process children one by one, considering only children who still are in the queue (using boolean array), and changing stored values.

Such solution has complexity O(n2) and requires author's attention much, especially the case with possible confidence value overflowing. Of course there are much faster solutions not required in our case.

585B - Phillip and Trains

The problem has been prepared by IlyaLos.

One could consider a graph with vertices corresponding to every (x, y) position. I should notice that train positions for each Phillip position are fully restorable from his y coordinate. Edge between vertices u and v means that we could get from position corresponding to u to position corresponding by v in one turn without moving onto a train cell or moving in a cell which will be occupied by some train before the next turn. All we need next is to find whether any finishing position is reachable from the only starting position (using BFS or DFS, or, as soon as graph is a DAG, dynamic programming).

As soon as graph has O(n) vertices and O(n) edges, solution complexity equals to O(n).

585C - Alice, Bob, Oranges and Apples

The problem has been prepared by Edvard.

Firstly, let's understand the process described in problem statement. If one would write a tree of a sum-pairs (x, y) with letters  and , he would get the Stern–Brocot tree. Let the number of oranges be enumerator and the number of apples be denumerator of fraction. At every step we have two fractions (at first step they are ) and should replace exactly one of them with their mediant. In such way first fraction is first parent to the left from mediant while second fraction is parent to the right. The process described in statement is, this way, a process of finding a fraction in the Stern-Brocot tree, finishing when the current mediant is equal to current node in the tree and (x, y) pair is the fraction we are searching.

This means that if , (x, y) does not correspond to any correct fraction and the answer is "Impossible". Other way, we could find it in the tree. If x > y, we should firstly go in the right subtree. Moreover, we could then consider we are searching  from the root. If x < y, we should go left and next consider  from the root. This gives us Euclidian algorithm, which could be realized to work in  complexity.

Complexity: O(logn).

585D - Lizard Era: Beginning

The problem has been prepared by danilka.pro.

To solve the problem we will use meet-in-the-middle approach. For  we should consider all  variants. Let in some variant approval values of three companions are a, b, c respectively. If we will consider some variant from other half (there are  of them) and a', b', c' approval values, then to ``merge'' such two parts correctly, two conditions a - b = b' - a' и b - c = c' - b' must be true (a + a' = b + b' = c + c' is true), and the value we are maximizing is a + a'.

This way, to solve the task one could consider every variant from the first half and store for every possible pair (a - b, b - c) the maximum a value achievable (using, for example, the  structure or any fast sorting algorithm). If one would then consider every variant from the second half, he just need to find (b' - a', c' - b') pair in the structure to get the maximum a value if possible and update answer with a + a' value. Answer restoring is pretty same to the algorithm above.

Such solution has  complexity.

585E - Present for Vitalik the Philatelist

The problem has been prepared by gridnevvvit.

Let's calculate the number of subsets with gcd equal to 1 — value A. Let's do that using principle of inclusions-exclusions: firstly we say that all subsets is good. The total number of subsets is equal to 2n. Now let's subtract subsets with gcd divisible by 2. The number of that subsets is equal to 2cnt2 - 1 (cnti is the number of numbers that is divisable by i). Next we should subtract 2cnt3 - 1. Subsets with gcd divisible by 4 we already counted with number two. Next we should subtract 2cnt5 - 1. Now we should notice that subsets with gcd divisible by 6 we already processed twice: firstly with number 2, then with — 3, so let's add the number of these subsets 2cnt6 - 1. If we continue this process we will get, that for all numbers d we should add the value μ(d)(2cntd - 1), where μ(d) is equals to 0, if d is divisible by square of some prime, 1, if the number of primes in factorization of d is even and  - 1 in other case. So the numbers that is divisible by square of some prime we can ignore, because they have coefficient 0. To calculate values cnti we should factorize all numbers and iterate over 2k divisors with value μ(d) ≠ 0. Now it's easy to see, that the number of subsets with gcd greater than 1 equals to B = 2n - A. To solve the problem let's fix the stamp that Vitaliy will buy ai. Let's recalculate the number B for array a without element ai. To do that we should only subtract those terms that was affected by number ai. We can do that in 2k, where k is the number of primes in factorization of the number ai. It's easy to see that only the subsets with gcd greater than 1, but not divisible by any divisor of ai, should we counted in answer. To calculate number of those subsets let's again use the principle of inclusions-exclusions. For every divisor d of ai let's subtract the value μ (2cntd - 1) from B. So now we got Bi — the number of subsets with gcd greater than 1, but coprime with ai. The answer to problem is the sum over all Bi. The maximum number of primes in factorization of number not greater than 107 is equal to 8. We can factorize all numbers from 1 to n in linear time by algorithm for finding the smallest divisors for all intergers from 1 to n, or by sieve of Eratosthenes in O(nloglogn) time.

Complexity: O(C + n2K), where , K — is the largest number of primes in factorization of ai.

585F - Digits of Number Pi

The problem has been prepared by Edvard.

Consider all substrings of string s with length . Let's add them all to trie data structure, calculate failure links and build automata by digits. We can do that in linear time using Aho-Korasik algorithm. Now to solve the problem we should calculate dp zi, v, b1, b2, b. State of dp is described by five numbers: i — number of digits, that we already put to our number, v — in which vertex of trie we are, b1 — equals to one if the prefix that we built is equals to prefix of x, b2 — equals to one if the prefix that we built is equals to prefix of y, b — equals to one if we already have some substring with length  on the prexif that we built. The value of dp is the number of ways to built prefix with the given set of properties. To update dp we should iterate over the digit that we want to add to prefix, check that we still is in segment [x, y], go from vertex v to the next vertex in automata. So the answer is the sum by all v, b1, b2 zb, v, v1, v2, 1.

Complexity: O(nd2).

Разбор Codeforces Round #324 (Div. 2)

By ZhNV, 7 years ago, translation, In English584A - Olesya and Rodion

Two cases: t = 10 and t ≠ 10.

If t = 10 then there are two cases again :). If n = 1 then answer is  - 1 (because there is not any digit divisible by t). If n > 1, then answer, for example, is '1111...110' (contains n - 1 ones).

If t < 10 then answer, for example, is 'tttttttt' (it, obviously, divisible by t).

584B - Kolya and Tanya

The number of ways to choose ai (without any conditions) — 33n. Let A be the number of ways to choose ai with condition that in every triangle gnomes have 6 coins. Then answer is 33n - A.

Note that we can separate all gnomes on n independent triangles (i-th triangle contains of ai, ai + n, ai + 2n, i < n). So we can count answer for one triangle and then multiply the results. To count answer for one triangle, we can note that there are 7 ways to choose gnomes with 6 coins (all permutations 1, 2, 3 and 2, 2, 2).

So answer is — 33n - 7n. We count it in O(n).

584C - Marina and Vasya

Let's find a string that will be equal to s1 in k = n - t positions and equal to s2 in k = n - t positions. Let's denote q = quantity of i that s1i = s2i. If k ≤ q, then let's take k positions such that s1pos = s2pos and put in answer the same symbols. Then put in other n - k positions symbols, which are not equal to corresponding in s1 and s2 (we can do it, because we have 26 letters).

Now k > q. So, if there is an answer, where exists pos such that s1pos = s2pos, s1pos ≠ anspos, let's denote ansi = s1i, and then in any position such that s1i ≠ s2i = ansi and s1i = ansi (and in the same position in s2) we will choose ai, such that ai ≠ s1i and ai ≠ s2i (we can do it because k > q). So, for every position from q we can put symbols, equal to corresponding symbols in s1 and s2. Now we have strings s1, s2 of length n - q (such that s1i ≠ s2i for every i) and we should find string ans such that f(ans, s1) = f(ans, s2). We know that s1i ≠ s2i, so ansi may be equal to corresponding in s1 or to corresponding in s2 or not equal to s1i and to s2i. So, we need, at least, 2(k - q) symbols in answer to make f(s1, ans) = k - q and f(s2, ans) = k - q. Consequently, if n - q < 2(k - q), the answer is  - 1, and else just put first k - q symbols in answer from s1, next k - q symbols from s2, and others won't be equal to corresponding in s1 and s2.

Solution works in O(n).

584D - Dima and Lisa

There is a fact that the distance between adjacent prime numbers isn't big. For n = 109 maximal distanse is 282. So let's find maximal prime p, such that p < n - 1 (we can just decrease n while it's not prime(we can check it in )). We know that n - p < 300. Now we have even (because n and p are odd) number n - p and we should divide it into a sum of two primes. As n - p < 300, we can just iterate over small primes P and check if P is prime and n - p - P is prime. You can check that there is a solution for all even numbers less than 300 by bruteforce.

584E - Anton and Ira

We can consider that we pay 2|i - j| coins for swap (we can divide answer in the end). Then we can consider that we pay |i - j| coins for moving pi and |i - j| for moving pj. So, if x was on position i and then came to position j, then we will pay at least |i - j| coins. Then the answer is at least  (pp — position k in permutation p, and ps — position k in permutation s). Let's prove that this is the answer by showing the algorithm of making swaps.

Let's consider that permutation s is sorted (our task is equal to it). Then we will put numbers from n to 1 on their positions.

How we can put n on its position? Denote ppos = n. Let's prove that there exists a position pos2 such that pos < pos2 and ppos2 ≤ pos(then we will swap ppos2 with n (and both numbers will move to their final positions and n will move to the right, so we can repeat this process until n returns to its position)). We can note that there are only n - pos positions that are bigger than pos. And how many numbers on these positions can be bigger than pos? We can say that answer is n - pos, but it's incorrect, because n is bigger than pos, but posn ≤ pos. Now we can use Pigeonhole principle and say that position x, such that x > pos and px ≤ pos exists.

But now our algorithm is O(n3). How we can put n in its position in O(n) operations? Let's move the pointer to the right while number is bigger than pos. Then swap n with found number. After we can move pointer from new n's position, so pointer always moves to the right and will not do more then n steps.

Codeforces Round #323 Editorial

By danilka.pro, history, 7 years ago, In EnglishAdiv2

To solve the problem one could just store two arrays hused[j] and vused[j] sized n and filled with false initially. Then process intersections one by one from 1 to n, and if for i-th intersections both hused[hi] and vused[vi] are false, add i to answer and set both hused[hi] and vused[vi] with true meaning that hi-th horizontal and vi-th vertical roads are now asphalted, and skip asphalting the intersection roads otherwise.

Such solution has O(n2) complexity.

Jury's solution: 13390628

Bdiv2

It is always optimal to pass all the computers in the row, starting from 1-st to n-th, then from n-th to first, then again from first to n-th, etc. and collecting the information parts as possible, while not all of them are collected.

Such way gives robot maximal use of every direction change. O(n2) solution using this approach must have been passed system tests.

Jury's solution: 13390612

Adiv1

Let the answer be a1 ≤ a2 ≤ ... ≤ an. We will use the fact that gcd(ai, aj) ≤ amin(i, j).

It is true that gcd(an, an) = an ≥ ai ≥ gcd(ai, aj) for every 1 ≤ i, j ≤ n. That means that an is equal to maximum element in the table. Let set an to maximal element in the table and delete it from table elements set. We've deleted gcd(an, an), so the set now contains all gcd(ai, aj), for every 1 ≤ i, j ≤ n and 1 ≤ min(i, j) ≤ n - 1.

By the last two inequalities gcd(ai, aj) ≤ amin(i, j) ≤ an - 1 = gcd(an - 1, an - 1). As soon as set contains gcd(an - 1, an - 1), the maximum element in current element set is equal to an - 1. As far as we already know an, let's delete the gcd(an - 1, an - 1), gcd(an - 1, an), gcd(an, an - 1) from the element set. Now set contains all the gcd(ai, aj), for every 1 ≤ i, j ≤ n and 1 ≤ min(i, j) ≤ n - 2.

We're repeating that operation for every k from n - 2 to 1, setting ak to maximum element in the set and deleting the gcd(ak, ak), gcd(ai, ak), gcd(ak, ai) for every k < i ≤ n from the set.

One could prove correctness of this algorithm by mathematical induction. For performing deleting and getting maximum element operations one could use multiset or map structure, so solution has complexity .

Jury's solution: 13390679

Bdiv1

One could calculate matrix sized n × n mt[i][j] — the length of the longest non-decreasing subsequence in array a1, a2, ..., an, starting at element, greater-or-equal to ai and ending strictly in aj element with j-th index.

One could prove that if we have two matrices sized n × n A[i][j] (the answer for a1, a2, ..., apn starting at element, greater-or-equal to ai and ending strictly in aj element with j-th index inside last block (a(p - 1)n + 1, ..., apn) and B[i][j] (the answer for a1, a2, ..., aqn ), then the multiplication of this matrices in a way



will give the same matrix but for length p + q. As soon as such multiplication is associative, next we will use fast matrix exponentiation algorithm to calculate M[i][j] (the answer for a1, a2, ..., anT) — matrix mt[i][j] raised in power T. The answer is the maximum in matrix M. Such solution has complexity .

Jury's solution (with matrices): 13390660

There's an alternative solution. As soon as a1, a2, ..., anT contains maximum n distinct elements, it's any non-decreasing subsequence has a maximum of n - 1 increasing consequtive element pairs. Using that fact, one could calculate standard longest non-decreasing subsequence dynamic programming on first n array blocks (a1, ..., an2) and longest non-decreasing subsequence DP on the last n array blocks (anT - n + 1, ..., anT). All other T - 2n blocks between them will make subsegment of consequtive equal elements in longest non-decreasing subsequence.

So, for fixed ai, in which longest non-decreasing subsequence of length p on first n blocks array ends, and for fixed aj ≥ ai, in which longest non-decreasing subsequence of length s on last n blocks array starts, we must update the answer with p + (T - 2n)count(ai) + s, where count(x) is the number of occurences of x in a1, ..., an array. This gives us  solution.

Jury's solution (with suffix and prefix): 13390666

Cdiv1

Let's fix s for every (l, s) pair. One could easily prove, that if subarray contains ai element, than ai must be greater-or-equal than aj for every j such that . Let's use this idea and fix g = gcd(n, s) (it must be a divisor of n). To check if ai can be in subarray with such constraints, let's for every 0 ≤ r < g calculate

.

It's true that every good subarray must consist of and only of . For finding all such subarrays we will use two pointers approach and for every good ai, such that  is not good we will find aj such that  are good and  is not good. Let  has k elements . Any it's subarray is superior, so it gives us arrays of length 1, 2, ..., k with count k, k - 1, ..., 1. As soon as sum of all k is not greater than n, we could just increase counts straightforward. There's a case when all ai are good, in which we must do another increases. Next we must add to the answer only counts of length x, such that gcd(x, n) = g.

Solution described above has complexity O(d(n)n), where d(n) is the number of divisors of n.

Jury's solution: 13390645

Ddiv1

It is a common fact that for a prime p and integer n maximum α, such that pα|n! is calculated as , where pw ≤ n < pw + 1. As soon as , the maximum α for  is calculated as .

One could see, that if we consider numbers n, k and n - k in p-th based numeric system, rounded-down division by px means dropping last x digits of its p-th based representation. As soon as k + (n - k) = n, every i-th summand in α corresponds to carry in adding k to n - k in p-th numeric system from i - 1-th to i-th digit position and is to be 0 or 1.

First, let convert A given in statement from 10 to p-th numeric system. In case, if α is greater than number of digits in A in p-th numeric system, the answer is 0. Next we will calculate dynamic programming on A p-th based representation.

dp[i][x][e][r] — the answer for prefix of length i possible equal to prefix of A representation (indicator e), x-th power of p was already calculated, and there must be carry equal to r from current to previous position. One could calculate it by bruteforcing all of p2 variants of placing i-th digits in n and k according to r and e and i-th digit of A, and make a translation to next state. It can be avoided by noticing that the number of variants of placing digits is always a sum of arithmetic progression and can be calculated in O(1).

It's highly recommended to examine jury's solution with complexity O(|A|2 + |A|min(|A|, α)).

Jury's solution: 13390698

Ediv1

One could prove that the number of binary functions on 4 variables is equal to 224, and can be coded by storing a 24-bit binary mask, in which every bit is storing function value for corresponding variable set. It is true, that if maskf and maskg are correspond to functions f(A, B, C, D) and g(A, B, C, D), then function (f&g)(A, B, C, D) corresponds to maskf&maskg bitmask.

Now, we could parse expression given input into binary tree. I should notice that the number of non-list nodes of such tree is about . Now, let's calculate dynamic programming on every vertex v — dp[v][mask] is the number of ways to place symbols in expression in the way that subtree of vertex v will correspond to function representing by mask. For list nodes such dynamic is calculated pretty straightforward by considering all possible mask values and matching it with the variable. One could easily recalculate it for one node using calculated answers for left and right subtree in 416 operations: dp[v][lmask|rmask] +  = dp[l][lmask] * dp[r][rmask].

But all the task is how to make it faster. One could calculate s[mask], where s[mask] is equal to sum of all its submasks (the masks containing 1-bits only in positions where mask contains 1-bits) in 24·224 operations using following code:

for (int mask = 0; mask < (1 << 16); ++mask) s[mask] = dp[x][mask];for (int i = 0; i < 16; ++i)    for (int mask = 0; mask < (1 << 16); ++mask)        if (!(mask & (1 << i))) s[mask ^ (1 << i)] += s[mask];Let's calculate sl[mask] and sr[mask] for dp[l][mask] and dp[r][mask] respectively. If we will find s[mask] = sl[mask] * sr[mask], s[mask] will contain multiplications of values of pairs of masks from left and right dp's, which are submasks of mask. As soon as we need pairs, which in bitwise OR will give us exactly mask, we should exclude pairs, which in bitwise OR gives a submask of mask, not equal to mask. This gives us exclusion-inclusion principle idea. The formula of this will be

, where p is the parity of number of bits in mask^submask.

Such sum could be calculated with approach above, but subtracting instead of adding

for (int mask = 0; mask < (1 << 16); ++mask) s[mask] = sl[mask] * sr[mask];for (int i = 0; i < 16; ++i)    for (int mask = 0; mask < (1 << 16); ++mask)        if (!(mask & (1 << i))) s[mask ^ (1 << i)] -= s[mask];In such way we will recalculate dynamic for one vertex in about 3·24·216 operations.

Jury's solution: 13390713

Codeforces Round #322 (Div.2) Editorial

By fcspartakm, history, 7 years ago, translation, In English581A — Vasya the HipsterThe first number in answer (number of days which Vasya can dress fashionably) is min(a, b) because every from this day he will dress one red sock and one blue sock.

After this Vasya will have either only red socks or only blue socks or socks do not remain at all. Because of that the second number in answer is max((a - min(a, b)) / 2, (b - min(a, b)) / 2).

Asymptotic behavior of this solution — O(1).

581B — Luxurious HousesThis problem can be solved in the following way. Let's iterate on given array from the right to the left and will store in variable maxH the maximal height if house which we have already considered.Then the answer to house number i is number max(0, maxH + 1 - hi), where hi number of floors in house number i.

Asymptotic behavior of this solution — O(n), where n — number of houses.

581C — Developing SkillsThis problem can be solved in many ways. Let's consider the most intuitive way that fits in the given time.

In the beginning we need to sort given array in the following way — from two numbers to the left should be the number to which must be added fewer units of improvements to make it a multiple of 10. You must add at least one unit of energy to every of this numbers. For example, if given array is {45, 30, 87, 26} after the sort the array must be equal to {87, 26, 45, 30}.

Now we iterate on the sorted array for i from 1 to n. Let's cur = 10 - (aimod10). If cur ≤ k assign ai = ai + cur and from k subtract cur else if cur > k break from cycle.

The next step is to iterate on array in the same way.

Now we need only to calculate answer ans — we iterate on array for i from 1 to n and assign ans = ans + (ai / 10).

Asymptotic behavior of this solution — O(n * log(n)) where n is the number of hero skills.

581D — Three LogosThis problem can be solved in many ways, let's consider one of them.

The first step is to calculate sum of squares s of given rectangles. Then the side of a answer square is sqrt(s). If sqrt(s) is not integer print -1. Else we need to make the following.

We brute the order in which we will add given rectangles in the answer square (we can do it with help of next_permutation()) and for every order we brute will we rotate current rectangle on 90 degrees or not (we can do it with help of bit masks). In the beginning on every iteration the answer square c in which we add the rectangles is empty.

For every rectangle, which we add to the answer square we make the following — we need to find the uppermost and leftmost empty cell free in answer square c (recall that we also brute will we rotate the current rectangle on 90 degrees or not). Now we try to impose current rectangle in the answer square c and the top left corner must coinside with the cell free. If current rectangle fully placed in the answer square c and does not intersect with the some rectangle which has already been added, we need to fill by the required letter appropriate cells in the answer square c.

If no one of the conditions did not disrupted after we added all three rectangles and all answer square c is fully filled by letters we found answer and we neeed only to print the answer square c.

Else if we did not find answer after all iterations on the rectangles — print -1.

For random number of the rectangles k asymptotic behavior — O(k! * 2k * s) where s — the sum of squares of the given rectangles.

Also this problem with 3 rectangles can be solved with the analysis of the cases with asymptotic O(s) where s — the sum of squares of given rectangles.

581E — Kojiro and FurrariLet's f — the position of start, and e — the position of finish. For convenience of implementation we add the gas-station in point e with type equals to 3.

Note: there is never a sense go to the left of the starting point because we already stand with a full tank of the besr petrol. It is correct for every gas-station in which we can appear (if in optimal answer we must go to the left in some gas-station pv, why not throw out all the way from pv to current gas-station v and back and after that the answer will be better). Now let's say about algorithm when we are in some gas-station v.

The first case: on distance no more than s there is the gas-station with quality of gasoline not worse, than in the current gas-station. Now we fix nearest from them nv (nearest to the right because go to the left as we understand makes no sense). In that case we refuel in such a way to can reach nv and go to nv.

The second case: from the current gas-station we can reach only gas-station with the worst quality (the type of the current gas-station can be 2 or 3). If we are in the gas-station of type 2 we need to refuel on maximum possiblevalue and go in the last achievable gas-station. If we are in the gas-station with type 3, we need to go in the farthest gas-station with type 2, but if there is not such gas-station we need to go to the farthest gas-station with type 1. This reasoning are correct because we first need to minimze the count of fuel with type 1, and the second to minimize the count of fuel with type 2.

This basic reasoning necessary to solve the problem. The next step — calc dynamic on all suffixes i of gas-stations — the answer to the problem if we start from the gas-station i with empty tank. We need to make updates, considering the above cases. For update the dynamic in v we need to take the value of dynamic in nv and make update in addiction of the case. If the case is equals to 1, we need to add to appropriate value the distance d from v to nv. If this case is equals to 2 and we are in the gas-station with type equals to 2 we need to add s to the second value of answer, and from the first value we need to substract s–d. If it is the case number 2 and we are in the gas-station with type equals to 3, we need to substract from the value, which determined by the type of the gas-station nv, s–d.

Now to answer on specific query of the starting position we nned to find the first gas-station which is to the right of the startiong position, make one update and take the value of dynamic, which already calculated, and recalculate this value in accordance with the above.

Asymptotic behavior — O(n logn) or O(n) in case how we find position in the list of gas-stations (the first in case of binary search, the second in case of two pointers).

To this solution we need O(n) memory.

581F — Zublicanes and MumocratesLet the number of leavs in tree (vertices with degree 1) is equal to c. It said in statement that c is even. If in given graph only 2 vertices the answer is equal to 1. Else we have vertex in graph which do not a leaf — we hang the three on this vertex.

Now we need to count 2 dynamics. The first z1[v][cnt][col] — the least amount of colored edges in the subtree rooted at the vertex v, if vertex v already painted in color col (col equals to 0 or to 1), and among the top of the leaves of the subtree v must be exactly cnt vertices with color 0. If we are in the leaf, it is easy to count this value. If we are not in the leaf — we count value with help of dynamic z1[v][cnt][col]:  = z2[s][cnt][col], where s — the first child int the adjacency list of vertex v.

We need the second dynamic z2[s][cnt][col] to spread cnt leaves with color 0 among subtrees of childs of vertex v. To calc z2[s][cnt][col] we brute the color of child s — ncol and the number of childs i with color 0, which will be locate in subtree of vertex s and calc the value in the following way — z2[s][cnt][col] = min(z2[s][cnt][col], z2[ns][cnt–a][col] + z1[s][a][ncol] + (ncol! = col)), where ns — the next child of vertex v after the child s. Note, that it is senselessly to take a more than the number of leaves in the subtree s and to take more than the number of vertices in subtree — sizes (because in that case it will not be enough leaves for painting).

The upper bound of asymptotic for such dynamics O(n3). We show that in fact it works with asymptotic O(n2). Let's count the number of updates: . Note, that every pair of vertices (x, y) appears in the last sum (x, y) exactly once when v = lca(x, y). So we have no more than O(n2) updates.

Asymptotic behavior of this solution: O(n2).

Codeforces Round #321 Editorial

By igdor99, 7 years ago, translation, In English580A - Kefa and First Steps

Note, that if the array has two intersecting continuous non-decreasing subsequence, they can be combined into one. Therefore, you can just pass the array from left to right. If the current subsequence can be continued using the i-th element, then we do it, otherwise we start a new one. The answer is the maximum subsequence of all the found ones.

Asymptotics — O(n).

Solution

580B - Kefa and Company

At first we sort all friends in money ascending order. Now the answer is some array subsegment. Next, we use the method of two pointers for finding the required subsegment.

Asymptotics — O(n log n).

Solution

580C - Kefa and Park

Let's go down the tree from the root, supporting additional parameter k — the number of vertices in a row met with cats. If k exceeds m, then leave. Then the answer is the number of leaves, which we were able to reach.

Asymptotics — O(n).

Solution

580D - Kefa and Dishes

A two-dimensional DP will be used to solve the problem. The first dimention is the mask of already taken dishes, and the second — the number of the last taken dish. We will go through all the zero bits of the current mask for the transitions. We will try to put the one in them, and then update the answer for a new mask. The answer will consist of the answer of the old mask, a dish value, which conforms to the added bit and the rule, that can be used. The final answer is the maximum of all the values of DP, where mask contains exactly m ones.

Asymptotics — O(2n * n2).

Solution

580E - Kefa and Watch

At first, we calculate the hash for all line elements depending on their positions. That is, the hash of the number k, standing on the i-th position will be equal to gi * k, where g is the base of the hash. We construct the segment tree of sums, which support a group modification, for all hashes. Thus, we can perform queries for modification in O(log n). It remains to deal with the queries of the second type. Let us assume, that we want to process the query 2 l r d. Obviously, the substring from l to r have a d-period, if a substring from l + d to r is equal to substring from l to r - d. We can find out the sum of hashes at the subsegment with the help of the sums tree, so we can compare the two strings in O(log n).

Asymptotics — O(m log n).

Solution

Codeforces Round #320 [Bayan Thanks-Round] Editorial

By dreamoon_love_AA, history, 7 years ago, In EnglishProblm 1 : Raising BacteriaWrite down x into its binary form. If the ith least significant bit is 1 and x contains n bits, we put one bacteria into this box in the morning of (n + 1 - i)th day. Then at the noon of the nth day, the box will contain x bacteria. So the answer is the number of ones in the binary form of x.

code of author's friend: this

Problem 2 : Finding Team MemberSort all possible combinations from high strength to low strength. Then iterator all combinations. If two people in a combination still are not contained in any team. then we make these two people as a team.

author's code: this

Problem 3 : A Problem about PolylineIf point (a,b) is located on the up slope/ down slope of this polyline. Then the polyline will pass the point (a - b,0)/(a + b,0).(we call (a - b) or (a + b) as c afterwards) And we can derive that c / (2 * x) should be a positive integer. Another condition we need to satisfy is that x must be larger than or equal to b. It’s easy to show that when those two conditions are satisfied, then the polyline will pass the point (a,b).

Formally speaking in math : Let c / (2 * x) = y Then we have x = c / (2 * y) ≥ b and we want to find the maximum integer y. After some more math derivation, we can get the answer is . Besides, the only case of no solution is when a < b.

In fact,  always dosn't exist or larger than .

author's code:

#include <bits/stdc++.h>typedef long long LL;using namespace std;int main(){    LL a,b;    cin>>a>>b;    if(a<b)puts("-1");    else printf("%.12f\n",(a+b)/(2.*((a+b)/(2*b))));    return 0;}Problem 4 : Or GameWe can describe a strategy as multiplying ai by x ti times so ai will become bi = ai * xti and sum of all ti will be equals to k. The fact is there must be a ti equal to k and all other ti equals to 0. If not, we can choose the largest number bj in sequence b, and change the strategy so that tj = k and all other tj = 0. The change will make the highest bit 1 of bj become higher so the or-ed result would be higher.

After knowing the fact, We can iterator all number in sequence a and multiply it by xk and find the maximum value of our target between them. There are several method to do it in lower time complexity. You can check the sample code we provide.(I believe you can understand it quickly.)

author's code:

#include<cstdio>#include<algorithm>using namespace std;const int SIZE = 2e5+2;long long a[SIZE],prefix[SIZE],suffix[SIZE];int main(){    int n,k,x;    scanf("%d%d%d", &n, &k, &x);    long long mul=1;    while(k--)        mul *= x;    for(int i = 1; i <= n; i++)        scanf("%I64d", &a[i]);    for(int i = 1; i <= n; i++)        prefix[i] = prefix[i-1] | a[i];    for(int i = n; i > 0; i--)        suffix[i] = suffix[i+1] | a[i];    long long ans = 0;    for(int i= 1; i <= n; i++)        ans = max(ans, prefix[i-1] | (a[i] * mul) | suffix[i+1]);    printf("%I64d\n",ans);}Problem 5 : Weakness and PoornessLet , we can write down the definition of poorness formally as

 

. It's easy to see that A is a strictly decreasing function of x, and B is a strictly increasing function of x. Thus the minimum of max(A, B) can be found using binary or ternary search. The time complexity is ,

Now here give people geometry viewpoint of this problem:

let 

We plot n + 1 straight line y = i * x + bi in the plane for i from 0 to n.

We can discover when you are given x. The weakness will be (y coordinator of highest line at x) — (y coordinator of lowest line at x).

So we only need to consider the upper convex hull and the lower convex hull of all lines. And the target x value will be one of the intersection of these convex hull.

Because you can get these line in order of their slope value. we can use stack to get the convex hulls in O(n).

author's code : this (using binary search)

code of author's friend (using stack to handle convexhull with O(n), have more precision)

Problem 6 : LCS againFollowings are solution in short. Considering the LCS dp table lcs[x][y] which denotes the LCS value of first x characters of S and first y characters of T. If we know lcs[n][n] = n - 1, then we only concern values in the table which abs(x - y) ≤ 1 and all value of lcs[x][y] must be min(x, y) or min(x, y) - 1. So each row contains only 8 states(In fact,three states among these states will never be used), we can do dp on it row by row with time complexity O(n).

There is another not dp method. You can refer this comment.

author's code:

#include <bits/stdc++.h>#define SZ(X) ((int)(X).size())#define ALL(X) (X).begin(), (X).end()#define REP(I, N) for (int I = 0; I < (N); ++I)#define REPP(I, A, B) for (int I = (A); I < (B); ++I)#define RI(X) scanf("%d", &(X))#define RII(X, Y) scanf("%d%d", &(X), &(Y))#define RIII(X, Y, Z) scanf("%d%d%d", &(X), &(Y), &(Z))#define DRI(X) int (X); scanf("%d", &X)#define DRII(X, Y) int X, Y; scanf("%d%d", &X, &Y)#define DRIII(X, Y, Z) int X, Y, Z; scanf("%d%d%d", &X, &Y, &Z)#define RS(X) scanf("%s", (X))#define CASET int ___T, case_n = 1; scanf("%d ", &___T); while (___T-- > 0)#define MP make_pair#define PB push_back#define MS0(X) memset((X), 0, sizeof((X)))#define MS1(X) memset((X), -1, sizeof((X)))#define LEN(X) strlen(X)#define PII pair<int,int>#define VPII vector<pair<int,int> >#define PLL pair<long long,long long>#define F first#define S secondtypedef long long LL;using namespace std;const int MOD = 1e9+7;const int SIZE = 1e5+10;// template end hereLL dp[SIZE][8];char s[SIZE];int get_bit(int x,int v){return (x>>v)&1;}int main(){    DRII(n,m);    RS(s+1);    REPP(i,1,n+1)s[i]-='a';    s[n+1]=-1;    REP(i,m){        int state=1;        if(i==s[1])state|=2;        if(i==s[1]||i==s[2])state|=4;        dp[1][state]++;    }    REPP(i,2,n+1){        REP(j,8){            int d[4]={i-3+get_bit(j,0),i-2+get_bit(j,1),i-2+get_bit(j,2)};            REP(k,m){                int d2[4]={};                REPP(l,1,4){                    if(s[i-2+l]==k)d2[l]=d[l-1]+1;                    else d2[l]=max(d2[l-1],d[l]);                }                if(d2[1]>=i-2&&min(d2[2],d2[3])>=i-1)dp[i][(d2[1]-(i-2))|((d2[2]-(i-1))<<1)|((d2[3]-(i-1))<<2)]+=dp[i-1][j];            }        }    }    printf("%lld\n",dp[n][0]+dp[n][1]+dp[n][4]+dp[n][5]);    return 0;}Problem 7 : Walking!Since there is only one person, it’s not hard to show the difference between the number of left footprints and the number of right footprints is at most one.

For a particular possible time order of a sequence of footprints, if there are k backward steps, we can easily divide all footprints into at most k + 1 subsequences without backward steps. Then you might guess that another direction of the induction is also true.That is, we can combine any k + 1 subsequence without backward steps into a whole sequence contains at most k backward steps. Your guess is correct !

Now we demostrate the process of combining those subsequences.

We only concern the first step and the last step of a divided subsequence. There are four possible combinations, we denote them as LL/LR/RL/RR subsequence separately(the first character is the type of the first step and the second character is the type of the second step).

Suppose the number of four types of subseueqnce(LL/LR/RL/RR) are A, B, C, D separately. We have abs(A - D) ≤ 1.

We can combine all RR, LL subsequeces in turn into one subsequenceswith at most A + D - 1 backward steps(the result may be of any of the four subsquence types). Now we have at most one LL or RR type subsequence.

Then we can combine all RL subsequence into only one RL subsequence with at most A - 1 backward steps easily. And so do LR subsequences. Now we want to combine the final RL and LR subsequences together. We could pick the last footprint among two subsequences, exclude it from the original subsequcne and append it at the tail of another subsequence. The move will not increase the number of backward step and the types of the two subsequences would become RR and LL ! We can easily combine them into one LR or RL subsequence now. If there is still a LL or RR type subsequence reamained. We can easily combine them, too.

So if we can divide all footprints into the least number of subsequences without backward steps. Then we have solved the problem. And this part can be done with greedy method.

Now we provide one possible greedy method:

Firstly, we translate this problem to a maximum matching problem on bipartite graph as following:

Take "RLLRRL" as example:

   

We split each footprint into two vertices which on is in left part and another is in right part.

If two footprints is next to each other in resulted subsequnces, we will connect the left vertex of the former to right vertex of the latter in the corresponded matching. So the matching described in above left graph is subsequences: "RL-R--" and "--L-RL" and in above right graph is "RL-R-L" and "--L-R-". we can find that the number of subsequences is (number of footprints) — (value of matching).

Due to the graphs produced by this problem is very special, we can solve this bipartite matching as following:

Iterate each vertex in left part from top to bottom and find the uppermost vertex which is able to be matched in right part and connect them.

If we process this algorithm in "RLLRRL", the resulted matching is the above right graph.

Why the greedy method is correct? we can prove it by adjusting any maximum matching to our intended matching step by step. In each step, you can find the uppermost vertex the state of which is different to what we intend and change its state. I guess the mission of adjusting is not too hard for you to think out! Please solve it by yourself >_<

By the way, I believe there are also many other greedy methods will work. If your greedy method is different to author's. Don't feel strange.

author's code: this

Problem 8 : The Mirror BoxIf we view the grid intersections alternatively colored by blue and red like this:

 

Then we know that the two conditions in the description are equivalent to a spanning tree in either entire red intersections or entire blue dots. So we can consider a red spanning tree and blue spanning tree one at a time.

We can use disjoint-sets to merge connected components. Each component should be a tree, otherwise some grid edges will be enclosed inside some mirrors. So for the contracted graph, we would like to know how many spanning trees are there. This can be done by Kirchhoff’s theorem.

Since there are at most 200 broken mirrors, the number of vertices in the contracted graph should be no more than 401. Hence a O(|V|3) determinant calculation algorithm may be applied onto the matrix.

author's code: this

Editorial Codeforces Round #319

By malcolm, 7 years ago, translation, In EnglishTask A. Div2.

It's easy to see that number x can appear in column i only once — in row x / i. For every column i, let's check that x divides i and x / i ≤ n. If all requirements are met, we'll update the answer.

The complexity is O(n)

Source

Task B. Div2.

Let's consider two cases: n > m and n ≤ m.

If n > m, let's look at prefix sums. By pigeonhole principle, there are two equals sums modulo m. Assume Slmodm = Srmodm. Then the sum on segment [l + 1, r] equals zero modulo m, that means the answer is definitely "YES".

If n ≤ m, we'll solve this task using dynamic programming in O(m2) time. Assume can[i][r] means if we can achieve the sum equal to r modulo m using only first i - 1 items. The updates in this dynamic programming are obvious: we either take number ai and go to the state can[i + 1][(r + ai) mod m] or not, then we'll get to the state can[i + 1][r].

The complexity is O(m2).

Source

Task A. Div1.

If Petya didn't ask pk, where p is prime and k ≥ 1, he would not be able to distinguish pk - 1 and pk.

That means, he should ask all the numbers pk. It's easy to prove that this sequence actually guesses all the numbers from 1 to n

The complexity is O(N1.5) or O(NloglogN) depending on primality test.

Source

Task B. Div1.

Let's look at the answer. It's easy to notice, that centers of that tree must turn into centers after applying the permutation. That means, permutation must have cycle with length 1 or 2 since there're at most two centers.

If permutation has cycle with length 1, we can connect all the other vertices to it.

For example, let's look at the permutation (4, 2, 1, 3). 2 is a cycle with length 2, so let's connect all the other vertices to it. The resulting tree edges would be (1, 2), (2, 3), (2, 4).

If answer has two centers, let's remove the edge between them. The tree will split into two connected parts. It's easy to see that they will turn into each other after applying permutation. That means, all cycles should be even.

It's easy to come up with answer with these restrictions. Let's connect vertices from the cycles with length 2. Then, let's connect vertices with odd position in cycles to first of these and vetices with even cycles to second one.

For example, let's consider permutation (6, 5, 4, 3, 1, 2). There are two cycles: (3, 4) и (1, 6, 2, 5). We add edge (3, 4), all other vertices we connect to these two, obtaining edges (1, 3), (6, 4), (2, 3), (5, 4).

The complexity is O(N).

Source

Task C. Div1.

Let's split rectangle 106 × 106 by vertical lines into 1000 rectangles 103 × 106. Let's number them from left to right. We're going to pass through points rectangle by rectangle. Inside the rectangle we're going to pass the points in increasing order of y-coordinate if the number of rectangle is even and in decreasing if it's odd.

Let's calculate the maximum length of such a way. The coordinates are independent. By y-coordinate we're passing 1000 rectangles from 0 to 106, 109 in total. By x-coordinate we're spending 1000 to get to the next point of current rectangle and 2000 to get to next rectangle. That means, 2 * 109 + 2000000 in total, which perfectly fits.

The complexity is O(n * log(n))

Source

Task D. Div1.

Let's optimize the first solution that comes to mind: O(m * dmax), let's calculate can[t][v] — can we get to the vertice v, while passing exactly t edges.

Now, it's easy to find out that the set of edges we are able to go through changed only m times. Let's sort these edges in increasing order of di, that means for each i di ≤ di + 1. Let's calculate can[t][v] only for t = di. We can calculate can[di + 1] using can[di] by raising the adjacency matrix to the di + 1 - di power and applying it to can[di].

Next step is to fix an edge with maximal di on our shortest path, let it be i. We know all the vertices we can be at moment di, so we need to calculate the shortest path to n - 1 using edges we can go through. We can even use Floyd algorithm to calculate that.

The complexity of this solution is O(m * n3 * log(dmax)) and it's not enough.

Next observation is that adjacency matrix contains only zeroes or ones, so we can multiply these matrixes using bitsets in O(n3 / 32).

This makes complexity O(m * n3 * log(dmax) / 32), which gets accepted.

Source

Task E. Div1.

Let's solve an easier task first: independent of bipartivity, the color of edge changes.

Then we could write a solution, which is pretty similar to solution of Dynamic Connectivity Offline task in O(nlog2n).

Let's consider only cases, where edges are not being deleted from the color graph. Then, we could use DSU with storing parity of the way to the parent along with parent. Now we can find parity of the path to the root by jumping through parents and xoring the parities. Also, we can connect two components by accurately calculating the parity of the path from one root to another.

Now edges are being deleted. For each edge and each color we know the segments of requests, when this edge will be in the graph of specified color. Let's build a segment tree on requests, in each vertex of the tree we store list of edges which exist on the subsegment. Every segment will be split into log parts, so, totally there would be n * log small parts.

Now we can dfs this segment tree with DSU. We get inside the vertex, apply all the requests inside it, go through the children and revert DSU to initial state. We also answer requests in leafs of the segment tree.

Let's return to initial task. We can't use this technique, because we don't know the exact segments of edge existence.

Instead, let's do following. Initially we add each edge right until the first appearance of this edge in requests. Now, when we're in some leaf, we found out which color this edge would be right until the next appearance of this edge. So, let's update this edge on that segment.

For each leaf we're going to make an update at most once, so the complexity is O(nlog2n).

Source

If anything is unclear or bad-written, ask any questions.

Codeforces Round #318 [RussianCodeCup Thanks-Round] Editorial

By Errichto, 8 years ago, In EnglishDiv2B — Bear and Three Musketeers

Warriors are vertices and "knowing each other" is an edge. We want to find connected triple of vertices with the lowest sum of degrees (and print sum - 6 because we don't want to count edges from one chosen vertex to another).

Brute force is O(n3). We iterate over all triples a, b, c and consider them as musketeers. They must be connected by edges (they must know each other). If they are, then we consider sum of their degrees.

We must notice that there is low limit for number of edges. So instead of iterating over triples of vertices we can iterate over edges and then iterate over third vertex. It gives us O(n2 + nm) and it's intended solution. To check if third vertex is connected with other two, you should additionally store edges in 2D adjacency matrix.

It's also possible to write it by adding "if" in right place in brute forces to get O(n2 + nm). Check it out in code.

Div1A — Bear and Poker

Any positive integer number can be factorized and written as 2a·3b·5c·7d·....

We can multiply given numbers by 2 and 3 so we can increase a and b for them. So we can make all a and b equal by increasing them to the same big value (e.g. 100). But we can't change powers of other prime numbers so they must be equal from the beginning. We can check it by diving all numbers from input by two and by three as many times as possible. Then all of them must be equal. Code

Alternative solution is to calculate GCD of given numbers. Answer is "YES" iff we can get each number by multiplying GCD by 2 and 3. Otherwise, some number had different power of prime number other than 2 and 3. Code

Div1B — Bear and Blocks

In one operation the highest block in each tower disappears. So do all blocks above heights of neighbour towers. And all other blocks remain. It means that in one operation all heights change according to formula hi = min(hi - 1, hi - 1, hi + 1) where h0 = hn + 1 = 0. By using this formula two times we get height after two operations: hi = max(0, min(hi - 2, hi - 1 - 1, hi - 2, hi + 1 - 1, hi + 2)) and so on. From now I will omit max(0, ...) part to make it easier to read.

After k operations we get hi = min(Left, Right) where Left = min(hi - j - (k - j)) = min(hi - j + j - k) for  and Right is defined similarly. hi becomes zero when Left or Right becomes zero. And Left becomes zero when k = min(hi - j + j) — we will find this value for all i. If you are now lost in this editorial, try to draw some test and analyze my formulas with it.

For each i we are looking for min(hi - j + j). We can iterate over i from left to right keeping some variable best:

best = min(best, h[i]);best is answer for i;best++;We should to the same for Right and take min(Left, Right) for each i. Then final answer is maximum over answers for i. Code

Div1C — Bear and Drawing

Let's consider a tree already drawn on a strip of paper. Let's take first vertex on the left and last vertex on the right (in case of two vertices with the same x, we choose any of them). There is a path between them. Let's forget about vertices not on this path. A path divides a strip into 1D regions.

 

What can be added to the main path? Only simple paths attached to it with one edge. So it can be one of the following structures — Y-letter or Line:

 

Note that Y-letter can have long legs but its central part can have only one edge.

How to check if given tree is a path + Y-letters + Lines? First, let's move from each leaf till we have vertex with degree at least 3, marking vertices as deleted. We don't mark last vertex (that with degree at least 3) as deleted but we increase his number of legs. Finally, for each not-deleted vertex we count his not-deleted neighbours for which degree - min(legs, 2) > 1 — otherwise this neighbour is start of Line or Y-letter. Each vertex on the main path can have at most two neighbours that also belong to the main path. There can be more neighbours but they must be in Lines or Y-letters — that's why we didn't count them. So answer is "No" iff for some vertex we counted more than two neighbours. Code

Div1D — Bear and Cavalry

Let's sort warriors and horses separately (by strength). For a moment we forget about forbidden assignments. Inversion is a pair of warriors that stronger one is assigned to weaker horse. We don't like inversions because it's not worse to assign strong warriors to strong horses: A·B + a·b ≥ A·b + B·a for A ≥ a and B ≥ b. Note that repairing an inversion (by swapping assigned horses) decreases number of inversions — prove it by yourself (drawing a matching with intersections could be helpful). Without any restrictions the optimal matching is when we assign i-th warrior to i-th horse (indexed after sorting) — to get no inversions.

Let's go back to version with forbidden connections. We have n disjoint pairs which we can't use. We will prove that there exists an optimal assignment where (for all i) i-th warrior is assigned to j-th horse where |i - j| ≤ 2.

Let's take an optimal assignment. In case of ties we take the one with the lowest number of inversions. Let's assume that i is assigned to i + 3. There are at least 3 warriors j > i assigned to horses with indices lower than i + 3. So we have at least 3 inversions with edge from i to i + 3 (warriors on the left, horses on the right):

 

Above, connection warrior-horse is an edge. Then inversions are intersections. Swapping horses for warriors i and j (where j belongs so some red edge) would decrease number of inversions and it wouldn't decrease a score. We took an optimal assignment so it means that it's impossible to swap horses for them. Hence, for each red edge we can't change pair (black, read) into the following blue edges:

 

So one of these blue edges is forbidden. Three red edges generate three pairs of blue edges and in each pair at least one blue edge must be forbidden. Note that all six blue edges are different. All blue edges are incident to warrior i or to horse i + 3 but only one forbidden edge can be incident to warrior i and only one forbidden edge can be incident to horse i + 3. We have at most two forbidden edges incident to them so it can't be true that three blue edges are forbidden.

By cases analysis we can prove something more — that there can be only three possible types of connecting in an optimal assignment. First type: i can be connected to i. Second: warrior i with horse i + 1 and warrior i + 1 with horse i. Third: warriors i, i + 1 and i + 2 are connected with horses i, i + 1, i + 2.

It gives us O(nq) solution with calculating queries independently with dp[i] defined as "what result can we get for assigning everything with indices lower than i?". To calculate dp[i] we must know dp[i - 3], dp[i - 2] and dp[i - 1]. It wasn't intended solution because we can get better complexity.

We can create a segment tree and for intervals we should keep info "result we can get for this interval with 0/1/2 first and 0/1/2 last elements removed". For an interval we keep matrix 3x3 and actualizing forbidden edge for single i consists of: 1. calculating values of 3x3 matrix for a small interval with i 2. actualizing a tree with  times multiplying matrices

Complexity is .

Div1E — Bear and Bowling

FIRST PART — greedy works

We will add (take) elements to a subsequence one by one. Adding number x, when we have k - 1 taken numbers on the left, increases result by k·x + suf where suf is sum of taken numbers on the right. Let's call this added value as the Quality of element x.

We will prove correctness of the following greedy algorithm. We take element with the biggest Quality till there are no elements left. For every size of a subsequence (number of taken elements) we will get optimal score.

(lemma) If ai > aj and i < j, we won't take aj first.

Proof. Let's consider a moment when we don't fulfill the lemma for the first time. If there are no taken numbers between ai and aj, we have Qi = k·ai + suf > k·aj + suf = Qj so ai is a better choice. For taken numbers between ai and aj — each number x changes Qi by x and Qj by aj. We'll see that x > aj so Qi will remain greater than Qj. If ai > x, the lemma (fulfilled till now) says that x wasn't taken before ai — it can't be true because x is taken and ai is not. So indeed x ≥ ai > aj.

Let's assume that our greedy strategy is not correct. Let's consider first moment when we take some element aj and for some s we can't get optimal subsequence with size s by taking more elements (using any strategy). Let A denote a set of elements taken before. So there is no way to add some more elements to set A + aj and achieve optimal score with size s. But it was possible just before taking aj so there is a subset of remaining elements B that |A + B| = s and set A + B is the best among sets with size s. Note that B can't be empty.

(case 1 — B contains at least one element on the left from aj) Let ai denote last element from B that i < j (here "last" means "with the biggest i"). Our strategy wanted aj before elements from B so we know from lemma that ai ≤ aj. It will turn out that replacing ai with aj (in set A + B) doesn't decrease the score so taking aj is acceptable. Note that replacing an element with another one doesn't change size of a set/subsequence.

In moment of choosing aj it had the biggest quality so then Qj ≥ Qi. Now in A + B there are new elements, those in B. Let's imagine adding them to A (without ai and aj). Each new element x on the right change both Qi and Qj by x. Elements on the left change Qi by ai and Qj by aj (note that ai ≤ aj). And there are no elements between ai and aj. Now, taking ai would give us set A + B but Qj remains not less than Qi so we can take aj instead.

(case 2 — B contains only elements on the right from aj) Similarly, we can replace ai with closest aj from set B. As before, elements on the right change Qi and Qj by the same value.

SECOND PART — how to implement it

First, let's understand  solution. We divide a sequence into  Parts. When choosing the best candidate in a Part, we want to forget about other Parts. It's enough to remember only x and suf — number of taken elements on the left (in previous Parts) and sum of elements on the right (in next Parts). x affects choosing the best element in a Part, suf doesn't (but we need this constant to add it to result for best candidate). For a Part we want to have hull with  linear functions of form ai·x + b. With binary search we can find the best element in  and then construct new hull for this Part in .

We can remove  from complexity. First, binary search can be replaced with pointers — for each Part initially we set a pointer at the beginning of Part. To find best candidate in Part, we slowly move pointer to the right (by one). Complexity is amortized . And we can sort linear functions ai·x + b by angle only once because value ai doesn't change — then constructing a hull is only . Note that when rebuilding a hull, we must set pointer to the beginning of Part.

So we have . Code.

There are other two correct lemmas to speed your solution up. We can take all positive numbers first (it's not so easy to prove). And we can stop when taken number doesn't increase score — next taken numbers won't increase score neither.

Codeforces Round #317 [AimFund Thanks-Round] Editorial

By Kostroma, history, 8 years ago, In English572A - Массивы

In this problem one need to check whether it's possible to choose k elements from array A and m elements from array B so that each of chosen element in A is less than each of chosen elements in B. If it's possible then it's possible to choose k smallest elements in A and m largest elements in B. That means that in particular, k-th smallest element of A is less than m-th largest element in B. So, if A[k] < B[n - m + 1] then the answer is "YES" and if not, then the answer is "NO".

Problem author: zeliboba.

Problem developers: riadwaw, Kostroma.

Solution code: 12873382.

572B - Биржевые заявки

First of all the problem may be solved for buy orders and sell orders separately.

The easiest soultion is to use structure like std::map or java.lang.TreeMap. To aggregate orders we just add volume to the corresponding map element: aggregated[price] += volume.

After that we should extract lowest (or largest) element from map s times (or while it's not empty).

Complexity of this solution is O(nlogn).

It is also possible to solve the problem without data structres other than an array. You should just maintain at most s best orders in sorted order and when adding another order you insert it in appropriate place and move worse elements in linear time of s. Complexity of this solution is O(sn).

Problem authors and developers: ArtDitel, yarrr.

Solution code: 12873385.

571A - Удлинение палочек

Let's count the number of ways to form a triple which can't represent triangle sides, and then we subtract this value from  — the total number of ways to increase the sticks not more than l in total. This number is obtained from partition of l into 4 summands (la + lb + lc + unusedl = l), or can be counted using a for loop.

Now we consider triples a + la, b + lb, c + lc, where la + lb + lc ≤ l, la, lb, lc ≥ 0. Fix the maximal side, for example it would be a + la. We'll have to do the following algo for b + lb and c + lc in the same way. The triple is not a triangle with maximal side a + la if a + la ≥ b + lb + c + lc. If we iterate over la between 0 and l, we have the following conditions on lb, lc:

lb + lc ≤ a - b - c + la, lb + lc ≤ l - la, lb, lc ≥ 0. So, non-negative integers lb, lc should be such that lb + lc ≤ min(a - b - c + la, l - la). If we denote this minimum as x than we can choose lb, lc in  different ways (again we divide x into three summands: lb, lc and some unused volume). Also when we fix lb, there are x - lb + 1 ways to choose lc, so the overall number of pair lb, lc is

so we obtain the same formula.

To sum up, we need to iterate over the maximal side and over the addition to that side, then write these formulas, and subtract the result from the total number of different additions to the sides. The complexity of the solution is O(l).

Problem author: Kostroma.

Problem developers: Kostroma, riadwaw.

Solution code: 12873406.

571B - Минимизация

We can divide all indices [1;n] into groups by their remainder modulo k. While counting , we can consider each group separately and sum the distances between neighbouring numbers in each group.

Consider one group, corresponding to some remainder i modulo k, i.e. containing aj for . Let's write down its numbers from left to right: b1, b2, ..., bm. Then this group adds to the overall sum the value

We can notice that if we sort b1, ..., bm in non-decreasing order, this sum will not increase. So, in the optimal answer we can consider that numbers in each group don't decrease. Furthermore, in that case this sum is equal to |bm - b1|.

Now consider two groups b1, ..., bm and c1, c2, ..., cl, both sorted in non-decreasing order. We claim that either b1 ≥ cl or bm ≤ c1, i.e. segments [b1, bm] and [c1, cl] can have common points only in their endpoints.

Why is this true? These groups add |bm - b1| + |cl - c1| to the overall sum. We consider the case c1 ≥ b1, the other is symmetric. If c1 < bm, then swapping c1 and bm will not increase the values these groups add to the answer, since the right border of b group moves to the left, and the left border of c group moves to the right. So, c1 ≥ bm in that case, and the assertion is proved.

Now we know that the values in each group should from a continuous segment of the sorted original array. In fact, we have  groups of size  (so called small groups) and  groups of size  (so called large groups). Consider the following dynamic programming: dp[L][S] — the minimal sum of values added to the answer by L large groups and S small groups, if we choose the elements for them from the first  elements of the sorted array A. There are no more than O(k2) states, and each transition can be made in O(1): we choose large or small group to add and obtain the number it adds to the sum by subtracting two elements of the sorted array. The answer for the problem will be in .

The overall complexity of the solution is . We can note that in pretests  was quite small, and some slower solutions could pass, but they failed on final tests.

Problem author: zeliboba.

Problem developers: Kostroma, riadwaw.

Solution code: 12873418.

571C - КНФ-2

Firstly let's assign values to variables occurring in our fomula only with negation or only without negation. After that we can throw away the disjuncts which contained them, since they are already true, and continue the process until it is possible. To make it run in time limit, one should use dfs or bfs algorithm to eliminate these variables and disjuncts.

So now we have only variables which have both types of occurrences in disjucnts. Let's build a graph with the vertices corresponding to disjuncts, and for each varible a make an edge between the disjuncts that contain a and !a. Now we should choose the directions of edges in this graph in such a way that every vertex has at least one incoming edge.

We can notice that if some connected component of this graph is a tree, the solution is not possible: on each step we can take some leaf of this tree, and we have to orient its only edge to it, and then erase the leaf. In the end we'll have only one vertex, and it'll not have any incoming edges.

Otherwise, take some cycle in the component and orient the edges between neighbouring vertices along it. Then run dfs from every vertex of the cycle and orient each visited edge in the direction we went along it. It is easy to easy that after this process every vertex will have at least one incoming edge.

So, we should consider cases with the variables which values can be assigned at once, than construct a graph from disjuncts and variables and find whether each connected component has a cycle. If so, we also should carefully construct the answer, assigning the remaining variables their values, looking at the directions of the edges in the graph. The overall complexity is O(n + m).

Problem author: zeliboba.

Problem developers: Kostroma, zeliboba, yarrr.

Solution codes: 12873432 (linear solution), 12873446 (), 12873456 (matching solution).

571D - Кампус

Let's suppose for each dormitory from Q query we already know the last raid moment.

When task will be much easier: we can throw away M and Z queries and to get right answer we should subtract two values: people count in dormitory right now and same count in a last raid moment.

On this basis, we have such plan:

For each Q query let's find the last raid moment using M and Z queries.Find people count in two interesting moments using U and A queries.Calculcates the final answer.Let's try to solve the first part.

We want to make such queries on disjoint sets:

Merge two sets (M query).Assign value time for all elements in particular set (Z query).Get value for a particular element (Q query).To solve this task we'll use a well-known technique: "merge smaller set to bigger".

We'll maintain such values:

elements — set elements.set_id — for each element their set id.last_set_update_time — last moment when assign operation has occurred for each set.last_update_time — last moment when assign operation has occurred for each element.actual_time — moment of time when last_update_time was actually for the element.Let's focus on actual_time value.

It's obvious that when we merge two sets each element can have a different last assign moment. But after first assignment all elements from any set will have the same value. So the answer for Q query for element i from set s: If last_set_update_time[s]=actual_time[i] then last_update_time[i] else last_set_update_time[s]

For each Z query you should just update last_set_update_time array.

It's easy to maintain this values when you merge two sets:

Let's suppose we want to merge set from to set to. For each element from set from we already know last assign time. So just update last_update_time with this value and actual_time is equal of last assign operation for set to.

The second part of the solution is the same as first one.

O(n * lg(n) + m) time and O(n + m) memory.

Problem author: ArtDitel.

Problem developers: yarrr, gchebanov, Kostroma.

Solution codes: 12873477 (solution, described in the editorail), 12873469 (solution with treaps).

571E - Геометрические прогрессии

If intersection of two geometric progressions is not empty, set of common elements indexes forms arithmetic progression in each progression or consists of not more than one element. Let's intersect first progression with each other progression. If any of these intersections are empty then total intersection is empty. If some of these intersection consist of one element, then we could check only this element. Otherwise one could intersect arithmetic progressions of first progression indexes and take minimal element of this intersection. The remaining question is how intersect two geometric progression? Let's factorise all numbers in these two progressions and find set of appropriate indexes for every prime factor in both progressions. These progressions one need intersect both by values and by indexes.

Problem author: zeliboba.

Problem developers: zeliboba, yarrr, gchebanov.

Solution code: 12873480.

Codeforces Round #316 Editorial

By josdas, history, 8 years ago, translation, In English570А — Elections

We need to determine choice for each city. Then sum it for each candidate and determine the winner.

O(n * m)

Solutions

570B — Simple Game

Lets find which variant is interesting. For Andrew is no need a variant wherein |a - m| > 1 because we can increase probability of victory if we will be closer to m. Then we consider two variants, a = c - 1 and a = c + 1. Probability of victory will be c / n for first variant and (n - c + 1) / n for second.

We need to choose better variant, also we must keep in mind case of n = 1.

O(1)

Solutions

570C — Replacement

Lets find how replacements occur. If we have segment of points with length l,we need l - 1 operations and stop replacements for this segment. If we sum lenghts of all segments and its quantity then answer will be = total length of segments — quantity of segments. After change of one symbol length changes by 1.

Quantity of segments can be supported by array. Consider events of merging, dividing,creation and deletion of segments. For merging we need to find if both of neighbors(right and left) are points then merging occured and quantity of segments reduced by 1. Other cases can be cosidered similarly.

O(n + m)

Solutions

570D — Tree Requests

We need to write vertices in DFS order and store time of enter/exit of vertices in DFS. All vertices in subtree represent a segment. Now we can get all vertices in subtree v on height h as a segment, making two binary searches.

We can make a palindrome if quantity of uneven entries of each letter is less than 2.

This function can be counted for each prefix in bypass for each depth.

For saving the memory bit compression can be used considering that we need only parity and function is xor.

O(m * (log + 26) + n)

D had a offline solution too in O(n + m * (26 / 32)) time and O(n * 26 / 8) memory

Solutions

570E — Pig and Palindromes

We need palindrome paths. Palindrome is word which reads the same backward or forward. We can use it. Count the dynamic from coordinates of 2 cells, first and latest in palindrome.

From each state exists 4 transitions (combinations: first cell down/to the right and second cell up/to the left). We need only transitions on equal symbols for making a palindrome. Note that we need a pairs of cells on equal distance from start and end for each.

For saving memory we need to store two latest layers.

O(n3) — time and O(n2) — memory

Solutions

Codeforces Round #315 Editorial

By Um_nik, history, 8 years ago, translation, In English569A - Music

Suppose we have downloaded S seconds of the song and press the 'play' button. Let's find how many seconds will be downloaded when we will be forced to play the song once more. . Hence x = qS.

Solution: let's multiply S by q while S < T. The answer is the amount of operations.

Complexity — 

569B - Inventory

Let's look at the problem from another side: how many numbers can we leave unchanged to get permutation? It is obvious: these numbers must be from 1 to n and they are must be pairwise distinct. This condition is necessary and sufficient.

This problem can be solved with greedy algorithm. If me meet the number we have never met before and this number is between 1 and n, we will leave this number unchanged. To implement this we can use array where we will mark used numbers.

After that we will look over the array again and allocate numbers that weren't used.

Complexity — O(n).

568A - Primes or Palindromes?

It is known that amount of prime numbers non greater than n is about .

We can also found the amount of palindrome numbers with fixed length k — it is about  which is .

Therefore the number of primes asymptotically bigger than the number of palindromic numbers and for every constant A there is an answer. Moreover, for this answer n the next condition hold: . In our case n < 107.

For all numbers smaller than 107 we can check if they are primes (via sieve of Eratosthenes) and/or palindromes (via trivial algorithm or compute reverse number via dynamic approach). Then we can calculate prefix sums (π(n) and rub(n)) and find the answer using linear search.

For A ≤ 42 answer is smaller than 2·106.

Complexity — .

568B - Symmetric and Transitive

Let's find Johnny's mistake. It is all right in his proof except ``If '' part. What if there is no such b for an given a? Then obviously  otherwise we'll take b = a.

We can see that our binary relation is some equivalence relation which was expanded by some "empty" elements. For "empty" element a there is no such b that .

Thus we can divide our solution into two parts:

Count the number of equivalence relations on sets of size 0, 1, ..., n - 1

For every size count the number of ways to expand it with some "empty" elements.

We can define equivalence relation using its equivalence classes.

So first part can be solved using dynamic programming: dp[elems][classes] — the numbers of ways to divide first elems elements to classes equivalence classes. When we handle next element we can send it to one of the existing equivalence classes or we can create new class.

Let's solve second part. Consider set of size m. We have found that there are eq[m] ways to build equivalence relation on this set. We have to add n - m "empty" elements to this set. The number of ways to choose their positions is Cnk. We can calculate all the binomial coefficients using Pascal's triangle.

So the answer to the problem is .

Complexity — O(n2)

568C - New Language

Suppose we have fixed letters on some positions, how can we check is there a way to select letters on other positions to build a word from the language? The answer is 2-SAT. Let's see: for every position there is two mutually exclusive options (vowel or consonant) and the rules are consequences. Therefore we can do this check in O(n + m) time.

Let's decrease the length of the prefix which will be the same as in s. Then the next letter must be strictly greater but all the next letters can be any. We can iterate over all greater letters and then check if we can made this word the word from the language (via 2-SAT). Once we have found such possibilty we have found the right prefix of the answer. After that we can increase the length of the fixed prefix in a similar way. This solution works in O(nmΣ ) time. We can divide this by Σ simply try not all the letter but only the smallest possible vowel and the smallest possible consonant.

And you should remember about the case when all the letters are vowel (or all the letters are consonant).

Complexity — O(nm)

568D - Sign Posts

Suppose, that solution exist. In case n ≤ k we can put one signpost on each road. In other case let's choose any k + 1 roads. By the Dirichlet's principle there are at least two roads among selected, which have common signpost. Let's simple iterate over all variants with different two roads. After choosing roads a and b, we will remove all roads, intersecting with a and b in common points and reduce k in our problem. This recursive process solves the problem (if solution exist).

Complexity of this solution — . If implement this solution carefully — you will get AC =)

But in case of TL we can add one improvement to our solution. Note, that if we find point, which belongs to k + 1 or more roads, then we must include this point to out answer. For sufficiently large n (for example, if n > 30k2) this point always exist and we can find it using randomize algorithm. If solution exist, probability that two arbitrary roads are intersects in such a point not less than . Because of it, if we 100 times pick two random roads, then with probability  such a point will be found and we can decrease k.

All operations better to do in integers.

Complexity — .

568E - Longest Increasing Subsequence

Let's calculate array c: c[len] — minimal number that can complete increasing subsequence of length len. (This is one of the common solution for LIS problem).

Elements of this array are increasing and we can add new element v to processed part of sequence as follows:

find such index i that c[i] ≤ v and c[i + 1] ≥ v

let c[i + 1] = v

We can process this action in  time.

When we handle a gap, we must try to insert all numbers from set b. If we sort elements of b in advance, then we can move with two iterators along arrays b and c and relax all needed values as explained above. This case requires O(n + m) time.

Authors implied solution with O(n) space complexity for answer restoring. We can do this in the following way:

Together with array c we will store array cindex[len] — index of element, which complete optimal increasing subsequence of length len. If this subsequence ends in a gap — we will store  - 1.

Also, we will store for every not gap — length of LIS(lenLIS[pos]), which ends in this position (this is simply calculating while processing array c) and position(prevIndex[pos]) of previous element in this subsequence (if this elements is gap, we store  - 1)

Now we will start recovery the answer with this information.

While we are working with not gaps — it's all right. We can simply restore LIS with prevIndex[pos] array. The main difficulty lies in processing gaps. If value of prevIndex[pos] in current position equal to  - 1 — we know, that before this elements must be one or more gaps. And we can determine which gaps and what values from b we must put in them as follows:

Let suppose that we stand at position r (and prevIndex[r] =  - 1). Now we want to find such position l (which is not gap), that we can fill exactly lenLIS[r] - lenLIS[l] gaps between l with increasing numbers from interval (a[l]..a[r]). Position l we can simply iterates from r - 1 to 0 and with it calculating gaps between l and r. Check the condition described above we can produce via two binary search query to array b.

Few details:

How do we know, that between positions l and r we can fill gaps in such a way, that out answer still the best?Let countSkip(l, r) — count gaps on interval (l..r), countBetween(x, y) — count different numbers from set b, lying in the range (x..y).Then, positions l and r are good only if lenLIS[r] - lenLIS[l] = min(countSkip(l, r), countBetween(a[l], a[r])). countSkip we can calculate while iterates position l, countBetween(x, y) = max(0, lower_bound(b, y) - upper_bound(b, x)).

What to do, is LIS ends or begins in gaps?This case we can solve by simply adding  - ∞ and  + ∞ in begin and end of out array.

Complexity — . Memory — O(n + m).

Editorial Codeforces Round #Pi

By vovuh, history, 8 years ago, translation, In English567A - Lineland Mail

One can notice that the maximum cost of sending a letter from i'th city is equal to maximum of distances from i'th city to first city and from i'th city to last (max(abs(xi - x0), abs(xi - xn - 1)). On the other hand, the minimum cost of sending a letter will be the minimum of distances between neighboring cities (i - 1'th and i + 1'th cities), more formally, min(abs(xi - xi - 1), abs(xi - xi + 1). For each city, except the first and the last this formula is correct, but for them formulas are (abs(xi - xi + 1)) and (abs(xi - xi - 1)) respectively.

Author solution

567B - Berland National Library

To answer the queries correct, we need to know if the person is still in the library. For that purpose we will use in array of type bool. Also we will store two variables for the answer and ''current state'' (it will store the current number of people in the library). Let's call them ans and state respectively.

Thus, if we are given query  + ai then we should increase state by one, mark that this person entered the library (in[ai] = true) and try to update the answer (ans = max(ans, state)).

Otherwise we are given  - ai query. If the person who leaves the library, was in there, we should just decrease state by one. Otherwise, if this person was not in the library (in[ai] == false) and leaves now, he entered the library before we started counting. It means we should increase the answer by one anyway. Also one should not forget that it is needed to mark that the person has left the library (in[ai] = false).

Author solution

567C - Geometric Progression

Let's solve this problem for fixed middle element of progression. This means that if we fix element ai then the progression must consist of ai / k and ai·k elements. It could not be possible, for example, if ai is not divisible by k ().

For fixed middle element one could find the number of sequences by counting how many ai / k elements are placed left from fixed element and how many ai·k are placed right from it, and then multiplying this numbers. To do this, one could use two associative arrays Al and Ar, where for each key x will be stored count of occurences of x placed left (or right respectively) from current element. This could be done with map structure.

Sum of values calculated as described above will give the answer to the problem.

Author solution

567D - One-Dimensional Battle Ships

First, we should understand when the game ends. It will happen when on the n-sized board it will be impossible to place k ships of size a. For segment with length len we could count the maximum number of ships with size a that could be placed on it. Each ship occupies a + 1 cells, except the last ship. Thus, for segment with length len the formula will look like  (we add "fictive" cell to len cells to consider the last ship cell). This way, for [l..r] segment the formula should be .

For solving the problem we should store all the [l..r] segments which has no ''free'' cells (none of them was shooted). One could use (std: : set) for that purpose. This way, before the shooting, there will be only one segment [1..n]. Also we will store current maximum number of ships we could place on a board. Before the shooting it is equal to .

With every shoot in cell x we should find the segment containing shooted cell (let it be [l..r]), we should update segment set. First, we should delete [l..r] segment. It means we should decrease current maximum number of ships by  and delete it from the set. Next, we need to add segments [l..x - 1] and [x + 1..r] to the set (they may not be correct, so you may need to add only one segments or do not add segments at all) and update the maximum number of ships properly. We should process shoots one by one, and when the maximum number of ships will become lesser than k, we must output the answer. If that never happen, output  - 1.

Author solution

567E - President and Roads

At first, let's find edges that do not belong to any shortest paths from s to t. Let's find two shortest path arrays d1 and d2 with any shortest-path-finding algorithm. First array stores shortest path length from s, and the second — from t. Edge (u, v) then will be on at least one shortest path from s to t if and only if d1[u] + w(u, v) + d2[v] == d1[t].

Let's build shortest path graph, leaving only edges described above. If we consider shortest path from s to t as segment [0..D] and any edge (u, v) in shortest path graph as its subsegment [d1[u]..d1[v]], then if such subsegment do not share any common point with any other edge subsegment, except its leftest and rightest point (d1[u] and d1[v]), this edge belongs to every shortest path from s to t.

Now we could surely answer "YES" to such edges. Next part of the solution are much simple. If edge (u, v) do not belong to every shortest path, we could try decrease its weight. This edge will belong to every shortest path if and only if its weight will become d1[t] - d1[u] - d2[v] - 1. So, if this value are strictly positive, we should answer "CAN" considering new edge weight. Otherwise we need to output "NO".

Author solution

567F - Mausoleum

Consider that we are placing blocks by pairs, one pair by one, starting from leftmost and rightmost places. Thus, for example, two blocks of height 1 we could place in positions 1 and 2, 1 and 2n, or 2n - 1 and 2n. The segment of unused positions will be changed that way and the next block pairs should be placed on new leftmost and rightmost free places. At last only two positions will be free and we should place two blocks of height n on them.

Any correct sequence of blocks could be builded that way. Let's try to review the requirements consider such way of placing blocks. As soon as we place blocks one by one, the requirements are now only describes the order of placing blocks. For example, requirement ''3 >= 5'' means that we should place block in position 3 only if block in position 5 is already placed (and thus it have lesser height), or we place pair of blocks of same height on them at one moment.

For counting required number of sequences we will use dynamic programming approach. Let's count dp[l][r] — the number of ways to place some blocks in the way that only positions at segment [l..r] are free. The height of current placed pair of blocks is counted from the segment borders itself (. Fix one way of placing current block pair (exclusion is l =  = r + 1). Now check if such placing meets the requirements. We will consider only requirements that meets one of the current-placing positions. For every "current" position "<" must be true only for free positions (positions in [l..r], which do not equal to current positions), ">" must be true for already-placed positions (out of [l..r]) and "=" must be true only for second current position.

This DP could be easily calculated using "lazy" approach.

Author solution

Codeforces Round 313 — Extended editoral

By Sammarize, 8 years ago, translation, In English560A - Currency System in Geraldion

If there is a banlnot of value 1 then one can to express every sum of money. Otherwise one can't to express 1 and it is minimum unfortunate sum.

560B - Gerald is into Art

It is easy to see that one can snuggle paintings to each other and to edge of board. For instance one can put one of painting right over other. Then height of two paintings equals to sum of two heights and width of two paintings is equals to maximum of two widths. Now we can just iterate orientation of paintings and board.

559A - Gerald's Hexagon & 560C - Gerald's Hexagon

Let's consider regular triangle with sides of k Let's split it to regular triangles with sides of 1 by lines parallel to the sides. Big triange area k2 times larger then small triangles area and therefore big triangle have splitted by k2 small triangles.

If we join regular triangles to sides a1, a3 and a5 of hexagon we get a triangle sides of a1 + a2 + a3. Then hexagon area is equals to (a1 + a2 + a3)2 - a12 - a32 - a52.

 

559B - Equivalent Strings & 560D - Equivalent Strings

Let us note that "equivalence" described in the statements is actually equivalence relation, it is reflexively, simmetrically and transitive. It is meant that set of all string is splits to equivalence classes. Let's find lexicographic minimal strings what is equivalent to first and to second given string. And then check if its are equals.

It is remain find the lexicographic minimal strings what is equivalent to given. For instance we can do it such a way:

String smallest(String s) {    if (s.length() % 2 == 1) return s;    String s1 = smallest(s.substring(0, s.length()/2));    String s2 = smallest(s.substring(s.length()/2), s.length());    if (s1 < s2) return s1 + s2;    else return s2 + s1;}Every recursive call time works is O(n) (where n is length of strings) and string splitten by two twice smaller strings. Therefore time of work this function is , where n is length of strings.

559C - Gerald and Giant Chess & 560E - Gerald and Giant Chess

Let's denote black cells ad A0, A1, ..., Ak - 1 . First of all, we have to sort black cells in increasing order of (row, column). If cell x available from cell y, x stands after y in this order. Let Ak = (h, w). Now we have to find number of paths from (1, 1) to Ak avoiding A0, ..., Ak - 1.

Let Di is number of paths from (1, 1) to Ai avoiding A0, ..., Ai - 1. It's easy to see that Dk is answer for the problem. Number of all paths from (1, 1) to (xi, yi) is . We should subtract from that value all paths containing at least one of previous black cells. We should enumerate first black cell on the path. It could be one of previous cell that is not below or righter than Ai. For each such cell Aj we have to subtract number of paths from (1, 1) to Aj avoiding black cells multiplied by number of all paths from Aj to Ai.

We have to calculate factorials of numbers from 1 to 2·105 and inverse elements of them modulo 109 + 7 for calculating binomial coefficients.

559D - Randomizer

We can use Pick's theorem for calculate integer points number in every polygon. Integer points number on the segment between points (0, 0) and (a, b) one can calculate over GCD(a, b).

Integer points number in some choosen polynom is integer points number in basic polynom minus integer points number in segmnent of basic polynom separated by every segment of choosen polynom.

Let consider every potencial segment of polygon. We can calculate integer points number in his segment and probability that we will meet it in choosen polygon.

Probability of segment AiAi + k is . Let use note that we can calculate only segments with k < 60 because of other segmnet propapility is too small.

559E - Gerald and Path

Lighted part of walking trail is union of ligted intervals. Let's sort spotlights in increasing order of ai. Consider some lighted interval (a, b). It's lighted by spotlights with numbers {l, l + 1, ..., r} for some l and r ("substring" of spotlights). Let x0, ..., xk is all possible boundaries of lighted intervals (numbers ai - li, ai и ai + li).

Imagine, that we know possible lighted intervals of all substrings of spotlights. Let left[l][r][j] is least possible i such that set of spotlights with numbers {l, l + 1, ..., r} lighting [xi, xj].

With left we can calculate value best[R][i] maximum possible length of walking trail that could be lighted using first L spotlights in such way that xi is rightmost lighted point. It's easy to do in O(n4) because .

Now all we have to do is calculate left. Consider some substring of spotlights [l, r]. Let all spotlights in the substring oriented in some way lighting some set of points. We could consider most left (i) and most right (j) lighted points, and left bound of first lighted interval (t). If set of lighted points is interval t = j. Consider how all the values change when we add spotlight r + 1 and choose its orientation. We have new lighted interval [a, b] which is equal to [ai - li, ai] or [ai, ai + li]. Now most left lighted point is min(a, xi), most right is max(b, xj). Right bound of leftmost lighted interval does not changes if a > t or becomes equal to b, if a ≤ t.

Not for each L we can calculate dp[r][j][y] least possible i that it's possible to orient spotlights from [L, r] in such way that xi is most left lighted point xj is most right one and right bound of leftmost lighted interval is xt. Thet it's easy to calculate left[L][][]. That part is done in O(n4) too.

Codeforces Round #312 (Div. 2) Editorial

By RetiredAmrMahmoud, 8 years ago, In English558A - Lala Land and Apple TreesLet's divide all the trees into two different groups, trees with a positive position and trees with a negative position. Now There are mainly two cases:

If the sizes of the two groups are equal. Then we can get all the apples no matter which direction we choose at first.If the size of one group is larger than the other. Then the optimal solution is to go to the direction of the group with the larger size. If the size of the group with the smaller size is m then we can get apples from all the m apple trees in it, and from the first m + 1 trees in the other group.So we can sort each group of trees by the absolute value of the trees position and calculate the answer as mentioned above.

Time complexity: 

Implementation .

558B - Amr and The Large ArrayFirst observation in this problem is that if the subarray chosen has x as a value that has the maximum number of occurrences among other elements, then the subarray should be [x, ..., x]. Because if the subarray begins or ends with another element we can delete it and make the subarray smaller.

So, Let's save for every distinct element x in the array three numbers, the smallest index i such that ai = x, the largest index j such that aj = x and the number of times it appears in the array. And between all the elements that has maximum number of occurrences we want to minimize j - i + 1 (i.e. the size of the subarray).

Time complexity: 

Implementation

558C - Amr and ChemistryLet the maximum number in the array be max. Clearly, changing the elements of the array to any element larger than max won't be optimal, because the last operation is for sure multiplying all the elements of the array by two. And not doing this operation is of course a better answer.

Now we want to count the maximum number of distinct elements that can be reached from some element ai that are not larger than max. Consider an element ai that has a zero in the first bit of its binary representation. If we divided the number by two and the multiplied it by two we will get the original number again. But if it has a one, the resulting number will be different. So, for counting the maximum number of distinct elements we will assume ai = x where x has only ones in its binary representation.

From x we can only reach elements that have a prefix of ones in its binary representation, and the other bits zeros (e.g. {0, 1, 10, 11, 100, 110, 111, 1000, ...} ). Let's assume max has m bits in its binary representation, then x can reach exactly  distinct elements. So, from each element in the array ai we can reach at most  elements.

So, Let's generate the numbers that can be reached from each element ai using bfs to get minimum number of operations. And between all the numbers that are reachable from all the n elements let's minimize the total number of operations.

Time complexity: 

Implementation

558D - Guess Your Way Out! IIFirst, each query in the level i from L to R can be transmitted into level i + 1 from L * 2 to R * 2 + 1, so, we can transform each query to the last level.

Let's maintain a set of correct ranges such that the answer is contained in one of them. At the beginning we will assume that the answer is in the range [2h - 1, 2h - 1] inclusive. Now Let's process the queries. If the query's answer is yes, then we want to get the intersection of this query's range with the current set of correct ranges, and update the set with the resulting set. If the query's answer is no, we want to exclude the query's range from the current set of correct ranges, and update the set with the resulting set.

After we finish processing the queries, if the set of correct ranges is empty, then clearly the game cheated. Else if the set has only one correct range [L, R] such that L = R then we've got an answer. Otherwise there are multiple exit candidates and the answer can't be determined uniquely using the current data.

We will have to use stl::set data structure to make updating the ranges faster. In each yes query we delete zero or more ranges. In each no query we may add one range if we split a correct range, so worst case will be linear in queries count.

Time complexity: 

Implementation

558E - A Simple TaskIn this problem we will be using counting sort. So for each query we will count the number of occurrences for each character, and then update the range like this

for(int j=x;j<=y;j++)  cnt[s[j] - 'a']++;ind = 0;for(int j=x;j<=y;j++){  while(cnt[ind] == 0)    ind++;  s[j] = ind + 'a';  cnt[ind]--;}But this is too slow. We want a data structure that can support the above operations in appropriate time.

Let’s make 26 segment trees each one for each character. Now for each query let’s get the count of every character in the range, and then arrange them and update each segment tree with the new values. We will have to use lazy propagation technique for updating ranges.

Time complexity:  where sz is the size of the alphabet (i.e. = 26).

Implementation

Codeforces Round #311 (Div.2) Editorial

By fcspartakm, 8 years ago, translation, In English557A — Ilya and DiplomasThis problem can be solved in the different ways. We consider one of them — parsing cases.

If max1 + min2 + min3 ≤ n then the optimal solution is (n - min2 - min3, min2, min3).

Else if max1 + max2 + min3 ≤ n then the optimal solution is (max1, n - max1 - min3, min3).

Else the optimal solution is (max1, max2, n - max1 - max2).

This solution is correct because of statement. It is guaranteed that min1 + min2 + min3 ≤ n ≤ max1 + max2 + max3.

Asymptotic behavior of this solution — O(1).

557B — Pasha and TeaThis problem can be solved in different ways too. We consider the simplest solution whici fits in the given restrictions.

At first we sort all cups in non-decreasing order of their volumes. Due to reasons of greedy it is correct thatsorted cups with numbers from 1 to n will be given to girls and cups with numbers from n + 1 to 2 * n will be given to boys.

Now we need to use binary search and iterate on volume of tea which will be poured for every girl. Let on current iteration (lf + rg) / 2 = mid. Then if for i from 1 to n it is correct that mid ≤ ai and for i from n + 1 to 2 * n it is correct that 2 * mid ≤ ai then we need to make lf = mid. Else we need to make rg = mid.

Asymptotic behavior of this solution — O(n * log(n)) where n — count of cups.

557C — Arthur and TableThis problem can be solved as follows. At first we need to sort all legs in non-descending order of their length. Also we need to use array cnt[].

Let iterate on length of legs (which will stand table) from the least. Let this lenght is equals to maxlen. Count of units of energy which we need for this we will store in variable cur.

Obviously that we must unscrew all legs with lenght more than maxlen. For calculate count of units of energy for doing it we can use array with suffix sums, for exapmle. Then we add this value to cur.

If count of legs with length maxlen is not strictly greater than the number of the remaining legs then we need to unscrew some count of legs with length less than maxlen. For this we can use array cnt[]. In cnt[i] we will store count of legs with difficulty of unscrew equals to i. In this array will store information about legs which already viewed.

We will iterate on difficulty of unscrew from one and unscrew legs with this difficulties (and add this difficulties to variable cur) while count of legs with length maxlen will not be strictly greater than the number of the remaining legs.

When it happens we need to update answer with variable cur.

Asymptotic behavior of this solution — O(n * d), where n — count of legs and d — difference between maximal and minimal units of energy which needed to unscrew some legs.

557D — Vitaliy and CycleTo solve this problem we can use dfs which will check every connected component of graph on bipartite. It is clearly that count of edges which we need to add in graph to get the odd cycle is no more than three.

Answer to this problem is three if count of edges in graph is zero. Then the number of ways to add three edges in graph to make odd cycle is equals to n * (n - 1) * (n - 2) / 6 where n — count of vertices in graph.

Answer to this problem is two if there is no connected component with number of vertices more than two. Then the number of ways to add two edges in graph to make odd cycle is equals to m * (n - 2) where m — number of edges in graph.

Now we have one case when there is at least one connected component with number of vertices more than two. Now we need to use dfs and try to split every component in two part. If for some component we can't do it that means that graph already has odd cycle and we need to print "0 1" and we can now finish our algorithm.

If all connected components in graph are bipartite then we need to iterate on them. Let cnt1 is the count of vertices in one part of current component and cnt2 — count of vertices in the other part. If number of vertices in this component more than two we need to add to answer cnt1 * (cnt1 - 1) / 2 and cnt2 * (cnt2 - 1) / 2.

Asymptotic behavior of this solution — O(n + m), where n — number of vertices in graph and m — number of edges.

557E — Anya and Half-palindromeThis problem can be solved with help of dynamic programming.

At first we calculate matrix good[][]. In good[i][j] we put true, if substring from position i to position j half-palindrome. Else we put in good[i][j]false. We can do it with iterating on "middle" of half-palindrome and expanding it to the left and to the right. There are 4 cases of "middle" but we omit it because they are simple enough.

Now we need to use Trie and we will put in it suffixes of given string. Also we will store array cnt[]. In cnt[v] we will store number of half-palindromes which ends in vertex v of our Trie. Let now we put in tree suffix which starts in position i, current symbol of string which we put is in position j and we go in vertex v of out Trie. Then if good[i][j] = true we add one to cnt[v].

Now with help of dfs let calculate for every vertex sum[v] — sum of numbers which stored in array cnt[] for vertex v and for vertices in all subtrees of vertex v.

It is left only to restore answer. Start from root of our Trie. We will store answer in variable ans. In variable k store number of required substring. Let now we in vertex v, by letter 'a' we can go in vertex toa and by letter 'b' — in vertex tob.

Then if sum[toa] ≤ k we make ans +  = 'a' and go in vertex toa of our Trie. Else we need to make as follows: k —  = sum[toa], ans +  = 'b' and go in vertex tob of our Trie.

When k will be  ≤ 0 print resulting string ans and finish algorithm.

Asymptotic behavior of this solution — O(szalph * n2) where szalph — size of input alphabet (in this problem it equals to two) and n — length of given string.

Codeforces Round #310 Editorial

By Lord_F, history, 8 years ago, In EnglishHello, everyone!

556A - Case of the Zeros and Ones

If there still exist at least one 0 and at least one 1 in the string then there obviously exists either substring 01 or substring 10 (or both) and we can remove it. The order in which we remove substrings is unimportant: in any case we will make min(#zeros, #ones) such operations. Thus the answer is #ones + #zeros - 2min(#ones, #zeros) = |#ones - #zeros|.

Time: O(n).

556B - Case of Fake Numbers

Notice that after pressing the button n times gears return to initial state. So the easiest solution is to simulate the process of pressing the button n times and if at some step the active teeth sequence is 0, 1, ... , n - 1 output "Yes" else "No". But this solution can be improved. For instance, knowing the active tooth of the first gear you can quickly determine how many times pressing the button is necessary, go to that state and check the sequence only once.

Time: O(n) or O(n2); solutions: O(n) and O(n^2)

555A - Case of Matryoshkas

Suppose we don't need to disassemble some sequence of dolls. Then no doll can be inserted into no doll from this chain. So we don't need to disassemble a sequence of dolls only if they are consecutive and start from 1. Let the length of this chain be l. Then we will need to get one doll from another n - k - l + 1 times. Now we have a sequence 1 → 2 → ... → l and all other dolls by themselves. n - l + 1 chains in total so we need to put one doll into another n - l times. 2n - k - 2l + 1 operations in total.

Time: O(n); solution.

555B - Case of Fugitive

We can put a bridge between bridges i and i + 1 if its length lies in the segment [li + 1 - ri;ri + 1 - li]. Now we have a well-known problem: there are n - 1 segments and m points on a plane, for every segment we need to assign a point which lies in it to this segment and every point can be assigned only once.

Let's call a segment open if no point is assigned to it. Let's go through all points from left to right and at every moment keep all open segments that contain current point in a BST (std::set). When processing a point it should be assigned to the segment (from our set) that has the leftmost right end.

This algorithm will find the answer if there is one. Suppose this solution is wrong and suppose there is a solution in which point A is assigned to another open segment (there's no sense in skipping this point). Then some point B is assigned to the segment which A was assigned to. B is to the right of A so we can swap them and come to our answer again.

Time: O((n + m)log(n + m)); solution.

555C - Case of Chocolate

Let's solve this problem with two segment trees: we'll keep the lowest eaten piece for each column in one of them and the leftmost eaten piece for each row in another. Suppose we have a query x y L. Position where we'll stop eating chocolate is stored in the row segment tree so we can easily find the number of eaten pieces. After that we need to update both segment trees.

n is rather big in this problem. One way to deal with it is to use coordinate compression. Another is to use implicit segment trees.

Time: O(qlogq) or O(qlogn); solutions: 1 and 2.

555D - Case of a Top Secret

I call the length of the part of the rope from the weight to the last met peg the active length (denoted as La). After each met peg active length is reduced. Let's process queries separately: at each step we can find next peg with using binary search. If active length becomes at least two times shorter or current step is the first one we proceed to the next step. Otherwise say current peg is peg i and the next one is peg j (without loss of generality i < j). Then after peg j the rope will again touch peg i and the weight will again rotate around peg i. Indeed, 2(xj - xi) ≤ La so the weight will rotate around a peg not to the right to peg i. And either i = 1 or La ≤ xi - xi - 1 so it won't also rotate around a peg to the left to peg i. As long as La ≥ xj - xi the weight will rotate around these two pegs so we can skip through several steps momentarily. This way active length is shortened at least twice so there will be no more than logL steps.

Time: O(mlogLlogn); solution.

555E - Case of Computer Network

First of all, let's reduce this problem to a problem on a tree. In order to achieve this let's orient edges in all biconnected components according to a DFS-order. We'll get a strongly connected component. Suppose it's false. Then this component can be divided into parts A and B such that there's no edge from B to A. As initially there are at least two edges between A and B this situation is impossible because after entering B in our DFS we'll have to exit via one of these edges. Contradiction. We can compress all biconnected components.

Now we need to handle several queries "orient edges on a simple path in a tree" and to check if there are no conflicts. For this let's hang our tree and find LCA's for queries' pairs of vertices. Start another DFS and for every subtree count vertices in this subtree that are beginnings of queries' paths (call it a), that are ends of queries' paths (call it b) and that are precalculated LCAs (call it c). Now we can orient the edge connecting the root of the subtree and its parent: if a - c is positive then it should be oriented up, if b - c is positive then it should be oriented down, if both are positive there's no solution, if both are zeros the direction does not matter.

Time: O(n + qlq) where lq is the time of calculating LCA per query; solution that uses slightly other method for the last part.

Codeforces Round #309 Editorial

By Lewin, 8 years ago, In EnglishDiv2A: Kyoya and PhotobooksSolving this problem just requires us to simulate adding every character at every position at the string, and removing any duplicates. For instance, we can use a HashSet of Strings in Java to do this (a set in C++ or Python works as well).

Bonus: Prove that the number of ways is always (length of string + 1) * 25 + 1.

Example code: http://codeforces.com/contest/554/submission/11767578

Div2B: Ohana Cleans UpFor each row, there is only one set of columns we can sweep so it becomes completely clean. So, there are only n configurations of sweeping columns to look at. Checking a configuration takes O(n2) time to count the number of rows that are completely clean. There are n configurations in all, so this takes O(n3) time total.

Alternatively, another way of solving this problem is finding the maximum number of rows that are all the same.

Example code: http://codeforces.com/contest/554/submission/11767576

Div2C/Div1A: Kyoya and Colored BallsLet fi be the number of ways to solve the problem using only the first i colors. We want to compute fn.

Initially, we have f1  =  1, since we only have a single color, and balls of the same color are indistinguishable. Now, to go from fi to fi + 1, we note that we need to put at a ball of color i + 1 at the very end, but the other balls of color i + 1 can go anywhere in the sequence. The number of ways to arrange the balls of color i + 1 is  (minus one because we need to put one ball at the very end). Using this recurrence, we can solve for fn.

Thus, we need to precompute binomial coefficients then evaluate the product.

Example code: http://codeforces.com/contest/553/submission/11767584

Div2D/Div1B: Kyoya and PermutationSolving this requires making the observation that only swaps between adjacent elements are allowed, and all of these swaps must be disjoint. This can be discovered by writing a brute force program, or just noticing the pattern for small n.

Here's a proof for why this is. Consider the cycle that contains n. Since n is the largest number, it must be the last cycle in the sequence, and it's the first element of the sequence. If this cycle is length 1, then we're obviously ok (we can always append (n) to the end). If the cycle is of length 2, we need n to be involved in a cycle with n - 1. Lastly, if the cycle is of length 3 or more, we will see we run into a problem. We'll only show this for a cycle of length 3 (though this argument does generalize to cycles of larger length). Let (nxy) be the cycle. So that means, n is replaced by x, x is replaced by y and y is replaced by n. So, in other words, the original permutation involving this cycle must look like

position:   ... y x nnumber  :   ... n y xHowever, we need it to look like (nxy) so this case is impossible.

So, once we know that n is a in a cycle of length 1 or 2, we can ignore the last 1 or 2 elements of the permutation and repeat our reasoning. Thus, the only valid cases are when we swap adjacent elements, and all swaps are disjoint. After making this observation, we can see the number of valid permutations of length n is fib(n+1). (to see this, write try writing a recurrence).

To reconstruct the kth permutation in the list, we can do this recursively as follows: If k is less than fib(n), then 1 must be the very first element, and append the kth permutation on {1,...,n-1} with 1 added everywhere. Otherwise, add 2, 1 to the very front and append the k-fib(n)th permutation on {1,...,n-2} with 2 added everywhere.

Example code: http://codeforces.com/contest/553/submission/11767583

Div2E/Div1C: Love TrianglesLet's look at the graph of characters who love each other. Each love-connected component can be collapsed into a single node, since we know that all characters in the same connected component must love each other.

Now, we claim that the resulting collapsed graph with the hate edges has a solution if and only if the resulting graph is bipartite.

To show this, suppose the graph is not bipartite. Then, there is an odd cycle. If the cycle is of length 1, it is a self edge, which clearly isn't allowed (since a node must love itself). For any odd cycle of length more than 1, let's label the nodes in the cycle a1, a2, a3, ..., ak. Then, in general, we must have ai loves a(i + 2), since ai, a(i + 1) hate each other and a(i + 1), a(i + 2) hate each other (all indicies taken mod k). However, we can use the fact that the cycle is odd and eventually get that ai and ai + 1 love each other. However, this is a contradiction, since we said they must originally hate each other.

For the other direction, suppose the graph is bipartite. Let X, Y be an arbitrary bipartition of the graph. If we let all nodes in X love each other and all nodes in Y love each other, and every edge between X and Y hate each other, then we get a solution. (details are omitted, though I can elaborate if needed).

Thus, we can see that we have a solution if and only if the graph is bipartite. So, if the graph is not bipartite, the answer is zero. Otherwise, the second part of the proof gives us a way to count. We just need to count the number of different bipartitions of the graph. It's not too hard to see that this is just simply 2^(number of connected components — 1) (once you fix a node, you fix every node connected to it).

This entire algorithm takes O(N + M) time.

Example code: http://codeforces.com/contest/553/submission/11767582

Div1D: Nudist BeachThe algorithm idea works as follows:

Start with all allowed nodes. Remove the node with the smallest ratio. Repeat. Take the best ratio over all iterations. It's only necessary to consider these subsets. Proof for why.

We say this process finds a ratio of at least p if and only if there exists a subset with ratio at least p.

Exists a subset with ratio at least p => algorithm will find answer of at least p. First, observe that the ratio of any particular node only decreases throughout the algorithm. Thus, all nodes in this subset initally have ratio at least p. Then, the very first node that gets removed from this subset must not have ratio smaller than p, thus the above algorithm will record an answer of at least p.

Exists no subset with ratio at least p => algorithm finds answer at most p. No subset with ratio at least p implies every subset has ratio at most p. Thus, at every iteration of our algorithm, we'll get an answer of at most p, so we're done.

Thus, we can see these are necessary and sufficient conditions, so we're done.

Now for efficient implementation, we can use a variant of Dijkstra's. Recording the best subset must be done a bit more carefully as well.

Example code: http://codeforces.com/contest/553/submission/11767581

Div1E: Kyoya and TrainThe Naive solution is O(MT2). Let Wj(t) be the optimal expected time given we are at node j, with t time units left. Also, let We(t) be the optimal expected time given we use edge e at time t.

Now, we have

And, if e = (u->v), we have 

Doing all this naively takes O(MT2).

Now, we'll speed this up using FFT. We'll focus on only a single edge for now. The problem here, however, is that not all Wv values are given in advance. Namely, the Wv values require us to compute the We values for all edges at a particular time, and vice versa. So we need some sort of fast "online" version of FFT.

We do this as follows. Let's abstract away the original problem, and let's say we're given two arrays a,b, where a is only revealed one at a time to us, and b is given up front, and we need to compute c, their convolution (in the original problem b is Pe, and a is Wv, and c is We). Now, when we get the ith value of a, we need to return the ith value of the convolution of c. We can only get the ith value of a when we compute the i-1th values of c for all c.

Split up b into a block of size 1, a block of size 1, then a block of size 2, then a block of size 4, then 8, and so on.

Now, we get a0, which will allow us to compute c1, which lets us get a1, which allows us to compute c2, and so on.

So, now we have the following:

b_1 | b_2 | b_3 b_4 | b_5 b_6 b_7 b_8 | ...We'll describe the processing of a single ai

When we get ai, we will first convolve it with the first two blocks, and add those to the appropriate entry. Now, suppose ai is multiple of a 2k for some k. Then, we will convolve ai - 2k .. ai - 1 with the block in b with the same size.

As an example.

      b_1 | b_2 | b_3 b_4 | b_5 b_6 b_7 b_8 | ...a_0   a0b1              a0b2This gives us c0, which then allows us to get a1

      b_1 | b_2 | b_3 b_4 | b_5 b_6 b_7 b_8 | ...a_0   a0b1  a1b1a_1         a0b2 a1b2This gives us c1, which then allows us to get a2

a2 is now a power of 2, so this step will also additionally convolve a0, a1 with b3, b4

      b_1 | b_2 | b_3      b_4    | b_5 b_6 b_7 b_8 | ...a_0   a0b1  a1b1  a2b1a_1         a0b2  a1b2    a2b2a_2               a0b3 (a1b3+a0b4)  a1b4So, we can see this gives us c2, which then allowus to get a3, and so on and so forth.

Thus, this process of breaking into blocks works. As for runtime, we run FFT on a block size of B T/B times, so this term contributes (T/B) * B log B = T log B

So, we sum T log 2 + T log 4 + ... + T log 2\^(log T) <= T log\^2 T

Thus, the overall time per edge is , which gives us a total runtime of .

Example code: http://codeforces.com/contest/553/submission/11767579

Codeforces Round #308 (Div 2) Editorial

By hsk, history, 8 years ago, In English552A - Vanya and Table For each rectangle she adds ,the value of all the cells in that rectangle is increased by one. Hence it is obvious that if a rectangle of side n*m is added ,the ans increases by n*m

for each rectangle

scan(x1)

scan(y1)

scan(x2)

scan(y1)

ans=ans+(x2-x1+1)*(y2-y+11)

Time Complexity O(n)

My submission:: 11637017

552B - Vanya and Books By number of digits the question means the total number of digits.

Hence number of digits for 1=1

number of digits for 10=2

number of digits for 100=3

We need to write all numbers from 1-n We find the number of digits in n (lets call it k).

Ans=(the number of digits in all 1 digit numbers)+(number of digits in all 2 digit numbers)+...(number of digits in all k-1 digit numbers)+number of digits from 10^k to n.

As the number of p digit numbers = 9*pow(10,p-1)

for(i from 1 to k-1)

ans=ans+i*(9*pow(10,k-1))And finally ans=ans+(n-pow(10,k-1)+1)*k

My submission: O(log(n))

My submission :11639835

552C - Vanya and Scales The problem is a simple case of recursion.We have weights of the form w^k(0<k<100).

if there exists a combination of weights that forms the mass M , then

M=summation(w^k1)-summation(w*k2)

Hence M has to be of the form w*t+k (-1<=k<=1)

t also has to be of the form w*t1+k1 (-1<=k1<=1)

Hence the recursion continues . The base case is when t<w.The answer will be yes if t=w-1||t=1||t=0

Time Complexity O(log(M))

My submission:11644642

552D - Vanya and Triangles

The problem can be solved by a simple brute force for all the points in pairs of 3.If the area of a given pair of 3 triangles is not zero , then it is a possible triangle.

for(i from 0,n-1)for(j from i,n-1)for(k from j,n-1)if (area (i,j,k)!=0)ans++;Time Complexity O(n^3)

The problem can however be solved in n^2 complexity.By iterating over all points in pairs of 2 , we can store their slopes in a map.

Then on iterating over the map we can find the number of triangles which wont contribute to the answer.

for(it in map)

k += (it*(it-1)*(it-2)/6)answer=n*(n-1)*(n-2)/6-k

Time Complexity O(n^2*log(n))

My submission: 11727314

552E - Vanya and Brackets

An easy analysis shows that the brackets must be placed adjacent to * sign since they wont have any effect next to a + sign.

We need to store the indexes of all the * in the string and iterate over all possible pairs. One thing to keep in mind is the maximum case may be one in which the brackets starts at the 0th index or the one in which it ends at the last index.

Time Complexity O((length of string)*15*15)

My submission: 11726590

Codeforces #307 (Div. 2) Editorial

By nikola12345, history, 8 years ago, In EnglishProblems proved to be much harder than we expected. There were some corner cases we didn't include in pretests, so many solutions failed, which was definitely a mistake. Anyway, I hope you find this problemset interesting!

Problem A. GukiZ and Contest

Very simple implementation problem. Just implement what is written in the statement: for every element of array, find the number of array elements greater than it, and add one to the sum. This can be easily done with two nested loops. Total complexity O(n2).

Solution: link

Problem B. ZgukistringZ

First, calculate the number of occurences of every English letter in strings a, b, and c. We can now iterate by number of non-overlapping substrings of the resulting string equal to b, then we can calculate in constant time how many substrings equal to c can be formed (by simple operations on the number of occurences of English letters in c). In every iteration, maximise the sum of numbers of b and c. Number of iterations is not greater than |a|. At the end, we can easily build the resulting string by concatenating previously calculated number of strings b and c, and add the rest of the letters to get the string obtainable from a. Total complexity is O(|a| + |b| + |c|).

Solution: link

Problem C. GukiZ hates Boxes

Problem solution (complete work time) can be binary searched, because if the work can be done for some amount of time, it can certainly be done for greater amount of time. Let the current search time be k. We can determine if we can complete work for this time by folowing greedy algorithm: find last non-zero pile of boxes and calculate the time needed to get there (which is equal to it's index in array) and take with first man as much boxes as we can. If he can take even more boxes, find next non-zero (to the left) pile, and get as much boxes from it, and repete untill no time is left. When the first man does the job, repete the algorithm for next man, and when all m men did their maximum, if all boxes are removed we can decrease upper bound in binary search. Otherwise, we must increase lower bound. Total compexity is .

Solution: link

Problem D. GukiZ and Binary Operations

First convert number k into binary number system. If some bit of k is 0 than the result of or opertion applied for every adjacent pair of those bits in array a must be 0, that is no two adjacent those bits in array a are 1. We should count how many times this is fulfilled. If the values were smaller we could count it with simply dpi = dpi - 1 + dpi - 2, where dpi is equal to number of ways to make array od i bits where no two are adjacent ones. With first values dp1 = 2 and dp2 = 3, we can see that this is ordinary Fibonacci number. We can calculate Fibonacci numbers up to 1018 easily by fast matrix multiplication. If some bit at k is 1 than number of ways is 2n — \t{(number of ways bit is 0)}, which is also easy to calculate. We must be cearful for cases when 2l smaller than k (solution is 0 then) and when l = 63 or l = 64. Total complexity is .

Solution: link

Problem E. GukiZ and GukiZiana

First we divide array a in  groups with  numbers. Every group in each moment will be kept sorted. For type 1 query, If we update some interval, for each group, which is whole packed in the interval, we will add the number it is being increased to it's current increasing value (this means all the elements are increased by this number). If some part of group is covered by interval, update these elements and resort them. Now, let's handle with type 2 queries. When we want find GukiZiana(a, j), we search for the first and the last occurence of j by groups. One group can be binary searched in , because of sorted values, and most  groups will be searched. Of course, for the first occurence we search for minimum index of value of j, and for the last occurence maximum index of value of j in array. When we find these 2 indexes, we must restore their original positions in array a and print their difference. If there is no occurence of j, print  - 1. Total complexity is .

Solution: link

Codeforces Round #306 (Div. 2) Editorial

By ADJA, history, 8 years ago, In English550A - Two SubstringsThere are many ways to solve this problem. Author solution does the following: check if substring "AB" goes before "BA", and then vice versa, if "BA" goes before "AB".

You can do it in the following way: find the first occurence of "AB" then check all substrings of length two to the right of it to check if substring "BA" also exists. Then do it vice versa.

Complexity of the solution is O(n), where n is the length of the given string.

550B - Preparing OlympiadBecause of the low constraints, this problem can be solved by complete search over all problem sets (there are 2n of them).

For every potential problem set (which can be conviniently expressed as bit mask) we need to check if it satisfies all needed criteria. We can simply find the sum of problem complexities and also the difference between the most difficult and the easiest problems in linear time, iterating over the problems that we included in our current set/bitmask. If this problem set can be used, we increase the answer by one.

Complexity of this solution is O(2n·n).

550C - Divisibility by EightThis problem can be solved with at least two different approaches.

The first one is based on the "school" property of the divisibility by eight — number can be divided by eight if and only if its last three digits form a number that can be divided by eight. Thus, it is enough to test only numbers that can be obtained from the original one by crossing out and that contain at most three digits (so we check only all one-digit, two-digit and three-digit numbers). This can be done in O(len3) with three nested loops (here len is the length of the original number).

Second approach uses dynamic programming. Let's calculate dp[i][j], 1 ≤ i ≤ n, 0 ≤ j < 8. The value of dp is true if we can cross out some digits from the prefix of length i such that the remaining number gives j modulo eight, and false otherwise.

This dp can be calculated in the following way: let ai be ith digit of the given number. Then dp[i][aimod8] = true (just this number). For all 0 ≤ j < 8 such that dp[i - 1][j] = true, dp[i][(j * 10 + ai)mod8] = true (we add current digit to some previous result), dp[i][j] = true (we cross out current digit).

Answer is "YES" if dp[i][0] = true for some position i. For restoring the answer we need to keep additional array prev[i][j], which will say from where current value was calculated. Complexity of such solution is O(8·len) = O(len) (again len is the length of the original number).

Code for DP solution:

Spoiler550D - Regular BridgeLet's prove that there is no solution for even k.

Suppose our graph contains some bridges, k = 2s (even), all degrees are k. Then there always exists strongly connected component that is connected to other part of the graph with exactly one bridge.

Consider this component. Let's remove bridge that connects it to the remaining graph. Then it has one vertex with degree k - 1 = 2s - 1 and some vertices with degrees k = 2s. But then the graph consisting of this component will contain only one vertex with odd degree, which is impossible by Handshaking Lemma.

Let's construct the answer for odd k. Let k = 2s - 1.

For k = 1 graph consisting of two nodes connected by edge works.

For k ≥ 3 let's construct graph with 2k + 4 nodes. Let it consist of two strongly connected components connected by bridge. Enumerate nodes of first component from 1 to k + 2, second component will be the same as the first one.

Let vertex 1 be connected to the second component by bridge. Also connect it with k - 1 edges to vertices 2, 3, ..., k. Connect vertices 2, 3, ..., k to each other (add all possible edges between them), and then remove edges between every neighbouring pair, for example edges 2 - 3, 4 - 5, ..., (k - 1) - k.

Then we connect vertices 2, 3, ..., k with vertices k + 1 and k + 2. And finally add an edge between nodes k + 1 and k + 2.

Build the second component in the similar manner, and add a bridge between components. Constructed graph has one bridge, all degrees of k and consists of O(k) nodes and O(k2) edges.

Complexity of the solution — O(k2).

550E - Brackets in ImplicationsLet input consists of , ai is 0 or 1 for all i.

Let's show that there is no solution in only two cases:

1) an = 1.

, for all x, and no parentheses can change last 1 to 0.

2) Input has the form  or its suffix with at least two arguments.

This can be proven by induction. For input  there is no solution, for longer inputs any attempt to put parentheses will decrease the number of 1s in the beginning by one, or will introduce 1 in the last position (which will lead to case one).

Let's construct solution for all other cases.

1) For input 0 we don't need to do anything.

2) For input of the form  we don't need any parentheses, the value of this expression is always

3) Expression in the form  (where second missed part consists of ones only). Then .

Complexity of the solution is O(n).

Codeforces Round #305 Editorial

By PrinceOfPersia, 8 years ago, In English548A - Mike and FaxConsider characters of this string are number 0-based from left to right. If |s| is not a multiply of k, then answer is "NO". Otherwise, let . Then answer is "Yes" if and only if for each i that 0 ≤ i < |s|, si = s(i / len) * len + len - 1 - (i%len) where a%b is the remainder of dividing a by b.

 

Time complexity: .

C++ Code by PrinceOfPersia

Python Code by Haghani

Python Code by Zlobober

548B - Mike and FunConsider this problem: We have a binary sequence s and want to find the maximum number of consecutive 1s in it. How to solve this? Easily:

ans = 0cur = 0for i = 1 to n:     if s[i] == 0          then cur = 0     else          cur = cur + 1     ans = max(ans, cur) 

Finally, answer to this problem is ans. For each row r of the table, let ansr be the maximum number of consecutive 1s in it (we know how to calculate it in O(m) right ?). So after each query, update ansi in O(m) and then find max(ans1, ans2, ..., ansn) in O(n).

Time complexity: 

C++ Code by PrinceOfPersia

C++ Code by Haghani

Python Code by Zlobober

547A - Mike and FrogIn this editorial, consider p = m, a = h1, a′ = a1, b = h2 and b′ = a2, x = x1, y = y1, X = x2 and Y = y2.

First of all, find the number of seconds it takes until height of Xaniar becomes a′ (starting from a) and call it q. Please note that q ≤ p and if we don't reach a′ after p seconds, then answer is  - 1.

If after q seconds also height of Abol will become equal to b′ then answer if q.

Otherwise, find the height of Abdol after q seconds and call it e.

Then find the number of seconds it takes until height of Xaniar becomes a′ (starting from a′) and call it c. Please note that c ≤ p and if we don't reach a′ after p seconds, then answer is  - 1.

if g(x) = Xx + Y, then find f(x) = g(g(...(g(x)))) (c times). It is really easy:

c = 1, d = 0for i = 1 to c     c = (cX) % p     d = (dX + Y) % pThen,

f(x)     return (cx + d) % p 

Actually, if height of Abol is x then, after c seconds it will be f(x).

Then, starting from e, find the minimum number of steps of performing e = f(e) it takes to reach b′ and call it o. Please note that o ≤ p and if we don't reach b′ after p seconds, then answer is  - 1.

Then answer is x + c × o.

Time Complexity: 

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

547B - Mike and FeetFor each i, find the largest j that aj < ai and show it by li (if there is no such j, then li = 0).

Also, find the smallest j that aj < ai and show it by ri (if there is no such j, then ri = n + 1).

This can be done in O(n) with a stack. Pseudo code of the first part (second part is also like that) :

stack s // initially emptyfor i = 1 to n     while s is not empty and a[s.top()] >= a[i]          do s.pop()     if s is empty          then l[i] = 0     otherwise          l[i] = s.top()     s.push(i) 

Consider that you are asked to print n integers, ans1, ans2, ..., ansn. Obviously, ans1 ≥ ans2 ≥ ... ≥ ansn.

For each i, we know that ai can be minimum element in groups of size 1, 2, ..., ri - li - 1.

Se we need a data structure for us to do this:

We have array ans1, ans2, ..., ansn and all its elements are initially equal to 0. Also, n queries. Each query gives x, val and want us to perform ans1 = max(ans1, val), ans2 = max(ans2, val), ..., ansx = max(ansx, val). We want the final array.

This can be done in O(n) with a maximum partial sum (keeping maximum instead of sum), read here for more information about partial sum.

Time complexity: .

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

547C - Mike and FoamWe define that a number x is good if and only if there is no y > 1 that y2 is a divisor of x.

Also, we define function f(x) as follow:

Consider x = p1a1 × p2a2 × ... × pkak where all pis are prime. Then, f(x) = a1 + a2 + ... + an.

Use simple inclusion. Consider all the primes from 1 to 5 × 105 are p1, p2, ..., pk.

So, after each query, if d(x) is the set of beers like i in the shelf that x is a divisor of ai, then number of pairs with gcd equal to 1 is: 

Consider good numbers from 1 to 5 × 105 are b1, b2, ..., bm. The above phrase can be written in some other way: |d(b1)| × ( - 1)f(b1) + |d(b2)| × ( - 1)f(b2) + ... + |d(bm)| × ( - 1)f(bm).

So, for each query if we can find all good numbers that ai is divisible by them in a fast way, we can solve the rest of the problem easily (for each good number x, we can store |d(x)| in an array and just update this array and update the answer).

 

Since all numbers are less than 2 × 3 × 5 × 7 × 11 × 13 × 17, then there are at most 6 primes divisible buy ai. With a simple preprocesses, we can find their maximum and so easily we can find these (at most 6) primes fast. If their amount is x, then there are exactly 2x good numbers that ai is divisible by them (power of each prime should be either 0 or 1).

So we can perform each query in O(26)

Time complexity: .

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

547D - Mike and FishConsider a bipartite graph. In each part (we call them first and second part) there are L = 2 × 105 vertices numbered from 1 to L. For each point (x, y) add an edge between vertex number x from the first part and vertex number y from the second part.

In this problem, we want to color edges with two colors so that the difference between the number of blue edges connected to a vertex and the number of red edges connected to it be at most 1.

Doing such thing is always possible.

We prove this and solve the problem at the same time with induction on the number of edges :

 

If all vertices have even degree, then for each component there is an Eulerian circuit, find it and color the edges alternatively_ with blue and red. Because graph is bipartite, then our circuit is an even walk and so, the difference between the number of blue and red edges connected to a vertex will be 0.

Otherwise, if a vertex like v has odd degree, consider a vertex like u that there is and edge between v and u. Delete this edge and solve the problem for the rest of the edges (with the induction definition) and then add this edge and if the number of red edges connected to u is more than the blue ones, then color this edge with blue, otherwise with red.

You can handle this add/delete edge requests and find odd vertices with a simple set. So,

Time complexity: 

C++ Code by PrinceOfPersia

C++ Code by Haghani

Java Code by Zlobober

547E - Mike and Friendscall(i, j) = match(sjinsi) which match(tins) is the number of occurrences of t in s.

Concatenate all strings together in order (an put null character between them) and call it string S. We know that .

Consider N = 5 × 105. Consider Consider for each i, Sxisxi + 1...syi = si (xi + 1 = yi + 2).

Also, for i - th character of S which is not a null character, consider it belongs to swi.

Calculate the suffix array of S in  and show it by f1, f2, ..., f|S| (we show each suffix by the index of its beginning).

For each query, we want to know the number of occurrences of sk in Sxl...syr. For this propose, we can use this suffix array.

Consider that we show suffix of S starting from index x by S(x).

Also, for each i < |S|, calculate lcp(S(fi), S(fi + 1)) totally in  and show it by lci.

 

For each query, consider fi = xk, also find minimum number a and maximum number b (using binary search and sparse table on sequence lc) such that a ≤ i ≤ b and min(lca, lca + 1, ..., lci - 1) ≥ |sk| and min(lci, lci + 1, ..., lcb - 1) ≥ |sk|.

Finally answer of this query is the number of elements in wa, wa + 1, ..., wb that are in the interval [l, r].

This problem is just like KQUERY. You can read my offline approach for KQUERY here. It uses segment tree, but you can also use Fenwick instead of segment tree.

This wasn't my main approach. My main approach uses aho-corasick and a data structure I invented and named it C-Tree.

Time complexity: 

C++ Code by PrinceOfPersia ()

C++ Code by PrinceOfPersia ()

C++ Code by Haghani (Suffix array construction in  and the rest in )

Java Code by Zlobober

 

If there's any suggestion or error let me know.

Codeforces Round #304 (Div.2) editorial

By Radewoosh, 8 years ago, In EnglishA. Soldier and BananasWe can easily calculate the sum of money that we need to buy all the bananas that we want, let's name it x.

If n >  = x the answer is 0, because we don't need to borrow anything.

Otherwise the answer is x - n.

B. Soldier and BadgesLet's count the number of badges with coolness factor 1, 2 and so on. Then, let's look at the number of badges with value equal to 1. If it's greater than 1, we have to increase a value of every of them except for one. Then, we look at number of badges with value 2, 3 and so on up to 2n - 2 (because maximum value of badge which we can achieve is 2n - 1). It is easy to see that this is the correct solution. We can implement it in O(n), but solutions that work in complexity O(n^2) also passed.

C. Soldier and CardsIt's easy to count who wins and after how many "fights", but it's harder to say, that game won't end. How to do it?

Firstly let's count a number of different states that we can have in the game. Cards can be arranged in any one of n! ways. In every of this combination, we must separate first soldier's cards from the second one's. We can separate it in n + 1 places (because we can count the before and after deck case too).

So war has (n + 1)! states. If we'd do (n + 1)! "fights" and we have not finished the game yes, then we'll be sure that there is a state, that we passed at least twice. That means that we have a cycle, and game won't end.

After checking this game more accurately I can say that the longest path in the state-graph for n = 10 has length 106, so it is enough to do 106 fights, but solutions that did about 40 millions also passed.

Alternative solution is to map states that we already passed. If we know, that we longest time needed to return to state is about 100, then we know that this solution is correct and fast.

D. Soldier and Number GameFirstly we have to note, that second soldier should choose only prime numbers. If he choose a composite number x that is equal to p * q, he can choose first p, then q and get better score. So our task is to find a number of prime factors in factorization of n.

Now we have to note that factorization of number a! / b! is this same as factorization of numbers (b + 1)*(b + 2)*...*(a - 1)*a.

Let's count number of prime factor in factorization of every number from 2 to 5000000.

First, we use Sieve of Eratosthenes to find a prime diviser of each of these numbers. Then we can calculate a number of prime factors in factorization of a using the formula:

primefactors[a] = primefactors[a / primediviser[a]] + 1

When we know all these numbers, we can use a prefix sums, and then answer for sum on interval.

E. Soldier and TravelingThere are few ways to solve this task, but I'll describe the simplest (in my opinion) one.

Let's build a flow network in following way:

Make a source.

Make a first group of vertices consisting of n vertices, each of them for one city.

Connect a source with ith vertex in first group with edge that has capacity ai.

Make a sink and second group of vertices in the same way, but use bi except for ai.

If there is a road between cities i and j or i = j. Make two edges, first should be connecting ith vertex from first group, and jth vertex from second group, and has infinity capacity. Second should be similar, but connect jth from first group and ith from second group.

Then find a maxflow, in any complexity.

If maxflow is equal to sum of ai and is equal to sum of bi, then there exists an answer. How can we get it? We just have to check how many units are we pushing through edge connecting two vertices from different groups.

I told about many solutions, because every solution, which doesn't use greedy strategy, can undo it's previous pushes, and does it in reasonable complexity should pass.

Codeforces Round #303 (Div.2) editorial

By seland, 8 years ago, In English545A - Toy Cars

We can find all information about i-th car collisions in the i-th row of the matrix A. More specific, if there is at least one 1 or 3 at i-th row, then i-th car isn't good (it was turned over in at least one collision). Otherwise, i-th car is good. We just need to check this condition for each car.

545B - Equidistant String

One can see, that if si = ti for some i, then the value of pi isn't important for us. Really, if we make pi equal to si then it also be equal to ti. And if we make pi not equal to si then it also be not equal to ti. So, we have an answer that is closer or further to both of s and t.

So we interested about such position i that si ≠ ti. If we make pi equal to si we make p further from t. If we make pi equal to ti we make p further from s. It means that we need to divide these positions into two equal parts to have equidistant string. For example, we can make first of these positions closer to s, second closer to t and so on. If the number of these positions is even, we find an answer, if it is odd, answer doesn't exist.

Time complexity — O(n).

545C - Woodcutters

One can solve this problem using dynamic programming or greedy algorithm. Start with DP solution.

Define stayi, lefti and righti as maximal count of trees that woodcutters can fell, if only trees with number from 1 to i exist, and i-th tree isn't cutted down, i-th tree is cutted down and fallen left, i-th tree is cutted down and fallen right correspondingly. Now we can compute this values for each i from 1 to n by O(n) time because for each next we need only two previous value. Answer is maximum of stayn, leftn, rightn.

Also this problem can be solved by the next greedy algoritm. Let's fell leftmost tree to the left (it always doesn't make an answer worse). After that, try to fell the next tree. If we can fell it to the left, let's do it (because it also always doesn't make an answer worse). If we can't, then try to fell it to the right. If it is possible, let's do it. Last step is correct because felling some tree to the right may only prevent the next tree's fallen. So we may "exchange" one tree to another without worsing an answer.

Time complexity — O(n).

545D - Queue

We can solve this problem by greedy algorithm. Let's prove that it is always possible find an answer (queue with the maximal number of not disappointed people), where all not disappointed people are at the begin of queue. Assume the contrary — there are two position i and j such that i < j, persons at position from i to j - 1 are disappointed, but j-th person isn't. Then just swap persons at positions i and j. After that all persons from i to j - 1 will be still disappointed (or become not disappointed) and j-th person will be still not disappointed. So the answer isn't maked worse.

So, we need to find person with minimal ti, that can be served now and will be not disappointed. We can do that by sorting all the people by time ti and try to serve them one by one. If somebody will be disappointed, we may send he to the end of queue, and doesn't add his serve time to the waiting time.

Time complexity — O(n + sort).

545E - Paths and Trees

It's true, that Dijkstra modification, where in case of equal distances we take one with shorter last edge, find an answer.

For prove that let's do some transformation with graph. At first, find all shortest paths from u to other vertices. Define di as the length of shortest path from u to i. After that, we can delete some edges. Specifically, we can delete an edge with ends in x and y and weight w if |dx - dy| ≠ w, because it isn't contained in any shortest path, so it isn't contained in shortest path tree. After that, we can direct all edges from vertices with less distance to vertices with greater distance (because of all weight are positive). It's easy to prove, that if we take one edge that entering each vertex, we have a shortest path tree. Then we only need to take for each vertex minimal egde, that entering this vertex. Why? Because we have to take at least one edge, that entering each vertex to make a graph connected. We can't take edges with less weights than minimal. And if we take minimal edges, that entering each vertex we will have an shortest path tree. So that is minimal possible total wieght of shortest path tree.

You can see, that Dijkstra with modification do exactly the same things.

Time complexity — 

Editorial Codeforces Round #302

By gridnevvvit, 8 years ago, translation, In English544A - Set of StringsIn that task you need to implement what was written in the statements. Let's iterate over all characters of string and keep array used. Also let's keep current string. If current character was not used previously, then let's put current string to the answer and after that we need to clear current string. Otherwise, let's append current character to the current string. If array, that contain answer will have more then k elements, we will concatenate few last strings.

The jury solution: 11035685

544B - Sea and IslandsIt's clear to understand, that optimal answer will consists of simple cells, for which following condition fullfills: the sum of indices of row and column is even. We will try to put k islands in such way, and if it's impossible, we will report that answer is NO. Try to prove that this solution is optimal.

The jury solution: 11035691

543A - Writing CodeLet's create the solution, which will work too slow, but after that we will improve it. Let's calculate the following dynamic programming z[i][j][k] — answer to the problem, if we already used exactly i programmers, writed exactly j lines of code, and there are exactly k bugs. How we can do transitions in such dp? We can suppose that we i-th programmer will write r lines of code, then we should add to z[i][j][k] value z[i - 1][j - r][k - ra[i]]

But let's look at transitions from the other side. It's clear, that there are exactly 2 cases. The first case, we will give any task for i-th programmer. So, we should add to z[i][j][k] value z[i - 1][j][k]. The second case, is to give at least one task to i-th programmer. So, this value will be included in that state: z[i][j - 1][k - a[i]]. In that solution we use same idea, which is used to calculate binomial coefficients using Pascal's triangle. So overall solution will have complexity: O(n3)

The jury solution: 11035704

543B - Destroying RoadsLet's solve easiest task. We have only one pair of vertices, and we need to calculate smallest amout of edges, such that there is a path from first of vertex to the second. It's clear, that the answer for that problem equals to shortest distance from first vertex to the second.

Let's come back to initial task. Let's d[i][j] — shortest distance between i and j. You can calculate such matrix using bfs from each vertex.

Now we need to handle two cases:

Paths doesn't intersects. In such way we can update the answer with the following value: m - d[s0][t0] - d[s1][t1] (just in case wheh conditions on the paths lengths fullfills).Otherwise paths are intersecting, and the correct answer looks like a letter 'H'. More formally, at the start two paths will consists wiht different edges, after that paths will consists with same edges, and will finish with different edges. Let's iterate over pairs (i, j) — the start and the finish vertices of the same part of paths. Then we can update answer with the following value: m - d[s0][i] - d[i][j] - d[j][t0] - d[s1][i] - d[j][t1] (just in case wheh conditions on the paths lengths fullfills).Please note, that we need to swap vertices s0 and t0, and recheck the second case, because in some situations it's better to connect vertex t0 with vertex i and s0 with vertex j. Solutions, which didn't handle that case failed system test on testcase 11.

The jury solution: 11035716

543C - Remembering StringsFirst that we need to notice, that is amout of strings is smaller then alphabet size. It means, that we can always change some character to another, because at least one character is not used by some string.

After that we need handle two cases:

We can change exactly one character to another. The cost of such operation equals to a[i][j] (which depends on chosed column) After that we can remember string very easy.We can choose some column, and choose some set of strings, that have same character in that column, By one move we can make all these strings are easy to remember.The cost of such move equals to cost of all characters, except most expensive.As the result, we will have following solution: d[mask] — answer to the problem, when we make all strings from set mask easy to remember. We can calculate this dp in following way: let lowbit — smallest element of set mask. It's clear, that we can do this string easy to remember using first or second move. So we need just iterate over possible columns, and try first or second move (in second move we should choose set that contain string lowbit) Overall complexity is O(m2n), where m — is length of strings.

The jury solution: 11035719

543D - Road ImprovementLet's suppose i is a root of tree. Let's calculate extra dynamic programming d[i] — answer to the problem for sub-tree with root i We can understand, that d[i] equals to the following value:  — where j is a child of the vertex i. It's nice. After that answer to problem for first vertex equal to d[1].

After that let's study how to make child j of current root i as new root of tree. We need to recalculate only two values d[i] and d[j]. First value we can recalculate using following formula d[i]: suf[i][j] * pref[i][j] * d[parent], where parent — is the parent of vertex i, (for vertex 1 d[parent] = 1), and array suf[i][j] — is the product of values d[k], for all childs of vertex i and k < j (pref[i][j] have same definition, but k > j). And after we can calculate d[j] as d[j] * (d[i] + 1). That is all, j is root now, and answer to vertex j equals to current value d[j]

The jury solution: 11035737

543E - Listening to MusicLet's sort all songs in decreasing order. We will iterate over songs, and each time we will say, that now current song will fully satisfy our conditions. So, let's si = 0, is song i was not processed yet and si = 1 otherwise. Let . It's clear, when we add new song in position idx then we should do  + 1 for all on segment [max(0, idx - m + 1), idx] in our array v. So, when we need to implement some data structure, which can restore our array v to the position when all strings have quality  ≥ q. It also should use very small amout of memory. So, answer to the query will be m - max(vi), lj ≤ i ≤ rj.

We will store this data structure in the following way. Let's beat all positions of songs in blocks of length . Each time, when we added about  songs as good, we will store three arrays: first array will contain value vi of first element of the block of indices. second array will contain maximum value of v on each block and also we will keep about  of ''small'' updates which doesn't cover full block. Using this information array v will be restored and we process current query in easy way.

The jury solution: 11035739

Разбор задач Codeforces Round #301 (Div. 2)

By dalex, 8 years ago, translation, In English540A - Combination Lock

For every symbol we should determine how to rotate the disk. This can be done either by formula: min(abs(a[i] - b[i]), 10 - abs(a[i] - b[i])) or even by the two for cycles: in both directions.

540B - School Marks

First count the number of marks that are less than y. If there are more than  such marks, we can't satisfy the second condition (about the median), and the answer is -1. Otherwise we can get exactly such number of y marks so that the total number of marks greater than or equal to y is at least  (maybe it's already satisfied). This is the required action for satisfying the second condition.

Now, in order not to break the first condition, get the remaining marks as lower as possible — all ones — and check the sum of the marks. If it is greater than x, the answer is -1, otherwise the correct answer is found.

540C - Ice Cave

There are three cases here, though some of them can be merged.

If the start and finish cells are equal, let's count the intact neighbours of this cell. If there is one, move there and instantly move back — the answer is YES. Otherwise it's NO.If the start and finish cells are neighbours, the solution depends on the type of the destination cell. If it's cracked, the answer is YES — we can just move there and fall down. Otherwise it must have at least one intact neighbour to get the positive answer — we can move to the finish cell, then to this intact neighbour, and then return to the finish cell.In the general case, check if the path from the start cell to the finish cell exists. If it doesn't, the answer is NO. Otherwise check the type of the destination cell. If it's cracked, it must have at least one intact neighbour, and if it's intact, it must have two intact neighbours.540D - Bad Luck Island (my code: http://pastebin.com/3s6dRK3A)

Let's count the values dp[r][s][p] — the probability of the situation when r rocks, s scissors and p papers are alive. The initial probability is 1, and in order to calculate the others we should perform the transitions.

Imagine we have r rocks, s scissors and p papers. Let's find the probability of the rock killing scissors (the other probabilities are calculated in the same way). The total number of the possible pairs where one species kills the other one is rs + rp + sp, and the number of possible pairs (rock, scissors) is rs. As all meetings are equiprobable, the probability we want to find is . This is the probability with which we go the the state dp[r][s — 1][p], with the number of scissors less by one.

In the end, for example, to get the probability of the event that the rocks are alive, we should sum all values dp[i][0][0] for i from 1 to r (the same goes to the other species).

540E - Infinite Inversions (my code: http://pastebin.com/QFEMRbNP)

At first find the position of each element which is used in swap (using map). Now let's find the answer. It consists of the two parts. First part is the number of inversions formed by only whose elements which took part in the swaps. They can be counted by one of the standard ways: mergesort or Fenwick tree. The second part is the number of inversions formed by pairs of elements where one element has been swapped even once, and the other element stayed at his position. Let's consider the following test:

22 64 8The global sequence will look as follows: [1 6 3 8 5 2 7 4 9 ...], and here is the array of swapped elements: [6 8 2 4].

Let's understand with which numbers the number 8 forms the inversions. The only elements that could do that are the elements between the initial position of the number 8 (where the number 4 is now) and its current position: [5 2 7]. There are two numbers on this segment which didn't take part in swaps: 5 and 7. The number 2 should not be counted as it took part in the swaps and we have already counted it in the first part of the solution.

So we should take the count of numbers between 8's indices in the global sequence (8 - 4 - 1 = 3) and subtract the count of numbers between its indices in the swaps array (4 - 2 - 1 = 1). We'll get the number of inversions formed by the element 8 and the elements which haven't moved at all, it's 2. Counting this value for all elements which have been swapped at least once, we get the second part of the answer. All operations in the second part of the solution can be performed using sorts and binary searches.




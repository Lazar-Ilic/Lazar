Codeforces Global Round 24 Editorial

By Imakf, history, 3 months ago, In English1764A - Doremy's Paint

idea: Cocoly1990

Solution1764A - Doremy's PaintAssume that you have picked a interval [L,R] as your answer. Now try to move the left point to make the answer larger.

Compare [L,R] with [L−1,R].

Δ(r−l)=1 because the length of the interval increases by 1.

Δc(l,r) increases at most 1. If aL appears in [L,R], c(L,R)=c(L−1,R); If aL does not appear in [L,R], c(L,R)+1=c(L−1,R).

So [L−1,R] is always better than [L,R].

Furthermore, we can see that if a≤b≤c≤d, then [a,d] is better than [b,c].

Since [1,n] includes all intervals, it is always better than any other interval. So just output 1 and n.

Code1764B - Doremy's Perfect Math Class

idea: waaitg

Solution1764B - Doremy's Perfect Math ClassFor any two natural numbers x,y , assign |x−y| to the bigger number. Repeat this process until the smaller number becomes 0, and then the bigger number will become gcd(x,y).

So we can know that if x,y∈S, then it is guaranteed that gcd(x,y)∈S. So gcd(a1,a2,…,an)∈S.

Let t=gcd(a1,a2,…,an),A=max(a1,a2,…,an)=Kt, then t,A∈S. So t,2t,…,Kt∈S.

Because |x−y|≤max(x,y), any number bigger than A will not be in S. Because |xt−yt|=|x−y|t, any number which is not divisible by t will not be in S. And 0∉S. So t,2t,…,Kt are all the numbers that can be in S.

Code1764C - Doremy's City Construction

idea: waaitg

Solution1764C - Doremy's City ConstructionWe can first assume that no edge links two vertices with the same value, then for each vertex u and his neighbors Su, either au>maxv∈Suav or au<minv∈Suav. If au>maxv∈Suav, we paint u black, otherwise we paint it white. Then it's obviously that any edge connects two vertices with different color.

So we can first determine the color of each vertex and then add as many as edges according to the color. (u,v) is addable only when u is black, v is white and au>av. If we paint u black and v white and au<av, we can swap the colors and the edges connecting to these 2 vertices and the answer will be no worse. So the best painting plan is determining a value A, painting u black if and only if au≥A, painting u white if and only if au<A.

If we add an edge linking two vertices with the same value, then the two vertices can not connect other vertices. This plan will only be considered when a1=a2=⋯=an. When a1=a2=⋯=an, the answer is ⌊n2⌋.

Code1764D - Doremy's Pegging Game

idea: Imakf

Solution1764D - Doremy's Pegging GameThe game will end immediately when the blue peg is not inside the convex formed by all remaining red pegs. Namely, there are ⌊n2⌋ consecutive red pegs removed. It can be proven by geometry.

Assume t=⌊n2⌋, and n is odd.

Let's enumerate the ending status: there are i (t≤i≤n−2) consecutive red pegs removed and another j (0≤j≤n−2−i) red pegs removed.

The last move makes the rubber band to stretch and touch the blue peg. So there is 2t−i ways to choose the last move. There are (n−2−ij) ways to choose another j pegs. And there are (i+j−1j)j!(i−1)! ways to combine them.

When n is even, the analysis is similar. The only difference is that there is a special case when i=n−1.

So the answer is:+n∑i=tn−2∑j=0n−i−2(n−i−2j)(i+j−1)!⋅(2t−i)[n is even]n(n−2)!which can be easily calculated in O(n2).

Code1764E - Doremy's Number Line

idea: Imakf

Solution1764E - Doremy's Number LineFirst if k can be colored with certain color, then any K<k can also be colored the this color. So we only need to calculate what is the biggest number color 1 can be. Apparently this value will not exceed x1+y1.

If x1 is not maximum among all x, you can pick any j such that xj≥x1. Color point x1 with color j, then color point x1+y1 with color 1. So x1+y1 is the answer in this case.

If x1 is maximum, just enumerate which color precedes color 1.

No color precedes. Directly color x1 with color 1.Color j precedes, but xj is not maximum among x2,x3,⋯,xn. In this case, point xj+yj can always be colored with color j. Point min{xj+yj,x1}+y1 can be colored with color 1.Color j precedes, meanwhile xj is maximum among x2,x3,⋯,xn. In this case, we can just enumerate which color precedes color j, which leads to a recursion, until there is only one color remaining.Time complexity is O(nlogn) due to sorting.

Code1764F - Doremy's Experimental Tree

idea: Cocoly1990

Solution1764F - Doremy's Experimental TreeIf path (x,y)⊂(X,Y), then f(x,y)>f(X,Y).

Then we build a graph based on f(i,j), the weight of the edge between i,j is f(i,j). It can be shown that the MST of the graph have the same structure as the original tree.

Then we need to compute the weight for each edge. The weight of the edge between x and y is f(x,x)−f(x,y)sizey, where x is y's parent on the tree, sizey is the size of subtree y.

Code1764G3 - Doremy's Perfect DS Class (Hard Version)

idea: waaitg

Solution1764G3 - Doremy's Perfect DS Class (Hard Version)If we add an edge between numbers a,b when ⌊a2⌋=⌊b2⌋, then when n is an odd number, 1 is the only one which has no neighbor, so let's consider the odd case at first.

Let the number of edges (u,v) satisfying u,v∈[l,r] be C(l,r), then C(l,r)+Q(l,r,2)=r−l+1. That is to say, we can get any C(l,r) with a query.

Try to use binary search to solve this problem. The key problem is for a certain m, determining whether 1 is in [1,m] or [m+1,n]. Let 2C(1,m)+x=m,2C(m+1,n)+y=n−m. The edges between [1,m] and [m+1,n] must connect the remaining x numbers in [1,m] and the remaining y numbers in [m+1,n]. There is exactly one number with no neighbor, so if x=y+1, 1 is in [1,m], otherwise y=x+1 and 1 is in [m+1,n]. So we can do this case in 20 queries.

If n is an even number, then 1,n will be the only two number which has no neighbor. With the similar analysis as above, we can know if x>y, 1,n are in [1,m], if y>x, 1,n are in [m+1,n], otherwise 1,n are in the different sides. When l<r, we can use Q(l,r,n) to check whether n is in [l,r]. Because n≥3, we can use this method to determine 1 is in which side. So we can do this case in 30 queries.

Finding that we only need one extra query Q(l,r,n), we can do the even case in 21 queries.

When we decrease the range of 1 to [l,r], we have already got C(1,l−1),C(1,r),C(l,n),C(r+1,n). When l+1=r, if C(1,l−1)+1=C(1,r), we only need to know C(1,l) to get the answer, if C(l,n)=C(r+1,n)+1, we only need to know C(r,n) to get the answer, otherwise it means that pl=1,pr=n or pl=n,pr=1, this case we also only need one more query. So we decrease the number of queries by 1, solving this case in 20 queries.

G1 CodeG3 Code1764H - Doremy's Paint 2

idea: Imakf, waaitg and errorgorn

Solution1764H - Doremy's Paint 2The main idea of the solution is that we can try to the answers for position x,x+1,…,x+k all at once. We do this by representing the interval [x+i,x+k+i) as [x+i,x+k)∪[x+k,x+k+i) and perform sweep line on both halves of interval.

Firstly, after applying some operations on the array a, we will have ai≤ai+1. That is, we can instead count the number of indices such that ai≠ai+1 for one less than the number of distinct elements. From here on, we will be counting the number of elements that ai≠ai+1 instead.

Let us consider that the state of the array is a after applying operations [s+1,e]. Consider the effect of applying operations [s,e] instead. The change this operation will make is that we replace all i such that ai∈[ls,rs] with ai=ls. We can think about it as only counting ai≆ai+1 where we can view the above operation of replacing ai∈[ls,rs] with ls as instead merging [ls,rs] values as a single equivalence class which we label ls.

So for interval [x+i,x+k+i)=[x+i,x+k)∪[x+k,x+k+i) we will get the equivalence class for values when considering ranges [lj,rj] with j∈[x+i,x+k−1]. This is a natural line sweep when considering going from [s,x+k−1] to [s−1,x+k−1] that uses O(nlogn) by amortized analysis.

We can find the state of the array when applying operations [x+k,x+k],[x+k,x+k+1],…,[x+k,x+2k−1] in O(nlogn) time by amoritzed analysis by only storing contiguous values as a set. By storing the changes we made when we go from [x+k,e] to [x+k,e+1], we are able to "undo" the changes to go from [x+k,e+1] to [x+k,e].

Now, we want to go from applying operations in [x+i+1,x+k+i+1)=[x+i+1,x+k)∪[x+k,x+k+i+1) to [x+i,x+k+i)=[x+i,x+k)∪[x+k,x+k+i), first we go from [x+k,x+k+i+1) to [x+k,x+k+i) by undoing the operation (and checking how many adjacent values are ≆), then we update our equivalence classes to go from [x+i+1,x+k) to [x+i,x+k).

However, The problem is that this algorithm runs in O(mknlogn) time. However, we note that we can discretize the range [1,n] using the ranges [lj,rj] with j∈[x,x+2k), so that our amortization works in O(klogk), to obtain a complexity of O(mkklogk)=O(mlogk) (with a super huge constant). Note that since the element of the array a are integers but are instead ranges now, there are some implementation details that are left as an exercise to the reader.

Code

Codeforces Global Round 23 Editorial

By MohammadParsaElahimanesh, 5 months ago, In EnglishHi Codeforces,

I've tried my best to make a different editorial, I wish you enjoy it ...

1746A - Maxmina

problem author: MohammadParsaElahimanesh, AmirrzwM

step by step solutionstep 1:

It's obvious that the answer is "NO" if ai=0 for all 1≤i≤n.

step 2:

Lets prove that the answer is "YES" if ai=1 for at least one 1≤i≤n.

step 3:

If size of a is equal to k, just use second type operation once and we are done.

step 4:

Otherwise (if |a|>k), there will be three cases: (assume that aj=1)

if j>2, you can use first type operation on first and second element and decrease size of a by 1.else if j<|a|−1, you can use first type operation on last and second to last element and decrease size of a by 1.else, it can be shown easily that |a|=3 and k=2 so you can use second type operation twice and turn a into a single 1.In first and second case, you can continue decreasing size of a until |a|=k (or you reach 3-rd case) and you can use second type operation to reach your aim.

step 5:

So we proved that the answer is "YES" iff ai=1 for at least one 1≤i≤n or in other words, iff ∑ni=1ai>0.

solution1746B - Rebellion

problem author: MohammadParsaElahimanesh

step by step solutionstep 1:

taskAssume that ai=0 for each 1≤i≤n, what should we do?

solutionNothing! The array is already sorted and the answer is 0.

step 2:

taskAfter sorting the array, consider the first non-zero element of a, how many elements after that are equal to zero? In other words, consider smallest i such that ai>0, how many indices k exist such that i<k and ak=0?

solution0, because we call an array a sorted (in non-decreasing order), if for all 1≤i<j≤n, ai≤aj holds. So all numbers after leftmost non-zero element must be non-zero too.

step 3:

taskassume that after sorting a, ai (1≤i≤n) is the leftmost non-zero element. Define G1 as the set of indices j such that 1≤j<i and aj>0 at the beginning, also define G2 as the set of indices j such that i≤j≤n and aj=0 at the beginning. What is the answer?

solutionmax(|G1|,|G2|). It's obvious that in one operation at most one element will be deleted from each group. So we must perform at least max(|G1|,|G2|) operations. Now we want to show that it's sufficient too. There are three cases:

min(|G1|,|G2|)>1, at this point, we know that all elements of a are 0 or 1. So we can pick one element from G1 and add it to an element from G2, so the size of both groups will decrease by 1. It's obvious that all elements of a will remain less than or equal to 1 after this operation.

|G1|=0, it's easy to see that we can add a[k] (k∈G2) to a random element. So |G2| will decrease by 1.

|G2|=0, it's easy to see that we can add a[k] (k∈G1) to the last element of a. So |G1| will decrease by 1.

step 4:

taskNow how can we solve the problem using previous steps?

solutionIf all elements are equal to 0, the answer is obviously zero. Otherwise we will calculate two arrays, number of ones in each prefix and number of zeros in each suffix. We will also fix the leftmost non-zero element and calculate the answer for it easily by using Step 3 algorithm in O(n).

solution1746C - Permutation Operations

problem author: napstablook

step by step solutionstep 1:

taskTry to prove that the answer is always zero. Or in other words, we can always make the array a non-decreasing.

solutionWe will prove this fact in next stpes.

step 2:

taskIf some array a is non-decreasing, what can we say about array d=[a2−a1,a3−a2,...an−an−1]?

solutionIt's obvious that all elements of array d should be non-negative.

step 3:

taskIf we perform the i-th operation on the suffix starting at index j, what happens to array d?

solutionAll elements of it will remain the same except dj−1=aj−aj−1 which will increase by i.

step 4:

taskConsidering the fact that array a consists only of positive integers, what can we say about di=ai+1−ai?

solutionSince ai+1≥0, we can say that di≥−ai.

step 5:

taskUsing step 3 and 4 and knowing that a is a permutation of numbers 1 to n, what can we do to make all elements of d non-negative?

solutionfor i≤n−1, we can perform ai-th operation on the suffix starting from index i+1. So di will increase by ai and since we knew that di≥−ai, after performing this operation di≥0 will hold. So after this steps, elements of d will be non-negative and according to Step 2, that's exactly what we want. It's also easy to see that it doesn't matter how we perform an-th operation, so we can do anything we want.

solution1746D - Paths on the Tree

problem author: AquaMoon, Cirno_9baka, mejiamejia, ChthollyNotaSeniorious, SSerxhs, TomiokapEace

single step solutionDefine f(u,cnt) represents the maximum score of cnt balls passing through the subtree of node u.

Define num as the number of the sons of node u. The transition is only related to ⌈cnt/num⌉ and ⌊cnt/num⌋ two states of the subtree.

For each node u, cnt can only be two adjacent integer (x,x+1).

It can be proved that the four numbers ⌊x/num⌋, ⌈x/num⌉, ⌈(x+1)/num⌉ and ⌊(x+1)/num⌋ can only have two kinds of numbers at most, and they are adjacent natural numbers.

So the number of states can be proved to be O(n).

solution1746E1 - Joking (Easy Version)

problem author: MohammadParsaElahimanesh

step by step solutionstep 1:

taskHow can we make sure that some statement is not joking?

solutionIf something is told for two times in a row, we can be sure that it's true. For example if we are told that x≠3 in two consecutive questions, we can be sure that it's true. Because at least one of those questions is answered correctly and that's enough.

step 2:

taskWhat can be found out if we ask about a set S? (assume that we will be answered correctly)

solutionIf the answer is "YES", then x∈S and we can reduce our search domain to S. Otherwise, we can remove S from the search domain.

step 3:

taskUsing previous steps, how can we really reduce our search domain? Step 2 can do it only if we have a correct statement about x and using Step 1, we can find something that is surely correct.

solutionAssume that V is our current search domain. Split it into 4 subsets V1,V2,V3 and V4. then ask about following sets:

V1∪V2V1∪V3It's easy to show that no matter what the answers are, we can always remove at least one of the subsets from the search domain. For example if both answers are "YES", we can remove V4 and if both answers are "NO", then we can remove V1.

So after these questions, we can reduce size of search domain by at least min(|V1|,|V2|,|V3|,|V4|), and it's obvious to see that we can choose Vi's in such a way that this value is at least |V|4.

Finally, as long as size of the search domain is greater than 3, we can reduce it using this algorithm. It can be shown easily that we can reduce our search domain to only 3 numbers with at most 76 questions.

step 4:

taskNow assume that we have only 3 candidates for x, since we have only 2 chances to guess, we must remove one of them. How can we do it? Note that since we've used 76 questions in previous step, we only have 6 questions left.

solutionAssume that our three candidates are a,b and c. it can be shown that using following questions, we can always remove at least one of them from the search domain:

abbaAfter that, when we have only two candidates for x, we can guess them one by one and we are done.

solution1746E2 - Joking (Hard Version)

problem author: MohammadParsaElahimanesh, AmirrzwM

step by step solutionstep 1:

First note that in any question we ask, a set will be introduced as the set that contains x. If the answer is "YES", then the set that we asked is introduced and otherwise, its complement.

taskAssume that our current search domain is some set V. In addition, assume that V=A∪B such that set A is the set that introduced to contain x in very last step and B is the set of other candidates for x (candidates that don't belong to A). Now assume that in next question, a set C is introduced to contain x such that C=a∪b,(a∈A,b∈B). what can we do? how can we reduce our search domain after this question?

solutionConsidering the solution of E1, it's not so hard to see that we can remove B−b from our search domain. So our new search domain will be V′=A′∪B′ such that A′=C=a∪b is the set of candidates that introduced in last question and B′=A−a is the set of other candidates.

step 2:

taskLet's calculate minimum needed questions for a search domain of size n using the idea of previous step.

solutionWe can do it using a simple dp, let dp[A][B] be the minimum number of questions needed to find x in a search domain of size A+B in which A numbers are introduced in last question and B numbers are not. In order to calculate our dp, if we ask about some set which consists of a numbers from first set and b numbers from second set, we should update dp[A][B] from dp[A−a][a+b]. So we can say that:

dp[A][B]=mina≤A,b≤Bdp[A−a][a+b]. Using this dp and keeping track of its updates, we can simply solve the task. But there is a problem, we don't have enough time to calculate the whole dp. So what can we do?

step 3:

taskSince calculating dp[A][B] for A<=n,B<=m is O(n2⋅m2), we can only calculate it for small n and m like n,m≤100. What can we do for the rest? Maybe some heuristic method?

solutionIt's not so hard to see that for most A and B (especially for large values) it's best to update dp[A][B] from something around dp[A−A/2][A/2+B/2] (in other words, asking A/2 numbers from the first set and B/2 numbers from the second one). Using such method, we can calculate dp in a reasonable time and with a very good accuracy, and this accuracy is enough to find the answer in less than 53 questions.

solution1746F - Kazaee

problem author: MohammadParsaElahimanesh

step by step solutionstep 1:

First of all, we can compress ai's and x's (in second type query). so we can assume that all numbers are less than n+q≤6⋅105.

step 2:

taskLets first solve the problem for smaller constrains.

solutionWe can use data structures like fenwick tree or segment tree to count the number of occurrences of each number and check if it's divisible by k to answer second type query. And we can simply update our data structure after each query of the first type.

So if we use something like fenwick tree, we can handle everything in O((n+q)⋅n+(n+q)⋅q⋅log2(n)).

step 3:

taskObviously we can not use previous step solution for original constrains. In other words, we don't have enough time to check all numbers one by one. How can we do better? Checking them together?!

solutionIt's obviously not a good idea to check all numbers together (checking that sum of their occurrences is divisible by k). So what can we do? What if we check a random subset of numbers?

step 4:

taskAssume that S is a random subset of all numbers, it's obvious that if the answer of the query is "YES" (number of occurrences of every number is divisible by k), the condition holds for S too (sum of number of occurrences of numbers that belong to S is divisible by k). What about the opposite? What is the probability that the answer of the query is "NO" and yet sum of occurrences of numbers belonging to S is divisible by k?

solutionIt's not so hard to prove that the probability is equal to 12 for k=2 and it's less than 12 for k≥2. So in general, the probability that a random subset S leads to a wrong answer is less than or equal to 12. So if we use something like 30 random subsets, the probability will be less than 1230 which is reasonable for problem constrains and we can use this random method to solve the task.

solution1746G - Olympiad Training

problem idea: SirShokoladina

problem development: SomethingNew, pakhomovee, SirShokoladina

single step solutionConsider all subsets of the original set in which tasks can be performed in some order to satisfy the constraints on their completion, and also that the size of each of them does not exceed a+b+c. It is easy to show that this set is a weighted matroid. This means that the optimal set of tasks can be found using a greedy algorithm.

So, we can find a set of tasks with maximum total usefulness, which:

satisfies all deadline constraintshas no more than a+b+c elementsFor the given parameters (x,y,z), we introduce the following transformation:

Increase the usefulness of all tasks of the first type by x, the second type~--- by y, and the third type~--- by z.Let's assume that the optimal solution after the transformation is described by the triple [a′,b′,c′]~--- the number of problems of each type, respectively. We need to get a solution described by the triple [a,b,c]. For [a,b,c]≠[a′,b′,c′], a+b+c=a′+b′+c′ holds. Then (without limitation of generality, since there are at least two inequalities among a∨a′,b∨b′,c∨c′) we assume that a′>a,b′<b.

Consider the following coordinate system on a two-dimensional plane (modulo the addition of (1;1;1)−→−−−−):

 

For the coordinates of the point, we take the value x⃗ ×x+y⃗ ×y+z⃗ ×z(x⃗ +y⃗ +z⃗ =0⃗ ). It is easy to understand that the coordinates of the point (x;y) on the plane are uniquely set by the triple (x;y;z) up to the addition of (1;1;1)−→−−−−×k,k∈ZLet's assume that there are parameters (x,y,z) for which the optimal solution is unique and equal to [a,b,c] (see "But what if..?" to see what needs to be done to the input to make this hold).

Consider the solution [a′,b′,c′] for the "center" of the current polygon (initially it is a hexagon with infinitely distant coordinates). The "center" is the center of the triangle formed by the middle lines of our polygon.

On this plane, decreasing z or y does not increase b′+c′, therefore, it does not decrease a′. Thus, the red area in the picture below does not suit us.

Increasing x or z does not decrease a′+c′, therefore, it does not increase b′. Because of this, the blue area in the picture below does not suit us either.

 

So, we need to cut off one half-plane along the z axis. It can be shown that the area of the polygon under consideration decreases by a constant time for every 2-3 iterations.

But what if the number of tasks of the desired color jumps from a−1 to a+1 at once? This is possible if and only if with the addition of some x we get several pairs of elements of equal weight at the same time. To get rid of this, we can simply add a random number from 0 to 13 to each weight. The fact that such a change will fix the problem described above and will not change the optimal answer to the original problem remains to the reader as an exercise (the authors have proof).

After O(logC) iterations, our algorithm will converge to a point (a triple of real numbers). It remains only to check that the solution found is suitable for us.

O(nlognlogC)solution

Editorial of Codeforces Global Round 22

By liouzhou_101, history, 5 months ago, In English1738A - Glory Addicts

Author: Milesian

Tutorial1738A - Glory AddictsSuppose the first skill to be performed is fixed. Then it is optimal to use the following greedy strategy.

If possible, perform a skill of a different type from the last skill. If there are multiple skills of a different type from the last skill, choose the one with the largest initial damage.Inspired by the above observation, if the type of the first skill is fixed, it is optimal to choose the one with the smallest initial damage. This is because the first skill will be never doubled.

Therefore, we have the following algorithm.

Try each possible type a (of the first skill).Remove the skill of type a with the smallest intial damage.Alternate the types of the following skills as much as possible.This algorithm is sufficient to pass this problem. Nevertheless, a slightly more elegant analysis will give a simpler solution.

If the number of skills of type fire is equal to that of skills of type frost, double the damage of all skills except for the one with the smallest initial damage.Otherwise, let k be the smaller number of skills of either type, then double the damage of the largest k skills of both types.The time complexity is O(nlogn) due to sortings.

Solution1738B - Prefix Sum Addicts

Author: liouzhou_101

Tutorial1738B - Prefix Sum AddictsIf k=1, it is always possible, so the answer is "YES".

In the following, we assume that k≥2. Here, we are given sn−k+1,…,sn. We can resume an−k+2,…,an by letting ai=si−si−1 for every n−k+2≤i≤n.

If the known elements of ai cannot form a sorted array, i.e., it does not hold that an−k+2≤⋯≤an, the answer is "NO".

Note that the sum of the first n−k+1 elements of ai should satisfy that sn−k+1=a1+⋯+an−k+1≤(n−k+1)an−k+2. If this does not hold, the answer is "NO".

Having checked that both an−k+2≤⋯≤an and sn−k+1≤(n−k+1)an−k+2 hold, we claim that the answer is "YES". A possible solution could beai=⎧⎩⎨⎪⎪⎪⎪⎪⎪⌊sn−k+1n−k+1⌋,⌈sn−k+1n−k+1⌉,1≤i≤sn−k+1mod(n−k+1),sn−k+1mod(n−k+1)<i≤n−k+1.Solution1738C - Even Number Addicts

Author: liouzhou_101

Tutorial1738C - Even Number AddictsWe only need to consider the case that ai= 0 or 1.

Suppose there are a 0's and b 1's in total. Consider the following cases:

b≡2(mod4). Bob has a winning strategy: Always choose the number that Alice chooses in her last move. This strategy keeps the invariant that Alice and Bob have the same number of 1's after Bob's each move. The only exception that Bob cannot go on with this strategy is that Alice takes the last 0. In this case, there must be an even number of 1's (and no 0's) remaining. Therefore, each of Alice and Bob will choose half of the remaining 1's. At last, Alice and Bob have the same number b/2 of 1's, which is odd.b≡3(mod4). Alice has a winning strategy: Choose 1 first. After this move, the game is reduced to a 0's and b−1 1's with Bob taking the first turn and Bob wins if he has an even number of 1's at last. This reduced game is indeed the case of b≡2(mod4) which we have already proved that Bob always loses.b≡0(mod4). Alice has a winning strategy: Choose 0 first; after that, choose the number that Bob chooses in his last move. This strategy keeps the invariant that Alice and Bob have the same number of 1's after Alice's each move. The only exception that Alice cannot go on with this strategy is that there is no 0. In this case, there must be an even number of 1's (and no 0's) remaining. Therefore, each of Alice and Bob will choose half of the remaining 1's. At last, Alice and Bob have the same number b/2 of 1's, which is even.b≡1(mod4). If any of Alice and Bob chooses the first 1, the game is reduced to a 0's and b−1 1's with its opponent moving first, resulting in the case of b≡0(mod4) and its opponent wins. Therefore, the one who chooses the first 1 loses. With this observation, Alice will lose if there are an even number of 0's, i.e., a≡0(mod2); and Alice will win if a≡1(mod2).Solution1738D - Permutation Addicts

Author: Milesian

Tutorial1738D - Permutation AddictsFor readability and convenience of the readers who are interested in the checker of this problem, we consider this problem without assuming the existence of the threshold k and permutation a1,a2,…,an.

Let's first determine the value of k. A valid sequence b must satisfy that

For every i≤k, we have bi>i;For every i>k, we have bi<i.With this, we find the largest index i0 such that bi0>i0, and then set k=i0. We can check whether the sequence b satisfies thatFor every i≤k, we have bi>k;For every i>k, we have bi≤k.If not, report no solution.Now k is fixed. We are going to find a sequence a that produces sequence b with respect to k. We construct a directed graph G with n+2 vertices numbered from 0 to n+1 as follows.

For every 1≤i≤n, add an edge from vertex bi to vertex i.It is clear that there are n edges in graph G. We consider two parts of the graph G, set A of vertices from 0 to k and set B of vertices from k+1 to n+1. Then every directed edge is either from A to B or from B to A.

Claim B.1. There is exactly one vertex between vertex 0 and vertex n+1 that is isolated (that is, no edges are incident to it).

Proof: First of all, we show that it cannot be the case that both vertex 0 and vertex n+1 are isolated. This is because ba1 is either 0 or n+1 according to its definition.

Now suppose both vertex 0 and vertex n+1 are not isolated. Then there are two different indexes x and y such that bx=0 and by=n+1 with 1≤y≤k<x≤n. Find two different indexes i and j such that ai=x and aj=y.

If i<j, then we have ai=x>k≥aj=y. By the definition of by, ai=x is a candidate. So by≠n+1.If i>j, then we have aj=y≤k<ai=x. By the definition of bx, aj=y is a candidate. So bx≠0.Therefore, there is exactly one isolated vertex between vertex 0 and vertex n+1. □By Claim B.1, we can just ignore the isolated vertex. After that, there are n+1 vertices and n edges. It seems like that the graph G is a tree! Next, we will show that this is true.

Claim B.2. The graph G must not contain loops. That is, G is a DAG (directed acyclic graph).

Proof: There is no edge leading to vertex 0 or n+1. So loops will only occur among vertices from 1 to n.

Every edge (u,v) in graph G for 1≤u,v≤n means that, in sequence a, the value of u is in front of the value of v. Since sequence a is a permutation, all values appear exactly once. A loop implies that there are two different vertices u and v such that u is in front of v and v is in front of u. This is of course imposssible. □According to the construction of graph G, there is at most one edge leading to each vertex. So DAG G is a rooted tree with vertex 0 or n+1, with every edge (u,v) meaning that u is the parent of v.

Now we have a tree G, and want to find a suitable sequence a.

Claim B.3. For every vertex u in tree G, there is at most one child vertex v of u that is not a leaf.

Proof: If there are two child vertices v1 and v2 of u that are not leaves, let w1 and w2 be child vertices of v1 and v2, respectively. Let a−1(x) the index i of x such that ai=x. In this notation, we have a−1(u)<a−1(v) for every edge (u,v) in tree G. Without loss of generality, we assume that a−1(v1)<a−1(v2).

Then, we have a−1(v2)<a−1(w1). If this is not true, i.e., a−1(v2)>a−1(w1), then w1 is a candidate for bv2, which leads that u is no longer the parent vertex of v2.

Now we have a−1(v2)<a−1(w1). This means that v2 is a candidate for bw1, which leads that v1 is no longer the parent vertex of w1. A contradiction! □Now we are ready to give an algorithm to find a suitable sequence a with tree G, which is rather simple:

Find the BFS order of tree G, with non-leaf vertices visited last.Sequence a is then obtained by removing the root (the only non-existing element) from the BFS order. If there are multiple valid BFS orders, any of them is acceptable. It can be shown that sequence a obtained by the BFS order will produce sequence b with respect to k, and the time complexity is O(n).Before processing the BFS, remember to check the graph G as follows:

There is exactly one isolated vertex between vertex 0 and n+1.The graph G is a DAG, i.e., no loops exist in graph G.With the above, graph G must be a rooted tree. Choose the non-isolated vertex from vertex 0 and n+1 as the root.For every vertex u in tree G, there is at most one non-leaf child vertex of u.Solution1738E - Balance Addicts

Author: Milesian

Tutorial1738E - Balance AddictsLet f(i,j) be the answer to the problem for the subsequence ai,ai+1,…,aj. And we want to find f(1,n).

For every 1≤i≤j≤n, we consider the following cases.

ai=⋯=aj=0. In this case, every partition produces a balanced sequence, thereby f(i,j)=2j−i.ai=aj=0. In this case, suppose that there are x prefix 0's and y suffix 0's in ai,…,aj with x,y≥1. There can be at most min{x,y} zeros in both the prefix and suffix of the balanced sequence. There arecx,y=∑k=0min{x,y}(xk)(yk)choices in total. So f(i,j)=cx,yf(i+x,j−y).Otherwise, find the leftmost position i≤l≤j and the rightmost position i≤r≤j such that ai+⋯+al=ar+⋯+aj>0.l=j. We have f(i,j)=1.al+1=⋯=ar−1=0. There are 2r−l possible choices to make the sequence balanced. So f(i,j)=2r−l.Otherwise, suppose there are x prefix 0's and y suffix 0's in al+1,…,ar−1. One can cut both parts with sum ai+⋯+al=ar+⋯+aj. The number of choices to cut out k 0's in the balanced sequence is(x+1k+1)(y+1k+1).With the case of no cut considered, we havef(i,j)=(∑k=0min{x,y}(x+1k+1)(y+1k+1)+1)f(l+x+1,r−y−1)=cx+1,y+1f(l+x+1,r−y−1).Since every element is processed once, it is clear that the time complexity is O(n).

Solution1738F - Connectivity Addicts

Author: liouzhou_101

Tutorial1738F - Connectivity AddictsLet's consider the following BFS-like algorithm.

Repeat the following procedure until all vertices are visited.Choose an unvisited vertex u with the largest degree. Let S be a set of vertices, initially consisting of the only vertex u.For every neighbor vertex v of vertex u,If vertex v is visited, color all vertices in S with the same color as vertex v, and then end the procedure this time;Otherwise, add vertex v to set S.Color all vertices in S with a new one color.It is clear that in each repetition of the procedure, the number k of edges visited (i.e., the number of queries) will cause at least k vertices being colored. Since all vertices will be colored exactly once eventually, the number of queries is no more than n. A careful analysis will find that the number of queries is no more than n−C, where C is the number of different existing colors.

The time complexity of this algorithm can be O(n), O(nlogn), or O(n2), depending on concrete implementations. Anyway, any implementation of such time complexity can pass.

It is clear that all vertices with the same color are connected. It remains to see why this algorithm will color all vertices such that sc≤n2c, where nc is the number of vertices with color c, and sc is the sum of degrees of vertices with color c. To see this, it can be shown by induction that after every repetition of the procedure, the number nc of vertices with an existing color c is always no less than the degree of any vertex with color c. Since we enumerate vertices in decreasing order of their degrees, the degree du of the current vertex u must hold that du≤nc for every existing color c. We consider two cases:

During the procedure, no neighbor vertex v of vertex u is visited. That is, every neighbor vertex of vertex u has degree ≤du. Then, there are du+1 vertices in S, and they are assigned with a new color c, thereby sc≤(du+1)du≤(du+1)2=n2c.During the procedure, we find a neighbor vertex v of vertex u that is visited. Let c be the color of vertex v and n′c be the number of vertices with color c before coloring all vertices in S. We have |S|≤d≤n′c. Let nc=n′c+|S| be the number of vertices with color c after coloring all vertices in S with color c. Then sc≤s′c+|S|d≤(n′c)2+|S|n′c≤(n′c+|S|)2=n2c.Therefore, it holds that sc≤n2c for every existing color c after each (and, of course the last) repetition of the procedure.This interesting problem surprisingly comes from non-traditional algorithm scenarios — QUANTUM algorithms.

Further reading: Christoph Dürr, Mark Heiligman, Peter Høyer, and Mehdi Mhalla. Quantum query complexity of some graph problems. SIAM Journal on Computing, 35(6):1310-1328, 2006.

Solution1738G - Anti-Increasing Addicts

Author: antontrygubO_o

Tutorial1738G - Anti-Increasing AddictsConsider increasing diagonals (sets of cells (x,y) for which x−y=c for some fixed c). Clearly, from the diagonal of length t, we have to delete at least max(0,t−(k−1)) cells. There are 2 diagonals of length i for each i from 1 to n−1 and one diagonal of length n, so we have to delete at least 2+4+…+2(n−k)+(n−k+1)=(n−k+1)2 cells from them in total. This means that we will delete precisely max(0,t−(k−1)) cells from the diagonal of length t.

Now, consider two adjacent diagonals of lengths t−1 and t for some t≥k. Let's call diagonal of length t large, and of t−1 small. Let's enumerate cells of large diagonal from 1 to t, and of small from 1 to t−1. We have to delete precisely t−k+1 cells from large diagonal, and t−k from small. Suppose that the cells deleted from the large diagonal have indexes 1≤x1<x2<…<xt−k+1≤t.

For some 1≤j≤t−k, consider the path, containing cells from 1-st to (xj−1)-st in the large diagonal, from xj-th to (xj+1−1)-st in the small diagonal, and from (xj+1+1)-st to t-th in the large diagonal. Note that this is an increasing sequence of cells of length t−1, so we have to delete at least t−k cells from it. We deleted precisely t−k−2 cells from it in the large diagonal, so we have to delete at least one cell in the small diagonal in the range [xj,xj+1−1].

Note that the ranges [xj,xj+1−1] for 1≤j≤t−k don't intersect, and there are t−k of them. So, we have to delete precisely one cell from each such range and not delete any cell outside of [x1,xt−k+1−1].

Surprisingly, these criteria are sufficient (meaning that for every two adjacent diagonals, the cells in the smaller one are deleted in these ranges determined from the cells deleted in the larger one). Let's first show how to solve the problem based on this and then how to prove that this is sufficient.

If these criteria are indeed sufficient, then let's construct the set of deleted cells one by one (if it exists).

How do we choose the first deleted cell on the main diagonal? Just choose the first cell which you can delete.How do we choose the first deleted cell on the diagonals adjacent to the main diagonal? Just choose the first cell which you can delete that goes after the deleted cell in the main diagonal.How do we choose the second deleted cell on the main diagonal and the first deleted cells on the diagonals of length n−2? Again, just choose the first cell that you are allowed to delete which does not violate the conditions.(and so on)You can simulate this greedy in just O(n2)  — just keep for each diagonal the last deleted cell. If at any point there were no allowed cells, then answer is NO, otherwise, we found the construction.

How to prove that this is sufficient? Let's prove the following statement.

Lemma: In each cell (x,y), write the number of non-deleted cells in the diagonal of (x,y), up to the cell (x,y). Denote this number by ax,y. Then ax−1,y≤ax,y for any 1≤x≤n−1, 1≤y≤n, and ax,y−1≤ax,y for any 1≤x≤n, 1≤y≤n−1 (in other words, a is nondecreasing by rows and columns).

Proof: Almost trivial from our constraints. Let's show that ax−1,y≤ax,y, for example. If cell (x−1,y) is on the main diagonal or lower, then cell (x−1,y) is on a larger diagonal than (x,y). We deleted y−ax,y cells in the diagonal of (x,y) up to this cell. Therefore, the (y−ax,y)-th deleted cell in the larger diagonal has to have y coordinate at most y as well, so we deleted at least y−ax,y cells in the diagonal of (x−1,y) up to that cell, and there are at most ax,y not deleted cells there. The similar argument goes for the case when (x−1,y) is above the main diagonal.

With this lemma, suppose that there is an increasing sequence of not deleted cells (x1,y1),(x2,y2),…,(xk,yk) (with xi<xi+1,yi<yi+1). Then it's easy to show that axi,yi<axi+1,yi+1. Indeed, axi,yi≤axi+1−1,yi+1−1=axi+1,yi+1−1. But then we would get axk,yk≥k, which obviously doesn't hold (there are at most k−1 not deleted cells in each diagonal by our construction).

Bonus: It's possible to show that the answer is NO if and only if there is an increasing sequence of k cells, each of which we aren't allowed to delete. Proof is left to the reader as an exercise.

Solution1738H - Palindrome Addicts

Author: liouzhou_101

Tutorial1738H - Palindrome AddictsTo count the number of distinct palindromic substrings, we adopt the powerful data structure called eertree (also known as palindromic tree or palindromic automaton). The number of distinct palindromic substrings of a string s is related to the number of nodes in the eertree of s. See Wikipedia for its standard operations. In the following, we will consider how to maintain the eertree under push and pop queue operations.

It is a standard trick to push a character at the back. So we only need to consider how to pop a character at the front. The key issue is to delete some nodes when they no longer exist. To achieve this, we maintain the following information of each node v:

link_cnt: the number of nodes that link to v.rightmost_occurrence: the rightmost occurrence of v.second_rightmost_occurrence: the second rightmost occurrence of v.When the front character is being popped, let v be the longest palindromic prefix of the current string s (right before popping the front character). Then v should be deleted if v is unique in s. Moreover, we know that v is unique in s if and only if link_cnt[v]=0 and second_rightmost_occurrence[v] does not exist.Now it remains to consider how to maintain rightmost_occurrence and second_rightmost_occurrence in a lazy manner.

After a character c has been pushed at the back of the string s, let v be the longest palindromic suffix of the current string sc. Update rightmost_occurrence[v] and second_rightmost_occurrence[v] immediately with the new occurrence of v.When a character is being popped from the front of the string s, let v be the longest palindromic prefix of the current string (right before the pop operation). If v is unique in s, then let u be the node that v links to, and update rightmost_occurrence[u] and second_rightmost_occurrence[u] with the occurrence of u induced by v (which is a suffix of v). Here, note that u occurs at least twice in v as its prefix and suffix; and the suffix u of v is desired as induced by v.In this way, we can maintain the eertree under push and pop queue operations in O(Σn) time, where Σ=26 is the size of alphabet.

Further reading: Takuya Mieno, Kiichi Watanabe, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai, and Masayuki Takeda. Palindromic trees for a sliding window and its applications. Information Processing Letters, 173:106174, 2022.

An alternative approach

Answer the queries offline.

Since we only push characters at the back and remove characters at the front, we can deal with all operations offline and find the whole string s with its characters deleted during the operations (This can be achieved easily by only considering push operations). For example, the whole string of the sample input is "aaabbaab".

In this way, every query of the number of distinct palindromic substrings is a range query of the form (l,r) that asks the number of distinct palindromic substrings in s[l..r]. Indeed, this kind of queries can be answered in O(logn) time per query with O(nlogn) time preprocess.

Further reading: Mikhail Rubinchik and Arseny M. Shur. Counting palindromes in substrings. In Proceedings of the 24th International Conference on String Processing and Information Retrieval, pages 290–303, 2017.

Solution

Editorial of Codeforces Global Round 21

By feecIe6418, 9 months ago, In EnglishThanks for participation!

If your solution to D involves any data structures and is not O(n) -- please read the "solution 1". I believe it is very interesting, but to make the difficulty suitable for D we allowed not O(n) solutions.

1696A - НИТ делает orz

Hint 1SolutionSuppose we can only perform exactly one operation. In this case the answer is S=max1≤i≤n(ai or z). In fact, we can prove that this is the answer.

Define a′i as the value of ai after some operations.

It suffices to prove the answer will never exceed S. Note that z will always become a submask of itself after any number of operations, so ai will always be a submask of (ai or z) after any number of operations. This leads to the conclusion that a′i≤(ai or z) for all i. Thus max1≤i≤na′i≤max1≤i≤n(ai or z)=S.

Time complexity is O(n).

1696B - НИТ уничтожает вселенную

Hint 1Hint 2SolutionThe answer is at most 2, because doing the operation on [1,n] at most twice will always work. (If the array contains at least one zero, we need 2 operations. Otherwise we need 1 operation.)

If the array consists of zeroes, the answer is 0.

If all non-zero elements form a contiguous segment in the array, the answer is $1$​. To check this, you can find the leftmost and rightmost occurrence of non-zero elements and check if elements in the middle of them are also non-zero.

Otherwise the answer is 2.

Time complexity is O(n).

1696C - Fishingprince играет с массивом

Hint 1Hint 2SolutionCall the first operation "expand" and the second operation "shrink".

Keep doing expand on both arrays until we can't do expand anymore, call the resulting arrays a′ and b′. It suffices to check if a′=b′. To implement this, you need to compress contiguous equal numbers.

Proof of why this is necessary and sufficient:

Sufficiency is obvious, since the operations are reversible. We can do something like a→a′=b′→b.

Necessity: Let f(a)=a′. It suffices to prove that an operation on a does not affect f(a). An expand operation obviously doesn't affect f(a). A shrink operation shrinks a[i,i+m−1] into one element. When computing f(a′), we will always expand a′i at some time, so the result is the same as $f(a)$​.

Time complexity is O((n+k)logmV), where V=maxai.

1696D - Граф перестановки

This problem has two different solutions. The first one is more beautiful, but less straight-forward.

Hint 1 for solution 1Hint 2 for solution 1Hint 3 for solution 1Solution 1Denote dis(x,y) as the length of the shortest path between x and y.

Consider a position i that ai=n. Assume i≠1 and i≠n. For a segment that passes i, its maximum element is always ai. Thus, for x<i<y, x and y will never be directly connected by an edge. This means that when going from 1 to n, we have to pass i. Let us solve recursively for dis(1,i) and dis(i,n). For example, we solve for dis(1,i).

We already know that ai=n, so i is the maximum element in [1,i]. Consider the minimum element in [1,i], suppose it is aj (j<i). From similar arguments, we can solve recursively for dis(1,j) and dis(j,i). However, note that dis(j,i) equals to 1: since j and i are respectively minimum and maximum in [1,i], they have to be minimum and maximum in [j,i] as well. So i,j must be directly connected. Thus, we only need to solve recursively for dis(1,j).

The process with dis(i,n) is similar. Note that we will only call dis(l,r) for l=1 or r=n (if not, the return value is always 1), so it suffices to pre-compute prefix and suffix minimums and maximums.

The time complexity is O(n).

Hint 1 for solution 2Hint 2 for solution 2Solution 2We can prove that keep going to the vertex with the largest index is a correct strategy. The proof is left as an exercise :) Hint: try to prove that the path we will visit is the same as the path we visited in solution 1.

Suppose we are at i. We want to find the largest j>i such that i and j are directly connected. WLOG, assume ai+1<ai. Then, it cannot be the case that aj>ai, since none of ai,aj will be mn(i,j). Thus aj<ai. It follows that all i<k<j satisfies ak<ai, otherwise none of ai,aj will be mx(i,j).

Let ri be the largest p, such that for all t∈[i+1,p], at<ai. From the arguments above we know j∈[i+1,ri]. ri can be pre-computed with a stack, or binary search + some data structures.

Let j0 be the position of the minimum element in [i+1,ri]. Obviously j0 is directly connected with i. For any j0<k≤ri, mn(i,k) will be aj0, showing that all such k is not directly connected with i. Thus, j0 is the desired j.

If we use data structures for range minimum, we get a O(nlogn) solution, which can easily pass (not sure whether O(nlog2n) ones will pass though, the large constraints were intended to cut those).

However, by building the cartesian tree of the array and doing proper pre-computations, we can optimize this solution to O(n).

1696E - Размещение кукол

Hint 1Hint 2Hint 3SolutionLet us find out the number of operations we do on a specific cell (i,j), call it f(i,j).

Every operation done on (i−1,j) will lead to one doll on (i,j), thus consuming one operation on (i,j). Similar observation holds for (i,j−1).

Thus, f(i,j)=f(i,j−1)+f(i−1,j) (given that (i,j),(i−1,j),(i,j−1) are all white cells). Note that a is non-increasing: this means that if (i,j) is white, (i−1,j),(i,j−1) will both be white. So we can conclude that f(i,j)=f(i,j−1)+f(i−1,j) always holds as long as (i,j) is white.

Another way to see the formula is f(i,j) is the number of ways to go from (0,0) to (i,j), only going down or right by 1 step. This implies that f(i,j)=(i+jj).

From this, we know that the answer is ∑ni=0∑ai−1j=0(i+ji). With the equation ∑ki=0(n+in)=(n+k+1n+1), we know that the answer is ∑ni=0(i+aii+1).

The time complexity is O(n+V), where V=maxai.

1696F - Восстановление дерева

Hint 1Hint 2SolutionRead the hints first to understand the solution better.

Construct a graph with (n2) vertices (1,2),(1,3),…,(n−1,n).

If dis(a,b)=dis(b,c), link an undirected edge between (a,b) and (b,c).

Observe that all edges in the tree form a connected component of size exactly n−1 in the graph!

Find all components of size n−1 and try if all vertices in it form a tree that satisfy the input. There are at most n2 such components, so complexity is O(n4). Proper pre-computation and the usage of bitsets can reduce the complexity to O(n4/w).

1696G - Fishingprince снова играет с массивом

Hint 1Hint 2Hint 3SolutionFirst we solve the problem with only 1 query on the whole array A.

This is a linear programming problem:

minimize∑1≤i<nai+biXa1+Yb1≥A1Xai+Ybi+Yai−1+Xbi−1≥Ai (2≤i<n)Yan−1+Xbn−1≥Anai,bi≥0Consider its dual:

maximize∑1≤i≤nAixiXxi+Yxi+1≤1 (1≤x<n)Yxi+Xxi+1≤1 (1≤x<n)xi≥0Suppose X≤Y. Now we will prove that there exists an optimal solution to the dual problem, in which xi can only take three values: 1/Y,1/(X+Y),0.

The proof is as follows: It is well-known that an optimal solution to a linear programming problem must lie on a vertex of the "multi-dimensional convex polygon" which the restrictions surround. Thus we are only interested in xi that satisfy several "=" restrictions (and the restrictions should really intersect at one point, meaning that those "=" should uniquely determine x). Consider any "sufficient" (that means they uniquely determine x) subset of them. If one restriction is related to xp,xq, we link an undirected edge between p and q. If one restriction is only related to xp (i.e. xp=0), we link a self-loop on p. "Being sufficient" means that all connected components in the graph has exactly one cycle. However, for an edge (u,v), we know that either u=v+1 or u=v. This means that all cycles can only be (i→i+1→i) or i→i. If a cycle is (i→i+1→i), all xi in the component are 1/(X+Y); If a cycle is i→i, all xi in the component are 1/Y or 0 (not 1/X, because it exceeds the constraints).

Thus we can use dp to solve the dual problem. Let dp(i,0/1/2) be the maximum ∑j≤iAjxj when xi is the 0/1/2-th candidate above. Transitions are straight-forward.

For multiple queries, the transitions can be written into multiplying matrices, and we can use segment tree to maintain updates.

About precision issues: actually we can avoid using floating point numbers completely. Note that all numbers in this problem are fractions with denominator Y(X+Y). Also note that the answer does not exceed (∑ai)/Y. This means that the numerator does not exceed (∑ai)×(X+Y)<1018, so we can use long long-s to only store numerators. If you use double in C++, the relative error of one operation is less than 10−15. 10−15×n<10−9, which means that using doubles is also enough.

Complexity: O(n+qlogn).

1696H - Максимальное произведение?

Hint 1Hint 2SolutionFirst, we describe a strategy to find the answer for a single subset. If the whole subset is negative, the answer is the product of the K maximum numbers in it. Otherwise, take K numbers with the maximum absolute value. If there is an even number of negative numbers in those numbers, we're done. Otherwise, find the smallest positive element and change it to the absolute-value-maximum negative element unchosen, or find the largest negative element and change it to the maximum positive element unchosen. We either do the first change or do the second change.

This gives a direct dp solution. Take all ai and sort them into two arrays consisting of positive and negative ones (0 goes to arbitary one), pos and neg, sorted by absolute values. By calculating fpos(i,k): the sum of the product of the largest K numbers of all subsets of pos[1…i] that contain posi, and fneg(i,k) similarly, and gneg(i,k), the sum of the product of the absolute value smallest K numbers of all subsets of neg[i…|neg|] that contain negi, and enumerating the following, we can solve the original problem in O(n5):

the number of positive elements in the K numbers with the maximum absolute value in our calculating subset, p.the smallest positive element in the K numbers with the maximum absolute value, posi.the greatest negative element in the K numbers with the maximum absolute value, negj.(if p is odd) the greatest positive element not in the K numbers with the maximum absolute value, posk.(if p is odd) the smallest negative element not in the K numbers with the maximum absolute value, posl.The contribution to the answer can be represented as the sum of product of fpos,fneg, and powers of two. I left the details as an exercise.

However, notice that the "enumerating k,l" part has nothing to do with p, so we can pre-calculate the contribution of k,l for every pair (i,j), giving an O(n4) algorithm.

What's more, for fixed i,j,k, the l-s that we do the first change is a prefix/suffix of all l, and l-s that we do the second change is a prefix/suffix of all l. So with two pointers and prefix sums, we can pre-calculate the contribution of every (i,j) in O(n3), which is fast enough.

You might be afraid that 6003 is too slow for 1.5 seconds. However, the two O(n3) parts of the algorithm actually run in O(n×cntpos×cntneg) (cntpos,cntneg are the number of positive/negative integers in the array), leading to an at most 1/4 constant factor. Thus, the algorithm actually runs very fast (less than 0.25 seconds). However for similar constant factor reasons, the O(n4) solution only takes about 6.5 seconds on Codeforces, so we had to set a seemingly-tight limit.

Global Round 20 Editorial

By maomao90, 10 months ago, In EnglishHope that everyone enjoyed the round. Feel free to ask questions in the comments if you do not understand any part of the editorial

1672A - Log ChoppingAuthor: errorgorn

HintsTutorialLet us consider the ending state of the game. It turns out that at the ending state, we will only have logs of 1 meter. Otherwise, players can make a move.

Now, at the ending state of the game, we will have ∑k=1nak logs. And each move we increase the number of logs by exactly 1. Since we started with n logs, there has been exactly (∑k=1nak)−n turns.

Alternatively, a log of length ak will be cut ak−1 times, so there will be ∑k=1n(ak−1) turns.

If there were an odd number of turns errorgorn wins, otherwise maomao90 wins.

Solution1672B - I love AAABAuthor: errorgorn

HintsTutorialClaim: The string is obtainable if it ends in B and every prefix of the string has at least as many A as B.

An alternative way to think about the second condition is to assign A to have a value of 1 and B to have a value of −1. Then, we are just saying that each prefix must have a non-negative sum. This is pretty similar to bracket sequences.

Now, both conditions are clearly necessary, let us show that they are sufficient too.

We will explicitly construct the string (in the reverse direction). While there are more than 1 occurrences of B in the string, remove the first occurrence of AB. After doing this process, you will eventually end up with the string AAA...AAB.

Solution1672C - Unequal ArrayAuthor: maomao90

HintsTutorialSuppose l is the smallest index where al=al+1 and r is the largest index where ar=ar+1. If l=r or l and r does not exist, the condition is already satisfied and we can do 0 operations. Otherwise, the answer is max(1,r−l−1). The proof is as follows:

Suppose l+1=r, then, there are 3 elements that are adjacent to each other. Hence, we can just do one operation with i=l and x=∞ to make the equality of the array 1.Suppose otherwise, then the array will look something like [...,X,X,...,Y,Y,...], with r−l−2 elements between the second X and the first Y. Then, we can do operations on i=l+1,l+2,…,r−2,r−1 to make the equality of the array 1.To see why we need at least r−l−1 operations, observe that each operation will cause r−l to decrease by at most 1. This is because if we do not do an operation on i∈{l−1,l+1,r−1,r+1}, then both al=al+1 and ar=ar+1 will still hold. We see that r−l only decreases when do we an operation on i∈l+1,r−1 and it is not too hard to show that it only decreases by 1 in those cases while r−l>2Hence, we keep doing the operation until r−l=2, which will only require 1 operation to change both pairs and make the equality 1.

Solution1672D - Cyclic RotationAuthor: errorgorn

HintsTutorial 1We will solve the problem by reversing the steps and transform array b to array a.

We can do the following operation on b:

pick index i<j such that bj=bj+1 and remove bj+1 and insert it after position i.Now, for every consecutive block of identical elements in b, we can remove all but one element from it and move it left.

If we process from right to left, we can imagine as taking consecutive elemnets in b out and placing in a reserve, and using them to match some elements in a towards the left.

Using this idea, we can use the following greedy two-pointer algorithm:

Let i and j represent the size of a and b respectively (and hence ai and bj will refer to the last elements of a and b respectively). We also have an initially empty multiset S, which represents the reserve. We will perform the following operations in this order:

While bj−1=bj, add bj to the multiset S and decrement jIf ai=bj, then decrement both i and jOtherwise, we delete an occurance of ai in S and decrement i. If we cannot find ai in S, it is impossible to transform b to a.Tutorial 2Let us define an array c where all elements of c is 1. We can rephrase the problem in the following way:

Choose i<j such that ai=aj and ci>0. Then update ci←ci−1 and cj←cj+1.The final array b is obtained by the following: Let b be initially empty, then iterate i from 1 to n and add ci copies of ai to b.

As such, we can consider mapping elements of b into elements of a. More specifically, consider a mapping f where f is non-decreasing, bi=afi and we increment cfi by 1 for all i. All that remains is to determine if we can make such a mapping such that c is valid.

Notice that if all elements of a are identical, the necessary and sufficient condition for a valid array c is that c1+c2+…+ci≤i for all i.

This motivates us to construct an array pa where pai is the number of indices j≤i such that ai=aj. Analogously, construct pb.

Then the necessary and sufficient conditions for a mapping f is that f is non-decreasing, bi=afi and pbi≤pafi. A greedy algorithm to construct f, if it exists, is trivial by minimizing fi for each i.

Solution 1Solution 21672E - notepad.exeAuthor: errorgorn, oolimry

HintsTutorialThe first idea that we have is that we want to be able to find the minimum possible width of the text editor for a specific height. We can do this in nlog(n⋅2000) queries using binary search for each height. This is clearly not good enough, so let us come up with more observations.

First, we can binary search for the minimum possible width for height 1. This value is (∑ni=1li)+n−1 which we will denote with S.

Let us consider what we might want to query for height h. Suppose that the words are arranged very nicely such that there are no trailing spaces in each line. Then, the total number of characters will be S−h+1. This means that the minimum possible area for height h will be S−h+1. We also know that if the area is more than S, it will not be useful as the area for h=1 is already S.

Now, we know that the range of possible areas that we are interested in is [S−h+1,S]. There is a total of h possible areas that it can take, and an area is only possible if h⋅w=a, or in other words, the area is divisible by h. Among the h consecutive possible values, exactly one of them will be divisible by h, hence we can just query that one value of w which can very nicely be found as ⌊Sh⌋.

The total number of queries used is n+log(n⋅2000) where n comes from the single query for each height and the log(n⋅2000) comes from the binary search at the start.

Solution1672F1 - Array Shuffling and 1672F2 - Checker for Array ShufflingAuthor: errorgorn

HintsTutorialLet N be the length of A and B.

We want to prove that an optimal swapping from B→A is equivalent to sorting via some cycles. Suppose our swap order is {(l1,r1),(l2,r2),…,(lK,rK)}. Let's consider a graph G with edges being the swaps. Suppose the number of connected components in G is CC, then there is a way to perform the transformation B→A using CC cycles since we can view the labels of each connected component of G as a permutation of the original vertices. One cycle of length X uses X−1 swaps, so we use N−CC swaps in total. Since CC≥N−K, we can always change the swap order to swapping cycles while not performing a bigger number of moves. Now we have changed the problem to maximizing the number of cycles we use.

Let cntx be the number of occurrences of x in A. WLOG cnt1≥cnt2≥….

Let sA(B) denote the sadness of B when the original array is A.

Claim: max(sA)≤N−cnt1Proof: By pigeonhole principle, we know there exist a cycle with 2 occurrences of the element 1.

Consider a cycle that swaps i1→i2→…→iK→i1 where Ai1=Aiz=1. Then we can increase the number of connected components while maintaining B by splitting into 2 cycles i1→i2→…→iz−1→i1 and iz→i2→…→iN→iz.

Therefore, in an optimal solution, there should not be a cycle that passes through the same value twice. ■Therefore, we can assume that all occurrences of 1 belong to different cycles. Therefore, #cyc≥cnt1 swaps are used. The number of swaps used is N−#cyc≤N−cnt1.

Therefore, N−cnt1 is a upper bound of s.

Claim: sA(B)<N−cnt1 ⇔ there exists a cycle i1→i2→…→iK→i1 such that all ix≠1.

Proof: (⇒) There exists a cycle decomposition of the graph that uses at least cnt1+1 cycles. Since a single element of 1 can only go to a single cycle, there exists a cycle without 1.

(⇐) Let's remove this cycle to form an arrays A′ and B′. Then sA′(B′)≤N−K−cnt1. Now, we only needed K−1 swaps to remove the cycle, so it much be that sA(B)≤(N−K−cnt1)+(K−1)=N−cnt1−1. ■Constructing maximal BTo construction a permutation such that s(B)=N−cnt1, let's construct a graph Gcnt based on the number of occurrences of each element in A. We draw cnti+1 edges from (i)→(i+1) and cnti−cnti+1 edges from (i)→(1). It is obviously impossible to find a cycle that does not contain 1. Since all edges will be of the form (i)→(i+1).

Another way to construct this permutation is to assume that A is sorted. Then we perform cnt1 cyclic shifts on A to obtain B.

Checking if B is maximalGiven the graph representation, finding such a cycle i1→i2→…→iK→i1 such that all ix≠1 is easy. Let's remove 1 from the graph then check if the graph is a DAG.

Solution for F1Solution for F21672G - Cross XorAuthor: maomao90, errorgorn

HintsTutorialDetermining which Grids are ObtainableLet Ri and Cj denote ⨂j=1cai,j and ⨂i=1rai,j respectively, or the xor-sum of the i-th row and the xor-sum of the j-th column respectively.

We will split the problem into 3 cases.

Case 1: r is even and c is evenChoose some (x,y) and do an operation on all (i,j) where i=x or j=y. The effect of this series of operations is toggling (x,y).

All possible grids are reachable. Counting them is easy.

Case 2: r is even and c is oddIf r is odd and c is even, we can treat it as the same case by swapping a few variables.

Notice that every operation toggles all elements in R. It is neccasary that R all values in R are the same, let us prove that this is sufficient as well.

Now suppose R is all 0. If R is all 1. We can perform the operation on (1,1) and now R is all 0.

If we pick 1≤x≤r and 1≤y<c and perform operations on all (i,j) where i≠x and j=y or j=c, then it is equivalent to toggling (x,y) and (x,c).

We can perform the following new operation:

pick 1≤x≤r and 1≤y<ctoggle (x,y),(x,c)Since R is all 0, each row has an even number of 1. If we apply the new operation on all (x,y) where ax,y=1 and y<c, then (x,c) will be 0 in the end. Hence, the whole grid will be 0.

Case 3: r is odd and c is oddNotice that every operation toggles all elements in R and C. It is neccasary that both R are C all having the same values, let us prove that this is sufficient as well.

Suppose R is all 0 and C is all 0. If R and C are all 1, we apply the operation on (1,1) to make R and C both all 0Notice that if we pick 1≤x1<x2≤r and 1≤y1<y2≤c. Let S={(x1,y1),(x1,y2),(x2,y1),(x2,y2)}. When we perform operations on all cells in S, it is equivalent to toggling all cells in S.

We can perform the following new operation:

pick 1≤x<r and 1≤y<ctoggle (x,y),(x,c),(r,y),(r,c)Since R and C is all 0, each row and column has an even number of 1. If we apply the new operation on all (x,y) where ax,y=1 and x<r and y<c , then (x,c) will be 0 for 0<x<r and (r,y) will be 0 for 0<y<c in the end. And hence, ar,c=0 too since R and C is all 0. Hence, the whole grid will be 0.

Alternate JustificationThanks to dario2994 for writing this.

Let V=Znm2. V is endowed with the natural scalar product, which induces the concept of orthogonality.

Let M be the subspace generated by the moves. Let M⊥ be the space orthogonal to M. It is a basic result in linear algebra that (M⊥)⊥=M.

One can see that {(x1,y1),(x1,y2),(x2,y1),(x2,y2)} belongs to M (it is a combination of 4 moves). Thus one deduces that if u∈M⊥ then ux,y=ax⊕by for two vectors a∈Zr2,b∈Zc2. Given a,b; the scalar product between u and the move centered at (x,y) is: xor(a)⊕xor(b)⊕(c+1)ax⊕(r+1)by. Assume that u is in M⊥:

If r,c are both even, then ax and by must be constant and equal each other. Thus M⊥ is only the 0 vector.If r is even and c is odd, then by is constant. Hence M⊥ is generated by any two rows.If r is odd and c is even, analogous.If r and c are both odd, then the only condition is xor(a)⊕xor(b)=0. This is necessary and sufficient for the orthogonality. And it implies that M⊥ is generated by any two rows and any two columns.Since we determined M⊥, we have determined also M.

CountingCase 1 and 2 are the easy cases while counting case 3 is more involved.

Case 1: r is even and c is evenAll grids are obtainable. Let #? denote the number of ?s in the grid. Then the answer is 2#? since all grid are obtainable.

Case 2: r is even and c is oddIf r is odd and c is even, we can treat it as the same case by swapping a few variables.

Let us fix whether we want R=[0,0,…,0] or R=[1,1,…,1]. We will count the number of valid grids for each case.

Let #?i denote the number of ?s in the i-th row. If #?i>0, then then number of ways to set the i-th row is 2#?i−1. Otherwise, the number of ways is either 0 to 1 depending on the initial value of Ri.

Case 3: r is odd and c is oddLet us define a bipartite graph with vertices r+c vertices, labelled VR,i for 1≤i≤r and VC,j for 1≤j≤c. If ai,j=?, then we will add an (undirected) edge VR,i↔VC,j. Now we assume that each ? is set to 0 at first. We will choose a subset of them to turn into 1. When we do this on ai,j, the value of Ri and Cj will toggle. In terms of the graph, this corresponds to assigning 0 or 1 to each edge. When we assign 1 to the edge connecting VR,i and VC,j, then Ri and Cj will toggle. We can consider Ri and Cj to be the weight of the vertices VR,i and VC,j respecitvely.

Consider a connected component of this bipartite graph. Choose an arbitrary spanning tree of this connected component. By assinging the weights of the edges in the spanning tree, we can arbitrarily set the weights of all but one vertex. We cannot arbitarily set the weight of all vertices as the xor-sum of the weight of vertices is an invariant.

Let us show that we can arbitarily choose the weights of all but one vertex on this connected component using the spanning tree. Let us arbitrarily root the tree. Choose some arbitrary leaf of the tree, if the weight of the leaf is correct, assign the edge connected to that vertex weight 0. Otherwise, assign it weight 1. Then remove the leaf and its corresponding edge. Actually, this shows that there is a one-to-one correspondents between the possible weights of the edges and the possible weights of the vertices.

For the edges not in the spanning tree we have chosen, we can arbitarily set their weights while we are still able to choose the weights of all but one vertex on this connected component by properly assigning weights of the edges in the spanning tree.

Suppose we want this constant value of R and C to be v, where v is either 0 or 1.

Suppose that the connected component has size n, has m edges and the xor of all the initial vertex weights is x.

If n is even:

If x=0, then there are 2m−n+1 ways to assign weights to edges.If x=1, then there are 0 ways to assign weights to edges.If n is odd:

If x=v, then there are 2m−n+1 ways to assign weights to edges.If x≠v, then there are 0 ways to assign weights to edges.Solution1672H - Zigu ZaguAuthor: maomao90, errorgorn

HintsTutorialWe can first split string A into the minimum number of sections of 010101… and 101010…. Let the number of sections be K. Since we can simply delete each section individually, the worst answer that we can get is K. Also, there is no reason to only delete part of a segment, so from here on we only assume that we delete maximal segments.

Now, we can decompose A based on its K sections and write it as a string D. The rules for the decomposition is as follows:

10…01→x01…10→x′10…10→y01…01→y′For example, the string A=[0101][1][1010] becomes D=y′xy. Now, let us look at what our operation does on D.

When we remove a section of even length (y or y′) that is not on the endpoint of the string, the left and right sections will get combined. This is because the two ends of an even section are opposite, allowing the left and right sections to merge. Otherwise, it results in no merging.

When some sections get combined, the length of string D gets reduced by 2, while the length of D gets reduced by 1 otherwise. Clearly, we want to maximize deleting the number of sections of even length that are not on the endpoints of the string. We will call such a move a power move.

Let us classify strings that have no power moves. They actually come in 8 types:

xx…xy′xx…xxx…xyy′xx…xyx′x′…x′yx′x′…x′x′x′…x′y′yx′x′…x′y′We can prove that for any string not of this form, there will be always be character y or y′ that is not on the ends of the string. Suppose that the string contains both x and x′, then xyx′ or x′y′x must be a substring. Also, the number of y or y′s on each side cannot be more than 1. Note that strings such that y or yy′ may fall under multiple types.

Furthermore, for string of these types, the number of moves we have to make is equal to the length of the string.

Let us define the balance of x as the number of x minus the number of x′. We will define the balance of y similarly. When we perform a power move, notice that the balance of the string is unchanged. Indeed, each power move either removes a pair of x and x′ or y and y′ from the string.

With this, we can easily find which type of ending string we will end up with based on the perviously mentioned invariants, except for the cases of differentiating between the string xx…x and y′xx…xy (and the case for x′).

To differentiate between these 2 cases, we can note that the first character of our string does not change when we perform power moves. And indeed, x and y′ have different starting characters.

Note that we have to be careful when the balance of x and the balance of y is 0 in the initial string as for strings such as yy′, the final string is not ∅ but yy′. With this, we can answer queries in O(1) since we can query the balance of x, the balance of y and the total length of the decomposed string in O(1).

Furthermore, there is a implementation trick here. Notice that if al−1≠al, then then answer for s[l−1,r] will be equal to the answer for s[l,r]. So in implementation, it is easier to "extend" l and r to find the balance of x and y.

Solution1672I - PermutationForcesAuthor: errorgorn

HintsTutorialLet us rephrase the problem. Let x and y be arrays where xi=pi and yi=i initially. For brevity, let ci=|xi−yi|.

We want to check if we can do the following operation n times on the array:

Choose an index i such that and ci≤s.For all j where xi<xj, update xj←xj−1.For all j where yi<yj, update yj←yj−1.Set xi←∞ and yi←−∞Let us fix s and solve the problem of checking whether a value of s allows us to transform the permutation into the empty permutation.

Lemma 1Let (x,y,c) be the arrays before some arbitrary operation and (x′,y′,c′) be the arrays after that operation. If we only perform moves with ci≤s, then cj≤s implies that c′j≤s i.e. if something was removable before, it will be removable later if we only use valid moves.

Proof: Note that x′j=xj or x′j=xj−1. The case for y is same.

We can see that c′j≤cj+1. So the only case where c′j>s is when cj=s.

Case 1: xj≤yjThen it must be that x′j=xj and y′j=yj−1. By the definition of our operation, we have the following inequality: xi<xj≤yj<yi.

This implies that ci>s, which is a contradiction.

Case 2: xj≥yjBy similar analysis we see that ci>s. ■Suppose that we only remove points with ci≤s for some fixed s. This greedy algorithm works here - at each step, choose any point ci≤s with and remove it. - if no such point exists, the s does not work

Proof:

Given any permutation, let any point with ca≤s be a. Consider any optimal sequence of moves [b1,b2,…,bw,a,…]. We can transform to another optimal solution it by moving a to the front.

Let the element before a to be bw. We will swap a and bw. a is already removable at the start so it will be removable after removing b1,b2,…,bw−1 by lemma 1. After removing everything before b1,b2,…,bw−1, bw is removable, so it will be removable after removing a by lemma 1. Hence we can move a to the front of the sequence of moves by repeatedly swaping elemenets.

By exchange arguement, the greedy solution of removing any point with ca≤s is an optimal solution.

Time Complexity SpeedupsBy extension, the following greedy algorithm works:

Set s←0.

At each step, choose index i with minimal ciUpdate s←max(s,ci)Remove point iLet's start with s=0 and remove things while we can. If we are at a state that we are stuck, incremenet s. When we increment s, the moves that we haved done before will still be a valid choice with this new value of s. We simply increment s until we can remove the entire permutation which is

Now the only difficult part about this is maintaining the array ci (the cost) for the points we have not removed.

Let's define a point as good as follows:

If y<x, the point is good if there exist no other point (x′,y′) such that y<y′≤x′<x.

Otherwise, the point is good if there exist no other point (x′,y′) such that x<x′≤y′<y.

We maintain only the good elements, because only good elements are candidates for the minimum ci. Suppose element is not good and minimal, then the point that causes it to be not good has a strictly smaller cost, an obvious contradiction.

Now we will use data structures to maintain ci of good points. We will split the good points into the left good and right good points which are those of xi≤yi and yi≤xi respectively. Notice that if xi=yi, then it is both left good and right good.

We will focus on the left good points. Suppose i and j are both left good with xi<xj, then yi<yj. Suppose otherwise, then we have xi<xj≤yj<yi, making i not good. As such x and y of the left good points are monotone.

To find this monotone chain of left good points, we can maintain a max segment tree which stores max y for all alive x. Using binary search on segment tree to find the unique point with x′>x such that y′ is minimized. Where (x,y) is a point on the chain, and (x′,y′) is the next point. We can repeatedly do this to find the entire chain of left good elements

We can store a segment tree where i is the key and ci is the value. If an element is left good, it will always be left good until it is removed.

The following two operations are simply range updates on the segment tree since yi is monotone. - For all j such that xj>xi, set xj←xj−1. - For all j such that yj<yi, set yj←yj−1.

Now, when we remove some left good point, some other points will become left good, and we will need to add them. We do this by starting from the previous element of the left good chain, and then keep repeating the same algo using descend on the segment tree.

When we add a new left good point, we need to know the cost at the current point in time. If we consider a point which is initially (x,y), and all other previously removed (x′,y′), x decreases by 1 per x′<x and y decreases by 1 per y′<y. Hence, we can maintain a fenwick tree of the removed point's x and y, and using that we can determine the x and y at the time when we add it to the left good chain (and hence to the segment tree).

Time Complexity: O(nlogn)Quad TreesThanks to dario2994 for pointing this out.

Surprisingly quad trees are provably O(nn−−√) here. Take the k-th layer of the quad tree. The n⋅n grid will be split into 4k squares in the k-th layer. Since we are doing half plane covers, our query range will only touch 2k squares. At the same time, the width of those 2k squares is n2k. Since each column only has a single element, our query range will also by bounded by n2k. The time complexity for a single update is given by ∑k=1lognmin(2k,n2k)=O(n−−√).

Solution

Global Round 19 Editorial

By Mangooste, history, 13 months ago, In EnglishWe hope you enjoyed the contest! We recommend you to read all tutorials even if you solve the problem, maybe you will learn something new.

1637A - Sorting PartsIdea: __JustMe__.

Hint 1Hint 2Tutorial1637A - Sorting PartsConsider two cases:

The array is already sorted.THe array is not sorted.In the first case, sorting any prefix and any suffix does not change the array. So the array will always remain sorted so the answer is "NO".

In the second case, there are two elements with indexes i and j, such that i<j and ai>aj. So choose len so that these two elements will be in different parts. For example — len=i. Note that after operation ai will remain to the left of aj, which means the array will not be sorted. So the answer is "YES".

Then the solution is to check if the array is sorted, which can be done in O(n).

Solution1637B - MEX and ArrayIdea: __JustMe__ and Mangooste.

Hint 1Hint 2Tutorial1637B - MEX and ArrayWe show, that replacing a segment of length k (k>1) with segments of length 1 does not decrease the cost of the partition. Consider two cases:

The segment does not contain 0.The segment contains 0.In the first case the contribution of the segment equals to 1 (because mex=0), but the contribution of k segments of length 1 equals to k. So the cost increased. In the second case the contribution of the segment equals to 1+mex<=1+k, but the contribution of the segments of length 1 would be at least 1+k, so the cost has not decreased.

Then it is possible to replace all segments of length more than 1 by segments of length 1 and not decrease the cost. So the value of the array b1,b2,…,bk equals to ∑ki=1(1+mex({bi})) = k + (the number of zeros in the array).

To calculate the total value of all subsegments, you need to calculate the total length of all subsegments and the contribution of each 0. The total length of all subsegments equals to n⋅(n+1)⋅(n+2)6. The contribution of a zero in the position i equals to i⋅(n−i+1). This solution works in O(n), but it could be implemented less efficiently.

There is also another solution, which uses dynamic programming: let dpl,r is the value of the array al,al+1,…,ar. Then dpl,r=max(1+mex({al,al+1,…,ar}),maxr−1c=l(dpl,c+dpc+1,r)). This solution can be implemented in O(n3) or in O(n4).

Solution1637C - Andrew and StonesIdea: TeaTime.

Hint 1Hint 2Tutorial1637C - Andrew and StonesConsider 2 cases when the answer is −1 for sure:

For all 1<i<n: ai=1. In this case, it's not possible to make any operation and not all stones are in piles 1 or n.n=3 and a2 is odd. Then after any operation this number will remain odd, so it can never become equal to 0.Later it will become clear why these are the only cases where the answer is −1. To show it consider the following algorithm:

If all stones are in piles 1 and n then the algorithm is done.If there is at least one non-zero even element (piles 1 and n don't count), then subtract 2 from it, add 1 to the odd number to the left or to the pile 1 if there's no such number. Similarly add 1 to the odd number to the right or to the pile n if there's no such number. Then continue the algorithm. Note that the number of odd elements after it (piles 1 and n don't count) decreases at least by 1 (if there was any odd number). Also either a new even number has appeared, or the algorithm will be done.If all remaining non-zero numbers are odd, then there is at least one odd number greater than 1. So let's subtract 2 from this element and add ones similar to the 2-nd case. In this case the number of odd elements decreases at least by 1.From the notes written in the second and third cases, it follows that the algorithm always puts all stones to the piles 1 and n. Also note that if in the initial array the element in position i (1<i<n) was even, then the algorithm did not add any 1 to it, so the number of operations with the center in i equals to ai2. And if ai was odd, the algorithm will add 1 to this element exactly once, so the number of operations with the center in i equals to ai+12.

This algorithm is optimal because for each odd number it's necessary to add at least 1 to it and the algorithm adds exactly 1. And from even elements the algorithm can only subtract. It means that the answer to the problem equals to ∑n−1i=2⌈ai2⌉. Time complexity is O(n).

Solution1637D - Yet Another Minimization ProblemIdea: Mangooste.

Hint 1Hint 2Hint 3Tutorial1637D - Yet Another Minimization ProblemThe cost of the array a equals to ∑ni=1∑nj=i+1(ai+aj)2=∑ni=1∑nj=i+1(a2i+a2j+2aiaj).

Let s=∑ni=1ai.

Then cost=(n−1)⋅∑ni=1a2i+∑ni=1(ai⋅(s−ai))=(n−1)⋅∑ni=1a2i+s2−∑ni=1a2i=(n−2)⋅∑ni=1a2i+(∑ni=1ai)2.

Then the total cost of two arrays equals to (n−2)⋅∑ni=1(a2i+b2i)+(∑ni=1ai)2+(∑ni=1bi)2. The first term is a constant ⇒ we need to minimize (∑ni=1ai)2+(∑ni=1bi)2.

There are two continuations of the solution, but the idea of both is to iterate over all possible sum of the array a, then calculate the sum of the array b and update the answer using formula written above:

Let dpi,w is true if it's possible to make some operations so that the sum of first i elements in the array a equals to w, otherwise dpi,w is false. Then dp1,a1=dp1,b1= true. For i>1: dpi,w=dpi−1,w−ai or dpi−1,w−bi. Then to iterate over all possible sums of the array a you need to consider such s, that dpn,s= true.Assume, that we have n items, where i-th item has a weight of |bi−ai|. By solving simple backpack problem let's find all possible sums of weights of these items. And if the sum contains i-th item, then we will assume that ai≥bi, otherwise ai≤bi. So if the sum of weights of some items equals to s, then the sum of the array a equals to ∑ni=1min(ai,bi)+s. So all possible sums of the array a can be received from all possible sums of weights of these items.Both solutions works in O(n2⋅maxA) where maxA=100, and both solutions can be optimized with std::bitest, speeding up them by 64 times, but it wasn't necessary.

Solution1637E - Best PairIdea: Mangooste.

Hint 1Hint 2Tutorial1637E - Best PairLet's fix x and iterate over cnty≤cntx. Then we need to find maximum y over all elements that occurs exactly cnty times, such that x≠y and pair (x,y) is not bad. To do that, we will just iterate over all elements that occurs exactly cnty times in not increasing order, while pair (x,y) is bad or x=y. If we find such y then we will update the answer.

To check if the pair is bad, just add all pairs into the set, and check is the pair is in the set. Also you can sort all bad pairs and check it using binary search. Both methods works in O(logn).

Iterating over all x and cnty≤cntx works in O(∑cntx)=O(n). And finding maximum y such that x≠y and the pair (x,y) is not bad works in O((n+m)logm) summary, because there are O(n+m) checks if the pair is bad or not. So this solution works in O((n+m)logm+nlogn).Solution1637F - TowersIdea: TeaTime.

Hint 1Hint 2Tutorial1637F - TowersMain solution:

Let's consider all leaves. If v is a leaf, then all paths, which cover v should start in v. Then let's increase heights of all towers in the leaves by 1 (it's necessary) and decrease all hv by 1. Now we should remove all leaves with hv=0 (they will be already covered). We will repeat the operation until there are covered leaves. We will continue the algorithm but instead of increasing height in new leaves of the tree we will increase height in deleted vertexes (in its subtree). If at some point we have only 1 vertex left we should increase height in 2 towers (due to the statement we should use 2 different towers to cover the vertex). To speed up the solution we will sort vertexes by hv and we will store current level of current leaves. On each iteration we will add amount of leaves multiplied by change of level.

If it is not optimal then let's consider heights of towers in the optimal answer. Let f(i) be amount of vertices in optimal answer with height larger or equal to i. It is easy to notice that f(i)−f(i−1) is at least amount of leaves in the tree on i-th iteration. If there is only one vertex left on iteration i then 2=f(i)−f(i−1). That means that the algorithm is optimal.

Alternative solution:

Let root be the vertex with the maximum height. Let's root tree at root. Now there must be two towers in the subtrees of the children of vertex root of height hroot (if there's only one child, then there must be a tower at the vertex root of height hroot). Now we need to place towers in the subtrees of the children of vertex root, such that for for every vertex v the highest tower in the subtree of vertex v (including v) must be at least hv. After it's done you need to select two highest towers in the subtrees of two different child of the vertex root and set their height to hroot.

Now we need to optimally place towers in the subtrees so that for every vertex v there must be a tower in the subtree of vertex v of height at least hv. To do that in the subtree of vertex v, let's recursively place towers in the subtrees of the children of vertex v, and then increase the height of the highest tower in the subtree of v to hv if it's necessary. If vertex v is a leaf then we need to place a tower of height hv in the vertex v.

This solutions can be implemented in O(n). For a better understanding, we recommend you to see the implementation.

SolutionAlternative solution1637G - BirthdayIdea: EvgeniyPonasenkov.

Hint 1Hint 2Hint 3Tutorial1637G - BirthdayThe answer is −1 only if n=2. It will become clear later.

Let all numbers be equal to val after all steps. Consider the moves in reverse order: numbers x and y are obtained from x+y2 and |x−y|2. If numbers x and y are multiples of an odd number p>1, then numbers x+y2 and |x−y|2 are also multiples of p. But after all steps in reverse order, we need to get 1 ⇒ val can't be a multiple of p. It means that val is a power of two. Moreover val≥n because the maximum after all steps in direct order can't get smaller.

Let's show how to make all numbers equal to the smallest power of two which is at least n.

First of all, let's transform numbers 1,2,…,n into the n powers of two (maybe different), but not greater than the answer. Let the function solve(n) do this. It can be implemented as follows:

If n≤2 then all numbers are already a power of two so we can finish the function.if n is a power of two, then call solve(n−1) and finish the function.Otherwise let's p be the maximum power of two not exceeding n. Lets make steps by choosing pairs (p−1,p+1),(p−2,p+2),…,(p−(n−p),p+(n−p)). After that, there will be numbers that can be divided into 3 groups:Numbers that have not been changed: 1,2,…,p−(n−p)−1 and p. p is already a power of two. To transform other numbers into the powers of two let's call solve(p−(n−p)−1).Numbers that have been obtained as |x−y| after some step: 2,4,…,2⋅(n−p). To transform them into the powers of two we can take the sequence of steps that does solve(n−p) and multiply all numbers in these steps by 2.All numers that have been obtained as x+y after some step, are equal to 2p and they are already a power of two.After this transformation, there are always two equal numbers that are smaller than the answer. Let them be equal to x. Let's make a step using them and we will get 0 and 2x.

From numbers 0 and x we can get numers 0 and 2x: (0,x)→(x,x)→(0,2x). So let's just use this 0 to transform all remaining numbers into the answer. After all, let's make a step using 0 and the answer, so 0 becomes equal to the answer.

It is obvious, that this solution works at most in O(n⋅logn). But at such limits it uses at most 7n steps.

Solution1637H - Minimize Inversions NumberIdea: Mangooste.

Hint 1Hint 2Hint 3Hint 4Tutorial1637H - Minimize Inversions NumberTo simplify the explanation, we will represent a permutation as a set of points (i,pi).

Lemma: Let's consider some selected subsequence. Then there always exists such sequence of the same length, so that if we select it instead, the number of inversions won't increase, for which the following condition is satisfied: if the point i is selected, then all points to the right and below point i are also selected.

Proof: Let assume that it's not right, then there is a pair of points (i,j) such that i is selected and j is not, and j is to the right and below point i (the point is selected if it is in the sequence). Let's call such pair a bad pair. Divide the points into 9 regions by 4 straight lines parallel to the coordinate axes passing through the point i and j. No for every point, considering if it is selected or not and considering the region where it is, let's determine by how many it reduces the number of inversions after replacing i with j (i.e. select j instead of i). Let's call it a contribution of this point. Also note that after replacing the point i with the point j, the inversion formed by these two points disappears.

The first integer in each region — the contribution of the point selected there. The second integer — the contribution of unselected one.Note that negative contribution has only selected points, located between the point i and j (on the Ox axis) above the point i, and unselected points located between the point i and j below the point j.

Now let's find any bad pair (i,j) and do the following:

If there is a selected point id, which has negative contribution, then set i=id and continue the algorithm.Otherwise, if there is a unselected point id, which has negative contribution, then set j=id and continue the algorithm.Otherwise, after replacing the point i with the point j the number of inversions will reduce.This algorithm always finds a bad pair such that after replacing i with j the number of inversions will reduce, because each time the value j−i reduces. Q.E.D.

Let di is a number by which the number of inversions will decrease after moving only the element with index i to the beginning. Then di= (the number of points to the left and above i)−(the number of points to the left and below i). Then, if sequence seq is selected, then the number of inversions in a new permutation will be equal to invs−∑i∈seqdi+seqInvs−(|seq|⋅(|seq|−1)2−seqInvs)=invs−∑i∈seqdi+2⋅seqInvs−|seq|⋅(|seq|−1)2. Here invs — the number of inversions in the initial permutation, and seqInvs — the number of inversions over all elements in the seq.

seqInvs=∑i∈seq (the number of selected points to the right and below i). Due to the lemma proved above, if the sequence seq is optimal, then if the point i is selected, then ⇒ all points to the right and below i are selected as well, so if si is the number of points to the right and below i, then seqInvs=∑i∈seqsi. So the number of inversions in the new permutation equals to invs−∑i∈seq(di−2si)−|seq|⋅(|seq|−1)2. Note, that this formula can be incorrect if the sequence is not optimal. In this case point i reduces the number of inversions by ci=di−2si.

Note that the number of points to the left and below i equals to pi−1−si, and the number of points to the left and above i equals to (i−1)−(pi−1−si)=i−pi+si. So di=(i−pi+si)−(pi−1−si)=i−2pi+2si+1. So ci=di−2si=i−2pi+1.

Now it's not hard to see, that if the point j is to the left and below the point i, then cj>ci. So if we select len maximum elements by the value of ci, the formula for the number of inversions written above is correct. It means that it is optimal. It can be implemented in O(nlogn).

Solution

Global Round 18 Editorial

By Monogon, history, 14 months ago, In EnglishI hope you enjoyed the contest!

1615A - Closing The Gap

Author: PurpleCrayon

Tutorial1615A - Closing The GapIf max(a)−min(a) is strictly greater than 1, you can apply the operation on the max and the min respectively, which brings them both closer to each other. In other words, it either decreases max(a)−min(a) or leaves it the same. This implies that the answer is always ≤1. Now what remains is determining whether the answer is 0 or 1. The answer can only be 0 if the sum of the array is divisible by n, as the sum of the array can't change after an operation, and if it's not divisible by n you can't make every element equal. This means that the answer is 0 if the sum is divisible by n, and 1 otherwise.

1615B - And It's Non-Zero

Author: PurpleCrayon

Tutorial1615B - And It's Non-ZeroLet's solve the complement problem: find the largest subsequence of the array such that their bitwise AND is non-zero. Let x be the bitwise and of the optimal subsequence. Since x≠0, at least one bit must be set in x. Let's iterate over that bit, call it b, and in each iteration, calculate the largest subsequence whose bitwise and has that bit set. For the b-th bit to be set in the final answer, every element in the chosen subsequence must have that bit set. Since choosing every element with the b-th bit on is a valid subsequence, this implies that the answer for the b-th bit is the number of elements that have the b-th bit set. Thus, the answer to the final problem is n−max1≤b≤30cntb, where cntb is the number of elements who have the b-th bit set.

Note: it doesn't matter if the final answer contains more than one set bit, it's still covered in at least one of the cases, and the bitwise and will still be non-zero.

All that remains is counting the number of elements in the range [l…r] with the b-th bit set, for all b. This can be done with precomputation, by creating b prefix sum arrays before answering any of the test cases, where the i-th element of the b-th array is the number of integers ≤i that have the b-th bit on. After this, you can use the prefix sum technique to answer queries, as cntb=ab,r−ab,l, if ab is the b-th array.

Challenge: solve the problem with 1≤l≤r≤109.

1615C - Menorah

Author: Monogon

Tutorial1615C - MenorahFirst, let's define the "type" of a candle i to be the string aibi. For example, if a candle is currently unlit and must be lit in the end, its type is 01. It's useful to think about the number of candles of each type because the position of a candle is irrelevant in this problem.

Now, let's consider what happens when we do two operations consecutively. All candles except the ones we select will flip twice, so let's focus on what happens to the candles we select. If we select the same candle twice, nothing changes. And if we select two different candles, it's equivalent to swapping a 1 and a 0 in the string.

Since we have a really nice description of two consecutive operations, any sequence of an even number of operations is just a sequence of swaps. So it's possible in an even number of operations as long as the number of 1's in both strings is the same, and the minimum number of operations will be the number of positions where the strings differ.

Now, what about an odd number of operations? Well, it's the same as performing one operation and then reducing it to the case of an even number of operations. There are two types of candles we can select on the first operation: type 10 and type 11. Simply try both options if they're present, and find the minimum number of operations after it's reduced to the even case.

Finally, there are some strings where it's possible to do in either an even or an odd number of operations, so in those cases we have to take the minimum of both options. The total complexity is O(n).

Bonus: Can you prove that in the case of an odd number of operations, it is never necessary to select a candle of type 10?

1615D - X(or)-mas Tree

Author: PurpleCrayon

Tutorial1615D - X(or)-mas TreeLet count(x) be the number of 1-bits in an integer x. Notice that count(x⊕y)mod2 = count(x)mod2⊕count(y)mod2. This means that you can replace each integer x on the tree with count(x)mod2. Note that you can pretend the initial given edges are also just elves who traveled over the path consisting solely of that edge. After this transformation, each of the edge weights is either 0 or 1, and you're given a set of paths and you are told the XOR of each path.

Root the tree at node 1. Let ri be the XOR of the values on the edges from node i to the root (r1=0). Notice that the XOR of a path (a,b) is ra⊕rb. From this, each constraint of the form (a,b,c) telling you that the XOR of the path (a,b) has to equal c is equivalent to ra⊕rb=c.

This problem can be solved using a variant of bipartite coloring, where you create a graph and add a bidirectional edge between (a,b) with weight c for each of those constraints. You run dfs through each of the individual connected components. Within a component, choosing the value of a single node uniquely determines the rest. During the dfs, if you're at a node a and are considering traversing the edge (a,b,c), you know that rb=ra⊕c, so you can determine rb from ra.

The final value of an edge between a and p (the parent of a) is ra⊕rp.

1615E - Purple Crayon

Author: PurpleCrayon

Tutorial1615E - Purple CrayonAfter expanding the expression given in the statement (by replacing w with n−r−b), it reduces to r⋅(n−r)−b⋅(n−b). This means that in Blue's turn, his only goal is to maximize b⋅(n−b). To maximize the value of that function, it's optimal to pick the value of b that is closest to ⌊n2⌋.

One thing to note is that if it's possible for Blue to color exactly x nodes, for some number x, it is possible for Blue to color exactly x−1 nodes as well. This is because, given some subtree that he has colored, he can also choose to color every node in the subtree except the root. This would reduce the number of Blue nodes by exactly 1. By repeating this process, one can show that if Blue can color exactly x nodes, Blue can also color y nodes if y≤x.

What this implies is that if you know the number of nodes that Red colors, Red's optimal strategy would be to minimize the maximum number of nodes that Blue can color (as it reduces the possible choices that Blue has). If Red chooses node x, it means that Blue can't choose any ancestors (or descendants) of node x. This transforms the problem into the following:

For all i≤k, perform the following operation exactly i times: choose a node v and mark all of the nodes on the path to the root. For each i, calculate the maximum number of nodes that are marked at least once at the end of this process by optimally choosing v at each step. The set of optimally chosen v (for a given i) can be found using the following greedy algorithm:

Sort all nodes in decreasing order of depth.Then, go through the nodes in order, let the current node be v. Go to the root marking nodes until you reach one that has already been marked. Let the number of marked nodes be cv.Finally, sort all nodes in decreasing order of cv. Choose the first i nodes from this list.Proof that the greedy produces the correct answer: We must prove that the greedy algorithm always chooses a subset of nodes that maximizes the number of marked nodes at the end of the process. We can imagine that instead of coloring nodes, we can delete them from the tree to get a forest of rooted trees. Let's prove that there is an optimal solution where the deepest leaf in a forest (say v) is chosen. Consider a configuration in which v is not chosen. Let u be the node that maximizes the depth of LCA(u, v) that is present in the configuration. You can replace the node u with v in the configuration, and the answer won't decrease (as the depth of v is greater than the depth of u). Since the relative order of depths in a tree in the forest at any point is the same as the relative order of depths of its vertices in the original tree, choosing the deepest node in a tree in the forest is equivalent to choosing the vertex in that tree, which has the max depth in the original tree.

Note that the process can be simulated in amortized linear time (not including the sorting), as each node will be colored at most once. All that's left is to iterate over all values of i, and take the maximum value that Red can get.

1615F - LEGOndary Grandmaster

Author: PurpleCrayon

Tutorial1615F - LEGOndary GrandmasterFirst, let's consider a fixed pair of strings s and t, and find a simple way to calculate the amount of time it takes.

Key observation: Flip every bit at an even position in both strings s and t. Now, the operation is equivalent to swapping two adjacent bits of s. This is because the operation is equivalent to flipping two adjacent bits and swapping them. Flipping bits on an even position takes care of the first part of the operation (as any operation includes one bit at an even and one bit at an odd position), so the problem reduces to simple swapping.

Now, for a fixed pair of strings, you want to find the minimum number of swaps to transform one into the other. Obviously, the answer is 0 if the number of 1's in both strings is different. Now, let the number of 1's in each string be k, and the position of the i-th 1 from the left in s be xi, and the i-th 1 from the left in t be yi. The answer for a fixed pair of strings is ∑i=1k|xi−yi|, as the i-th 1 in s will always be matched with the i-th 1 in t.

This expression can be transformed into a more convenient one. Let ai be the number of 1's in s in the prefix ending at i, and bi the number of 1's in t in the prefix ending at i. The previous expression is equivalent to ∑i=1n|ai−bi|. This is because the i-th index contributes 1 to each 1 in the previous expression if and only if a 1 needs to "cross" the i-th index when moving to it's corresponding location in t. Exactly |ai−bi| 1's will cross over the index, so the answer is the sum over all of the values.

Now going back to the original problem, apply the initial transformation on the strings s and t, where for each even index, you change 0 to 1, 1 to 0, and keep ? the same. Let pi,j be the number of ways, if you only consider indices ≤i, to replace the ?'s with 0's and 1's so that ai−bi=j. si,j is defined similarly, except you only consider indices ≥i. Both of these have O(n2) states and O(1) transitions. The final answer is ∑i=1n−1∑j=−nn| j⋅pi,j⋅si+1,−j |.

1615G - Maximum Adjacent Pairs

Author: BledDest

Tutorial1615G - Maximum Adjacent PairsLet's consider each segment of zeroes in our sequence. Each of these segments has either odd or even length.

If a segment has length 2m+1 (it is odd), then it can be used to create m pairs of neighboring elements, and an additional pair for either the number right before the segment, or for the number right after the segment.

If a segment has length 2m (it is even), then it can be used either to create m pairs of neighboring elements, or m−1 pairs of any integers and two additional pairs for the elements that are on the borders of the segment. It's never optimal to match only one of the zeroes in an even segment with the element on the border, because we could just use the segment to create m pairs instead.

Let's build an undirected graph which initially has m=maxi=1nai vertices (one for each integer from 1 to m). Let's add the following edges and vertices to it:

For each integer already having a pair of adjacent elements, add an auxiliary vertex and connect it with the vertex representing the integer.For each 0-segment of even length, add an edge between vertices representing elements on the borders of this segment (we need at most one of these for each pair of elements on the border).For each 0-segment of odd length, add an auxiliary vertex and connect it with vertices representing elements on the borders of this segment (we need at most two of these for each pair of elements on the border).Let's find the maximum matching in this graph using some maximum matching algorithm (for example, Edmonds' blossom algorithm). Let the size of the maximum matching be M. It can be shown that the sum of M and all values ⌊len2⌋ over all 0-segments (where len is the length of the segment) is equal to the maximum number of integers that can have a pair of neighboring elements: for each segment of even length, the edge representing it will either be in the matching (and the segment will create len2+1 pairs), or the edge won't belong to the matching (and the segment will create len2 pairs). For each odd 0-segment, we either match its vertex with a number on its border (so this segment creates len−12+1 pairs), or won't match its vertex (so this segment creates len−12 pairs). The numbers already having a pair of neighboring elements will be processed by the vertices connected only to them, so they get +1 to the size of the matching "for free" and can't be matched with anything else (or will be matched, but won't add +1 for free). The maximum matching can enforce the constraint that each number is counted in the answer only once.

How fast will this solution work? Unfortunately, it can be too slow. The resulting graph can have up to O(n) edges and up to 6002 vertices, so the standard implementation of Edmonds is not sufficient. But there are many different heuristics you can use in this problem to speed up the solution. We used the following one:

Split all vertices into two "parts", the first part will contain the vertices representing the numbers, and the second part will contain all of the other vertices. The edges can connect only vertices from the first part and the vertices from different parts, and there are only up to 600 vertices in the first part.

Let's ignore the edges between the vertices in the first part and find the maximum matching in this graph using Kuhn's algorithm. Then, we claim that if we find the maximum general matching starting from this bipartite matching and improving it, the augmenting paths cannot both start and end in the vertices of the second part (since the number of matched vertices in the second part cannot exceed the maximum bipartite matching). Then we can search for augmenting paths only starting in vertices of the first part in Edmonds (so we need only 600 phases of Edmonds).

Furthermore, we can speed up each phase of Edmonds as follows: if the current size of the matching is M, then we'll visit no more than 2M+2 vertices while searching for an augmenting path; and if we contract each blossom in linear time of its size, each phase will work in O(M2), where M is the current size of the matching (and it cannot me greater than 600).

1615H - Reindeer Games

Author: Monogon

Tutorial1615H - Reindeer GamesLet's try to find a nice lower bound for the answer. Let's denote a requirement of two nodes u and v by a directed edge u→v. We can observe that if there are two nodes u and v such that there's a requirement u→v (or a path of requirements from u to v), then we will need to do at least au−av operations on these two nodes. So, if we can create a list of pairs (u1,v1),…,(uk,vk) with all distinct nodes such that there is a path from ui to vi for all i, then a lower bound of the answer is∑i=1k(aui−avi)Our strategy will be to find the largest possible lower bound of this form, and then construct a solution with exactly that cost (which is therefore the optimal cost). To find an optimal set of pairs, we can set it up as a flow problem. Every directed edge u→v of the original graph will have infinite capacity and a cost of au−av. In addition, we will create two new nodes s and t. For each node u, add an edge s→u with capacity 1 and cost 0, and add an edge u→t with capacity 1 and cost 0.

Compute the maximum cost flow from s to t (the amount of flow doesn't need to be maximized). If there is any node u such that s→u and u→t both have flow, make them both have 0 flow, and this won't change the cost. The flow can be decomposed into paths with distinct endpoints in the original graph. The endpoints are distinct because each node u cannot have flow on both edges s→u and u→t. And the cost of a path beginning in u and ending in v will be au−av (intermediate nodes of the path cancel out when computing the cost). It's also easy to see that any set of pairs has a corresponding flow in the graph with the same cost. So, this flow gives us a way to compute a set of pairs with the maximum lower bound, just like we want.

Now, how do we construct the operations to perform? First, take the edges of the residual flow graph that are not at full capacity. Using only these edges, compute the longest path from s to every node in the graph (where length of a path is the sum of edge costs). Let's say the longest path from s to u is du.

Let's show that bu:=au+du satisfies all requirements. Every requirement u→v is present in the residual graph because it has infinite capacity. So we have that du+(au−av)≤dv, otherwise we could find a longer path from s to v. By moving av to the right side of this inequality, we get au+du≤av+dv, In other words, bu≤bv, meaning this requirement is satisfied.

Let's show that the total number of operations ∑u|bu−au| does not exceed the cost of the flow. It's sufficient to show that for each node u that isn't in one of the pairs, we have bu=au, and for each pair (ui,vi) we have that avi≤bvi=bui≤aui.

For the first part, suppose a node u is unpaired. If du>0, then there is a path from s to u with positive cost, and there is an edge from u to t of 0 cost because it's unpaired, so we've found an augmenting path in the flow graph that will increase the cost. This contradicts the fact that we found the maximum cost flow. On the other hand, if du<0, this contradicts the definition of du since there's an edge s→u of cost 0 which makes a longer path. Therefore, du=0 and bu=au+du=au, as desired.

For the second part, consider a pair (ui,vi). There is a path in the residual graph from vi to ui, so we have dvi+(avi−aui)≤dui. In other words, bvi≤bui. But we already had that bui≤bvi because all requirements are satisfied, therefore bui=bvi. It's impossible to have dvi<0 because there's a longer path with the direct edge s→vi which is present in the residual graph. It's impossible to have dui>0 because it would mean the edge ui→t creates an augmenting path with positive cost. Therefore, avi≤avi+dvi=bvi=bui=aui+dui≤aui, as desired.

In summary, the solution is to build a flow graph, compute the maximum cost flow (which is equivalent to minimum cost flow with all costs negated), and compute the distance values du to construct the solution. The flow can be computed with the potential method in O(nmlogn) time.

Codeforces Global Round 17 Editorial

By Keshi, 15 months ago, In English1610A - Anti Light's Cell GuessingIdea: Anti-Light, Preparation: DeadlyCritic

HintsSolution1610A - Anti Light's Cell GuessingCompleteSolution:

I encourage you to read the Hints and Assumptions before reading this.Let's say the answer is ans. If n==1 and m==1, then there's only one cell, so we don't need any more information, and the hidden cell is that single cell. So for this scenario ans=0.

If exactly one of n or m equals 1, then it's trivial that the answer is greater than 0. Also if we choose the cell (1,1), we can find the hidden cell. So for this case ans=1.

Now assume 2≤n and 2≤m, if you choose (1,1) and (n,1) then let's say the distance from (1,1) to the hidden cell is b1 and the distance from (n,1) to the hidden cell is b2. Then if the hidden cell is (i,j) then b1=i−1+j−1 and b2=n−i+j−1 so b1+b2=n−1+2j−2 so we can find j. After finding j we can find i using b1=i−1+j−1. So the answer is at most 2.

Now we proof 2≤ans, trivially 0<ans, but why ans≠1?. Assume someone chose a cell (i,j) and they could distinguish all the n⋅m possible hidden cells. It's easy to see that at least 3 of the 4 cells (i,j−1), (i+1,j), (i−1,j) and (i,j+1) exist in the table, but their distance from (i,j) is 1 for all 4 of them, so we can't distinguish them, so ans=2.

Time complexity: O(1)Implementation1610B - Kalindrome ArrayIdea: Davoth, Keshi, Preparation: AmShZ, Keshi

HintSolutionRead the Hints and Assumptions before reading this.

1610B - Калиндромный массивIf the array is already a palindrome the answer is Yes. Otherwise, let's find the minimum i that ai≠an+1−i.

We can prove that we have to remove either ai or an+1−i in order the make the array palindrome.

Imagine it's possible to make the array palindrome by removing all appearances of x. x≠ai,an+1−iThe number of appearances of x before i is equal to the number of appearances of x after n+1−i. So in order to make the array palindrome, ai must be equal to an+1−i.

So we just have to check if the array will be palindrome after removing all appearances of ai or after removing all appearances of an+1−i.

Time complexity: O(n)Implementation1610C - Keshi Is Throwing a PartyIdea: Keshi, Preparation: Keshi

HintsSolutionRead the Hints and Assumptions before reading this.

1610C - Кеши устраивает вечеринкуTake a look at this greedy approach.

Let pi be the i-th poorest invited person.(pi<pi+1)

Find the poorest person v that x−1−av≤0≤bv. We will invite this person so p1=v.

For each 2≤i≤x find the poorest person v that v>pi−1 and x−1−av≤i−1≤bv this means that person v can be the i-th poorest invited person.

Imagine we fail to find x people but there is a way to do so. The solution chooses s1,s2,…,sx.

for each i we chose the minimum pi possible, therefor pi≤si. But if our algorithm fails there must exist an index i that pi>si.

So our algorithm is correct.

Time complexity: O(nlogn)Implementation1610D - Not Quite LeeIdea: DeadlyCritic, Preparation: DeadlyCritic

HintsSolution1610D - Not Quite LeeCompleteSolution:

I encourage you to read the Hints and Assumptions before reading this.Assume we have an array c of length k, need to know if it's good or not. We can choose an initial sequence ti for all 1≤i≤k, then slide them (in other words, choose an index i and increase or decrease all the elements in the i-th sequence, keep doing this as many times as you need) that way we can reach any other possible set of sequences that satisfy the first property, so it doesn't matter what we choose as initial sequences, because from any set of k sequences that satisfy the first property, we can reach any other such set of k sequences.

After that, if ∑i=1ksumi=s, we want to find such xi-s that ∑i=1kxici=−su so after sliding i-th sequence |xi| times to the right(or left if xi is negative) for all i, we will have a set of sequences that satisfy both the properties.

Now to do that, one can prove if gcd(c1,c2,…,ck)=g, then if g divides s, the array is good, otherwise it's not (I won't prove it because it's quite well-known and easy).

If we choose the initial sequences such that the i-th sequence starts from 0 and ends with ci−1, then s=∑i=1kci(ci−1)2. Now we want g to divide s. If g is odd, then it will always divide s because it divides ci2. From now on we assume g to be even.

One can prove that if 2l divides g and 0<l is maximum such integer, then g2l (which is odd) divides all ci2, so s is divisible by g2l. So we should only check if 2l also divides s or not.

If 2l+1 divides some ci, then 2l divides ci(ci−1)2 for that i as well. Also if 2l+1 doesn't divide ci, we knew that 2l divides ci (because 2l divides g and g divides ci) so 2l−1 divides ci2 but 2l doesn't, also ci−1 is odd. So ci(ci−1)2 has a reminder equal to 2l−1 modulo 2l. All the other terms ci(ci−1)2 were divisible by 2l except these, so if the number of such ci-s is even, then their reminders sum up to 0 modulo 2l then c is good, and not otherwise.

To solve the actual problem, we can fix l, maximum power of 2 that divides g, now we only care about how many ci-s are divisible by 2l (let's say x such ci-s, also if x<2 then we should skip this l because we need at least 2 such ci-s to have an array with that l), and how many are divisible by 2l+1 (let's say y such ci-s).

Now there are 2x possible subsequences such that 2l divides g (including the empty subsequence), but some of them may have an odd number of ci-s not divisible by 2l+1, it's easy to see that half of them have an even number of such ci-s, still, for 2y of them, 2l+1 divides g as well (which is not what we want. Also includes the empty subsequence). So we have 2x−1−2y subsequences with that l (doesn't include the empty subsequence).

Then we sum up this for all possible l, also don't forget to count l=0 separately (i.e. g is odd).

Time complexity: O(nlog(109))Implementation1610E - AmShZ and G.O.A.T.Idea: AmShZ, Preparation: AmShZ

HintsSolutionRead the Hints and Assumptions before reading this.

1610E - AmShZ and G.O.A.T.We build the longest good subsequence starting with as greedily step by step.

In each step we add the smallest possible element to the subsequence. If the last element is ak, we have to find the minimum i that i>k and ai≥2⋅ak−as. (using lower_bound)

Assume b1≠b2, then k<log(an)). Because for each i, bi+1≥2⋅bi−b1 then bi+1−b1≥2⋅bi−2⋅b1 then bi+1−b1≥2⋅(bi−b1).

And for cases that b1=b2, +cnti. (cnti being the number of occurrences of element i)

So for each i that ai≠ai−1 we do the above greedy approach. We don't need to do it for indices that ai=ai−1 since adding ai−1 to the longest subsequence starting from ai doesn't make it bad.

Time complexity is log(n)⋅∑ai≠ai−1cnti+log(an)≤log(n)⋅(n⋅log(an)+∑ai≠ai−1cnti)≤log(n)⋅(n⋅log(an)+n).

The overall time complexity will be O(n⋅logn⋅logan)Implementation1610F - Mashtali: a Space OddyseyIdea: AliShahali1382, Preparation: AliShahali1382

HintSolutionRead the Hints and Assumptions before reading this.

1610F - Маштали: космическая одиссеяIf there is a vertex v connected to its neighbors x and y with same edge weights, we delete these edges and add a new edge between x and y. So the number of edges decreases by 1.

Now we solve the problem for our new graph recurrently.

Then we check whether the assigned direction is from x to y or from y to x. In the first case, we should delete this edge and add a directional edge from x to v and from v to y. Otherwise, after deleting the edge we add a directional edge from y to v and from v to x.

After these changes, for every v, d+(v)−d−(v) will not change.

However if there is no such vertex, the graph contains some paths and cycles in which the weight of each path and cycle is 1 or 2 every other one.

So we can direct edges of each cycle to produce a directed cycle and do the same thing for edges of each path in order to make a directed path.

By doing this, every v with odd cv will become Oddysey.

Implementation1610G - AmShZ Wins a BetIdea: AmShZ, Keshi, Preparation: AmShZ, Keshi, alireza_kaviani, AliShahali1382

HintsSolutionRead the Hints and Assumptions before reading this.

1610G - AmShZ выиграл париMake a rooted tree. Each suffix has a node and except for the root, each node belongs to a suffix. Each edge has a character written on it. "(" or ")"

The answer for each suffix can be obtained by moving up from it's node to the root and concatenating the characters. (kind of like an upside-down Trie)

Now we need to be able to compare answers of two suffixes.

For each node v and for each i≤log(n) store hash of the path of v to it's 2i-th ancestor in h[v][i].

In order to compare two nodes v and u, find the smallest i that the i-th character of them differ. Then we can determine which one is lexicographically smaller. And we use binary lifting to find that i.

The root of the tree is called node n+1.

Iterate i in decreasing order.Assign node i+1 to be the parent of node i.If currently ansi<ansnxti, assign nxti's parent to be i's parent with the same edge character as nxti. (You could also make nxti to present both of them. In order to do this, for each suffix you need to store which node is storing it's answer.)And then you have calculate the answer by moving up the tree.

Time complexity: O(nlogn)Implementation1610H - Squid GameIdea: Tet, AliShahali1382, Preparation: AliShahali1382

Solution1610H - Игра в кальмараA player gets eliminated iff (xi,yi) is a cross-edge while rooting the tree from where Mashtali sits. we say a vertex is marked if Mashtali choses it in a move.

Lets solve the problem in polynomial time. First, lets fix one of the marked vertices and root the tree from it. Then all cross-edges are already covered and we have a set of back-edges to cover. Then, we can use this greedy approach: At each step, take the lowest uncovered back-edge and mark the second highest vertex in its path.(the highest one is either xi or yi which is not allowed) You can prove its correct using the fact that there is no lower back-edges, so if we mark a higher vertex all vertices that were marked before, are marked now.

So far the complexity is smth like O(n3). But we can use fenwick-tree to check whether an edge is covered or not. Which leads to a O(n2⋅log(n)) solution.

Now, let's forget about fixing one of the moves! let's just make the tree rooted at 1, ignore all cross-edges, and do the previous solution. Finally, check if there is an uncovered cross-edge. If so, just put a token on 1.

Now, why is that correct? if all cross-edges are covered, everything is ok. So we just need to show we need more marked vertices if a cross-edge is uncovered. If that happens, it means all our tokens are either in subtree of xi or in subtree of yi. Since we put our tokens at highest possible nodes, there is no vertex that would mark the cross-edge and a back-edge with it. So, we need to mark at least one more vertex and the root, suffice. time complexity: O(n⋅log(n))Implementation1610I - Mashtali vs AtCoderIdea: AliShahali1382, Preparation: AliShahali1382

Solution1610I - Mashtali vs AtCoderFirst, please read the atcoder editorial for the k=1 case. Now, I just say how to calculate the grundy for greater k and prove later:

Lets color all vertices that lie on the path between a pair of pinned vertices as black.(And others as white) Now, lets call an edge black if it connects two black vertices, And call an edge gray if it connects a black vertex to a white one. Now: grundy=xor of grundy of all gray edges xor parity of number of black edges. And that can be calculated when a new pinned vertex is added, move to the root and re-color all white edges as black.

complexity: O(n)And the proof: We should prove that all lesser grundies are reachable and the grundy itself is not. The second one is easier. You either remove a white/gray edge, in which case the grundy changes because exactly one of the gray edges, changes its grundy. Otherwise, we remove a black edge, in which case you can show the parity of grundy changes(this one is easy to prove and left for the reader).

Now to prove all lesser grundies are achievable: First, If there was an even number of black edges, we can see our game as NIM on grundies of white edges. Also, If the lesser grundy we want is differs in the current grundy in not only the 0'th bit, Again we can choose one of the gray edges and perform our move in its subtree. So, we have odd number of black edges and we want to remove a black edge such that **even** number of black edges remain(note that some black edges may turn into white and gray ones.) And xor of grundy of gray edges in result tree = xor of grundies of gray edges in original tree. You can see that proving this suffice.

Imagine we have proved for k=2 case. For 3≤k we use induction on k. If there was a pinned vertex with more than 1 black neighbour, We can cut the tree from that vertex(decompose edges to some components with this vertex appearing in all of them) and use induction on the independent components. Otherwise, the pinned vertices are leaves of the subtree of black vertices. (And we have at least 3 leaves.)

lets decompose black edges to maximal paths such that the middle vertices of each path each have exactly 2 black neighbours. (In other words, lets say we merge black vertices of degree 2. now each merged edge is one of our paths.) Also note that by decomposing, we dont ignore the gray edge subtrees! For each gray edge we assign it to its black vertex from arbitrary path.(A black vertex could appear in more than one path.)

Since we have an odd number of black edges over-all, There is a path of odd length. Lets take a random odd path and call it special.(Let u,v be its endpoints.)

Here a sample subtree of black vertices is drawn. Adjacent edges that belong to same path have same color, And for example the green path is special.Now, we solve the k=2 case on the uv path. It removes a black edge and splits the tree into two components. Use induction on both trees. So, we can imagine vertices u and v are pinned after cutting the edge! And, while solving the k=2 case on uv path, we had the same condition. This shows that if an edge on the uv path has our condition only on this path, It also suffice for what we wanted to prove!

So, the only thing that remains to prove is the k=2 case.

Implementation

Codeforces Global Round 16 Editorial

By Artyom123, 18 months ago, translation, In EnglishWe hope that you enjoyed the contest. Let's get right into the editorial:

A: Median Maximization1566A - Median Maximization

First solutionHint 1Hint 2Hint 3EditorialLet's consider the array of n elements in non-decreasing order. We can make numbers before the median equal to zero, after that we have m=⌊n2⌋+1 numbers, which sum should be n and the minimal of them (i.e. median value) should be maximized.

To do so, it is enough to make all these numbers equal ⌊sm⌋, and then add what's left to the last number (smodm). It's easy to see that such array matches all the conditions and it is impossible to make median greater.

Implementation (C++, shishin)Implementation (Python 3, shishin)Second solutionHint 1Hint 2Hint 3EditorialLet's run a binary search for the answer. This will work because if the answer M then we can decrease the median element by d and add d to the max element, so we can get any median element from 1 to M, but we can't get more than M. In the binary search we will use the greedy technique. All numbers less than the median can be 0 and all numbers from the median should be at least M. So there are m=⌊n2⌋+1 numbers and each of them should be at least M and we find the M using the binary search. Number M is reachable if M⋅m≤s because we can add s−M⋅m to the maximal number and the median will be M. Otherwise, the median element can not be M.

Implementation (C++, shishin)Implementation (Python, shishin)B: MIN-MEX Cut1566B - MIN-MEX Cut

Hint 1Hint 2Hint 3EditorialThe answer is never greater than 2, because MEX of the whole string is not greater than 2.

The answer is 0 only if there are no zeroes in the string.

Now we need to understand, when the answer is 1 or when it is 2. The sum of MEX is 1 only if all zeroes create a single segment without ones. Then we can cut this segment out, its MEX is 1, everything else is ones, their total MEX is 0.

If the zeroes do not create a single segment without ones, the there are two such zeroes that there is a 1 between them. Then either these zeroes are in a single segment with the 1, so total MEX is not less than 2 or these zeroes are in different segments and the answer is still not less then 2.

Implementation (C++, shishin)Implementation (Python, shishin)C: MAX-MEX Cut1566C - MAX-MEX Cut

First solutionHint 1Hint 2Hint 3EditorialLet's solve the same problem but for a string:

It's needed to cut a binary string into segments so that each its element is in exactly one segment and the sum of MEX for all segments is maximal.

Initially we will say that the string is cut into segments of length 1. Then the answer is the number of zeroes in the string. After that the answer is increased every time we merge a segment of 0 with a segment of 1. Each such merge increases the answer by 1. Let's make the merges greedily, maximizing the number of merges. Let's consider the first zero. If the previous element is a 1, let's merge them and consider the next zero. Else, if the next element is a 1, let's merge them and consider the next zero. Else, the next element is a zero and we should consider it instead of the current zero the same way. By doing so we get the answer as the number of zeroes + the number of merges.

Now let's solve the initial problem. We can cut out the columns that contain both 0 and 1, because their MEX is already maximized and the answer will not become worse.

Now we solve the problem for all remaining bi-tables independently. Each their column consists either only of 0 or only of 1 so both rows are equal. We will solve the problem for one row of each remaining bi-table as mentioned before and then sum up the values to get the answer.

Implementation (C++, shishin)Second solution (two similar solutions)This problem could be solved in many ways using the dp. We will consider these solutions in short.

Let's say that dpi — is the answer for a prefix until i. Then there are different approaches:

We can calculate the dp values, iterating through all possible MEX values on the last segment. For example, if we want to make MEX equal 2 on the last segment, then we need to find the closest 0 and the closest 1 to position i. Let it be last0 and last1. Then we should recalc the dp like this dpi=max(dpi,dpj−1+2), where j=min(last0,last1), because we take the shortest segment ending in i which has both 0 and 1 and after that we add the answer for this segment and for prefix that ends in j−1.

Implementation(C++, kpw29)Another possible solution with dp is based on the fact that we should not take any segments with length more than x, where x is some small number. We can just take some random big enough x and not prove anything. There exists a solution which does not consider segments with length bigger than 5.

Implementation (C++, physics0523)D: Seating Arrangements1566D2 - Seating Arrangements (hard version)

Hint 1Hint 2Hint 3EditorialLet's consider all seats in increasing order of their indices. For each seat we can consider the level of sight of a person that takes that seat. The considered sequence is non-decreasing. This means that people with the same level of sight should take consequent seats and for each level of sight x we can determine which seats will be taken by people with level of sight x.

Now we should find out how do people with level of sight x sit in the cinema. For that x we know that people with that level of sight should take places with indices from l to r.

Let's seat people with the same level of sight greedily. If all places from l to r are in the same row, then we should seat people in decreasing order of seat indices. Otherwise, these seats form a suffix of some row (maybe empty), some full rows (maybe zero), a prefix of some row (maybe empty). Firstly we need to seat people on the suffix in decreasing order of seat indices. This is not worse than other seatings, because the seats before that suffix may be taken in future and total inconvenience will increase. Seats on the prefix should be taken last of all in decreasing order of seat indices. This is not worse than other seatings, because if some people sit on that prefix then they will bother people on the right, increasing the total inconvenience. Full rows should be taken in decreasing order of seat indices, this does not increase the total inconvenience at all. So we should start by seating poeple on the suffix, then we should cover full rows and finally we should cover the prefix. In each case places should be taken in decreasing order of seat indices.

The constraints for m are low, so each time we want to seat someone we can consider all places in the row and find how many people increase our inconvenience.

Implementation (C++, pashka)E: Buds Re-hanging1566E - Buds Re-hanging

Hint 1Hint 2Hint 3EditorialIf we re-hang a bud from its parent to the root, the amount of leaves either doesn't change (if the parent has other children), or increases by 1. By doing that we don't make the answer worse, because if there are leaves except for bud's leaves, then we can re-hang the bud to some leaf, decreasing the amount of leaves by 1. So let's re-hang all buds to the root, until there are no free buds left.

Now we will assume that all buds are hung to the root, and their amount is k. The answer is either n−2⋅k if there is no leaf, hung to the root, or n−2⋅k−1 if there is a leaf, hung to the root. Why is it so? Initially, there are n−k−1 leaves (total amount of nodes — the amount of buds — root). If there is a leaf, hung to the root, then we can hang a bud to it, then hang a bud to the previous bud's leaf, and keep doing so until we use all k buds. Then there are k re-hangs, each of them decreases the answer by 1. So the final answer is n−k−1−k=n−2⋅k−1. If there is no leaves hung to the root, then we can hang a bud to another bud's leaf, then a bud to the previous bud's leaf, and so on until we use k−1 buds. The final answer in this case is n−k−1−(k−1)=n−2⋅k. It is not possible to make the answer less, because each re-hang decreases the answer by \le 1 and each re-hang we make decreases it exactly by 1 and we use all re-hangs.

Implementation (C++, shishin)F: Points Movement1566F - Points Movement

Hint 1Hint 2Hint 3Hint 4EditorialFirstly, if a point has initially visited some segment, then we can throw it out of consideration. It means that all segments that cover at least one point can be thrown out. This can be done using the binary search for each segment separately.

Secondly, if a segment A is contained in a segment B (i.e. lB≤lA≤rA≤rB), then a point that visited A will visit B, too. It means that we should save only those segments that do not contain any other segments.

This can be done using a Fenwick tree. Initially, all values in the tree are zeroes. We will consider the segments in decreasing order of l. Let's assume we are considering segment i. If there is an already considered segment j (rj≤ri), then segment j is in segment i. It is so because li≤lj because of the considering order, so li≤lj≤rj≤ri. To find the amount of such j it is enough to find the amount of 1 on a prefix until ri in the Fenwick tree. Now when we considered the segment i we set 1 in the Fenwick tree on position ri.

After that there are only segments that do not contain any other segments and they are not initially visited by any point. We will consider only these segments.

Let's say that a segment is assigned to a point if that point visits this segment. Let's find out how to calculate the answer for one point if we already know the set of segments that are assigned to it. Let's consider the segments that are on the left to the point and say that the maximal distance from the point to these segments is a. In the same way let b be the maximal distance from the point to the segments on the right. Then the answer for the point is 2⋅min(a,b)+max(a,b).

Now if a segment is between two neighbouring points, then it should be assigned to one of these points. (If a segment is to the left from the leftmost point or to the right from the rightmost point then it should be assigned to the leftmost point or to the rightmost point respectively). Now let's consider the segments between two neighbouring points. These segments are ordered by the left ends and by the right ends at the same time. Some prefix of these segments should be assigned to the left point, other segments (suffix) should be assigned to the right point.

Now let's solve the problem using the dynamic programming. Let dp[i][j] be the answer if we assigned the segments for first i points and there are j segments assigned to the i-th point that are to the right from it. There is a linear amount of dp states. Let's learn to calculate the dp. We will consider the dp states in increasing order of i and, after that, j. Let b be the distance from i-th point to j segment after it. Then dp[i][j]=min0≤k≤x(dp[i−1][k]+2⋅min(b,ai,k)+max(b,ai,k)), where ai,k — is the distance from i-th point to (k+1)-th segment after (i−1)-th point and x is the amount of segments between points i and (i+1). But this is a quadratic dp. Now we can find out that for some prefix of segments after (i−1)-th point ai,k is greater than b and for some suffix it is less than b. The length of that prefix may be found using the binary search or two pointers. For k on that prefix the dp will be dp[i−1][k]+xi−rk+1+2⋅b, and for k on the suffix — dp[i−1][k]+2⋅(xi−rk+1)+b. In these formulas everything except b depends on i and k. It means that we can calculate dp quickly using prefix and suffix minimums.

The answer is dp[n][x], where x is the amount of segments to the right of the rightmost point.

Implementation (C++, Artyom123)G: Four Vertices1566G - Four Vertices

Hint 1Hint 2Hint 3EditorialObservation: the answer always consists either of three edges that have one common end or of two edges that do not have any common ends.

To find the answer of the first type it is enough to maintain three minimal edges for each vertex.

To find the answer of the second type we will use this observation: we can leave in the graph only those edges that are in the set of three minimal edges for each their end. Let's prove that. Let's assume that the answer consists of two edges (a,b) and (c,d) and there are at least three edges (a,a1), (a,a2), (a,a3) less than (a,b). Then the edge (a,b) can be swapped by one of these edges because at least one of te integers a1, a2, a3 is not equal to c and d. Then we will maintain the set of all these edges.

Now let's consider two cases. Let (a,b) be the minimal edge. If it is in the answer then we need to find the minimal edge, that does not have any common vertices with (a,b). In this case there are at most 6 ``bad'' edges because the degrees of each vertex in the graph that consists only of remaining edges do not exceed 3. It means that we have to consider O(1) variants. If (a,b) is not in the answer, then there are two edges in the answer that have vertices a and b as one of their ends. But there are at most 9 such pairs of edges, so we have to consider only O(1) variants.

So the final answer is the minimum of answers of both types.

Implementation (C++, Kirill22)H: Xor-quiz1566H - Xor-quiz

Hint 1Hint 2Hint 3Hint 4EditorialLet f(x) be the multiplication of all prime divisors of x. Then let's make queries for all such y that there is at least one such x, 1≤x≤C and f(x)=y. For such constraints there will be at most ⌈0.65⋅C⌉ queries.

Let's group all numbers by f(x). All numbers in one group in any query will be considered together. Let ans(x) be the answer for the query with number x and g(x) be the xor of all number that are not coprime with x. Then g(x)=ans(x)⊕ans(1). Now let's find out how to calculate the xor of all such x that f(x) is divisible by an arbitrary y. Let's take xor of all g(k) where k is a divisor of y greater than 1. Let's prove that by doing that we will get the needed value. If f(x) is divisible by y then such x will be considered 2l−1 times, where l is the amount of prime divisors of y. It means that x will be contained in the final value. Now let's prove that there will be no unintended x values. Let f(x) be not divisible by y. It means that there is suche prime p that y is divisible by p and x is not divisible by p. Then for each divisor a of y that is divisible by p we will assign b=a/p. Then such x will be considered either for both a and b or for none of them. It means that it will be considered an even amount of times. Now to find the xor of all numbers with an arbitrary f(x) we need to consider all x from C to 1 and make f(x)=f(x)⊕f(2x)⊕f(3x)⊕….

Now we only need to find n distinct numbers from 1 to C such that xor of numbers in each group is equal to a specific number. For each group of numbers with given f(x) we will start the Gaussian elimination. Let k be the size of a group and after the Gaussian elimination there are b non-zero numbers. Then if b=k there is a single way to obtain the needed xor. Else there are 2k−b ways to obtain the needed xor. Now let's take some random sets of numbers with the needed xor and calculate dp on these numbers to get take exactly n numbers. If there are several ways we can choose any of them.

Implementation (C++, Artyom123)Who did what?Problem AIdea: shishyandoPolygon: shishyandoEditorial: shishyandoProblem BIdea: shishyandoPolygon: shishyandoEditorial: shishyandoProblem CIdea: shishyandoPolygon: shishyandoEditorial: shishyandoProblem DIdea: Artyom123Polygon: Artyom123Editorial: Artyom123Problem EIdea: shishyandoPolygon: shishyandoEditorial: shishyandoProblem FIdea: Artyom123Polygon: shishyandoEditorial: shishyando + Artyom123Problem GIdea: Artyom123 + isaf27Polygon: tests: Artyom123 + other: shishyandoEditorial: Artyom123Problem HIdea: Artyom123 + isaf27Polygon: shishyando + Artyom123Editorial: Artyom123English translation: shishyandoEdits on Polygon, common enhancements: KAN, isaf27, MikeMirzayanov

Editorial of Global Round 15

By cip999, 19 months ago, In EnglishWe hope you liked the problems! Before we go ahead with the editorial, let us make some general comments about this round.

Problems A, B, C, D, E, F are "div 2" problems, while problems G, H, I are meant to be solved by Grandmasters. Overall, our goal was to provide a problemset that could be enjoyable for a wide range of participants and such that the winner could solve all the problems.

There were three big "jumps" in the difficlty gaps between consecutive problems. Problems A and B are meant to be easy, many contestants have the skills and the techniques to attack them (and, maybe, to solve them). Problems C, D, E, F are gradually harder but the difficulty gap between C and F is not as large as usual (and this is reflected in the score distribution). The same holds for problem G, H, I; the difficulty gap between G and I is relatively small (but there is a big score difference because coding I is much harder). Sadly, we discovered 14 minutes into the round that problem I has already appeared in a contest (most likely also in Polish contest, if you know it please tell us in the comments). See also this comment.



Pre-contest predictions

Detailed overview on the problemset and a bit of behind-the-scenes

Which author did what?

Some thoughts from cip999

Hints and solutions

AHint 1.Hint 2.Hint 3.Solution1552A - Subsequence PermutationLet sort(s) be s sorted alphabetically. The answer to the problem is the number m of mismatches between s and sort(s) (i.e., the positions with different characters in the two strings).

Choosing k=m characters is sufficient. Let us choose the mismatched characters between s and sort(s), and permute them so that they are sorted alphabetically. It is not hard to prove that the resulting string will coincide with sort(s).

Choosing strictly less than m characters is not sufficient. If k<m, by the Pigeonhole Principle at least one of the mismatched characters will be left out, and thus it will prevent the final string from being ordered alphabetically.

Complexity: O(nlogn).

Implementation

BHints for Solution 1Hints for Solution 2Solution1552B - Running for GoldSolution 1

First of all, observe that athlete i is superior to athlete j if and only if athlete j is not superior to athlete i.

The issue is, of course, that we cannot iterate over all pairs of athletes as there are (n2)=O(n2) pairs, which is too much to fit in the time limit.

Notice that there can be at most one athlete who is likely to get the gold medal (if there were 2, one would not be superior to the other which is a contradiction).

Let us describe the algorithm. We iterate over the athletes from 1 to n, keeping a possible winner w.

When we process i, we check whether w is superior to i. In that case, clearly i is not the one who is likely to get the gold medal and we do nothing. On the other hand, if i is superior to w, we deduce that w cannot be the athlete who is likely to get the gold medal. In this case, we assign w:=i and we proceed.

Notice that, when we have finished processing athletes, if there is an athlete superior to everyone else it is for sure w. Finally, we check whether w is superior to everyone else or not.

Complexity: O(n).

Solution 2

Let us describe a randomized solution which seems very naive but can actually be proven to have a good complexity (still, the proof is much harder than an optimistic guess). There are many other possible randomized approach which can be proven to have a correct complexity with a similar proof.

For each athlete i check whether he is superior to all other athletes, iterating over other athletes in a random order, and stop as soon as you find an athlete who is superior to i.

Let us show that the described algorithm has complexity O(nlogn).

Consider an athlete i who is superior to exactly n−1−k other athletes. Let us compute the expected amount of other athletes the algorithm processes when deciding if athlete i is likely to get a medal.

If k=0, the algorithm iterates over all other n−1=O(n) athletes.If k≥1, the expected number of other athletes the algorithm iterates over is O(nk). To prove this, one shall observe that if we take k random distinct elements out of {1,2,…,n} the expected value of the smallest one is O(nk).So, the overall complexity of the algorithm is:O(q0⋅n+∑k=1n−1qknk)=O(n(q0+∑k=1n−1qkk)),where qk is the number of athletes who are superior to exactly n−1−k other athletes.

If we let sk=q0+q1+⋯+qk, we can also estimate the complexity withO(n(s0+∑k=1n−1sk−sk−1k))=O(n(∑k=1n−2skk(k+1)+sn−1n−1)).It remains to estimate sk and the following lemma does exactly this.

Lemma. For each k≥0, there are at most 2k+1 athletes which are superior to at least n−1−k athletes.

Proof. Assume that there are m athletes who are superior to at least n−1−k other athletes. Consider the complete directed graph on these m athletes so that the edge i→j is present if and only if athlete i is superior to athlete j. Each vertex has out-degree ≥m−1−k and therefore the number of edges is at least m(m−1−k). On the other hand, the number of edges is clearly (m2) and therefore we obtainm(m−1−k)≤m(m−1)2⟹m≤2k+1as desired.

The lemma tells us that sk≤2k+1 and therefore the complexity is estimated byO(n(∑k=1n−22k+1k(k+1)+2n−1n−1))=O(2n∑k=1n−21k)=O(nlogn).Complexity: O(nlogn), randomized.

Implementation of Solution 1Implementation of Solution 2

CHint 1.Hint 2.Hint 3.Solution1552C - Maximize the IntersectionsLet us forget about the original labeling of the points. Relabel the 2(n−k) "free" points 1,2,…,2(n−k) in clockwise order, starting from an arbitrary point. Also, in the following, we will color black the original k chords, and red the additional n−k chords.

For 1≤i≤n−k, connect point i to point i+n−k with a red chord. We shall prove that this configuration — which we will henceforth refer to as the star configuration — is the only one that achieves the maximum number of intersections. The proof will be divided into two parts.

First part: we show that, if there are two red chords that do not intersect, it is possible to increase the number of intersections.Second part: we show that there is exactly one configuration in which all pairs of red chords intersect, namely the star configuration.First part. Suppose that, after drawing n−k red chords, there is a pair of red chords that do not intersect. Let these chords connect points a—b and c—d respectively. Without loss of generality, assume that the chords a—d and b—c intersect. We show that, by replacing chords a—b and c—d with a—d and b—c, the overall number of intersections increases.

Consider any other chord (either black or red) that intersected exactly one of a—b and c—d. It is easy to see that, in the new configuration, that chord intersects exactly one of a—d and b—c, as exemplified in the following picture:

(There would actually be four cases to consider, but one can see that they are symmetric.)Now consider any other chord (either black or red) that intersected both a—b and c—d. Again, one can see that, in the new configuration, that chord intersects both a—d and b—c:

Since all previous intersections are preserved, and there is at least one new intersection (the one between a—d and b—c), the total number of intersections has increased.Second part. Consider a configuration that is not the star configuration. Then, there is at least one chord a—b (a<b) such that b≠a+n−k. Without loss of generality, suppose a=1.

Now, exactly one of the two sets of points {2,…,b−1} and {b+1,…,2(n−k)} must contain at least n−k points. By the Pigeonhole Principle, there must be a chord whose endpoints are both contained in this set, and one can see that such a chord does not intersect a—b.

Thus we have shown that the star configuration is the only one in which all pairs of chords intersect, which implies (from the first part) that it is the only one that maximizes the number of intersections.

Producing the n−k chords of the star configuration is trivial. It remains to count the number of intersections, which can be done naively in O(n2) (for each pair of chords, check if they intersect).

Bonus: Find an O(nlogn) algorithm to count the number of intersections.

Complexity: O(n2).

Implementation

DHint 1.Hint 2.Hint 3.Hint 4.Solution1552D - Array DifferentiationSuppose that a solution b1,…,bn exists. For each 1≤i≤n, let ji,ki be the indices such that ai=bji−bki.

Consider the directed graph on vertices 1,…,n, with the n edges ji→ki. If we ignore, for a moment, the orientations, we are left with an undirected graph with n vertices and n edges, which must contain a cycle (possibly a loop). Let m be the length of one such cycle, and let v1,…,vm be its vertices.

Now, of course (bv1−bv2)+(bv2−bv3)+⋯+(bvm−bv1)=0, since all the terms cancel out. Notice that, for each i, there exists 1≤ti≤n such that (indices are taken modulo m, so that vm+1=v1)bvi−bvi+1={ati−atiif there is an edge vi→vi+1,if there is an edge vi←vi+1.Thus, there must be a nonempty subset {t1,…,tm}⊆{1,…,n} and a choice of signs s1,…,sm (si∈{+1,−1}) such thats1at1+⋯+smatm=0.(⋆)Let us show that this condition is also sufficient for the existence of a valid sequence b1,…,bn. Suppose there exist m, t1,…,tm and s1,…,sm so that (⋆) holds. We construct b1,…,bn as follows. Set bt1=0. Then, inductively, for each 1≤i<m set bti+1=bti−siati. Finally, for i∉{t1,…,tm}, set bi=ai. It is easy to check that this construction works.

The algorithm that iterates over all 3n−1 choices of the subset and the signs (for each i we decide whether ai is included in the subset and if it is included, whether its sign is positive or negative) and checks if for one of them (⋆) holds, is sufficient to solve the problem under the given constraints.

Alternatively, one may treat the problem as a knapsack instance (the weights are ai, but can be chosen with arbitrary sign, and we shall understand whether we can fill precisely a knapsack with 0 capacity). With this approach, the complexity is O(n2max|ai|).

Bonus: Solve the problem with complexity O(n3n2).

Complexity: O(n3n).

Implementation

EHints for Solution 1Hints for Solution 2Solution1552E - Colors and IntervalsSolution 1

We describe the algorithm and later we explain why the construction works.

Let xi,j (1≤i≤n, 1≤j≤k) denote the position of the j-th occurrence of color i (from the left).

First, sort the colors according to xi,2. Take the first ⌈nk−1⌉ colors, and to each of them assign the interval [xi,1,xi,2]. Then, sort the remaining colors according to xi,3, take the first ⌈nk−1⌉ and to each of them assign the interval [xi,2,xi,3].

More generally, in the t-th step: sort the remaining colors according to xi,t+1; take the first ⌈nk−1⌉ (possibly less in the last step) of these colors; assign to each color i the interval [xi,t,xi,t+1].

Let us show that this choice of intervals works. It is straightforward to see that the first two properties hold.

It remains to check the third property. We prove that two intervals selected in different steps are disjoint. Since in each step we select at most ⌈nk−1⌉ intervals, this is sufficient to conclude. Consider two colors i,j selected in two different steps s<t respectively. Then, we have xi,s+1<xj,s+1≤xj,t and thus [xi,s,xi,s+1]∩[xj,t,xj,t+1]=∅, which is exactly what we wanted to prove.

Complexity: O(nk).

Solution 2

A greedy approach is also possible.

Let xi,j be defined as in Solution 1. Consider all intervals of the form [xi,j,xi,j+1] and sort them increasingly according to their right endpoint. We now iterate over these intervals, and for each of them, we decide to select it if both these conditions are met (which are equivalent to "selecting the interval does not violate any requirement"):

no interval of the same color has been chosen yet;among the numbers spanned by the interval, no one is contained in (at least) ⌈nk−1⌉ already selected intervals.Let us prove that this algorithm works (i.e., it selects exactly one interval for each color). Suppose, by contradiction, that, for some color i, no interval of that color gets chosen. This means that, for each 1≤j≤k−1, there exist ⌈nk−1⌉ selected intervals that intersect interval [xi,j,xi,j+1]. We can say more: the rightmost endpoints of these intervals must belong to [xi,j,xi,j+1]; indeed, if it weren't the case for at least one interval [a,b], the interval [xi,j,xi,j+1] would come before [a,b] in the ordering, so it would actually have been selected. Since all these intervals must be distinct, they are (k−1)⌈nk−1⌉≥n. Yet this contradicts the fact that they must be at most n−1, one for each color other than i.

Complexity: O(n2k).

Implementation of Solution 1Implementation of Solution 2

FHint 1.Hint 2.Hint 3.Hint 4.Solution1552F - TelepantingSolution 1

The key insight is realizing that, if at some point the ant is located at position x, then all the portals with xi<x are active. One can prove this by induction on the time t. Indeed, when t=0, x=0 and there are no portals with xi<x. Now suppose this is true at time t, and let x be the position of the ant at that time. There are three possible scenarios to consider.

If there is no portal at position x, then the statement is trivially true at time t+1.If there is an inactive portal at position x, then that portal will become active and the position of the ant at time t+1 will be x+1, so all the portals with xi<x+1 will be active.If there is an active portal at position x, the ant will be teleported to some position y<x, and thus at time t+1 it will be at position y+1≤x. Since all the portals with xi<x were active in the first place, and y+1≤x, all the portals with xi<y+1 will be active as well.Let qi be the time the ant needs to go from the position xi to the position xi again assuming that all the portals 1,2,…,i are active.

In order to find a formula for qi, let us describe the movement of the ant when it starts from position xi and the portals 1,2,…,i are active.

The ant gets instantly teleported to yi.The ant walks from yi to xji, where ji≤i is the smallest index so that yi<xji.The ant walks for qji seconds and it ends up in xji with the portal inactive.The ant walks from xji to xji+1.The ant walks for qji+1 seconds and it ends up in xji+1 with the portal inactive.⋯The ant walks for qi−1 seconds and it ends up in xi−1 with the portal inactive.The ant walks from xi−1 to xi.Adding up the contributions of the steps described above, we obtain the following recurrence for qi:qi=(xi−yi)+qji+qji+1+⋯+qi−1.Let A be the set of portals that are initially active. The answer to the problem is given by the formula (which can be proven analyzing the movement of the ant as we have done to prove the recurrence relation for qi)xn+1+∑i∈Aqi.Using a binary search to identify ji and keeping the prefix sums of q1,q2,…,qn, one can implement the described solution in O(nlogn).

Complexity: O(nlogn).

Solution 2

Let zi be the index of the teleporter reached immediately after using teleporter i (it can be computed by binary search).

Let dpi,0 be the number of times xi is reached. Let dpi,1 be the number of times the teleporter i is used. Then, the answer is easy to calculate: each time the teleporter i is active you spend xzi−yi time, and each time the teleporter i is inactive you spend xi+1−xi time. Summing up all the contributions, the answer turns out to be∑i=in[dpi,1(xzi−yi)+(dpi,0−dpi,1)(xi+1−xi)],where xn+1=xn+1.

Now we find recurrences for dpi,0 and dpi,1. The crucial observation is that dpi,0 has the same parity of si⊕1, where ⊕ denotes bitwise XOR. Thus, it is not hard to see that, for 1≤i≤n,dpi+1,0=∑zj=i+1dpj,1+dpi,0+(si⊕1)2⟹dpi,0dpi,1=2(dpi+1,0−∑zj=i+1dpj,1)−(si⊕1),=dpi,0−(si⊕1)2.It now suffices to iterate over the indices i in decreasing order.

Complexity: O(nlogn).

Implementation of Solution 1Implementation of Solution 2

GHint 1.Hint 2.Hint 3.Solution1552G - A Serious RefereeLet us say that an array of n integers is good if it is sorted by Andrea's algorithm, and bad otherwise.

First of all, we state and prove the following intuitive fact (which is well-known for sorting networks):

Lemma. (Zero-One Principle) All arrays a with values in {0,1} are good if and only if all arrays are good.

Proof. The "if" part is trivial.

To prove the converse, consider an array a made up of arbitrary integers (for simplicity, we assume that they are distinct). Fix some 1≤s≤n and construct the array b such that bi=0 if ai is among the s smallest elements of a, and bi=1 otherwise. Since we know that b is good, it follows that Andrea's algorithm applied on a will produce an array in which the s smallest elements occupy the first s positions.

Since this is true for every s∈{1,2,…,n}, we deduce that a is good.

If n=1, then the answer is always ACCEPTED. From now on, we assume n≥2.

Let Si={ji,1,…,ji,qi} be the set of indices considered in the i-th step. Let Ti=S1∪S2∪⋯∪Si.

Given a function f:Ti→{0,1}, we say that it is i-achievable if there is an initial array a1,a2,…,an∈{0,1} so that, after i steps, aj=f(j) holds for each j∈Ti. Applying the Zero-One Principle, one can show that the answer to the problem is ACCEPTED if and only if Tk={1,2,…,n} and all the k-achievable functions are nondecreasing (there are n+1 nondecreasing functions, which are those like (0,0,…,0,1,…,1,1)).

The idea, then, is to compute, for each i=1,2,…,k, the set of i-achievable functions. Let f:Ti→{0,1} be an i-achievable function. Notice that, for each g:Si+1∖Ti→{0,1}, we can find an initial configuration such that after i steps it coincides with f on Ti and with g on Si+1∖Ti. In particular, we can choose arbitrarily how many times the function g takes the value 1.

The crucial observation is that if we know f and we know how many times the function g takes the value 1, then we know unambiguously what happens on Ti+1 after i+1 steps: on Ti+1∖Si+1 the values are exactly the values of f, on Si+1 the values are nondecreasing and thus only the number of ones is necessary to determine them.

Thus, given an i-achievable function, we can construct the (i+1)-achievable functions it can evolve into and there are exactly |Si+1∖Ti|+1 of them.

Let di=|Si∖Ti−1|. The complexity of the described algorithm is O(n⋅(d1+1)(d2+1)⋯(dk+1)). Since (d1+1)+(d2+1)+⋯+(dk+1)≤n+k, we have (by the AM-GM inequality):(d1+1)(d2+1)⋯(dk+1)≤(n+kk)k.Thus the complexity turns out to be O(n(n+kk)k). Depending on the implementation, this might or might not fit into the time-limit.

Here are three observations which reduce hugely the execution time (the first one is already sufficient to fit into the time-limit comfortably):

It is possible to encode the i-achievable functions as bitmasks and all the steps of the solutions can be performed as bitwise operations.Let us show that if Tk−1≠{1,2,…,n} and Sk≠{1,2,…,n}, then the answer is REJECTED. Let x∉Tk−1 and y∉Sk. If x=y, then x∉Tk and we already know that the answer is REJECTED. Otherwise, let a be a permutation of 1,2,…,n with ax=y. After k−1 steps it still holds ax=y and after k steps y∈{aj:j∈Sk} which implies that ay≠y and therefore the array is not sorted by the algorithm. With this observation (together with the above described usage of bitmasks), the complexity of the algorithm becomes O((n+k−1k−1)k−1).To save a lot of memory (and, since memory allocation is expensive, also execution time), one can implement the algorithm in a recursive fashion.Complexity: O(n(n+kk)k).

Implementation

HHint 1.Hint 2.Hint 3.Hint 4.Hint 5.Solution1552H - Guess the PerimeterLet b and h be the lengths of base and height of the rectangle. We will solve a harder problem, that is, finding the explicit values of b and h.

For a positive integer d, define S(d) as the set of admissible points (x,y) with d∣x, and define f(d) as the answer to the query with subset S(d). Then f(1)=(b+1)(h+1).

Lemma 1. We have d⋅f(d)=f(1) if and only if d∣b+1.

Proof. Consider the set {d,2d,3d,…} of all positive multiples of d, and let n be the number of such multiples that are the x-coordinate of at least one point of the rectangle. Then f(d)=n(h+1). We notice that n=b+1d⟺d∣b+1 (indeed, the "if" statement is trivial, since n must be integer; the converse is true because we can split the base in b+1d segments, and each segment contains exactly one point whose x-coordinate is a multiple of d). On the other hand, df(d)=f(1)⟺dn(h+1)=(b+1)(h+1)⟺n=b+1d. This completes the proof.

Lemma 2. Let p=2k be the highest power of 2 which divides b+1. Then ∣∣2f(2p)−f(1)p∣∣=h+1.

Proof. Let n=f(p)h+1 be as in the previous Lemma, and let n′=f(2p)h+1. Then it is easy to see that n′=n±12, which means that 2f(2p)=2n′(h+1)=(n±1)(h+1). But, since p∣b+1, n(h+1)=b+1p(h+1)=f(1)p. Finally,∣∣∣2f(2p)−f(1)p∣∣∣=∣∣∣n(h+1)±(h+1)−f(1)p∣∣∣=∣∣∣f(1)p±(h+1)−f(1)p∣∣∣=h+1.Now it suffices to ask for f(1) (one query), and then binary-search the value of p from the set {1,2,22,…,27}, which takes 3 queries. Note that, when we find p, we have already computed f(2p) (except when p=27, but in this case f(2p)=0), so no further query is required.

Implementation

IHint 1.Hint 2.Hint 3.Hint 4.Solution1552I - Organizing a Music FestivalLet Si:={si,1,si,2,…,si,qi}. Consider the graph on the subsets S1,S2,…,Sk such that Si is adjacent to Sj if and only if Si∩Sj≠∅,Si,Sj. Without loss of generality we can assume that the sets S1,S2,…,Sm are distinct.

Consider a connected component C in such a graph (that is, C is a family of subsets). Let P(C):=⋃S∈CS be the union of all sets in C. For each x∈P(C), let Cx:={S∈C:x∈S}. Notice that Cx=Cy if and only if the elements x,y belongs to exactly the same set in C.

Consider the equivalence relationship on P(C) induced by the function x↦Cx (i.e., x≡y⟺Cx=Cy).

Lemma. If |C|≥2, there is either 0 or exactly 2 (one is the reversal of the other) ways to order the equivalence classes so that any subset T∈C is the union of a contiguous (in the ordering) interval of equivalence classes.

Proof. This can be proven by induction on the number of sets in C. If |C|=2, assume C={S1,S2}. The possible values of Cx are {S1}, {S2}, {S1,S2}. For sure the equivalence class corresponding to {S1,S2} is nonempty and, without loss of generality, we may also assume that the equivalence class corresponding to {S1} is nonempty. Then the valid orderings are exactly {S1} − {S1,S2} − {S2} and its reversal.

Now, assume that |C|≥3. Take S∈C so that C′:=C∖{S} is still connected. Notice that the equivalence classes induced by C′ may be less refined than those induced by C (moreover, the elements in S∖P(C′) are not even considered). If already there is no good ordering of the equivalence classes induced by C′, then the same holds for the equivalence classes induced by C.

Otherwise, by induction, we may assume that there is a unique (up to reversal) ordering of the equivalence classes induced by C′. Let Z1,Z2,…,Zk be the equivalence classes induced by C′ on P(C′) in the correct order. What changes when we consider also the set S? Each Zi splits into two (possibly empty) equivalence classes Z′i:=Zi∩S and Z′′i:=Zi∖S. Moreover, we have to take care of the (possibly empty) new equivalence class Z0:=S∖P(C′).

Consider the set of indices I so that i∈I if and only if both sets Zi∩S and Zi∖S are nonempty. Let us consider various cases:

If I=∅, then there is a valid ordering if and only if the set {1≤i≤k:Zi∩S≠∅} is a prefix or a suffix of {1,2,…,k} or it is a contiguous interval and Z0=∅.If |I|≥3, then there is no good ordering.If |I|=2, assume that I={l,r} and l<r. Then there is a valid ordering if and only if the set {1≤i≤k:Zi∩S≠∅} coincides with [l,r] and Z0=∅. In such case, the unique valid ordering (up to reversal) is given by:Z1,Z2,…,Zl−1,Z′′l,Z′l,Zl+1,…,Zr−1,Z′r,Z′′r,Zr+1,…,Zn.If |I|=1, assume that I={t}. Then there is a valid ordering if and only if the set {1≤i≤k:Zi∩S≠∅} coincides with [1,t] or [t,k]; or if such set is {t} and also Z0 is empty. In the first case (the other cases are analogous), the unique valid ordering (up to reversal) is given by:Z0,Z1,Z2,…,Zt−1,Z′t,Z′′t,Zt+1,…,Zk.The lemma teaches us how to handle a single component (of course, one has to compute also the number of possible orderings of each equivalence class, which is just the factorial of its size). What about the interaction between components?

It is not hard to check that if C,D are two distinct connected components then either P(C)∩P(D)=∅ or P(C)⊆P(D) or P(D)⊆P(C). Moreover, if P(C)=P(D) then either C or D contains only one subset. Let us consider the forest on the connected components such that C is an ancestor of D if and only if P(D)⊆P(C) (if P(C)=P(D) then we require additionally that C contains only one subset). It is not hard to check that this ancestorship is induced by a forest. By adding (if necessary) to the initial family the subset Sk+1={1,2,…,n}, we may assume that this forest is a tree.

The number of valid permutations is given by the product of the contributions of each connected component C. The contribution of a connected component C is the product of the contributions of the equivalence classes of P(C) (and, if there is more than one equivalence class, a factor 2). Given an equivalence class E of P(C), its contribution is the factorial of|P(C)|−∑D∈sons(C)P(D)⊆E(|P(D)|−1).In other words, the problem is completely independent for different connected components up to collapsing the smaller connected components to a single element.

Complexity: O(k2n64) (using bitsets to store the subsets and implementing everything naïvely).

ImplementationIf you find any typo, feel free to tell us with a comment. Moreover, if you want to share your opinion on the problemset, we are eager to read it.

Codeforces Global Round 14 Editorial

By FieryPhoenix, 22 months ago, In English1515A - Феникс и золото

Idea: FieryPhoenix

Tutorial1515A - Феникс и золотоNote that if the sum of all the weights is x, the scale will always explode and the answer will be NO. Otherwise, we claim there is always an answer.

Basically, at each point, we choose an arbitrary gold piece to add to the scale so that it doesn't explode. There is always a valid gold piece to add because the weights are distinct.

For example, we can try adding piece 1, 2, …, n, in that order. Suppose we are currently considering the i-th piece. If we can add it to the scale without an explosion, we do it. If we can't, then we can just first add piece i+1, and then piece i (wi≠wi+1 because weights are distinct). i+1 must be less than or equal to n because otherwise, the total sum of the weights would be x.

Time complexity for each test case: O(n)Solution1515B - Феникс и пазл

Idea: FieryPhoenix

Tutorial1515B - Phoenix and PuzzleIf n can be written as 2x or 4x, where x is a square number, then the answer is YES. Otherwise it is NO.

To visualize this construction, we start by first building a smaller square using exactly 2 or 4 pieces (the drawings are in the sample test explanation). We can just use x of those smaller squares to build a larger square.

Let's prove that there are no other answers (although this isn't necessary to solve the problem). Let's define each triangle piece to have a short side of length 1 and a longer side of length 2–√. Consider one side of the square, and suppose that it has a triangles on the short side and b triangles on the longer side. The side length will be a+2–√b. The area of the square is a rational number because the area of each triangle piece is rational. So, (a+2–√b)2 has to be rational, which means either a is 0, or b is 0. If either is 0, we can use the construction in the previous paragraph.

Time complexity for each test case: O(n−−√) or O(logn) (depends on how you check for square numbers)

Solution1515C - Феникс и башни

Idea: FieryPhoenix

Tutorial1515C - Phoenix and TowersGreedily adding blocks to the current shortest tower will always give a valid solution. Let's prove it with contradiction. If the towers weren't beautiful, then some two towers would have a height difference of more than x. Since a single block cannot exceed a height of x, the difference would be more than one block. This is a contradiction with our solution because we always add to the shortest tower.

To implement this, we can use a set-like structure and store pairs of (hi, i) for each i (1≤i≤m), where hi is the current height of the i-th tower (initialized to 0). When adding a block, we remove the first element of the sorted set, update the tower height, and add it back into the set.

Time complexity for each test case: O(nlogn)Solution1515D - Феникс и носки

Idea: FieryPhoenix

Tutorial1515D - Phoenix and SocksFirst, let's remove all pairs that are already matching because an optimal solution will never change them. Suppose there remain l left socks and r right socks.

Without loss of generality, assume l≥r. If not, we can just swap all left and right socks. We know that regardless of other operations, we will always need to turn (l−r)/2 left socks into right socks. So, if there are any pairs of left socks with the same color, we will first make matching pairs by turning half of them into right socks (while making sure l is always at least r). This is optimal because since we need to turn left socks into right socks eventually, we might as well do it in a way that yields matching pairs immediately. After we equalize the number of left socks and right socks, or run out of pairs of left socks with the same color, we can finish by turning any (l−r)/2 left socks into right socks and then recoloring all left socks to match a right sock. Note that l and r change throughout this process.

Time complexity for each test case: O(n)Solution1515E - Феникс и компьютеры

Idea: FieryPhoenix

Tutorial1515E - Phoenix and ComputersLet's first determine how many ways there are to turn on a segment of k computers without any of them turning on automatically (we manually enable all k). We have two methods:

Method 1:

If we turn on computer 1 first, then we must turn on 2, 3, …, k in that order. There are (k−10) ways to do this, by stars and bars.If we turn on computer 2 first, then we must turn on 3, 4, …, k in that order, with computer 1 inserted somewhere. There are (k−11) ways to do this.If we turn on computer 3 first, then we must turn on 4, 5, …, k in that order, with computers 2 and 1 inserted somewhere (also in that order). There are (k−12) ways to do this.In total, there are (k−10) + (k−11) + … + (k−1k−1)=2k−1 ways.Method 2:

We can prove it with induction. For the base case k=1, there is 1 way. Now, if there are x ways for some k, we wish to show that there are 2x ways for k+1.The critical observation is that the last computer in the sequence is either computer 1 or computer k+1. If the last computer is k+1, then we have x ways (we simply append k+1 to each previous sequence). If the last computer is 1, then we also have x ways (we append 1 and increment every computer in the previous sequences). In total, we have x+x=2x ways. Therefore, there are 2k−1 ways for any k.Any sequence that turns on all computers will look like this from left to right: several manual computers, one automatic computer, several manual computers, one automatic computer, and so on. In other words, computers 1…i1 are manual, i1+1 is automatic, i1+2…i2 are manual, and so on. We will merge together the segments of manual computers using binomial coefficients.As a result, we can write dp[len][cnt]  — the number of ways to turn on a prefix of length len−1 computers having manually turned on cnt computers. The last one len (if len<n) will be turned on automatically.

To transition, iterate the length k of a new segment of manual computers to add and calculate the number of ways with formula (dp[len+k+1][cnt+k] += dp[len][cnt] ⋅ (cnt+kk) ⋅ 2k−1). The answer will be ∑i=1ndp[n+1][i].

Time Complexity: O(n3)Solution1515F - Феникс и землетрясение

Idea: dragonslayerintraining

Tutorial1515F - Phoenix and EarthquakeFirst, note that cities connected by roads behave as one city with the total amount of asphalt. This means building a road is equivalent to merging two cities and summing their asphalt.

If the total asphalt is less than (n−1) ⋅ x, then we don't have enough asphalt to repair all the roads. It turns out that if the total asphalt is at least (n−1) ⋅ x, it is always possible to repair all the roads. We can prove this by induction on the number of vertices. This is obviously true for n=1. Now we just need to show there is always a road that can be repaired, because doing so will reduce the number of vertices by one and the resulting asphalt will be at least (n−2) ⋅ x, so the resulting graph can be merged by the inductive hypothesis.

If some city has at least x asphalt, we can merge it with any neighbor.

Otherwise, all cities have less than x asphalt. It turns out that any two cities i and j must have at least x asphalt between them. To see why, notice that ak<x for all 1≤k≤n, so if ai+aj<x, then the total asphalt must be less than (n−1) ⋅ x.

Thus, one approach is to repeatedly find the city with the most asphalt and merge it with any of its neighbors. This can be implemented with a priority queue and union-find data structure in O(m+nlogn).

There are other approaches as well. For example, since only connectedness of the graph is important, we can discard all edges except for a spanning tree. Pick any leaf. If it can be merged with its parent, do so. Otherwise, it must have less than x asphalt. This means deleting the leaf will leave a connected graph with at least (n−2) ⋅ x asphalt, which can be merged recursively. The leaf is merged last. This can be implemented with a DFS in O(m+n).

Solution1515G - Феникс и одометры

Idea: dragonslayerintraining

Tutorial1515G - Phoenix and OdometersWe can solve for each strongly-connected component independently. From now on, we will assume the graph is strongly-connected.

Define the length of a walk to be the sum of the weights of its edges, modulo MOD, the distance at which the odometer resets. This is different for different queries, but the important thing is some MOD exists.

If there is a walk from a to b with length x, there is a walk from b to a with length −x (for any MOD). To see this, note that since the graph is strongly-connected, there is a path from b to a. Let its length be y. We can walk from b to a and back MOD−1 times and then go to a for a total length of (MOD)y+(MOD−1)x≡−x. Note that this works for any MOD, even if we don't know what it is yet.

We can show that if a is in a cycle of length x, then b is in a cycle of length x. Suppose a path from a to b has length y. We can go from b to a, go around the cycle, and go back to b for a total length of y+x+(−y)=x.

a is in a cycle of length 0. If a is in a cycle of length x, it is in a cycle of kx for any integer k. If a is in a cycle of length x and a cycle of length y, it is in a cycle of length x+y.

The set of possible cycle lengths of cycles containing vertex a are exactly the multiples of some number, namely the gcd of all possible cycle lengths.

So, if we want to determine all possible cycle lengths, we just need to compute this gcd. Fix an arbitrary spanning tree rooted at r and denote the length of the tree path from r to a by ϕ(a).

If there is an edge of length l from a to b, then r is in a cycle of length ϕ(a)+l−ϕ(b). This cycle can be constructed by taking the walk along tree edges from r to a, across the edge from a to b, then backwards along tree edges from b to a.

Thus, we can make any cycles whose length is a multiple of G=gcd{ϕ(a)+l−ϕ(b):(a,b,l)∈E}. It turns out these are the only possible lengths.

If a walk from a to b has length x, then x≡ϕ(b)−ϕ(a)(modG). This can be proved by induction on the number of edges in the walk.

Now that we know which cycle lengths are possible, we can answer the queries.

An odometer can be reset if and only if S plus some multiple of T is a multiple of G.

An odometer can be reset if and only if S is a multiple of gcd(T,G).

For implementation, the easiest way to get a spanning tree is by DFS. This can be done while computing strongly-connected components.

Solution1515H - Феникс и биты

Idea: dragonslayerintraining

Tutorial1515H - Phoenix and BitsWe store the binary representation of all the numbers in a trie. To perform operations on a range, we split the trie to extract the range, perform the operation, and merge everything back.

AND x is equivalent to the sequence XOR 220−1, OR x⊕(220−1), XOR 220−1. XOR does not affect the number of numbers in a subtrie, so we can just lazily propagate it. This leaves just OR operations.

Suppose we want to set the kth bit in a subtrie. If all numbers in it have the kth bit set, we do nothing; if no numbers in it have the kth bit set, we lazily XOR that bit.

Thus, we can handle OR operations recursively, merging the children if the bit to be set is at the current level, and stopping when all bits to be set satisfy one of those two conditions. We can detect these conditions by storing, in every trie node, a mask of bits that are set in some leaf and a mask of bits not set in some leaf.

This approach can be shown to be O((n+q)log2C) by amortized analysis. Intuitively, the expensive OR operations will make the bits in a subtrie more similar.

Define Φk to be the number of trie nodes that have some leaf with the kth bit set and some leaf with the kth bit not set. Define Φ∗ to be 1+logC times the total number of trie nodes. Define the total potential to be the ∑logC−1k=0Φk+Φ∗. This is always nonnegative and at most O(nlog2C).

Split operations create at most logC nodes, each adding at most O(logC) to the potential, so its amortized time complexity is O(log2C).

Merge operations where one side is empty take O(1). Recursive merge operations combine the two roots, the decrease in Φ∗ paying for the possible increase in Φk at the root. (As usual, the recursive calls are not included in the cost as they are paid for by their own potential decrease).

An OR operation only recurses when there is some k such that the subtrie has both a leaf with the kth bit set and a leaf with the k bit not set. After the operation, all leaves will have the kth bit set. Thus, the recursion is paid for by the decrease in Φk at the root.

Solution1515I - Феникс и бриллианты

Idea: dragonslayerintraining

Tutorial1515I - Phoenix and DiamondsSuppose the largest weight of an item is less than 2k. Call an item heavy if its weight is in the range [2k−1,2k) and light if its weight is in the range (0,2k−1). Sort the items in decreasing order by value. As the thief moves left to right, his remaining capacity is nonincreasing. Consider the point where it drops below 2k−1. Before this point, he takes all light items. After this point, he takes no heavy items. The latter can be solved recursively by querying the same data structure only on light items, starting at the appropriate point. The former is a bit trickier.

The thief will take every item until his capacity drops below 2k. This point can be found by binary searching on a segment tree of sums. After this point, he can only take at most one more heavy item. To find this item (if it exists), we can binary search on a segment tree storing range minimums of prefix sum of light items plus weight of heavy item. The first item that is small enough will be taken, if it exists. Either way, we've located all heavy items that will be taken and can recursively handle the light items.

To handle updates, reserve space for all items offline and change their multiplicity as needed. When an item is updated, we can modify all segment trees that it participates in.

This solution is O((n+q)lognlogC).

Solution

Codeforces Global Round 13 Editorial

By errorgorn, 2 years ago, In English1491A - K-th Largest ValueSetter: syksykCCCPrepared by: syksykCCC

Hint 1Hint 2SolutionLet's define cnt to represent the number of 1s in the array.

For the modifications, if ai is already 1 now, then we let cnt←cnt−1. Otherwise, let cnt←cnt+1.

For the querys, just compare cnt with k. If cnt≥k, the answer will be 1. Otherwise, the answer will be 0.

The complexity : O(n+q).

Code (C++)Code (Python) (vim1729)1491B - Minimal CostSetter: syksykCCCPrepared by: syksykCCC

Hint 1Hint 2SolutionConsider the following situations:

∀i∈[2,n],|ai−ai−1|=0, then the answer will be v+min(u,v).∃i∈[2,n],|ai−ai−1|>1, then the answer will be 0.Otherwise, the answer will be min(u,v).Code (C++)1491C - Pekora and TrampolineSetter: oolimryPrepared by: errorgorn

Hint 1Hint 2SolutionFor a series of passes, we can describe it as an array P where Pi is the trampoline Pekora starts at in the i-th pass. We claim that the final state of trampolines after performing any permutation of P will be the same.

ProofFocus on 2 adjacent passes. We realize that if we swap those 2 passes, the jumps done on both these passes are the same.

img

Since swapping any 2 adjacent passes does not change the final state of trampolines, any permutation of P will not change the final state of trampolines.

Now, we can claim that there is an optimal solution with P being non-decreasing. Since Pekora can only move right, we must put Pekora on the first trampoline such that Si≠1.

However, we cannot directly simulate putting Pekora on the first trampoline such that Si≠1. This actually uses O(N3).

Countertest5000 4999 4998 4997 ... 2 1

However, we can simulate this in O(N2) by the following. Instead of simulating passes individually, we will combine them. The main idea is that when Pekora jumps on a trampoline of strength Si, we just add another Pekora on trampoline Si+i and process it later.

So, when we process trampolines from 1 to N, we keep track of how many Pekoras there are on trampoline i, which we will denote as Ci. Then, we only add extra Pekoras to trampoline i if Si>Ci+1. Now, we have some Pekoras on trampoline i and we need to update other values of Ci.

If Si=4 and Ci=6 for example, we would add 1 Pekora each trampolines to i+2,i+3,i+4 to reduce Si to 1. Then, the rest of the Pekoras will be moved to trampoline i+1.

This algorithm runs in O(N2) as we only need to update O(N) other trampolines at each step.

Bonus: solve this problem in O(N). (This was the original constraints but it was later changed since it was too hard for its position.)

Code (C++)Code (Python)1491D - Zookeeper and The Infinite ZooSetter: errorgornPrepared by: errorgorn

Hint 1Hint 2Hint 3Hint 4SolutionFirstly, we can show that the reachability graph is equivalent if we restrict to a directed edge between vertices u and u+v if u&v=v and that v=2k for some k.

This is because we can add each bit from v from u from the highest bit as adding a bit to a number will not affect lower bits.

Now, we observe that such as operation converts a binary string of the form 01…11 into 10…00 for some substring when we represent u as a binary string. (more significant bits are to the left).

Now, we consider s and t as binary strings.

If and only if there is a matching from bits in t to a lower bit in s and t > s, then t is reachable from s.

Turning 01…11 into 10…00 means that we can move a bit (01->10) or we can squish multiple bits (0111->1000).

Let us show it is necessary. If s>t, it is impossible. And if there is no such matching, we are not able to put a position in t as bits cannot move back, or there are not enough bits in s to form t (since the number of bits cannot increase).

Let is show it is sufficient. Since s<t (s=t is trivial), the strings have some common prefix and the most significant different bit has 0 in s and 1 and t. Now, we can shift every bit in s into a position in t and squish the most significant bits.

To check if there is a matching, we find the least significant bit (lsb) of t and s. if lsb(t)<lsb(s) or if s=0, then it is impossible. Else, we remove the lsb from both t and s and repeat. If we're able to remove bits until t=0, then it is possible to go from s to t.

Code (C++)Code (C++) (gamegame)Code (Python)1491E - Fib-treeSetter: WidowmakerPrepared by: Widowmaker and syksykCCC

HintSolutionFirstly, we can discover that we can only cut a tree in the size of fi into one in size of fi−1 and one in size of fi−2.

ProofWe want to show that the only solution to Fi=Fj+Fk is (j,k)=(i−1,i−2) for j≥k.

Clearly, i>j, otherwise, Fi<Fj+Fk.

Furthermore, j>i−2 as Fi>2⋅Fi−2.

Therefore, we have shown the only solution is (j,k)=(i−1,i−2).

However, we will have 2 ways to partition the tree sometimes. But it turns out we can cut any edge!

We will prove that if some edge cuts Fib-tree of Fn vertices into trees with sizes Fn−1 and Fn−2, we can cut it, and the resulting trees are also Fib-trees.

ProofBy induction. For n=2 it's obvious.

If only edge cuts Fib-tree into trees with sizes Fn−1 and Fn−2, we have to cut it.

If there are two such edges: suppose that cutting the first edge results in making two Fib-trees. Then in the tree of size Fn−1 the second edge divides it into trees of sizes Fn−2 and Fn−3, so we can cut it as well in the next step. But then we could as well cut the second edge first: we will have one Fib-tree of size Fn−2, and one tree of size Fn−1 which is cut into Fib-trees of sizes Fn−2 and Fn−3 by the first edge, so it's also a Fib-tree!

Because the growth of Fibonacci sequence is approximately O(ϕn), we only need to cut our tree O(logϕn) times: every time, if we find the splitting edge, we cut it, and recurse to the resulting trees, if at some point there was no splitting edge — tree isn't Fib-tree.

Finally, we got an O(nlogϕn) solution.

Code (C++)1491F - MagnetsSetter: 3.141592653 and star_xingchen_cPrepared by: 3.141592653 and star_xingchen_c

Hint 1Hint 2Hint 3SolutionIt seems this problem needs some random technique, but here is a determinate solution:

We just try to find a not demagnetized magnet.

You can go through the following method to find one:

First put the first magnet in the left.

Then ask all the other magnets with the left pile.

If we got a non-zero answer, we find a valid magnet; else we just put this magnet in the left.

It can be proven later that we will always be able to find a valid magnet.

Then use this magnet to try on all other magnets.

This process form a solution requiring at most 2n−2 queries.

However, when we look back at this solution we'll realize that there is a huge waste of information in the previous queries.

As all the previous answers are 0, it's easy to prove that the magnet we found is the second one we have selected.

Since we know nothing about the right part, we can simply check the magnets in the right one by one.

However, you have known that there is only 1 magnetic magnet in the left, so you can do a binary search to seek for the answer.

The maximum number of queries is n−1+⌈log2n⌉, which perfectly matches the limit.

Code (C++)1491G - Switch and FlipSetter: errorgorn and oolimryPrepared by: errorgorn

Hint 1Hint 2Hint 3SolutionWe can visualize the problem as a graph with nodes of 2 colors (face up — red and face down — blue). Initially, the graph has nodes with all red color and with a directed edge to ci.

Firstly, any 2 cycles with all red nodes can be converted into a single cycle with 2 blues nodes with 1 swap.

 

A cycle with 2 blue nodes is very convenient here as swapping a blue node with a red node it is pointing to will decrease the cycle size and maintain that the cycle still has 2 blue nodes. We can keep decreasing the cycle size until the cycle has only 2 blue nodes and solve that in 1 swap. Thus, solving 2 cycles which have X nodes in total uses only X swaps.

Now, we simply pair the cycles and do this.

However, if there is an odd number of cycles, there are 2 cases:

If the cycle does not cover the whole graph, we can solve the remaining cycle and a cycle of size 1 together.

Otherwise, we can force 2 blue nodes into the cycle with 2 swaps (does not work for n=2 so be careful).

 

Both cases need X+1 moves where X is the size of the remaining cycle.

Thus, at most X+1 swaps is needed in this algorithm.

Code (C++)Code (Python)1491H - Yuezheng Ling and Dynamic TreeSetter: YnoiPrepared by: Widowmaker and Ynoi

Hint 1SolutionDivide the nodes into n−−√ blocks. The i-th block will contain the nodes in [(i−1)n−−√+1,in−−√].

Let's define fx as an ancestor of x such that fx is in the same block as x and afx is not in the same block as x.

Notice that for a given block, if all ax is not in the same block as x, then fx=x.

So, we do not have to re-compute all values of fx for a certain block if ∀x,x−ax≥n−−√ in this block.

When we update a range, we will update some ranges fully and update at most 2 ranges partially. Let's show that only O(n+q) re-computations will happen.

For a certain block, if it is completely contained in an update, the value of x−ax will increase by 1, a single block will be re-computed by at most O(n−−√) of such updates, which will contribute O(n−−√⋅n−−√)=O(n) re-computations.

For blocks that are partially updated by an update, such things will only happen at most 2q times, therefore we have a bound of O(q) re-computations from such updates.

Maintaining fx, querying can be easily done in O(n−−√).

Code (C++)1491I - Ruler Of The ZooSetter: oolimryPrepared by: oolimry

As the solution to this problem is very long, the full editorial is split into 4 parts. If you want to challenge yourself, you can try reading one part at a time and see if you get any inspiration. You can also try to read the specific hints for each part.

Part 1 Hint 1Convert the queue into a circle.

Part 1Firstly, let's convert the queue into a circle. In our new problem, n animals stand in a circle. The king fights the animal directly clockwise to it. If the king wins, he and the other person swap places, otherwise nothing happens. The animal that is king will always move 1 space clockwise regardless of what happens.

 

For example, in this scenario, 0 beats 1, so he stays as king. But he then loses to 2.

Part 2 Hint 1Call animals whose A is smaller than the B of the animal before them RED color and the rest of the animals NONRED color.

Part 2 Hint 2Work out the inequalities.

Part 2 Hint 3How do the colors of animals change?

Part 2Let's give each animal a color. An animal i is RED if Bi−1 > Ai. In other words, and animal is red if and only if the previous animal will beat it as king. The animals that are not red are called NONRED for now.

We can assume no two animals are consecutively RED* (*will elaborate more in part 4). Suppose we have 3 animals XYZ in that order, and Y is red while X and Z are non-red. Suppose X becomes king and wins Y but not Z. As such, the final arrangement is YXZ. The claim here is that X and Z cannot become RED.

For X, X beats Y, We have BX>AY, but since AX>BX and AY>BY, we get that BY<AX. As such, X cannot be RED.

For Z, we have CX<AZ (since X lost to Z) and BX<CX, we hence have BX<AZ. As such, Z cannot be RED

Finally for Y, it is possible that it turns from RED to NONRED.

From these we can conclude that RED cannot be created, but can be destroyed.

Part 3 Hint 1REDs can only be destroyed at most O(n) times.

Part 3 Hint 2Simulate a lot "uneventful" moves at once.

Part 3 Hint 3Consider NONRED positions to be fixed, and the REDs rotate anti-clockwise about them.

Part 3 Hint 4After n−1 moves, what do you observe?

Part 3 Hint 5Do many sets of n−1 moves at once until a RED is destroyed or when the game ends.

Part 3 Hint 6How to find when a RED is destroyed or when the game ends event occurs quickly?

Part 3As such, we have the following conclusions:

REDS are never created only destroyedThe order of NONREDS will not change unless a RED inserts itself within the sequenceREDS will never battle REDS (because of * assumption)Since the number of times REDS can be destroyed is limited, we should exploit that. We define an event as either when a RED is destroyed or when the game ends. Since events can occur at most O(n) times, we just need to find some way to quickly simulate the moves until the next event.

Let's visualize the moves like this: instead of the RED and NONRED swapping positions, the NONREDs are fixed in position, and the REDs move around anticlockwise.

 

After n−1 moves, every RED moves one space anticlockwise around the belt of NONREDs Then in that case, we just need to check how many sets of n−1 moves is needed until the first event occurs.

For convenience, let's split NONRED into BLUE and GREEN. If a NONRED beats a red in front of it, and it loses to next animal, then it is BLUE. If it wins one more time (and hence the entire game) it is GREEN.

Let's look at the conditions for the events:

A RED is destroyed. This occurs when Bnr<Ar where nr is any BLUE or GREENThe game ends. This occurs when Bg>Ar where g is any GREENTo find the first how many times the reds need to move anticlockwise, we could maintain a monotonic vector across the belt of NONREDs, and then for each RED, binary search the earliest position where an event occurs.

Finally, when we find the number of sets of n−1 we need to move backwards, we move everything manually, check if the game ends. Then we recompute the color of all animals, and repeat. If no event occurs, then it will repeat infinitely.

The step of finding the number of steps before first event occurs takes O(nlogn) in total. Since REDs can disappear at most O(n) times, then the total time complexity is O(n2logn).

It's worth noting that the constant factor for this algorithm is small as the number of REDs is 0.5n and binary search is a very fast log. Hence, it passes quite comfortably (author's solution is under 400ms) even though n≤6000.

Part 4In terms of implementation, we can run the first 2n by brute force just to handle some bad corner cases. In particular, it is mostly to handle the assumption "We can assume no two animals are consecutively RED".

If two animals are consecutively RED, then working out the inequalities will show that the one right before the two REDs should be able to win, and hence the game should end within 2n moves.

Code (C++)Code (C++) (errorgorn)

Codeforces Global Round 12 Editorial

By Monogon, history, 2 years ago, In EnglishI hope you enjoyed the problems! Implementations will be added soon.

UPD: Implementations are added!

1450A - Avoid Trygub

Tutorial1450A - Avoid TrygubThe string "trygub" is not sorted alphabetically, and a subsequence of a sorted string is necessarily sorted. So, if we sort the input string, it will be a solution. Complexity is O(n) with counting sort.

Implementation

1450B - Balls of Steel

Tutorial1450B - Balls of SteelWe claim the answer is always −1 or 1.

In fact, suppose in the first operation of a solution we select a point p. If we aren't done, there will at least one point with distance more than k from p. However, there will be no point within distance k of p, no matter how we perform future operations. So it is impossible for p to merge with a new point, and a solution with more than 1 operation will be impossible.

To see if the answer is 1, we should check if there is some point p within distance k from all other points. Otherwise, the answer is −1. Complexity is O(n2) to compute pairwise distances.

Implementation

1450C1 - Errich-Tac-Toe (Easy Version)

Tutorial1450C1 - Errich-Tac-Toe (Easy Version)For each cell (i,j), let's associate it with the color (i+j)mod3. Every three consecutive cells contains one of each color. So, if we choose one color and flip all tokens with that color, it will be a solution. We need only prove that there is a color associated with at most one third of the tokens.

Let there be xi tokens in cells of diagonal number i, for i=0,1,2. Then we have k=x0+x1+x2. Therefore, min{x0,x1,x2}≤⌊k3⌋.

Here's the coloring on an example. There are 3 X's on red, 4 on blue, and 5 on green. Red has the fewest, so we flip those.

Implementation

1450C2 - Errich-Tac-Toe (Hard Version)

Tutorial1450C2 - Errich-Tac-Toe (Hard Version)If for every three consecutive tokens in the grid, we make sure there is an X and there is an O, we are done. For each cell (i,j), let's associate it with the color (i+j)mod3. Since every three consecutive cells contains one of each color, if we make all of one color X and all of a different color O, it would be a solution. It remains to prove that one such way makes at most ⌊k3⌋ operations.

For each token on the grid, it is associated with a color (0, 1, or 2) and a type (X or O). Therefore each token falls into one of 6 categories. So we can make a table for how many tokens fall in each category.

XO0x0o01x1o12x2o2Firstly, k=x0+x1+x2+o0+o1+o2.

Let aij denote the number of operations we make if we flip all X's in cells with color i and flip all O's in cells with color j. Then aij=xi+oj.

Now, we have a01+a02+a10+a12+a20+a21=2k.

Finally, min{a01,a02,a10,a12,a20,a21}≤⌊2k/6⌋=⌊k3⌋.

Here's the coloring in an example. We flip all green X's and blue O's.

Implementation

1450D - Rating Compression

Tutorial1450D - Rating CompressionFor k=1, we simply need to check that the array is a permutation.

If k=n, we simply need to check that the array has minimum 1.

For 1<k<n, we know the k-compression should contain exactly one occurrence of 1. But 1 is the minimum possible element, so it should occur in only one length k subarray. Therefore, 1 should only occur at one of the extremes: index 1 or index n. Without loss of generality, suppose it occurs at index n. Then we require that the k-compression of a[1,…,n−1] is a permutation of the numbers {2,3,…,n−k+1}, and we can solve iteratively.

This gives us the following algorithm. We maintain an interval [l,r]. Initially l=1 and r=n. Now, we iterate i=1,…,n. For each i, we make sure that either al=i or ar=i, increment l or decrement r accordingly. Then check that minj=lraj=i+1.

If i is the first index that our checks fail, then the answer is 0 for 2≤k≤n−i+1 and the answer is 1 for n−i+1<k≤n.

Checking the minimum element each iteration can be done with data structures like a sparse table or segment tree. It is also sufficient to maintain a count array of the elements, for a complexity of O(n).

Implementation

1450E - Capitalism

Tutorial1450E - CapitalismFirstly, each edge connects a person with even income and a person with odd income. So if the graph is not bipartite, then a solution does not exist.

Consider a friendship between people u and v, where we don't know the direction. Since |au−av|=1, we know that au−av≤1 and av−au≤1. Consider a directed friendship (u→v). Since au+1=av, we know that av−au≤1 and au−av≤−1.

For each friendship, let's add two directed edges between them. If it's undirected, we add one from u→v of weight 1 and one from v→u of weight 1. If it's directed, we add one from u→v of weight 1, and one from v→u of weight −1.

The way we added these edges ensures that if u and v are any two vertices and there is a path of distance d from u to v, then av−au≤d. Note that if a negative cycle exists in our graph, then the inequalities give a contradiction. Otherwise if an answer exists, some vertex u will have minimum au and another vertex v will have maximum av, and av−au≤dist(u→v). Therefore, the answer cannot be greater than the diameter: maxu,vdist(u→v). If we find a construction with this answer, then this proves optimality.

Let our construction be as follows. First, choose two vertices u and v such that dist(u→v) is maximized. Let's assign ai=dist(u→i). The property of shortest paths tell us that all the desired inequalities hold for ai. Then we know all directed friendships are correct: av−au=1. For all undirected friendships, we know |av−au|≤1. Since the graph is bipartite, it cannot hold that au=av, therefore |av−au|=1, so all requirements hold and the income inequality is maximized.

For the implementation, we need to check the graph is bipartite, check if negative cycles exist, and find all-pairs shortest paths. For this, we can simply do Floyd-Warshall in O(n3) time.

Implementation

1450F - The Struggling Contestant

Tutorial1450F - The Struggling ContestantSuppose p is a permutation that satisfies the condition. Imagine we add a divider between adjacent indices that are not adjacent in p. If k is the number of "jumps" in p, then we have split the array a into k+1 consecutive segments. The permutation will scan these segments in some order, and each segment can be scanned in forward or reversed order. We can visualize the problem like we "cut" the array in k places, then reorder and reverse the segments so that no two adjacent tags are equal.

Obviously, for all i such that ai=ai+1 we need to cut between i and i+1. Now, we only need to think about the endpoints of these segments, and we need a condition for when it is possible to avoid connecting equal endpoints. For a tag x, define f(x) as the number of times x appears as an endpoint of a segment. Note that if a segment consists of only one tag, we count x twice, as both a left and right endpoint.

We claim that a valid reordering of the segments is possible if and only if for all tags x, it holds that f(x)≤k+2.

Let x be a tag. Let's prove that if a solution exists, then f(x)≤k+2. Consider a reordering of the segments as [y1,y2],[y3,y4],…,[y2k+1,y2k+2]. Here, y2i−1 and y2i are the endpoints of the segment that appears i-th in the solution order. Since y2i and y2i+1 are connected, they cannot both be x. It can be that y1=x, and it can be that y2k+2=x, but at most half of the remaining endpoints (there are 2k of them) can be x due to these connections. So f(x)≤k+2.Let's prove that if f(x)≤k+2 for all tags x, then we can construct a solution. We proceed by induction on k. If k=0, there is only one segment and we are done. Now, suppose k≥1. Let x be any tag with maximum f(x). Select one segment with x as an endpoint and another with y≠x as an endpoint. (Note that such a pair of segments always exists). Connect the selected x and y together, merging them into one segment. We have reduced the number of segments by 1, and we have decreased the frequencies of x and y as endpoints by 1. After making this connection, the condition clearly holds for x and y. For all other tags z (z≠x, z≠y), it holds before the operation that f(z)≤(2k+2)−f(x)≤(2k+2)−f(z) and so f(z)≤k+1. After the operation, k decreases and f(z) is unchanged, so f(z)≤k+2 holds. By induction, a solution exists.To find the solution with the minimum number of cuts, we firstly must cut the array between all adjacent indices of equal tags. If this set of cuts already satisfies the above condition, we are done.

Otherwise, there is a tag x such that f(x)>k+2 and for all tags y≠x, f(y)≤k+2. If we add a cut between two consecutive tags such that one of them is x, it increases f(x) by one and k by one, so it is useless. If we cut between two consecutive tags that are not x, it does not change f(x) and it increases k by one. That is, each such cut brings the condition one step closer to equality. Therefore if a solution exists and f(x)>k+2, we require exactly f(x)−(k+2) additional cuts.

Let's summarize the solution. If some tag x has more than ⌈n/2⌉ occurrences, a solution does not exist. Otherwise, let k be the number of adjacent equal tags, and add the necessary cuts in these positions. Let x be the tag that occurs most frequently as an endpoint in the resulting segments. The answer is k+max{0,f(x)−(k+2)}.

Implementation

1450G - Communism

Tutorial1450G - CommunismLet C denote the set of distinct characters in s.

Suppose there is a sequence of operations that transforms every character to x in the end. For an operation where we transform all occurrences of y to z, let's add a directed edge (y→z). The resulting structure is a directed tree rooted at x. This is because every character except x is transformed exactly once.

For each character y, denote the index of its first occurrence by ly and its last occurrence by ry. For any non-empty subset S of characters, define range(S)=[miny∈Sly,maxy∈Sry]. That is, the smallest interval capturing all occurrences of characters belonging to S. Also define cnt(S) as the number of occurrences of characters in S.

Given a directed tree structure, we can decide its validity regardless of the order of operations. For a character y, let Sy denotes the set of characters in the subtree of y. The condition is that for every character y,

cnt(Sy)≥k|range(Sy)|.(1)Now, we can devise a bitmask dp. For any subset M, let dp(M) be true if we can organize the characters of M into a valid tree rooted at a character outside of M. Then the final answer will be the set of characters x such that dp(C∖{x}) is true.

To create the dp transitions, there are 2 cases.

Choose a character y∈M to be an ancestor of all of M. That is, if the condition (1) holds for the set M=Sy and dp(M∖{y}) is true, then dp(M) is true.The set M should be split into at least two disjoint subtrees. That is, if there is a non-empty, proper subset S⊂M such that dp(S) and dp(M∖S) are true, then dp(M) is also true.These transitions give rise to an O(n+3|C|) solution, since we iterate over all subsets of M in case 2. We still need another observation to optimize this further. The key observation is that we may assume for the transitions of case 2 that range(S)∩range(M∖S)=∅. That is, the sets of characters in sibling subtrees occur on disjoint intervals.

To prove that this assumption is justified, we show that a valid tree can be transformed to a valid tree that does satisfy our assumption.

Suppose there are two siblings y and z whose subtrees have overlapping ranges. Then if we change z's parent to y, we only need to check that the condition (1) still holds for y. In fact,

cnt(A∪{y}∪B∪{z})=cnt(A∪{y})+cnt(B∪{z})≥k⋅|range(A∪{y})|+k⋅|range(B∪{z})|≥k⋅|range(A∪{y}∪B∪{z})|.Of course, after the transformation in the figure, maybe our assumption still does not hold. But observe that if we repeat this process, it will stop in finitely many steps. This is because the sum of depths of all nodes strictly increases with each transformation, and the depth of a node is bounded by |C|.

Now that the claim is proven, it is not hard to improve our solution to O(n+|C|2|C|). If we sort the characters in C by the index of their first occurrence, it is sufficient to try only |C|−1 splits according to this order for case 2. That is, if the characters in M are ordered c1,…,cm, then we should take S={c1,…,ci} for some i.

Implementation

1450H1 - Multithreading (Easy Version)

Tutorial1450H1 - Multithreading (Easy Version)Lets first solve for a given coloring, c, the value of f(c). Let Bodd, Beven denote the number of black spots on even positions, and odd positions respectively. We notate similarly for Wodd and Weven.

Claim: f(c)=12|Bodd−Beven|.

Proof: Let's show for any coloring where Bodd−Beven=2k (the other case Beven−Bodd=2k is equivalent) we have f(c)=k.

Let's show f(c)≤k with a construction of k intersections. Given the condition, let's show a construction. Suppose that Bodd≥1 and Beven≥1. Then there are two adjacent positions of the same color. Connect those positions and continue to solve for the remaining spools. Eventually, there will be Bodd=2k and Weven=2k in an alternating pattern bwbw…bwbw. It's easy to connect these to form k connections.Let's show f(c)≥k by proving any matching has at least k intersections. First, we may assume there are no same-color intersections. If one existed, we could improve the matching, not increasing the number of different-color intersections.Now, since Bodd−Beven=2k, there are at least k black spools on odd positions that are connected to other black spools on odd positions. Each such thread splits the other spools into two sections, each with an odd number of spools. Therefore each of these k threads intersects another thread. Qed.

Now, suppose we have F unfilled positions total. Say Fodd are on odd positions and Feven are on even positions. Let x=n2−Wodd−Beven.

Claim: Let i≡x(mod2). The number of valid, s-reachable colorings c with f(c)=12|x−i| is equal to (Fi).

Proof: Suppose we have a subset of i unfilled positions. For the elements of the subset, we color even positions black and odd positions white. For elements outside the subset, we color even positions white and odd positions black. Say that a is the number of positions in our subset on even positions. Now, Beven+a spools will be black on even positions, and Bodd+Fodd−i+a will be black on odd positions. Then

f(c)=12|(Beven+a)−(Bodd+Fodd−i+a)|=12|Beven−Bodd−Fodd+i|=12|x−i|.It is clear that our mapping is a bijecetion. Qed.

Given our claims, we can write the expected value as such:

12F∑0≤i≤Fi≡x(mod2)|x−i|(Fi).Implementation

1450H2 - Multithreading (Hard Version)

Tutorial1450H2 - Multithreading (Hard Version)Continued from Easy Version tutorial.

Recall the answer is

12F∑0≤i≤Fi≡x(mod2)|x−i|(Fi).Now we have to maintain this sum over updates.

Let's ignore the 2F, and rewrite the sum as

∑0≤i≤x−2i≡x(mod2)x(Fi)−∑0≤i≤x−2i≡x(mod2)i(Fi)+∑x+2≤i≤Fi≡x(mod2)i(Fi)−∑x+2≤i≤Fi≡x(mod2)x(Fi).We will transform sums of the form i(Fi) to sums of the form (Fi). We rewrite them with the following identity.i(Fi)=F(F−1i−1)To deal with the i≡x(mod2) condition, we use Pascal's rule to rewrite each (Fi) as (F−1i−1)+(F−1i), and each sum becomes a prefix sum or suffix sum of some binomial coefficients with the same upper index. The indices change by O(1) between updates, and we should handle these cases. We can handle changes to the upper index by noting the following equation, again due to Pascal's rule.

∑i=0k(F+1i)=2∑i=0k(Fi)−(Fk).It is easy to handle updates to the lower index by adding and subtracting some binomial coefficients when necessary.

Be careful about cases where F=1 since the transformed prefix sum won't consider all possibilities.

Implementation

Editorial of Global Round 11

By dario2994, 2 years ago, In EnglishGeneral commentsBroadly speaking, problems A-B-C-D were "div2 problems", while F-G-H were "strong grandmaster problems" (with E staying in the middle). I did not expect anyone to solve all the problems and thus I decided to give the scoring F+G=H (so that maybe someone would have solved H).

Many of the problems (A, C, D, E, G) admit multiple solutions. Sometimes the core of the solution is the same (C, D) and sometimes the solutions are truly different (A, E, G).

If you are an experienced participant, I would like to hear your opinion on the problems. Feel free to comment on this post or send me a private message.

Overview of the problemsetHintsABCDEFGHSolutionsA1427A - Avoiding ZeroFirst of all, notice that if the sum a1+a2+⋯+an is 0, then, since b is a rearrangement of a, it holds b1+b2+⋯+bn=0 and therefore the answer is NO.

On the other hand, if a1+a2+⋯+an≠0, then there is a valid array b. To show this, let us consider two cases.

If a1+a2+⋯+an>0, then b can be chosen as the array a sorted in decreasing order. In this way, for any k=1,…,n, it holds b1+⋯+bk>0. Let us prove it by dividing in two cases.If bk>0, then also b1,…,bk−1 are positive and therefore the sum is positive.If bk≤0, then also bk+1,…,bn are nonpositive and thereforeb1+⋯+bk=b1+⋯+bn−(bk+1+⋯+bn)≥b1+⋯+bn>0.If a1+a2+⋯+an<0, then b can be chosen as the array a sorted in increasing order. The proof that this choice works is analogous to the previous case.Alternative, randomized solution

If the sum a1+⋯+an=0, then the answer is NO (as explained in the previous solution). Otherwise, we repeatedly random shuffle the cities until all the conditions are satisfied.

It can be proven that a random shuffle works with probability ≥1n (see this comment for a neat proof).

Notice that the probability is exactly 1n in at least two cases:

a1=a2=⋯=an−1=0 and an=1.a1=a2=⋯=am+1=1 and am+2=am+3=⋯=a2m+1=−1 (and n=2m+1).Solution codeB1427B - Chess CheaterNotice that the score is equal toscore=2⋅#{wins}−#{winning_streaks},where a winning streak is a maximal sequence of consecutive wins.

In the explanation that follows, the variables #{wins}, #{winning_streaks} are always related to the initial situation.

If k+#{wins}≥n, then it is possible to win all games and therefore the answer is 2n−1.

Otherwise, it is clear that we want to transform k losses in k wins. Thus, after the cheating, the number of wins will be k+#{wins}. Considering the formula above, it remains only to minimize the number of winning streaks.

How can we minimize the number of winning streaks? It is very intuitive that we shall "fill" the gaps between consecutive winning streaks starting from the shortest gap in increasing order of length. This can be proven noticing that if g gaps are not filled (i.e., after cheating this g gaps still contain at least one loss each) then there are at least g+1 winning streaks.

The implementation goes as follows. With a linear scan we find the lengths of the gaps and then we sort them. Finally we count how many we can select with a sum of lengths ≤k. The answer is2⋅(k+#{wins})−#{winning_streaks}+#{gaps_we_can_fill}.The complexity of the solution is O(nlog(n)).

Solution code

C1427C - The Hard Work of PaparazziThis is a classical dynamic-programming task with a twist. For the solution to work it is fundamental that the city has a small diameter (i.e., r shall not be large) and that there are not simultaneous appearances.

We say that two celebrities i<j are compatible if it is possible to take a photo of both, that is|xi−xj|+|yi−yj|≤tj−ti.Let ansk be the maximum number of photos we can take of the first k celebrities assuming that we take a photo of celebrity k (if we cannot take a photo of celebrity k, then ansk:=−∞). It holds (assuming that we can take a photo of celebrity k)ansk=1+max(0,max1≤i<k,i is compatible with kansi).This formula produces immediately a solution with complexity O(n2): we compute ansk for k that goes from 1 to n; for each k we need just to compute the maximum of O(k) values.

How can we speed up this algorithm? The idea is that if |k−i| is big, then i and k are always compatible. More precisely, if k−i≥2r then tk−ti≥2r (because there are no simultaneous appearances) and therefore|xi−xk|+|yi−yk|≤2r≤tk−ti,so i is compatible with k. Applying this additional observation, we deduceansk=1+max(0,max1≤i≤k−2ransi,maxk−2r<i<k,i is_compatible_with kansi).Hence, if we bookkeep the maximum of ansi on prefixes, we can compute ansk in O(r) and the overall complexity becomes O(nr).

Alternative optimization It is also true that any optimal solution does not skip more than 4r consecutive celebrities (we leave the proof to the reader). Hence another possible optimization of the naïve formula is to take the maximum only over k−4r≤i<k.

Solution code

D1427D - Unshuffling a DeckWe say that a pair of consecutive cards in the deck is good if they have consecutive numbers (in the right order). Let m be the number of good pairs. We show that, if the deck is not sorted, with one move we can increase m. Hence after at most n−1 moves it will hold m=n−1 and the deck will be sorted.

Since the deck is not sorted, there must be two indices i<j such that ci=cj+1. Moreover, since ci>cj, there is i≤t<j such that ct>ct+1. We split the deck as (with k=4 packets, or less if some of the packets are empty)D1=[c1,c2,…,ci−1], D2=[ci,ci+1,…,ct], D3=[ct+1,ct+2,…,cj], D4=[cj+1,cj+2,…,cn]and we perform the operation, obtaining the new deck[cj+1,cj+2,…,cn,ct+1,ct+2,…,cj,ci,ci+1,…,ct,c1,c2,…,ci−1].In the new deck any pair that was good before the operation is still good (notice that (ct,ct+1) was not a good pair) and moreover the pair (cj,ci) has become good. Therefore m has increased as desired.

The limit on n is so small that fundamentally any polynomial implementation gets accepted. Producing an O(n2) implementation is trivial, but it should also be possible to produce a pseudo-linear implementation.

Solution code

E1427E - XumWe present two different solutions. The first solution is by Anton, the second is mine.

The first solution is deterministic, it is fundamentally based on Bezout's Theorem and comes with a proof. It performs ≈100 operations and writes numbers up to O(x3).The second solution is randomized, uses some xor-linear-algebra and comes without a proof. It performs ≈1000 operations and writes numbers up to O(x2).There are many variations on the randomized solution, some of them being quite messy. The randomized solution we present is rather clean. Let us remark that, due to the constraint x≤999,999, it is possible to test on your personal computer whether a certain algorithm is correct or not on all possible inputs.Deterministic, provable, "gcd" solution

Step 0: If u is written on the blackboard, then we can write nu on the blackboard with O(log(n)) operations.

How? Just using the sum operation as in the binary exponentiation (same algorithm, just replace multiplication with addition and exponentiation with multiplication).

Step 1: Write on the blackboard a number y coprime with x.

Let e∈N be the largest integer such that 2e≤x (i.e., 2e is the largest bit of x). Notice that y=(2ex)∧x=(2e+1)x−2e+1 and therefore gcd(x,y)=gcd(x,2e+1)=1.

Step 2: Write 1=gcd(x,y) on the blackboard.

Let a,b≥0 be such that ax−by=1 (a,b exist thanks to Bezout's theorem) with b even (if b is odd, we can add y to a and x to b, getting an even b). Since by is even, we have ax∧by=1 and therefore we are able to write 1 on the blackboard.

Randomized, unproven, linear-algebraic solution

We are going to talk about subspaces and basis; they shall be understood with respect to the operation xor on nonnegative integers.

The rough idea is to sample randomly two numbers from the subspace generated by the numbers currently on the blackboard and write their sum on the blackboard.

First, we choose the maximum number of bits L that any number on the blackboard will ever have. A good choice is 2L>x2 (L=40 works for any odd x below 106).

We iterate the following process until 1 belongs to the subspace generated by the numbers written on the blackboard.

Let S be the subspace generated by the numbers currently on the blackboard (i.e., the set of numbers that can be written as the xor of some numbers on the blackboard). Let b1,…,bk be a basis for S. Randomly choosing k bits e1,…,ek we can produce a random element in S as(e1b1)∧(e2b2)∧⋯∧(ekbk).Let us choose two random numbers u,v∈S.

If u+v≥2L, we choose a different pair of numbers.If u+v∈S (we can check this in O(k) since we know a basis for S), we choose a different pair of numbers.Otherwise, we add u+v to S and update the basis accordingly.It turns out that this approach solves all odd values 3≤x≤999,999 instantaneously.

Could we choose a much smaller L? The answer is no. If x=219+1 then there is a xor-subspace S that contains x and such that if u,v∈S and u+v<238 then u+v∈S. Notice that this implies that any strategy needs to write on the blackboard some "some big numbers". This is why any approach that avoids large numbers by design is doomed to fail.

Comment: Why should this solution work? Fundamentally, and this is the main idea of the problem, because the two operations + and ∧ are not related by any strange hidden structure. It would be a miracle if we could find a very big subspace for ∧ that is closed also for +. And, since miracles are rare, here there is no miracle.

It should not be very hard to show that this solution works for any odd x, i.e. there is not a subspace that contains x and is closed for sums that are below 2L (if 2L>x2). Nonetheless, I could not show it. On the other hand, I think that proving that this solution has a very good (expected) time-complexity is very hard, but I would be happy if someone proves me wrong.

Solution code

F1427F - Boring Card GameBefore describing the solution, let us comment it.

The solution is naturally split in two parts:

Solving the problem without the "alternating turns" constraint.Noticing that a simple greedy is sufficient to take care of the "alternating turns" constraint.The first part of the solution is a rather standard greedy approach with complexity O(n). It is quite easy (considering that this is problem F) to guess that such a greedy approach works. On the other hand, the second part of the solution (i.e. noticing that Giada takes the last turn and this imposes a condition on the appropriate forest provided by the first part of the solution) is still a greedy with O(n) complexity, but harder to guess and less standard.

The constraint on n is very low as we did not want to implicitly hint towards a greedy approach. Moreover the greedy used in the first part of the solution can be replaced with an O(n3) dynamic-programming approach (which fits in the timelimit if implemented carefully) and the greedy described in the second part of the solution is slightly easier to implement with complexity O(n2).

Simpler problem, not alternating turns

Let us first consider a different (and easier) problem. Federico and Giada don't take turns, they take 3 cards in the order they prefer (so at the end they may have a different number of cards). You are given a final situation (that is, the cards in Federico's pocket at the end) and you have to produce a sequence of moves that generates that set of cards at the end of the game. We assume that the final situation is fixed, hence each card is assigned to either Federico or Giada.

We are going to describe what is natural to call the stack-partitioning. The stack-partitioning is a particular partition of the deck into 2n groups of 3 cards each (not necessarily contiguous) such that each group of cards contain cards taken by the same player (either all 3 by Federico or all 3 by Giada). A priori the stack-partitioning might fail, not producing the described partition (but we will se that if the set of cards in Federico's pocket is achievable then the stack-partitioning does not fail).

In order to create the stack-partitioning we iterate over the cards in the deck (hence the numbers from 1 to 6n) and we keep a stack of partial groups (i.e. of groups of less than 3 cards). When we process a card,

if it was taken by the same player that took the cards in the group at the top of the stack, then we add it to that group. If the group has now 3 cards, we pop it from the stack and it becomes a group in the stack-partitioning.if it was taken by the other player, we add it on top of the stack (as a group with just that card).If in the end the stack is empty, we say that the stack-partitioning works (otherwise we say that it fails).For example, if n=2 and the cards in Federico's pocket are {1,5,8,9,10,12} then the stack-partitioning works and produces the partition{{2,3,4},{8,9,10},{6,7,8},{1,5,12}}.The fundamental observation is:

Lemma: Let us fix a possible final situation. Let us perform the stack-partition starting with a nonempty stack, i.e. at the beginning the stack already contains some partial groups assigned to either Federico and Giada (these groups do not correspond to cards in the deck). At the end of the algorithm the stack will be as it was at the beginning, i.e., same number of partial groups, with same sizes and assigned to the same player.

proof: The proof is by induction on the number of cards in the deck. Since it is not hard and quite standard, we leave it to the reader.

Corollary: A final situation (i.e., a set of cards in Federico's pocket) is possible if and only if the stack-partitioning works. Moreover the stack-partitioning yields a way to produce the final situation.

proof: If the stack-partitioning works, then it clearly yields a way to produce the final situation (players take the groups of three cards in the same order as they are popped out of the stack). The other implication follows directly from the Lemma.

Original problem

Now, we can go back to the original statement. Let us notice a couple more properties of the stack-partitioning (both observations are valid both in the simpler version of the problem and in the harder):

The stack-partitioning produces a forest where each node is a group of 3 cards taken by the same player (hence we will say that a node is owned by Federico or Giada). More precisely any group G of 3 cards is son of the group of 3 cards at the top of the stack after G is popped out (or G is a root if the stack becomes empty). We will refer to this forest as the stack-forest. Notice that in the stack-forest two adjacent vertices are owned by different players.In any possible sequence of moves, the group taken in the last move intersects at least one root of the stack-forest. Indeed, the cards before the first card of the group can be taken independently from the others (without alternating turns) and therefore, thanks to the Lemma, when the first card of the group is processed the stack is empty (thus it belongs to a root).We prove that a certain final situation is possible if and only if the stack-partitioning works and there is a root of the stack-forest that is owned by Giada.

First, if a situation is possible then the stack-partitioning works (because of the lemma). Moreover, since Giada performs the last move, thanks to the second property above, there must be a root of the stack-forest owned by Giada.

Let us now describe a greedy algorithm to produce a given final situation provided that the stack-partitioning works and there is a root owned by Giada in the stack-forest.

Notice that if we remove leaves from the stack-forest, alternating between nodes owned by Federico and Giada, we are actually performing a sequence of valid moves. The algorithm is the following:

When it is Federico's turn, we remove an arbitrary leaf owned by Federico.When it is Giada's turn we remove an arbitrary leaf owned by Giada taking care of not removing a root if there is only one root owned by Giada.Why does the algorithm work?

When it is Federico's turn, since there is at least one root owned by Giada and the number of nodes owned by Federico and Giada is the same, there must be at least one leaf owned by Federico (recall that adjacent vertices have different owners).When it is Giada's turn, there are more nodes owned by Giada then by Federico, hence there is at least one leaf owned by Giada. Could it be that such a leaf is also a root and it is the only root owned by Giada? It can be the case only if that is in fact the only remaining vertex.Solution code

G1427G - One Billion Shades of GreyWe present two solutions: the first solution is mine, the second is by dacin21.

The first solution reduces the problem to the computation of O(n) min-cuts and then computes the min-cuts with total complexity O(n3). This solution requires no advanced knowledge and it fits easily in the time-limit.The second solution solves the dual of the problem, which happens to be a min-cost flow. This shall be implemented with complexity O(n3) (or O(n3log(n)) and some optimizations) to fit in the time-limit.We will solve the problem on a general graph (tiles = vertices, two tiles are adjacent if there is an edge between them).

Solution via many min-cuts

The solution is naturally split in two parts:

Reduce the problem to the computation of O(n) min-cuts in the grid-graph (here O(n) represents the number of already painted tiles).Compute all the min-cuts with overall complexity O(n3).Reducing to many min-cuts

A natural way to come up with this solution is to consider the special case in which the painted tiles have only two colors. In such a case the problems is clearly equivalent to the min-cut. We show that something similar holds true in general.

Given a graph (V,E), let B be the set of vertices that are already painted (in our problem, B contains the tiles on the boundary). Let us fix a choice of all the shades, that is a function s:V→N such that s(v) is the shade assigned to vertex v. Let TC be the total contrast. We have (using that, for x≤y, it holds |x−y|=∑k≥1[x≤k and y>k])TC=∑(u,v)∈E|s(u)−s(v)|=∑k≥1#{(u,v)∈E: s(u)≤k,s(v)>k}.Given two disjoint subsets U1,U2 of vertices, let mc(U1,U2) be the minimum-cut between these two set of vertices. Using the formula above, we haveTC=∑k≥1mc({v∈V:s(v)≤k},{v∈V:s(v)>k})≥∑k≥1mc({v∈B:s(v)≤k},{v∈B:s(v)>k}).Therefore, we have proven a lowerbound for the minimum total contrast. Let us show that this lowerbound can be achieved.

Given two disjoint subsets U1,U2, let MC(U1,U2) be the family of all the subsets U1⊆W⊆V∖U2 such that mc(U1,U2)=mc(W,V∖W), i.e. the family of subsets achieving the minimum-cut. We are going to need the following lemma. Even though the proof is unilluminating, the statement is very intuitive.

Lemma: Take U1,U2 disjoint and U~1,U~2 disjoint, such that U1⊆U~1 and U~2⊆U2 (that is, U1 grows and U2 shrinks). If W∈MC(U1,U2) and W~∈MC(U~1,U~2), then W∪W~∈MC(U~1,U~2).

proof. Given two disjoint sets A,B⊆V, let c(A,B):=|(A×B)∩E| be the number of cross-edges. It holds (without using any assumption on W or W~)c(W∪W~,(W∪W~)c)−c(W~,W~c)=c(W∖W~,(W∪W~)c)−c(W~,W∖W~)≤c(W∖W~,Wc)−c(W∩W~,W∖W~)=c(W,Wc)−c(W∩W~,(W∩W~)c).Since W∈MC(U1,U2) and U1⊆W∩W~⊆Uc2, the right-hand side is nonpositive. Hence also the left-hand side is nonpositive; thus we deduce c(W∪W~,(W∪W~)c)≤c(W~,W~c) and therefore W∪W~∈MC(U~1,U~2).

Applying the lemma, we may find an increasing family of subsets W1⊆W2⊆W3⊆⋯ such that for all k≥1 it holdsWk∈MC({v∈B:s(v)≤k},{v∈B:s(v)>k}).It is easy to check that s(v):=min{k:v∈Wk} is a valid assignment of shades that achieves the minimum possible contrast (that is, it achieves equality in the formula above).

Hence, we may solve the problem running many maximum-flow algorithms. Running O(n) times a max-flow algorithm should get time-limit-exceeded independently on how good your implementation of the maximum-flow is.

Remark. For those interested, the relation between min-cuts and the minimization of the contrast is very similar to the relation between the isoperimetric problem and the 1-Sobolev inequality (see this wiki page). In the continuous setting, the strategy employed in this solution corresponds to the coarea formula.

Computing quickly many min-cuts

Our goal is computing mc({v∈B:s(v)≤k},{v∈B:s(v)>k}) for all values of k. The number of interesting values of k is clearly O(n). For simplicity, we assume that the interesting values of k are contiguous and that all the tiles on the boundary have different shades.

Let us assume that we have computed, via a simple augmenting-path algorithm, a max-flow between {v∈B:s(v)≤k} and {v∈B:s(v)>k}. In particular we are keeping the flow as a union of disjoint paths. We show how to update it to a max-flow between {v∈B:s(v)≤k+1} and {v∈B:s(v)>k+1} in O(n2) time (thus the overall complexity will be O(n3)).

Passing from k to k+1 we only need to transform a sink into a source (in particular the vertex such that s(v)=k+1 becomes a source). How shall we do that?. First of all we remove all the paths that ends in v (there are at most 3, which is the degree of v). Then we look for augmenting paths. Due to the optimality of the flow before the update, it is not hard to prove that there can be at most 6 augmenting paths. The overall complexity of the update is 3n2+6n2=O(n2).

Solution via min-cost flow

The crucial point is formulating the problem as a linear programming problem and computing its dual, which somewhat magically turns out to be a min-cost flow. Then a very careful implementation of the min-cost flow algorithm is necessary to get accepted (with some optimizations, it is possible to get accepted with execution time below 1 second).

Let xv be the shade of vertex v. For any edge u∼v, let cuv be the contrast between u and v. Then we havecuv≥xu−xv and cuv≥xv−xu,and the total contrast is ∑cuv.

Hence, we have formulated the minimization of the total contrast as a linear programming problem. In this form, it's not clear how to solve it efficiently (the simplex algorithm would be way to slow).

Computing the dual problem is straight-forward (using well-known formulas) but a bit heavy on notation. In the end, the dual problem turns out to be the min-cost flow with the following parameters:

There is a source, connected to all the vertices v already painted via an edge (from the source to v) with capacity 1 and cost xv.There is a sink, connected to all the vertices v already painted via an edge (from v to the sink) with capacity 1 and cost −xv.All the edges of the graph have capacity 1 and cost 0.The issue is that general-purpose min-cost flow algorithm have a rather bad complexity and are doomed to get time-limit-exceeded. The trick is to choose the simplest possible algorithm: use Dijkstra to repeatedly find a min-cost path from a source to a sink. Doing so yields an algorithm with complexity O(n3log(n)). This might get time-limit-exceeded or not depending on implementation details. Let us briefly describe two independent optimizations that may help in fitting in the time-limit:Remove the edges between already painted vertices (taking care of the contrast generated by adjacent painted vertices).Use a radix-heap instead of a standard heap for Dijkstra.Solution code

H1427H - Prison BreakWe fix the unit of measure and say that the prisoner moves at 1 meter per second.

Let us parametrize the boundary of the prison as follows (ignoring the very long, very high walls). Start walking with speed 1 from P1 towards Pn+1 staying on the prison wall and let γ(t) be the point you are at after time t (so γ is a curve with speed 1). Let L be the total length of such curve (i.e., γ(L)=Pn+1). With an abuse of notation, we will denote with γ also the image of γ (i.e., the climbable walls).

A criterion for the prison break

The prisoner can escape if and only if there are three times 0≤t1<t2<t3≤L such that|γ(t2)−γ(t1)|<t2−t1v and |γ(t3)−γ(t2)|<t3−t2v.(⋆)proof.

If there are three times t1<t2<t3 such that (⋆) holds, then the prisoner can escape. The strategy of the prisoner is as follows.

He begins by going (very close) to the point γ(t2). If there is not a guard there, he escapes. Otherwise, there must be a guard at (a point very close to) γ(t2). Without loss of generality we may assume that the other guard is at γ(t) with t<t2. Then the prisoner goes directly to γ(t3) and escapes from there. Notice that the prisoner reaches γ(t3) in |γ(t3)−γ(t2)| seconds, while the closest guard (the one at γ(t2)) needs t3−t2v seconds. The assumption guarantees that the prisoner reaches γ(t3) before the guard.

If there are not three such times such that (⋆) holds, then the guards have a strategy to avoid the prison break. This implication is harder; we split its proof into various steps.

The strategy of the guards is encoded by two functions f1,f2. Assume that we are given two functions f1,f2:Z→[0,L], where Z denotes the interior of the prison, such that they are both v-Lipschitz (i.e., |f(A)−f(B)|≤v|A−B|) and, for any 0≤t≤L, either f1(γ(t))=t or f2(γ(t))=t (or also both). Denoting with Q the position of the prisoner, the guards may follow the following strategy (it is easy to adapt this strategy to the fact that initially the guards are at P1, we leave it to the reader):

The first guard will always be at γ(f1(Q)).The second guard will always be at γ(f2(Q)).Notice that since the two functions are v-Lipschitz, it is possible for the guards to follow this strategy. Moreover, thanks to the properties of the functions f1,f2, when the prisoner reaches a point on the climbable walls there is always a guard waiting for him there.Extending Lipschitz functions. It remains to construct two such functions f1,f2. The idea is to define them on γ and then extend them inside Z through a standard technique. Assume that we are able to define them on γ, it is well-known that a real-valued Lipschitz function defined on a subset of a metric space (the metric space is Z, its subset is γ) can be extended to the whole metric space without increasing the Lipschitz constant (this may sound as abstract nonsense, but it's easy... prove it!).

From two functions to two subsets. The existence of the desired f1,f2 boils down to finding two functions on γ that are v-Lipschitz and for each 0≤t≤L we have either f1(γ(t))=t or f2(γ(t))=t. Let γ1,γ2 be the subsets of γ where, respectively, f1(γ(t))=t and f2(γ(t))=t. What can we say on the two subsets γ1 and γ2? Well, restricted on them, the function γ(t)↦t must be v-Lipschitz! Thus, applying again the extension argument described above, the problem reduces to finding two subsets γ1,γ2 of γ such that γ1∪γ2=γ and the function γ(t)↦t is v-Lipschitz on γ1 and γ2.

Existence of the subsets via a bipartition argument. We have finally arrived at the core of the proof, constructing γ1 and γ2. Given two points γ(s) and γ(t), we say that they are compatible if v|γ(s)−γ(t)|≥|s−t|. The conditions on γ1 and γ2 are equivalent to:

It holds γ1∪γ2=γ.Any two points in γ1 are compatible.Any two points in γ2 are compatible.If we endow γ with the graph structure induced by the incompatibility (there is an edge between two points if they are incompatible), then the existence of γ1 and γ2 is equivalent to the fact that such a graph is bipartite! Notice that the assumption of nonexistence of the three times such that (⋆) holds, is equivalent to the fact that there are not three points γ(t1),γ(t2),γ(t3) with t1<t2<t3 such that γ(t1) is incompatible with γ(t2) and γ(t2) is incompatible with γ(t3). It is not hard (left to the reader) to check that this condition implies that the incompatibility-graph is bipartite.Computing the minimal speed v

In order to find the minimal v such that the guards can avoid the prison break, we binary search the answer. Given a certain v, we must check whether there are three times 0≤t1<t2<t3≤L such that (⋆) holds.

We say that t2 is left-incompatible if there is a t1<t2 such that (⋆) holds and we say that it is right-incompatible if there is a t3>t2 such that (⋆) holds. We have to check whether there is a time that is both left-incompatible and right-incompatible.

Let us assume that γ(t1)∈[Pi,Pi+1] and γ(t2)∈[Pj,Pj+1] with i<j. Under this additional constraint, characterizing the "left-incompatible" times t2 reduces to finding all the points γ(t2)∈[Pj,Pj+1] such thatminγ(t1)∈[Pi,Pi+1]|γ(t2)−γ(t1)|−t2−t1v<0.There are many different approaches to characterize the set of left-incompatible times t2. The crucial observation that is common to all the approaches is that the set of left-incompatible t2 is the union of O(1) intervals (actually it is an interval, but this observation is not necessary for all the approaches). We present two such methods:

The first method, based on solving quadratic equations, needs some care to avoid precision issues/division by zero. The complexity is O(1) (once i and j are fixed) and produces a complete algorithm with complexity O(n2log(n)log(ε−1)) (or a slightly easier to implement O(n3log(ε−1)) that is super-fast.The second method, based on ternary search, is pretty straight-forward to implement but proving its correctness is rather hard. The complexity is O(log(ε−1)2) and produces a complete algorithm with complexity O(n2log(ε−1)3+n3log(ε−1)) which is rather slow in practice; some care might be necessary to get it accepted.Since we will need them in both approaches, let us define t±12 as the values such that γ(t−1)=Pi, γ(t+1)=Pi+1, γ(t−2)=Pj, γ(t+2)=Pj+1.

Via quadratic equations. Consider the function F(t1,t2):=|γ(t2)−γ(t1)|2v2−(t2−t1)2. We have to find the values t2∈[t−2,t+2] such thatmint1∈[t−1,t+1]F(t1,t2)<0.Notice that t1↦F(t1,t2) is a quadratic polynomial with positive leading coefficient. Hence the minimum is either at an extreme point t1∈{t−1,t+1} or at the point t1=:f(t2) such that ∂t1F(t1,t2)=0. Moreover t2↦F(t−1,t2) and t2↦F(t+1,t2) and t2↦F(f(t2),t2) are all quadratic polynomials, so the set of times t2 where they are negative is either an interval or a union of two intervals (which can be found finding the roots of the appropriate quadratic equations). Since f(t2)∈[t−1,t+1] holds for t2 in an interval (with easy to find extreme points), the solution is complete.

Let us remark that, even if everything seems elementary and easy, implementing this is not a cakewalk.

Via ternary search. Consider the function G(t1,t2):=|γ(t2)−γ(t1)|t2−t1. We have to find the values t2∈[t−2,t+2] such thatmint1∈[t−1,t+1]G(t1,t2)<v−1.The function t1↦G(t1,t2) is unimodal, hence, given t2, with a ternary search we may computeG~(t2):=mint1∈[t−1,t+1]G(t1,t2).Then, also the function t2↦G~(t2) is unimodal, hence with a ternary search+binary search we may find the interval where it is below v−1.

For a proof that the above functions are really unimodal, take a look at this short pdf.

Implementing this second approach might be a bit tedious, but presents no real difficulty. Since this is quite slow, it might need some care to get accepted (for example, the arg-min of G~ shall be computed only once and not for each binary-search iteration on v).

Solution code

Codeforces Global Round 10 — Editorial

By Tlatoani, 3 years ago, In EnglishWe hope you liked the problems! We apologize for the weak pretests for A and B -- that was a major oversight on our part. Hopefully you were still able to enjoy the contest regardless :)

We have to apologize to antontrygubO_o a bit here -- the rejection count mentioned in the editorial for Codeforces Round #655 (Div. 2) actually also included this round, as the problems from that round and problems A through G in this round were created together. We did have one more problem rejected after that round happened, bringing up the total to 73. For reference, here are the overall rejection counts for each problem:

Rejection CountsWithout further ado, here are the tutorials for each of the problems:

1392A - Omkar and PasswordIf your array consists of one number repeated n times, then you obviously can't do any moves to shorten the password. Otherwise, you can show that it is always possible to shorten the password to 1 number.

For an array consisting of 2 or more distinct elements, considering the maximum value of the array. If its max value appears once, you can just repeat operations on the maximum array value until you are left with one number. What if the maximum elements appears more than once? Well, because there must exist at least 2 distinct numbers, you can always pick a maximum element adjacent to a different number to perform an operation on. The array will then have one occurrence of a maximum and you can simply repeat using aforementioned logic.

Solution (Kotlin) by golionsSolution (Java) by MagentaCobraSolution (C++) by hugopmIdea: MagentaCobra and qlf9

Preparation: MagentaCobra

1392B - Omkar and Infinity ClockThere's only two possible states the array can end up as. Which state it becomes after k turns is determined solely by the parity of k.

After the first move, the array will consists of all non-negative numbers (d−ai will never be negative because ai never exceeds d). After one turn, let's define x as max(ai) over all i. For any number ai, it will turn into x−ai. Because a zero will always exist after any one operation, x will be the maximum of the array in the next turn as well. Then the value at index i will turn into x−(x−ai). This is just equal to ai!

Now that it's obvious that our array will enter a cycle with a period of 2, we simply do the following: If k is odd, perform 1 operation. Otherwise perform 2 operations.

Solution (Kotlin) by TlatoaniSolution (Java) by MagentaCobraSolution (C++) by tfgIdea: MagentaCobra

Preparation: MagentaCobra

1392C - Omkar and WaterslideCall the initial array a. We claim that the answer is ∑max(ai−ai+1,0) over the entire array of supports (call this value ans). Now let's show why.

First, notice that in a nondecreasing array, ans=0. So, the problem is now to apply operations to the array such that ans=0.

Now, let's see how applying one operation affects ans. Perform an operation on an arbitrary nondecreasing subarray that begins at index i and ends at index j. Note that the differences of elements within the subarray stay the same, so the only two pairs of elements which affect the sum are ai−1,ai and aj,aj+1.

Let's initially look at the pair ai−1,ai. If ai−1≤ai (or if i=1), applying an operation would not change ans. But, if ai−1/gtai, applying an operation would decrease ans by 1.

Now let's look at the pair aj,aj+1. If aj≤aj+1 (or if j=n), applying an operation would not change ans. But, if aj>aj+1, applying an operation would increase ans by 1.

We have now shown that we can decrease ans by at most 1 with each operation, showing that it is impossible to make his supports able to hold the waterslide in fewer than ∑max(ai−ai+1,0) over the initial array. Now, let's construct a solution that applies exactly ∑max(ai−ai+1,0) operations to make the array valid.

Consider applying operations to each suffix of length j until the suffix of length j+1 is nondecreasing. Since operations are applied iff an−j+1<an−j, and each operation decreases an−j+1<an−j by 1, the total number of operations would just be the sum of max(0,an−j−an−j+1), which is equal to ∑max(ai−ai+1,0) over the entire array.

Solution (Kotlin) by TlatoaniSolution (Java) by qlf9Solution (C++) by tfgIdea: qlf9

Preparation: qlf9

1392D - Omkar and Bed WarsAs described in the statement, the only situation in which a player is not acting logically according to Bed Wars strategy is when they are being attacked by exactly 1 player, but they are not attacking that player in response. Let the player acting illogically be player j. There are two cases in which player j is acting illogically:

The first case is that player j is being attacked by the player to their left, player j−1, and not by the player to their right, player j+1. This means that sj−1= R, as they are attacking player j who is to their right, and sj+1= R, as they are attacking the player to the right instead of player j who is to their left. Furthermore, since player j is not being logical, instead of attacking player j−1, they are attacking player j+1, so sj= R. This means that in this case sj−1=sj=sj+1= R, i. e. R occurs 3 times in a row somewhere in s. We want to avoid this case, so the final string (after Omkar has convinced some player to change) cannot have 3 Rs in a row.

The second case is that player j is being attacked by the player to their right, player j+1, and not by the player to their left, player j−1. It is easy to see that this case is essentially the same as the first case, but reversed, meaning that the final string also cannot have 3 Ls in a row.

Combining these two cases, the condition in the statement reduces to the simple condition that the same character cannot occur 3 times in a row in our final string.

If we have some subsegment of length l of the same character in s, and this subsegment is maximal, so that the characters preceding and following it in s are different from the characters in it, then we can make all players in this subsegment logical by having Omkar talk to ⌊l3⌋ of the players in that subsegment. Therefore, assuming that not all characters in s are the same, we simply find the lengths of all maximal subsegments of the same characters in s (noting that we need to wrap around if s1=sn), and sum over their lengths divided (rounding down) by 3. Finding these lengths and summing over their quotients can be done easily by looping through s in O(n).

If all the characters in s are the same, then we can see similarly that Omkar needs to talk to ⌈n3⌉ of the players. (Note that we are rounding up instead of down  — this is due to the circular nature of s).

Solution (Kotlin) by TlatoaniSolution (Java) by qlf9Solution (C++) by AriIdea: Tlatoani

Preparation: Tlatoani

1392E - Omkar and DuckThe problem essentially boils down to constructing a grid such that any path from (1,1) to (n,n) has a different sum and you can easily determine any path from its sum. You can do this using the following construction: for all (x,y), if x is even, then let ax,y=2x+y; otherwise, let ax,y=0.

The construction is illustrated below for n=8:

0230250270290240260280210025027029021102602802100212027029021102130280210021202140290211021302150210021202140216You can see that this construction works using the following observations:

The maximum value of n is 25, and 22⋅25=250<1016.For any integer j between 2 and 2n (inclusive), all paths cross exactly one cell (x,y) such that x+y=j.For any cell (x,y), you can move to either one or two cells, and if you can move to two cells, then exactly one of those will have x′ even and exactly one of those will have x′ odd, as the cells will necessarily be (x+1,y) and (x,y+1) which have different parities of x′.This means that the sum on any path will be the sum of distinct powers of 2 between 22 and 22n (inclusive), meaning that given that we know which cell (x,y) the path crossed satisfying x+y=j, we can determine which cell (x′,y′) the path crossed satisfying x′+y′=j+1 by checking whether the path sum contains 2j+1 and then appropriately selecting either (x′,y′)=(x+1,y) or (x′,y′)=(x,y+1). We know that the path must start at (1,1) so we can therefore easily determine the rest of the path given the sum.

Solution (Kotlin) by TlatoaniSolution (Java) by golionsSolution (C++) by hugopmIdea: Tlatoani

Preparation: Tlatoani and golions

1392F - Omkar and LandslideFun fact: This problem was originally proposed as B.

TL;DR: We can show that in the resulting array, every pair of adjacent elements differs by exactly 1 except that there may be at most one pair of adjacent equal elements. It is easy to see that there is only one such array satisfying that condition that also has the same length and sum as the given array, so we simply calculate that array based on the sum of the given array.

Proof: Clearly, the order in which we perform the slides (transfers of one square meter of dirt from aj+1 to aj for some j) does not matter. Consider then performing slides in the following manner: whenever we perform a slide from aj to aj−1, after that slide, if it is possible to perform a slide from aj−1 to aj−2, we will do so, and then from aj−2 to aj−3 and so on. We will call this action "performing a sequence of slides from aj".

Assume that we have just performed a sequence of slides from aj. We can see that if there was a pair of adjacent elements to the left of aj that were equal, i. e. some k<j such that ak−1=ak, then, assuming that ak−1,ak is the rightmost such pair, then the sequence of slides that we started will end with ak being increased. In this case, ak−1 and ak are no longer equal, but ak,ak+1 may now be equal, so the amount of pairs of adjacent equal elements to the left of aj has either decreased or stayed the same.

On the other hand, if there was no such pair, then the sequence of slides would end with a1 being increased, meaning it might now be true that a1 and a2 are equal, so that the amount of pairs of adjacent equal elements to the left of aj is either still 0 or now 1.

Combining these two facts, we see that if there were either 0 or 1 pairs of adjacent equal elements to the left of aj to start with, then there will only be either 0 or 1 pairs of adjacent equal elements to the left of aj after performing a sequence of slides from aj.

Noting that as our array is initially strictly increasing, there are initially no pairs of adjacent equal elements, we can simply first perform as many sequences of slides from a2 as possible, then perform as many sequences of slides from a3 as possible, and so on, until we perform as many sequences of slides from an as possible. When we are performing sequences of slides from aj, there can clearly only be either 0 or 1 pairs of adjacent equal elements to the left of aj, and there can't be any such pairs to the right of aj as that part of the array hasn't been touched yet and is therefore still strictly increasing. Therefore, we can conclude that once all possible slides have been performed, the entire array will contain at most 1 pair of adjacent equal elements.

Since it cannot be possible to perform any more slides once all possible slides have been performed, all pairs of adjacent elements that are not equal must differ by at most 1. It is easy to see that there is only one array satisfying these conditions that has the same length n and sum S=∑nj=1aj. You can construct this array by starting with the array 0,1,2,…,n−1, then adding 1 to each element from left to right, looping back to the beginning when you reach the end, until the sum of the array is S. From this construction we can derive the following formula for the array:

aj=j−1+⌊S−n(n−1)2n⌋+{j≤(S−n(n−1)2)%n}where {C} is 1 if the condition C is satisfied, and 0 otherwise.

EDIT: The fact that the order of operations doesn't matter turned out to be harder to prove than I thought (thanks to the comments for pointing this out), so I decided to add the following proof:

If you have two sequences of maximal operations, then what we want to show is that they have to consist of the same operations (possibly in different orders). Since they are both maximal, they must either both be empty or both be nonempty. If they are both empty then we are done.

If they are both nonempty: consider the current state of the vector (before applying either sequence of operations). Since the sequences are nonempty, there is at least one operation α that can be immediately applied on the vector.

Here we should make the observation that applying an operation at some index cannot prevent operations at other indexes from being able to be applied (it can only allow other operations to be applied).

Therefore, applying other (different) operations cannot prevent operation α from being able to be applied, so operation α must occur in both sequences. From our observation, we can see that if, in either sequence, operation α does not occur initially, then operation α can be applied initially because by performing it earlier we are not preventing any of the operations in between from being applied.

Thus, the first operation of each sequence is now the same, so we can apply the same argument to the remainder of the sequence (since it must be finite).

Solution (Kotlin) by TlatoaniSolution (Java) by qlf9Solution (C++) by DevilIdea: Tlatoani

Preparation: Tlatoani and qlf9

1392G - Omkar and PiesConsider any two binary strings u and v of length k. Notice that if you swap the bits at positions α and β in u and also swap the bits at positions α and β in v, then the amount of common bits in u and v remains the same. Furthermore, you can do this multiple times – i. e. applying the same sequence of swaps to u and v doesn't change their amount of common bits.

Let's apply this to the problem at hand. Assume that Omkar has selected the subsegment of elves between some l and r. Let s be Omkar's original binary string, let s′ be s after applying the subsegment of swaps between l and r (inclusive) to it, and let t be Omkar's ideal binary string. Now consider applying all the swaps in the subsegment from 1 to r (inclusive) to both s and t, but in reverse – first we apply the r-th swap, then the r−1-th swap, and so on, until we finally apply the 1-st swap.

From our first observation, these new strings s′′ and t′′ have the same amount of common bits as s′ and t. We additionally notice that just as t′′ is t with the subsegment of swaps from 1 to r applied in reverse, s′′ is actually s with the subsegment of swaps from 1 to l−1 applied in reverse, as the subsegment of swaps from l to r that were applied to s to create s′ has been undone.

Let us then define some more strings as follows: for all j such that (0≤j≤n), let sj be the result of applying the subsegment of swaps from 1 to j in reverse to s, and let tj be the result of applying the subsegment of swaps from 1 to j in reverse to s (so s0=s and t0=t). We now see that the amount of common bits that result from choosing a subsegment of swaps between l and r is equivalent to the amount of common bits between sl−1 and tr, and so the problem is now simply to find two indices j1 and j2 such that j2−j1≥m and the amount of common bits between sj1 and tj2 is the maximum possible.

Here we make another observation: if ω is the amount of common bits between two binary strings u and v of length k, ϵ is the amount of bits set to 1 in u, ζ is the amount of bits set to 1 in v, and λ is the amount of common bits set to 1 in u and v, then ω=2λ+k−ϵ−ζ. Since we are only comparing strings derived from performing swaps on s to strings derived from performing swaps on t, and swaps don't change the overall amount of 1 bits in a string, ϵ and ζ, like k, are constants – ϵ is the amount of 1 bits in s, and ζ is the amount of 1 bits in t. This means that maximizing ω, the amount of common bits in u and v, is equivalent to maximizing λ, the amount of common 1 bits in u and v.

Therefore, we can now proceed with bitmask DP to finish the problem. For a binary string μ of length k, let leftμ be the smallest index j such that μ is a subset of sj considering 1 bits, and let rightμ be the largest index j such that μ is a subset of tj considering 1 bits. These DP values are straightforward to compute, and we can obtain our answer by choosing the subsegment of swaps from leftμ to rightμ for any μ with the largest amount of 1 bits such that leftμ and rightμ both exist and rightμ−leftμ≥m.

Solution (Kotlin) by TlatoaniSolution (Java) by qlf9Solution (C++) by mohammedehab2002Idea: Tlatoani

Preparation: Tlatoani

1392H - ZS Shuffles CardsFirstly, let's find a simple dp. Let f(x) denote the expected time before the game ends with the deck is full (with n+m cards) and S contains n−x elements. Hence, f(0)=0. Our goal is to find f(n).

Suppose the jokers are also numbered from 1 to m and S contains n−x elements. Consider the cards drawn before we draw our first joker (which causes the deck to be reshuffled). Suppose we draw i cards with a number, l of which is a number not in S, before drawing our first joker. There are (xl)⋅(n−xi−l)⋅i! ways to choose and permute the first i cards, m ways to choose the first joker and (n+m−i−1)! ways to permute the cards that were not drawn. The total time taken is i+1+f(x−l). Hence,

f(x)=∑l=0x∑i=0n(xl)(n−xi−l)⋅i!⋅m⋅(n+m−i−1)!(n+m)!⋅(f(x−l)+i+1).This gives us an easy O(n3) solution. Note that f(x) is also on the right hand side, so you need to move the corresponding term to the left first before computing (this is not difficult).

To optimize our solution, we just need to manipulate the sums. I will show how to simplify ∑l=0x∑i=0n(xl)(n−xi−l)⋅i!⋅m⋅(n+m−i−1)!(n+m)!⋅(i+1). The way to simplify ∑l=0x∑i=0n(xl)(n−xi−l)⋅i!⋅m⋅(n+m−i−1)!(n+m)!⋅f(x−l) is analogous.

We have

∑l=0x∑i=0n(xl)(n−xi−l)⋅i!⋅m⋅(n+m−i−1)!(n+m)!⋅(i+1)=m⋅x!⋅(n−x)!(n+m)!⋅∑l=0x1l!(x−l)!∑i=0n(i+1)!⋅(n+m−i−1)!(i−l)!⋅(n−x−i+l)! (expanding and regrouping)

=m⋅x!⋅(n−x)!(n+m)!⋅∑l=0x(m−1+x−l)!(l+1)(x−l)!∑i=0n(i+1)!(l+1)!(i−l)!⋅(n+m−i−1)!(n−x−i+l)!(m−1+x−l)! (making binomial coefficients appear)

=m⋅x!⋅(n−x)!(n+m)!⋅∑l=0x(m−1+x−l)!(l+1)(x−l)!∑i=0n(i+1l+1)(n+m−i−1m−1+x−l)Recall that ∑i(ia)(n−ib−a)=(n+1b+1), because we can count the right hand side by fixing the position of the (a+1)-th element, where i denotes the number of elements on the left of the (a+1)-th element.

Hence,

=m⋅x!⋅(n−x)!(n+m)!⋅∑l=0x(m−1+x−l)!(l+1)(x−l)!⋅(n+m+1m+x+1)=m⋅x!⋅(n−x)!(n+m)!⋅(n+m+1m+x+1)⋅∑l=0x(m−1+x−l)!(x−l)!⋅(l+1)=m⋅x!⋅(n−x)!(n+m)!⋅(n+m+1m+x+1)⋅∑l=0x(m−1+l)!l!⋅(x−l+1).

We can compute the latter sum in O(1) via prefix sums (after splitting x+1 and −l). A similar computation can be done for ∑l=0x∑i=0n(xl)(n−xi−l)⋅i!⋅m⋅(n+m−i−1)!(n+m)!⋅f(x−l).

Hence, f(x) can be computed in O(1) (with prefix sums) for x=1 to n. This gives a O(n+m) time solution if you precompute factorials.

Solution (C++) by zscoderSolution (Java) by qlf9Solution (Kotlin) by TlatoaniIdea: zscoder

Preparation: zscoder

1392I - Kevin and GridAn obvious solution would be to do DFS, but it is O(nmq).

Firstly we focus on answering a single question.

We represent our input with two graphs (one for cells with temperature less than X and other for temperatures greater than X), in which we add an edge between two neigbouring cells.

As it is a subgraph of the grid graph, this means that this graph is planar and thus we may apply Euler's formula on both graphs:

V1+F1=E1+C1, where V1 is the number of vertices in graph 1, F1 is the number of faces in graph 1, ….

However, some faces are not interesting, namely the 2×2 square of adjacent cells. Let Q1 be the number of such squares.

Similarly, V2+F2=E2+1+C2.

We see that interesting faces in graph 1 represent connected components in graph 2 that cannot reach the border, and vice-versa. In this way, if we subtract the equations, we get C1−F1+F2−C2=V1−E1+E2−V1+Q1−Q2. We can observe that, because of this interpretation, the LHS of the equation is the answer.

We have to devise an algorithm to calculate efficiently the number of squares/edges. Letś calculate horizontal edges, and do the same for vertical edges.

Firstly, if ai+bj≥X and ai+bj+1≥X then ai+min(bj,bj+1)≥X. So we create array B such that Bj=min(bj,bj+1).

The number of edges is the number of indexes i,j such that ai+Bj≥X.

This trick can also be used to calculate edges in cold regions.

To have a more efficient solution, we must calculate faster the number of indexes i,j such that ai+Bj≥X.

We can thus apply fast Fourier transform to arrays representing frequencies of a and B and multiply them, inverting the Fourier transform in order to get the answers quickly in O(1) with prefix sums.

By doing this we can calculate the number of edges, and the number of 2×2 squares can be calculated in a similar way.

The final complexity is, thus, O((n+m)log(n+m)+max(ai,bi)log(max(ai,bi)))Solution (C++) by KLPPIdea: KLPP

Preparation: KLPP

Codeforces Global Round 9 — Editorial

By enoone, history, 3 years ago, In EnglishProblem A1375A - Sign FlippingNotice that ai+1−ai≥0 is equivalent to ai+1≥ai. Similarly ai+1−ai≤0 is equivalent to ai+1≤ai. Flip the signs in such a way that ai≥0 for odd i, while ai≤0 for even i. Then

ai+1≥0≥ai, and thus ai+1≥ai, for i=2,4,…,n−1.ai+1≤0≤ai, and thus ai+1≤ai, for i=1,3,…,n−2.Giving at least n−12  of each, as desired.

Problem A authors — antontrygubO_o, Ari

Problem B1375B - Neighbor GridFor every cell (i,j) let's denote by ni,j the number of neighbors it has (either zero or non-zero, it doesn't matter). Then for each cell, it must hold that ai,j≤ni,j, otherwise, no solution exists because it is impossible to decrease ai,j.

Let's now suppose that ai,j≤ni,j for all cells (i,j). Then a solution always exists: We can increase each ai,j to make it equal to ni,j. This always works because every number will be non-zero, so every neighbor of every cell will be non-zero, and every cell has a value equal to its number of neighbors.

Problem B author — Ari

Problem C1375C - Element ExterminationThe answer is YES iff a1<an. Let's find out why.

When a1<an, we can repeatedly use this algorithm while the permutation contains more than one element:

Find the smallest index r such that a1<ar.Choose ar and the element comes right before ar and delete the element before ar.Repeat step 2 until ar is adjacent to a1.Choose a1 and ar, and delete ar.This algorithm is valid because since r is the smallest index such that a1<ar, every element between a1 and ar is less than a1 and therefore less than ar, so all of them can be deleted when pairing up with ar.When a1>an, we have some observations:

The leftmost element is non-decreasing. That is because if we want to remove the old leftmost element a1, we need to pair it with a2>a1, and that will result in the leftmost element increasing.Likewise, we can use the same argument to show that the rightmost element is non-increasing.Therefore, the leftmost and rightmost elements can never pair up, hence our permutation cannot be reduced to one element.Problem C author — Kuroni

Problem D1375D - Replace by MEX(We consider the array 0-indexed)

Instead of trying to reach any non-decreasing array, we will try to reach precisely [0,1,…,n−1].

Let's call any index i such that ai≠i an unfixed point. We will repeat the following procedure in order to remove all unfixed points:

If mex=n, we apply an operation on any unfixed point.Now that mex<n, we apply an operation on index mex (which was an unfixed point, since mex was not present in the array).Each turn uses at most 2 operations, and decrease the number of unfixed points by exactly 1. Since there are at most n unfixed points initially, we use at most 2n operations.

It was not necessary under the given constraints, but one can notice that if mex=n, the current array is a permutation, and that solving a cycle will take size+1 operations. Hence, the described algorithm use in fact at most 1.5n operations, the worst case being [1,0,3,2,5,4,…] when there are a lot of 2-cycles.

Since the constraint on n is low, we can recompute naively the mex each time in O(n), leading to an O(n2) final time complexity.

Problem D author — hugopm

Problem E1375E - Inversion SwapSortWe can prove that the answer always exists. Let's first solve the problem for a permutation of length n.

Let's define posi(1≤i≤n) as the index of i in the permutation.

First we are going to use all the pairs whose second element is n. Let's define the resulting permutation that we get, after using all these pairs in some order, as b. We want b to satisfy all of these conditions.

bn=nIf ai>aj then bi>bj (1≤i<j≤n−1)If ai<aj then bi<bj (1≤i<j≤n−1)We can achieve this if we use the pairs in the order (posan+1,n),(posan+2,n),...,(posn,n). It can be easily seen that after doing this an+k (0≤k≤n−an−1) in the resulting permutation will have the same position that an+k+1 had in the starting permutation. So basically after doing operations in this order we are decreasing all the values in the starting permutation that are greater than an by 1 and we make the last element equal to n. It can be easily proven that this permutation satisfies the conditions listed above. After this we can remove the last element and solve the problem for the remaining part of the permutation (which is a permutation itself because the last element was n). This way all the pairs of inversions that are in the new permutation coincide with the unused pairs written on the paper.So we solved the problem for a permutation, how can we approach the general problem? For every i>j,ai=aj we can assume that ai>aj, and this won't change anything because the order of equal elements doesn't matter and we are not adding any inversions by assuming this. So after doing this we can easily squeeze the numbers into a permutation and solve the problem for a permutation.

Total complexity O(n2logn) or O(n2).

Problem E author — enoone

Problem F1375F - Integer GameLet's prove that the first player can always win in at most three turns. Assume that the initial numbers of stones are p<q<r. On the first turn, choose y=2r−p−q. We then have three cases:

Case 1. y is added to p.

The piles now have 2r−q, q and r stones. Now choose y=r−q. Since the pile with 2r−q stones cannot be chosen on this turn, this results in a win.

Case 2. y is added to q.

The piles now have p, 2r−p and r stones. Choose y=r−p. Similarly to the previous case this results in a win since the pile with 2r−p stones cannot be chosen on this turn.

Case 3. y is added to r.

The piles have p<q<3r−p−q stones. We now have a situation similar to the initial one, with the difference that the pile with the largest number of stones cannot be chosen on the next turn. Thus we may repeat the strategy and obtain a guaranteed win this time.

Problem F author — antontrygubO_o

Problem G1375G - Tree ModificationThe solution is based on the following observation: Every tree is a bipartite graph, i. e. its vertices can be colored black or white in such a way that every white vertex is adjacent only to black vertices and vice versa. Notice that a tree is a star if and only if one of the colors appears exactly once.

Let's fix a bipartite coloring of the tree and look at what happens when we apply the operation to vertices a, b, and c. For concreteness, let's suppose that b is black, so a and c must be white. When we perform the operation:

Every neighbor of a other than b is black. After connecting it to c it remains black since c is white.After connecting a to c it must switch from being white to being black since c is white.Every other vertex is unaffected by the operation.Thus every operation changes the color of exactly one vertex! Suppose that initially there are b black vertices and w white vertices. Then we need at least min(w,b)−1 operations to turn the tree into a star since one of the colors must end up having a single vertex. This is always achievable: as long as there are at least two vertices with a certain color we can choose two which are adjacent to a common neighbor and use the operation to recolor one of them.

The values of w and b can be found through a simple DFS, leading to an O(n) solution.

Problem G author — antontrygubO_o

Problem H1375H - Set MergingFirst, two sets a and b can be merged if and only if the range of elements in a do not intersect with the range of elements in b. It is obvious because if they intersect, neither g(a)<f(b) nor g(b)<f(a) are satisfied. If they do not intersect, there must be one of them satisfied.

Notice that 2×n√q is near to 2.2×106, this hints us to use sqrt-decomposition.

We separate the numbers 1,2,⋯,n into nS  consecutive blocks, each of size S.

Consider a block Bi=[l,r], we take all elements in the original permutation that satisfy l≤ai≤r, and form a new sequence that preserves the original order.

For example, if the permutation 9,8,2,1,5,6,3,7,4 is divided into 3 blocks B1=[1,3],B2=[4,6],B3=[7,9], their sequences will be 2,1,3 and 5,6,4 and 9,8,7.

Consider any consecutive subsequence in the permutation. We want to construct a set that just contains all elements in it. We can first divide this subsequence into nS  subsequences in each block that contains only elements in this block and merge them up.

For example, if we want the subsequence 8,2,1,5,6,3,7 in the permutation above, then we can divide it into 2,1,3 and 5,6 and 8,7.

Notice that those subsequences in each block are also consecutive subsequences. Also, notice that since the range of elements in each block do not intersect, the range of elements in these subsequences also do not intersect. This means that if we can somehow construct the set that equals the set of each of those subsequences, we can just merge those subsequences of each block to form the original subsequence that we want to obtain in nS −1 merges.

Thus the process of constructing sets in total costs less that qnS  merges.

Now we have to construct the subsequences of each block, notice that the subsequences are consecutive, thus we can just construct sets of all of those 12 S(S+1) consecutive subsequences.

Consider divide and conquer. We can divide a sequence in to two parts of equal size, construct subsequences of them, and try to merge them to obtain the new sets. So how do we split and merge?

Consider two sequences, that elements in the first sequence is less than elements in the second, and we have already constructed the sets of all the consecutive subsequences in each of those sequences. Now we consider a sequence that contains the union of the elements in the two subsequences. All elements in sequences here are ordered according to the order in the original permutation. Now we want to construct all the consecutive subsequences in the new sequence. Consider for each consecutive subsequence in the new sequence, it must be composed by two parts, the ones present in the first sequence, and the one present in the second. It is obvious that each part is also a consecutive subsequence in the respective sequence, thus the sets representing them is already constructed. Because the two sequence do not intersect in range of elements, we can just merge those two sets to form the new one.

For example, we want to obtain all subsequences of the sequence 1,4,3,2,6,5, and we have already obtained the ones of 1,3,2 and 4,6,5.

So if we want to get the consecutive subsequence 1,4,3,2,6, we first divide it into 1,3,2 and 4,6. Because the sets of them are already constructed(they are consecutive subsequences of 1,3,2 and 4,6,5), and their range of elements do not intersect, we can merge it in one operation.

Other consecutive subsequences can also be obtained similarly.

Thus there are 12 S(S+1) subsequences, and less than 12 S(S−1) need a merge operation (because those with only one element in it need no operation).

We use f(S) to denote the number of operation needed to construct all consecutive subsequences of a block of length SThere is f(1)=0 and f(x)≤12 x2+f(⌊x/2⌋)+f(⌈x/2⌉),(if we divide a subsequence evenly),it can be proved that f(x)≤x2So, we need nS ×S2 operations to construct all consecutive subsequences.

So in total, nS+nqS  operations are needed. According to the mean inequality, there is nS+nqS ≥2√n2q=2n√q, and if S=√q, nS+nqS =2√n2q=2n√qAnd, 2n√q≤221<2.2×106, thus the restriction is satisfied.

Also, there exists a solution based on segment-tree.

The main idea is to maintain a segment-tree of 1 to n, in each node, we save a hash-map of sets with elements in the range of that node already constructed.

Anytime we want a new set, we do a query on the segment tree, if the set on that node is constructed, we return it. Otherwise, we split the wanted set into two parts, and query on its sons, and merge them.

The details is omitted due to laziness issue.

And we find that this solution can pass, why?

Suppose n=2N and q=2QWe can calculate that we need no more than

n∑i=0 2N−imin(22i−1,2Q)sets. This is because in the ith layer(bottom to top) of the segment-tree, there are 2N−i nodes, each one can contain no more than 2i(2i−1)/2 sets (the consecutive subsegment limitation). but it is also bounded by 2Q queries, because a query can only visit a node at most once.

Calculating this sum yield a bound lower that the resiriction.

Also we can find that this solution is similar to the previous sol.

We find that

For i≤Q/2,the sum is

Q/2∑i=0 2N−i22i−1= Q/2∑i=0 2N+i−1≤2N+Q/2And for i>Q/2 the sum is

2Q N∑i=Q/2+1 2N−i≤2Q2N−Q/2=2N+Q/2Summing these two parts yield 2N+Q/2+1 which is also 2n√qSo these solutions have the same complexity.

Other than that, we observe that the lower-Q/2 layers is just like those blocks constructed in the first solution, only the merging in the upper one is different, the first solution used brute-force, while the second just extended the segment-tree up.

Thus, we say that the first solution is just the second one, but bounded manually. So these two solutions are intrinsically similar.

Problem H authors — Ynoi, dengyaotriangle

Problem I1375I - Cubic Lattice2-dimensional version of this problem appeared as problem K in Makoto Soejima Contest 4 from Petrozavodsk Winter Training Camp 2016 (Also known as GP of Asia in OpenCup XVI). Solution for this case is based on the fact that the whole lattice equation may be represented as the product of two Gaussian integers ak=αk⋅g, where g is the complex number representing ( →r 1, →r 2) basis. Thus, the solution was to find largest g which divides every point ak. This can be done with Euclidean algorithm.

Similar idea applies to this problem except for rotations in 3-dimensional case are represented with quaternions rather than complex numbers. You may get some basic notion of quaternions from this article. Note that in 3-dimensional space if integer vectors  →r 1,  →r 2 and  →r 3 are pairwise orthogonal and have the same length, then their length is an integer number as well. This is due to the fact that  →r 3 may be represented explicitly in the following form:

→r 3=±→r 1× →r 2|r1| We should note here that both  →r 3 and  →r 1× →r 2 have integer coordinates, thus |r1| is rational. But since |r1|2 is integer, we may conclude that |r1| is integer as well. This brings us to the conclusion that vectors →r 1| →r 1| , →r 2| →r 2|  and →r 3| →r 3|  have rational coordinates, thus the transformation which maps basis vectors  →e x,  →e y and  →e z into  →r 1,  →r 2 and  →r 3 may be represented as the combination of rational rotation and scaling, that is:

→v ↦k⋅q⋅ →v ⋅ ˉq q⋅ ˉq  Here q=s+ix+jy+kz is an integer quaternion representing the rotation,  ˉq =s−ix−jy−kz is its conjugate quaternion, and k=r is some integer scaling factor.

If we write this transform explicitly in matrix form, its matrix will be as follows:

ks2+x2+y2+z2 ⋅( s2+x2−y2−z2	2xy−2sz	2xz+2sy2xy+2sz	s2−x2+y2−z2	2yz−2sx2xz−2sy	2yz+2sx	s2−x2−y2+z2 )Since this transform maps  →e x,  →e y and  →e z to integer vectors  →r 1,  →r 2 and  →r 3, all matrix elements should be integer. That is, if we reduce the fraction ks2+x2+y2+z2 , its denominator should divide every matrix element. Without loss of generality we may assume that gcd(s,x,y,z)=1, because otherwise we may simply reduce all quaternion coordinates by this common divisor and matrix elements will stay same. Now if ks2+x2+y2+z2 =PQ  then Q should divide every element of the matrix and it also should divide s2+x2+y2+z2. Thus, it divides:

gcd( s2+x2+y2+z2s2+x2−y2−z2s2−x2+y2−z2s2−x2−y2+z2 )=gcd( s2+x2+y2+z22(y2+z2)2(x2+z2)2(x2+y2) )=gcd( s2+x2+y2+z22(y2+z2)2(x2+z2)4z2 )Here we utilized the fact that gcd(a±b,b)=gcd(a,b)=gcd(−a,b). Next thing to note is that gcd(a,b) always divides gcd(k⋅a,b), thus Q should divide:

gcd( 4(s2+x2+y2+z2)4(y2+z2)4(x2+z2)4z2 )=4gcd(s2,x2,y2,z2)=4Which means that every transform we're looking for may be represented in the following form:

→v ↦k4 ⋅q⋅ →v ⋅ ˉq Where q is some integer quaternion with gcd(s,x,y,z)=1 and k is some integer scaling factor. Quaternions having all integer components are called Lipschitz quaternions. But in this problem we will need to find greatest common divisor of some quaternions and using Lipschitz quaternions won't be enough for us because they don't form an Euclidean domain. Instead, we'll stick to Hurwitz quaternions in which it's also allowed for quaternion to have all of its coordinates semi-integer. With such quaternions we may further divide quaternion by 2 if all its components are odd, which will reduce the set of possible denominators to {1,2} only, thus in Hurwitz quaternions any transform may be represented as:

→v ↦k2 ⋅q⋅ →v ⋅ ˉq Now, given this knowledge, we have to find a Hurwitz quaternion q and scaling factor k such that every point from the set A is the image of some integer vector under this transform. Basically, we assume here that  →r 1,  →r 2 and  →r 3 are images of unit basis vectors  →e x,  →e y and  →e z. If this is true, then ak=uk⋅ →r 1+vk⋅ →r 2+wk⋅ →r 3 is the image of the vector bk defined as bk=uk⋅ →e x+vk⋅ →e y+wk⋅ →e z.

For simplicity we will further work with vectors ai multiplied by 2, as in this way we may safely assume that they were obtained with v↦k⋅q⋅ →v ⋅ ˉq  mapping. Now we should further work with the quaternion g=gcd(a1,…,an) which is obtained as GCD of input vectors as if they were Hurwitz quaternions and with the number G=gcd(‖a1‖,…,‖an‖), where ‖q‖=q⋅ ˉq =s2+x2+y2+z2 is the norm of q. Among major properties of quaternionic norm we should note that it's multiplicative, that is ‖a⋅b‖=‖a‖⋅‖b‖. Due to this we may conclude that ‖k‖⋅‖q‖2=k2‖q‖2 should always divide G. Thus with the number G fixed there may only be at most O(G1/6) possible values of ‖q‖ which may be found in O(G1/3) because if a2 divides b then either a or b/a is at most b1/3.

In our problem G may only be up to 1016, which makes it up to nearly 500 candidate numbers for being equal to ‖q‖ which may be found in ≈2.5⋅105 arithmetic operations. Now to check if it's possible to obtain q with ‖q‖ being fixed we should look on the quaternion g. Under given constraints g is primitive (not divisible by any integer constant larger than 1). It may be proven thus that if g is primitive and ‖g‖=ab then g may be uniquely (up to units) represented as g=qp where ‖q‖=a and ‖p‖=b. Due to this if we fix ‖q‖ we may find actual q as gcd(g,‖q‖) because q ˉq =‖q‖. After this we only have to check if this q actually produces all points from the input set, which may be done in O(n). Therefore, the total complexity of described solution is O(G1/3+G1/6n).

Problem I author — adamant

Codeforces Global Round 8: editorial

By Endagorion, history, 3 years ago, In EnglishThank you for waiting! I hope you've enjoyed the problems. Let me know what you think in the comments!

UPD: I almost forgot but here are some notes, as well as challenges for all problems. For a lot of them I don't have a solution and would be happy to hear your ideas.

1368A - C+=After any operation either a or b becomes a+b. Out of the two options, clearly it is better to increase the smaller number. For example, with numbers 2,3 we can either get a pair 2,5 or 3,5; to obtain larger numbers, the last pair is better in every way.

With this we can just simulate the process and count the number of steps. The worst case is a=b=1, n=109, where each new addition produces the next element of the Fibonacci sequence. At this point we can just run the simulation and find out that 43 steps are always enough. In general, Fibonacci sequence grows exponentially, thus O(logn) steps are needed.

Challenge (awful)1368B - Codeforces SubsequencesSuppose that instead of codeforces subsequences we're looking for, say, abcde subsequences. Then in an optimal string all a's appear at the front. Indeed, moving any other occurence of a to the front will leave all the other occurences intact, and can only possibly create new ones. For a similar reason, all b's should immediately follow, then go all c's, and so on.

The only question is how many a's, b's, etc should we take. The answer is we should have quantities of each letter as close as possible to each other. Indeed, the number of subsequences is na×nb×…×ne, where na,nb,… are the number of occurences of each letter. If, say, na−nb>1, then it is not hard to show that transforming an a to a b increases the product. Now the optimal distribution can be obtained simply by increasing na,nb,… one by one in a loop. We should stop once the product is at least k.

This approach will, however, not work quite as well if the subsequence has repeated letters. Still, it is natural to expect that the same pattern applies to optimal strings with codeforces subsequences: it has a lot of unique letters, and repeated letters are far apart. It was hardly necessary, but here's one way to prove that the pattern works (math and casework alert):

Letters d, f, r, s should form consecutive blocks. If, say, two d's are separated by other letters, we can look which d is present in fewer number of subsequences, and more it next to the more popular one. The same argument works for all other letters.It doesn't make sense to put anything other than e's between d's and f's. Indeed, any other letter won't be present in any subsequences. Similarly, there can only be o's between f's and r's. Now we know the string looks like ???dddeeefffooorrr???sss.Finally, only c's and o's can precede d's, and it doesn't make sense to place o's before c's. Similarly, c's and e's in this order occupy the space between r's and s's.It follows that the same solution as above can be applied to solve this problem.

Challenge (?)Notes1368C - Even PictureThe sample picture was a red herring, it's hard to generalize to work for arbitrary n. After drawing for a while you may come up with something like this:

or like this:

or something even more complicated. Of course, having a simpler construction (like the first one) saves time on implementation compared to other ones. Don't settle for a solution if it feels too clunky, take a moment and see if you can make it simpler.

Challenge (probably doable)1368D - AND, OR and square sumLet's look at a single operation x,y→x AND y,x OR y, let the last two be z and w respectively. We can notice that x+y=z+w. Indeed, looking at each bit separately we can see that the number of 1's in this bit is preserved.

Clearly z≤w, and suppose also that x≤y. Since the sum is preserved, we must have z=x−d, w=y+d for some non-negative d. But then the sum of squares of all numbers changes by z2+w2−x2−y2. Substituting for z and w and simplifying, this is equal to 2d(d+y−x), which is positive when d>0.

Side note: an easier (?) way to spot the same thing is to remember that f(x)=x2 is convex, thus moving two points on the parabola away from each other by the same amount increases the sum of values.

It follows that any operation increases the square sum (as long as any numbers change), and we should keep doing operations while we can.

When can we no longer make meaningful operations? At that point all numbers should be submasks of each other. The only way that could happen is when for any bit only several largest numbers have 1 in that position. We also know that the number of 1's in each bit across all numbers is preserved. Thus, it's easy to recover the final configuration: for each bit count the number of 1's, and move all these 1's to the last (=greatest) numbers. For example, for the array [1,2,3,4,5,6,7] there are four 1's in each of the smallest three bits, thus the final configuration is [0,0,0,7,7,7,7]. Finally, print the sum of squares of all these numbers.

The total complexity is O(nlog2A), where A is the largest possible number (thus log2A is roughly the number of bits involved).

Challenge (?)1368E - Ski AccidentsLet's consider vertices from 1 to n (that is, in topological order). We divide them into three sets V0, V1, V2:

V0 contains all vertices that only have incoming edges from V2;V1 contains all vertices that have an incoming edge from V0, but not from V1;V2 contains all vertices that have an incoming edge from V1.It is not hard to see that erasing all vertices in V2 leaves no two-edge paths. The same solution can be simply rephrased as: go from left to right, and remove current vertex if it is at the end of a two-edge path.

Why does this work? Every vertex of V2 has to have at least one incoming edge from V1. There are at most 2|V1| such edges, thus |V2|≤2|V1|, and |V1|≥|V2|/2. Similarly, |V0|≥|V1|/2≥|V2|/4. But then n=|V0|+|V1|+|V2|≥|V2|(1+1/2+1/4)=7|V2|/4, thus |V2|≤4n/7.

This is very easy to implement in O(n) time.

Challenge (???)Notes1368F - Lamps on a CircleLet try to come up with an upper bound on R(n). Let x be the number of currently turned on lamps. Consider our last move that resulted in increasing x (after the response was made), and suppose it turned on k lamps. If the opponent could then find a segment of k consecutive lamps and turn them off, the move could be reverted. From this we can conclude that x could not be too large.

Indeed, after the move x+k lamps should have been divided into segments of length at most k−1 each (since the opponent couldn't turn k lamps off), separated by turned off lamps. The number of segments should have been at least x+kk−1, and the same bound applies to the number of separating lamps. Thus we must have had x+k+x+kk−1≤n. After some boring transformations we obtain x≤n−k−nk+1. It follows that x can not be increased past this threshold with turning on k lamps.

This implies that x can not be increased past maxk(n−k−nk+1) with any move, thus R(n)≤maxk(n−k−⌈nk⌉+1).

On the other hand, let's take such a k that maximizes n−k−⌈nk⌉+1, and adopt the following strategy:

Pick ⌈nk⌉ lamps that divide the circle into segments of length ≤k−1 each, and never turn these lamps on. We can choose these lamps greedily at distance k from each other, until we go full circle (at that point the distance from the last to the first lamp may be less than k).On each move, turn on any k lamps except for the forbidden ones. Since the turned on lamps never form a segment of length k, we will successfully increase x with this move.We stop once there are less than k non-forbidden lamps to turn on. At this point we will have x≥n−⌈nk⌉−k+1, thus R(n) can not be less than this value.We've determined that R(n)=maxk(n−k−⌈nk⌉+1), and provided a quite simple strategy to achieve this result. For large n, the maximum is attained at k≈n−−√, thus R(n)≈n−2n−−√.

Challenge (probably doable)1368G - Shifting DominoesLet's think of how a certain cell can be freed up. One way is to just lift the domino covering it from the start. If we didn't do it, then we must move the domino covering the cell, and there is exactly one way of doing so. But at this point the cell we've moved to should have been free. We can follow this chain of events, and we must eventually arrive to a cell that was covered by the initially removed domino.

This is more readily seen if we draw a graph with vertices being cells, and edges leading from the cell freed up by moving a domino to the cell becoming occupied by doing so. Note that some of the cells are impossible to free up with such a move.

Let us study this graph a bit more. If we color the board like a chessboard, we can see that edges always connect cells of the same color, so the two subgraphs for white and black cells are independent. Further, since initially a white and a black cell are freed, the two free cells will always have different colors.

In this graph each vertex (= cell) has out-degree at most 1. In general directed graphs of this kind are called functional graphs, and look like a bunch of trees linked to directed cycles. However, it turns out that our graph can not have cycles! To prove this, let's look a how this cycle would look like:

Centers of all the cells in a cycle form a lattice polygon. The area of such a polygon can be found with Pick's formula: S=I+B/2−1, where I and B is the number of lattice points inside and on the boundary respectively. However, we can observe that:

B is the length of the boundary. The boundary can be broken into segments of length 2. The length of upward and downward arrows is the same, therefore the length of vertical borders is divisible by 4, same for horizontal arrows. Thus B is divisible by 4, and B/2 must be even.Inside of the polygon can be broken down into 2×2 squares, therefore S must be even.I=S−B/2+1 should therefore be odd. However, the inside of the cycle is isolated from the outside, and therefore should be independently tilable with dominoes. But the number of cells (= vertices) inside the cycle is odd, therefore it's impossible.Since our directed graph has no cycles, it must be a directed forest, which makes it much easier to handle.

Now consider a pair of cells c1,c2 of different colors, and look at the paths P1 and P2 starting at these cells. If these paths reach the boundary without visiting the same domino, then the pair c1,c2 is impossible to free up, since we would have to remove at least two dominoes.

If the paths do visit at least one common domino, then we argue that the pair is possible to free up. Indeed, consider the first domino D on P1 that is also visited by P2. If we remove D, then the parts of P1 and P2 until D can not intersect, thus it is possible to move dominoes to free c1 and c2 without trying to move any domino twice.

To figure out the answer, consider the two forests F1 and F2 built up by black and white cells of the board. If we label each cell of each forest with the index of the domino covering this cell, then the answer is equal to the number of pairs of cells c1∈F1, c2∈F2 such that the paths starting at c1 and c2 have common labels. To actually compute the answer we will instead count the cell pairs with label-disjoint paths.

This is now a fairly standard data structure problem. Construct Euler tours in both F1 and F2. Then, the subtree of each vertex is a segment in the Euler tour. For a cell c1∈F1 labeled with domino D, suitable cells in F2 are the ones not in the subtree of a cell sharing the label with c1 or with any parent of c1.

Perform a DFS of F1, following edges in reverse. When we enter a cell labeled D, locate the cell with this label in F2 and mark all vertices in its subtree. At this point, we should add the number of unmarked cells in F2 to the answer. When we leave the cell, revert to the previous configuration before marking the subtree. Implementation-wise, this can be done with a segment tree that supports adding on a segment (= subtree in the Euler tour), and finding the number of zeros (= unmarked cells).

Segment tree is the most demanding component of the solution, thus the complexity is O(nmlog(nm)).

Challenge (?)Notes1368H2 - Breadboard Capacity (hard version)We are basically asked to find the maximum flow value from red ports to blue ports in the grid network. All edges can be assumed to be bidirectional and have capacity 1.

By Ford-Fulkerson theorem, the maximum flow value is equal to the minimum cut capacity. In our context it is convenient to think about minimum cut as a way to paint nodes inside the grid red and blue so that the number of edges connecting differently colored nodes is smallest possible.

For a given coloring, let us construct a cut in the dual graph by connecting the faces separated by multicolored edges.

Note that the cut can be decomposed into cycles, paths connecting two points on the border, and single edge cuts adjacent to the ports. We may assume that different parts of the cut do not cross each other since we can just reassign parts at the crossing.

The following actions modify the cut without increasing its capacity (the number of crossed edges):

Interior of any cycle can be recolored, which makes the cycle disappear.If a path connects a pair of adjacent sides, we may get rid of the path and instead cut/uncut ports in the corner separated by the path.

A path connecting opposite sides can be transformed into a straight segment, possibly with cutting/uncutting some ports.

Applying these operations to any minimum cut, we can obtain a minimum cut that only consists of port cuts and straight segments parallel to one of the sides.

Note that a port cut is essentially equivalent to recoloring of that port, with increase 1 towards the cut capacity. Each straight segment contributes n or m to the capacity depending on the orientation.

A minimum cut of the form above can be found with a simple linear dynamic programming. First, choose the direction of straight cuts (say, vertical). All ports along each vertical side should be recolored to the same color. Then, proceeding in the horizontal direction we may decide to recolor ports adjacent to horizontal sides, and/or to make a straight vertical cut. We need to make sure that each connected part between the cuts has uniform color.

In addition to the horizontal position, the only extra parameter for this DP is the color immediately behind the current vertical line. This solves the easy version of the problem.

To solve the hard version, we need to combine this DP with lazy propagation segment tree. We will store a separate segment tree for each direction of straight cuts. Say, for vertical cuts, a node [L,R) should store costs to properly recolor and/or make straight cuts in the horizontal range [L,R) so that the leftmost/rightmost nodes are red/blue (all four options). Make sure to take fixing vertical sides into account when calculating the answer. Merging the cost values from two halves of a node segment follows directly from the original DP recalculation.

To be able to make range flips fast enough, we need to store four more values — the answers assuming that the opposite sides take opposite colors instead of the same colors. Now to flip a node in the segment tree simply exchange the correct values with the opposite ones. Implementation details are left for the reader to work out. =)

With this approach we are able to process each modification query in O(logn+logm) time, although the constant factor is fairly large because of complicated merging process.

Challenge (running out of ideas)

Codeforces Global Round 7 — Editorial

By isaf27, history, 3 years ago, In EnglishThe problems A, C, D, G are authored and prepared by isaf27.

The problems B, E, F are authored and prepared by 300iq.

1326A - Bad Ugly NumbersIf n=1, no solution exists.

Otherwise, if n≥2, the number 233…3¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯ (n digits) satisfies all conditions, because it is not divisible by 2 and 3.

Jury solution: link

1326B - MaximumsLet's restore a1,a2,…,an from left to right.

a1=b1.

For i>1, xi=max(a1,…,ai−1), so we can maintain the maximum of previous elements and get the value of xi. Using this value, we can restore ai as bi+xi.

Jury solution: link

1326C - Permutation PartitionsNote that the maximum possible partition value is equal to (n−k+1)+…+(n−1)+n.

Let's define a1,a2,…,ak as positions of the numbers (n−k+1),…,n in the increasing order (a1<a2<…<ak). The number of partitions with the maximum possible value is equal to ∏i=1k−1(ai+1−ai).

This is true because if we have the maximum possible value, each of the segments in a partition should contain exactly one of the values (n−k+1),…,n, and thus, one of the positions a1,a2,…,ak. So, between each pair of neighboring positions, we should choose exactly one of the borders of the segments in the partition. There are (ai+1−ai) ways to do this.

Jury solution: link

1326D2 - Prefix-Suffix Palindrome (Hard version)Each possible string t can be modeled as s[1..l]+s[(n−r+1)..n] for some numbers l,r such that 0≤l,r and l+r≤n.

Let's find the maximum integer 0≤k≤⌊n2⌋ such that s1=sn,s2=sn−1,…,sk=sn−k+1.

In some optimal solution, where t is as long as possible, min(l,r)=k. This is because if min(l,r)<k, we can increase l or r by 1 and decrease the other variable by 1 (if needed), and the string will be still a palindrome.

So if we know that min(l,r)=k, we just need to find the longest palindrome w that is a prefix or suffix of the string s[(k+1)..(n−k)]. After that, the answer will be s[1..k]+w+s[(n−k+1)..n].

In order to find the longest palindrome which is a prefix of some string, a, let's find p from the prefix function of the string a+ '#' +a¯¯¯, where a¯¯¯ represents the reverse of a. The string a[1..p] will be the longest palindrome which is a prefix of a.

After that, we can repeat this process for a¯¯¯ to find the longest palindrome which is a suffix of the string.

Time complexity: O(|s|).

Jury solution: link

1326E - BombsLet's come up with some criteria that answer is <x.

We claim that the answer is <x if:

There is at least one bomb after the rightmost value ≥x.There are at least two bombs after the next rightmost value ≥x....

There are at least k bombs after the k-th rightmost value ≥x.Let ansi be the answer for bombs q1,q2,…,qi−1.

Then, ansi≥ansi+1.

Let's add new bombs starting from ansi−1, and while the actual answer is smaller than the current answer, decrease the actual answer.

To do this quickly, we'll use a segment tree.

In the segment tree, let's store bi= (number of values ≥x on suffix i…n) − (number of bombs on this suffix).

Then, the real answer is <x if bi≤0 for all i.

Using range addition updates and max queries, we can update b and decrease the answer quickly.

The total complexity is O(nlogn).

Bonus: is it possible to solve the problem in O(n)?

Jury solution: link

1326F2 - Wise Men (Hard Version)For each binary string s, let's calculate f(s) – the number of permutations, such that, if si=1, then pi and pi+1 know each other, otherwise, they may know or don't know each other.

To get real answers, we may use inclusion-exclusion, which may be optimized using a straightforward sum over subsets dp.

To calculate f(s), we need to note that f depends only on the multiset of lengths of blocks of 1's in it.

For example, f(110111)=f(111011), because the multiset of lengths is {1,3,4} (note that block of size x of 1's corresponds to length x+1).

And note that there are exactly P(n) (the number of partitions of n) possible multisets.

P(18)=385To process further, at first let's calculate glen,mask – the number of paths of length len, which pass only through the vertices from mask (and only through them).

You can calculate it with a straightforward dpmask,v in O(2n⋅n2).

Then, let's fix the multiset of lengths a1,a2,…,ak.

I claim that the f(s) for this multiset is equal to ∑∏gai,mi over all masks m1,m2,…mk, such that the bitwise OR of m1,m2,…,mk is equal to 2n−1 (note that we don't care about the number of bits like in a usual non-intersecting subsets convolution, because if some masks are intersecting, then their OR won't be equal to 2n−1 because ∑ai=n).

You can calculate this sum by changing glen to the sum over subsets.

And then, for this partition, you can just calculate dmask=∏gai,mask in O(k⋅2n), and you can restore the real value of 2n−1 by inclusion-exclusion in O(2n).

If you will calculate this naively, you will get the O((sum of sizes of all partitions) ⋅2n) solution, which is enough to get AC.

But you can optimize this because you can maintain dmask during the brute force of all partitions. And in the tree of all partitions, there are O(P(n)) intermediate vertices, so it will work in O(P(n)⋅2n).

The total complexity is O((P(n)+n2)⋅2n)).

Jury solution: link

1326G - Spiderweb TreesLet's hang the tree on the vertex 1. After that, we will calculate the value dpi for all vertices i, which is equal to the number of good partitions of the subtree of the vertex i (subtree in the rooted tree). The answer to the problem in these definitions is dp1.

To calculate these values let's make dfs. We know in the vertex p and we want to calculate dpp. We know the values dpi for all i in the subtree of p. Let's define the set of the partition, which contains p as S.

There are some cases:

Case 1: |S|=1. In this case, the number of good partitions is dpi1dpi2…dpik, there i1,i2,…,ik are all sons of the vertex p.

Case 2: |S|=2. In this case, the number of good partitions is ∑i∈Sons(p)fi∏j∈Sons(p),j≠idpj, there fi=dpi1dpi2…dpik, there i1,i2,…,ik are all sons of the vertex i.

The values in these cases are easy to find. We have one, last case:

Case 3: |S|≥3.

In this case, the number of good partitions is ∑p∈S,Sisspiderwebfunc(S). Let's define func(S) as the product of dpi for all vertices i, which are going from S (it means, that i isn't in S, but ancestor of i is in S). Let's try to calculate this sum faster.

Let's call a pair of vertices (i,j) good if they are not connected and all vertices t on the path from i to j lies on the left side from the vector AiAj−→−−. It can be shown, that if the polygon Ai1Ai2…Aik is convex and all pairs (ij,ij+1) are good, the subtree with leafs i1,i2,…,ik is spiderweb.

So, let's fix all leaf vertices in S: i1,i2,…,ik (these are the vertices of the subtree of p, they can be equal to p). If S is the spiderweb tree, the ways (ij,ij+1) divide the plane into infinite parts (for explanation look at the picture):

The part is defined only with the way in the tree. Let's define valueij as the product of dpt for all vertices t, such that At lies in the part for the way (i,j), the vertex t doesn't lie on the way and the ancestor of t lies on the way. So, it's easy to see, that func(S)=∏i=1kvalueijij+1. We can calculate the value for each path only one time during the dfs, after the moment, when all needed values of dp will be defined.

So, let's take all pairs of vertices (i,j), such that i and j are in the subtree of vertex p, the way (i,j) is good and the point Ap lies on the left side from the vector AiAj−→−−. After that, we should calculate the sum of products of valueijij+1 for all convex polygons Ai1Ai2…Aik, which contains the vertex p on some path (ijij+1). This thing can be done by the standard dp in time O(n3) (the same dp as how we calculate the number of convex polygons). To fix the last condition we can make this dp two times: with all good pairs and with good pairs, which don't contain the vertex p. After that, the needed number is the subtraction of these two numbers.

So, we have the solution with time complexity O(n4).

Jury solution: link

Let's discuss your ideas and solutions in the comments. Thanks for your participation!

Codeforces Global Round 6 Editorial

By majk, 3 years ago, In English1266A - Competitive ProgrammerThanks to Chinese remainder theorem, a number is divisible by 60 if and only if it is divisible by 3 and 20.

A number is divisible by 3 if and only if the sum of its digits is divisible by 3. Note that as the sum doesn't change if we reorder digits, it applies also to the sum of digits of s.

A number is divisible by 20 if it ends in 20, 40, 60, 80 or 00. Hence, it is necessary and sufficient if s contains a 0 and then at least one additional even digit.

Overall, there are three conditions to check:

The digit sum is divisible by 3.There is at least a single 0.There are at least two even digits (including 0s).1266B - Dice TowerConsider a die other than the top-most one. As the sum of numbers on the opposite faces of a die is always 7, the sum of numbers on the visible faces is always 14, regardless of its orientation.

For the top-most die, the numbers on the sides also add up to 14, and there is an additional number on top of the die. The total number of visible pips is thus 14d+t, where d is the number of dice and t is the number on top.

For a given x, compute t=xmod14 and d=⌊x14⌋. The answer is positive if and only if d≥1 and 1≤t≤6.

1266C - Diverse MatrixAs the example reveals, the case when r=c=1 is impossible. It turns out that this is the only impossible case. We will prove this by providing a construction that always achieves a magnitude of r+c.

If r=1, one optimal solution is A=(2,3,…,c+1). The case where c=1 is similar.

Assume r,c≥2 and assign ai,j=i∗(j+r). We can now show that the gcd of the i-th row equals to i:

bi=gcd{i∗(r+1),i∗(r+2),…i∗(r+c)}=i⋅gcd{r+1,r+2,…,r+c}As r+1 and r+2 are coprime, bi=i. Similarly, we can show that br+j = r+j.

To summarise, bk=k for all k, hence all row and column gcds are pairwise distinct, and the maximum is r+c. As the magnitude is a maximum of r+c pairwise distinct positive integers, r+c is optimal.

1266D - Decreasing DebtsConsider a solution which minimises the total debt.

Assume for contradiction that there is a triple of vertices u≠v≠w, such that d(u,v)>0 and d(v,w)>0. We can use the first rule with a=u, b=c=v, d=w and z=min(d(u,v),d(v,w)) and then the second rule with a=v and the same z. We have just reduced the total debt by z, which is a contradiction. So, there cannot be such a triple, in particular there cannot be a vertex v that has both incoming and outgoing debt. Hence, every vertex has only outgoing edges or only incoming ones.

Define bal(u)=∑vd(u,v)−∑vd(v,u) to be the balance of u. Any application of either rule preserves balance of all vertices. It follows that any solution in which every vertex has either outgoing or incoming edges is constructible using finite number of applications of rules. This means that we can just find balances, and greedily match vertices with positive balance to vertices with negative balance.

The total debt is then Σd=∑v|bal(v)|2 and it is clear that we cannot do better than that.

1266E - Spaceship SolitaireConsider a fixed game. Let mi be the total number of milestones having uj=i, that is, the maximum possible number of "free" units of resource i that can be obtained. We claim that in optimal solution, we (manually) produce this resource exactly pi=max(ai−mi,0) times.

It is obvious that we cannot do better and this number is necessary. Let's prove that it is also sufficient.

First remove arbitrary milestones such that ai≥mi for all i. This clearly cannot make the production work faster. Now, pi+mi=ai holds for each resource. Let's perform the production of pi units for all i in arbitrary order and let ci be the total amount of i-th resource after this process finishes. Clearly ci≤ai.

Assume for contradiciton that for a resource i we have ci<ai, that is, the goal has not been reached. As we performed all pi manual productions for this resource, it means that we did not reach ai−ci milestones claiming this resource. The total number of unclaimed awards is thus:∑(ai−ci)Where are the milestones corresponding to these awards? Clearly, they can only be of form (i,j,k) for j>ci, otherwise we would have claimed them. There is never an award for reaching the goal, so the total number of positions for unreached milestones is∑max(0,ai−ci−1)As there is always at most one award for reaching a milestone, the number of unclaimed awards is at most the number of milestones not reached:∑(ai−ci)≤∑max(0,ai−ci−1)As ai≥ci, this is equivalent to∑(ai−ci)≤∑ai>ci(ai−ci−1)+∑ai=ci(ai−ci)=∑(ai−ci)−|{i:ai>ci}|Subtracting ∑(ai−ci) from both sides and rearranging yields|{i:ai>ci}|≤0so the number of resources that did not reach their goal is 0, which is a contradiction.

From here the solution is simple. We need to maintain all mi and the sum of pi. Each update changes at most two mi, so the total complexity is O(n).

1266F - Almost Same DistanceThere are three cases of how an almost-k-uniform set looks like depending on the value of k.

The first case is when k=1. In this case, any maximal almost-1-uniform set is a vertex plus all of its neighbours. We can simply check each vertex and find the one with the highest degree.The second case is when k is odd and greater than one: k=2l+1 for l≥1. Then any almost-k-uniform set looks as follows. There is a middle vertex v, and every w∈W has distance of l or l+1 from v. Additionally, at most one of the vertices is in distance l, and each w is in a different subtree of w.The third case is when k is even: k=2l for l≥1. Then any almost-k-uniform set can be constructed in one of two ways. The first is similar to the previous case, except that all vertices have to be at distance of exactly l from the middle vertex. The second construction begins by selecting a middle edge {u,v}, removing it from the tree and then finding a set of vertices W such that each w∈W is in the distance of l from either u or v (depending in which subtree it is) and each w is in a different subtree of u or v.Now we need to figure out how to make these constructions efficiently. We begin by calculating dv(u) – the depth of a subtree u when the tree is rooted at v. We compute this for each edge {u,v} by using the standard technique of two DFS traversals. Furthermore we use the fact that the answer is monotone with respect to parity: Ans[i+2]≤Ans[i] for all i – we only calculate the answer in some "interesting" points and then preserve this inequality in the end by taking suffix maximums.

For the odd case, consider a middle vertex v. Sort the depths of subtrees of neighbours of v. Then, Ans[2∗l+1]≥x if there are at x−1 subtrees of depth at least l+1 and one additional subtree of depth l or more. By sorting the depths, we can process each middle vertex in O(degvlogdeg(v)). In total, we have O(nlogn) for this step.

For the even case there are two options. The first of these is very similar to the above construction, we just look for x subtrees of depth at least l. The second option is more involved. Consider a middle edge {u,v}. Let x be the number of du(w)≥l for w≠v and y be the number of dv(w)≥l for w≠u. Then we can conclude that Ans[2∗l]≥x+y.

However, we cannot directly calculate the above quantity for each edge, as the processing of each vertex would take time quadratic in its degree. We will do a series of steps to improve upon this.

The first optimization is that in the process of finding x and y above, we also consider dv(u) and du(v), but then subtract 2 from the answer. Why can we do that? First see that this case is only important if both x≥1 and y≥1 – otherwise this is the middle vertex case that is already processed. This means that maxdv(w)≥l and hence du(v)≥l+1≥l. This means that adding du(v) to the set increases x by one. The same argument shows that y increases by 1.

How does this modification help us? There are two ways of proceeding now.

We can fix v as one of the endpoints of the middle edge and merge the subtree depths from individual subtrees by taking the maximum and process all neighbours of u at the same time. This alone still does not change the complexity, because we still process each vertex once for each of its neighbours, and this processing takes time at least linear in the degree. Now comes the final step.Perform a centroid decomposition of the tree. When processing v as the fixed end of the middle vertex, consider all dv(w) for the almost-k-universal set, but as the other endpoint of the middle edge we consider only the vertices in the tree where v is the centroid.

This way, each middle edge is processed exactly once. Each individual vertex is processed once when it is centroid and then once within each centroid tree it belongs to. Since the depth of centroid decomposition is O(logn), we only process each vertex O(logn) times. A single processing every vertex costs O(degvlogdegv) time (because of sorting the degrees). Thus the total running time is O(nlog2n), which is the most expensive part of the algorithm. We can also replace the sort with parallel counting sort, and this makes the time O(nlogn), but that doesn't run faster in practice.

For each vertex u, store the histogram of du(v) in a map. Now, consider each edge separately, and merge calculate the answer naively, using a linear pass through dv(u) and du(v). Why does it work fast? The sum of all du(v) for a fixed u equals to n−1, so there are at most O(n−−√) different values in the histogram, which makes the solution O(nn−−√) in total, and quite fast in practice.1266G - Permutation ConcatenationLet LCP be the longest-common-prefix array associated with a suffix tree of the sequence p. The answer is |p|⋅(|p|+1)−∑pi=1LCP[i].

Let's calculate ci – the number of positions for which LCP[j]=i.

The following holds:

c0=nci=n!(n−i+1)!∗((n−i)∗(n−i)+1) for all i between 1 and n−1ci=n!−ci−n for all i between n and 2n−1ci=0 for all i≥2nUsing the above formulas, we can calculate the answer in O(n).

Below follows a proof of the above statement. Beware that it is neither

complete,polished, norinterestingIt is just case bashing that I used to convince myself that the pattern I observed during problem preparation is correct, an incomplete transript of my scribbles. Apologies to everybody who expected something nice here.

Proof

Construct the suffix array such that the terminator is strictly larger than n. This doesn't change the answer nor the LCP histogram, and it's easier to reason about.

Here LCPn[i] denotes the longest-common-prefix of the suffix starting at position i with the next suffix in lexicographic order. We will build the knowledge about the LCP values guided by induction over n.

Lemma 1: For every i between 1 and n−1, and for every k between 1 and n!, it holds

LCPn[k⋅n+i]=LCPn[k⋅n+i−1]−1In other words, the LCP value is largest for the suffix aligned on permutation boundary, and shortening the suffix by one decreases the LCP by one. It is obvious that it can't decrease it more. Why does it always decrease by one? TODO

For the above reason, we only need to consider positions divisible by n (if we number from 0), which we will do in the rest of the text.

Lemma 2: Let i be between 1 and n and p=[n,n−1,…,i+1,i−1,…,2,1,i]. Then LCPn[indexof(p)]=n−1. We call such permutation semidecreasing.

Proof: First, let's see that there is no position which has LCP of n or more (even one that would be lexicographically smaller. Such position needs to have a permutation boundary somewhere, let it be after the number j: [n,n−1,…,j]+[j−1,j−2,…,2,1,i]. Note that the suffix of the left permutation is in decreasing order and it's first element is n. When this happens, the next permutation in must swap n with the preceding element, and hence the prefix of the right permutation cannot be complemetary to the suffix of the left permutation.

Next, see that there is a subarray of P that has common prefix of exactly n−1 with this permutation, and the next element is larger. There are two cases:

i=n, that is, the permutation is [n−1,n−2,…,2,1,n]. Then there is a suffix [n−1,n−2,…,2,1,$] at the end of P.i≠n, a permutation of form [n,n−1,…,i+1,i−1,…,2,1,i]. Then there is lexicographically larger string with common prefix of length n−1 on the boundary of permutations [i,n,n−1,…,i+1,i−1,…,2,1] and [i+1,1,2,…,i−1,i+1,…,n−1,n]Definition (enlarged permutations)

Consider a permutation on n elements. There are n+1 permutation on n+1 elements that can be obtained from it by prefixing it with a number from set {0.5,1.5,…,n+0.5} and renumbering.

For example, from p=[3,1,2,4] we obtain q={[1,4,2,3,5],[2,4,1,3,5],[3,4,1,2,5],[4,3,1,2,5],[5,3,1,2,4]}. These enlarged permutations will be of great use within the proofs, as we will see soon. Their LCP values will be closely related.

Lemma 3 (enlarging non-semidecreasing permutations): Let LCPn[k⋅n]≥n. Then LCPn+1[(k+m⋅n!)⋅(n+1)]+2.

In other words, the LCP of enlarged permutations is two more than that of the original permutation, provided the original permutation was having LCP large enough.

Proof: The permutation with corresponding LCP n and the following one are enlarged with the same number e (because the last permutation of Pn−1 has LCP=n−2 as shown by Lemma 2). The lexicographically following permutation in Pn−1 can also be found in Pn, subject to insertion of element e and renumbering. We will just demonstrate this fact informally.

For example, consider permutation p=[1,2,4,3]. The lexicographically following suffix is on the boundary of permutations q1=[3,1,2,4] and q2=[3,1,4,2]. Say we enlarge p to p′=[3,1,2,5,4]. Then the boundary of permutations q′1=[4,3,1,2,5] and q′2=[4,3,1,5,2] contains the subarray [3,1,2,5,4,3,1], which is longer than the original LCP by two. Here, we inserted [3] after the first element and renumbered the old 3 to 4 and 4 to 5.

Let's characterize the indices where LCPn[k⋅n]<n.

Lemma 4 (enlarging semidecreasing permutations): Let p be a semidecreasing permutation on n elements. Consider its enlargement p+ – a permutation on n+1 elements. There are three cases:

p+ is also semidecreasing. Then LCPn+1[indexof(p+)]=n.p is the last permutation and the enlargement element is neither 0.5 nor n+0.5. Then LCPn+1[indexof(p+)]=n+2.Otherwise, LCPn+1[indexof(p+)]=n+1.Proof: The first case is obvious.

In the third case, the enlarged permutation is p+=[i,n+1,n,…,i+1,i−1,…,2,1]. The lexicographically next permutation is on the boundary of [1,i,n+1,n,…,i+1,i−1,…,2] and [1,i+1,2,3,…,i,i+2,…,n,n+1] and the LCP has length n+2. This is because there is an extra match of i at the beginning, and 1 and i+1 at the end.

The second case is similar to the Lemma 3.

Combined the above and induction on n yields:

Lemma 5: For all k it holds LCPn[k⋅n]<2n.

Using induction, we can also count the number of permutations pn for which LCPn[indexof(pn)]=k. Thanks to Lemma 1 this is extendable to suffices not aligned with a permutation, yielding the ci values in the statement.

1266H - Red-Blue GraphConsider a fixed query {si}n−1i=1 and v.

Let xi be the number of times the red arc from i was traversed, and yi the number of times the blue arc was traversed. The answer for a given query, should the xi and yi exist, is the sum of all of them. Let's try to find these values.

When the blue arc going from i is active, we have xi=yi. Otherwise, xi=yi+1. In both cases

xi=yi+[si='R'].Let's denote Bi the set of blue arcs going to i, and Ri the set of red arcs going to i. For every vertex other than 1 and the current vertex v, the sum of traversals of incoming edges must equal the sum of traversals of outgoing edges. For the current vertex, the sum of incoming traversals is one more than the outgoing, and for vertex 1 it is the opposite. This gives us

∑r∈Rixr+∑b∈Biyb+[i=1]=xi+yi+[i=v].Substituting the ys and rearranging yields:

2xi−∑r∈Rixr−∑b∈Bixb=[si='R']−∑b∈Bi[sb='R']+[i=1]−[i=v].Consider this equality for each i from 1 to n−1. We have n−1 equalities for n−1 unknowns, written in matrix form Ax=z. The value of A does not depend on the actual query – it is determined by the structure of the graph. Let's look at the matrix in more detail.

On the main diagonal, each value is 2 – because each vertex has outdegree 2. Then there are some negative values for incoming edges. Those values are either −1, or −2 when both the red and blue edge have the same endpoint. In each column, the sum of negative entries is between 0 and −2, because each −1 corresponds to and outgoing edge, and because some of the edges may end in n, for which we don't have equation.

This combined yields an important observation: the matrix A is irreducibly diagonally dominant. That is, in each column it holds |aii|≥∑i≠j|aij|, and there is at least one column for which there is strict inequality (because vertex n is reachable). An interesting property of such matrix is that it is non-singular. For every right side z there is thus exactly one solution for x.

There are 2n−1⋅(n−1) possible queries, and each of them corresponds to some pair of vectors (x,y). Clearly, every reachable state corresponds to exactly one pair that describes the process that led to this state. However, it is evident that there are input graphs in which the target vertex is reached in fewer moves, hence some (x,y) pairs must correspond to invalid states. Let's look at which states are invalid.

First, every element of x must be non-negative and integer. Consider a graph on three vertices, where each arc, red or blue, goes to the vertex with higher ID (1→2 and 2→3), v=2 and s="BB". The solution of this linear system is x=(12,0). This is clearly not a valid state.

There is one more situation that is invalid. Consider again a graph on three vertices where each red arc goes to the vertex with higher ID as before, but each blue arc is a loop. In this graph, the token moves to the last vertex in two moves, making both red edges active in the process. For query v=2 and s="RR", we get a solution x=(1,0) and y=(1,0). This is not a valid state. The reason for this is the fact that the active arc from i speaks truth about a simple fact – where did the token go the last time it left vertex i. The active edge in vertex 1 is blue, which leads to itself, meaning that the token never left the vertex. But this is a contradiction, because we know it is in vertex 2. This condition can be phrased as follows:

For every vertex that had the token at least once, the vertex containing the token must be reachable via the active arcs.

These two conditions are in fact necessary and sufficient.

Let's summarise what we have so far:

Build a system of linear equations and solve for x.Check whether all x are non-negative and integer.Verify that the current vertex is reachable from all visited vertices using active edges.If both conditions are true, calculate y and sum all x and y to get the answer. Otherwise, the answer is negative.There are some technical details left to be solved.

Firstly, as we already noticed, the matrix A doesn't depend on the actual query, only on the graph structure. We can thus precompute its inverse and solve each query as a matrix vector implementation, reducing time per query from O(n3) to O(n2).

Secondly, how do we compute x precisely to check whether they are integers? There are two ways – either we use exact fractions with big integers, or compute everything in modular arithmetic and verify the solution on integers. Since 128-bit integers are not a thing on codeforces, we either use Schrage's method for the modular multiplication, or use two moduli and Chinese remainder theorem.

The total complexity is O(n3+q⋅n2).

Codeforces Global Round 5 Editorial

By tourist, history, 3 years ago, In EnglishEnjoy!

A. Balanced Rating Changes1237A - Balanced Rating ChangesLet bi=ai2+δi. It follows that if ai is even, then δi=0, and if ai is odd, then either δi=12 or δi=−12.

At the same time, the sum of bi is equal to the sum of δi, as the sum of ai is 0. Thus, as the sum of bi must be equal to 0, we need to have an equal number of δi equal to 12 and −12.

In simple words, we have to divide all numbers by 2, and out of all non-integers, exactly half of them must be rounded up and the other half must be rounded down.

Solution by touristB. Balanced Tunnel1237B - Balanced TunnelThis problem can be approached in several ways, here is one of them.

Let's say that cars exit the tunnel at time moments 1,2,…,n, and let ci be time when car ai exited the tunnel.

For instance, in the first example we had a=⟨3,5,2,1,4⟩ and b=⟨4,3,2,5,1⟩. Then, c=⟨2,4,3,5,1⟩: car 3 entered first and exited at time 2, so c1=2; car 5 entered second and exited and time 4, so c2=4; and so on.

Note that c is a permutation, and not only it can be found in O(n), but also it can be very useful for us. It turns out that we can use c to easily determine if car ai must be fined.

Specifically, car ai must be fined if ci is smaller than max(c1,c2,…,ci−1).

Why is that? Recall that car ai must be fined if there exists a car that entered the tunnel earlier and exited the tunnel later. If a car entered the tunnel earlier, it must be aj such that j<i. If a car exited the tunnel later, it must be that cj>ci.

Therefore, now we can just go from left to right, keeping the maximum of c1,c2,…,ci−1 to compare it to ci. The overall complexity is O(n).

Solution by touristC1. Balanced Removals (Easier)1237C1 - Balanced Removals (Easier)Pick any two points i and j, let's say that this is our candidate pair (i,j) for removal. Loop over all other points. If some point k lies inside the bounding box of i and j, change our candidate pair to (i,k). Note that the bounding box of i and k lies inside the bounding box of i and j, so we don't need to recheck points that we have already checked. The candidate pair we get at the end of the loop can surely be removed.

Another look at the situation is that we can pick any point i, and then pick point j that is the closest to point i, either by Euclidean or Manhattan metric. Pair (i,j) can be removed then, as if any point k lies inside the bounding box of i and j, it's strictly closer to i than j.

Both of these solutions work in O(n2).

Solution by arsijoC2. Balanced Removals (Harder)1237C2 - Balanced Removals (Harder)Consider a one-dimensional version of the problem where n is not necessarily even. We can sort all points by their x-coordinate and remove them in pairs. This way, we'll leave at most one point unremoved.

Now, consider a two-dimensional version of the problem where n is not necessarily even. For each y, consider all points that have this y-coordinate and solve the one-dimensional version on them. After we do this, we'll have at most one point on each y left. Now we can sort the points by y and remove them in pairs in this order. Again, we'll leave at most one point unremoved.

Finally, consider a three-dimensional version of the problem. Again, for each z, consider all points that have this z-coordinate and solve the two-dimensional version on them. After we do this, we'll have at most one point on each z left. Now we can sort the points by z and remove them in pairs in this order.

We can even generalize this solution to any number of dimensions and solve the problem in O(dnlogn).

Solution by touristD. Balanced Playlist1237D - Balanced PlaylistThis problem allowed a lot of approaches.

First, to determine if the answer is all −1, compare half of maximum xi and minimum xi.

Second, note that during the first n tracks, we'll listen to the track with maximum xi, and during the next n tracks, we'll stop at the track with minimum xi. Thus, to pretend that the cyclic playlist is linear, it's enough to repeat it three times.

For each track i, let's find the next track j with coolness more than xi, and the next track k with coolness less than xi2. Then it's easy to see that if j<k, we have ci=cj+j−i, and if j>k, we have ci=k−i.

Thus, all that remains is to find the next track after every track i whose coolness lies in some segment of values. This can be done with binary search over segment tree in O(nlog2n), binary search over sparse table in O(nlogn), binary search over stack in O(nlogn) as well... Alternatively, if we go through tracks in increasing/decreasing order of coolness, we can also answer these queries with two pointers and a structure like C++ set or Java TreeSet.

Bonus: solve the problem in O(n).

Solution by touristE. Balanced Binary Search Trees1237E - Balanced Binary Search TreesConsider perfectly balanced striped BSTs of some maximum depth d. Note that both the left and the right subtree of the root must be perfectly balanced striped BSTs of maximum depth d−1. Also note that the parity of the root must be equal to the parity of n, as n lies on the rightmost branch of the tree; thus, the size of the right subtree must be even.

Consider trees of maximum depth 2: there is one with n=4 and one with n=5. A tree of maximum depth 3 can have its right subtree of size 4 only, and its left subtree can have size 4 or 5; thus, we have one tree with n=9 and one with n=10.

Using induction, we can prove that for any maximum depth d, we have exactly two possible trees, of sizes x and x+1 for some x. We can enumerate these trees and check if n belongs to the set of possible sizes in O(logn).

Solution by touristF. Balanced Domino Placements1237F - Balanced Domino PlacementsSuppose we're going to place dh extra horizontal dominoes and dv extra vertical ones. Consider all rows of the grid, and mark them with 0 if it's empty and with 1 if it already has a covered cell. Do the same for columns.

Now, let's find the number of ways R to pick dh rows marked with 0, and also dv pairs of neighboring rows marked with 0, so that these sets of rows don't intersect. Similarly, let's find the number of ways C to pick dh pairs of columns marked with 0, and also dv columns marked with 0. Then, the number of ways to place exactly dh horizontal dominoes and dv vertical ones is R⋅C⋅dh!⋅dv!.

To find R, let's use DP: let f(i,j) be the number of ways to pick j pairs of neighboring rows out of the first i rows. Then, f(i,j)=f(i−1,j) if any of rows i or i−1 is marked with 1, and f(i,j)=f(i−1,j)+f(i−2,j−1) if both are marked with 0. It follows that R=f(h,dv)∗(h−2dvdh). C can be found similarly.

The complexity of this solution is O((R+C)2).

Solution by arsijoG. Balanced Distribution1237G - Balanced DistributionLet A be the average of ai, and let pi be the sum of a0,a1,…,ai minus A times i+1.

Consider a pair of friends i and (i+1)modn that never attend the same meeting. Then we can make a "cut" between them to transform the circle into a line. Consider some other pair of friends j and (j+1)modn with the same property. Now we can cut our line into two segments. As these segments never interact with each other, we must have pi=pj if we want the problem to be solvable. Similarly, for all "cuts" we do, between some pairs k and (k+1)modn, the value of pk must be the same.

Now, considering some value x, let's make cuts at all positions i with pi=x. The circle is cut into several segments. For a segment of length l, I claim that it can always be balanced in ⌈l−1k−1⌉ meetings. Let's trust this for a while.

If we carefully look at the formulas, we may note that if a segment has length l such that l≠1(mod(k−1)), it can be merged to any neighboring segment without increasing the number of meetings.

It follows that we either make just one cut anywhere, or in the sequence of imod(k−1) for i with pi=x, we need to find the longest subsequence of (0,1,…,k−2)∗ in cyclic sense. This can be done, for example, with binary lifting. The complexity of this step will be proportional to O(clogc), where c is the number of positions with pi=x.

Thus, for any value of x, we can find the smallest number of meetings we need if we only make cuts at positions with pi=x in O(nlogn) overall, and we can pick the minimum over these.

It remains to show that we can balance any segment of length l in ⌈l−1k−1⌉ meetings. Consider the k leftmost positions. If we have at least (k−1)⋅A stones there, then we can make a meeting on these positions, send whatever remains to the k-th leftmost position, and proceed inductively. If we have less than (k−1)⋅A stones there, let's solve the problem for the rightmost l−k+1 positions first, with the goal of sending all the extra stones to the k-th leftmost position. This is similar to what we usually want to do, so again we can proceed inductively to reach the goal on the right first, and then conduct a meeting on the k leftmost positions, this time having enough stones to satisfy the demand.

Solution by KANH. Balanced Reversals1237H - Balanced ReversalsUnfortunately, solutions used by most participant are different from what I expected. Here is the intended solution that works in exactly n+1 reversals.

Let's form string b from right to left at the front of string a. For each i=2,4,6,…,n, we'll make some reversals so that a[1..i]=b[n−i+1..n]. For each i, we need to move the first i−2 characters by two characters to the right, and place some correct pair of characters at the front.

Consider some pair of characters at positions x and x+1, where xmod2=1 and x>i. What if we perform two reversals: first, reverse prefix of length x−1, then, reverse prefix of length x+1? The answer is: characters x and x+1 will move to the beginning of a in reverse order, while all the other characters will not change their relative positions.

OK, what if we need to put some pair 00 or 11 to the front? Then we can just pick any 00 or 11 pair to the right of position i and move it to the front in two steps, that's easy enough.

It becomes harder when we need some pair 01 or 10 to get to the front. We might not have a suitable corresponding 10 or 01 pair in store, so we might need to use three steps here. Let's call this situation undesirable.

Let's get back to the initial situation. Suppose that the number of 01 pairs in a matches the number of 10 pairs in b. Then we'll never get into an undesirable situation. Let's call this initial situation handy.

What if these counts don't match? Then we can actually make them match using just one reversal. Specifically, pick a string out of a and b that has higher absolute difference of counts of 01 and 10, and it turns out, due to some monotonicity, that we can always find a prefix to reverse to make our initial situation handy. (Note that when I say that we can reverse a prefix in b, that's equivalent to reversing the same prefix in a as the last reversal.)

Thus, we can solve the problem in n+1 reversals: one reversal to make the initial situation handy, and then n/2 times we make at most two reversals each step without ever getting into an undesirable situation.

Solution by KAN

Codeforces Global Round 4 Editorial

By majk, history, 4 years ago, In English1178A - Prime MinisterIgnore the parties that have more than half of Alice's party seats. For all other parties it is never disadvantageous to include them in the coalition, so we might as well take all of them. If the resulting number of seats is a majority, we output all involved parties, otherwise the answer is 0.

The complexity is O(n).

Code1178B - WOW FactorWe find all maximal blocks of vs. If there are k of them, we replace the block with k−1 copies of w. After that, we can use a simple DP for finding the number of subsequences equal to wow.

Complexity O(n).

Code1178C - TilesObserve that for a fixed pair of tiles (i−1,j) and (i,j−1) there is exactly one way of placing a tile at (i,j) that satisfies the conditions. As a result, when all tiles (1,i) and (j,1) are placed, the rest is determined uniquely. We only need to count the number of ways to tile the first row and first column.

There are four ways of placing the tile on (1,1). After that, each tile in the first row or first column has exactly two ways of being placed.

The answer is 2w+h. The complexity is O(w+h) or O(logw+logh) if we use binary exponentiation.

Bonus: Hexagonal tiles and hexagonal kitchen.

Code1178D - Prime GraphA solution always exists. We show a simple construction.

For n=3, a triangle is (the only) solution.

For n≥4 we make a cycle on n vertices: 1↔2↔3…n↔1. The degree of each vertex is 2 (a prime number), but the total number of edges – n – might not be. For some k, we add edges of form i↔i+n2 for all i from 1 to k. If k≤n2, each vertex gets at most one more neighbor, having degree 3.

Fortunately for us, for each n≥3 there is a prime number in interval [n,3n2], simply the smallest of them will do.

The time complexity is O(n).

Code1178E - ArchaeologyThe answer always exists. Let's prove by induction on |s|, giving a construction in the process.

|s|=0⇒t= empty string,|s|≤3⇒t=s[0],|s|≥4⇒. Let t′ be solution for s[2:−2], which exists due to induction. As s[0]≠s[1] and s[−1]≠s[−2], there is at least one character 'x' that occurs in one of s[0],s[1] and s[−1],s[−2]. Then t=xt′x is a palindrome and its length is|t|=2+|t′|≥2+⌊|s[2:−2]|2⌋=2+⌊|s|−42⌋=⌊|s|2⌋.The time complexity is O(|s|).

Bonus: Find a subpalindrome of length at least ⌈|s|2⌉.

Code1178F1 - Short Colorful StripLet LO[l][r] be the lowest ID of a colour used in the final strip on interval [l,r]. Let I[c] be the position on which the colour c occurs on the target strip.

We solve this problem by computing DP[l][r] – the number of ways of painting the interval [l,r], given that it is painted with a single colour and all subsequent colouring intervals must be either completely inside or completely outside of this interval.



The first colour used on this interval will be c=LO[l][r]. How can we choose to paint it? Clearly, we can choose any interval [a,b] such that l≤a≤I[c]≤b≤r. Once we perform this operation, then I[c] can never be recoloured, and the interval [l,r] is split into four single coloured intervals (possibly empty) that can be solved independently.



This gives us DP[l][r]=∑a∑bDP[l][a−1]∗DP[a][I[c]−1]∗DP[I[c]+1][b]∗DP[b+1][r] which can be computed naively in O(n4). To optimise it to O(n3) just note that the selection of a and b is independent.

Code1178F2 - Long Colorful StripThere are several additional observations we need compared to previous subtask.

First, note that if we ever colour a pair of positions with different colours, they will forever stay coloured with different colours. In other words, if two positions have the same colour in the final strip, the set of colours they were coloured with is the same. As a result, we can compress the input by removing consecutive equal values.

Next, we look at the number of changes in the strip. A change is a position i such that ci≠ci+1. Initially, there are 0 changes, and each operation adds at most 2 changes. As a result, if the length of the input after the compression is more than 2n, we can immediately print 0.

Now we can use the DP as in previous tasks, but there is one more complication to resolve. Consider the third sample:

2 32 1 2The DP suggests that DP[0][2]=DP[0][0]∗DP[2][2]=1. The reason why we get a wrong answer is that we treat the intervals [0,0] and [2,2] as independent, but in reality they are not.

To fix this, instead of finding a single value of I[c], we set I′[c] to be all positions (in the whole array) containing colour c. We can then pick l≤a≤min(I′[c]) and max(I′[c])≤b≤r. For this to be possible, all occurrences of the colour c must be within interval [l,r], otherwise D[l][r]=0. The occurrences of colour c and the indices a and b now can split the interval [l,r] into more than 4 segments, but this does not affect the complexity.

Final complexity is O(n3+m).

Bonus (courtesy of [user:Um_nik]): Can you solve it faster?

Code1178G - The Awesomest VertexDenote cv=∑w∈R(v)aw and dv=∑w∈R(v)bw.

Let's solve a simpler task first, where we assume that all ai and bi are positive, and all updates and queries are on the root vertex. We can see that we are looking into maximum (x+cv)⋅dv = cvdv+xdv, where x is the cumulative sum of updates until this point. For a given x, this can be solved in O(logn) using convex hull trick.

How do we handle negative values of ai and bi? We simply try all the lines −cvdv−xdv as well.

The second issue is that our updates and queries can occur on arbitrary vertices. We can linearise the tree using DFS – then subtree of a vertex corresponds to an interval in the array. Afterwards, we use sqrt-decomposition in a fairly standard way:

We partition the array into blocks of size roughly n−−√, build a convex hull trick structure on each of them, and remember the value of x for each of them separately.Given an update, some blocks are untouched, in some we just need to update x in constant time, and there are at most two blocks which are updated partially, which we rebuild from scratch.Given a query, we can use the convex hull trick structure to get the maximum in a block that is fully covered by the query. Again, we have at most two blocks that are partially intersected – there we can brute force the maximum.This yields a O(n+qn−−√logn) algorithm.

You just want contribution, go away!Oh wait, you're right. This solution has a rather large constant factor, so let's not stop there. What do we need the logn factor for? Two things: sorting all the lines by slope and determining the best line in a convex hull trick structure. Let's get rid of both – firstly, as bi doesn't change, we can sort once before processing any queries. Secondly, notice that the updates only add positive values, thus we only ever query lines with increasing x. Hence, no binary search is needed – we can simply advance a pointer over the structure in O(1) amortised. Overall complexity becomes O(nlogn+qn−−√). There, no marmots harmed.

One final remark – the cost of building a convex hull structure in a block is slightly higher than that of iterating over the blocks. It seems that the most efficient size of the block is n/6−−−√. This final observation was not needed to get AC.

Code1178H - Stock ExchangeLemma: If there is a solution S for time T, there is also a solution S′ for time T using not more exchanges than S, in which all exchanges occur either in time 0 or in time T.

Proof: Induction on n - the number of exchanges not happening in time 0 or T. If n=0, we are done.

Otherwise, pick an arbitrary exchange i→j at time t. There are a few cases:

There is an exchange j→k at time t. We can substitute both by exchange i→k.There is an exchange k→i at time t. We can substitute both by exchange k→j.If a[i]≥a[j] andthere is an exchange j→k in time t<t1<T. We substitute both with exchange i→k in time t1.otherwise, postpone the exchange to time TIf a[i]<a[j] andthere is an exchange k→i in time 0<t1<t. We substitute both with exchange k→j in time t1.otherwise, prepone the exchange to time 0Thanks to this lemma, and the fact that we can get rid of transitive exchanges happening at the same time, we can model this problem as min-cost max-flow on 4N+2 vertices. Let there be vertices ui and vi for each stock, and s and t are source and sink, respectively. There are edges of six types:

Edge s→ui for all 0≤i<N with capacity 1 and cost 0 (representing the starting stock).Edge ui→vi for all 0≤i<N with capacity 1 and cost 0 (representing stock not exchanged at t=0).Edge ui→vj for all 0≤i<N and j such that B[i]≥B[j], with capacity 1 and cost 1 (representing an exchange at t=0).Edge vi→ui for all N≤i<2N with capacity 1 and cost 0 (representing stock not exchanged at t=T).Edge vi→uj for all 0≤i<2N and N≤j<N sucht that A[i]∗T+B[i]≥A[j]∗T+B[j], with capacity 1 and cost 1 (representing an exchange at t=T).Edge ui→t for all N≤i<2N with capacity 1 and cost 0 (representing desired stock).If the flow size equals N, then there exists a strategy. The number of exchanges equals to the cost of the flow.

This combined runs in O(N3logNlogMAX) using e.g. preflow-push. Even when considering the fact that the bounds on flow algorithms are often not tight, this is not very promising. Furthermore, it uses O(N2) memory, which is clearly too much. Let's improve it.

Removing logMAX factor: The first observation is that we don't need to run the MCMF for every iteration of the binary search – we don't need the cost, all that is required is deciding whether max-flow size is N. There are many approaches to this, perhaps the simplest one is to solve it in O(NlogN):

At time T, exchange each stock to the most expensive stock at t=T that we can afford to exchange at t=0.Check whether at time t=T the prices of stocks obtained this way dominate the prices of the desired stocks.Reducing the space complexity: Note that the edges of type 3 and 5 connect a stock i to some subset of stocks j. This subset of stocks is a prefix of the array of stocks sorted by their price. We can thus connect each stock only to the most expensive stock to which it can be exchanged, and connect these in order of decreasing price with edges of capacity N and cost 0 (make sure the ties are broken correctly).

This way, we reduce the number of edges from quadratic to 12N, improving the space complexity.

Reducing to O(N2logN) time: The maximum flow is capped by N. In such a setting primal methods such as Ford-Fulkerson, respectively it's MCMF version called Successive Shortest Paths Algorithm, behave quite well, needing only O(f⋅|E|log|E|)=O(N2logN) time.

Reducing to O(N2) time: However, in our problem, the costs are also bounded by a small constant, namely 0 or 1. In Dijsktra's algorithm, the subroutine of SSPA, one can use a fixed size array instead of a priority queue, reducing the complexity even further. This last optimisation is difficult to separate, so with a reasonable implementation it is not necessary to get AC.

The total complexity is thus O(NlogNlogMAX+N2).

Code

Codeforces Global Round 3 Editorial

By Egor.Lifar, history, 4 years ago, translation, In English1148A - Another One Bites The DustThe answer is 2∗c+min(a,b)+min(max(a,b),min(a,b)+1).

First, you can place all "ab" strings together.

Then if there are more "a" strings than "b" strings, you can start adding in the end "a" and "b" strings one by one in an alternating order.

If there are more "b" strings than "a" strings, you can do the same thing but add to the begin of the string.

Author: Egor.Lifar

1148B - Born This WayIf k≥n, we can cancel all flights between A and B, and Arkady won't be able to get to C, so answer will be equal to −1. Otherwise, k<n.

If the subset of canceled flights is chosen, the Arkady's strategy is clear: use the earliest available flight from A to B, arrive to B at some time moment t and choose the earliest not canceled flight from B to C with a departure time moment greater or equal than t.

Suppose we have chosen x — a number of canceled flights between A and B. No matter what subset of flights will be cancelled between B and C, we should cancel the first x flights from A to B. Now we know the exact moment of the Arkady's arrival to B — it is equal to ax+1+ta. Now our optimal strategy is to cancel the first k−x flights between B and C, which Arkady can use. If there is no flights remaining, the answer is −1. Otherwise, Arkady will be in C at the bj+tb-th time moment, where j is the index of the earliest flight, which Arkady can use. j is equal to pos+(k−x), where pos is index of the first flight from B to C, which departure time moment is greater or equal than ax+1+ta.

Now we can just iterate through all possible x and calculate the biggest time moment. Since array b is sorted, you can find pos using binary search. The complexity of this solution is O(nlogn). Also the array of ax+1+ta values is sorted too, so you can use two-pointers method. This solution will work with O(n) complexity.

Author: KAN1148C - Crazy DiamondThe problem can be solved in 4n swaps in total in the worst case (might be there is a more optimal solution, but it wasn't required). Let's go from left to right through the array. Suppose our current position is i and position of the number i is j. If i≠j, we want to swap them.

If |i−j|⋅2≥n, you can just swap(i, j).

If n2≤i−1, than you can do swap(i, 1), swap(1, j), swap(i, 1).

If n2≤n−j, than you can do swap(i, n), swap(j, n), swap(i, n).

In the last case n2≤j−1 and n2≤n−i and so you do 5 swaps: swap(i, n), swap(n, 1), swap(1, j), swap(1, n), swap(i, n).

One can be see, that the last case happens at most n2 times, since when i≥n2+1 you only need 3 swaps or less. And so in total it's no more than 5⋅n2+3⋅n2=4n swaps.

Author: Jatana1148D - Dirty Deeds Done Dirt CheapFirst notice, that there are two types of pairs: one with ai<bi and another one with ai>bi.

Note, that we can't form an answer with pairs of different types. Now let's notice that we can take all pairs of fixed type. Suppose the type is ai<bi. Then sort pairs by their ai in the decreasing order and that is the answer.

For type ai>bi let's sort them by bi in increasing order.

Just select the longest of two answers.

Author: Egor.Lifar1148E - Earth Wind and FireConsider original and target position of stones in sorted order.

Note, that we can always construct an answer preserving the original stones order (suppose we have an answer which doesn't preserve the order. It will happen when there are two stones at the same spot, just move the other one).

So now we simplified our problem — we want to move stone si into ti. So we now can compute δi=ti−si — the relative movement of each stone.

To begin with, observe that if ∑δi≠0 there is no solution, since the operations we can use preserve the sum of the coordinates.

However this is not enough, for example if δ1<0 (you need to move to the left the leftmost stone), there is clearly no answer. The real condition is that elements δi should form a "balanced bracket sequence", that is, the sum of every prefix of δi must be ≥0. In this and only in this case we can match corresponding right-movements with left-movements.

In order to construct the exact answer we can go from left to right maintaining the stack of not-yet-closed "move-to-the right actions", formally we will put on stack pairs (stone_index, steps_to_move). So when we see stone with δi>0 we put it on the stack, and when we see stone with δi<0 we match it with the stones on the stack, removing the elements from the stack if they have moved to the full extent.

Author: Jatana1148F - Foo FightersLet's solve this problem using the induction method. Let's solve this problem for all objects with masks less than 2K.

Base of the induction: K=1, than we just can multiply price by −1, like adding a single bit into the answer, if the price has the same sign as the initial sum.

Move: we solved the problem for all masks less than 2K−1. Now take a look on all masks smaller than 2K and not less than 2K−1. If the sum of their prices has the same sign as the initial sum, than we add bit K−1 into the answer and multiply all prices of object with this bit in the mask by −1.

It's important to notice, that when we chose whether we need this bit we go only through numbers where this bit is the biggest one, but when we added it we need to recalculate prices for all object with this bit in the mask.

Author: Egor.Lifar1148G - Gold ExperienceFirstly, let's discuss how to find the answer in O(N2) time. Let's assume k is even. Pick any set on k vertices. If it is a clique, just print it as an answer, if it is not, there must be two vertices in this set that don't share an edge. Just remove these two vertices and replace them with 2 arbitrary ones from the rest of the vertices. We can notice that if we remove k2 such pairs, then removed vertices will form a set where all vertices are not fair.

If k is odd, then the above algorithm has a problem, because we remove two vertices in one step. To fix it, we can find a triplet of vertices a, b, c such that there is no edge between a and b, and there is no edge between b, and c. Now, with this triplet we can get the set with odd size. If there are no such triplet, then, our graph has quite simple structure which we can handle separately.

Now to the O(N⋅Log⋅28) solution.

Assume we have a set of integers a1,a2,…,an and an integer x. We want to find, for how many ai have gcd(ai,x)≠1. This can be done using inclusion-exclusion principle. Let p1,p2,…,pk be distinct prime divisors of x. At first, we want to count how many ai is divisible by p1,p2,…,pk, but than ai's divisible by both p1,p2 are counted twice, so we subtract count of ai that is divisible by p1⋅p2 and so on. We can maintain set a1,a2,…,an and answer queries dynamically in O(2NumberOfPrimeDivisors) time. This is the only place where we use the graph structure defined by the edge between two vertices i and j exists if only if gcd(ai,aj)≠1.Like in O(N2) solution, let's find a triplet of vertices a, b, c such that there is no edge between a and b, and there is no edge between b and c. Let's remove this triplet from the graph.Let b be the number of vertices that are connected to all other n−3 vertices. If b≥k we can print any k of them as a clique. Otherwise, let's remove all of these b vertices. We can notice that remaining vertices plus removed triplet form an antifair set. Let's estimate size of this set: S=(n−3)−b+3=n−b. Recall that b≤k and 2⋅k≤n, so we have S=n−b≥k. So, now we get an antifair set of size equal to k or greater than k. Let's show that we always can construct an antifair set with size strictly equal to k.In the previous paragraph we have estimated the maximum size of an antifair set on vertices 1,2,…,n−3. Let f(R) be the maximum size of an antifair set on vertices with indices: 1,2,…,R. Let's find with binary search lowest integer c such that f(c−1)+3<k and f(c)+3≥k. Let's look at the vertex c. The size of the maximal antifair set without it is f(c−1). The size of the maximal antifair set with it is f(c). So among vertices 1,2,…,c−1 there are exactly f(c)−f(c−1)−1 of them connected with all vertices from 1 to c−1 and not connected with the vertex c. It is easy to see, that we can delete any f(c)−f(c−1)−2 of them or less and the remaining set of vertices will still be antifair. With this observation we can achieve either set of size k or set of size k+1. In the first case, we just find the answer. In the second case, remember, that we have reserved triplet and can delete one of it's vertex to make the total size k.Author: Jatana1148H - Holy DiverFirst, let's try to solve it if we know the whole array initially.

Let's move from the last element to the first. When we are in the element i let's store all segments of right borders ([r′,r"]) in the set, so that segment [i,r] have the same mex value for all r′≤r≤r". You can see that mex values in those segments are increasing from left to right, so you can recalculate those segments efficiently when you add another element from the left.

How to do so? Suppose we added element k on the left. Then we must remove the segment with mex k and replace it (with possibly many) segments of greater mex, the last of those segments might get merge with the segment following the removed one. It's easy to see that we add/remove only O(n) segments in total since each time we remove exactly once segment, but add quite a lot. Informally, we simply can't add too much segments each time, since all mex's are distinct at every moment.

After that for each segment of the right borders we can compute when it was added to the set and when it was deleted. Then we can see it as a rectangle, where x coordinates correspond to the left borders and y coordinates correspond to the right borders. After that the problem is reduced to add value in the rectangle and compute the sum of values in the rectangle of a query.

So after that you need to notice, that those rectangles lay like in different stripes of surface. So they don't have points with the same x coordinates from different rectangles. That's why you can say, that to count total area laying on a query rectangle, you just can keep a segment tree with operations: add number to the segment, count the sum of number on the segment.

That's because there is only one rectangle intersecting your query, but not laying completely inside. So when you meet a rectangle during you scan line, you just add its width to the proper segment. Notice that there are actually O(n) scan lines, because you need to keep them for every mex value. And for the query you need to get the state of your structure after some prefix of rectangles proceeded. They lay completely inside your query, so you need just to take the sum on the segment in your structure. Also there is one rectangle which can intersect you query, and you need to proceed it by hands. Another case is that in your set, when you proceed queries one by one, there are some current segment of mex, who was not deleted yet, so you need to take care about it too, because it can contain one segment with proper mex value for you query.

Author: Egor.Lifar

Codeforces Global Round 2 Editorial

By KAN, 4 years ago, translation, In English1119A - Ilya and a Colorful Walk

Author, preparation: 300iq.

Editorial1119A - Ilya and a Colorful WalkIt is enough to find the last color different from the c1 and the first color different from cn and print the maximum of the two distances.

1119B - Alyona and a Narrow Fridge

Author, preparation: KAN.

Editorial with bonuses1119B - Alyona and a Narrow FridgeFor a fixed set of bottles the optimal way to put them in the fridge is to sort them in decreasing order and then put the tallest next to the second tallest, the third next to the fourth and so on. The total required height is then h1+h3+h5+…, where h is the sorted array of heights.

Now just try all possible k, sort the heights of the first k bottles, and output the last k when the bottles fit. The total complexity is O(n2logn).

Bonus 1: solve the problem in O(nlog2n).

Bonus 2: solve the problem in O(nlogn).

Aleks5d invites you to compete in the shortest solution challenge for this problem. His code (155 bytes):

CodeAuthors during the contest1119C - Ramesses and Corner Inversion

Author, preparation: 300iq.

Editorial1119C - Ramesses and Corner InversionOne can notice that the operation does not change the total parity of the matrix. So, if the total parity of A and B do not match, then the answer is No. However, this is not the only case when the answer is no.

You can also notice that the operation does not change the total parity of each row/column independently. Thus, if in at least one row or column the parity of A and B do not match, then the answer is No. It turns out that if all these parities match, then the answer is Yes.

We will prove this constructing a sequence of operations that transforms A to B whenever parities in all rows and column match. Let's perform an operation (1,1,x,y) for all such x>1 and y>1 that Axy≠Bxy. After all these operations the whole matrices except maybe the first column and the first row match. But the first column and the first row also match because of the parity! So A is now B.

1119D - Frets On Fire

Author, preparation: cyand1317.

Editorial1119D - Frets On FireLet's sort all si's in ascending order.

This does not affect the answers, but now we notice that for some i, as soon as r−l exceeds si+1−si we don't need to consider row i any more. This is because from then on, any integer that appears in row i also appears in row i+1.

Taking this observation one step further, we approach the problem considering the contribution of row i, i.e. the number of integers that appear in the queried range in row i, but not row i+1. The answer to a query is the sum of contributions of all rows.

From this definition we know that the contribution of row i is min{si+1−si,r−l+1} for 1≤i<n and r−l+1 for i=n. In other words, it is min{di,w}, where di=si+1−si, dn=+∞ and w=r−l+1.

Now come the queries. Given a fixed value of w, we need to quickly compute (∑n=1i=1min{di,w})+w. From another perspective, this equals the sum of value times the number of occurrences, namely (∑wk=0k⋅count(k))+(∑∞k=w+1w⋅count(k))+w, where count(k) denotes the number of times that integer k occurs in d1…n−1.

This problem can be solved by representing count(∗) values with an array, combined with partial sums. However, as di (and thus the size of such array) can be as large as 1018, it's required to compress the coordinates (discretize) and find desired indices with binary search. Please refer to the model solution attached below.

The overall time complexity is O((n+q)logn).

Code1119E - Pavel and Triangles

Author: gen, preparation: 300iq.

Editorial1119E - Pavel and TrianglesFirst, possible triangles have sides (2i,2j,2j) where i≤j.

There are several correct greedies to finish the solution, let's discuss one of them.

The greedy is to loop through the values of j in increasing order, then first try to match as many pairs (j,j) to some unmatched i as possible, after that create as many triples (j,j,j) as possible and continue to the next j.

To prove correctness, let's take our solution and one of the optimal solutions. Let's find the first difference in them if we consider the triples in the same order as our solutions considers them. There can be only one type of difference: we take some triple while the optimal solution skippes it. It can't be be the other way around because we always take a triple if there is one. So there are a few cases now:

the triple is (i,j,j) where i<j. Let's see where the corresponding i, j and j are used in the optimal solution:all three are used in different triples: (t1,k1,k1), (t2,k2,k2), (t3,k3,k3), {t1,t2,t3}={i,j,j}, j≤k1≤k2≤k3. Remove these triples and replace them with (i,j,j), (k1,k2,k2), (k1,k3,k3).two are used in the same triple, one in another: the only case is (i,k,k), (j,j,j), j<k. Remove these, add (i,j,j) and (j,k,k).two of them are used in different triples, one not used: (t1,k1,k1), (t2,k2,k2), {t1,t2}⊂{i,j,j}, j≤k1≤k2. Remove these triples, replace with (i,j,j) and (k1,k2,k2).two of them are used in the same triple, one not used: the only case is (j,j,j). Remove this, add (i,j,j).one of them in used in some triple, two are not used: (t,k,k), t∈{i,j,j}, j≤k. Remove this, add (i,j,j).none of them is used. This is not possible because it is the optimal solution.the triple is (j,j,j). Let's see where these js are used. They can only be used in three different triples (j,k1,k1), (j,k2,k2), (j,k3,k3), j≤k1≤k2≤k3. Remove these triples and replace them with (j,j,j), (k1,k2,k2), (k1,k3,k3).The optimal solution is still optimal, but it shares a longer prefix with our solution. We can continue this process until there are no differences, this shows that our solution is also optimal.1119F - Niyaz and Small Degrees

Author, preparation: 300iq.

Editorial1119F - Niyaz and Small DegreesFirst, let's learn how to solve for a fixed x in O(nlogn).

We can calculate the dp on subtrees, dpv,flag, denoting the minimum total weight of edges to be removed, if we consider the subtree of the vertex v, and flag is zero, if the vertex has the degree ≤x, and one, if ≤x+1.

Then to recalculate it you need to sort the children by dpto,1−dpto,0, and add to the sum dpto,0 (degv−(x+flag)) minimum values, depending on flag which we consider for the dp answer for the vertex v.

Then, it is obvious that the sum of degrees in the tree is equal to twice the number of edges, which is 2(n−1).

It follows that the sum of all x values «number of vertices, with degree ≥x», equal to the sum of degrees, is also 2(n−1).

Therefore, if for each x we will know how to answer the query, for the time of the order of the number of vertices with a sufficiently large degree, we will solve the problem.

Let's call a vertex interesting if its degree is >x.

We will support the forest only on interesting vertices, and also in some data structure (for example, two heaps perfectly fit this) for each interesting vertex of the weight of edges to the uninteresting.

Then, to calculate the same dynamics for each vertex in the forest, it is enough to iterate over how many edges from it down to interesting vertices we will take (in the forest ≤ «number of interesting vertices» −1 edges, so we can iterate over it).

And also add to the answer the sum of a sufficient number of edges in uninteresting vertices from the data structure.

This solution works for «number of interesting vertices» ⋅log, and all necessary data structures can also be maintained as x increases.

In total, we got the solution for O(nlogn).

1119G - Get Ready for the Battle

Authors: Aleks5d, KAN; preparation: Aleks5d.

Editorial1119G - Get Ready for the BattleNote that on each turn the total health of enemy groups decreases by n. When all groups are destroyed, their health does not exceed 0, and thus the answer is at least ⌈∑ni=1hpin⌉.

Now let's construct a way to win in this number of steps. Let's emulate the battle and split the soldiers in groups at the same time. Let's start with one group n, and attack the first enemy on each step. Once its health becomes less than n, say k1, let's assume that some of our groups have total size exactly k1 and they attack the first enemy on this step, while all the other groups start attacking the second enemy. After that let's attack the second enemy with all n soldiers until its health is k2<n. Let's assume that some of our groups have total size k2 and they attack the second soldier on this step, while the other groups start attacking the third.

Continue with this process until all enemies are destroyed. We won't add the constraint on kn, we will just assume that all soldiers attack the last enemy on the last step. Note that the total number of steps is exactly ⌈∑ni=1hpin⌉, because we have "extra" hits only on the very last step.

Now we have m−1 assumptions of type "some of our groups have total size ki". It's easy to satisfy them by sorting ki and stating that the i-th groups has size ki−ki−1. This way the first i groups will have size ki (after sorting). In order to reconstruct the attacks we have to simulate the process again.

1119H - Triple

Author, preparation: RDDCCD.

Editorial1119H - TripleIf we form n arrays, i-th of them is Fi, and set Fi,Ai=a, Fi,Bi=b, Fi,Ci=c and others zero. It's easy to find that the xor-convolution of all the arrays is the answer we want.

Implementation with the Fast Walsh-Hadamard Transform works in O(n×2k×k), this is too slow.

To make it easier, we set Ai=0, Bi=BixorAi, Ci=CixorAi. The answer won't change if we xor all x by the xor sum of all Ai.

That is Fi,0=a, Fi,BixorAi=b, Fi,CixorAi=c.

Note we only have 4 values in each array after FWHT of the array: a+b+c, a+b−c, a−b+c, a−b−c. Let's fix some position, let the occurrences of them in all n arrays be x,y,z,w. Obviously, x+y+z+w=n. For each position, if we can figure out the values of x,y,z,w, it's easy to count the final answer by FWHT.

If we add all arrays together and make a FWHT, we can form a new equation. (a+b+c)⋅x+(a+b−c)⋅y+(a−b+c)⋅z+(a−b−c)⋅w=p, where p is the value we get in this position.

Take two different (a,b,c) to form 2 equations. Now we have 3 equations in total, including (x+y+z+w=n) .

More equations formed by this operation (take a,b,c and compute FWHT) are useless because the equation x,y,z,w lies in the same linear span, so we already have three equations.

However, if we set up a new array, Fi,BixorCi+=1, other is zero, and do the FWHT (add them together of course). We can get a new equation x−y−z+w=p. The equation can be easily proved.

Now we can solve a system of 4 equations to calculate x,y,z,w for each position and get the final array. Then do the reverse FWHT and get the answer.

The Editorial of the First Codeforces Global Round

By cdkrot, history, 4 years ago, In EnglishThe round has finished. I hope you liked it!

Credits to the round authors and developers:

1110A - Parity. Authored by _h_ and simonlindholm.

1110B - Tape. Authored by _h_ and simonlindholm, development: cdkrot

1110C - Meaningless Operations. Authored by GreenGrape

1110D - Jongmah. Authored by _h_ and simonlindholm, development: KAN and MikeMirzayanov

1110E - Magic Stones. Authored by _h_ and simonlindholm, developed by GreenGrape

1110F - Nearest Leaf. Authored by grphil, developed by vintage_Vlad_Makeev

1110G - Tree-Tac-Toe . Authored by cdkrot and KAN

1110H - Modest Substrings. Authored by _h_ and simonlindholm, development: budalnik

And now, the editorial:

1110A - ParityIf b is even, then only the last digit matters.

Otherwise bk is odd for any k, so each digit is multiplied by odd number. A sum of several summands is even if and only if the number of odd summands is even. So we should just compute the number of even digits.

1110B - TapeLet's start with n pieces of length 1 covering only broken segments and then decrease the number of pieces used. After reducing the number of segments by x, some x of long uncovered initial segments of unbroken places will be covered. It's easy to see that you should cover the shortest x segments.

Thus, to make at most k segments, you should cover n−k shortest initial segments. You can find their total length using sort.

1110C - Meaningless OperationsDenote the highest bit of a as x (that is largest number x, such that 2x≤a) and consider b=(2x−1)⊕a. It's easy to see that if a≠2x−1 then 0<b<a holds. In this, gcd is maximum possible, because a&b=0 и gcd(2x−1,0)=2x−1.

Now consider the case when a=2x−1. This implies gcd(a⊕b,a&b)=gcd(2x−1−b,b)=gcd(2x−1,b), since gcd(x,x+y)=gcd(x,y) (for all x and y), hence it's sufficient to find the largest non trivial divisor of a — it will be the desired answer.

Finding the largest divisor can be done in sqrt time which leads to the time O(qm−−√) or it's possible to calculate answers for all a=2x−1 beforehand.

1110D - JongmahFirst thing to note is that one can try solving this problem with different greedy approaches, but authors don't know any correct greedy.

To solve this problem, note that you can always replace 3 triples of type [x,x+1,x+2] with triples [x,x,x], [x+1,x+1,x+1] and [x+2,x+2,x+2]. So we can assume that there are at most 2 triples of type [x,x+1,x+2] for each x.

Having noted this, you can write dynamic programming solution. Let ans[i][t1][t2] be the answer considering only the first i denominations, and there are t1 triples of type [i−1,i,i+1] and t2 triples of type [i,i+1,i+2]. Try all possible number t3 of triples of type [i+1,i+2,i+3], put all the remaining tiles of denomination i+1 into triples [i+1,i+1,i+1] and make a transition to ans[i + 1][t2][t3].

1110E - Magic StonesConsider the difference array d1,d2,…,dn−1, where di=ci+1−ci. Let's see what happens if we apply synchronization.

Pick an arbitrary index j and transform cj to c′j=cj+1+cj−1−cj. Then:

d′j−1=c′j−cj−1=(cj+1+cj−1−cj)−cj−1=cj+1−cj=dj;d′j=cj+1−c′j=cj+1−(cj+1+cj−1−cj)=cj−cj−1=dj−1.In other words, synchronization simply transposes two adjacent differences. That means that it's sufficient to check whether the difference arrays of two sets of stones are equal and make sure that s1=t1.

1110F - Nearest LeafLet's answer the queries offline: for each vertex we'll remember all queries for it.

Let's make vertex 1 root and find distances from it to all leaves using DFS. Now for answering queries for vertex 1 we should simply answer some range minimum queries, so we'll build a segment tree for it.

For answering queries for other vertices we will make segment trees with distances to leaves (like we did for handling queries for vertex 1) for all vertices. We will traverse vertices of a tree using DFS and maintain actual distances to leaves in segment tree. Suppose, DFS went through edge (u,v) with weight w where u is an ancestor of v. Distances to leaves in subtree of v will decrease by w and distances to other vertices will increase by w. Since set of leaves in subtree of some vertex is a subsegment of vertices written in euler traversal order, we should simply make range additions/subtractions on segment tree to maintain distances to leaves when passing through an edge.

This way we got a solution with O(nlogn+qlogn) complexity.

1110G - Tree-Tac-ToeTo start with, let's notice that the white vertices are not necessary. Actually, you can solve the problem analyzing the cases with the whites as well, but there is an easy way to get rid of them:

Examine the following construction:

That is, replace the white A with some set of four non-white vertices.

One can notice, that neither white nor black can win on these four vertices. That means that they are actually interested in getting the color of the end of this graph, connected to the remaining graph being of their color — it can help them later.

Let's start the game as white player and paint a vertex A white. If black player will not paint the vertex B black, we have a win. Otherwise, two turns have passed now and that means that the "parity" has preserved and it is our turn again. Then we can play as we would have played in the original game, except if the black player paints C or D in some point, we should color the remaining one (and the parity will preserve again).

———————

Now let's solve the problem assuming there are no white vertices.

Note, that if there is a vertex of degree 4 or more, then the white player wins, maing the first move into that vertex, and then two moves in some leaves of this vertex.

In case there is a vertex of degree 3 having at least two non-white neighbors, then it's a win as well: we can either collect a path going through this vertex or going through non-leave neighbor somewhere else.

Now, note that if there are at least 3 vertexes of degree 3, this implies the case above.

So we are left with a case when there are at most three vertices of degree 3 and all other have degree 1 or 2.

It's natural to claim (and many got wa2 for that), that all remaining cases are draws. But it's not true:

It's easy to see, that this game (picture above) is winning for white. Applying the same argument, as before, we can deduce that the game above is equivalent to the game below. Which is clearly winning for white.

Actually, any path having odd number of vertices and colored in white on both ends is winning for white (make a move into the vertex colored blue on the picture below):

This actually meains, that in our solution, in which we got rid of all white vertices, the winning cases are «bones» having odd number of vertices.

It's possible to show, that in all other cases the game will end in draw.

1110H - Modest SubstringsSet of modest numbers could be represented by set of size approximately (|l|+|r|)⋅10 of regular expressions of form d0d1d2…dk−1[0−9]{e}, where |l| and |r| are lengths of numbers l and r correspondingly, and di are digits. Set of regular expressions can be build in the following way. Consider prefix of l of length x. Then for every q>lx let's make the following expression: l0l1l2…lx−1q[0−9]{|l|−x−1}. Similarly for r, but here q<rx. Also for all |l|<x<|r| we should make regular expressions [1−9][0−9]{x−1}, this is equal to nine expressions of our form. Notice that every modest number would satisfy exactly one regular expression and no other number would satisfy any expression.

Let's call wildcard of length x tail of regular expression of form [0−9]{x}. Let's build Aho-Corasick automaton for all prefixes of regular expressions until wildcards. For every regular expression put in corresponding node length of wildcard. After that task could be solved using dynamic programming. State would be length of prefix of answer and node of the automaton. From state (i,v) we can go by digit d to the state (i+1,u), u is node where d leads from v. Value for (i+1,u) should be updated by value for (i,v) plus number of wildcards with lengths not exceeding n−i−1, placed in nodes reachable from u by suffix links in automaton. This value can be calculated beforehand for every pair node and length. Asymptotics of solution is O((|l|+|r|)⋅n⋅Σ2), where Σ is size of alphabet, i.e. 10.


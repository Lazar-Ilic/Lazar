CHAPTER 1
Introduction I
I.I The Scope and Nature of Econometrics I
1.2 The Organization of the Book 3
PART I: FUNDAMENTAL METHODOLOGY 5
CHAPTER 2
Review of Ordinary Least Squares and General ized Least Squares 7
2.I Introduction 7
2.2 The Classical Linear Regression Model 7
2.3 Ordinary Least Squares and the Gauss-Markov Theorem 9
2.4 Large Sample Properties of Ordinary Least Squares Estimators 12
2.5 Generalized Least Squares and Aitken's Theorem 16
2.6 Properties of the Ordinary Least Squares Estimators in the Context
of the Generalized Least Squares Model 18
2.7 Summary and Guide to Further Readings 20
2.8 Exercises ' 21
2.9 References 25
CHAPTER 3
Point Estimation and Tests of Hypotheses in Small Samples 26
3.I Introduction 26
3.2 Maximum Likelihood Estimation 27
3.3 Small Sample Estimation Theory 3I
3.3.1 Minimum Variance Unbiased Through Cramer-Rae
Lower Bound Approach 32
3.3.2 Small Sample Efficiency of ji and 82 34
3.3.3 Minimum Variance Unbiased Through Complete-Sufficient
Statistics Approach 35
IX
x
3.4 Tests of Hypotheses in Small Samples
3.5 Confidence Intervals
3.6 Summary and Guide to Further Readings
3.7 Appendix : Proof of Cramer-Rae Theorem
3.8 Exercises
3.9 References
CHAPTER 4
Large Sample Point Estimation and Tests of Hypotheses
4.1 Introduction
4.2 Asymptotic Distribution Theory
4.3 Asymptotic Efficiency of jJ and {j2 Under Normality
4.4 Nonnormal Disturbances
4.5 Summary and Guide to Further Readings
4.6 Exercises
4.7 References
CHAPTER 5
Stochastic Regressors
5.1 Introduction
5.2 Multivariate Normal Linear Regression Model
5.3 Independent Stochastic Linear Regression Model
5.4 Summary and Guide to Further Readings
5.5 Exercises
5.6 References
Contents
36
41
42
43
45
50
52
52
53
59
62
65
66
69
70
70
71
72
77
78
79
CHAPTER 6
Use of Prior Information 80
6.1 Introduction 80
6.2 Restricted Least Squares: Exact General Linear Restrictions 81
6.2.1 Dimension of Parameter Space 81
6.2.2 Correct Restrictions 82
6.2.3 Alternative Views of Restricted Least Squares 84
6.2.4 Incorrect Restrictions 85
6.3 Mixed Estimation: Stochastic Linear Restrictions 88
6.3.1 Nature of Stochastic Restrictions 88
6.3.2 Implications of Biased Restrictions 90
6.3.3 Feasible Mixed Estimation 91
6.3.4 Restricted Least Squares and Ordinary Least Squares as Limiting
Cases of Mixed Estimation 92
6.3.5 A Reformulation of the Mixed Estimation Model 93
6.4 Mean Square Error Criteria 97
6.5 Inequality Restricted Least Squares 102
6.5.1 Derivation ofInequality Restricted Least Squares Estimator \02
Contents xi
6.5.2 Sampling Properties ofInequality Restricted Least Squares Estimator 105
6.5.3 Comparison of Restricted Least Squares and Mixed Estimation with
Inequality Restricted Least Squares 106
6.6 Bayesian Procedures and Prior Information 108
6.6.1 Basic Concepts in Bayesian Analysis 108
6.6.2 Relationship Between Bayesian and Sampling Theory Approaches 110
6.7 Summary and Guide to Further Readings 111
6.8 Exercises 114
6.9 References 119
CHAPTER 7
Preliminary Test and Stein-Rule Estimators 122
7.1 Introduction 122
7.2 Pretest Estimators 123
7.2.1 The Orthonormal Linear Statistical Model 123
7.2.2 The Pretest Estimator 124
7.2.3 Properties of the Pretest Estimator 125
7.2.4 The Choice of the Optimal Value of ex for Pretesting 127
7.2.5 The Pretest Estimator in the General Linear Statistical Model 128
7.2.6 Some General Remarks About the Consequences and Scope of
Preliminary Test Procedures 130
7.3 Stein-Rule Estimat ors for the Orthonormal Linear Regression Model 131
7.3.1 The James and Stein Estimator 131
7.3.2 The James-Stein Positive Rule Estimator 134
7.3.3 Sclove's Modified Positive-Part Rule 137
7.4 Stein-Rule Estimator s for the General Linear Model 137
7.5 Summary and Guide to Further Readings 139
7.6 Exercises 140
7.7 References 143
PART II: VIOLATIONS OF BASIC ASSUMPTIONS 145
CHAPTER 8
Feasible Generalized Least Squares Estimation 147
8.1 Introduction 147
8.2 Definition of Feasible Generalized Least Squares 148
8.3 Properties of Feasible Generalized Least Squares Estimators 150
8.3.1 FeasibleGeneralized Least Squares in the Absenceof Normal Errors 150
8.3.2 FeasibleGeneralized Least Squares in the Presenceof Normal Errors 151
8.4 An Example of Feasible Generalized Least Squares: Seemingly Unrelated
Regressions 155
8.5 Seemingly Unrelated Regressions Estimation : Asymptotic Results 160
8.6 Seemingly Unrelated Regre ssions Estimation : Small Sample Results 162
8.7 Summary and Guide to Further Readings 166
8.8 Exercises 167
8.9 References 169
xii
CHAPTER 9
Heteroscedasticity
Contents
170
9.1 Introduction 170
9.2 Estimation Under Various Forms of Heteroscedasticity 174
9.2.1 Grouped Heteroscedasticity 174
9.2.2 Heteroscedasticity as a Function of Exogenous Variables 176
9.2.2a Varianceas a Linear Function of Exogenous Variables:(It = ZiIJ. 177
9.2.2b Standard Deviation as a Linear Function of Exogenous
Variables: a, = ZiIJ. 180
9.2.2c Multiplicative Heteroscedasticity :(It = exp(ziIJ.) 183
9.2.2d Heteroscedasticity of Known but General Functional Form :
MaximumLikelihoodEstimation 186
9.3 Tests for Heteroscedasticity 187
9.3.1 Likelihood Ratio Test for Grouped Heteroscedasticity 188
9.3.2 Tests for Heteroscedasticity Which Are Specific Functions of
ExogenousVariables 189
9.3.2a Tests of Varianceas a Linear Function of Exogenous
Variables:(It = ZiIJ. 189
9.3.2b Tests of Standard Deviation as a Linear Function of
Exogenous Variables: a, = Z;IJ. 190
9.3.2c Tests for Multiplicative Heteroscedasticity:(It = exp(ziIJ.) 191
9.3.2d Tests Involving Heteroscedasticityof Known but General
Form: MaximumLikelihood Methods 192
9.3.3 Nonspecific Tests for Heteroscedasticity 193
9.3.3a Goldfeld-Quandt Test 193
9.3.3b Peak Test 194
9.3.3c Breush-Pagan Test 195
9.3.3d White's General HeteroscedasticityTest 196
9.4 Chow Test Under Heteroscedasticity 197
9.4.1 Jayatissa's Test 199
9.5 Summary and Guide to Further Readings 201
9.6 Exercises 202
9.7 References 204
CHAPTER 10
Autocorrelation 205
10.1 Introduction 205
10.2 Autoregressive Error Structure AR(I) 206
10.3 Maximum Likelihood Estimation of AR(I) 208
10.3.1 Maximum LikelihoodSearch 208
10.3.2 Cochrane-Orcutt Iterative Procedure 209
10.3.3 Hildreth-Lu Search Procedure 210
10.4 Two-Step Methods 211
10.5 Small Sample Estimation in the AR(I) Model 213
10.6 Other Correlated Error Structures 215
10.7 Feasible Generalized Least Squares for AR(2), MA(I), and ARMA(p, q) 217
10.7.1 Estimation for AR(2) Process 217
10.7.2 Estimation for MA(I) Process 219
10.7.3 Estimation for General ARMA(p, q) Process 221
Contents xiii
10.8 Testing for AR(l) Error Process 222
10.8.1 The Durbin-Watson Test 222
10.8.2 The Inconclusive Region 225
1O.8.2a Approximate Methods 225
10.8.2b Nonparametric Test 226
1O.8.2c Transformations of Ordinary Least Squares Residuals 228
10.8.2d Imhof Technique 228
10.8.3 Power Comparisonsof Various AR(I) Tests 229
10.9 Testing ARMA(p, q) Processes 229
10.10 Summary and Guide to Further Readings 231
10.1I Exercises 232
10.12 References 235
CHAPTER II
Lagged Dependent Variables and Autcorrelation 237
ILl Introduction 237
11.2 Lagged Dependent Variable Model (Autoregressive Linear Model) 238
11.3 Lagged Dependent Variable Models with Autocorrelated Errors 242
11.3.1 Inconsistency of Ordinary Least Squares 242
11.3.2 Durbin hÂ·test 244
11.3.3 Estimation of the Lagged Dependent Variable Model with
Autocorrelated Errors 245
11.4 Feasible Generalized Least Squares and Contemporaneous Correlation 249
11.5 Hatanaka's Estimator 251
11.6 Summary and Guide to Further Readings 253
11.7 Appendix : Instrumental Variables 254
II. 7.1 Motivation 254
11.7.2 Theoretical Results 254
11.7.3 Criteria for Selectionof Z 258
11.7.4 LaggedVariablesas Instruments 259
11.7.5 AsymptoticInefficiency of Instrumental Variable Estimators 260
11.7.6 Case of Surplus Instruments 261
11.8 Exercises 263
11.9 References 266
CHAPTER 12
Unobservable Variables 268
12.1 Introduction
12.2 Maximum Likelihood Approach
12.3 Instrumental Variable Methods
12.3.1 Wald's Grouping Method
12.3.2 Durbin's Ranking Procedure
12.4 The Use ofIncidental Equations
12.5 Summary and Guide to Further Readings
12.6 Exercises
12.7 References
268
271
273
273
274
275
276
277
279
xiv Contents
PART III: SPECIAL TOPICS 281
CHAPTER 13
Multicollinearity 283
13.1 Introduction 283
13.2 The Nature and Statistical Consequences of Multicollinearity 284
13.2.1 Exact Multicollinearity 285
13.2.2 Near Exact Multicollinearity 285
13.2.3 Principal Components 287
13.2.4 The Geometry of Principal Components 288
13.3 Detection of the Presence and Form of Multicollinearity 293
13.4 Improved Estimation in the Context of Multicollinearity 296
13.4.1 Principal Components Regression 298
13.4.2 Ridge Regression 300
13.5 Summary and Guide to Further Readings 303
13.6 Exercises 304
13.7 References 305
CHAPTER 14
Varying Coefficient Models 307
14.1 Introduction 307
14.2 Dummy Variables and Sets of Regression Equations 308
14.3 Switching Regression Models 312
14.3.1 Piecewise Regression Models: Known Join Point 312
14.3.2 Piecewise Regression Models: Unknown Join Point 313
14.4 Systematically Varying Parameter Models 314
14.5 Random Coefficient Models 316
14.5.1 The Hildreth-Houck Random Coefficient Model 316
14.5.2 The Swamy Random Coefficient Model 317
14.5.3 Models with Coefficients That Evolve Over Time 319
14.6 Summary and Gu ide to Further Readings 320
14.7 Exerc ises 321
14.8 References 321
CHAPTER 15
Models That Combine Time-Series and Cross-Section Data 324
15.1 Introduction 324
15.2 Models in Which All Variation Is Contained in the Error Term 325
15.3 Models Where All Structural Change Is Captured by the Intercept 328
15.3.1 Dummy Variable Models 328
15.3.la Dummy Variable Models Where the Intercept Varies
Over Individuals 328
15.3.lb Dummy Variable Models Where the Intercept Varies
Over Individuals and Time 330
15.3.2 Error Components with Variation Only Over Individuals 332
15.3.2a Generalized Least Squares Estimation 333
15.3.2b Estimation of the Variance Components 333
15.3.3 Error Components Models with Variation Over Individuals and Time 334
Contents
15.4 Models Where All Coefficients Are Allowed to Vary
15.5 Summary and Guide to Further Readings
15.6 Exercises
15.7 References
xv
336
337
338
338
CHAPTER 16
The Analysis of Models with Qualitative or Censored
Dependent Variables 339
16.1 Introduction 339
16.2 A Framework for Studying Models with Binary Dependent Variables 340
16.3 Feasible Generalized Least Squares Estimation of Probit and Logit
Models When Repeated Observations Are Available 344
16.3.1 Feasible Generalized Least Squares Estimation of the Probit Model 345
16.3.2 Feasible Generalized Least Squares Estimation of the Logit Model 346
16.3.3 An Interpretive Note 348
16.4 Maximum Likelihood Estimation of Logit and Probit Models 348
16.5 General Choice Models 352
16.6 Analysis of Models with Censored Dependent Variables 358
16.6.1 Heckman's Analysis of Censored Samples 358
16.6.2 Maximum Likelihood Estimation of Models with Censored Samples 360
16.6.3 An Interpretive Note 364
16.7 Summary and Guide to Further Readings 364
16.8 Exercises 367
16.9 References 367
CHAPTER 17
Distributed Lags 371
17.1 Introduction 371
17.2 Finite Distributed Lags 373
17.2.1 The Arithmetic Lag 373
17.2.2 Lag Operators and Restrictions on Polynomial Distributed Lags 375
17.2.3 The Almon Polynomial Distributed Lag 377
17.2.4 Summary and Guide to Further Readings on Finite Lags 380
17.3 Geometric Lag Structures 381
17.3.1 Model Formulation 381
17.3.la Partial Adjustment Models 382
17.3.lb Adaptive Expectations Models 384
17.3.2 Estimation of the Geometric Lag 384
17.3.2a Estimation of the Autoregressive Form of the Geometric Lag 384
17.3.2b Estimation of the Direct Form of the Geometric Lag 386
17.3.3 Summary and Guide to Further Readings on Geometric Lags 390
17.4 Other Infinite Lag Structures 390
17.4.1 The Pascal Lag 391
17.4.2 The Rational Distributed Lag 391
17.4.3 The Gamma Distributed Lag 392
17.4.4 The Exponential Lag 392
17.5 Exercises 392
17.6 References 397
xvi
CHAPTER 18
Uncertainty in Model Specification and Selection
Contents
400
18.1 Introduction 400
18.2 Classical Specification Analysis 401
18.2.1 Effects of Omitting Relevant Variables or Including Irrelevant Variables 401
18.2.2 Other Forms of Misspecification in Regression Variables 405
18.3 Specification Error Tests 407
18.3.1 Traditional Tests for Relevant Variables 408
18.3.2 Tests for Omitted Variables and Incorrect Functional Form When the
Alternatives Are Nonspecific 409
18.3.3 Hausman 's Test 412
18.4 Choice Between Competing Nonnested Models 414
18.4.1 Mechanical Nesting 415
18.4.2 Residual Variance (Adjusted R2 ) Criterion 416
18.4.3 The Cox Generalized Likelihood Ratio Procedure : Peseran's Results 418
18.4.4 Other Work on Discriminating Between Alternative Models 422
18.5 Choice of Functional Form: Box-Cox Transformation 423
18.5.1 Motivation 423
18.5.2 Maximum Likelihood Estimation 426
18.5.3 Overstatement of Significance by the Ordinary Least Squares
Covariance Matrix 430
18.6 Summary and Guide to Further Readings 431
18.7 Exercises 432
18.8 References 435
PART IV: SIMULTANEOUS EQUATIONS
MODELS 4TI !
CHAPTER 19
Introduction to Simultaneous Equations Models 439
19.1 Introduction 439
19.2 The Simultaneous Equations Problem 439
19.3 Notation and Assumptions 443
19.4 Ordinary Least Squares Estimation of the Reduced Form 445
19.5 Summary and Guide to Further Readings 448
19.6 Exercises 449
19.7 References 449
CHAPTER 20
Identification 451
20.1 Introduction
20.2 The Identification Problem
20.3 Admissible Transformations
20.4 Identification Using Linear Homogeneous Restrictions
20.5 Identification Using Covariance Restrictions
20.6 Ordinary Least Squares and Simple Recursive Systems
20.7 Summary and Guide to Further Readings
20.8 Exercises
20.9 References
451
451
455
457
463
467
468
469
470
Contents xvii
CHAPTER 21
Limited Information Estimation 472
21.1 Introduction 472
21.2 Indirect Least Squares 473
21.3 Two-Stage Least Squares 475
21.4 Two-Stage Least Squares as Aitken and Instrumental Variable Estimators 478
21.5 Asymptotic Properties of Two-Stage Least Squares Estimators 482
21.6 k-Class Estimators 486
21.7 Limited Information Maximum Likelihood 487
21.8 Summary and Guide to Further Readings 490
21.9 Exercises 492
21.10 References 495
CHAPTER 22
Full Information Estimation 499
22.1 Introduction 499
22.2 Three-Stage Least Squares 500
22.3 Asymptotic Distribution of Three-Stage Least Squares Est imators and
Relative Efficiency 501
22.4 Use of Linear Hypotheses in Simultaneous Equations 503
22.4.1 Restricted Three-Stage Least Squares Estimation 503
22.4.2 Tests of Linear Hypotheses Using Three-Stage Least Squares Estimates 505
22.5 Full Information Maximum Likelihood 505
22.6 Summary and Guide to Further Readings 506
22.7 Exercises 508
22.8 References 510
CHAPTER 23
Reduced Form Estimation and Prediction in Simultaneous
Equations Models 512
23.1 Introduction 512
23.2 Restricted Reduced Form 513
23.3 Forecasting in Simultaneous Equations Models with Usual Error
Assumptions 518
23.4 Forecasting-with an Autocorrelated Error Structure 524
23.5 Summary and Guide to Further Readings 526
23.6 Exercises 528
23.7 References 528
CHAPTER 24
Properties of Dynamic Simultaneous Equations Models 530
24.1 Introduction 530
24.2 Final Form and Dynamic Multipliers 531
24.3 Efficient Estimation and Asymptotic Distribution of Dynamic Multipliers 539
24.4 Stability and Standard Error of Dominant Characteristic Root 543
24.5 Standard Errors of Dynamic Simulation Forecasts 545
XVIII
24.6 Optimal Control in Dynamic Simultaneous Equations Models
24.7 Summary and Gu ide to Further Readings
24.8 Exercises
24.9 References
Contents
547
549
551
551
PART V: FRONTIERS 553
CHAPTER 25
Special Topics in Simultaneous Equations 555
25.1 Introduction 555
25.2 A Simultaneous Equations Tobit Model 555
25.2.1 Exercises 562
25.2.2 References 562
25.3 A Simultaneous Equations Generalized Pro bit Model 562
25.3.1 Exercise 566
25.3.2 References 566
25.4 Disequilibrium Econometric Models 567
25.4.1 References 575
25.5 Vector Autoregressive Error Processes in Simultaneous Equations Models 576
25.5.1 Covariance Structure of the Vector Autoregressive Error Structure 578
25.5.2 Two-Step Estimation of Simultaneous Equations with Vector
Autoregressive Error Structure and No Lagged Dependent Variables 582
25.5.3 Tests of Hypotheses R = 0 and R = diag(rII' . . . , rGd when No
Lagged Dependent Variables Are Present 583
25.5.4 Two-Step Estimation of a Simultaneous Equations Model with
Vector AutoregressiveError Structure and Lagged Dependent Variables 585
25.5.4a A Wallis-Like Two-Step Estimator 586
25.5.4b Hatanaka's Residual Adjusted Two-Step Estimator for
Simultaneous Equations with Vector Autoregressive
Error Processes 587
25.5.5 Final Comments 588
25.5.6 References 589
25.6 Rational Expectations 590
25.6.1 Rationality and Model Specification 590
25.6.2 Estimation 593
25.6.3 Applications 594
25.6.4 Exercises 595
25.6.5 References 596
25.7 Updating 597
25.7.1 Mixed Estimation and Kalman Filtering 597
25.7.2 Implications for Experimental Design 599
25.7.3 Conclusions 600
25.7.4 Exercises 601
25.7.5 References 601
APPENDIX
Estimation and Inference in Nonlinear Statistical Models 603
A.l Nonlinear Optimization
A.1.1 Method of Steepest Ascent
A.1.2 The Method of Newton
603
605
606
Contents xix
A.I.3 Method of Quadratic Hill Climbing 606
A.lA Nume rical Differentiation 608
A.2 Maximum Likelihood Estimation 610
A.2.l Use of the Method of Newton 610
A.2.2 Method of Scoring 611
A.2.3 The Method of Berndt, Hall, Hall, and Hausman 612
A.2A Asymptot ic Tests Based on the Maximum Likelihood Method 612
A.2Aa The Wald Test 612
A.2Ab The Lagrange-Multiplier Test 613
A.2.4c The Likelihood Ratio Test Statistic 613
A.2Ad Concluding Remarks 614
A.3 Nonlinear Regression 614
AA Summary and Guide to Further Read ings 615
A.5 References 616
Index 619